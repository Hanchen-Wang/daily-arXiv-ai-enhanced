<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 276]
- [cs.CL](#cs.CL) [Total: 178]
- [cs.AI](#cs.AI) [Total: 153]
- [cs.DB](#cs.DB) [Total: 7]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [EDU-CIRCUIT-HW: Evaluating Multimodal Large Language Models on Real-World University-Level STEM Student Handwritten Solutions](https://arxiv.org/abs/2602.00095)
*Weiyu Sun,Liangliang Chen,Yongnuo Cai,Huiru Xie,Yi Zeng,Ying Zhang*

Main category: cs.CV

TL;DR: 研究者发布EDU-CIRCUIT-HW数据集，包含1300+大学STEM课程学生手写解答，评估多模态大语言模型在识别和自动评分中的表现，发现大量潜在错误，并提出通过错误模式检测提升系统鲁棒性的方法。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在解读学生手写解答（包含数学公式、图表和文本推理）方面存在挑战，缺乏真实领域特定基准，且现有评估主要依赖下游任务（如自动评分），无法全面评估模型对复杂手写逻辑的理解。

Method: 发布EDU-CIRCUIT-HW数据集，包含1300+真实学生手写解答，利用专家验证的逐字转录和评分报告，同时评估多种MLLM的上游识别保真度和下游自动评分性能。通过错误模式分析，提出预检测和纠正识别错误的方法。

Result: 评估揭示了MLLM在学生手写内容识别中存在惊人的潜在错误规模，表明模型在高风险教育环境中的自动评分和其他理解导向应用可靠性不足。案例研究表明，利用识别的错误模式预检测和纠正错误（仅需约4%人工干预）能显著提升AI评分系统在未见学生解答上的鲁棒性。

Conclusion: MLLM在学生手写解答识别和自动评分方面仍存在显著可靠性问题，但通过错误模式分析和最小化人工干预的预检测机制，可以显著提升AI教育系统的实用性和鲁棒性。

Abstract: Multimodal Large Language Models (MLLMs) hold significant promise for revolutionizing traditional education and reducing teachers' workload. However, accurately interpreting unconstrained STEM student handwritten solutions with intertwined mathematical formulas, diagrams, and textual reasoning poses a significant challenge due to the lack of authentic and domain-specific benchmarks. Additionally, current evaluation paradigms predominantly rely on the outcomes of downstream tasks (e.g., auto-grading), which often probe only a subset of the recognized content, thereby failing to capture the MLLMs' understanding of complex handwritten logic as a whole. To bridge this gap, we release EDU-CIRCUIT-HW, a dataset consisting of 1,300+ authentic student handwritten solutions from a university-level STEM course. Utilizing the expert-verified verbatim transcriptions and grading reports of student solutions, we simultaneously evaluate various MLLMs' upstream recognition fidelity and downstream auto-grading performance. Our evaluation uncovers an astonishing scale of latent failures within MLLM-recognized student handwritten content, highlighting the models' insufficient reliability for auto-grading and other understanding-oriented applications in high-stakes educational settings. In solution, we present a case study demonstrating that leveraging identified error patterns to preemptively detect and rectify recognition errors, with only minimal human intervention (approximately 4% of the total solutions), can significantly enhance the robustness of the deployed AI-enabled grading system on unseen student solutions.

</details>


### [2] [Mirage2Matter: A Physically Grounded Gaussian World Model from Video](https://arxiv.org/abs/2602.00096)
*Zhengqing Gao,Ziwen Li,Xin Wang,Jiaxin Huang,Zhenyang Ren,Mingkai Shao,Hanlue Zhang,Tianyu Huang,Yongkang Cheng,Yandong Guo,Runqi Lin,Yuanyuan Wang,Tongliang Liu,Kun Zhang,Mingming Gong*

Main category: cs.CV

TL;DR: Simulate Anything：基于多视角视频和现成资产的图形驱动世界建模与仿真框架，通过3D高斯泼溅重建真实环境，生成高质量具身训练数据，VLA模型在零样本任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 具身智能的可扩展性受到真实世界交互数据稀缺的限制。现有仿真平台存在视觉和物理差距，依赖昂贵传感器、精确标定或深度测量，限制了大规模实用性。

Method: 1. 使用3D高斯泼溅从多视角环境视频重建真实世界为逼真场景表示；2. 利用生成模型恢复物理真实表示；3. 通过精度标定目标集成到仿真环境，实现重建场景与真实世界的精确尺度对齐。

Result: 基于仿真数据训练的视觉语言动作模型在下游任务中实现强大的零样本性能，匹配甚至超越使用真实世界数据的结果。

Conclusion: 重建驱动的世界建模为可扩展且实用的具身智能训练提供了潜力，通过图形驱动的仿真框架能够高效生成高质量训练数据。

Abstract: The scalability of embodied intelligence is fundamentally constrained by the scarcity of real-world interaction data. While simulation platforms provide a promising alternative, existing approaches often suffer from a substantial visual and physical gap to real environments and rely on expensive sensors, precise robot calibration, or depth measurements, limiting their practicality at scale. We present Simulate Anything, a graphics-driven world modeling and simulation framework that enables efficient generation of high-fidelity embodied training data using only multi-view environment videos and off-the-shelf assets. Our approach reconstructs real-world environments into a photorealistic scene representation using 3D Gaussian Splatting (3DGS), seamlessly capturing fine-grained geometry and appearance from video. We then leverage generative models to recover a physically realistic representation and integrate it into a simulation environment via a precision calibration target, enabling accurate scale alignment between the reconstructed scene and the real world. Together, these components provide a unified, editable, and physically grounded world model. Vision Language Action (VLA) models trained on our simulated data achieve strong zero-shot performance on downstream tasks, matching or even surpassing results obtained with real-world data, highlighting the potential of reconstruction-driven world modeling for scalable and practical embodied intelligence training.

</details>


### [3] [R3G: A Reasoning--Retrieval--Reranking Framework for Vision-Centric Answer Generation](https://arxiv.org/abs/2602.00104)
*Zhuohong Chen,Zhengxian Wu,Zirui Liao,Shenao Jiang,Hangrui Xu,Yang Chen,Chaokui Su,Xiaoyu Liu,Haoqian Wang*

Main category: cs.CV

TL;DR: R3G是一个模块化的推理-检索-重排框架，通过生成推理计划指导视觉信息检索，采用两阶段策略（粗检索+细粒度重排）为VQA任务选择证据图像，在MRAG-Bench上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 视觉中心检索在VQA任务中需要为模型提供缺失的视觉线索，但如何选择合适的图像并有效整合到推理过程中仍然具有挑战性。

Method: 提出R3G框架：首先生成简要推理计划明确所需视觉线索，然后采用两阶段策略（粗检索+细粒度重排）选择证据图像，最后将选定的图像整合到推理过程中。

Result: 在MRAG-Bench上，R3G提升了六个MLLM骨干网络和九个子场景的准确率，实现了整体最先进的性能。消融实验表明充分感知的重排和推理步骤是互补的。

Conclusion: R3G框架通过模块化的推理-检索-重排设计，有效解决了VQA任务中视觉信息检索和整合的挑战，为视觉增强问答提供了有效的解决方案。

Abstract: Vision-centric retrieval for VQA requires retrieving images to supply missing visual cues and integrating them into the reasoning process. However, selecting the right images and integrating them effectively into the model's reasoning remains challenging.To address this challenge, we propose R3G, a modular Reasoning-Retrieval-Reranking framework.It first produces a brief reasoning plan that specifies the required visual cues, then adopts a two-stage strategy, with coarse retrieval followed by fine-grained reranking, to select evidence images.On MRAG-Bench, R3G improves accuracy across six MLLM backbones and nine sub-scenarios, achieving state-of-the-art overall performance. Ablations show that sufficiency-aware reranking and reasoning steps are complementary, helping the model both choose the right images and use them well. We release code and data at https://github.com/czh24/R3G.

</details>


### [4] [HYPE-EDIT-1: Benchmark for Measuring Reliability in Frontier Image Editing Models](https://arxiv.org/abs/2602.00105)
*Wing Chan,Richard Allen*

Main category: cs.CV

TL;DR: HYPE-EDIT-1是一个包含100个任务的基准测试，用于评估基于参考的市场/设计图像编辑模型，通过二元通过/失败判断，测量每次尝试通过率、通过@10、重试次数和有效编辑成本。


<details>
  <summary>Details</summary>
Motivation: 现有图像编辑模型的公开演示通常展示最佳案例，但实际工作流程需要多次重试和人工审核时间，缺乏真实成本评估标准。

Method: 创建100个参考图像编辑任务，每个任务生成10个独立输出，使用二元通过/失败判断，计算每次尝试通过率、通过@10、重试上限下的预期尝试次数，以及结合模型价格和人工审核时间的有效成功编辑成本。

Result: 评估模型的每次尝试通过率在34-83%之间，有效成功成本在0.66-1.42美元之间。低单图定价的模型在考虑重试和人工审核总成本后更昂贵。

Conclusion: 需要综合考虑模型定价、重试率和人工审核时间来评估图像编辑模型的真实成本效益，仅看单次定价会误导决策。

Abstract: Public demos of image editing models are typically best-case samples; real workflows pay for retries and review time. We introduce HYPE-EDIT-1, a 100-task benchmark of reference-based marketing/design edits with binary pass/fail judging. For each task we generate 10 independent outputs to estimate per-attempt pass rate, pass@10, expected attempts under a retry cap, and an effective cost per successful edit that combines model price with human review time. We release 50 public tasks and maintain a 50-task held-out private split for server-side evaluation, plus a standardized JSON schema and tooling for VLM and human-based judging. Across the evaluated models, per-attempt pass rates span 34-83 percent and effective cost per success spans USD 0.66-1.42. Models that have low per-image pricing are more expensive when you consider the total effective cost of retries and human reviews.

</details>


### [5] [Efficient UAV trajectory prediction: A multi-modal deep diffusion framework](https://arxiv.org/abs/2602.00107)
*Yuan Gao,Xinyu Guo,Wenjing Xie,Zifan Wang,Hongwen Yu,Gongyang Li,Shugong Xu*

Main category: cs.CV

TL;DR: 提出一种基于LiDAR与毫米波雷达信息融合的多模态无人机轨迹预测方法，通过双向交叉注意力机制实现模态互补，在MMAUD数据集上相比基线模型提升40%准确率。


<details>
  <summary>Details</summary>
Motivation: 为满足低空经济中管理未经授权无人机的需求，需要准确预测无人机轨迹。单一传感器存在局限性，需要融合LiDAR和毫米波雷达的多模态信息来提升预测精度。

Method: 设计多模态深度融合框架，包含两个模态特定特征提取网络和双向交叉注意力融合模块。LiDAR和雷达使用独立但结构相同的特征编码器，通过双向交叉注意力机制实现信息互补和语义对齐。

Result: 在CVPR 2024 UG2+挑战赛的MMAUD数据集上，多模态融合模型相比基线模型轨迹预测准确率提升40%。消融实验验证了不同损失函数和后处理策略对性能提升的有效性。

Conclusion: 提出的多模态融合模型能有效利用LiDAR和雷达的互补信息，为低空经济中未经授权无人机轨迹预测提供了高效解决方案，显著提升了预测精度。

Abstract: To meet the requirements for managing unauthorized UAVs in the low-altitude economy, a multi-modal UAV trajectory prediction method based on the fusion of LiDAR and millimeter-wave radar information is proposed. A deep fusion network for multi-modal UAV trajectory prediction, termed the Multi-Modal Deep Fusion Framework, is designed. The overall architecture consists of two modality-specific feature extraction networks and a bidirectional cross-attention fusion module, aiming to fully exploit the complementary information of LiDAR and radar point clouds in spatial geometric structure and dynamic reflection characteristics. In the feature extraction stage, the model employs independent but structurally identical feature encoders for LiDAR and radar. After feature extraction, the model enters the Bidirectional Cross-Attention Mechanism stage to achieve information complementarity and semantic alignment between the two modalities. To verify the effectiveness of the proposed model, the MMAUD dataset used in the CVPR 2024 UG2+ UAV Tracking and Pose-Estimation Challenge is adopted as the training and testing dataset. Experimental results show that the proposed multi-modal fusion model significantly improves trajectory prediction accuracy, achieving a 40% improvement compared to the baseline model. In addition, ablation experiments are conducted to demonstrate the effectiveness of different loss functions and post-processing strategies in improving model performance. The proposed model can effectively utilize multi-modal data and provides an efficient solution for unauthorized UAV trajectory prediction in the low-altitude economy.

</details>


### [6] [SITUATE -- Synthetic Object Counting Dataset for VLM training](https://arxiv.org/abs/2602.00108)
*René Peinl,Vincent Tischler,Patrick Schröder,Christian Groth*

Main category: cs.CV

TL;DR: SITUATE是一个用于训练和评估视觉语言模型在空间约束计数任务上的新数据集，填补了简单2D数据集和模糊现实数据集之间的空白。


<details>
  <summary>Details</summary>
Motivation: 现有计数数据集存在局限性：像VLMCountBench这样的简单2D数据集缺乏真实世界的复杂性，而像TallyQA这样的现实数据集又存在遮挡和空间组合模糊的问题，缺乏控制。需要一个新的数据集来填补这个空白。

Method: 提出了SITUATE数据集，专门设计用于训练和评估具有空间约束的计数任务。通过实验验证，在Qwen VL 2.5 7B模型上对SITUATE进行微调，并与Pixmo count测试数据和其他计数基准进行交叉验证比较。

Result: 在SITUATE上微调的Qwen VL 2.5 7B模型在Pixmo count测试数据上提高了准确性，但反之则不成立。这表明SITUATE有助于提高模型在分布外图像上的泛化能力。

Conclusion: SITUATE数据集有效地填补了现有计数数据集的空白，能够提升视觉语言模型在空间约束计数任务上的泛化性能，特别是在处理分布外图像时表现更优。

Abstract: We present SITUATE, a novel dataset designed for training and evaluating Vision Language Models on counting tasks with spatial constraints. The dataset bridges the gap between simple 2D datasets like VLMCountBench and often ambiguous real-life datasets like TallyQA, which lack control over occlusions and spatial composition. Experiments show that our dataset helps to improve generalization for out-of-distribution images, since a finetune of Qwen VL 2.5 7B on SITUATE improves accuracy on the Pixmo count test data, but not vice versa. We cross validate this by comparing the model performance across established other counting benchmarks and against an equally sized fine-tuning set derived from Pixmo count.

</details>


### [7] [Robustness of Presentation Attack Detection in Remote Identity Validation Scenarios](https://arxiv.org/abs/2602.00109)
*John J. Howard,Richard O. Plesh,Yevgeniy B. Sirotin,Jerry L. Tipton,Arun R. Vemury*

Main category: cs.CV

TL;DR: 商用PAD系统在低光照和自动采集场景下性能显著下降，仅一个系统能保持稳定性能


<details>
  <summary>Details</summary>
Motivation: 远程身份验证系统中，演示攻击检测子系统在多样环境条件下的鲁棒性仍面临挑战，需要研究低光照和自动图像采集对商用PAD系统性能的影响

Method: 通过远程身份验证的场景测试，评估商用PAD系统在低光照条件和自动采集工作流程下的性能表现

Result: PAD系统在低光照条件下错误率增加约4倍，在自动采集工作流程下错误率翻倍；仅有一个测试系统在所有场景下保持最大真实演示分类错误率低于3%

Conclusion: 为确保PAD系统在真实应用中的鲁棒性和可靠性，必须在多样化环境条件下进行测试

Abstract: Presentation attack detection (PAD) subsystems are an important part of effective and user-friendly remote identity validation (RIV) systems. However, ensuring robust performance across diverse environmental and procedural conditions remains a critical challenge. This paper investigates the impact of low-light conditions and automated image acquisition on the robustness of commercial PAD systems using a scenario test of RIV. Our results show that PAD systems experience a significant decline in performance when utilized in low-light or auto-capture scenarios, with a model-predicted increase in error rates by a factor of about four under low-light conditions and a doubling of those odds under auto-capture workflows. Specifically, only one of the tested systems was robust to these perturbations, maintaining a maximum bona fide presentation classification error rate below 3% across all scenarios. Our findings emphasize the importance of testing across diverse environments to ensure robust and reliable PAD performance in real-world applications.

</details>


### [8] [Observing Health Outcomes Using Remote Sensing Imagery and Geo-Context Guided Visual Transformer](https://arxiv.org/abs/2602.00110)
*Yu Li,Guilherme N. DeSouza,Praveen Rao,Chi-Ren Shyu*

Main category: cs.CV

TL;DR: 提出一种新颖的视觉-地理空间多模态模型，通过地理空间嵌入机制和引导注意力模块，将辅助地理信息与遥感图像结合，提升地理空间理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有视觉transformer和视觉语言模型主要关注语义对齐，缺乏对结构化地理空间层的理解和推理能力，无法有效利用辅助地理信息进行遥感图像分析。

Method: 1) 地理空间嵌入机制：将多样化的地理空间数据转换为与图像块空间对齐的嵌入块；2) 引导注意力模块：基于与辅助数据的相关性动态计算注意力权重，引导模型关注相关区域；3) 注意力头角色分配：让不同注意力头捕捉指导信息的互补方面，提高预测可解释性。

Result: 实验结果表明，该框架在预测疾病流行率等任务上优于现有的预训练地理空间基础模型，证明了其在多模态地理空间理解方面的有效性。

Conclusion: 该研究提出的模型成功地将辅助地理信息与遥感图像处理相结合，通过创新的地理空间嵌入和引导注意力机制，显著提升了地理空间理解能力，为遥感图像分析提供了更强大的多模态解决方案。

Abstract: Visual transformers have driven major progress in remote sensing image analysis, particularly in object detection and segmentation. Recent vision-language and multimodal models further extend these capabilities by incorporating auxiliary information, including captions, question and answer pairs, and metadata, which broadens applications beyond conventional computer vision tasks. However, these models are typically optimized for semantic alignment between visual and textual content rather than geospatial understanding, and therefore are not suited for representing or reasoning with structured geospatial layers. In this study, we propose a novel model that enhances remote sensing imagery processing with guidance from auxiliary geospatial information. Our approach introduces a geospatial embedding mechanism that transforms diverse geospatial data into embedding patches that are spatially aligned with image patches. To facilitate cross-modal interaction, we design a guided attention module that dynamically integrates multimodal information by computing attention weights based on correlations with auxiliary data, thereby directing the model toward the most relevant regions. In addition, the module assigns distinct roles to individual attention heads, allowing the model to capture complementary aspects of the guidance information and improving the interpretability of its predictions. Experimental results demonstrate that the proposed framework outperforms existing pretrained geospatial foundation models in predicting disease prevalence, highlighting its effectiveness in multimodal geospatial understanding.

</details>


### [9] [From Manual Observation to Automated Monitoring: Space Allowance Effects on Play Behaviour in Group-Housed Dairy Calves](https://arxiv.org/abs/2602.00111)
*Haiyu Yang,Heidi Lesscher,Enhong Liu,Miel Hostens*

Main category: cs.CV

TL;DR: 研究通过计算机视觉分析商业农场中犊牛空间分配与玩耍行为的关系，发现8-10平方米/犊牛的空间分配能最大化玩耍行为，并开发了高精度自动监测系统。


<details>
  <summary>Details</summary>
Motivation: 在商业条件下，空间分配对犊牛玩耍行为（作为积极福利指标）的影响尚不明确，特别是在6-20平方米的中高分配范围内。需要开发可扩展的自动监测方法来评估福利。

Method: 在荷兰14个商业农场对60头群养犊牛进行研究，空间范围2.66-17.98平方米/犊牛。使用详细行为谱分析视频观察，以观察期百分比表示玩耍行为。采用线性混合模型进行统计分析。开发基于108小时手动标注数据的计算机视觉管道，并在测试数据上验证。

Result: 计算机视觉分类器在主动玩耍检测上达到97.6%准确率和99.4%召回率。犊牛平均花费1.0%观察时间玩耍（约17小时中的10分钟）。空间与玩耍关系呈非线性，8-10平方米/犊牛时玩耍水平最高（1.6%），6-8平方米和12-14平方米时最低（<0.6%）。控制年龄、健康和群体大小后，空间影响仍显著。

Conclusion: 8-10平方米/犊牛的空间分配是平衡福利效益与经济可行性的实用目标。自动监测系统可将小规模标注项目扩展为连续福利评估系统，实现规模化监测。

Abstract: Play behaviour serves as a positive welfare indicator in dairy calves, yet the influence of space allowance under commercial conditions remains poorly characterized, particularly at intermediate-to-high allowances (6-20 m2 per calf). This study investigated the relationship between space allowance and play behaviour in 60 group-housed dairy calves across 14 commercial farms in the Netherlands (space range: 2.66-17.98 m2 per calf), and developed an automated computer vision pipeline for scalable monitoring. Video observations were analyzed using a detailed ethogram, with play expressed as percentage of observation period (%OP). Statistical analysis employed linear mixed models with farm as a random effect. A computer vision pipeline was trained on manual annotations from 108 hours on 6 farms and validated on held-out test data. The computer vision classifier achieved 97.6% accuracy with 99.4% recall for active play detection. Calves spent on average 1.0% of OP playing reflecting around 10 minutes per 17-hour period. The space-play relationship was non-linear, with highest play levels at 8-10 m2 per calf (1.6% OP) and lowest at 6-8 m2 and 12-14 m2 (<0.6% OP). Space remained significant after controlling for age, health, and group size. In summary, these findings suggest that 8-10 m2 per calf represents a practical target balancing welfare benefits with economic feasibility, and demonstrate that automated monitoring can scale small annotation projects to continuous welfare assessment systems.

</details>


### [10] [AI-Driven Three-Dimensional Reconstruction and Quantitative Analysis for Burn Injury Assessment](https://arxiv.org/abs/2602.00113)
*S. Kalaycioglu,C. Hong,K. Zhai,H. Xie,J. N. Wong*

Main category: cs.CV

TL;DR: AI平台整合多视角摄影测量、3D重建与深度学习分割，实现客观、可重复的烧伤评估与治疗管理


<details>
  <summary>Details</summary>
Motivation: 传统视觉检查和2D摄影评估烧伤存在主观性强、难以进行纵向比较的问题，需要客观、可重复的评估方法用于治疗规划、愈合监测和法医记录

Method: 整合多视角摄影测量、3D表面重建和深度学习分割技术，使用消费级相机采集多角度图像，重建患者特异性3D烧伤表面，计算客观指标（表面积、TBSA、深度相关几何代理、体积变化），并支持空间对齐的连续重建以量化愈合进程

Result: 模拟评估显示系统重建稳定、指标计算一致，能够产生临床合理的纵向趋势，支持可扩展、无创的几何感知烧伤评估和决策支持

Conclusion: 该AI平台为急性和门诊护理提供了客观、几何感知的烧伤评估和决策支持方法，具有临床实用性和可扩展性

Abstract: Accurate, reproducible burn assessment is critical for treatment planning, healing monitoring, and medico-legal documentation, yet conventional visual inspection and 2D photography are subjective and limited for longitudinal comparison. This paper presents an AI-enabled burn assessment and management platform that integrates multi-view photogrammetry, 3D surface reconstruction, and deep learning-based segmentation within a structured clinical workflow. Using standard multi-angle images from consumer-grade cameras, the system reconstructs patient-specific 3D burn surfaces and maps burn regions onto anatomy to compute objective metrics in real-world units, including surface area, TBSA, depth-related geometric proxies, and volumetric change. Successive reconstructions are spatially aligned to quantify healing progression over time, enabling objective tracking of wound contraction and depth reduction. The platform also supports structured patient intake, guided image capture, 3D analysis and visualization, treatment recommendations, and automated report generation. Simulation-based evaluation demonstrates stable reconstructions, consistent metric computation, and clinically plausible longitudinal trends, supporting a scalable, non-invasive approach to objective, geometry-aware burn assessment and decision support in acute and outpatient care.

</details>


### [11] [1S-DAug: One-Shot Data Augmentation for Robust Few-Shot Generalization](https://arxiv.org/abs/2602.00114)
*Yunwei Bai,Ying Kiat Tan,Yao Shu,Tsuhan Chen*

Main category: cs.CV

TL;DR: 1S-DAug：一种单样本生成增强算子，通过结合几何扰动、可控噪声注入和去噪扩散过程，从单个测试图像生成多样且忠实的变化，无需训练即可提升少样本学习性能。


<details>
  <summary>Details</summary>
Motivation: 少样本学习中，传统测试时增强方法在只有少量标记样本的情况下效果有限。需要一种能够从单个测试图像生成多样且忠实变体的增强方法，以提升模型在少样本场景下的泛化能力。

Method: 1S-DAug结合传统几何扰动、可控噪声注入和基于原始图像条件的去噪扩散过程，生成多样化的图像变体。生成的图像与原始图像一起编码并聚合为组合表示，用于更鲁棒的少样本学习预测。

Result: 在4个不同数据集的标准基准测试中，1S-DAug无需更新模型参数即可持续提升少样本学习性能，在miniImagenet 5-way-1-shot基准上实现了超过10%的比例精度提升。

Conclusion: 1S-DAug作为一种免训练、模型无关的插件，能够有效提升少样本学习性能，通过单样本生成增强解决了传统测试时增强在少样本场景下的局限性。

Abstract: Few-shot learning (FSL) challenges model generalization to novel classes based on just a few shots of labeled examples, a testbed where traditional test-time augmentations fail to be effective. We introduce 1S-DAug, a one-shot generative augmentation operator that synthesizes diverse yet faithful variants from just one example image at test time. 1S-DAug couples traditional geometric perturbations with controlled noise injection and a denoising diffusion process conditioned on the original image. The generated images are then encoded and aggregated, alongside the original image, into a combined representation for more robust FSL predictions. Integrated as a training-free model-agnostic plugin, 1S-DAug consistently improves FSL across standard benchmarks of 4 different datasets without any model parameter update, including achieving over 10% proportional accuracy improvement on the miniImagenet 5-way-1-shot benchmark. Codes will be released.

</details>


### [12] [Event Driven Clustering Algorithm](https://arxiv.org/abs/2602.00115)
*David El-Chai Ben-Ezra,Adar Tal,Daniel Brisk*

Main category: cs.CV

TL;DR: 提出一种新颖的异步事件驱动算法，用于实时检测事件相机数据中的小型事件簇，具有线性复杂度O(n)且运行时间与像素阵列维度无关。


<details>
  <summary>Details</summary>
Motivation: 事件相机产生异步事件流，传统聚类算法难以实时处理这种特殊数据结构，需要开发专门针对事件相机特性的高效实时聚类算法。

Method: 采用异步事件驱动架构，基于时空距离进行层次凝聚聚类，利用事件相机的特殊异步数据结构，通过复杂但高效简单的决策机制实现线性复杂度。

Result: 算法实现O(n)线性复杂度，运行时间与像素阵列维度无关，能够实时检测小型事件簇，适用于事件相机数据的高效处理。

Conclusion: 该算法为事件相机数据提供了一种高效、实时的聚类解决方案，特别适合需要实时处理的小型事件簇检测应用场景。

Abstract: This paper introduces a novel asynchronous, event-driven algorithm for real-time detection of small event clusters in event camera data. Like other hierarchical agglomerative clustering algorithms, the algorithm detects the event clusters based on their tempo-spatial distance. However, the algorithm leverages the special asynchronous data structure of event camera, and by a sophisticated, efficient and simple decision-making, enjoys a linear complexity of $O(n)$ where $n$ is the events amount. In addition, the run-time of the algorithm is independent with the dimensions of the pixels array.

</details>


### [13] [IC-EO: Interpretable Code-based assistant for Earth Observation](https://arxiv.org/abs/2602.00117)
*Lamia Lahouel,Laurynas Lopata,Simon Gruening,Gabriele Meoni,Gaetan Petit,Sylvain Lobry*

Main category: cs.CV

TL;DR: 提出一个基于工具LLM的对话式代码生成代理，将自然语言查询转换为可执行、可审计的Python工作流，用于地球观测分析，提高透明度和可重复性。


<details>
  <summary>Details</summary>
Motivation: 地球观测分析对非专家来说仍然困难，需要专业知识和技术能力，且现有系统多为黑盒预测，难以审计或复现。需要开发透明、可审计的分析工具。

Method: 利用工具LLM构建对话式代码生成代理，通过统一可扩展的API支持分类、分割、检测、光谱指数和地理空间操作。在三个层面控制结果：工具级性能、代理级代码生成质量、任务级特定用例。

Result: 代理在土地组成映射和野火后损害评估两个用例中优于通用LLM/VLM基线（GPT-4o、LLaVA），准确率分别为64.2% vs. 51.7%和50% vs. 0%，同时生成透明、可解释的结果。

Conclusion: 通过输出可验证的代码，该方法将地球观测分析转变为透明、可重复的过程，为非专家提供了易于使用且可审计的分析工具。

Abstract: Despite recent advances in computer vision, Earth Observation (EO) analysis remains difficult to perform for the laymen, requiring expert knowledge and technical capabilities. Furthermore, many systems return black-box predictions that are difficult to audit or reproduce. Leveraging recent advances in tool LLMs, this study proposes a conversational, code-generating agent that transforms natural-language queries into executable, auditable Python workflows. The agent operates over a unified easily extendable API for classification, segmentation, detection (oriented bounding boxes), spectral indices, and geospatial operators. With our proposed framework, it is possible to control the results at three levels: (i) tool-level performance on public EO benchmarks; (ii) at the agent-level to understand the capacity to generate valid, hallucination-free code; and (iii) at the task-level on specific use cases. In this work, we select two use-cases of interest: land-composition mapping and post-wildfire damage assessment. The proposed agent outperforms general-purpose LLM/VLM baselines (GPT-4o, LLaVA), achieving 64.2% vs. 51.7% accuracy on land-composition and 50% vs. 0% on post-wildfire analysis, while producing results that are transparent and easy to interpret. By outputting verifiable code, the approach turns EO analysis into a transparent, reproducible process.

</details>


### [14] [VDE Bench: Evaluating The Capability of Image Editing Models to Modify Visual Documents](https://arxiv.org/abs/2602.00122)
*Hongzhu Yi,Yujia Yang,Yuanxiang Wang,Zhenyu Guan,Jiahuan Chen,Chenxi Bao,Tiankun Yang,Yixuan Yuan,Tianyu Zong,Xinming Wang,Tao Yu,Ruiwen Tao,Haijin Liang,Jin Ma,Jinwen Luo,Yeshani Xinyu Zuo,Jungang Xu*

Main category: cs.CV

TL;DR: 提出了VDE Bench基准测试，用于评估多语言密集文本视觉文档编辑模型，填补了现有方法主要针对英文和稀疏布局文档的不足。


<details>
  <summary>Details</summary>
Motivation: 现有多模态图像编辑模型在视觉文档图像编辑方面研究不足，特别是对密集、结构复杂的文档和非拉丁文字（如中文）支持不够，缺乏系统评估基准。

Method: 构建了VDE Bench基准测试，包含高质量英文和中文密集文本文档数据集，并提出了解耦评估框架，在OCR解析层面系统量化编辑性能。

Result: 通过该基准对代表性SOTA图像编辑模型进行全面评估，人工验证显示人工判断与自动评估指标具有强一致性。

Conclusion: VDE Bench是首个用于评估多语言密集文本视觉文档编辑模型的系统基准，填补了该领域的研究空白。

Abstract: In recent years, multimodal image editing models have achieved substantial progress, enabling users to manipulate visual content through natural language in a flexible and interactive manner. Nevertheless, an important yet insufficiently explored research direction remains visual document image editing, which involves modifying textual content within images while faithfully preserving the original text style and background context. Existing approaches, including AnyText, GlyphControl, and TextCtrl, predominantly focus on English-language scenarios and documents with relatively sparse textual layouts, thereby failing to adequately address dense, structurally complex documents or non-Latin scripts such as Chinese. To bridge this gap, we propose \textbf{V}isual \textbf{D}oc \textbf{E}dit Bench(VDE Bench), a rigorously human-annotated and evaluated benchmark specifically designed to assess image editing models on multilingual and complex visual document editing tasks. The benchmark comprises a high-quality dataset encompassing densely textual documents in both English and Chinese, including academic papers, posters, presentation slides, examination materials, and newspapers. Furthermore, we introduce a decoupled evaluation framework that systematically quantifies editing performance at the OCR parsing level, enabling fine-grained assessment of text modification accuracy. Based on this benchmark, we conduct a comprehensive evaluation of representative state-of-the-art image editing models. Manual verification demonstrates a strong consistency between human judgments and automated evaluation metrics. VDE Bench constitutes the first systematic benchmark for evaluating image editing models on multilingual and densely textual visual documents.

</details>


### [15] [Context-Aware Autoencoders for Anomaly Detection in Maritime Surveillance](https://arxiv.org/abs/2602.00124)
*Divya Acharya,Pierre Bernab'e,Antoine Chevrot,Helge Spieker,Arnaud Gotlieb,Bruno Legeard*

Main category: cs.CV

TL;DR: 提出上下文感知自编码器用于海事异常检测，通过整合上下文特定阈值提高集体和上下文异常的检测精度，降低计算成本


<details>
  <summary>Details</summary>
Motivation: 传统自编码器在海事异常检测中效果有限，特别是对集体和上下文异常，因为海事异常依赖于船舶特定的上下文信息（来自AIS消息）

Method: 提出上下文感知自编码器，整合上下文特定阈值，比较四种变体和传统自编码器，以捕鱼状态异常为案例研究

Result: 上下文对重构损失和异常检测有显著影响，上下文感知自编码器在时间序列数据异常检测中表现最优

Conclusion: 通过整合上下文特定阈值并认识到上下文在异常检测中的重要性，该方法为提高海事船舶交通监控系统准确性提供了有前景的解决方案

Abstract: The detection of anomalies is crucial to ensuring the safety and security of maritime vessel traffic surveillance. Although autoencoders are popular for anomaly detection, their effectiveness in identifying collective and contextual anomalies is limited, especially in the maritime domain, where anomalies depend on vessel-specific contexts derived from self-reported AIS messages. To address these limitations, we propose a novel solution: the context-aware autoencoder. By integrating context-specific thresholds, our method improves detection accuracy and reduces computational cost. We compare four context-aware autoencoder variants and a conventional autoencoder using a case study focused on fishing status anomalies in maritime surveillance. Results demonstrate the significant impact of context on reconstruction loss and anomaly detection. The context-aware autoencoder outperforms others in detecting anomalies in time series data. By incorporating context-specific thresholds and recognizing the importance of context in anomaly detection, our approach offers a promising solution to improve accuracy in maritime vessel traffic surveillance systems.

</details>


### [16] [D3R-Net: Dual-Domain Denoising Reconstruction Network for Robust Industrial Anomaly Detection](https://arxiv.org/abs/2602.00126)
*Dmytro Filatov,Valentyn Fedorov,Vira Filatova,Andrii Zelenchuk*

Main category: cs.CV

TL;DR: D3R-Net：一种用于无监督异常检测的双域去噪重建框架，通过结合空间域和频域损失来改善高频细节的重建，提高缺陷分割精度。


<details>
  <summary>Details</summary>
Motivation: 现有基于重建的无监督异常检测方法存在过度平滑问题，无法有效重建高频细节，导致细微缺陷被部分重建而非突出显示，限制了分割精度。

Method: 提出D3R-Net框架，采用自监督"修复"任务和频域感知正则化。训练时使用合成损坏的正常图像重建干净目标，防止恒等映射。除了空间MSE损失外，引入FFT幅度损失确保频域一致性，可选SSIM损失。

Result: 在MVTec AD Hazelnut基准测试中，FFT损失将PRO AUC从0.603提升到0.687；在15个MVTec类别上，平均像素ROC AUC从0.733提升到0.751，PRO AUC从0.417提升到0.468，单GPU约20FPS。

Conclusion: D3R-Net通过双域重建框架有效解决了高频细节重建问题，提高了异常检测的定位一致性，为工业视觉检测提供了轻量实用的解决方案。

Abstract: Unsupervised anomaly detection (UAD) is a key ingredient of automated visual inspection in modern manufacturing. The reconstruction-based methods appeal because they have basic architectural design and they process data quickly but they produce oversmoothed results for high-frequency details. As a result, subtle defects are partially reconstructed rather than highlighted, which limits segmentation accuracy. We build on this line of work and introduce D3R-Net, a Dual-Domain Denoising Reconstruction framework that couples a self-supervised 'healing' task with frequency-aware regularization. During training, the network receives synthetically corrupted normal images and is asked to reconstruct the clean targets, which prevents trivial identity mapping and pushes the model to learn the manifold of defect-free textures. In addition to the spatial mean squared error, we employ a Fast Fourier Transform (FFT) magnitude loss that encourages consistency in the frequency domain. The implementation also allows an optional structural similarity (SSIM) term, which we study in an ablation. On the MVTec AD Hazelnut benchmark, D3R-Net with the FFT loss improves localization consistency over a spatial-only baseline: PRO AUC increases from 0.603 to 0.687, while image-level ROC AUC remains robust. Evaluated across fifteen MVTec categories, the FFT variant raises the average pixel ROC AUC from 0.733 to 0.751 and PRO AUC from 0.417 to 0.468 compared to the MSE-only baseline, at roughly 20 FPS on a single GPU. The network is trained from scratch and uses a lightweight convolutional autoencoder backbone, providing a practical alternative to heavy pre-trained feature embedding methods.

</details>


### [17] [PovNet+: A Deep Learning Architecture for Socially Assistive Robots to Learn and Assist with Multiple Activities of Daily Living](https://arxiv.org/abs/2602.00131)
*Fraser Robinson,Souren Pashangpour,Matthew Lisondra,Goldie Nejat*

Main category: cs.CV

TL;DR: POVNet+：首个用于社交辅助机器人的多模态深度学习架构，通过ADL和运动嵌入空间识别已知/未知/非典型ADL，主动发起辅助交互


<details>
  <summary>Details</summary>
Motivation: 社交辅助机器人长期部署的主要障碍是无法同时感知和辅助多项日常生活活动（ADL），需要能够识别已知ADL、未知ADL和非典型ADL执行方式的能力

Method: 提出POVNet+多模态深度学习架构，引入ADL和运动双重嵌入空间，结合新颖的用户状态估计方法，在运动嵌入空间中识别新ADL并监控用户表现

Result: 与最先进的人类活动识别方法相比，POVNet+具有更高的ADL分类准确率；在杂乱生活环境中的人机交互实验表明，系统能成功识别已知/未知/非典型ADL，并启动适当的辅助交互

Conclusion: POVNet+架构为社交辅助机器人提供了有效的多活动识别能力，能够主动发起辅助交互，解决了机器人长期部署中的关键感知障碍

Abstract: A significant barrier to the long-term deployment of autonomous socially assistive robots is their inability to both perceive and assist with multiple activities of daily living (ADLs). In this paper, we present the first multimodal deep learning architecture, POVNet+, for multi-activity recognition for socially assistive robots to proactively initiate assistive behaviors. Our novel architecture introduces the use of both ADL and motion embedding spaces to uniquely distinguish between a known ADL being performed, a new unseen ADL, or a known ADL being performed atypically in order to assist people in real scenarios. Furthermore, we apply a novel user state estimation method to the motion embedding space to recognize new ADLs while monitoring user performance. This ADL perception information is used to proactively initiate robot assistive interactions. Comparison experiments with state-of-the-art human activity recognition methods show our POVNet+ method has higher ADL classification accuracy. Human-robot interaction experiments in a cluttered living environment with multiple users and the socially assistive robot Leia using POVNet+ demonstrate the ability of our multi-modal ADL architecture in successfully identifying different seen and unseen ADLs, and ADLs being performed atypically, while initiating appropriate assistive human-robot interactions.

</details>


### [18] [Shedding the Facades, Connecting the Domains: Detecting Shifting Multimodal Hate Video with Test-Time Adaptation](https://arxiv.org/abs/2602.00132)
*Jiao Li,Jian Lang,Xikai Tang,Wenzheng Shu,Ting Zhong,Qiang Gao,Yong Wang,Leiting Chen,Fan Zhou*

Main category: cs.CV

TL;DR: SCANNER是一个针对仇恨视频检测的测试时自适应框架，通过利用仇恨内容的核心不变性来应对语义漂移问题，相比现有方法平均提升4.69%的Macro-F1分数。


<details>
  <summary>Details</summary>
Motivation: 仇恨视频检测面临严重挑战：仇恨内容不断演变为不规则和模糊形式以逃避审查，导致语义漂移，使训练好的模型失效。传统测试时自适应方法针对轻度分布偏移，难以处理仇恨视频检测中的严重语义漂移。

Method: 提出SCANNER框架：1）通过基于质心的对齐机制从模糊布局中揭示稳定核心；2）采用样本级自适应质心对齐策略减轻异常样本影响；3）引入簇内多样性正则化防止语义塌缩。

Result: 实验表明SCANNER优于所有基线方法，在Macro-F1指标上平均比最佳基线提升4.69%。

Conclusion: SCANNER是首个专门针对仇恨视频检测的测试时自适应框架，通过利用仇恨内容的核心不变性作为源域和目标域的桥梁，有效应对语义漂移问题。

Abstract: Hate Video Detection (HVD) is crucial for online ecosystems. Existing methods assume identical distributions between training (source) and inference (target) data. However, hateful content often evolves into irregular and ambiguous forms to evade censorship, resulting in substantial semantic drift and rendering previously trained models ineffective. Test-Time Adaptation (TTA) offers a solution by adapting models during inference to narrow the cross-domain gap, while conventional TTA methods target mild distribution shifts and struggle with the severe semantic drift in HVD. To tackle these challenges, we propose SCANNER, the first TTA framework tailored for HVD. Motivated by the insight that, despite the evolving nature of hateful manifestations, their underlying cores remain largely invariant (i.e., targeting is still based on characteristics like gender, race, etc), we leverage these stable cores as a bridge to connect the source and target domains. Specifically, SCANNER initially reveals the stable cores from the ambiguous layout in evolving hateful content via a principled centroid-guided alignment mechanism. To alleviate the impact of outlier-like samples that are weakly correlated with centroids during the alignment process, SCANNER enhances the prior by incorporating a sample-level adaptive centroid alignment strategy, promoting more stable adaptation. Furthermore, to mitigate semantic collapse from overly uniform outputs within clusters, SCANNER introduces an intra-cluster diversity regularization that encourages the cluster-wise semantic richness. Experiments show that SCANNER outperforms all baselines, with an average gain of 4.69% in Macro-F1 over the best.

</details>


### [19] [LLaVA-FA: Learning Fourier Approximation for Compressing Large Multimodal Models](https://arxiv.org/abs/2602.00135)
*Pengcheng Zheng,Chaoning Zhang,Jiarong Mo,GuoHui Li,Jiaquan Zhang,Jiahao Zhang,Sihan Cao,Sheng Zheng,Caiyan Qin,Guoqing Wang,Yang Yang*

Main category: cs.CV

TL;DR: LLaVA-FA：一种在频域进行联合低秩+量化近似的高效多模态模型，通过傅里叶变换特性实现更紧凑准确的权重表示，显著降低计算和内存成本。


<details>
  <summary>Details</summary>
Motivation: 现有大型多模态模型计算和内存成本过高，阻碍实际部署。现有压缩方法将低秩分解和量化解耦，导致重建误差累积，特别是在存在跨模态冗余的多模态架构中。

Method: 1. 在频域进行联合低秩+量化近似；2. 利用傅里叶变换的去相关和共轭对称特性；3. 提出PolarQuant，针对复数矩阵的极坐标量化方法；4. 引入可选对角校准方案，无需大规模校准数据。

Result: LLaVA-FA在多个基准测试中优于现有高效多模态模型，同时保持最少的激活参数和低计算成本，验证了其作为LMM压缩方案的有效性。

Conclusion: LLaVA-FA通过频域联合压缩方法有效解决了多模态模型压缩中的误差累积问题，为实际部署提供了强大解决方案。

Abstract: Large multimodal models (LMMs) have achieved impressive performance on various vision-language tasks, but their substantial computational and memory costs hinder their practical deployment. Existing compression methods often decouple low-rank decomposition and quantization, leading to compounded reconstruction errors, especially in multimodal architectures with cross-modal redundancy. To address this issue, we propose LLaVA-FA, a novel efficient LMM that performs joint low-rank plus quantization approximation in the frequency domain. By leveraging the de-correlation and conjugate symmetry properties of Fourier transform, LLaVA-FA achieves more compact and accurate weight representations. Furthermore, we introduce PolarQuant, a polar-coordinate quantization method tailored for complex matrices, and an optional diagonal calibration (ODC) scheme that eliminates the need for large-scale calibration data. Extensive experimental results demonstrate that our proposed LLaVA-FA outperforms existing efficient multimodal models across multiple benchmarks while maintaining minimal activated parameters and low computational costs, validating its effectiveness as a powerful solution for compressing LMMs.

</details>


### [20] [Scalable Analytic Classifiers with Associative Drift Compensation for Class-Incremental Learning of Vision Transformers](https://arxiv.org/abs/2602.00144)
*Xuan Rao,Mingming Ha,Bo Zhao,Derong Liu,Cesare Alippi*

Main category: cs.CV

TL;DR: 提出LR-RGDA和HopDC框架，解决Vision Transformers在类增量学习中分类器重建的计算瓶颈问题，通过低秩分解和Hopfield网络实现高效且准确的增量学习。


<details>
  <summary>Details</summary>
Motivation: Vision Transformers在类增量学习中面临分类器重建的计算瓶颈，现有方法依赖昂贵的迭代SGD。虽然分析性RGDA能达到与SGD相当的精度，但其二次推理复杂度限制了在大规模场景中的应用。

Method: 提出LR-RGDA（低秩分解RGDA），利用Woodbury矩阵恒等式分解协方差矩阵，将判别函数分解为全局仿射项和低秩二次扰动，将推理复杂度从O(Cd²)降低到O(d²+Crd²)。同时引入HopDC（Hopfield分布补偿器），使用现代连续Hopfield网络通过关联记忆动态重新校准历史类统计量，以缓解骨干网络更新引起的表示漂移。

Result: 在多个类增量学习基准测试中取得了最先进的性能，为Vision Transformers的大规模类增量学习提供了可扩展的解决方案。

Conclusion: LR-RGDA结合了RGDA的表达能力和线性分类器的效率，HopDC有效缓解了表示漂移问题，共同构成了一个高效且准确的类增量学习框架，特别适用于大规模场景。

Abstract: Class-incremental learning (CIL) with Vision Transformers (ViTs) faces a major computational bottleneck during the classifier reconstruction phase, where most existing methods rely on costly iterative stochastic gradient descent (SGD). We observe that analytic Regularized Gaussian Discriminant Analysis (RGDA) provides a Bayes-optimal alternative with accuracy comparable to SGD-based classifiers; however, its quadratic inference complexity limits its use in large-scale CIL scenarios. To overcome this, we propose Low-Rank Factorized RGDA (LR-RGDA), a scalable classifier that combines RGDA's expressivity with the efficiency of linear classifiers. By exploiting the low-rank structure of the covariance via the Woodbury matrix identity, LR-RGDA decomposes the discriminant function into a global affine term refined by a low-rank quadratic perturbation, reducing the inference complexity from $\mathcal{O}(Cd^2)$ to $\mathcal{O}(d^2 + Crd^2)$, where $C$ is the class number, $d$ the feature dimension, and $r \ll d$ the subspace rank. To mitigate representation drift caused by backbone updates, we further introduce Hopfield-based Distribution Compensator (HopDC), a training-free mechanism that uses modern continuous Hopfield Networks to recalibrate historical class statistics through associative memory dynamics on unlabeled anchors, accompanied by a theoretical bound on the estimation error. Extensive experiments on diverse CIL benchmarks demonstrate that our framework achieves state-of-the-art performance, providing a scalable solution for large-scale class-incremental learning with ViTs. Code: https://github.com/raoxuan98-hash/lr_rgda_hopdc.

</details>


### [21] [DensiThAI, A Multi-View Deep Learning Framework for Breast Density Estimation using Infrared Images](https://arxiv.org/abs/2602.00145)
*Siva Teja Kakileti,Geetha Manjunath*

Main category: cs.CV

TL;DR: DensiThAI：基于红外热成像和多视角深度学习的乳腺密度分类框架，无需电离辐射，AUROC达0.73


<details>
  <summary>Details</summary>
Motivation: 乳腺组织密度是乳腺癌风险的关键生物标志物，但目前主要依赖X射线钼靶（电离辐射成像）。需要开发无辐射的替代方法来评估乳腺密度，改善患者体验和工作流程。

Method: 提出DensiThAI多视角深度学习框架，利用5个标准热成像视角，基于纤维腺体和脂肪组织不同的热物理和生理特性导致的表面温度差异，从红外热图像进行乳腺密度分类。

Result: 在包含3,500名女性的多中心数据集上评估，使用钼靶密度标签作为参考。在10个随机分割中平均AUROC为0.73，所有分割中密度类别间均有统计学显著差异（p << 0.05），在不同年龄组中表现一致。

Conclusion: 热成像作为无辐射的乳腺密度评估方法具有潜力，能够改善患者体验和工作流程优化，为乳腺癌风险评估提供新的非电离成像途径。

Abstract: Breast tissue density is a key biomarker of breast cancer risk and a major factor affecting mammographic sensitivity. However, density assessment currently relies almost exclusively on X-ray mammography, an ionizing imaging modality. This study investigates the feasibility of estimating breast density using artificial intelligence over infrared thermal images, offering a non-ionizing imaging approach. The underlying hypothesis is that fibroglandular and adipose tissues exhibit distinct thermophysical and physiological properties, leading to subtle but spatially coherent temperature variations on the breast surface. In this paper, we propose DensiThAI, a multi-view deep learning framework for breast density classification from thermal images. The framework was evaluated on a multi-center dataset of 3,500 women using mammography-derived density labels as reference. Using five standard thermal views, DensiThAI achieved a mean AUROC of 0.73 across 10 random splits, with statistically significant separation between density classes across all splits (p << 0.05). Consistent performance across age cohorts supports the potential of thermal imaging as a non-ionizing approach for breast density assessment with implications for improved patient experience and workflow optimization.

</details>


### [22] [Learning Physics-Grounded 4D Dynamics with Neural Gaussian Force Fields](https://arxiv.org/abs/2602.00148)
*Shiqian Li,Ruihong Shen,Junfeng Ni,Chang Pan,Chi Zhang,Yixin Zhu*

Main category: cs.CV

TL;DR: NGFF是一个端到端神经框架，结合3D高斯感知与物理动力学建模，从多视角RGB输入生成交互式、物理真实的4D视频，速度比现有高斯模拟器快两个数量级。


<details>
  <summary>Details</summary>
Motivation: 当前视频生成模型虽然视觉质量高，但缺乏物理规律建模，无法生成物理合理的视频。现有结合3D高斯溅射和物理引擎的方法计算成本高，在复杂现实场景中缺乏鲁棒性。

Method: 提出Neural Gaussian Force Field (NGFF)框架，集成3D高斯感知与基于物理的动态建模。同时创建GSCollision数据集，包含64万+渲染物理视频（约4TB），涵盖多种材料、多物体交互和复杂场景。

Result: NGFF在合成和真实3D场景评估中展现出强大的泛化能力和物理推理鲁棒性，速度比现有高斯模拟器快两个数量级。

Conclusion: NGFF通过神经物理建模推进视频预测向物理基础的世界模型发展，为生成交互式、物理真实的4D视频提供了高效解决方案。

Abstract: Predicting physical dynamics from raw visual data remains a major challenge in AI. While recent video generation models have achieved impressive visual quality, they still cannot consistently generate physically plausible videos due to a lack of modeling of physical laws. Recent approaches combining 3D Gaussian splatting and physics engines can produce physically plausible videos, but are hindered by high computational costs in both reconstruction and simulation, and often lack robustness in complex real-world scenarios. To address these issues, we introduce Neural Gaussian Force Field (NGFF), an end-to-end neural framework that integrates 3D Gaussian perception with physics-based dynamic modeling to generate interactive, physically realistic 4D videos from multi-view RGB inputs, achieving two orders of magnitude faster than prior Gaussian simulators. To support training, we also present GSCollision, a 4D Gaussian dataset featuring diverse materials, multi-object interactions, and complex scenes, totaling over 640k rendered physical videos (~4 TB). Evaluations on synthetic and real 3D scenarios show NGFF's strong generalization and robustness in physical reasoning, advancing video prediction towards physics-grounded world models.

</details>


### [23] [SDCM: Simulated Densifying and Compensatory Modeling Fusion for Radar-Vision 3-D Object Detection in Internet of Vehicles](https://arxiv.org/abs/2602.00149)
*Shucong Li,Xiaoluo Zhou,Yuqian He,Zhenyu Liu*

Main category: cs.CV

TL;DR: SDCM框架通过模拟密度化、雷达补偿映射和Mamba建模交互融合，解决4D雷达-视觉3D目标检测中的稀疏点云和视觉退化问题，在多个数据集上取得最佳性能。


<details>
  <summary>Details</summary>
Motivation: 4D雷达点云稀疏导致3D表示不佳，视觉数据在低光照、远距离和密集遮挡场景下存在表示退化问题，影响融合效果。

Method: 1. SimDen模块：基于3D核密度估计的关键点高斯模拟生成点云，基于曲率模拟生成轮廓，实现雷达点云密度化；2. RCM模块：利用雷达全天候特性补偿视觉数据退化；3. MMIF模块：提取特征张量差异值，建模异质性减少和模态交互。

Result: 在VoD、TJ4DRadSet和Astyx HiRes 2019数据集上取得最佳性能，同时具有更少的参数量和更快的推理速度。

Conclusion: SDCM框架有效解决了雷达-视觉融合中的稀疏性和视觉退化问题，通过模拟密度化和补偿建模实现了更好的3D目标检测性能。

Abstract: 3-D object detection based on 4-D radar-vision is an important part in Internet of Vehicles (IoV). However, there are two challenges which need to be faced. First, the 4-D radar point clouds are sparse, leading to poor 3-D representation. Second, vision datas exhibit representation degradation under low-light, long distance detection and dense occlusion scenes, which provides unreliable texture information during fusion stage. To address these issues, a framework named SDCM is proposed, which contains Simulated Densifying and Compensatory Modeling Fusion for radar-vision 3-D object detection in IoV. Firstly, considering point generation based on Gaussian simulation of key points obtained from 3-D Kernel Density Estimation (3-D KDE), and outline generation based on curvature simulation, Simulated Densifying (SimDen) module is designed to generate dense radar point clouds. Secondly, considering that radar data could provide more real time information than vision data, due to the all-weather property of 4-D radar. Radar Compensatory Mapping (RCM) module is designed to reduce the affects of vision datas' representation degradation. Thirdly, considering that feature tensor difference values contain the effective information of every modality, which could be extracted and modeled for heterogeneity reduction and modalities interaction, Mamba Modeling Interactive Fusion (MMIF) module is designed for reducing heterogeneous and achieving interactive Fusion. Experiment results on the VoD, TJ4DRadSet and Astyx HiRes 2019 dataset show that SDCM achieves best performance with lower parameter quantity and faster inference speed. Our code will be available.

</details>


### [24] [Investigating the Impact of Histopathological Foundation Models on Regressive Prediction of Homologous Recombination Deficiency](https://arxiv.org/abs/2602.00151)
*Alexander Blezinger,Wolfgang Nejdl,Ming Tang*

Main category: cs.CV

TL;DR: 该研究系统评估了组织病理学基础模型在回归任务中的应用，特别是同源重组缺陷（HRD）评分预测，发现基础模型特征优于对比学习基线，并提出分布上采样策略改善数据不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 尽管大规模组织病理学基础模型在计算病理学多个领域取得成功，但其在回归性生物标志物预测方面的影响尚未充分探索。HRD评分作为个性化癌症治疗的关键生物标志物，需要更精确的预测方法。

Method: 在多实例学习框架下，从全切片图像中提取五个最先进基础模型的patch级特征，并与对比学习特征进行比较。在乳腺癌、子宫内膜癌和肺癌队列上训练模型预测连续HRD评分，提出分布上采样策略解决目标不平衡问题，并通过消融研究分析不同采样策略和实例包大小的影响。

Result: 基于基础模型特征的模型在预测准确性和泛化能力上持续优于基线，不同基础模型间存在系统性差异。分布上采样策略显著提高了对临床重要但代表性不足患者群体的召回率和平衡准确率。

Conclusion: 大规模组织病理学预训练能够实现更精确和可迁移的回归性生物标志物预测，展示了其在推进AI驱动的精准肿瘤学方面的潜力。

Abstract: Foundation models pretrained on large-scale histopathology data have found great success in various fields of computational pathology, but their impact on regressive biomarker prediction remains underexplored. In this work, we systematically evaluate histopathological foundation models for regression-based tasks, demonstrated through the prediction of homologous recombination deficiency (HRD) score - a critical biomarker for personalized cancer treatment. Within multiple instance learning frameworks, we extract patch-level features from whole slide images (WSI) using five state-of-the-art foundation models, and evaluate their impact compared to contrastive learning-based features. Models are trained to predict continuous HRD scores based on these extracted features across breast, endometrial, and lung cancer cohorts from two public medical data collections. Extensive experiments demonstrate that models trained on foundation model features consistently outperform the baseline in terms of predictive accuracy and generalization capabilities while exhibiting systematic differences among the foundation models. Additionally, we propose a distribution-based upsampling strategy to mitigate target imbalance in these datasets, significantly improving the recall and balanced accuracy for underrepresented but clinically important patient populations. Furthermore, we investigate the impact of different sampling strategies and instance bagsizes by ablation studies. Our results highlight the benefits of large-scale histopathological pretraining for more precise and transferable regressive biomarker prediction, showcasing its potential to advance AI-driven precision oncology.

</details>


### [25] [Real-Time Human Activity Recognition on Edge Microcontrollers: Dynamic Hierarchical Inference with Multi-Spectral Sensor Fusion](https://arxiv.org/abs/2602.00152)
*Boyu Li,Kuangji Zuo,Lincong Li,Yonghui Wu*

Main category: cs.CV

TL;DR: 提出HPPI-Net网络，通过多光谱融合和可解释模块实现边缘设备上实时人体活动识别，在ARM Cortex-M4上达到96.70%准确率，仅使用22.3 KiB RAM和439.5 KiB ROM。


<details>
  <summary>Details</summary>
Motivation: 边缘应用中需要准确且计算受限的模式识别，现有方法难以平衡准确率和计算约束之间的矛盾。

Method: 采用资源感知的分层网络架构：第一层使用FFT频谱图提取初步特征；第二层根据活动类型选择专用模块（静态活动）或并行LSTM-MobileNet网络（动态活动）。PLMN融合FFT、小波和Gabor三种频谱图，通过并行LSTM编码器、高效通道注意力和深度可分离卷积减少计算量并提供通道级可解释性。

Result: 在ARM Cortex-M4微控制器上实现低功耗实时推理，达到96.70%准确率，仅使用22.3 KiB RAM和439.5 KiB ROM。相比MobileNetV3，准确率提升1.22%，RAM使用减少71.2%，ROM使用减少42.1%。

Conclusion: HPPI-Net在准确率和效率之间取得了良好平衡，提供可解释的预测，为可穿戴设备、工业和智能家居等内存受限的边缘平台提供了实用解决方案。

Abstract: The demand for accurate on-device pattern recognition in edge applications is intensifying, yet existing approaches struggle to reconcile accuracy with computational constraints. To address this challenge, a resource-aware hierarchical network based on multi-spectral fusion and interpretable modules, namely the Hierarchical Parallel Pseudo-image Enhancement Fusion Network (HPPI-Net), is proposed for real-time, on-device Human Activity Recognition (HAR). Deployed on an ARM Cortex-M4 microcontroller for low-power real-time inference, HPPI-Net achieves 96.70% accuracy while utilizing only 22.3 KiB of RAM and 439.5 KiB of ROM after optimization. HPPI-Net employs a two-layer architecture. The first layer extracts preliminary features using Fast Fourier Transform (FFT) spectrograms, while the second layer selectively activates either a dedicated module for stationary activity recognition or a parallel LSTM-MobileNet network (PLMN) for dynamic states. PLMN fuses FFT, Wavelet, and Gabor spectrograms through three parallel LSTM encoders and refines the concatenated features using Efficient Channel Attention (ECA) and Depthwise Separable Convolution (DSC), thereby offering channel-level interpretability while substantially reducing multiply-accumulate operations. Compared with MobileNetV3, HPPI-Net improves accuracy by 1.22% and reduces RAM usage by 71.2% and ROM usage by 42.1%. These results demonstrate that HPPI-Net achieves a favorable accuracy-efficiency trade-off and provides explainable predictions, establishing a practical solution for wearable, industrial, and smart home HAR on memory-constrained edge platforms.

</details>


### [26] [See Without Decoding: Motion-Vector-Based Tracking in Compressed Video](https://arxiv.org/abs/2602.00153)
*Axel Duché,Clément Chatelain,Gilles Gasso*

Main category: cs.CV

TL;DR: 提出轻量级压缩域跟踪模型，直接在视频流上操作，无需完整RGB解码，利用压缩数据中的运动向量和变换系数，实现3.7倍计算加速，仅带来4% mAP@0.5下降


<details>
  <summary>Details</summary>
Motivation: 在大规模监控系统中，实时视频分析需要高效处理。传统方法需要完整解码RGB视频，计算成本高。压缩域数据（如运动向量和变换系数）包含丰富信息，可直接用于跟踪，减少解码开销

Method: 使用压缩数据中的运动向量和变换系数构建深度学习模型，直接在压缩域传播目标边界框。模型轻量级设计，避免完整RGB解码，利用编解码器域的运动建模信息

Result: 在MOTS15/17/20数据集上，相比RGB基线方法，计算速度提升最高达3.7倍，仅带来4% mAP@0.5的性能下降。证明了编解码器域运动建模的高效性

Conclusion: 压缩域跟踪模型能显著提升计算效率，适合大规模监控系统的实时分析。利用压缩数据中的运动信息可有效减少解码开销，同时保持较好的跟踪精度

Abstract: We propose a lightweight compressed-domain tracking model that operates directly on video streams, without requiring full RGB video decoding. Using motion vectors and transform coefficients from compressed data, our deep model propagates object bounding boxes across frames, achieving a computational speed-up of order up to 3.7 with only a slight 4% mAP@0.5 drop vs RGB baseline on MOTS15/17/20 datasets. These results highlight codec-domain motion modeling efficiency for real-time analytics in large monitoring systems.

</details>


### [27] [Deep Learning Pose Estimation for Multi-Label Recognition of Combined Hyperkinetic Movement Disorders](https://arxiv.org/abs/2602.00163)
*Laura Cif,Diane Demailly,Gabriella A. Horvàth,Juan Dario Ortigoza Escobar,Nathalie Dorison,Mayté Castro Jiménez,Cécile A. Hubsch,Thomas Wirth,Gun-Marie Hariz,Sophie Huby,Morgan Dornadic,Zohra Souei,Muhammad Mushhood Ur Rehman,Simone Hemm,Mehdi Boulayme,Eduardo M. Moraud,Jocelyne Bloch,Xavier Vasques*

Main category: cs.CV

TL;DR: 开发基于姿态的机器学习框架，将门诊视频转换为关键点时间序列，计算运动学特征来客观识别和监测运动障碍


<details>
  <summary>Details</summary>
Motivation: 运动障碍（如肌张力障碍、震颤、舞蹈症等）的临床表现波动、间歇且常重叠，临床识别和监测主要依赖主观评估，缺乏客观、可扩展的方法来区分这些重叠表型

Method: 开发基于姿态的机器学习框架，将标准门诊视频转换为解剖学意义的关键点时间序列，计算统计、时域、频域和高阶不规则性-复杂性特征等运动学描述符

Result: 论文描述了方法框架，但未在摘要中提供具体实验结果

Conclusion: 该框架为运动障碍的客观识别和纵向监测提供了新的技术途径，有望改善临床评估的主观性和变异性问题

Abstract: Hyperkinetic movement disorders (HMDs) such as dystonia, tremor, chorea, myoclonus, and tics are disabling motor manifestations across childhood and adulthood. Their fluctuating, intermittent, and frequently co-occurring expressions hinder clinical recognition and longitudinal monitoring, which remain largely subjective and vulnerable to inter-rater variability. Objective and scalable methods to distinguish overlapping HMD phenotypes from routine clinical videos are still lacking. Here, we developed a pose-based machine-learning framework that converts standard outpatient videos into anatomically meaningful keypoint time series and computes kinematic descriptors spanning statistical, temporal, spectral, and higher-order irregularity-complexity features.

</details>


### [28] [YOLOE-26: Integrating YOLO26 with YOLOE for Real-Time Open-Vocabulary Instance Segmentation](https://arxiv.org/abs/2602.00168)
*Ranjan Sapkota,Manoj Karkee*

Main category: cs.CV

TL;DR: YOLOE-26是一个统一框架，结合了YOLOv26的部署优化架构和YOLOE的开放词汇学习范式，用于实时开放词汇实例分割。


<details>
  <summary>Details</summary>
Motivation: 将YOLO系列的高效确定性扩展到开放词汇识别，超越传统的封闭集识别，为动态真实世界环境提供实用的实时开放词汇实例分割解决方案。

Method: 采用卷积骨干网络和PAN/FPN多尺度特征聚合，用对象嵌入头替换固定类别logits，通过相似度匹配进行分类。包含RepRTA零开销文本提示、SAVPE示例引导分割和Lazy Region Prompt Contrast无提示推理等技术。

Result: 实验显示在不同模型尺寸下均具有一致的扩展行为和良好的准确率-效率权衡，支持文本提示、视觉提示和完全自主分割的无缝切换。

Conclusion: YOLOE-26为动态真实世界环境中的实时开放词汇实例分割提供了实用且可扩展的解决方案，保持了YOLO家族的高效性和确定性。

Abstract: This paper presents YOLOE-26, a unified framework that integrates the deployment-optimized YOLO26(or YOLOv26) architecture with the open-vocabulary learning paradigm of YOLOE for real-time open-vocabulary instance segmentation. Building on the NMS-free, end-to-end design of YOLOv26, the proposed approach preserves the hallmark efficiency and determinism of the YOLO family while extending its capabilities beyond closed-set recognition. YOLOE-26 employs a convolutional backbone with PAN/FPN-style multi-scale feature aggregation, followed by end-to-end regression and instance segmentation heads. A key architectural contribution is the replacement of fixed class logits with an object embedding head, which formulates classification as similarity matching against prompt embeddings derived from text descriptions, visual examples, or a built-in vocabulary. To enable efficient open-vocabulary reasoning, the framework incorporates Re-Parameterizable Region-Text Alignment (RepRTA) for zero-overhead text prompting, a Semantic-Activated Visual Prompt Encoder (SAVPE) for example-guided segmentation, and Lazy Region Prompt Contrast for prompt-free inference. All prompting modalities operate within a unified object embedding space, allowing seamless switching between text-prompted, visual-prompted, and fully autonomous segmentation. Extensive experiments demonstrate consistent scaling behavior and favorable accuracy-efficiency trade-offs across model sizes in both prompted and prompt-free settings. The training strategy leverages large-scale detection and grounding datasets with multi-task optimization and remains fully compatible with the Ultralytics ecosystem for training, validation, and deployment. Overall, YOLOE-26 provides a practical and scalable solution for real-time open-vocabulary instance segmentation in dynamic, real-world environments.

</details>


### [29] [Intra-Class Subdivision for Pixel Contrastive Learning: Application to Semi-supervised Cardiac Image Segmentation](https://arxiv.org/abs/2602.00174)
*Jiajun Zhao,Xuan Yang*

Main category: cs.CV

TL;DR: 提出SPCL框架用于心脏图像分割，通过引入"不关心样本"概念和边界对比损失来解决边界表示污染问题，显著提升分割质量和边界精度。


<details>
  <summary>Details</summary>
Motivation: 解决心脏图像分割中边界区域表示污染的问题。传统方法在处理同一类别内不同区域（内部区域和边界区域）时，像素表示容易混淆，导致边界分割不精确。

Method: 1. 提出"不关心样本"概念，区分同一类别内的内部区域和边界区域像素表示；2. 设计边界对比损失函数，增强边界表示在跨边界时的区分能力；3. 构建类内细分像素对比学习框架（SPCL）。

Result: 在公开心脏数据集上的实验表明，SPCL显著提升了分割性能，在分割质量和边界精度方面优于现有方法。

Conclusion: SPCL框架通过类内细分和边界对比学习有效解决了边界表示污染问题，为心脏图像分割提供了更精确的解决方案，代码已开源。

Abstract: We propose an intra-class subdivision pixel contrastive learning (SPCL) framework for cardiac image segmentation to address representation contamination at boundaries. The novel concept ``Unconcerned sample'' is proposed to distinguish pixel representations at the inner and boundary regions within the same class, facilitating a clearer characterization of intra-class variations. A novel boundary contrastive loss for boundary representations is proposed to enhance representation discrimination across boundaries. The advantages of the unconcerned sample and boundary contrastive loss are analyzed theoretically. Experimental results in public cardiac datasets demonstrate that SPCL significantly improves segmentation performance, outperforming existing methods with respect to segmentation quality and boundary precision. Our code is available at https://github.com/Jrstud203/SPCL.

</details>


### [30] [Stabilizing Diffusion Posterior Sampling by Noise--Frequency Continuation](https://arxiv.org/abs/2602.00176)
*Feng Tian,Yixuan Li,Weili Zeng,Weitian Zhang,Yichao Yan,Xiaokang Yang*

Main category: cs.CV

TL;DR: 提出噪声-频率延续框架，通过构建中间后验分布，在噪声依赖频带内执行测量一致性，改善扩散后验采样中的细节恢复问题


<details>
  <summary>Details</summary>
Motivation: 传统扩散后验采样方法在结合预训练扩散先验和测量一致性指导时，常因测量项与扩散噪声水平弱耦合而无法恢复精细细节。高噪声下数据一致性梯度与后验几何不一致，导致早期漂移、伪高频伪影以及对调度和病态算子的敏感性

Method: 提出噪声-频率延续框架，构建连续中间后验分布，其似然仅在噪声依赖频带内强制执行测量一致性。实现稳定后验采样器，结合扩散预测器、带限似然指导和多分辨率一致性策略：积极采用可靠粗粒度修正，保守采用高频细节（仅当可识别时）

Result: 在超分辨率、修复和去模糊任务中实现最先进性能，运动去模糊PSNR相比强基线提升高达5dB

Conclusion: 通过噪声-频率延续框架和多分辨率一致性策略，有效解决了扩散后验采样中的细节恢复问题，显著提升了逆问题求解性能

Abstract: Diffusion posterior sampling solves inverse problems by combining a pretrained diffusion prior with measurement-consistency guidance, but it often fails to recover fine details because measurement terms are applied in a manner that is weakly coupled to the diffusion noise level. At high noise, data-consistency gradients computed from inaccurate estimates can be geometrically incongruent with the posterior geometry, inducing early-step drift, spurious high-frequency artifacts, plus sensitivity to schedules and ill-conditioned operators. To address these concerns, we propose a noise--frequency Continuation framework that constructs a continuous family of intermediate posteriors whose likelihood enforces measurement consistency only within a noise-dependent frequency band. This principle is instantiated with a stabilized posterior sampler that combines a diffusion predictor, band-limited likelihood guidance, and a multi-resolution consistency strategy that aggressively commits reliable coarse corrections while conservatively adopting high-frequency details only when they become identifiable. Across super-resolution, inpainting, and deblurring, our method achieves state-of-the-art performance and improves motion deblurring PSNR by up to 5 dB over strong baselines.

</details>


### [31] [CamReasoner: Reinforcing Camera Movement Understanding via Structured Spatial Reasoning](https://arxiv.org/abs/2602.00181)
*Hang Wu,Yujun Cai,Zehao Li,Haonan Ge,Bowen Sun,Junsong Yuan,Yiwei Wang*

Main category: cs.CV

TL;DR: CamReasoner：首个将相机运动理解重构为结构化推理过程的框架，采用观察-思考-回答范式，通过强化学习实现几何逻辑对齐，在多个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有多模态模型将相机运动理解视为黑盒分类任务，经常混淆物理上不同的运动，依赖表面视觉模式而非几何线索。需要弥合感知与电影逻辑之间的差距。

Method: 提出CamReasoner框架，采用观察-思考-回答（O-T-A）范式，迫使模型在显式推理块中解码轨迹和视锥体等时空线索。构建大规模推理轨迹套件（18k SFT推理链和38k RL反馈样本），首次在该领域使用强化学习进行逻辑对齐。

Result: 通过将强化学习应用于O-T-A推理范式，CamReasoner有效抑制幻觉，在多个基准测试中实现了最先进的性能。

Conclusion: CamReasoner通过结构化推理过程重新构建相机运动理解，将强化学习与几何逻辑对齐相结合，显著提升了模型对相机动态的理解能力，为视频空间智能提供了新范式。

Abstract: Understanding camera dynamics is a fundamental pillar of video spatial intelligence. However, existing multimodal models predominantly treat this task as a black-box classification, often confusing physically distinct motions by relying on superficial visual patterns rather than geometric cues. We present CamReasoner, a framework that reformulates camera movement understanding as a structured inference process to bridge the gap between perception and cinematic logic. Our approach centers on the Observation-Thinking-Answer (O-T-A) paradigm, which compels the model to decode spatio-temporal cues such as trajectories and view frustums within an explicit reasoning block. To instill this capability, we construct a Large-scale Inference Trajectory Suite comprising 18k SFT reasoning chains and 38k RL feedback samples. Notably, we are the first to employ RL for logical alignment in this domain, ensuring motion inferences are grounded in physical geometry rather than contextual guesswork. By applying Reinforcement Learning to the Observation-Think-Answer (O-T-A) reasoning paradigm, CamReasoner effectively suppresses hallucinations and achieves state-of-the-art performance across multiple benchmarks.

</details>


### [32] [AI-Generated Image Detectors Overrely on Global Artifacts: Evidence from Inpainting Exchange](https://arxiv.org/abs/2602.00192)
*Elif Nebioglu,Emirhan Bilgiç,Adrian Popescu*

Main category: cs.CV

TL;DR: 论文发现当前图像修复检测器主要依赖全局伪影而非局部合成内容，因为VAE重建会在整个图像（包括未编辑区域）引入频谱偏移。作者提出INP-X操作来分离这种效应，并创建了包含9万张图像的测试集。实验显示现有检测器在INP-X干预下准确率大幅下降，揭示了需要内容感知检测的重要性。


<details>
  <summary>Details</summary>
Motivation: 现代基于深度学习的图像修复技术能够实现逼真的局部图像编辑，这对可靠检测提出了严峻挑战。作者观察到当前检测器主要依赖作为修复副作用的全局伪影，而非局部合成内容，这导致检测存在根本性缺陷。

Method: 提出Inpainting Exchange (INP-X)操作，该操作在保留所有合成内容的同时，恢复编辑区域外的原始像素。创建包含9万张真实、修复和交换图像的测试数据集。通过理论分析将检测器行为与VAE信息瓶颈引起的高频衰减联系起来。

Result: 在INP-X干预下，预训练的最先进检测器（包括商业检测器）准确率大幅下降（如从91%降至55%），经常接近随机猜测水平。使用该数据集训练的检测器比标准修复检测具有更好的泛化能力和定位能力。

Conclusion: 当前检测器过度依赖全局频谱伪影而非局部合成内容，存在根本性缺陷。需要开发内容感知的检测方法，而作者提出的数据集和INP-X操作为此提供了重要基础。

Abstract: Modern deep learning-based inpainting enables realistic local image manipulation, raising critical challenges for reliable detection. However, we observe that current detectors primarily rely on global artifacts that appear as inpainting side effects, rather than on locally synthesized content. We show that this behavior occurs because VAE-based reconstruction induces a subtle but pervasive spectral shift across the entire image, including unedited regions. To isolate this effect, we introduce Inpainting Exchange (INP-X), an operation that restores original pixels outside the edited region while preserving all synthesized content. We create a 90K test dataset including real, inpainted, and exchanged images to evaluate this phenomenon. Under this intervention, pretrained state-of-the-art detectors, including commercial ones, exhibit a dramatic drop in accuracy (e.g., from 91\% to 55\%), frequently approaching chance level. We provide a theoretical analysis linking this behavior to high-frequency attenuation caused by VAE information bottlenecks. Our findings highlight the need for content-aware detection. Indeed, training on our dataset yields better generalization and localization than standard inpainting. Our dataset and code are publicly available at https://github.com/emirhanbilgic/INP-X.

</details>


### [33] [Vision-Language Model Purified Semi-Supervised Semantic Segmentation for Remote Sensing Images](https://arxiv.org/abs/2602.00202)
*Shanwen Wang,Xin Sun,Danfeng Hong,Fei Zhou*

Main category: cs.CV

TL;DR: 提出SemiEarth模型，利用视觉语言模型（VLM）净化半监督语义分割中的伪标签，特别针对遥感图像的多类别边界区域，显著提升分割性能。


<details>
  <summary>Details</summary>
Motivation: 传统半监督语义分割（S4）架构面临伪标签质量低的问题，特别是在教师-学生框架中。遥感图像的多类别边界区域伪标签质量尤其需要改进。

Method: 提出SemiEarth模型，引入视觉语言模型（VLM）伪标签净化（VLM-PP）结构，利用VLM的开放世界能力净化教师网络生成的伪标签，特别是在边界区域纠正错误类别预测。

Result: 在多个遥感数据集上的实验表明，SemiEarth达到SOTA性能，不仅性能优异，还具有良好的可解释性。

Conclusion: 通过引入VLM-PP模块，SemiEarth有效解决了半监督语义分割中伪标签质量低的问题，特别适用于遥感图像的多类别边界区域，为S4任务提供了新的解决方案。

Abstract: The semi-supervised semantic segmentation (S4) can learn rich visual knowledge from low-cost unlabeled images. However, traditional S4 architectures all face the challenge of low-quality pseudo-labels, especially for the teacher-student framework.We propose a novel SemiEarth model that introduces vision-language models (VLMs) to address the S4 issues for the remote sensing (RS) domain. Specifically, we invent a VLM pseudo-label purifying (VLM-PP) structure to purify the teacher network's pseudo-labels, achieving substantial improvements. Especially in multi-class boundary regions of RS images, the VLM-PP module can significantly improve the quality of pseudo-labels generated by the teacher, thereby correctly guiding the student model's learning. Moreover, since VLM-PP equips VLMs with open-world capabilities and is independent of the S4 architecture, it can correct mispredicted categories in low-confidence pseudo-labels whenever a discrepancy arises between its prediction and the pseudo-label. We conducted extensive experiments on multiple RS datasets, which demonstrate that our SemiEarth achieves SOTA performance. More importantly, unlike previous SOTA RS S4 methods, our model not only achieves excellent performance but also offers good interpretability. The code is released at https://github.com/wangshanwen001/SemiEarth.

</details>


### [34] [Interpretable Unsupervised Deformable Image Registration via Confidence-bound Multi-Hop Visual Reasoning](https://arxiv.org/abs/2602.00211)
*Zafar Iqbal,Anwar Ul Haq,Srimannarayana Grandhi*

Main category: cs.CV

TL;DR: 提出VCoR框架，将无监督医学图像配准重构为渐进推理过程，通过多跳视觉推理链实现大变形配准，提供可解释的中间预测和不确定性估计。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在无监督医学图像配准中缺乏透明度和可解释性，导致误差漂移和临床信任度降低。需要一种既能保持高精度又能提供透明推理过程的配准方法。

Method: 提出多跳视觉推理链(VCoR)框架，将配准重构为渐进推理过程。每跳包含局部空间细化(LSR)模块增强特征表示，以及交叉参考注意力(CRA)机制引导迭代细化，保持解剖一致性。多跳策略处理大变形，提供中间预测序列和理论边界。

Result: 在DIR-Lab 4D CT（肺部）和IXI T1加权MRI（脑部）两个挑战性公开数据集上评估，VCoR达到竞争性配准精度，同时提供丰富的中间可视化和置信度测量。

Conclusion: 通过嵌入隐式视觉推理范式，VCoR提供了一种可解释、可靠且临床可行的无监督医学图像配准方法，超越了单纯追求精度的传统方法。

Abstract: Unsupervised deformable image registration requires aligning complex anatomical structures without reference labels, making interpretability and reliability critical. Existing deep learning methods achieve considerable accuracy but often lack transparency, leading to error drift and reduced clinical trust. We propose a novel Multi-Hop Visual Chain of Reasoning (VCoR) framework that reformulates registration as a progressive reasoning process. Inspired by the iterative nature of clinical decision-making, each visual reasoning hop integrates a Localized Spatial Refinement (LSR) module to enrich feature representations and a Cross-Reference Attention (CRA) mechanism that leads the iterative refinement process, preserving anatomical consistency. This multi-hop strategy enables robust handling of large deformations and produces a transparent sequence of intermediate predictions with a theoretical bound. Beyond accuracy, our framework offers built-in interpretability by estimating uncertainty via the stability and convergence of deformation fields across hops. Extensive evaluations on two challenging public datasets, DIR-Lab 4D CT (lung) and IXI T1-weighted MRI (brain), demonstrate that VCoR achieves competitive registration accuracy while offering rich intermediate visualizations and confidence measures. By embedding an implicit visual reasoning paradigm, we present an interpretable, reliable, and clinically viable unsupervised medical image registration.

</details>


### [35] [Deep Learning Based CNN Model for Automated Detection of Pneumonia from Chest XRay Images](https://arxiv.org/abs/2602.00212)
*Sathish Krishna Anumula,Vetrivelan Tamilmani,Aniruddha Arjun Singh,Dinesh Rajendran,Venkata Deepak Namburi*

Main category: cs.CV

TL;DR: 提出一个基于定制CNN的自动化肺炎诊断模型，通过深度可分离卷积和预处理技术，在胸片图像上实现高精度肺炎检测


<details>
  <summary>Details</summary>
Motivation: 肺炎是全球发病率和死亡率的主要原因之一，尤其在资源匮乏地区的儿童和老年人群中患病率较高。传统依赖放射科医生手动解读胸片的方法存在观察者间差异、专家疲劳和合格放射科医生短缺等问题，需要快速准确的自动化诊断方案。

Method: 使用定制卷积神经网络（CNN），采用深度可分离卷积设计，针对灰度医学图像的纹理特征进行优化。使用对比度受限自适应直方图均衡化（CLAHE）和几何增强等预处理技术处理类别不平衡问题，提高泛化能力。

Result: 系统在包含5863张前后位胸片的数据集上进行测试，能够以高精度和最小计算成本识别肺炎。

Conclusion: 提出的统一自动化诊断模型能够有效解决传统肺炎诊断方法的局限性，为临床干预提供快速准确的诊断支持。

Abstract: Pneumonia has been one of the major causes of morbidities and mortality in the world and the prevalence of this disease is disproportionately high among the pediatric and elderly populations especially in resources trained areas Fast and precise diagnosis is a prerequisite for successful clinical intervention but due to inter observer variation fatigue among experts and a shortage of qualified radiologists traditional approaches that rely on manual interpretation of chest radiographs are frequently constrained To address these problems this paper introduces a unified automated diagnostic model using a custom Convolutional Neural Network CNN that can recognize pneumonia in chest Xray images with high precision and at minimal computational expense In contrast like other generic transfer learning based models which often possess redundant parameters the offered architecture uses a tailor made depth wise separable convolutional design which is optimized towards textural characteristics of grayscale medical images Contrast Limited Adaptive Histogram Equalization CLAHE and geometric augmentation are two significant preprocessing techniques used to ensure that the system does not experience class imbalance and is more likely to generalize The system is tested using a dataset of 5863 anterior posterior chest Xrays.

</details>


### [36] [A Geometric Multimodal Foundation Model Integrating Bp-MRI and Clinical Reports in Prostate Cancer Classification](https://arxiv.org/abs/2602.00214)
*Juan A. Olmos,Antoine Manzanera,Fabio Martínez*

Main category: cs.CV

TL;DR: 提出MFM-Geom几何多模态基础模型，结合双参数MRI和临床报告，使用SPD矩阵和黎曼深度学习提升前列腺癌识别性能


<details>
  <summary>Details</summary>
Motivation: 前列腺癌诊断依赖专家主观解读，现有计算机辅助诊断方法多关注影像而忽略临床背景，且受数据稀缺限制，难以学习鲁棒表示

Method: 提出MFM-Geom几何多模态基础模型，从双参数MRI和临床报告中学习表示，利用对称正定矩阵和黎曼深度学习整合影像-文本表示

Result: 仅用10%训练数据，MFM-Geom在AUC-PR上比基线分类token嵌入方法提升8.3%，达到90.67%；在外部数据集验证中AUC-PR达90.6，证明鲁棒性

Conclusion: MFM-Geom通过整合多模态数据和几何深度学习，显著提升前列腺癌识别性能，验证了微调生物医学基础模型的泛化能力

Abstract: Prostate cancer (PCa) is one of the most common cancers in men worldwide. Bi-parametric MRI (bp-MRI) and clinical variables are crucial for PCa identification and improving treatment decisions. However, this process is subjective to expert interpretations. Furthermore, most existing computer-aided diagnosis methods focus on imaging-based models, overlooking the clinical context and suffering from data scarcity, limiting their ability to learn robust representations. We propose a geometric multimodal Foundation Model (FM), named MFM-Geom, that learns representations from bp-MRI and clinical reports, encoding visual findings and information from the context of clinical variables. In the representations classification head, the approach leverages symmetric positive definite (SPD) matrices and Riemannian deep learning to integrate imaging-text representations from a biomedical multimodal FM. Using 10% of the training data, MFM-Geom outperformed baseline class token embedding-based classification (+8.3%, AUC-PR of 90.67). Generalization on external dataset confirmed the robustness of fine-tuning biomedical FM, achieving an AUC-PR of 90.6.

</details>


### [37] [Development of a Cacao Disease Identification and Management App Using Deep Learning](https://arxiv.org/abs/2602.00216)
*Zaldy Pagaduan,Jason Occidental,Nathaniel Duro,Dexielito Badilles,Eleonor Palconit*

Main category: cs.CV

TL;DR: 开发离线移动应用，利用深度学习识别可可病害，帮助菲律宾小农改善种植管理


<details>
  <summary>Details</summary>
Motivation: 菲律宾可可小农面临技术落后、病虫害严重、信息获取困难等问题，缺乏大型种植园的资源和专业知识，需要适合偏远地区的技术解决方案

Method: 开发离线移动应用程序，集成深度学习模型进行可可病害识别，包括病害类型识别和黑腐病感染程度检测两个模型

Result: 病害识别模型验证准确率达96.93%，黑腐病感染程度检测模型准确率79.49%，现场测试与专家评估一致性达84.2%

Conclusion: 离线移动应用为小农提供可访问的技术工具，能有效改善可可作物健康和生产效率，具有实际应用价值

Abstract: Smallholder cacao producers often rely on outdated farming techniques and face significant challenges from pests and diseases, unlike larger plantations with more resources and expertise. In the Philippines, cacao farmers have limited access to data, information, and good agricultural practices. This study addresses these issues by developing a mobile application for cacao disease identification and management that functions offline, enabling use in remote areas where farms are mostly located. The core of the system is a deep learning model trained to identify cacao diseases accurately. The trained model is integrated into the mobile app to support farmers in field diagnosis. The disease identification model achieved a validation accuracy of 96.93% while the model for detecting cacao black pod infection levels achieved 79.49% validation accuracy. Field testing of the application showed an agreement rate of 84.2% compared with expert cacao technician assessments. This approach empowers smallholder farmers by providing accessible, technology-enabled tools to improve cacao crop health and productivity.

</details>


### [38] [CAPA: Contribution-Aware Pruning and FFN Approximation for Efficient Large Vision-Language Models](https://arxiv.org/abs/2602.00247)
*Samyak Jha,Junho Kim*

Main category: cs.CV

TL;DR: CAPA框架通过注意力贡献度筛选视觉token并线性近似FFN计算，在保持性能的同时显著提升大视觉语言模型的推理效率


<details>
  <summary>Details</summary>
Motivation: 大视觉语言模型处理数千个视觉token成本高昂，但现有方法（如注意力分数）无法准确识别哪些token和计算可以安全移除，需要更精确的token重要性评估标准

Method: 提出注意力贡献度（权重注意力概率与值向量大小），识别可修剪的概率垃圾和必需的结构锚点；引入CAPA框架，在关键功能转换处基于贡献度修剪视觉token，并通过线性近似减少FFN计算

Result: 在多个基准测试中，CAPA实现了效率与性能的良好权衡，并展现出改进的鲁棒性

Conclusion: 注意力贡献度是比传统注意力分数更准确的视觉token选择标准，视觉注意力汇具有功能异质性，CAPA框架通过双策略方法有效提升大视觉语言模型的推理效率

Abstract: Efficient inference in Large Vision-Language Models is constrained by the high cost of processing thousands of visual tokens, yet it remains unclear which tokens and computations can be safely removed. While attention scores are commonly used to estimate visual token importance, they are an imperfect proxy for actual contribution. We show that Attention Contribution, which weights attention probabilities by value vector magnitude, provides a more accurate criterion for visual token selection. Our empirical analysis reveals that visual attention sinks are functionally heterogeneous, comprising Probability Dumps with low contribution that can be safely pruned, and Structural Anchors with high contribution essential for maintaining model performance. Further, we identify substantial redundancy in Feed-Forward Networks (FFNs) associated with visual tokens, particularly in intermediate layers where image tokens exhibit linear behavior. Based on our findings, we introduce CAPA (Contribution-Aware Pruning and FFN Approximation), a dual-strategy framework that prunes visual tokens using attention contribution at critical functional transitions and reduces FFN computation through efficient linear approximations. Experiments on various benchmarks across baselines show that CAPA achieves competent efficiency--performance trade-offs with improved robustness.

</details>


### [39] [SANEval: Open-Vocabulary Compositional Benchmarks with Failure-mode Diagnosis](https://arxiv.org/abs/2602.00249)
*Rishav Pramanik,Ian E. Nielsen,Jeff Smith,Saurav Pandit,Ravi P. Ramachandran,Zhaozheng Yin*

Main category: cs.CV

TL;DR: SANEval是一个新的文本到图像模型评估基准，专注于空间关系、属性和数量推理的开放词汇组合评估，使用LLM进行深度提示理解和开放词汇目标检测来评估组合忠实度。


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像模型在渲染涉及多个对象、属性和空间关系的复杂提示时存在瓶颈，但缺乏足够的评估方法。现有基准通常受限于封闭词汇表，缺乏细粒度诊断能力，无法提供可解释的反馈来诊断和修复特定的组合失败。

Method: 提出SANEval基准，建立了一个可扩展的开放词汇组合评估流程。结合大型语言模型进行深度提示理解，以及LLM增强的开放词汇目标检测器来稳健评估组合忠实度，不受固定词汇表限制。

Result: 在六个最先进的T2I模型上进行广泛实验，证明SANEval的自动评估能更忠实地替代人工评估；该指标在属性绑定、空间关系和数量推理任务上，与现有基准相比具有统计上不同的斯皮尔曼等级相关性结果。

Conclusion: SANEval解决了当前T2I组合评估的局限性，提供了更全面、可解释的评估方法。将发布SANEval数据集和开源评估流程，以促进未来组合T2I生成和评估的研究。

Abstract: The rapid progress of text-to-image (T2I) models has unlocked unprecedented creative potential, yet their ability to faithfully render complex prompts involving multiple objects, attributes, and spatial relationships remains a significant bottleneck. Progress is hampered by a lack of adequate evaluation methods; current benchmarks are often restricted to closed-set vocabularies, lack fine-grained diagnostic capabilities, and fail to provide the interpretable feedback necessary to diagnose and remedy specific compositional failures. We solve these challenges by introducing SANEval (Spatial, Attribute, and Numeracy Evaluation), a comprehensive benchmark that establishes a scalable new pipeline for open-vocabulary compositional evaluation. SANEval combines a large language model (LLM) for deep prompt understanding with an LLM-enhanced, open-vocabulary object detector to robustly evaluate compositional adherence, unconstrained by a fixed vocabulary. Through extensive experiments on six state-of-the-art T2I models, we demonstrate that SANEval's automated evaluations provide a more faithful proxy for human assessment; our metric achieves a Spearman's rank correlation with statistically different results than those of existing benchmarks across tasks of attribute binding, spatial relations, and numeracy. To facilitate future research in compositional T2I generation and evaluation, we will release the SANEval dataset and our open-source evaluation pipeline.

</details>


### [40] [Subspace Clustering on Incomplete Data with Self-Supervised Contrastive Learning](https://arxiv.org/abs/2602.00262)
*Huanran Li,Daniel Pimentel-Alarcón*

Main category: cs.CV

TL;DR: 提出对比自监督框架CSC，用于处理不完整数据的子空间聚类，通过掩码视图和对比学习学习不变嵌入，再结合稀疏子空间聚类


<details>
  <summary>Details</summary>
Motivation: 现有子空间聚类方法大多假设数据完全观测，但在实际应用中数据常有缺失，限制了这些方法在真实场景中的有效性

Method: 提出对比自监督框架CSC：1) 对部分观测输入生成掩码视图；2) 使用SimCLR风格对比损失训练深度神经网络学习不变嵌入；3) 结合稀疏子空间聚类进行聚类

Result: 在六个基准数据集上的实验表明，CSC始终优于传统和深度学习基线方法，对缺失数据表现出强鲁棒性，并能扩展到大型数据集

Conclusion: CSC框架有效解决了不完整数据的子空间聚类问题，通过对比自监督学习不变嵌入，在实际应用中具有重要价值

Abstract: Subspace clustering aims to group data points that lie in a union of low-dimensional subspaces and finds wide application in computer vision, hyperspectral imaging, and recommendation systems. However, most existing methods assume fully observed data, limiting their effectiveness in real-world scenarios with missing entries. In this paper, we propose a contrastive self-supervised framework, Contrastive Subspace Clustering (CSC), designed for clustering incomplete data. CSC generates masked views of partially observed inputs and trains a deep neural network using a SimCLR-style contrastive loss to learn invariant embeddings. These embeddings are then clustered using sparse subspace clustering. Experiments on six benchmark datasets show that CSC consistently outperforms both classical and deep learning baselines, demonstrating strong robustness to missing data and scalability to large datasets.

</details>


### [41] [World-Shaper: A Unified Framework for 360° Panoramic Editing](https://arxiv.org/abs/2602.00265)
*Dong Liang,Yuhao Liu,Jinyuan Jia,Youjun Zhao,Rynson W. H. Lau*

Main category: cs.CV

TL;DR: World-Shaper：一个直接在等距柱状投影域中操作的几何感知全景图像编辑框架，通过生成-编辑范式解决数据稀缺问题，实现几何一致的高质量360°图像编辑


<details>
  <summary>Details</summary>
Motivation: 现有基于透视的图像编辑方法无法建模全景图像的空间结构，传统的立方体贴图分解方法由于与球面几何不匹配而破坏全局一致性，需要直接在等距柱状投影域中进行全景编辑

Method: 采用生成-编辑范式：先通过可控全景生成合成多样化的配对数据，然后进行监督编辑学习；引入几何感知学习策略，包括显式的位置感知形状监督和通过渐进训练隐式内化全景先验

Result: 在PEBench新基准上的实验表明，该方法在几何一致性、编辑保真度和文本可控性方面优于现有SOTA方法，能够实现连贯灵活的360°视觉世界创建

Conclusion: World-Shaper成功解决了全景编辑中的几何失真问题，通过统一的几何感知框架实现了高质量的全景图像编辑，为创建一致的360°视觉体验提供了有效解决方案

Abstract: Being able to edit panoramic images is crucial for creating realistic 360° visual experiences. However, existing perspective-based image editing methods fail to model the spatial structure of panoramas. Conventional cube-map decompositions attempt to overcome this problem but inevitably break global consistency due to their mismatch with spherical geometry. Motivated by this insight, we reformulate panoramic editing directly in the equirectangular projection (ERP) domain and present World-Shaper, a unified geometry-aware framework that bridges panoramic generation and editing within a single editing-centric design. To overcome the scarcity of paired data, we adopt a generate-then-edit paradigm, where controllable panoramic generation serves as an auxiliary stage to synthesize diverse paired examples for supervised editing learning. To address geometric distortion, we introduce a geometry-aware learning strategy that explicitly enforces position-aware shape supervision and implicitly internalizes panoramic priors through progressive training. Extensive experiments on our new benchmark, PEBench, demonstrate that our method achieves superior geometric consistency, editing fidelity, and text controllability compared to SOTA methods, enabling coherent and flexible 360° visual world creation with unified editing control. Code, model, and data will be released at our project page: https://world-shaper-project.github.io/

</details>


### [42] [PLACID: Identity-Preserving Multi-Object Compositing via Video Diffusion with Synthetic Trajectories](https://arxiv.org/abs/2602.00267)
*Gemma Canet Tarrés,Manel Baradad,Francesc Moreno-Noguer,Yumeng Li*

Main category: cs.CV

TL;DR: PLACID是一个基于视频扩散模型的多物体合成框架，通过利用时间先验保持物体一致性，并使用合成数据训练，能生成高质量的多物体组合图像。


<details>
  <summary>Details</summary>
Motivation: 当前生成式AI在照片级图像合成方面取得进展，但在工作室级别的多物体合成任务中仍存在不足：无法完美保持物体身份、精确的背景和颜色保真度、布局控制以及完整展示所有物体。现有模型常改变物体细节、遗漏或重复物体，并产生尺寸比例错误或不一致的呈现。

Method: PLACID采用两个主要创新：1) 利用预训练的文本控制图像到视频(I2V)扩散模型，通过视频的时间先验保持物体一致性和背景细节；2) 提出新颖的数据策展策略，生成合成序列，其中随机放置的物体平滑移动到目标位置，这些数据在训练时与视频模型的时间先验对齐。推理时，随机初始化的物体在文本引导下一致收敛为连贯布局，最终帧作为合成图像。

Result: 广泛的定量评估和用户研究表明，PLACID在多物体合成方面超越了现有最先进方法，在身份、背景和颜色保持方面表现更优，遗漏物体更少，视觉效果更吸引人。

Conclusion: PLACID通过利用视频扩散模型的时间先验和创新的合成数据策略，成功解决了多物体合成中的关键挑战，实现了高质量、一致性的多物体组合图像生成。

Abstract: Recent advances in generative AI have dramatically improved photorealistic image synthesis, yet they fall short for studio-level multi-object compositing. This task demands simultaneous (i) near-perfect preservation of each item's identity, (ii) precise background and color fidelity, (iii) layout and design elements control, and (iv) complete, appealing displays showcasing all objects. However, current state-of-the-art models often alter object details, omit or duplicate objects, and produce layouts with incorrect relative sizing or inconsistent item presentations. To bridge this gap, we introduce PLACID, a framework that transforms a collection of object images into an appealing multi-object composite. Our approach makes two main contributions. First, we leverage a pretrained image-to-video (I2V) diffusion model with text control to preserve objects consistency, identities, and background details by exploiting temporal priors from videos. Second, we propose a novel data curation strategy that generates synthetic sequences where randomly placed objects smoothly move to their target positions. This synthetic data aligns with the video model's temporal priors during training. At inference, objects initialized at random positions consistently converge into coherent layouts guided by text, with the final frame serving as the composite image. Extensive quantitative evaluations and user studies demonstrate that PLACID surpasses state-of-the-art methods in multi-object compositing, achieving superior identity, background, and color preservation, with less omitted objects and visually appealing results.

</details>


### [43] [TokenTrim: Inference-Time Token Pruning for Autoregressive Long Video Generation](https://arxiv.org/abs/2602.00268)
*Ariel Shaulov,Eitan Shaar,Amit Edenzon,Lior Wolf*

Main category: cs.CV

TL;DR: 提出一种推理时方法，通过识别并移除不稳定的潜在token来缓解自回归视频生成中的时间漂移问题，无需修改模型架构或训练过程。


<details>
  <summary>Details</summary>
Motivation: 自回归视频生成在生成长视频时存在严重的时间漂移问题，错误会随着时间累积和放大。作者认为这主要不是模型容量不足导致的，而是推理时的错误传播问题，特别是由于在自回归推理中重复使用了已损坏的潜在条件token。

Method: 提出简单的推理时方法：在潜在token被重复用于条件化之前，识别并移除不稳定的潜在token。将不稳定的token定义为那些表示与先前生成批次显著偏离的潜在token，表明可能存在损坏或语义漂移。通过从自回归上下文中显式移除损坏的潜在token，而不是修改整个空间区域或模型参数，防止不可靠的潜在信息影响未来的生成步骤。

Result: 该方法显著改善了长时域的时间一致性，同时无需修改模型架构、训练过程或离开潜在空间。

Conclusion: 通过推理时识别和移除不稳定的潜在token，可以有效缓解自回归视频生成中的时间漂移问题，提高长视频生成的时间一致性，且方法简单易用，不改变原有模型结构。

Abstract: Auto-regressive video generation enables long video synthesis by iteratively conditioning each new batch of frames on previously generated content. However, recent work has shown that such pipelines suffer from severe temporal drift, where errors accumulate and amplify over long horizons. We hypothesize that this drift does not primarily stem from insufficient model capacity, but rather from inference-time error propagation. Specifically, we contend that drift arises from the uncontrolled reuse of corrupted latent conditioning tokens during auto-regressive inference. To correct this accumulation of errors, we propose a simple, inference-time method that mitigates temporal drift by identifying and removing unstable latent tokens before they are reused for conditioning. For this purpose, we define unstable tokens as latent tokens whose representations deviate significantly from those of the previously generated batch, indicating potential corruption or semantic drift. By explicitly removing corrupted latent tokens from the auto-regressive context, rather than modifying entire spatial regions or model parameters, our method prevents unreliable latent information from influencing future generation steps. As a result, it significantly improves long-horizon temporal consistency without modifying the model architecture, training procedure, or leaving latent space.

</details>


### [44] [TimeBlind: A Spatio-Temporal Compositionality Benchmark for Video LLMs](https://arxiv.org/abs/2602.00288)
*Baiqi Li,Kangyi Zhao,Ce Zhang,Chancharik Mitra,Jean de Dieu Nyandwi,Gedas Bertasius*

Main category: cs.CV

TL;DR: TimeBlind是一个诊断性基准测试，用于评估多模态大语言模型在细粒度时空理解上的能力，通过最小对比对范式揭示模型依赖静态视觉线索而非真正的时间逻辑。


<details>
  <summary>Details</summary>
Motivation: 虽然多模态大语言模型在静态语义理解上表现出色，但对时间动态的理解仍然脆弱。视频推理和具身AI需要细粒度的时空理解能力，而现有基准测试往往将识别与时间推理混淆。

Method: 采用认知科学启发的三层分类：识别原子事件、描述事件属性、推理事件间依赖关系。使用最小对比对范式：视频对共享相同的静态视觉内容，仅时间结构不同，配合互补问题来消除语言先验。

Result: 评估了20多个最先进的MLLM（包括GPT-5、Gemini 3 Pro）在600个精选实例（2400个视频-问题对）上的表现。最佳模型的实例准确率仅为48.2%，远低于人类表现（98.2%）。

Conclusion: 前沿模型严重依赖静态视觉捷径而非真正的时间逻辑推理。TimeBlind成为下一代视频理解的重要诊断工具，揭示了当前MLLM在时间理解上的根本性缺陷。

Abstract: Fine-grained spatio-temporal understanding is essential for video reasoning and embodied AI. Yet, while Multimodal Large Language Models (MLLMs) master static semantics, their grasp of temporal dynamics remains brittle. We present TimeBlind, a diagnostic benchmark for compositional spatio-temporal understanding. Inspired by cognitive science, TimeBlind categorizes fine-grained temporal understanding into three levels: recognizing atomic events, characterizing event properties, and reasoning about event interdependencies. Unlike benchmarks that conflate recognition with temporal reasoning, TimeBlind leverages a minimal-pairs paradigm: video pairs share identical static visual content but differ solely in temporal structure, utilizing complementary questions to neutralize language priors. Evaluating over 20 state-of-the-art MLLMs (e.g., GPT-5, Gemini 3 Pro) on 600 curated instances (2400 video-question pairs), reveals that the Instance Accuracy (correctly distinguishing both videos in a pair) of the best performing MLLM is only 48.2%, far below the human performance (98.2%). These results demonstrate that even frontier models rely heavily on static visual shortcuts rather than genuine temporal logic, positioning TimeBlind as a vital diagnostic tool for next-generation video understanding. Dataset and code are available at https://baiqi-li.github.io/timeblind_project/ .

</details>


### [45] [Computer Vision and Its Relationship to Cognitive Science: A perspective from Bayes Decision Theory](https://arxiv.org/abs/2602.00289)
*Alan Yuille,Daniel Kersten*

Main category: cs.CV

TL;DR: 本文从贝叶斯决策理论视角介绍计算机视觉及其与认知科学的关系，分析贝叶斯方法和深度神经网络两种途径的优缺点，并探讨如何将它们结合到更丰富的框架中。


<details>
  <summary>Details</summary>
Motivation: 计算机视觉领域庞大复杂，需要理论框架来捕捉关键概念。贝叶斯决策理论提供了一个统一视角，既能涵盖与认知科学共鸣的贝叶斯方法，又能解释在现实世界中取得巨大成功的深度神经网络方法。

Method: 采用贝叶斯决策理论作为理论框架，分析计算机视觉中的两种主要方法：贝叶斯方法和深度神经网络方法。通过讨论BDT的局限性，指出如何将这两种方法结合到更丰富的框架中。

Result: 贝叶斯决策理论能够统一分析计算机视觉的两种主要方法：贝叶斯方法提供与认知科学共鸣的概念框架，深度神经网络方法则在实践中取得巨大商业成功。BDT框架揭示了这两种方法的优缺点。

Conclusion: 贝叶斯决策理论为理解计算机视觉提供了有价值的理论视角，通过分析其局限性，可以指导将贝叶斯方法和深度神经网络方法结合到更丰富的框架中，推动计算机视觉的进一步发展。

Abstract: This document presents an introduction to computer vision, and its relationship to Cognitive Science, from the perspective of Bayes Decision Theory (Berger 1985). Computer vision is a vast and complex field, so this overview has a narrow scope and provides a theoretical lens which captures many key concepts. BDT is rich enough to include two different approaches: (i) the Bayesian viewpoint, which gives a conceptually attractive framework for vision with concepts that resonate with Cognitive Science (Griffiths et al., 2024), and (ii) the Deep Neural Network approach whose successes in the real world have made Computer Vision into a trillion-dollar industry and which is motivated by the hierarchical structure of the visual ventral stream. The BDT framework relates and captures the strengths and weakness of these two approaches and, by discussing the limitations of BDT, points the way to how they can be combined in a richer framework.

</details>


### [46] [LogicGaze: Benchmarking Causal Consistency in Visual Narratives via Counterfactual Verification](https://arxiv.org/abs/2602.00292)
*Rory Driscoll,Alexandros Christoforos,Chadbourne Davis*

Main category: cs.CV

TL;DR: LogicGaze是一个评估视觉语言模型在序列推理中视觉基础能力的基准框架，通过因果验证、叙事合成和扰动拒绝三个测试，发现现有模型存在显著漏洞。


<details>
  <summary>Details</summary>
Motivation: 尽管序列推理增强了视觉语言模型处理复杂多模态任务的能力，但它们在将推理链基于实际视觉证据方面的可靠性尚未得到充分探索。当前模型存在幻觉问题，需要评估其验证因果链与视觉输入一致性的能力。

Method: 创建LogicGaze基准框架，从ShareGPT4Video的40,000个视频片段和Flickr30k图像子集中收集数据，整合因果序列与视觉矛盾但语言合理的扰动，迫使模型验证每个推理步骤的真实性。采用三部分评估协议：因果验证、基础叙事合成和扰动拒绝。

Result: 评估揭示了最先进的视觉语言模型（如Qwen2.5-VL-72B）存在显著漏洞，表明当前模型在将序列推理链基于视觉证据方面存在可靠性问题。

Conclusion: LogicGaze基准框架为评估多模态推理的鲁棒性和可信度提供了重要工具，所有资源已在匿名存储库中公开，以促进更可靠、可信的多模态推理研究。

Abstract: While sequential reasoning enhances the capability of Vision-Language Models (VLMs) to execute complex multimodal tasks, their reliability in grounding these reasoning chains within actual visual evidence remains insufficiently explored. We introduce LogicGaze, a novel benchmark framework designed to rigorously interrogate whether VLMs can validate sequential causal chains against visual inputs, specifically targeting the pervasive issue of hallucination. Curated from 40,000 video segments from ShareGPT4Video and a subset of Flickr30k imagery, LogicGaze integrates causal sequences with visually contradictory yet linguistically plausible perturbations, compelling models to verify the authenticity of each reasoning step. Our tripartite evaluation protocol - Causal Validation, Grounded Narrative Synthesis, and Perturbation Rejection - exposes significant vulnerabilities in state-of-the-art VLMs such as Qwen2.5-VL-72B. LogicGaze advocates for robust, trustworthy multimodal reasoning, with all resources publicly available in an anonymized repository.

</details>


### [47] [Opportunistic Promptable Segmentation: Leveraging Routine Radiological Annotations to Guide 3D CT Lesion Segmentation](https://arxiv.org/abs/2602.00309)
*Samuel Church,Joshua D. Warner,Danyal Maqbool,Xin Tie,Junjie Hu,Meghan G. Lubner,Tyler J. Bradshaw*

Main category: cs.CV

TL;DR: SAM2CT：首个可提示分割模型，利用放射科医生在PACS系统中的稀疏标注（箭头和线测量）生成3D CT分割，实现大规模历史标注数据挖掘


<details>
  <summary>Details</summary>
Motivation: CT影像的机器学习模型开发需要大量高质量标注数据，但3D分割标注成本高昂。放射科医生在日常工作中会产生大量稀疏标注（如箭头和线测量），这些数据存储在PACS系统中但未被充分利用。如何将这些稀疏标注转化为3D分割是一个重要挑战。

Method: 提出SAM2CT模型，基于SAM2架构扩展提示编码器以支持箭头和线输入，并引入Memory-Conditioned Memories（MCM）内存编码策略专门针对3D医学影像。该模型可将放射科医生的稀疏标注转换为3D分割。

Result: 在公共病灶分割基准测试中，SAM2CT优于现有可提示分割模型：箭头提示Dice系数0.649，线提示0.757。在临床PACS的60个GSPS标注上，87%的分割结果被放射科医生评为临床可接受或仅需微小调整。在急诊科发现上表现出强零样本性能。

Conclusion: SAM2CT证明了利用历史GSPS标注进行大规模3D CT分割数据集生成的可行性和可扩展性，为医学影像分析提供了新的数据获取途径。

Abstract: The development of machine learning models for CT imaging depends on the availability of large, high-quality, and diverse annotated datasets. Although large volumes of CT images and reports are readily available in clinical picture archiving and communication systems (PACS), 3D segmentations of critical findings are costly to obtain, typically requiring extensive manual annotation by radiologists. On the other hand, it is common for radiologists to provide limited annotations of findings during routine reads, such as line measurements and arrows, that are often stored in PACS as GSPS objects. We posit that these sparse annotations can be extracted along with CT volumes and converted into 3D segmentations using promptable segmentation models, a paradigm we term Opportunistic Promptable Segmentation. To enable this paradigm, we propose SAM2CT, the first promptable segmentation model designed to convert radiologist annotations into 3D segmentations in CT volumes. SAM2CT builds upon SAM2 by extending the prompt encoder to support arrow and line inputs and by introducing Memory-Conditioned Memories (MCM), a memory encoding strategy tailored to 3D medical volumes. On public lesion segmentation benchmarks, SAM2CT outperforms existing promptable segmentation models and similarly trained baselines, achieving Dice similarity coefficients of 0.649 for arrow prompts and 0.757 for line prompts. Applying the model to pre-existing GSPS annotations from a clinical PACS (N = 60), SAM2CT generates 3D segmentations that are clinically acceptable or require only minor adjustments in 87% of cases, as scored by radiologists. Additionally, SAM2CT demonstrates strong zero-shot performance on select Emergency Department findings. These results suggest that large-scale mining of historical GSPS annotations represents a promising and scalable approach for generating 3D CT segmentation datasets.

</details>


### [48] [On the Assessment of Sensitivity of Autonomous Vehicle Perception](https://arxiv.org/abs/2602.00314)
*Apostol Vassilev,Munawar Hasan,Edward Griffor,Honglan Jin,Pavel Piliptchak,Mahima Arora,Thoshitha Gamage*

Main category: cs.CV

TL;DR: 该研究通过集成多种计算机视觉模型，评估自动驾驶感知系统在恶劣驾驶场景下的鲁棒性，发现光照不足、天气条件和距离增加会显著降低感知性能。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶的可行性严重依赖感知系统的实时准确性和可靠性，但自然和对抗性驾驶因素会导致感知错误和检测延迟，因此需要评估感知系统的鲁棒性并探索提高可靠性的策略。

Method: 使用基于模型集成的预测敏感性量化方法，在模拟和真实环境中评估感知性能；提出基于停车距离的感知评估标准；使用YOLO(v8-v9)、DETR50、DETR101、RT-DETR等五种先进计算机视觉模型进行实验。

Result: 光照不足（雾、低太阳高度）对感知模型性能影响最大；对抗性道路条件（物体遮挡）增加感知敏感性；恶劣天气与对抗性条件组合时模型性能下降；距离道路物体越远，感知鲁棒性越差。

Conclusion: 自动驾驶感知系统在恶劣条件下存在显著脆弱性，需要开发更鲁棒的感知策略，特别是在光照不足、复杂天气和远距离检测场景下。

Abstract: The viability of automated driving is heavily dependent on the performance of perception systems to provide real-time accurate and reliable information for robust decision-making and maneuvers. These systems must perform reliably not only under ideal conditions, but also when challenged by natural and adversarial driving factors. Both of these types of interference can lead to perception errors and delays in detection and classification. Hence, it is essential to assess the robustness of the perception systems of automated vehicles (AVs) and explore strategies for making perception more reliable. We approach this problem by evaluating perception performance using predictive sensitivity quantification based on an ensemble of models, capturing model disagreement and inference variability across multiple models, under adverse driving scenarios in both simulated environments and real-world conditions. A notional architecture for assessing perception performance is proposed. A perception assessment criterion is developed based on an AV's stopping distance at a stop sign on varying road surfaces, such as dry and wet asphalt, and vehicle speed. Five state-of-the-art computer vision models are used, including YOLO (v8-v9), DEtection TRansformer (DETR50, DETR101), Real-Time DEtection TRansformer (RT-DETR)in our experiments. Diminished lighting conditions, e.g., resulting from the presence of fog and low sun altitude, have the greatest impact on the performance of the perception models. Additionally, adversarial road conditions such as occlusions of roadway objects increase perception sensitivity and model performance drops when faced with a combination of adversarial road conditions and inclement weather conditions. Also, it is demonstrated that the greater the distance to a roadway object, the greater the impact on perception performance, hence diminished perception robustness.

</details>


### [49] [Bridging the Semantic Chasm: Synergistic Conceptual Anchoring for Generalized Few-Shot and Zero-Shot OOD Perception](https://arxiv.org/abs/2602.00340)
*Alexandros Christoforos,Sarah Jenkins,Michael Brown,Tuan Pham,David Chen*

Main category: cs.CV

TL;DR: SynerNet框架通过多智能体协同解决VLMs在OOD概念上的跨模态对齐退化问题，在VISTA-Beyond基准上取得了1.2%-5.4%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决视觉语言模型在遇到分布外概念时出现的跨模态对齐退化问题，提升模型对未见概念的泛化能力。

Method: 提出Synergistic Neural Agents Network框架，包含四个专门的计算单元（视觉感知、语言上下文、名义嵌入、全局协调），通过结构化消息传播协议协同工作，包括多智能体潜在空间命名获取框架、语义上下文交换算法和自适应动态平衡机制。

Result: 在VISTA-Beyond基准测试中，SynerNet在少样本和零样本场景下均取得显著性能提升，精度改进范围在1.2%到5.4%之间。

Conclusion: SynerNet框架有效缓解了VLMs在OOD概念上的跨模态对齐退化问题，为视觉语言模型的泛化能力提供了新的解决方案。

Abstract: This manuscript presents a pioneering Synergistic Neural Agents Network (SynerNet) framework designed to mitigate the phenomenon of cross-modal alignment degeneration in Vision-Language Models (VLMs) when encountering Out-of-Distribution (OOD) concepts. Specifically, four specialized computational units - visual perception, linguistic context, nominal embedding, and global coordination - collaboratively rectify modality disparities via a structured message-propagation protocol. The principal contributions encompass a multi-agent latent space nomenclature acquisition framework, a semantic context-interchange algorithm for enhanced few-shot adaptation, and an adaptive dynamic equilibrium mechanism. Empirical evaluations conducted on the VISTA-Beyond benchmark demonstrate that SynerNet yields substantial performance augmentations in both few-shot and zero-shot scenarios, exhibiting precision improvements ranging from 1.2% to 5.4% across a diverse array of domains.

</details>


### [50] [When RAG Hurts: Diagnosing and Mitigating Attention Distraction in Retrieval-Augmented LVLMs](https://arxiv.org/abs/2602.00344)
*Beidi Zhao,Wenlong Deng,Xinting Liao,Yushu Li,Nazim Shaikh,Yao Nie,Xiaoxiao Li*

Main category: cs.CV

TL;DR: MAD-RAG：一种训练免费的干预方法，通过双问题表述和解耦视觉定位与上下文集成，解决检索增强生成中的注意力分散问题，显著提升知识型视觉问答任务的性能。


<details>
  <summary>Details</summary>
Motivation: 研究发现检索增强生成（RAG）在知识型视觉问答中存在一个被忽视的失败模式：注意力分散（AD）。当检索到的上下文足够相关时，检索文本会全局抑制视觉注意力，导致图像注意力从问题相关区域转移，使得原本能够正确回答的问题反而失败。

Method: 提出MAD-RAG方法：1）通过双问题表述解耦视觉定位与上下文集成；2）结合注意力混合机制来保留图像条件证据；3）无需额外训练，计算开销极小。

Result: 在OK-VQA、E-VQA和InfoSeek数据集上的实验表明，MAD-RAG在不同模型家族中均优于现有基线，相比原始RAG基线分别获得4.76%、9.20%和6.18%的绝对提升，能够纠正高达74.68%的失败案例。

Conclusion: MAD-RAG有效解决了RAG中的注意力分散问题，通过解耦视觉定位和上下文集成，显著提升了知识型视觉问答任务的性能，且无需训练、计算开销小，具有很好的实用价值。

Abstract: While Retrieval-Augmented Generation (RAG) is one of the dominant paradigms for enhancing Large Vision-Language Models (LVLMs) on knowledge-based VQA tasks, recent work attributes RAG failures to insufficient attention towards the retrieved context, proposing to reduce the attention allocated to image tokens. In this work, we identify a distinct failure mode that previous study overlooked: Attention Distraction (AD). When the retrieved context is sufficient (highly relevant or including the correct answer), the retrieved text suppresses the visual attention globally, and the attention on image tokens shifts away from question-relevant regions. This leads to failures on questions the model could originally answer correctly without the retrieved text. To mitigate this issue, we propose MAD-RAG, a training-free intervention that decouples visual grounding from context integration through a dual-question formulation, combined with attention mixing to preserve image-conditioned evidence. Extensive experiments on OK-VQA, E-VQA, and InfoSeek demonstrate that MAD-RAG consistently outperforms existing baselines across different model families, yielding absolute gains of up to 4.76%, 9.20%, and 6.18% over the vanilla RAG baseline. Notably, MAD-RAG rectifies up to 74.68% of failure cases with negligible computational overhead.

</details>


### [51] [AdaFuse: Adaptive Multimodal Fusion for Lung Cancer Risk Prediction via Reinforcement Learning](https://arxiv.org/abs/2602.00347)
*Chongyu Qu,Zhengyi Lu,Yuxiang Lai,Thomas Z. Li,Junchao Zhu,Junlin Guo,Juming Xiong,Yanfan Zhu,Yuechen Yang,Allen J. Luna,Kim L. Sandler,Bennett A. Landman,Yuankai Huo*

Main category: cs.CV

TL;DR: AdaFuse：基于强化学习的自适应多模态融合框架，用于肺癌风险预测，通过序列决策动态选择患者特定模态，实现个性化诊断


<details>
  <summary>Details</summary>
Motivation: 现有多模态融合方法要么平等处理所有模态，要么学习分配贡献权重，但未解决一个基本问题：对于特定患者，是否应该使用某些模态？需要更智能的个性化融合策略

Method: 将多模态融合建模为序列决策过程，使用强化学习训练策略网络，迭代决定是否纳入额外模态或基于已获取信息进行预测，实现条件选择和早期终止

Result: 在NLST数据集上，AdaFuse达到最高AUC（0.762），优于最佳单模态基线（0.732）、最佳固定融合策略（0.759）和自适应基线DynMM（0.754）、MoE（0.742），且计算量少于所有三模态方法

Conclusion: 强化学习在医学影像个性化多模态融合中具有潜力，代表从统一融合策略向自适应诊断流程的转变，学习何时咨询额外模态以及何时现有信息足以进行准确预测

Abstract: Multimodal fusion has emerged as a promising paradigm for disease diagnosis and prognosis, integrating complementary information from heterogeneous data sources such as medical images, clinical records, and radiology reports. However, existing fusion methods process all available modalities through the network, either treating them equally or learning to assign different contribution weights, leaving a fundamental question unaddressed: for a given patient, should certain modalities be used at all? We present AdaFuse, an adaptive multimodal fusion framework that leverages reinforcement learning (RL) to learn patient-specific modality selection and fusion strategies for lung cancer risk prediction. AdaFuse formulates multimodal fusion as a sequential decision process, where the policy network iteratively decides whether to incorporate an additional modality or proceed to prediction based on the information already acquired. This sequential formulation enables the model to condition each selection on previously observed modalities and terminate early when sufficient information is available, rather than committing to a fixed subset upfront. We evaluate AdaFuse on the National Lung Screening Trial (NLST) dataset. Experimental results demonstrate that AdaFuse achieves the highest AUC (0.762) compared to the best single-modality baseline (0.732), the best fixed fusion strategy (0.759), and adaptive baselines including DynMM (0.754) and MoE (0.742), while using fewer FLOPs than all triple-modality methods. Our work demonstrates the potential of reinforcement learning for personalized multimodal fusion in medical imaging, representing a shift from uniform fusion strategies toward adaptive diagnostic pipelines that learn when to consult additional modalities and when existing information suffices for accurate prediction.

</details>


### [52] [MASC: Metal-Aware Sampling and Correction via Reinforcement Learning for Accelerated MRI](https://arxiv.org/abs/2602.00348)
*Zhengyi Lu,Ming Lu,Chongyu Qu,Junchao Zhu,Junlin Guo,Marilyn Lionts,Yanfan Zhu,Yuechen Yang,Tianyuan Yao,Jayasai Rajagopal,Bennett Allan Landman,Xiao Wang,Xinqiang Yan,Yuankai Huo*

Main category: cs.CV

TL;DR: MASC是一个统一的强化学习框架，联合优化金属感知的k空间采样和伪影校正，用于加速MRI扫描，通过端到端训练同时学习采样策略和伪影去除网络。


<details>
  <summary>Details</summary>
Motivation: 传统方法将金属伪影减少（MAR）和加速MRI采集作为两个独立问题处理，但金属植入物在MRI中会造成严重伪影，影响图像质量和临床诊断。需要一种统一的方法来同时解决这两个问题。

Method: 1. 构建基于物理模拟的配对MRI数据集，包含有/无金属植入物的k空间数据和重建图像；2. 将主动MRI采集建模为序列决策问题，使用基于PPO的伪影感知智能体学习在有限采集预算下选择k空间相位编码线；3. 采用U-Net基础的MAR网络处理欠采样重建；4. 提出端到端训练方案，使采样策略和MAR网络相互适应。

Result: MASC学习的采样策略优于传统采样方法，端到端训练相比使用冻结预训练MAR网络能提升性能，验证了联合优化的优势。在FastMRI数据集上的跨数据集实验进一步证实了该方法在真实临床MRI数据上的泛化能力。

Conclusion: MASC成功实现了金属感知k空间采样和伪影校正的联合优化，为加速MRI扫描中的金属伪影问题提供了有效的统一解决方案，代码和模型已开源。

Abstract: Metal implants in MRI cause severe artifacts that degrade image quality and hinder clinical diagnosis. Traditional approaches address metal artifact reduction (MAR) and accelerated MRI acquisition as separate problems. We propose MASC, a unified reinforcement learning framework that jointly optimizes metal-aware k-space sampling and artifact correction for accelerated MRI. To enable supervised training, we construct a paired MRI dataset using physics-based simulation, generating k-space data and reconstructions for phantoms with and without metal implants. This paired dataset provides simulated 3D MRI scans with and without metal implants, where each metal-corrupted sample has an exactly matched clean reference, enabling direct supervision for both artifact reduction and acquisition policy learning. We formulate active MRI acquisition as a sequential decision-making problem, where an artifact-aware Proximal Policy Optimization (PPO) agent learns to select k-space phase-encoding lines under a limited acquisition budget. The agent operates on undersampled reconstructions processed through a U-Net-based MAR network, learning patterns that maximize reconstruction quality. We further propose an end-to-end training scheme where the acquisition policy learns to select k-space lines that best support artifact removal while the MAR network simultaneously adapts to the resulting undersampling patterns. Experiments demonstrate that MASC's learned policies outperform conventional sampling strategies, and end-to-end training improves performance compared to using a frozen pre-trained MAR network, validating the benefit of joint optimization. Cross-dataset experiments on FastMRI with physics-based artifact simulation further confirm generalization to realistic clinical MRI data. The code and models of MASC have been made publicly available: https://github.com/hrlblab/masc

</details>


### [53] [ReLAPSe: Reinforcement-Learning-trained Adversarial Prompt Search for Erased concepts in unlearned diffusion models](https://arxiv.org/abs/2602.00350)
*Ignacy Kolton,Kacper Marzol,Paweł Batorski,Marcin Mazur,Paul Swoboda,Przemysław Spurek*

Main category: cs.CV

TL;DR: ReLAPSe：基于强化学习的对抗框架，用于恢复文本到图像扩散模型中已遗忘的概念，通过策略学习而非逐实例优化实现高效概念恢复


<details>
  <summary>Details</summary>
Motivation: 现有对抗方法存在局限性：基于优化的方法计算成本高（需要逐实例迭代搜索），而基于推理和启发式的方法缺乏目标模型潜在视觉表示的直接反馈。需要一种更高效、可扩展的方法来严格测试已遗忘扩散模型的安全性

Method: 提出ReLAPSe框架，将概念恢复重新定义为强化学习问题。使用可验证奖励的强化学习（RLVR）训练智能体，利用扩散模型的噪声预测损失作为模型内在且可验证的反馈信号。这种闭环设计直接将文本提示操作与潜在视觉残差对齐，使智能体能够学习可迁移的恢复策略而非优化孤立提示

Result: ReLAPSe实现了高效、接近实时的细粒度身份和风格恢复，适用于多种最先进的遗忘方法。通过从逐实例优化转向全局策略学习，为严格测试已遗忘扩散模型提供了可扩展工具

Conclusion: ReLAPSe通过强化学习框架解决了现有对抗方法的局限性，实现了高效的概念恢复，为机器遗忘系统的安全性评估提供了新的可扩展方法，有助于更严格地测试扩散模型的遗忘效果

Abstract: Machine unlearning is a key defense mechanism for removing unauthorized concepts from text-to-image diffusion models, yet recent evidence shows that latent visual information often persists after unlearning. Existing adversarial approaches for exploiting this leakage are constrained by fundamental limitations: optimization-based methods are computationally expensive due to per-instance iterative search. At the same time, reasoning-based and heuristic techniques lack direct feedback from the target model's latent visual representations. To address these challenges, we introduce ReLAPSe, a policy-based adversarial framework that reformulates concept restoration as a reinforcement learning problem. ReLAPSe trains an agent using Reinforcement Learning with Verifiable Rewards (RLVR), leveraging the diffusion model's noise prediction loss as a model-intrinsic and verifiable feedback signal. This closed-loop design directly aligns textual prompt manipulation with latent visual residuals, enabling the agent to learn transferable restoration strategies rather than optimizing isolated prompts. By pioneering the shift from per-instance optimization to global policy learning, ReLAPSe achieves efficient, near-real-time recovery of fine-grained identities and styles across multiple state-of-the-art unlearning methods, providing a scalable tool for rigorous red-teaming of unlearned diffusion models. Some experimental evaluations involve sensitive visual concepts, such as nudity. Code is available at https://github.com/gmum/ReLaPSe

</details>


### [54] [Modeling Image-Caption Rating from Comparative Judgments](https://arxiv.org/abs/2602.00381)
*Kezia Minni,Qiang Zhang,Monoshiz Mahbub Khan,Zhe Yu*

Main category: cs.CV

TL;DR: 提出基于比较判断而非直接评分的机器学习框架，用于图像描述质量评估，通过比较学习模型减少人工标注成本


<details>
  <summary>Details</summary>
Motivation: 人类对图像描述进行准确评分耗时且主观，而比较两个描述哪个更好匹配图像则更容易。因此需要一种能建模比较判断而非直接评分的机器学习方法。

Method: 使用VICR数据集，提取ResNet-50视觉特征和MiniLM文本特征，训练回归模型和比较学习模型。比较学习模型通过建模成对比较判断来学习偏好。

Result: 回归模型表现更好（Pearson's ρ: 0.7609, Spearman's rs: 0.7089），但比较学习模型随数据增加稳步改进，接近回归基线。人工评估显示比较标注更快且标注者间一致性更高。

Conclusion: 比较学习能有效建模人类偏好，同时显著降低人工标注成本，为图像描述质量评估提供了一种更高效的方法。

Abstract: Rating the accuracy of captions in describing images is time-consuming and subjective for humans. In contrast, it is often easier for people to compare two captions and decide which one better matches a given image. In this work, we propose a machine learning framework that models such comparative judgments instead of direct ratings. The model can then be applied to rank unseen image-caption pairs in the same way as a regression model trained on direct ratings. Using the VICR dataset, we extract visual features with ResNet-50 and text features with MiniLM, then train both a regression model and a comparative learning model. While the regression model achieves better performance (Pearson's $ρ$: 0.7609 and Spearman's $r_s$: 0.7089), the comparative learning model steadily improves with more data and approaches the regression baseline. In addition, a small-scale human evaluation study comparing absolute rating, pairwise comparison, and same-image comparison shows that comparative annotation yields faster results and has greater agreement among human annotators. These results suggest that comparative learning can effectively model human preferences while significantly reducing the cost of human annotations.

</details>


### [55] [Deep Learning-Based Object Detection for Autonomous Vehicles: A Comparative Study of One-Stage and Two-Stage Detectors on Basic Traffic Objects](https://arxiv.org/abs/2602.00385)
*Bsher Karbouj,Adam Michael Altenbuchner,Joerg Krueger*

Main category: cs.CV

TL;DR: 该研究对YOLOv5和Faster R-CNN两种目标检测模型在自动驾驶场景下的性能进行了综合实验分析，发现YOLOv5在mAP、召回率和训练效率方面表现更优，而Faster R-CNN在小目标检测和复杂光照条件下有优势。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统中的目标检测至关重要，但现有深度学习模型（如YOLO、SSD、Faster R-CNN）在具体自动驾驶应用中的适用性指导有限。模型选择直接影响检测精度、处理速度、环境鲁棒性等关键性能指标，因此需要系统性的比较分析。

Method: 采用实验分析方法，在包含真实和合成图像的多样化数据集上，比较YOLOv5（单阶段检测器）和Faster R-CNN（两阶段检测器）的性能。评估指标包括平均精度均值（mAP）、召回率和推理速度，并分析了不同置信度阈值和真实场景下的表现。

Result: YOLOv5在mAP、召回率和训练效率方面表现更优，特别是在数据集规模和图像分辨率增加时优势更明显。Faster R-CNN在检测小且远的物体方面有优势，在挑战性光照条件下表现良好。两种模型在不同置信度阈值和真实场景下表现出不同的行为特性。

Conclusion: 研究为自动驾驶系统选择合适的目标检测模型提供了实用指导：YOLOv5更适合需要高效率和良好整体性能的应用，而Faster R-CNN在特定场景（如小目标检测、复杂光照）中表现更佳。模型选择应根据具体应用需求和场景特点进行权衡。

Abstract: Object detection is a crucial component in autonomous vehicle systems. It enables the vehicle to perceive and understand its environment by identifying and locating various objects around it. By utilizing advanced imaging and deep learning techniques, autonomous vehicle systems can rapidly and accurately identify objects based on their features. Different deep learning methods vary in their ability to accurately detect and classify objects in autonomous vehicle systems. Selecting the appropriate method significantly impacts system performance, robustness, and efficiency in real-world driving scenarios. While several generic deep learning architectures like YOLO, SSD, and Faster R-CNN have been proposed, guidance on their suitability for specific autonomous driving applications is often limited. The choice of method affects detection accuracy, processing speed, environmental robustness, sensor integration, scalability, and edge case handling. This study provides a comprehensive experimental analysis comparing two prominent object detection models: YOLOv5 (a one-stage detector) and Faster R-CNN (a two-stage detector). Their performance is evaluated on a diverse dataset combining real and synthetic images, considering various metrics including mean Average Precision (mAP), recall, and inference speed. The findings reveal that YOLOv5 demonstrates superior performance in terms of mAP, recall, and training efficiency, particularly as dataset size and image resolution increase. However, Faster R-CNN shows advantages in detecting small, distant objects and performs well in challenging lighting conditions. The models' behavior is also analyzed under different confidence thresholds and in various real-world scenarios, providing insights into their applicability for autonomous driving systems.

</details>


### [56] [Robust automatic brain vessel segmentation in 3D CTA scans using dynamic 4D-CTA data](https://arxiv.org/abs/2602.00391)
*Alberto Mario Ceballos-Arroyo,Shrikanth M. Yadav,Chu-Hsuan Lin,Jisoo Kim,Geoffrey S. Young,Huaizu Jiang,Lei Qin*

Main category: cs.CV

TL;DR: 提出一种基于动态4D-CTA扫描的脑血管标注新方法，通过多时相数据增强血管可视化，并利用深度学习模型实现更精确的脑血管分割。


<details>
  <summary>Details</summary>
Motivation: 传统脑血管标注需要大量人工努力，且CTA扫描中骨骼和软组织会干扰血管可视化。动态4D-CTA提供了多时相数据，但如何有效利用这些数据提升血管分割精度是一个挑战。

Method: 使用动态4D-CTA多时相数据，通过减影技术去除骨骼和软组织干扰，增强血管可视化。利用同一分割标注应用于多个时相，将数据集扩大4-5倍，训练nnUNet模型，并引入对造影剂时相的鲁棒性。

Result: 在110张训练图像和165张测试图像上，模型在TopBrain数据集中动脉平均mDC达0.846，静脉达0.957。平均定向Hausdorff距离（动脉0.304mm，静脉0.078mm）和拓扑敏感度（动脉0.877，静脉0.974）均显示优异性能。

Conclusion: 该方法显著提升了脑血管分割的准确性和鲁棒性，为脑血管疾病诊断提供了更可靠的自动化工具。代码和模型权重已开源。

Abstract: In this study, we develop a novel methodology for annotating the brain vasculature using dynamic 4D-CTA head scans. By using multiple time points from dynamic CTA acquisitions, we subtract bone and soft tissue to enhance the visualization of arteries and veins, reducing the effort required to obtain manual annotations of brain vessels. We then train deep learning models on our ground truth annotations by using the same segmentation for multiple phases from the dynamic 4D-CTA collection, effectively enlarging our dataset by 4 to 5 times and inducing robustness to contrast phases. In total, our dataset comprises 110 training images from 25 patients and 165 test images from 14 patients. In comparison with two similarly-sized datasets for CTA-based brain vessel segmentation, a nnUNet model trained on our dataset can achieve significantly better segmentations across all vascular regions, with an average mDC of 0.846 for arteries and 0.957 for veins in the TopBrain dataset. Furthermore, metrics such as average directed Hausdorff distance (adHD) and topology sensitivity (tSens) reflected similar trends: using our dataset resulted in low error margins (aDHD of 0.304 mm for arteries and 0.078 for veins) and high sensitivity (tSens of 0.877 for arteries and 0.974 for veins), indicating excellent accuracy in capturing vessel morphology. Our code and model weights are available online: https://github.com/alceballosa/robust-vessel-segmentation

</details>


### [57] [Brazilian Portuguese Image Captioning with Transformers: A Study on Cross-Native-Translated Dataset](https://arxiv.org/abs/2602.00393)
*Gabriel Bromonschenkel,Alessandro L. Koerich,Thiago M. Paixão,Hilário Tomaz Alves de Oliveira*

Main category: cs.CV

TL;DR: 该研究评估了基于Transformer的视觉语言模型在巴西葡萄牙语图像描述任务中的表现，比较了原生标注与自动翻译数据集，发现Swin-DistilBERTimbau表现最佳，ViTucano在文本指标上优于大型多语言模型，GPT-4在图像-文本对齐方面表现最好。


<details>
  <summary>Details</summary>
Motivation: 虽然图像描述研究主要集中在英语，但巴西葡萄牙语等低资源语言面临数据集和模型缺乏的挑战。现有研究通过自动翻译缓解资源稀缺，但缺乏对原生标注与翻译数据集的系统比较。

Method: 使用包含巴西葡萄牙语原生标注的Flickr30K版本，与自动翻译版本进行比较。采用交叉上下文方法：在一个数据集上训练，在另一个上测试。结合注意力图进行模型解释，使用CLIP-Score评估图像-描述对齐。

Result: Swin-DistilBERTimbau在所有模型中表现最稳定，具有强大的跨数据集泛化能力。巴西葡萄牙语预训练模型ViTucano在传统文本评估指标上优于GPT-4o和LLaMa 3.2 Vision等大型多语言模型。GPT-4模型获得最高的CLIP-Score，表明更好的图像-文本对齐。注意力分析揭示了系统性偏见，包括性别误分类、对象枚举错误和空间不一致性。

Conclusion: 研究表明巴西葡萄牙语预训练模型在文本指标上具有优势，而大型多语言模型在图像-文本对齐方面表现更好。注意力分析揭示了模型偏见问题。研究提供了公开的数据集和模型，支持巴西葡萄牙语图像描述研究的进一步发展。

Abstract: Image captioning (IC) refers to the automatic generation of natural language descriptions for images, with applications ranging from social media content generation to assisting individuals with visual impairments. While most research has been focused on English-based models, low-resource languages such as Brazilian Portuguese face significant challenges due to the lack of specialized datasets and models. Several studies create datasets by automatically translating existing ones to mitigate resource scarcity. This work addresses this gap by proposing a cross-native-translated evaluation of Transformer-based vision and language models for Brazilian Portuguese IC. We use a version of Flickr30K comprised of captions manually created by native Brazilian Portuguese speakers and compare it to a version with captions automatically translated from English to Portuguese. The experiments include a cross-context approach, where models trained on one dataset are tested on the other to assess the translation impact. Additionally, we incorporate attention maps for model inference interpretation and use the CLIP-Score metric to evaluate the image-description alignment. Our findings show that Swin-DistilBERTimbau consistently outperforms other models, demonstrating strong generalization across datasets. ViTucano, a Brazilian Portuguese pre-trained VLM, surpasses larger multilingual models (GPT-4o, LLaMa 3.2 Vision) in traditional text-based evaluation metrics, while GPT-4 models achieve the highest CLIP-Score, highlighting improved image-text alignment. Attention analysis reveals systematic biases, including gender misclassification, object enumeration errors, and spatial inconsistencies. The datasets and the models generated and analyzed during the current study are available in: https://github.com/laicsiifes/transformer-caption-ptbr.

</details>


### [58] [Modeling Art Evaluations from Comparative Judgments: A Deep Learning Approach to Predicting Aesthetic Preferences](https://arxiv.org/abs/2602.00394)
*Manoj Reddy Bethi,Sai Rupa Jhade,Pravallika Yaganti,Monoshiz Mahbub Khan,Zhe Yu*

Main category: cs.CV

TL;DR: 该论文提出使用成对比较学习框架来降低人类审美判断标注成本，通过深度卷积特征和比较学习模型，在减少60%标注时间的情况下接近回归模型性能。


<details>
  <summary>Details</summary>
Motivation: 人类审美判断建模面临个体偏好差异大和标注数据获取成本高的挑战，需要开发更高效的标注方法来降低大规模偏好建模的成本。

Method: 使用ResNet-50提取绘画图像深度卷积特征，开发深度神经网络回归模型和双分支成对比较模型，基于比较判断定律进行相对选择而非直接评分。

Result: 深度回归模型比基线线性回归提升328%的R²；比较模型在无直接评分情况下接近回归性能；成对比较标注时间减少60%；个体偏好预测仍具挑战性。

Conclusion: 成对比较学习是降低人类审美判断标注成本的有效方法，在标注效率上具有显著优势，但个体偏好预测仍需进一步研究。

Abstract: Modeling human aesthetic judgments in visual art presents significant challenges due to individual preference variability and the high cost of obtaining labeled data. To reduce cost of acquiring such labels, we propose to apply a comparative learning framework based on pairwise preference assessments rather than direct ratings. This approach leverages the Law of Comparative Judgment, which posits that relative choices exhibit less cognitive burden and greater cognitive consistency than direct scoring. We extract deep convolutional features from painting images using ResNet-50 and develop both a deep neural network regression model and a dual-branch pairwise comparison model. We explored four research questions: (RQ1) How does the proposed deep neural network regression model with CNN features compare to the baseline linear regression model using hand-crafted features? (RQ2) How does pairwise comparative learning compare to regression-based prediction when lacking access to direct rating values? (RQ3) Can we predict individual rater preferences through within-rater and cross-rater analysis? (RQ4) What is the annotation cost trade-off between direct ratings and comparative judgments in terms of human time and effort? Our results show that the deep regression model substantially outperforms the baseline, achieving up to $328\%$ improvement in $R^2$. The comparative model approaches regression performance despite having no access to direct rating values, validating the practical utility of pairwise comparisons. However, predicting individual preferences remains challenging, with both within-rater and cross-rater performance significantly lower than average rating prediction. Human subject experiments reveal that comparative judgments require $60\%$ less annotation time per item, demonstrating superior annotation efficiency for large-scale preference modeling.

</details>


### [59] [3DGS$^2$-TR: Scalable Second-Order Trust-Region Method for 3D Gaussian Splatting](https://arxiv.org/abs/2602.00395)
*Roger Hsiao,Yuchen Fang,Xiangru Huang,Ruilong Li,Hesam Rabeti,Zan Gojcic,Javad Lavaei,James Demmel,Sophia Shao*

Main category: cs.CV

TL;DR: 3DGS²-TR：用于3D高斯溅射场景训练的矩阵自由二阶优化器，仅使用Hessian矩阵对角线近似曲率，通过参数化信任区域技术实现稳定优化，比ADAM减少50%训练迭代，内存开销小于1GB。


<details>
  <summary>Details</summary>
Motivation: 现有二阶优化方法（如3DGS-LM和3DGS2）依赖显式或密集曲率表示，计算和内存成本高，限制了在大规模场景中的应用。需要一种更高效、内存友好的二阶优化器来加速3DGS场景训练。

Method: 提出3DGS²-TR优化器：1）仅使用Hessian矩阵对角线近似曲率，通过Hutchinson方法高效计算；2）引入基于平方Hellinger距离的参数化信任区域技术，正则化高斯参数更新；3）完全矩阵自由，计算和内存复杂度与ADAM相同（O(n)）。

Result: 在相同参数初始化和无致密化条件下，相比ADAM：1）达到更好的重建质量；2）减少50%训练迭代；3）峰值GPU内存开销小于1GB（比ADAM多17%，比3DGS-LM少85%）。

Conclusion: 3DGS²-TR是一种高效、内存友好的二阶优化器，能够加速3DGS场景训练，在保持高质量重建的同时显著减少训练时间和内存需求，适用于大规模场景和分布式训练环境。

Abstract: We propose 3DGS$^2$-TR,a second-order optimizer for accelerating the scene training problem in 3D Gaussian Splatting (3DGS). Unlike existing second-order approaches that rely on explicit or dense curvature representations, such as 3DGS-LM (Höllein et al., 2025) or 3DGS2 (Lan et al., 2025), our method approximates curvature using only the diagonal of the Hessian matrix, efficiently via Hutchinson's method. Our approach is fully matrix-free and has the same complexity as ADAM (Kingma, 2024), $O(n)$ in both computation and memory costs. To ensure stable optimization in the presence of strong nonlinearity in the 3DGS rasterization process, we introduce a parameter-wise trust-region technique based on the squared Hellinger distance, regularizing updates to Gaussian parameters. Under identical parameter initialization and without densification, 3DGS$^2$-TR is able to achieve better reconstruction quality on standard datasets, using 50% fewer training iterations compared to ADAM, while incurring less than 1GB of peak GPU memory overhead (17% more than ADAM and 85% less than 3DGS-LM), enabling scalability to very large scenes and potentially to distributed training settings.

</details>


### [60] [Toward Autonomous Laboratory Safety Monitoring with Vision Language Models: Learning to See Hazards Through Scene Structure](https://arxiv.org/abs/2602.00414)
*Trishna Chakraborty,Udita Ghosh,Aldair Ernesto Gongora,Ruben Glatt,Yue Dong,Jiachen Li,Amit K. Roy-Chowdhury,Chengyu Song*

Main category: cs.CV

TL;DR: 该研究提出了一种用于实验室安全监控的视觉语言模型评估框架，通过合成数据集测试发现VLMs在文本场景图输入下表现良好，但在纯视觉输入下性能显著下降，并提出了场景图引导对齐方法来弥合这一差距。


<details>
  <summary>Details</summary>
Motivation: 实验室安全监控因人力限制而难以持续进行，虽然视觉语言模型有望实现自主监控，但缺乏真实视觉评估数据来验证其在实际场景中的有效性。

Method: 1) 开发结构化数据生成流程，将文本实验室场景转换为对齐的（图像、场景图、真实标签）三元组；2) 在合成数据集上评估多个开源和闭源模型；3) 提出场景图引导对齐的后训练方法，将视觉输入转换为结构化场景图以改善VLM推理。

Result: 在1,207个样本、362个独特场景的合成数据集上，VLMs在文本场景图输入下表现有效，但在纯视觉设置下性能显著下降，表明直接从像素中提取结构化对象关系存在困难。提出的场景图引导对齐方法改善了纯视觉设置下的危险检测性能。

Conclusion: 视觉语言模型在实验室安全监控中具有潜力，但需要专门的方法来弥合视觉感知与结构化推理之间的差距，场景图引导对齐提供了一种有效的后训练策略来提升纯视觉环境下的性能。

Abstract: Laboratories are prone to severe injuries from minor unsafe actions, yet continuous safety monitoring -- beyond mandatory pre-lab safety training -- is limited by human availability. Vision language models (VLMs) offer promise for autonomous laboratory safety monitoring, but their effectiveness in realistic settings is unclear due to the lack of visual evaluation data, as most safety incidents are documented primarily as unstructured text. To address this gap, we first introduce a structured data generation pipeline that converts textual laboratory scenarios into aligned triples of (image, scene graph, ground truth), using large language models as scene graph architects and image generation models as renderers. Our experiments on the synthetic dataset of 1,207 samples across 362 unique scenarios and seven open- and closed-source models show that VLMs perform effectively given textual scene graph, but degrade substantially in visual-only settings indicating difficulty in extracting structured object relationships directly from pixels. To overcome this, we propose a post-training context-engineering approach, scene-graph-guided alignment, to bridge perceptual gaps in VLMs by translating visual inputs into structured scene graphs better aligned with VLM reasoning, improving hazard detection performance in visual only settings.

</details>


### [61] [Text is All You Need for Vision-Language Model Jailbreaking](https://arxiv.org/abs/2602.00420)
*Yihang Chen,Zhao Xu,Youyuan Jiang,Tianle Zheng,Cho-Jui Hsieh*

Main category: cs.CV

TL;DR: Text-DJ是一种针对大型视觉语言模型的新型越狱攻击，通过利用OCR能力将有害查询分解为多个良性子查询，并添加无关干扰查询，以图像网格形式绕过安全防护。


<details>
  <summary>Details</summary>
Motivation: 现有LVLM安全防护主要关注显式文本输入或相关视觉场景分析，但忽视了模型OCR能力可能被利用的漏洞。研究者发现通过将文本转换为图像并分散处理，可以绕过现有的安全机制。

Method: 采用三阶段方法：1) 将单个有害查询分解为多个语义相关但更良性的子查询；2) 选择与有害查询最大程度无关的干扰查询；3) 将所有子查询和干扰查询以图像网格形式同时呈现给LVLM，其中子查询位于网格中间位置。

Result: 该方法成功绕过了最先进LVLM的安全对齐机制，通过将文本提示转换为图像绕过标准文本过滤器，并通过诱导干扰使模型安全协议无法在大量无关查询中关联分散的子查询。

Conclusion: 研究揭示了LVLM OCR能力对分散、多图像对抗输入的脆弱性，暴露了关键安全漏洞，强调需要对碎片化多模态输入开发防御机制。

Abstract: Large Vision-Language Models (LVLMs) are increasingly equipped with robust safety safeguards to prevent responses to harmful or disallowed prompts. However, these defenses often focus on analyzing explicit textual inputs or relevant visual scenes. In this work, we introduce Text-DJ, a novel jailbreak attack that bypasses these safeguards by exploiting the model's Optical Character Recognition (OCR) capability. Our methodology consists of three stages. First, we decompose a single harmful query into multiple and semantically related but more benign sub-queries. Second, we pick a set of distraction queries that are maximally irrelevant to the harmful query. Third, we present all decomposed sub-queries and distraction queries to the LVLM simultaneously as a grid of images, with the position of the sub-queries being middle within the grid. We demonstrate that this method successfully circumvents the safety alignment of state-of-the-art LVLMs. We argue this attack succeeds by (1) converting text-based prompts into images, bypassing standard text-based filters, and (2) inducing distractions, where the model's safety protocols fail to link the scattered sub-queries within a high number of irrelevant queries. Overall, our findings expose a critical vulnerability in LVLMs' OCR capabilities that are not robust to dispersed, multi-image adversarial inputs, highlighting the need for defenses for fragmented multimodal inputs.

</details>


### [62] [DISK: Dynamic Inference SKipping for World Models](https://arxiv.org/abs/2602.00440)
*Anugunj Naman,Gaibo Zhang,Ayushman Singh,Yaguang Zhang*

Main category: cs.CV

TL;DR: DISK是一种无需训练的自适应推理方法，通过双分支控制器协调视频和自我轨迹的扩散变换器，在保持性能的同时实现2倍速度提升。


<details>
  <summary>Details</summary>
Motivation: 自回归世界模型在长时域视频和轨迹预测中计算成本高昂，需要在不重新训练的情况下提高推理效率，同时保持运动-外观一致性。

Method: 使用双分支控制器协调两个耦合的扩散变换器（视频和轨迹），通过跨模态跳过决策和扩展的高阶潜在差异跳过测试，在自回归链式前向传播中传播控制器统计信息。

Result: 在NuPlan和NuScenes数据集上，DISK实现了轨迹扩散2倍加速和视频扩散1.6倍加速，同时保持L2规划误差、视觉质量（FID/FVD）和NAVSIM PDMS分数。

Conclusion: DISK能够在显著降低计算成本的情况下实现实用的长时域视频和轨迹预测，为自回归世界模型提供了高效的推理解决方案。

Abstract: We present DISK, a training-free adaptive inference method for autoregressive world models. DISK coordinates two coupled diffusion transformers for video and ego-trajectory via dual-branch controllers with cross-modal skip decisions, preserving motion-appearance consistency without retraining. We extend higher-order latent-difference skip testing to the autoregressive chain-of-forward regime and propagate controller statistics through rollout loops for long-horizon stability. When integrated into closed-loop driving rollouts on 1500 NuPlan and NuScenes samples using an NVIDIA L40S GPU, DISK achieves 2x speedup on trajectory diffusion and 1.6x speedup on video diffusion while maintaining L2 planning error, visual quality (FID/FVD), and NAVSIM PDMS scores, demonstrating practical long-horizon video-and-trajectory prediction at substantially reduced cost.

</details>


### [63] [Model Optimization for Multi-Camera 3D Detection and Tracking](https://arxiv.org/abs/2602.00450)
*Ethan Anderson,Justin Silva,Kyle Zheng,Sameer Pusegaonkar,Yizhou Wang,Zheng Tang,Sujit Biswas*

Main category: cs.CV

TL;DR: Sparse4D多相机3D检测跟踪框架在低帧率、量化、跨数据集迁移和混合精度训练下的性能分析，重点关注身份稳定性指标


<details>
  <summary>Details</summary>
Motivation: 室内环境中静态相机网络需要处理遮挡和多视角下的多目标跟踪问题，需要评估现有方法在不同实际约束下的鲁棒性

Method: 评估Sparse4D框架在多种条件下的表现：降低输入帧率、后训练量化（INT8/FP8）、跨数据集迁移到WILDTRACK、Transformer Engine混合精度微调，引入平均跟踪持续时间指标衡量身份稳定性

Result: Sparse4D在适度帧率降低下稳定，但低于2FPS时身份关联崩溃；选择性量化骨干网络和颈部提供最佳速度-精度权衡；低帧率预训练在WILDTRACK上带来显著零样本提升；混合精度减少延迟但可能破坏身份传播稳定性

Conclusion: 多相机感知系统需要综合考虑帧率、量化精度和身份稳定性，选择性量化和稳定性验证是关键，低帧率预训练有助于跨数据集泛化，混合精度需要谨慎处理以保持跟踪连续性

Abstract: Outside-in multi-camera perception is increasingly important in indoor environments, where networks of static cameras must support multi-target tracking under occlusion and heterogeneous viewpoints. We evaluate Sparse4D, a query-based spatiotemporal 3D detection and tracking framework that fuses multi-view features in a shared world frame and propagates sparse object queries via instance memory. We study reduced input frame rates, post-training quantization (INT8 and FP8), transfer to the WILDTRACK benchmark, and Transformer Engine mixed-precision fine-tuning. To better capture identity stability, we report Average Track Duration (AvgTrackDur), which measures identity persistence in seconds. Sparse4D remains stable under moderate FPS reductions, but below 2 FPS, identity association collapses even when detections are stable. Selective quantization of the backbone and neck offers the best speed-accuracy trade-off, while attention-related modules are consistently sensitive to low precision. On WILDTRACK, low-FPS pretraining yields large zero-shot gains over the base checkpoint, while small-scale fine-tuning provides limited additional benefit. Transformer Engine mixed precision reduces latency and improves camera scalability, but can destabilize identity propagation, motivating stability-aware validation.

</details>


### [64] [LatentLens: Revealing Highly Interpretable Visual Tokens in LLMs](https://arxiv.org/abs/2602.00462)
*Benno Krojer,Shravan Nayak,Oscar Mañas,Vaibhav Adlakha,Desmond Elliott,Siva Reddy,Marius Mosbach*

Main category: cs.CV

TL;DR: 提出LatentLens方法，通过将视觉token表示与大型文本语料库的上下文文本表示进行比较，实现视觉语言模型中视觉token的可解释性分析。


<details>
  <summary>Details</summary>
Motivation: 理解为什么大型语言模型能够轻松处理视觉token，需要能够揭示LLM处理过程中每一层视觉token表示内容的可解释性方法。

Method: LatentLens方法：编码大型文本语料库并存储每个token的上下文表示，然后将视觉token表示与这些文本表示进行比较，通过top-k最近邻表示提供视觉token的描述。

Result: 在10个不同VLM上评估，显示常用方法（如LogitLens）严重低估了视觉token的可解释性。使用LatentLens后，大多数视觉token在所有研究模型和所有层中都是可解释的。

Conclusion: LatentLens产生的描述具有语义意义，比单个token提供更细粒度的人类可解释性，为视觉和语言表示的对齐提供了新证据，开辟了分析潜在表示的新方向。

Abstract: Transforming a large language model (LLM) into a Vision-Language Model (VLM) can be achieved by mapping the visual tokens from a vision encoder into the embedding space of an LLM. Intriguingly, this mapping can be as simple as a shallow MLP transformation. To understand why LLMs can so readily process visual tokens, we need interpretability methods that reveal what is encoded in the visual token representations at every layer of LLM processing. In this work, we introduce LatentLens, a novel approach for mapping latent representations to descriptions in natural language. LatentLens works by encoding a large text corpus and storing contextualized token representations for each token in that corpus. Visual token representations are then compared to their contextualized textual representations, with the top-k nearest neighbor representations providing descriptions of the visual token. We evaluate this method on 10 different VLMs, showing that commonly used methods, such as LogitLens, substantially underestimate the interpretability of visual tokens. With LatentLens instead, the majority of visual tokens are interpretable across all studied models and all layers. Qualitatively, we show that the descriptions produced by LatentLens are semantically meaningful and provide more fine-grained interpretations for humans compared to individual tokens. More broadly, our findings contribute new evidence on the alignment between vision and language representations, opening up new directions for analyzing latent representations.

</details>


### [65] [PSGS: Text-driven Panorama Sliding Scene Generation via Gaussian Splatting](https://arxiv.org/abs/2602.00463)
*Xin Zhang,Shen Chen,Jiale Zhou,Lei Li*

Main category: cs.CV

TL;DR: PSGS：一个两阶段框架，通过双层优化架构生成语义连贯的全景图，然后通过全景滑动机制初始化全局一致的3D高斯泼溅点云，实现高质量文本到3D场景生成。


<details>
  <summary>Details</summary>
Motivation: 当前文本驱动3D场景生成方法面临两个主要问题：1）有限的3D-文本配对数据；2）多视角拼接不一致导致场景过于简单。这些问题限制了在VR、AR和游戏等沉浸式应用中的实用性和质量。

Method: PSGS采用两阶段框架：第一阶段通过双层优化架构生成全景图，包括布局推理层（将文本解析为结构化空间关系）和自优化层（通过迭代MLLM反馈优化视觉细节）；第二阶段通过全景滑动机制，策略性地采样重叠视角来初始化全局一致的3D高斯泼溅点云，并在训练中结合深度和语义一致性损失。

Result: 实验表明PSGS在全景图生成方面优于现有方法，并能生成更具吸引力的3D场景，为可扩展的沉浸式内容创作提供了鲁棒解决方案。

Conclusion: PSGS通过创新的双层优化架构和全景滑动机制，有效解决了文本到3D场景生成中的语义一致性和视觉质量问题，为高质量沉浸式内容创作提供了实用框架。

Abstract: Generating realistic 3D scenes from text is crucial for immersive applications like VR, AR, and gaming. While text-driven approaches promise efficiency, existing methods suffer from limited 3D-text data and inconsistent multi-view stitching, resulting in overly simplistic scenes. To address this, we propose PSGS, a two-stage framework for high-fidelity panoramic scene generation. First, a novel two-layer optimization architecture generates semantically coherent panoramas: a layout reasoning layer parses text into structured spatial relationships, while a self-optimization layer refines visual details via iterative MLLM feedback. Second, our panorama sliding mechanism initializes globally consistent 3D Gaussian Splatting point clouds by strategically sampling overlapping perspectives. By incorporating depth and semantic coherence losses during training, we greatly improve the quality and detail fidelity of rendered scenes. Our experiments demonstrate that PSGS outperforms existing methods in panorama generation and produces more appealing 3D scenes, offering a robust solution for scalable immersive content creation.

</details>


### [66] [ZS-TreeSeg: A Zero-Shot Framework for Tree Crown Instance Segmentation](https://arxiv.org/abs/2602.00470)
*Pengyu Chen,Fangzheng Lyu,Sicheng Wang,Cuizhen Wang*

Main category: cs.CV

TL;DR: 提出ZS-TreeSeg零样本框架，通过将树冠建模为星凸对象，利用Cellpose-SAM在拓扑流场中实现密集重叠树冠的实例分割，无需训练即可跨传感器和冠层密度泛化。


<details>
  <summary>Details</summary>
Motivation: 个体树冠分割对森林生物量估算和生态监测很重要，但密集重叠冠层的准确分割仍是瓶颈。监督深度学习方法标注成本高、泛化有限，而基础模型缺乏领域知识导致欠分割。

Method: 提出ZS-TreeSeg零样本框架，从两个成熟任务（冠层语义分割和细胞实例分割）迁移。将树冠建模为星凸对象，在拓扑流场中使用Cellpose-SAM，基于向量收敛实现接触树冠实例的数学分离。

Result: 在NEON和BAMFOREST数据集上的实验和视觉检查表明，该框架能稳健地跨不同传感器类型和冠层密度泛化，为树冠实例分割和标签生成提供免训练解决方案。

Conclusion: ZS-TreeSeg通过迁移学习和拓扑建模，解决了密集树冠分割的挑战，提供了高效、泛化性强的零样本解决方案，有望降低标注成本并提高分割精度。

Abstract: Individual tree crown segmentation is an important task in remote sensing for forest biomass estimation and ecological monitoring. However, accurate delineation in dense, overlapping canopies remains a bottleneck. While supervised deep learning methods suffer from high annotation costs and limited generalization, emerging foundation models (e.g., Segment Anything Model) often lack domain knowledge, leading to under-segmentation in dense clusters. To bridge this gap, we propose ZS-TreeSeg, a Zero-Shot framework that adapts from two mature tasks: 1) Canopy Semantic segmentation; and 2) Cells instance segmentation. By modeling tree crowns as star-convex objects within a topological flow field using Cellpose-SAM, the ZS-TreeSeg framework forces the mathematical separation of touching tree crown instances based on vector convergence. Experiments on the NEON and BAMFOREST datasets and visual inspection demonstrate that our framework generalizes robustly across diverse sensor types and canopy densities, which can offer a training-free solution for tree crown instance segmentation and labels generation.

</details>


### [67] [GTATrack: Winner Solution to SoccerTrack 2025 with Deep-EIoU and Global Tracklet Association](https://arxiv.org/abs/2602.00484)
*Rong-Lin Jian,Ming-Chi Luo,Chen-Wei Huang,Chia-Ming Lee,Yu-Fan Lin,Chih-Chung Hsu*

Main category: cs.CV

TL;DR: GTATrack是一个用于鱼眼相机足球比赛多目标跟踪的分层框架，在SoccerTrack Challenge 2025中获得第一名，通过Deep-EIoU和GTA组件实现短期匹配和长期身份一致性。


<details>
  <summary>Details</summary>
Motivation: 体育场景中的多目标跟踪面临球员运动不规则、外观相似、频繁遮挡等挑战，而静态鱼眼相机带来的几何畸变和极端尺度变化进一步加剧了这些困难。

Method: 提出GTATrack分层跟踪框架，包含两个核心组件：Deep Expansion IoU用于运动无关的在线关联，Global Tracklet Association用于轨迹级精炼。采用两阶段设计实现短期匹配和长期身份一致性，并使用伪标签策略提升小目标和畸变目标的检测召回率。

Result: 在SoccerTrack Challenge 2025中获得第一名，HOTA得分0.60，显著减少误报至982个，在鱼眼相机足球跟踪中达到最先进精度。

Conclusion: GTATrack通过局部关联和全局推理的协同作用，有效解决了身份切换、遮挡和跟踪碎片化问题，在具有挑战性的鱼眼相机足球跟踪场景中表现出色。

Abstract: Multi-object tracking (MOT) in sports is highly challenging due to irregular player motion, uniform appearances, and frequent occlusions. These difficulties are further exacerbated by the geometric distortion and extreme scale variation introduced by static fisheye cameras. In this work, we present GTATrack, a hierarchical tracking framework that win first place in the SoccerTrack Challenge 2025. GTATrack integrates two core components: Deep Expansion IoU (Deep-EIoU) for motion-agnostic online association and Global Tracklet Association (GTA) for trajectory-level refinement. This two-stage design enables both robust short-term matching and long-term identity consistency. Additionally, a pseudo-labeling strategy is used to boost detector recall on small and distorted targets. The synergy between local association and global reasoning effectively addresses identity switches, occlusions, and tracking fragmentation. Our method achieved a winning HOTA score of 0.60 and significantly reduced false positives to 982, demonstrating state-of-the-art accuracy in fisheye-based soccer tracking. Our code is available at https://github.com/ron941/GTATrack-STC2025.

</details>


### [68] [Refining Strokes by Learning Offset Attributes between Strokes for Flexible Sketch Edit at Stroke-Level](https://arxiv.org/abs/2602.00489)
*Sicong Zang,Tao Sun,Cairong Yan*

Main category: cs.CV

TL;DR: SketchMod：通过变换源笔划来对齐目标草图模式，实现灵活的笔划级草图编辑，包括缩放、旋转和位移调整


<details>
  <summary>Details</summary>
Motivation: 现有方法仅重新定位源笔划而不调整其大小和方向，当源笔划与目标草图在尺寸和方向上差异显著时，无法产生合理的编辑结果

Method: 学习源笔划的三个关键偏移属性（缩放、方向和位置），通过：1）缩放匹配空间比例，2）旋转对齐局部几何，3）位移满足语义布局，来对齐目标草图模式

Result: 实验结果表明SketchMod在笔划级草图编辑上实现了精确和灵活的性能

Conclusion: 通过变换源笔划来对齐目标草图模式，SketchMod能够实现更精确和灵活的笔划级草图编辑，同时通过暴露的笔划属性实现对笔划轮廓的精确控制

Abstract: Sketch edit at stroke-level aims to transplant source strokes onto a target sketch via stroke expansion or replacement, while preserving semantic consistency and visual fidelity with the target sketch. Recent studies addressed it by relocating source strokes at appropriate canvas positions. However, as source strokes could exhibit significant variations in both size and orientation, we may fail to produce plausible sketch editing results by merely repositioning them without further adjustments. For example, anchoring an oversized source stroke onto the target without proper scaling would fail to produce a semantically coherent outcome. In this paper, we propose SketchMod to refine the source stroke through transformation so as to align it with the target sketch's patterns, further realize flexible sketch edit at stroke-level. As the source stroke refinement is governed by the patterns of the target sketch, we learn three key offset attributes (scale, orientation and position) from the source stroke to another, and align it with the target by: 1) resizing to match spatial proportions by scale, 2) rotating to align with local geometry by orientation, and 3) displacing to meet with semantic layout by position. Besides, a stroke's profiles can be precisely controlled during sketch edit via the exposed captured stroke attributes. Experimental results indicate that SketchMod achieves precise and flexible performances on stroke-level sketch edit.

</details>


### [69] [HSSDCT: Factorized Spatial-Spectral Correlation for Hyperspectral Image Fusion](https://arxiv.org/abs/2602.00490)
*Chia-Ming Lee,Yu-Hao Ho,Yu-Fan Lin,Jen-Wei Lee,Li-Wei Kang,Chih-Chung Hsu*

Main category: cs.CV

TL;DR: 提出HSSDCT网络，通过分层密集残差Transformer块和空间-光谱相关层，解决高光谱图像融合中的感受野限制、光谱冗余和自注意力二次复杂度问题，实现高效高质量重建。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在高光谱图像融合中存在三个主要问题：1) 感受野有限，2) 光谱波段冗余，3) 自注意力的二次复杂度。这些问题限制了方法的效率和鲁棒性。

Method: 提出分层空间-光谱密集相关网络(HSSDCT)，包含两个核心模块：1) 分层密集残差Transformer块(HDRTB)，通过渐进扩大窗口和使用密集残差连接实现多尺度特征聚合；2) 空间-光谱相关层(SSCL)，显式分解空间和光谱依赖关系，将自注意力复杂度降至线性，同时缓解光谱冗余。

Result: 在基准数据集上的大量实验表明，HSSDCT在显著降低计算成本的同时，提供了优越的重建质量，在高光谱图像融合任务中达到了新的最先进性能。

Conclusion: HSSDCT通过创新的分层Transformer结构和空间-光谱分解机制，有效解决了高光谱图像融合中的关键挑战，实现了高效且高质量的重建，为相关领域提供了新的解决方案。

Abstract: Hyperspectral image (HSI) fusion aims to reconstruct a high-resolution HSI (HR-HSI) by combining the rich spectral information of a low-resolution HSI (LR-HSI) with the fine spatial details of a high-resolution multispectral image (HR-MSI). Although recent deep learning methods have achieved notable progress, they still suffer from limited receptive fields, redundant spectral bands, and the quadratic complexity of self-attention, which restrict both efficiency and robustness. To overcome these challenges, we propose the Hierarchical Spatial-Spectral Dense Correlation Network (HSSDCT). The framework introduces two key modules: (i) a Hierarchical Dense-Residue Transformer Block (HDRTB) that progressively enlarges windows and employs dense-residue connections for multi-scale feature aggregation, and (ii) a Spatial-Spectral Correlation Layer (SSCL) that explicitly factorizes spatial and spectral dependencies, reducing self-attention to linear complexity while mitigating spectral redundancy. Extensive experiments on benchmark datasets demonstrate that HSSDCT delivers superior reconstruction quality with significantly lower computational costs, achieving new state-of-the-art performance in HSI fusion. Our code is available at https://github.com/jemmyleee/HSSDCT.

</details>


### [70] [RGBX-R1: Visual Modality Chain-of-Thought Guided Reinforcement Learning for Multimodal Grounding](https://arxiv.org/abs/2602.00504)
*Jiahe Wu,Bing Cao,Qilong Wang,Qinghua Hu,Dongdong Li,Pengfei Zhu*

Main category: cs.CV

TL;DR: RGBX-R1框架通过UAV提示策略构建视觉模态思维链，采用两阶段训练增强MLLM在红外、深度等X模态的感知与推理能力，在RGBX-Grounding基准上显著超越基线22.71%


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型主要预训练于RGB模态，限制了在红外、深度、事件数据等其他视觉模态上的性能，而这些模态对复杂场景至关重要

Method: 提出RGBX-R1框架：1) 使用Understand-Associate-Validate提示策略构建视觉模态思维链；2) 采用两阶段训练：冷启动监督微调监督推理过程，时空强化微调使用模态理解时空奖励强化推理

Result: 构建首个RGBX-Grounding基准，在三个RGBX grounding任务上超越基线22.71%，在多模态理解和空间感知方面表现优异

Conclusion: RGBX-R1框架有效扩展了MLLM在多种视觉模态上的感知和推理能力，为处理复杂场景提供了有力工具

Abstract: Multimodal Large Language Models (MLLM) are primarily pre-trained on the RGB modality, thereby limiting their performance on other modalities, such as infrared, depth, and event data, which are crucial for complex scenarios. To address this, we propose RGBX-R1, a framework to enhance MLLM's perception and reasoning capacities across various X visual modalities. Specifically, we employ an Understand-Associate-Validate (UAV) prompting strategy to construct the Visual Modality Chain-of-Thought (VM-CoT), which aims to expand the MLLMs' RGB understanding capability into X modalities. To progressively enhance reasoning capabilities, we introduce a two-stage training paradigm: Cold-Start Supervised Fine-Tuning (CS-SFT) and Spatio-Temporal Reinforcement Fine-Tuning (ST-RFT). CS-SFT supervises the reasoning process with the guidance of VM-CoT, equipping the MLLM with fundamental modality cognition. Building upon GRPO, ST-RFT employs a Modality-understanding Spatio-Temporal (MuST) reward to reinforce modality reasoning. Notably, we construct the first RGBX-Grounding benchmark, and extensive experiments verify our superiority in multimodal understanding and spatial perception, outperforming baselines by 22.71% on three RGBX grounding tasks.

</details>


### [71] [Sparse Shortcuts: Facilitating Efficient Fusion in Multimodal Large Language Models](https://arxiv.org/abs/2602.00505)
*Jingrui Zhang,Feng Liang,Yong Zhang,Wei Wang,Runhao Zeng,Xiping Hu*

Main category: cs.CV

TL;DR: SparseCut是一种用于多模态大语言模型的通用跨模态融合架构，通过稀疏快捷连接实现多层次视觉特征的高效分层集成，提升跨模态理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs大多关注扩展语言模型或构建高质量训练数据，但忽略了如何有效将跨模态知识集成到语言空间中。在视觉语言模型中，仅使用高层视觉特征进行模态对齐会丢弃中低层特征的丰富语义信息，限制了模型的跨模态理解能力。

Method: 提出SparseCut架构，在跨模态编码器和LLM之间引入稀疏快捷连接，实现多层次视觉特征的高效分层集成。进一步引入高效的多粒度特征融合模块，在通过快捷连接路由之前进行视觉特征融合，保持原始语言上下文且不增加输入长度。

Result: 实验表明，SparseCut显著提升了MLLMs在各种多模态基准测试中的性能，对不同基础LLM具有通用性和可扩展性。

Conclusion: SparseCut通过稀疏快捷连接和多粒度特征融合，有效解决了跨模态知识集成问题，在不增加计算开销的情况下显著提升了MLLMs的跨模态理解能力。

Abstract: With the remarkable success of large language models (LLMs) in natural language understanding and generation, multimodal large language models (MLLMs) have rapidly advanced in their ability to process data across multiple modalities. While most existing efforts focus on scaling up language models or constructing higher-quality training data, limited attention has been paid to effectively integrating cross-modal knowledge into the language space. In vision-language models, for instance, aligning modalities using only high-level visual features often discards the rich semantic information present in mid- and low-level features, limiting the model's ability of cross-modality understanding. To address this issue, we propose SparseCut, a general cross-modal fusion architecture for MLLMs, introducing sparse shortcut connections between the cross-modal encoder and the LLM. These shortcut connections enable the efficient and hierarchical integration of visual features at multiple levels, facilitating richer semantic fusion without increasing computational overhead. We further introduce an efficient multi-grained feature fusion module, which performs the fusion of visual features before routing them through the shortcuts. This preserves the original language context and does not increase the overall input length, thereby avoiding an increase in computational complexity for the LLM. Experiments demonstrate that SparseCut significantly enhances the performance of MLLMs across various multimodal benchmarks with generality and scalability for different base LLMs.

</details>


### [72] [DuoGen: Towards General Purpose Interleaved Multimodal Generation](https://arxiv.org/abs/2602.00508)
*Min Shi,Xiaohui Zeng,Jiannan Huang,Yin Cui,Francesco Ferroni,Jialuo Li,Shubham Pachori,Zhaoshuo Li,Yogesh Balaji,Haoxiang Wang,Tsung-Yi Lin,Xiao Fu,Yue Zhao,Chieh-Yun Chen,Ming-Yu Liu,Humphrey Shi*

Main category: cs.CV

TL;DR: DuoGen是一个通用的交错多模态生成框架，通过数据构建、架构设计和评估系统解决现有交错生成模型在通用指令下的质量问题，在文本质量、图像保真度和图像上下文对齐方面优于现有开源模型。


<details>
  <summary>Details</summary>
Motivation: 现有的交错多模态生成模型在通用指令下的质量受到训练数据不足和基础模型能力的限制，需要系统性的解决方案来提升交错生成的质量。

Method: 1) 数据方面：构建大规模高质量的指令调优数据集，结合从精选网站重写的多模态对话和覆盖日常场景的多样化合成示例；2) 架构方面：利用预训练多模态LLM的视觉理解能力和预训练视频生成的扩散变换器(DiT)的视觉生成能力，避免昂贵的单模态预训练；3) 采用两阶段解耦策略：先指令调优MLLM，然后用精选的交错图像-文本序列将DiT与之对齐。

Result: 在公共和新提出的基准测试中，DuoGen在文本质量、图像保真度和图像上下文对齐方面优于先前的开源模型，同时在统一生成模型中实现了文本到图像和图像编辑的最先进性能。

Conclusion: DuoGen通过系统性的数据构建、架构设计和评估方法，成功提升了交错多模态生成的质量，为通用交错生成提供了一个有效的框架，并在多个任务上达到了最先进的性能。

Abstract: Interleaved multimodal generation enables capabilities beyond unimodal generation models, such as step-by-step instructional guides, visual planning, and generating visual drafts for reasoning. However, the quality of existing interleaved generation models under general instructions remains limited by insufficient training data and base model capacity. We present DuoGen, a general-purpose interleaved generation framework that systematically addresses data curation, architecture design, and evaluation. On the data side, we build a large-scale, high-quality instruction-tuning dataset by combining multimodal conversations rewritten from curated raw websites, and diverse synthetic examples covering everyday scenarios. Architecturally, DuoGen leverages the strong visual understanding of a pretrained multimodal LLM and the visual generation capabilities of a diffusion transformer (DiT) pretrained on video generation, avoiding costly unimodal pretraining and enabling flexible base model selection. A two-stage decoupled strategy first instruction-tunes the MLLM, then aligns DiT with it using curated interleaved image-text sequences. Across public and newly proposed benchmarks, DuoGen outperforms prior open-source models in text quality, image fidelity, and image-context alignment, and also achieves state-of-the-art performance on text-to-image and image editing among unified generation models. Data and code will be released at https://research.nvidia.com/labs/dir/duetgen/.

</details>


### [73] [SPARK: Stochastic Propagation via Affinity-guided Random walK for training-free unsupervised segmentation](https://arxiv.org/abs/2602.00516)
*Kunal Mahatha,Jose Dolz,Christian Desrosiers*

Main category: cs.CV

TL;DR: 提出新的训练无关分割方法，将分割重新定义为扩散诱导亲和力图上的随机流平衡问题，通过马尔可夫传播方案实现零样本分割，在多个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有训练无关分割方法存在根本性缺陷：依赖谱图分割假设、需要预设簇数量、边界过度平滑、对噪声和多模态亲和力分布敏感，且忽视局部邻域结构的重要性。

Method: 将训练无关分割重新定义为扩散诱导亲和力图上的随机流平衡问题，引入马尔可夫传播方案，结合随机游走标签扩散和自适应剪枝策略，整合全局扩散注意力与稳定扩散提取的局部邻域。

Result: 在七个广泛使用的语义分割基准测试中达到最先进的零样本性能，产生更锐利的边界、更连贯的区域，相比基于谱聚类的方法获得显著更稳定的掩码。

Conclusion: 通过将分割重新定义为随机流平衡问题并引入马尔可夫传播方案，克服了传统谱图分割方法的局限性，实现了更鲁棒、更精确的训练无关分割。

Abstract: We argue that existing training-free segmentation methods rely on an implicit and limiting assumption, that segmentation is a spectral graph partitioning problem over diffusion-derived affinities. Such approaches, based on global graph partitioning and eigenvector-based formulations of affinity matrices, suffer from several fundamental drawbacks, they require pre-selecting the number of clusters, induce boundary oversmoothing due to spectral relaxation, and remain highly sensitive to noisy or multi-modal affinity distributions. Moreover, many prior works neglect the importance of local neighborhood structure, which plays a crucial role in stabilizing affinity propagation and preserving fine-grained contours. To address these limitations, we reformulate training-free segmentation as a stochastic flow equilibrium problem over diffusion-induced affinity graphs, where segmentation emerges from a stochastic propagation process that integrates global diffusion attention with local neighborhoods extracted from stable diffusion, yielding a sparse yet expressive affinity structure. Building on this formulation, we introduce a Markov propagation scheme that performs random-walk-based label diffusion with an adaptive pruning strategy that suppresses unreliable transitions while reinforcing confident affinity paths. Experiments across seven widely used semantic segmentation benchmarks demonstrate that our method achieves state-of-the-art zero-shot performance, producing sharper boundaries, more coherent regions, and significantly more stable masks compared to prior spectral-clustering-based approaches.

</details>


### [74] [MRAD: Zero-Shot Anomaly Detection with Memory-Driven Retrieval](https://arxiv.org/abs/2602.00522)
*Chaoran Xu,Chengkan Lv,Qiyu Chen,Feng Zhang,Zhengtao Zhang*

Main category: cs.CV

TL;DR: MRAD提出基于记忆检索的零样本异常检测框架，通过构建两级记忆库直接检索异常分数，无需复杂模型拟合，在工业与医疗数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有零样本异常检测方法多使用提示学习或复杂建模来拟合数据分布，导致训练/推理成本高且跨域稳定性有限，需要更高效稳定的解决方案。

Method: 提出MRAD框架：1) MRAD-TF冻结CLIP编码器，构建图像级和像素级两级记忆库存储特征-标签对；2) MRAD-FT用两个线性层微调检索度量；3) MRAD-CLIP将正常/异常区域先验注入CLIP文本提示。

Result: 在16个工业和医疗数据集上，MRAD框架在异常分类和分割任务中均表现优异，在训练免费和基于训练两种设置下都展示了优越性能。

Conclusion: 充分利用原始数据的经验分布而非仅依赖模型拟合，可以获得更强的异常检测性能。记忆检索方法为高效稳定的零样本异常检测提供了新思路。

Abstract: Zero-shot anomaly detection (ZSAD) often leverages pretrained vision or vision-language models, but many existing methods use prompt learning or complex modeling to fit the data distribution, resulting in high training or inference cost and limited cross-domain stability. To address these limitations, we propose Memory-Retrieval Anomaly Detection method (MRAD), a unified framework that replaces parametric fitting with a direct memory retrieval. The train-free base model, MRAD-TF, freezes the CLIP image encoder and constructs a two-level memory bank (image-level and pixel-level) from auxiliary data, where feature-label pairs are explicitly stored as keys and values. During inference, anomaly scores are obtained directly by similarity retrieval over the memory bank. Based on the MRAD-TF, we further propose two lightweight variants as enhancements: (i) MRAD-FT fine-tunes the retrieval metric with two linear layers to enhance the discriminability between normal and anomaly; (ii) MRAD-CLIP injects the normal and anomalous region priors from the MRAD-FT as dynamic biases into CLIP's learnable text prompts, strengthening generalization to unseen categories. Across 16 industrial and medical datasets, the MRAD framework consistently demonstrates superior performance in anomaly classification and segmentation, under both train-free and training-based settings. Our work shows that fully leveraging the empirical distribution of raw data, rather than relying only on model fitting, can achieve stronger anomaly detection performance. The code will be publicly released at https://github.com/CROVO1026/MRAD.

</details>


### [75] [SAGE: Accelerating Vision-Language Models via Entropy-Guided Adaptive Speculative Decoding](https://arxiv.org/abs/2602.00523)
*Yujia Tong,Tian Zhang,Yunyang Wan,Kaiwei Lin,Jingling Yuan,Chuang Hu*

Main category: cs.CV

TL;DR: SAGE提出了一种动态调整推测解码树结构的方法，根据实时预测不确定性自适应构建更深更窄或更浅更宽的树，从而在视觉语言模型中实现更优的加速效果。


<details>
  <summary>Details</summary>
Motivation: 现有推测解码方法使用静态树结构，无法适应不同生成步骤中预测难度的变化，导致接受长度不理想和加速效果有限。需要一种能够根据实时预测不确定性动态调整树结构的方法。

Method: SAGE框架利用输出熵作为置信度指标，根据实时预测不确定性动态调整推测树结构：对于高置信度预测构建更深更窄的树以最大化推测深度，对于不确定预测构建更浅更宽的树以多样化探索。

Result: SAGE在多个基准测试中表现出色，在不损失输出质量的情况下，为LLaVA-OneVision-72B提供最高3.36倍的解码加速，为Qwen2.5-VL-72B提供最高3.18倍的解码加速。

Conclusion: SAGE通过动态调整推测树结构，有效解决了静态树方法的局限性，显著提高了视觉语言模型推理的加速效果，为推测解码提供了新的自适应框架。

Abstract: Speculative decoding has emerged as a promising approach to accelerate inference in vision-language models (VLMs) by enabling parallel verification of multiple draft tokens. However, existing methods rely on static tree structures that remain fixed throughout the decoding process, failing to adapt to the varying prediction difficulty across generation steps. This leads to suboptimal acceptance lengths and limited speedup. In this paper, we propose SAGE, a novel framework that dynamically adjusts the speculation tree structure based on real-time prediction uncertainty. Our key insight is that output entropy serves as a natural confidence indicator with strong temporal correlation across decoding steps. SAGE constructs deeper-narrower trees for high-confidence predictions to maximize speculation depth, and shallower-wider trees for uncertain predictions to diversify exploration. SAGE improves acceptance lengths and achieves faster acceleration compared to static tree baselines. Experiments on multiple benchmarks demonstrate the effectiveness of SAGE: without any loss in output quality, it delivers up to $3.36\times$ decoding speedup for LLaVA-OneVision-72B and $3.18\times$ for Qwen2.5-VL-72B.

</details>


### [76] [Enhancing Open-Vocabulary Object Detection through Multi-Level Fine-Grained Visual-Language Alignment](https://arxiv.org/abs/2602.00531)
*Tianyi Zhang,Antoine Simoulin,Kai Li,Sana Lakdawala,Shiqing Yu,Arpit Mittal,Hongyu Fu,Yu Lin*

Main category: cs.CV

TL;DR: VLDet是一个新颖的开放词汇目标检测框架，通过重新设计特征金字塔实现细粒度视觉-语言对齐，显著提升了新类别的检测性能。


<details>
  <summary>Details</summary>
Motivation: 传统目标检测系统受限于预定义类别，无法适应动态环境。开放词汇目标检测(OVD)虽然能识别训练集中未出现的新类别，但现有方法在将CLIP的单尺度图像骨干网络适配到检测框架或确保稳健的视觉-语言对齐方面面临挑战。

Method: 提出VLDet框架：1) VL-PUB模块有效利用CLIP的视觉-语言知识，通过特征金字塔将骨干网络适配到目标检测；2) SigRPN模块引入基于sigmoid的锚点-文本对比对齐损失，提升新类别检测能力；3) 重新设计特征金字塔以实现细粒度视觉-语言对齐。

Result: 在COCO2017上达到58.7 AP（新类别），在LVIS上达到24.8 AP，分别比现有最优方法提升27.6%和6.9%。同时在闭集目标检测上也表现出优越的零样本性能。

Conclusion: VLDet通过重新设计特征金字塔实现细粒度视觉-语言对齐，显著提升了开放词汇目标检测性能，为动态环境中的目标识别提供了有效解决方案。

Abstract: Traditional object detection systems are typically constrained to predefined categories, limiting their applicability in dynamic environments. In contrast, open-vocabulary object detection (OVD) enables the identification of objects from novel classes not present in the training set. Recent advances in visual-language modeling have led to significant progress of OVD. However, prior works face challenges in either adapting the single-scale image backbone from CLIP to the detection framework or ensuring robust visual-language alignment. We propose Visual-Language Detection (VLDet), a novel framework that revamps feature pyramid for fine-grained visual-language alignment, leading to improved OVD performance. With the VL-PUB module, VLDet effectively exploits the visual-language knowledge from CLIP and adapts the backbone for object detection through feature pyramid. In addition, we introduce the SigRPN block, which incorporates a sigmoid-based anchor-text contrastive alignment loss to improve detection of novel categories. Through extensive experiments, our approach achieves 58.7 AP for novel classes on COCO2017 and 24.8 AP on LVIS, surpassing all state-of-the-art methods and achieving significant improvements of 27.6% and 6.9%, respectively. Furthermore, VLDet also demonstrates superior zero-shot performance on closed-set object detection.

</details>


### [77] [SADER: Structure-Aware Diffusion Framework with DEterministic Resampling for Multi-Temporal Remote Sensing Cloud Removal](https://arxiv.org/abs/2602.00536)
*Yifan Zhang,Qian Chen,Yi Liu,Wengen Li,Jihong Guan*

Main category: cs.CV

TL;DR: SADER是一个用于多时相遥感影像去云的结构感知扩散框架，通过多时相条件扩散网络、云感知注意力损失和确定性重采样策略，显著提升了去云效果和采样效率。


<details>
  <summary>Details</summary>
Motivation: 云污染严重降低了遥感影像的可用性，对下游地球观测任务构成根本性挑战。现有的基于扩散模型的方法存在采样效率有限、对多时相遥感场景中的结构和时间先验利用不足的问题。

Method: 提出SADER框架：1) 可扩展的多时相条件扩散网络(MTCDN)，通过时间融合和混合注意力充分捕捉多时相和多模态相关性；2) 云感知注意力损失，考虑云层厚度和亮度差异来强调云主导区域；3) 确定性重采样策略，在固定采样步骤下通过引导校正替换异常值来迭代优化样本。

Result: 在多个多时相数据集上的广泛实验表明，SADER在所有评估指标上都一致优于最先进的去云方法。

Conclusion: SADER通过结构感知的扩散框架有效解决了多时相遥感去云问题，在保持生成能力的同时提升了采样效率和对时空先验的利用，代码已公开。

Abstract: Cloud contamination severely degrades the usability of remote sensing imagery and poses a fundamental challenge for downstream Earth observation tasks. Recently, diffusion-based models have emerged as a dominant paradigm for remote sensing cloud removal due to their strong generative capability and stable optimization. However, existing diffusion-based approaches often suffer from limited sampling efficiency and insufficient exploitation of structural and temporal priors in multi-temporal remote sensing scenarios. In this work, we propose SADER, a structure-aware diffusion framework for multi-temporal remote sensing cloud removal. SADER first develops a scalable Multi-Temporal Conditional Diffusion Network (MTCDN) to fully capture multi-temporal and multimodal correlations via temporal fusion and hybrid attention. Then, a cloud-aware attention loss is introduced to emphasize cloud-dominated regions by accounting for cloud thickness and brightness discrepancies. In addition, a deterministic resampling strategy is designed for continuous diffusion models to iteratively refine samples under fixed sampling steps by replacing outliers through guided correction. Extensive experiments on multiple multi-temporal datasets demonstrate that SADER consistently outperforms state-of-the-art cloud removal methods across all evaluation metrics. The code of SADER is publicly available at https://github.com/zyfzs0/SADER.

</details>


### [78] [NPNet: A Non-Parametric Network with Adaptive Gaussian-Fourier Positional Encoding for 3D Classification and Segmentation](https://arxiv.org/abs/2602.00542)
*Mohammad Saeid,Amir Salarpour,Pedram MohajerAnsari,Mert D. Pesé*

Main category: cs.CV

TL;DR: NPNet：一种完全非参数化的3D点云分类和部件分割方法，无需学习权重，使用确定性算子构建点特征，通过自适应高斯-傅里叶位置编码适应不同尺度和采样密度


<details>
  <summary>Details</summary>
Motivation: 现有点云处理方法通常依赖学习权重，需要大量训练数据和计算资源。本文旨在开发一种完全非参数化的方法，减少对训练数据的依赖，提高在少样本场景下的性能，同时保持跨尺度和采样密度的稳定性

Method: 使用确定性算子（最远点采样、k最近邻、池化）构建点特征，核心是自适应高斯-傅里叶位置编码，其带宽和高斯-余弦混合参数根据输入几何自动选择。对于分割任务，额外加入固定频率傅里叶特征提供全局上下文

Result: 在ModelNet40/ModelNet-R、ScanObjectNN和ShapeNetPart数据集上，NPNet在非参数基线中表现出色，特别是在ModelNet40的少样本设置中效果显著。相比之前的非参数方法，NPNet在内存使用和推理时间方面也有优势

Conclusion: NPNet证明了完全非参数化方法在3D点云处理任务中的可行性，通过自适应位置编码机制有效处理不同尺度和采样密度，在少样本场景下表现优异，为点云分析提供了高效、数据高效的新途径

Abstract: We present NPNet, a fully non-parametric approach for 3D point-cloud classification and part segmentation. NPNet contains no learned weights; instead, it builds point features using deterministic operators such as farthest point sampling, k-nearest neighbors, and pooling. Our key idea is an adaptive Gaussian-Fourier positional encoding whose bandwidth and Gaussian-cosine mixing are chosen from the input geometry, helping the method remain stable across different scales and sampling densities. For segmentation, we additionally incorporate fixed-frequency Fourier features to provide global context alongside the adaptive encoding. Across ModelNet40/ModelNet-R, ScanObjectNN, and ShapeNetPart, NPNet achieves strong performance among non-parametric baselines, and it is particularly effective in few-shot settings on ModelNet40. NPNet also offers favorable memory use and inference time compared to prior non-parametric methods

</details>


### [79] [Learning to Decode Against Compositional Hallucination in Video Multimodal Large Language Models](https://arxiv.org/abs/2602.00559)
*Wenbin Xing,Quanxing Zha,Lizheng Zu,Mengran Li,Ming Li,Junchi Yan*

Main category: cs.CV

TL;DR: 论文提出了OmniVCHall基准来评估视频多模态大语言模型中的孤立和组合幻觉，并提出了TriCD对比解码框架来缓解组合幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 当前视频幻觉缓解研究主要关注孤立错误类型，而组合幻觉（涉及多个时空因素交互的错误推理）尚未得到充分探索，需要系统性评估和改进。

Method: 1) 构建OmniVCHall基准，涵盖多样视频领域，引入新的相机幻觉类型，定义细粒度分类，并设计对抗性答案选项；2) 提出TriCD对比解码框架，包含三路径校准机制、自适应扰动控制器和显著性引导增强模块，通过强化学习优化。

Result: 评估39个代表性VLLM发现，即使先进模型（如Qwen3-VL和GPT-5）也表现出显著性能下降。TriCD在两个代表性骨干网络上平均准确率提升超过10%。

Conclusion: 组合幻觉是视频多模态大语言模型的重要挑战，OmniVCHall基准为系统性评估提供了工具，TriCD框架通过对比解码有效缓解了组合幻觉问题。

Abstract: Current research on video hallucination mitigation primarily focuses on isolated error types, leaving compositional hallucinations, arising from incorrect reasoning over multiple interacting spatial and temporal factors largely underexplored. We introduce OmniVCHall, a benchmark designed to systematically evaluate both isolated and compositional hallucinations in video multimodal large language models (VLLMs). OmniVCHall spans diverse video domains, introduces a novel camera-based hallucination type, and defines a fine-grained taxonomy, together with adversarial answer options (e.g., "All are correct" and "None of the above") to prevent shortcut reasoning. The evaluations of 39 representative VLLMs reveal that even advanced models (e.g., Qwen3-VL and GPT-5) exhibit substantial performance degradation. We propose TriCD, a contrastive decoding framework with a triple-pathway calibration mechanism. An adaptive perturbation controller dynamically selects distracting operations to construct negative video variants, while a saliency-guided enhancement module adaptively reinforces grounded token-wise visual evidences. These components are optimized via reinforcement learning to encourage precise decision-making under compositional hallucination settings. Experimental results show that TriCD consistently improves performance across two representative backbones, achieving an average accuracy improvement of over 10%. The data and code can be find at https://github.com/BMRETURN/OmniVCHall.

</details>


### [80] [GLAD: Generative Language-Assisted Visual Tracking for Low-Semantic Templates](https://arxiv.org/abs/2602.00570)
*Xingyu Luo,Yidong Cai,Jie Liu,Jie Tang,Gangshan Wu,Limin Wang*

Main category: cs.CV

TL;DR: GLAD：一种基于扩散模型的生成式语言辅助跟踪模型，通过生成式多模态融合增强文本描述与模板图像的兼容性，提升低语义图像下的跟踪性能


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言跟踪方法在处理低语义图像（如模糊、低分辨率）时存在局限性，文本与视觉特征之间的差距导致直接融合效果有限，需要更好的多模态融合方法来提升跟踪性能

Method: 提出GLAD模型，利用扩散模型对文本描述和模板图像进行生成式多模态融合，增强语言与图像的兼容性，提升模板图像的语义信息，改善跨模态理解能力

Result: 在多个基准测试中达到新的最先进水平，推理速度令人印象深刻，能够有效恢复模糊和语义模糊的模板图像

Conclusion: GLAD通过生成式多模态融合显著提升了视觉语言跟踪性能，特别是在处理低语义图像时表现出色，为跨模态跟踪提供了新的有效解决方案

Abstract: Vision-language tracking has gained increasing attention in many scenarios. This task simultaneously deals with visual and linguistic information to localize objects in videos. Despite its growing utility, the development of vision-language tracking methods remains in its early stage. Current vision-language trackers usually employ Transformer architectures for interactive integration of template, search, and text features. However, persistent challenges about low-semantic images including prevalent image blurriness, low resolution and so on, may compromise model performance through degraded cross-modal understanding. To solve this problem, language assistance is usually used to deal with the obstacles posed by low-semantic images. However, due to the existing gap between current textual and visual features, direct concatenation and fusion of these features may have limited effectiveness. To address these challenges, we introduce a pioneering Generative Language-AssisteD tracking model, GLAD, which utilizes diffusion models for the generative multi-modal fusion of text description and template image to bolster compatibility between language and image and enhance template image semantic information. Our approach demonstrates notable improvements over the existing fusion paradigms. Blurry and semantically ambiguous template images can be restored to improve multi-modal features in the generative fusion paradigm. Experiments show that our method establishes a new state-of-the-art on multiple benchmarks and achieves an impressive inference speed. The code and models will be released at: https://github.com/Confetti-lxy/GLAD

</details>


### [81] [Bridging Degradation Discrimination and Generation for Universal Image Restoration](https://arxiv.org/abs/2602.00579)
*JiaKui Hu,Zhengjian Yao,Lujia Jin,Yanye Lu*

Main category: cs.CV

TL;DR: BDG提出一种结合退化判别与生成的通用图像恢复方法，通过MAS-GLCM进行细粒度退化分析，并采用三阶段扩散训练提升多任务多退化场景下的恢复能力。


<details>
  <summary>Details</summary>
Motivation: 通用图像恢复面临两大挑战：高质量图像分布采样困难，以及需要根据具体退化类型调整输出。现有方法难以同时处理多种退化类型和程度。

Method: 提出MAS-GLCM进行细粒度退化类型和程度判别；将扩散训练分为生成、桥接和恢复三个阶段，将判别信息融入恢复过程，保持纹理恢复能力的同时增强多退化处理能力。

Result: 在不改变架构的情况下，BDG在通用图像恢复和真实世界超分辨率任务中均取得显著性能提升，在保持感知质量的同时大幅提高保真度。

Conclusion: BDG通过结合退化判别与生成，有效解决了通用图像恢复中的多任务多退化挑战，为低层视觉任务提供了新的解决方案。

Abstract: Universal image restoration is a critical task in low-level vision, requiring the model to remove various degradations from low-quality images to produce clean images with rich detail. The challenges lie in sampling the distribution of high-quality images and adjusting the outputs on the basis of the degradation. This paper presents a novel approach, Bridging Degradation discrimination and Generation (BDG), which aims to address these challenges concurrently. First, we propose the Multi-Angle and multi-Scale Gray Level Co-occurrence Matrix (MAS-GLCM) and demonstrate its effectiveness in performing fine-grained discrimination of degradation types and levels. Subsequently, we divide the diffusion training process into three distinct stages: generation, bridging, and restoration. The objective is to preserve the diffusion model's capability of restoring rich textures while simultaneously integrating the discriminative information from the MAS-GLCM into the restoration process. This enhances its proficiency in addressing multi-task and multi-degraded scenarios. Without changing the architecture, BDG achieves significant performance gains in all-in-one restoration and real-world super-resolution tasks, primarily evidenced by substantial improvements in fidelity without compromising perceptual quality. The code and pretrained models are provided in https://github.com/MILab-PKU/BDG.

</details>


### [82] [MAUGen: A Unified Diffusion Approach for Multi-Identity Facial Expression and AU Label Generation](https://arxiv.org/abs/2602.00583)
*Xiangdong Li,Ye Lou,Ao Gao,Wei Zhang,Siyang Song*

Main category: cs.CV

TL;DR: MAUGen是一个基于扩散模型的多模态框架，能够通过单一文本提示生成大量逼真面部表情和对应的解剖学一致的动作单元标签（包括出现和强度），并创建了大规模合成数据集MIFA。


<details>
  <summary>Details</summary>
Motivation: 现有的大规模、人口统计学多样且具有精确动作单元（AU）出现和强度标注的面部图像数据缺乏，这已成为开发可泛化AU识别系统的基本瓶颈。

Method: MAUGen包含两个关键模块：1）多模态表示学习模块，在统一潜在空间中捕捉文本描述、面部身份、表情图像和AU激活之间的关系；2）基于扩散的图像标签生成器，将联合表示解码为跨不同身份的对齐面部图像-标签对。

Result: 提出了Multi-Identity Facial Action（MIFA）大规模多模态合成数据集，包含全面的AU标注和身份变化。实验表明MAUGen在合成逼真、人口统计学多样的面部图像和语义对齐的AU标签方面优于现有方法。

Conclusion: MAUGen框架能够有效生成大规模、多样化的面部表情数据及其精确AU标注，为解决AU识别系统的数据瓶颈问题提供了有效解决方案，并创建了有价值的合成数据集MIFA。

Abstract: The lack of large-scale, demographically diverse face images with precise Action Unit (AU) occurrence and intensity annotations has long been recognized as a fundamental bottleneck in developing generalizable AU recognition systems. In this paper, we propose MAUGen, a diffusion-based multi-modal framework that jointly generates a large collection of photorealistic facial expressions and anatomically consistent AU labels, including both occurrence and intensity, conditioned on a single descriptive text prompt. Our MAUGen involves two key modules: (1) a Multi-modal Representation Learning (MRL) module that captures the relationships among the paired textual description, facial identity, expression image, and AU activations within a unified latent space; and (2) a Diffusion-based Image label Generator (DIG) that decodes the joint representation into aligned facial image-label pairs across diverse identities. Under this framework, we introduce Multi-Identity Facial Action (MIFA), a large-scale multimodal synthetic dataset featuring comprehensive AU annotations and identity variations. Extensive experiments demonstrate that MAUGen outperforms existing methods in synthesizing photorealistic, demographically diverse facial images along with semantically aligned AU labels.

</details>


### [83] [From Pixels to Facts (Pix2Fact): Benchmarking Multi-Hop Reasoning for Fine-Grained Visual Fact Checking](https://arxiv.org/abs/2602.00593)
*Yifan Jiang,Cong Zhang,Bofei Zhang,Yifan Yang,Bingzhang Wang,Yew-Soon Ong*

Main category: cs.CV

TL;DR: Pix2Fact是一个新的视觉问答基准，专门评估专家级视觉感知和知识密集型多跳推理能力，现有最先进VLM仅达到24%准确率，远低于人类的56%。


<details>
  <summary>Details</summary>
Motivation: 现有基准分别评估视觉基础和知识推理能力，但缺乏对两者协同作用的评估。需要一个新的基准来评估需要详细视觉定位、多跳推理和外部知识整合的复杂任务。

Method: 创建包含1,000张高分辨率（4K+）图像的Pix2Fact基准，涵盖8个日常生活场景。问题由全球顶尖大学的博士与专业数据标注公司合作精心设计，每个问题都需要详细视觉定位、多跳推理和外部知识整合。

Result: 评估9个最先进的VLM（包括Gemini-3-Pro和GPT-5等专有模型），最先进模型仅达到24.0%的平均准确率，而人类表现达到56%，显示出显著差距。

Conclusion: Pix2Fact揭示了当前模型在复制人类级视觉理解方面的局限性，将作为推动下一代多模态智能体发展的关键基准，这些智能体需要结合细粒度感知和稳健的知识推理能力。

Abstract: Despite progress on general tasks, VLMs struggle with challenges demanding both detailed visual grounding and deliberate knowledge-based reasoning, a synergy not captured by existing benchmarks that evaluate these skills separately. To close this gap, we introduce Pix2Fact, a new visual question-answering benchmark designed to evaluate expert-level perception and knowledge-intensive multi-hop reasoning. Pix2Fact contains 1,000 high-resolution (4K+) images spanning 8 daily-life scenarios and situations, with questions and answers meticulously crafted by annotators holding PhDs from top global universities working in partnership with a professional data annotation firm. Each question requires detailed visual grounding, multi-hop reasoning, and the integration of external knowledge to answer. Our evaluation of 9 state-of-the-art VLMs, including proprietary models like Gemini-3-Pro and GPT-5, reveals the substantial challenge posed by Pix2Fact: the most advanced model achieves only 24.0% average accuracy, in stark contrast to human performance of 56%. This significant gap underscores the limitations of current models in replicating human-level visual comprehension. We believe Pix2Fact will serve as a critical benchmark to drive the development of next-generation multimodal agents that combine fine-grained perception with robust, knowledge-based reasoning.

</details>


### [84] [Tune-Your-Style: Intensity-tunable 3D Style Transfer with Gaussian Splatting](https://arxiv.org/abs/2602.00618)
*Yian Zhao,Rushi Ye,Ruochong Zheng,Zesen Cheng,Chaoran Feng,Jiashu Yang,Pengchong Qiao,Chang Liu,Jie Chen*

Main category: cs.CV

TL;DR: 提出Tune-Your-Style方法，实现强度可调的3D风格迁移，用户可灵活调整风格注入强度以满足个性化内容-风格平衡需求。


<details>
  <summary>Details</summary>
Motivation: 现有3D风格迁移方法采用固定输出范式，难以适应不同用户对内容-风格平衡的多样化需求，需要增强3D风格迁移的可定制性。

Method: 1) 引入高斯神经元显式建模风格强度，参数化可学习风格调节器实现强度可调的风格注入；2) 提出可调风格化引导，通过跨视图风格对齐从扩散模型获得多视图一致的风格化视图，采用两阶段优化策略通过调制全风格引导和零风格引导的平衡来提供稳定高效的引导。

Result: 实验表明该方法不仅产生视觉吸引力的结果，而且展现出3D风格迁移的灵活可定制性。

Conclusion: Tune-Your-Style方法通过强度可调的3D风格迁移范式，成功解决了现有方法在内容-风格平衡定制性方面的不足，为用户提供了灵活的风格强度控制能力。

Abstract: 3D style transfer refers to the artistic stylization of 3D assets based on reference style images. Recently, 3DGS-based stylization methods have drawn considerable attention, primarily due to their markedly enhanced training and rendering speeds. However, a vital challenge for 3D style transfer is to strike a balance between the content and the patterns and colors of the style. Although the existing methods strive to achieve relatively balanced outcomes, the fixed-output paradigm struggles to adapt to the diverse content-style balance requirements from different users. In this work, we introduce a creative intensity-tunable 3D style transfer paradigm, dubbed \textbf{Tune-Your-Style}, which allows users to flexibly adjust the style intensity injected into the scene to match their desired content-style balance, thus enhancing the customizability of 3D style transfer. To achieve this goal, we first introduce Gaussian neurons to explicitly model the style intensity and parameterize a learnable style tuner to achieve intensity-tunable style injection. To facilitate the learning of tunable stylization, we further propose the tunable stylization guidance, which obtains multi-view consistent stylized views from diffusion models through cross-view style alignment, and then employs a two-stage optimization strategy to provide stable and efficient guidance by modulating the balance between full-style guidance from the stylized views and zero-style guidance from the initial rendering. Extensive experiments demonstrate that our method not only delivers visually appealing results, but also exhibits flexible customizability for 3D style transfer. Project page is available at https://zhao-yian.github.io/TuneStyle.

</details>


### [85] [Towards Interpretable Hallucination Analysis and Mitigation in LVLMs via Contrastive Neuron Steering](https://arxiv.org/abs/2602.00621)
*Guangtao Lyu,Xinyi Cheng,Qi Liu,Chenghao Xu,Jiexi Yan,Muli Yang,Fen Fang,Cheng Deng*

Main category: cs.CV

TL;DR: 该论文通过稀疏自编码器分析LVLM内部表示，发现幻觉源于图像特定神经元的异常激活，提出对比神经元导向方法在预填充阶段增强信息性神经元、抑制扰动激活，有效减少幻觉同时保持多模态理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有缓解LVLM幻觉的方法主要关注输出级调整，对产生幻觉的内部机制探索不足。需要从表示层面深入理解幻觉的产生机制，从而开发更有效的干预方法。

Method: 1. 引入稀疏自编码器将密集视觉嵌入分解为稀疏可解释神经元；2. 识别不同神经元类型（常开神经元和图像特定神经元）；3. 提出对比神经元导向方法，通过对比干净和噪声输入识别图像特定神经元，选择性增强信息性神经元并抑制扰动激活。

Result: 发现幻觉通常源于图像特定神经元的破坏或虚假激活，而常开神经元保持稳定。CNS方法在幻觉聚焦和通用多模态基准测试中一致减少幻觉，同时保持整体多模态理解能力，且与现有解码阶段方法完全兼容。

Conclusion: 通过表示层面分析揭示了LVLM幻觉的内部机制，提出的CNS方法在预填充阶段有效干预神经元激活，增强视觉基础并减少幻觉，为理解和管理LVLM幻觉提供了新视角。

Abstract: LVLMs achieve remarkable multimodal understanding and generation but remain susceptible to hallucinations. Existing mitigation methods predominantly focus on output-level adjustments, leaving the internal mechanisms that give rise to these hallucinations largely unexplored. To gain a deeper understanding, we adopt a representation-level perspective by introducing sparse autoencoders (SAEs) to decompose dense visual embeddings into sparse, interpretable neurons. Through neuron-level analysis, we identify distinct neuron types, including always-on neurons and image-specific neurons. Our findings reveal that hallucinations often result from disruptions or spurious activations of image-specific neurons, while always-on neurons remain largely stable. Moreover, selectively enhancing or suppressing image-specific neurons enables controllable intervention in LVLM outputs, improving visual grounding and reducing hallucinations. Building on these insights, we propose Contrastive Neuron Steering (CNS), which identifies image-specific neurons via contrastive analysis between clean and noisy inputs. CNS selectively amplifies informative neurons while suppressing perturbation-induced activations, producing more robust and semantically grounded visual representations. This not only enhances visual understanding but also effectively mitigates hallucinations. By operating at the prefilling stage, CNS is fully compatible with existing decoding-stage methods. Extensive experiments on both hallucination-focused and general multimodal benchmarks demonstrate that CNS consistently reduces hallucinations while preserving overall multimodal understanding.

</details>


### [86] [FaceSnap: Enhanced ID-fidelity Network for Tuning-free Portrait Customization](https://arxiv.org/abs/2602.00627)
*Benxiang Zhai,Yifang Xu,Guofeng Zhang,Yang Li,Sidan Du*

Main category: cs.CV

TL;DR: FaceSnap：基于Stable Diffusion的单参考图像个性化肖像生成方法，无需微调，单次推理即可生成高保真面部细节


<details>
  <summary>Details</summary>
Motivation: 现有个性化肖像生成方法要么需要耗时微调且泛化性差，要么无法实现面部细节的高保真度，需要一种更高效、保真度更高的解决方案

Method: 基于Stable Diffusion设计Facial Attribute Mixer提取多层次融合特征，引入Landmark Predictor保持不同姿态下的身份一致性，使用ID-preserving模块注入UNet

Result: 实验结果表明，FaceSnap在个性化肖像生成方面表现优异，超越了该领域的其他最先进方法

Conclusion: FaceSnap是一种即插即用的高效方法，仅需单张参考图像即可在单次推理中生成高度一致且保真度高的个性化肖像，可轻松扩展到不同的SD模型

Abstract: Benefiting from the significant advancements in text-to-image diffusion models, research in personalized image generation, particularly customized portrait generation, has also made great strides recently. However, existing methods either require time-consuming fine-tuning and lack generalizability or fail to achieve high fidelity in facial details. To address these issues, we propose FaceSnap, a novel method based on Stable Diffusion (SD) that requires only a single reference image and produces extremely consistent results in a single inference stage. This method is plug-and-play and can be easily extended to different SD models. Specifically, we design a new Facial Attribute Mixer that can extract comprehensive fused information from both low-level specific features and high-level abstract features, providing better guidance for image generation. We also introduce a Landmark Predictor that maintains reference identity across landmarks with different poses, providing diverse yet detailed spatial control conditions for image generation. Then we use an ID-preserving module to inject these into the UNet. Experimental results demonstrate that our approach performs remarkably in personalized and customized portrait generation, surpassing other state-of-the-art methods in this domain.

</details>


### [87] [S$^3$POT: Contrast-Driven Face Occlusion Segmentation via Self-Supervised Prompt Learning](https://arxiv.org/abs/2602.00635)
*Lingsong Wang,Mancheng Meng,Ziyan Wu,Terrence Chen,Fan Yang,Dinggang Shen*

Main category: cs.CV

TL;DR: S³POT：一种结合人脸生成与自监督空间提示的对比驱动框架，用于解决人脸解析中遮挡分割问题，无需遮挡标注数据。


<details>
  <summary>Details</summary>
Motivation: 现有的人脸解析方法通常将遮挡误分类为人脸组件。遮挡是高层概念，不属于具体对象类别，构建覆盖所有遮挡类别的真实人脸数据集几乎不可能，且精确掩码标注成本高昂。

Method: 提出S³POT框架，包含三个模块：参考生成（RF）利用解析掩码的结构指导生成参考图像；特征增强（FE）通过原始图像与参考图像的token对比获得初始提示，并通过交叉注意力修改图像特征；提示选择（PS）基于增强特征构建正负提示集，通过自注意力网络筛选后输入掩码解码器。整个网络在三个新颖互补的目标函数指导下学习，无需遮挡真实掩码。

Result: 在专门收集的数据集上进行广泛实验，证明了S³POT的优越性能以及每个模块的有效性。

Conclusion: S³POT通过结合现代人脸生成器的遮挡区域重建能力和基础分割模型的精确掩码提取能力，成功实现了无需遮挡标注的遮挡分割，为人脸解析中的遮挡问题提供了有效解决方案。

Abstract: Existing face parsing methods usually misclassify occlusions as facial components. This is because occlusion is a high-level concept, it does not refer to a concrete category of object. Thus, constructing a real-world face dataset covering all categories of occlusion object is almost impossible and accurate mask annotation is labor-intensive. To deal with the problems, we present S$^3$POT, a contrast-driven framework synergizing face generation with self-supervised spatial prompting, to achieve occlusion segmentation. The framework is inspired by the insights: 1) Modern face generators' ability to realistically reconstruct occluded regions, creating an image that preserve facial geometry while eliminating occlusion, and 2) Foundation segmentation models' (e.g., SAM) capacity to extract precise mask when provided with appropriate prompts. In particular, S$^3$POT consists of three modules: Reference Generation (RF), Feature enhancement (FE), and Prompt Selection (PS). First, a reference image is produced by RF using structural guidance from parsed mask. Second, FE performs contrast of tokens between raw and reference images to obtain an initial prompt, then modifies image features with the prompt by cross-attention. Third, based on the enhanced features, PS constructs a set of positive and negative prompts and screens them with a self-attention network for a mask decoder. The network is learned under the guidance of three novel and complementary objective functions without occlusion ground truth mask involved. Extensive experiments on a dedicatedly collected dataset demonstrate S$^3$POT's superior performance and the effectiveness of each module.

</details>


### [88] [VIZOR: Viewpoint-Invariant Zero-Shot Scene Graph Generation for 3D Scene Reasoning](https://arxiv.org/abs/2602.00637)
*Vivek Madhavaram,Vartika Sengar,Arkadipta De,Charu Sharma*

Main category: cs.CV

TL;DR: VIZOR是一个无需训练、端到端的框架，直接从原始3D场景构建密集、视角不变的3D场景图，使用基于物体正面方向的相对空间关系，实现零样本开放词汇关系推理。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要多输入（2D图像、深度图、物体标签等）且依赖特定参考视角，导致泛化能力差，空间关系（如左右）在不同视角下不一致。需要解决视角依赖和训练数据需求的问题。

Method: 提出VIZOR框架：1) 直接从原始3D场景构建场景图；2) 使用基于每个物体正面方向的相对空间关系定义，确保视角不变性；3) 无需训练数据，实现开放词汇空间和邻近关系推理。

Result: 在场景图生成和下游任务（如查询式物体定位）上优于现有方法，在Replica和Nr3D数据集上分别实现22%和4.81%的零样本定位准确率提升。

Conclusion: VIZOR通过视角不变的空间关系定义和零样本开放词汇推理，解决了现有3D场景图生成方法的泛化问题和视角依赖问题，为3D场景理解提供了更鲁棒的解决方案。

Abstract: Scene understanding and reasoning has been a fundamental problem in 3D computer vision, requiring models to identify objects, their properties, and spatial or comparative relationships among the objects. Existing approaches enable this by creating scene graphs using multiple inputs such as 2D images, depth maps, object labels, and annotated relationships from specific reference view. However, these methods often struggle with generalization and produce inaccurate spatial relationships like "left/right", which become inconsistent across different viewpoints. To address these limitations, we propose Viewpoint-Invariant Zero-shot scene graph generation for 3D scene Reasoning (VIZOR). VIZOR is a training-free, end-to-end framework that constructs dense, viewpoint-invariant 3D scene graphs directly from raw 3D scenes. The generated scene graph is unambiguous, as spatial relationships are defined relative to each object's front-facing direction, making them consistent regardless of the reference view. Furthermore, it infers open-vocabulary relationships that describe spatial and proximity relationships among scene objects without requiring annotated training data. We conduct extensive quantitative and qualitative evaluations to assess the effectiveness of VIZOR in scene graph generation and downstream tasks, such as query-based object grounding. VIZOR outperforms state-of-the-art methods, showing clear improvements in scene graph generation and achieving 22% and 4.81% gains in zero-shot grounding accuracy on the Replica and Nr3D datasets, respectively.

</details>


### [89] [Diff-PC: Identity-preserving and 3D-aware Controllable Diffusion for Zero-shot Portrait Customization](https://arxiv.org/abs/2602.00639)
*Yifang Xu,Benxiang Zhai,Chenyu Zhang,Ming Li,Yang Li,Sidan Du*

Main category: cs.CV

TL;DR: Diff-PC：基于扩散模型的零样本肖像定制框架，通过3D面部先验、ID编码器和ID控制器实现高身份保真度和精确面部控制


<details>
  <summary>Details</summary>
Motivation: 现有肖像定制方法缺乏精确的身份保真度和面部控制能力，需要解决这些问题以实现高质量的个性化肖像生成

Method: 使用3D人脸预测器重建包含参考ID、目标表情和姿态的3D面部先验；设计ID-Encoder融合局部和全局面部特征；开发ID-Ctrl用3D面部指导ID特征对齐；引入ID-Injector增强ID保真度和面部可控性；在自收集的ID中心数据集上训练

Result: 在身份保真度、面部控制和文本-图像一致性方面超越现有最先进方法，兼容多风格基础模型，生成具有高ID保真度、指定面部属性和多样化背景的现实肖像

Conclusion: Diff-PC成功解决了肖像定制中的身份保真度和面部控制问题，为零样本肖像定制提供了有效的解决方案，具有实际应用价值

Abstract: Portrait customization (PC) has recently garnered significant attention due to its potential applications. However, existing PC methods lack precise identity (ID) preservation and face control. To address these tissues, we propose Diff-PC, a diffusion-based framework for zero-shot PC, which generates realistic portraits with high ID fidelity, specified facial attributes, and diverse backgrounds. Specifically, our approach employs the 3D face predictor to reconstruct the 3D-aware facial priors encompassing the reference ID, target expressions, and poses. To capture fine-grained face details, we design ID-Encoder that fuses local and global facial features. Subsequently, we devise ID-Ctrl using the 3D face to guide the alignment of ID features. We further introduce ID-Injector to enhance ID fidelity and facial controllability. Finally, training on our collected ID-centric dataset improves face similarity and text-to-image (T2I) alignment. Extensive experiments demonstrate that Diff-PC surpasses state-of-the-art methods in ID preservation, facial control, and T2I consistency. Furthermore, our method is compatible with multi-style foundation models.

</details>


### [90] [A Hybrid Mamba-SAM Architecture for Efficient 3D Medical Image Segmentation](https://arxiv.org/abs/2602.00650)
*Mohammadreza Gholipour Shahraki,Mehdi Rezaeian,Mohammad Ghasemzadeh*

Main category: cs.CV

TL;DR: Mamba-SAM：将冻结的SAM编码器与Mamba状态空间模型结合，用于3D医学图像分割的混合架构，通过参数高效适配策略解决领域偏移和计算成本问题。


<details>
  <summary>Details</summary>
Motivation: 基础模型如SAM在医学影像分割中存在领域偏移、固有的2D设计以及微调计算成本高的问题，需要高效解决方案。

Method: 提出Mamba-SAM混合架构：1）双分支架构融合冻结SAM编码器特征与可训练VMamba编码器的领域特定表示；2）基于适配器的方法在冻结SAM ViT编码器中注入轻量级3D感知TPMamba模块。引入多频门控卷积增强特征表示。

Result: 在ACDC心脏MRI数据集上，双分支Mamba-SAM-Base模型达到平均Dice分数0.906，与UNet++相当（0.907），在心肌（0.910）和左心室（0.971）分割上优于所有基线。基于适配器的TP MFGC变体提供优越推理速度（4.77 FPS）和良好精度（0.880 Dice）。

Conclusion: 将基础模型与高效的SSM架构混合为3D医学图像分割提供了实用有效的解决方案，在保持性能的同时显著提升效率。

Abstract: Accurate segmentation of 3D medical images such as MRI and CT is essential for clinical diagnosis and treatment planning. Foundation models like the Segment Anything Model (SAM) provide powerful general-purpose representations but struggle in medical imaging due to domain shift, their inherently 2D design, and the high computational cost of fine-tuning. To address these challenges, we propose Mamba-SAM, a novel and efficient hybrid architecture that combines a frozen SAM encoder with the linear-time efficiency and long-range modeling capabilities of Mamba-based State Space Models (SSMs). We investigate two parameter-efficient adaptation strategies. The first is a dual-branch architecture that explicitly fuses general features from a frozen SAM encoder with domain-specific representations learned by a trainable VMamba encoder using cross-attention. The second is an adapter-based approach that injects lightweight, 3D-aware Tri-Plane Mamba (TPMamba) modules into the frozen SAM ViT encoder to implicitly model volumetric context. Within this framework, we introduce Multi-Frequency Gated Convolution (MFGC), which enhances feature representation by jointly analyzing spatial and frequency-domain information via 3D discrete cosine transforms and adaptive gating. Extensive experiments on the ACDC cardiac MRI dataset demonstrate the effectiveness of the proposed methods. The dual-branch Mamba-SAM-Base model achieves a mean Dice score of 0.906, comparable to UNet++ (0.907), while outperforming all baselines on Myocardium (0.910) and Left Ventricle (0.971) segmentation. The adapter-based TP MFGC variant offers superior inference speed (4.77 FPS) with strong accuracy (0.880 Dice). These results show that hybridizing foundation models with efficient SSM-based architectures provides a practical and effective solution for 3D medical image segmentation.

</details>


### [91] [Non-Contrastive Vision-Language Learning with Predictive Embedding Alignment](https://arxiv.org/abs/2602.00653)
*Lukas Kuhn,Giuseppe Serra,Florian Buettner*

Main category: cs.CV

TL;DR: NOVA提出了一种非对比视觉语言对齐框架，通过联合嵌入预测和分布正则化来简化多模态表示学习，无需负采样、动量编码器或停止梯度，在零样本胸部X光分类中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前主流的对比学习方法（如CLIP）需要大批量、精心设计的负采样和大量超参数调优，训练过程复杂且不稳定。作者希望开发一种更简单、更稳定的非对比视觉语言对齐方法。

Method: NOVA框架通过预测增强图像视图的文本嵌入来对齐视觉表示到冻结的文本编码器，同时使用Sketched Isotropic Gaussian Regularization (SIGReg)强制各向同性高斯结构，消除了负采样、动量编码器和停止梯度的需求。

Result: 在三个基准数据集上的零样本胸部X光分类任务中，NOVA优于多个标准基线方法，同时展现出更一致的训练运行表现，训练目标仅需一个超参数。

Conclusion: 非对比视觉语言预训练为对比方法提供了更简单、更稳定、更有效的替代方案，特别是在医学影像领域具有应用潜力。

Abstract: Vision-language models have transformed multimodal representation learning, yet dominant contrastive approaches like CLIP require large batch sizes, careful negative sampling, and extensive hyperparameter tuning. We introduce NOVA, a NOn-contrastive Vision-language Alignment framework based on joint embedding prediction with distributional regularization. NOVA aligns visual representations to a frozen, domain-specific text encoder by predicting text embeddings from augmented image views, while enforcing an isotropic Gaussian structure via Sketched Isotropic Gaussian Regularization (SIGReg). This eliminates the need for negative sampling, momentum encoders, or stop-gradients, reducing the training objective to a single hyperparameter. We evaluate NOVA on zeroshot chest X-ray classification using ClinicalBERT as the text encoder and Vision Transformers trained from scratch on MIMIC-CXR. On zero-shot classification across three benchmark datasets, NOVA outperforms multiple standard baselines while exhibiting substantially more consistent training runs. Our results demonstrate that non-contrastive vision-language pretraining offers a simpler, more stable, and more effective alternative to contrastive methods.

</details>


### [92] [Schrödinger-Inspired Time-Evolution for 4D Deformation Forecasting](https://arxiv.org/abs/2602.00661)
*Ahsan Raza Siyal,Markus Haltmeier,Ruth Steiger,Elke Ruth Gizewski,Astrid Ellen Grams*

Main category: cs.CV

TL;DR: 提出基于薛定谔方程启发的物理引导神经网络架构，用于4D（3D+时间）时空预测，通过可微分薛定谔时间步进器演化复值波函数，实现稳定、可解释的长期预测。


<details>
  <summary>Details</summary>
Motivation: 解决复杂三维现象时空预测中传统无约束神经网络模型存在的长期预测漂移、误差累积问题，同时缺乏物理可解释性，特别是在医学成像等需要保持解剖保真度的应用中。

Method: 提出物理引导的神经网络架构，从观测的体序列中学习体素级振幅、相位和势场，定义复值波函数ψ=Ae^{iφ}，通过可微分的展开式薛定谔时间步进器进行时间演化，将物理先验直接集成到学习过程中。

Result: 在模拟真实形状变形和拓扑变化的合成基准测试中，展示了准确稳定的未来4D状态预测，包括体强度和变形场，实现了长期预测的稳定性、可解释的潜在表示以及与变形合成的自然兼容性。

Conclusion: 这是首个将薛定谔型演化算子集成到端到端4D神经预测框架中的方法，为可解释、稳定且解剖一致的时空预测提供了原则性途径，结合了深度网络的表达能力和基于物理建模的鲁棒性。

Abstract: Spatiotemporal forecasting of complex three-dimensional phenomena (4D: 3D + time) is fundamental to applications in medical imaging, fluid and material dynamics, and geophysics. In contrast to unconstrained neural forecasting models, we propose a Schrödinger-inspired, physics-guided neural architecture that embeds an explicit time-evolution operator within a deep convolutional framework for 4D prediction. From observed volumetric sequences, the model learns voxelwise amplitude, phase, and potential fields that define a complex-valued wavefunction $ψ= A e^{iφ}$, which is evolved forward in time using a differentiable, unrolled Schrödinger time stepper. This physics-guided formulation yields several key advantages: (i) temporal stability arising from the structured evolution operator, which mitigates drift and error accumulation in long-horizon forecasting; (ii) an interpretable latent representation, where phase encodes transport dynamics, amplitude captures structural intensity, and the learned potential governs spatiotemporal interactions; and (iii) natural compatibility with deformation-based synthesis, which is critical for preserving anatomical fidelity in medical imaging applications. By integrating physical priors directly into the learning process, the proposed approach combines the expressivity of deep networks with the robustness and interpretability of physics-based modeling. We demonstrate accurate and stable prediction of future 4D states, including volumetric intensities and deformation fields, on synthetic benchmarks that emulate realistic shape deformations and topological changes. To our knowledge, this is the first end-to-end 4D neural forecasting framework to incorporate a Schrödinger-type evolution operator, offering a principled pathway toward interpretable, stable, and anatomically consistent spatiotemporal prediction.

</details>


### [93] [Improving Neuropathological Reconstruction Fidelity via AI Slice Imputation](https://arxiv.org/abs/2602.00669)
*Marina Crespo Aguirre,Jonathan Williams-Ramirez,Dina Zemlyanker,Xiaoling Hu,Lucas J. Deden-Binder,Rogeny Herisse,Mark Montine,Theresa R. Connors,Christopher Mount,Christine L. MacDonald,C. Dirk Keene,Caitlin S. Latimer,Derek H. Oakley,Bradley T. Hyman,Ana Lawry Aguila,Juan Eugenio Iglesias*

Main category: cs.CV

TL;DR: 提出一种计算高效的超分辨率方法，从各向异性的3D解剖照片重建中生成解剖一致的各向同性体积，提高神经病理学分析的精度


<details>
  <summary>Details</summary>
Motivation: 现有从2D解剖照片重建3D脑体积的方法有时会产生粗糙、过度平滑的重建结果，特别是在高各向异性（厚切片）情况下，需要提高重建的分辨率和解剖保真度

Method: 引入计算高效的超分辨率步骤，通过插值切片从各向异性的3D重建生成解剖一致的各向同性体积，使用领域随机化的合成数据进行训练，确保方法对不同解剖协议和大切片厚度的鲁棒性

Result: 插值后的体积改善了自动分割效果，获得了更高的Dice分数（特别是在皮质和白质区域），在表面重建和图谱配准任务验证中显示出更准确的皮质表面和MRI配准

Conclusion: 该方法通过增强基于照片重建的分辨率和解剖保真度，加强了神经病理学和神经影像学之间的联系，代码已公开可用

Abstract: Neuropathological analyses benefit from spatially precise volumetric reconstructions that enhance anatomical delineation and improve morphometric accuracy. Our prior work has shown the feasibility of reconstructing 3D brain volumes from 2D dissection photographs. However these outputs sometimes exhibit coarse, overly smooth reconstructions of structures, especially under high anisotropy (i.e., reconstructions from thick slabs). Here, we introduce a computationally efficient super-resolution step that imputes slices to generate anatomically consistent isotropic volumes from anisotropic 3D reconstructions of dissection photographs. By training on domain-randomized synthetic data, we ensure that our method generalizes across dissection protocols and remains robust to large slab thicknesses. The imputed volumes yield improved automated segmentations, achieving higher Dice scores, particularly in cortical and white matter regions. Validation on surface reconstruction and atlas registration tasks demonstrates more accurate cortical surfaces and MRI registration. By enhancing the resolution and anatomical fidelity of photograph-based reconstructions, our approach strengthens the bridge between neuropathology and neuroimaging. Our method is publicly available at https://surfer.nmr.mgh.harvard.edu/fswiki/mri_3d_photo_recon

</details>


### [94] [HPC: Hierarchical Point-based Latent Representation for Streaming Dynamic Gaussian Splatting Compression](https://arxiv.org/abs/2602.00671)
*Yangzhi Ma,Bojun Liu,Wenting Liao,Dong Liu,Zhu Li,Li Li*

Main category: cs.CV

TL;DR: HPC提出了一种用于流式动态高斯泼溅压缩的分层点基潜在表示框架，通过避免未占用空间的参数冗余和利用局部相关性，在保持高质量重建的同时显著减少存储需求。


<details>
  <summary>Details</summary>
Motivation: 现有流式动态高斯泼溅压缩方法存在参数冗余或紧凑性不足的问题：结构化网格基方法会建模未占用空间导致冗余，非结构化点基方法则无法充分利用局部相关性。需要一种既能避免冗余又能保持紧凑性的压缩方案。

Method: HPC采用分层点基潜在表示，以每个高斯为基础避免未占用空间冗余；通过定制聚合方案实现高紧凑性和低空间冗余；首次探索通过挖掘和利用参数间帧相关性来压缩神经网络，形成端到端压缩框架。

Result: 实验评估表明HPC显著优于现有方法，在保持高重建保真度的同时，相比基线实现了67%的存储减少。

Conclusion: HPC通过分层点基潜在表示和神经网络参数压缩，有效解决了动态高斯泼溅流式传输中的存储效率问题，为高质量自由视点视频的紧凑表示提供了新方案。

Abstract: While dynamic Gaussian Splatting has driven significant advances in free-viewpoint video, maintaining its rendering quality with a small memory footprint for efficient streaming transmission still presents an ongoing challenge. Existing streaming dynamic Gaussian Splatting compression methods typically leverage a latent representation to drive the neural network for predicting Gaussian residuals between frames. Their core latent representations can be categorized into structured grid-based and unstructured point-based paradigms. However, the former incurs significant parameter redundancy by inevitably modeling unoccupied space, while the latter suffers from limited compactness as it fails to exploit local correlations. To relieve these limitations, we propose HPC, a novel streaming dynamic Gaussian Splatting compression framework. It employs a hierarchical point-based latent representation that operates on a per-Gaussian basis to avoid parameter redundancy in unoccupied space. Guided by a tailored aggregation scheme, these latent points achieve high compactness with low spatial redundancy. To improve compression efficiency, we further undertake the first investigation to compress neural networks for streaming dynamic Gaussian Splatting through mining and exploiting the inter-frame correlation of parameters. Combined with latent compression, this forms a fully end-to-end compression framework. Comprehensive experimental evaluations demonstrate that HPC substantially outperforms state-of-the-art methods. It achieves a storage reduction of 67% against its baseline while maintaining high reconstruction fidelity.

</details>


### [95] [Video Understanding: Through A Temporal Lens](https://arxiv.org/abs/2602.00683)
*Thong Thanh Nguyen*

Main category: cs.CV

TL;DR: 该论文提出五种方法改进视频理解中的时序建模：自动标注框架、循环适配器微调、状态空间层长视频建模、细粒度运动-时刻对比学习框架，以及针对大视觉语言模型的时序导向优化方案。


<details>
  <summary>Details</summary>
Motivation: 现有视频理解方法在利用视频元素间的时序关系方面存在局限，需要更有效的时序建模方法来提升对视频动态内容的理解和推理能力。

Method: 1) 基于大视觉语言模型的自动标注框架，采用抗噪对比学习目标和减性角度边界；2) 使用"循环适配器"的参数高效微调策略；3) 集成状态空间层进行长视频建模，并引入两个新的长时基准；4) 细粒度运动-时刻关系对比学习框架；5) 针对大视觉语言模型的时序导向优化方案。

Result: 研究证明显式的时序建模能显著提升模型对视频动态内容的表示和推理能力，特别是在低数据场景和长视频理解方面表现优异。

Conclusion: 通过五种创新方法系统性地解决了视频理解中的时序建模问题，为提升视频理解能力提供了全面解决方案，并识别出视觉-语言接口是时序推理的关键瓶颈。

Abstract: This thesis explores the central question of how to leverage temporal relations among video elements to advance video understanding. Addressing the limitations of existing methods, the work presents a five-fold contribution: (1) an automatic annotation framework that utilizes large vision-language models and a noise-robust contrastive learning objective with a subtractive angular margin; (2) a parameter-efficient fine-tuning strategy using "recurrent adapters" to capture temporal dynamics in low-data regimes; (3) the integration of State Space Layers (SSL) for efficient long-form video modeling, supported by the introduction of two new long-term benchmarks for egocentric and feature-length content; (4) a novel contrastive learning framework designed to explicitly model fine-grained relations between motions and video moments; and (5) a comprehensive empirical study on Large Vision-Language Models (LVLMs) that identifies the visual-language interface as a bottleneck for temporal reasoning, leading to a new "temporal-oriented recipe" for upscaled video understanding. Collectively, these contributions demonstrate that explicit temporal modeling significantly enhances a model's ability to represent and reason about the fluid nature of video content.

</details>


### [96] [V2X-DSC: Multi-Agent Collaborative Perception with Distributed Source Coding Guided Communication](https://arxiv.org/abs/2602.00687)
*Yuankun Zeng,Shaohui Li,Zhi Li,Shulan Ruan,Yu Liu,You He*

Main category: cs.CV

TL;DR: V2X-DSC：基于分布式信源编码的带宽受限协同感知框架，利用条件编解码器压缩BEV特征，接收端以本地特征为边信息进行条件重建，实现KB级通信下的最优精度-带宽权衡。


<details>
  <summary>Details</summary>
Motivation: 协同感知通过融合多智能体观测提升3D理解能力，但中间特征共享面临严格带宽约束，密集BEV特征会饱和V2X链路。观察到协作者观察同一物理世界，其特征高度相关，接收端只需获取超出本地上下文的创新信息。

Method: 从分布式信源编码角度重新审视该问题，提出V2X-DSC框架，包含条件编解码器（DCC）。发送端将BEV特征压缩为紧凑码字，接收端以本地特征为边信息进行条件重建，将比特分配给互补线索而非冗余内容。这种条件结构正则化学习，鼓励增量表示。

Result: 在DAIR-V2X、OPV2V和V2X-Real数据集上的实验表明，在KB级通信约束下实现了最先进的精度-带宽权衡，并可作为即插即用的通信层泛化到多种融合骨干网络中。

Conclusion: V2X-DSC通过条件编解码有效解决了协同感知中的带宽约束问题，利用特征相关性实现高效压缩，为V2X通信提供了通用的高效特征融合方案。

Abstract: Collaborative perception improves 3D understanding by fusing multi-agent observations, yet intermediate-feature sharing faces strict bandwidth constraints as dense BEV features saturate V2X links. We observe that collaborators view the same physical world, making their features strongly correlated; thus receivers only need innovation beyond their local context. Revisiting this from a distributed source coding perspective, we propose V2X-DSC, a framework with a Conditional Codec (DCC) for bandwidth-constrained fusion. The sender compresses BEV features into compact codes, while the receiver performs conditional reconstruction using its local features as side information, allocating bits to complementary cues rather than redundant content. This conditional structure regularizes learning, encouraging incremental representation and yielding lower-noise features. Experiments on DAIR-V2X, OPV2V, and V2X-Real demonstrate state-of-the-art accuracy-bandwidth trade-offs under KB-level communication, and generalizes as a plug-and-play communication layer across multiple fusion backbones.

</details>


### [97] [JoyAvatar: Unlocking Highly Expressive Avatars via Harmonized Text-Audio Conditioning](https://arxiv.org/abs/2602.00702)
*Ruikui Wang,Jinheng Feng,Lang Tian,Huaishao Luo,Chaochao Li,Liangbo Zhou,Huan Zhang,Youzheng Wu,Xiaodong He*

Main category: cs.CV

TL;DR: JoyAvatar是一个能够生成长时间虚拟角色视频的框架，通过双教师增强训练算法和多模态条件动态调制技术，解决了现有方法在复杂文本指令（如全身运动、相机轨迹、背景转换）对齐方面的限制。


<details>
  <summary>Details</summary>
Motivation: 现有视频虚拟角色模型在说话、公开演讲和唱歌等场景中表现出色，但在复杂文本指令对齐方面存在局限，特别是涉及全身运动、动态相机轨迹、背景转换或人机交互等元素时。

Method: 1. 双教师增强训练算法：从基础模型转移固有的文本可控性，同时学习音频-视觉同步。2. 多模态条件动态调制：在训练过程中基于不同的去噪时间步动态调节音频和文本等多模态条件的强度，以减轻异质条件信号之间的冲突。

Result: JoyAvatar在GSB评估中超越了Omnihuman-1.5和KlingAvatar 2.0等最先进模型，能够生成自然、时间连贯的全身运动和动态相机移动，同时保持准确的唇形同步和身份一致性。

Conclusion: JoyAvatar通过创新的训练算法和条件调制技术，显著扩展了虚拟角色模型的能力，支持复杂应用如多人对话和非人类角色扮演，突破了现有方法在文本指令对齐方面的限制。

Abstract: Existing video avatar models have demonstrated impressive capabilities in scenarios such as talking, public speaking, and singing. However, the majority of these methods exhibit limited alignment with respect to text instructions, particularly when the prompts involve complex elements including large full-body movement, dynamic camera trajectory, background transitions, or human-object interactions. To break out this limitation, we present JoyAvatar, a framework capable of generating long duration avatar videos, featuring two key technical innovations. Firstly, we introduce a twin-teacher enhanced training algorithm that enables the model to transfer inherent text-controllability from the foundation model while simultaneously learning audio-visual synchronization. Secondly, during training, we dynamically modulate the strength of multi-modal conditions (e.g., audio and text) based on the distinct denoising timestep, aiming to mitigate conflicts between the heterogeneous conditioning signals. These two key designs serve to substantially expand the avatar model's capacity to generate natural, temporally coherent full-body motions and dynamic camera movements as well as preserve the basic avatar capabilities, such as accurate lip-sync and identity consistency. GSB evaluation results demonstrate that our JoyAvatar model outperforms the state-of-the-art models such as Omnihuman-1.5 and KlingAvatar 2.0. Moreover, our approach enables complex applications including multi-person dialogues and non-human subjects role-playing. Some video samples are provided on https://joyavatar.github.io/.

</details>


### [98] [StomataSeg: Semi-Supervised Instance Segmentation for Sorghum Stomatal Components](https://arxiv.org/abs/2602.00703)
*Zhongtian Huang,Zhi Chen,Zi Huang,Xin Yu,Daniel Smith,Chaitanya Purushothama,Erik Van Oosterom,Alex Wu,William Salter,Yan Li,Scott Chapman*

Main category: cs.CV

TL;DR: 提出一种半监督实例分割框架，用于高粱气孔组件的分析，通过补丁预处理和伪标签策略显著提升微小结构分割性能


<details>
  <summary>Details</summary>
Motivation: 高粱作为耐旱作物对气候适应性农业至关重要，但气孔自动分析困难，因为气孔微小（<40μm）且形状多样，现有方法面临嵌套小结构和标注瓶颈的挑战

Method: 收集并标注11,060个人工标注的高粱叶片图像补丁，涵盖多个基因型和叶表面的三个气孔组件（气孔孔、保卫细胞和复合区域）；将高分辨率显微图像分割为重叠小补丁以改善微小结构检测；采用伪标签策略处理未标注图像，生成额外56,428个伪标注补丁

Result: 语义分割模型的mIoU从65.93%提升至70.35%，实例分割模型的AP从28.30%提升至46.10%，证明补丁预处理结合半监督学习能显著改善精细气孔结构分割

Conclusion: 该框架支持可扩展的气孔性状提取，促进AI驱动表型分析在作物科学中的广泛应用

Abstract: Sorghum is a globally important cereal grown widely in water-limited and stress-prone regions. Its strong drought tolerance makes it a priority crop for climate-resilient agriculture. Improving water-use efficiency in sorghum requires precise characterisation of stomatal traits, as stomata control of gas exchange, transpiration and photosynthesis have a major influence on crop performance. Automated analysis of sorghum stomata is difficult because the stomata are small (often less than 40 $μ$m in length in grasses such as sorghum) and vary in shape across genotypes and leaf surfaces. Automated segmentation contributes to high-throughput stomatal phenotyping, yet current methods still face challenges related to nested small structures and annotation bottlenecks. In this paper, we propose a semi-supervised instance segmentation framework tailored for analysis of sorghum stomatal components. We collect and annotate a sorghum leaf imagery dataset containing 11,060 human-annotated patches, covering the three stomatal components (pore, guard cell and complex area) across multiple genotypes and leaf surfaces. To improve the detection of tiny structures, we split high-resolution microscopy images into overlapping small patches. We then apply a pseudo-labelling strategy to unannotated images, producing an additional 56,428 pseudo-labelled patches. Benchmarking across semantic and instance segmentation models shows substantial performance gains: for semantic models the top mIoU increases from 65.93% to 70.35%, whereas for instance models the top AP rises from 28.30% to 46.10%. These results demonstrate that combining patch-based preprocessing with semi-supervised learning significantly improves the segmentation of fine stomatal structures. The proposed framework supports scalable extraction of stomatal traits and facilitates broader adoption of AI-driven phenotyping in crop science.

</details>


### [99] [Supervised makeup transfer with a curated dataset: Decoupling identity and makeup features for enhanced transformation](https://arxiv.org/abs/2602.00729)
*Qihe Pan,Yiming Wu,Xing Zhao,Liang Xie,Guodao Sun,Ronghua Liang*

Main category: cs.CV

TL;DR: 提出一种基于扩散模型的化妆迁移方法，通过构建高质量数据集、解耦身份与化妆特征、文本引导控制，实现高保真、可控制的化妆迁移。


<details>
  <summary>Details</summary>
Motivation: 现有化妆迁移方法存在数据集有限、身份与化妆特征解耦不充分、可控性弱等问题，需要更稳定、高质量的解决方案。

Method: 1. 采用训练-生成-过滤-重训练策略构建高质量数据集；2. 设计基于扩散模型的框架解耦身份与化妆特征；3. 提出文本引导机制实现细粒度区域控制。

Result: 在基准测试和实际场景中，该方法在保真度、身份保持和灵活性方面均有提升，支持通过自然语言提示修改眼妆、唇妆或面部妆容。

Conclusion: 该方法通过高质量数据集、特征解耦和文本控制，为化妆迁移提供了更稳定、可控的解决方案，优于现有方法。

Abstract: Diffusion models have recently shown strong progress in generative tasks, offering a more stable alternative to GAN-based approaches for makeup transfer. Existing methods often suffer from limited datasets, poor disentanglement between identity and makeup features, and weak controllability. To address these issues, we make three contributions. First, we construct a curated high-quality dataset using a train-generate-filter-retrain strategy that combines synthetic, realistic, and filtered samples to improve diversity and fidelity. Second, we design a diffusion-based framework that disentangles identity and makeup features, ensuring facial structure and skin tone are preserved while applying accurate and diverse cosmetic styles. Third, we propose a text-guided mechanism that allows fine-grained and region-specific control, enabling users to modify eyes, lips, or face makeup with natural language prompts. Experiments on benchmarks and real-world scenarios demonstrate improvements in fidelity, identity preservation, and flexibility. Examples of our dataset can be found at: https://makeup-adapter.github.io.

</details>


### [100] [Diffusion-Driven Inter-Outer Surface Separation for Point Clouds with Open Boundaries](https://arxiv.org/abs/2602.00739)
*Zhengyan Qin,Liyuan Qiu*

Main category: cs.CV

TL;DR: 提出基于扩散的算法，从双层点云中分离内外表面，特别针对TSDF融合中截断产生的"双层伪影"，能处理开放边界模型，约10秒处理4万点。


<details>
  <summary>Details</summary>
Motivation: 室内或医学3D重建中，TSDF融合的截断会导致"双层伪影"（不对称截断阈值产生错误的内外壳），需要提取真实内层以解决表面重叠和法线混乱问题。

Method: 基于扩散的算法，专注于处理具有开放边界（拓扑开口/孔洞）而非缺失表面区域的点云，作为TSDF融合后的轻量级后处理模块。

Result: 能稳健处理水密和开放边界模型，从2万内层点和2万外层点中提取内层约需10秒，适用于室内场景建模和医学成像等需要精确表面表示的应用。

Conclusion: 该方法有效解决TSDF融合中的双层伪影问题，作为后处理模块补充现有重建流程，但不替代完整的变分或基于学习的重建管道。

Abstract: We propose a diffusion-based algorithm for separating the inter and outer layer surfaces from double-layered point clouds, particularly those exhibiting the "double surface artifact" caused by truncation in Truncated Signed Distance Function (TSDF) fusion during indoor or medical 3D reconstruction. This artifact arises from asymmetric truncation thresholds, leading to erroneous inter and outer shells in the fused volume, which our method addresses by extracting the true inter layer to mitigate challenges like overlapping surfaces and disordered normals. We focus on point clouds with \emph{open boundaries} (i.e., sampled surfaces with topological openings/holes through which particles may escape), rather than point clouds with \emph{missing surface regions} where no samples exist. Our approach enables robust processing of both watertight and open-boundary models, achieving extraction of the inter layer from 20,000 inter and 20,000 outer points in approximately 10 seconds. This solution is particularly effective for applications requiring accurate surface representations, such as indoor scene modeling and medical imaging, where double-layered point clouds are prevalent, and it accommodates both closed (watertight) and open-boundary surface geometries. Our goal is \emph{post-hoc} inter/outer shell separation as a lightweight module after TSDF fusion; we do not aim to replace full variational or learning-based reconstruction pipelines.

</details>


### [101] [HSI-VAR: Rethinking Hyperspectral Restoration through Spatial-Spectral Visual Autoregression](https://arxiv.org/abs/2602.00749)
*Xiangming Wang,Benteng Sun,Yungeng Liu,Haijin Zeng,Yongyong Chen,Jingyong Su,Jie Liu*

Main category: cs.CV

TL;DR: HSI-VAR将高光谱图像恢复重新构想为自回归生成问题，通过渐进建模光谱和空间依赖关系，相比扩散模型大幅降低计算成本，在多个基准测试中取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 真实世界的高光谱图像常受噪声、模糊和波段缺失等多种退化影响。现有方法存在两个问题：扩散模型需要数百次迭代步骤，计算成本过高；回归模型则产生过度平滑的结果，无法保留关键结构细节。

Method: HSI-VAR将HSI恢复重新定义为自回归生成问题，包含三个关键创新：1) 潜在条件对齐，耦合潜在先验和条件嵌入的语义一致性；2) 退化感知引导，将混合退化编码为嵌入空间的线性组合，推理时计算成本降低近50%；3) 空间-光谱适应模块，在解码阶段细化两个域的细节。

Result: 在9个一体化HSI恢复基准测试中，HSI-VAR取得最先进性能，在ICVL数据集上PSNR提升3.77dB，推理速度比基于扩散的方法快95.5倍，同时提供优越的结构保留能力。

Conclusion: HSI-VAR通过自回归生成方法有效解决了高光谱图像恢复的计算效率和细节保留问题，为真实世界HSI恢复提供了高度实用的解决方案。

Abstract: Hyperspectral images (HSIs) capture richer spatial-spectral information beyond RGB, yet real-world HSIs often suffer from a composite mix of degradations, such as noise, blur, and missing bands. Existing generative approaches for HSI restoration like diffusion models require hundreds of iterative steps, making them computationally impractical for high-dimensional HSIs. While regression models tend to produce oversmoothed results, failing to preserve critical structural details. We break this impasse by introducing HSI-VAR, rethinking HSI restoration as an autoregressive generation problem, where spectral and spatial dependencies can be progressively modeled rather than globally reconstructed. HSI-VAR incorporates three key innovations: (1) Latent-condition alignment, which couples semantic consistency between latent priors and conditional embeddings for precise reconstruction; (2) Degradation-aware guidance, which uniquely encodes mixed degradations as linear combinations in the embedding space for automatic control, remarkably achieving a nearly $50\%$ reduction in computational cost at inference; (3) A spatial-spectral adaptation module that refines details across both domains in the decoding phase. Extensive experiments on nine all-in-one HSI restoration benchmarks confirm HSI-VAR's state-of-the-art performance, achieving a 3.77 dB PSNR improvement on \textbf{\textit{ICVL}} and offering superior structure preservation with an inference speed-up of up to $95.5 \times$ compared with diffusion-based methods, making it a highly practical solution for real-world HSI restoration.

</details>


### [102] [Evaluating Deep Learning-Based Nerve Segmentation in Brachial Plexus Ultrasound Under Realistic Data Constraints](https://arxiv.org/abs/2602.00763)
*Dylan Yves,Khush Agarwal,Jonathan Hoyin Chan,Patcharapit Promoppatum,Aroonkamon Pattanasiricharoen*

Main category: cs.CV

TL;DR: 评估深度学习在超声图像中分割臂丛神经的性能，发现多设备训练有正则化效果但不如单源训练，多类别分割会降低神经分割精度，神经大小与分割准确性呈正相关。


<details>
  <summary>Details</summary>
Motivation: 超声引导区域麻醉中神经准确定位至关重要，但手动识别因图像对比度低、斑点噪声和患者间解剖变异而具有挑战性，需要评估深度学习分割方法。

Method: 使用U-Net架构进行超声图像中的神经分割，研究数据集组成（来自SIEMENS ACUSON NX3 Elite和Philips EPIQ5设备）和标注策略（二分类神经分割 vs 多类别分割）对性能的影响。

Result: 多设备训练对性能较差的采集源有正则化效果，但不如目标域匹配的单源训练；多类别分割导致神经特异性Dice分数下降9%-61%；神经大小与分割准确性呈中等正相关（Pearson r=0.587）。

Conclusion: 研究为在真实临床数据约束下开发稳健的超声神经分割系统提供了方法学指导，指出小神经分割仍是主要挑战，多类别分割需谨慎处理类别不平衡和边界模糊问题。

Abstract: Accurate nerve localization is critical for the success of ultrasound-guided regional anesthesia, yet manual identification remains challenging due to low image contrast, speckle noise, and inter-patient anatomical variability. This study evaluates deep learning-based nerve segmentation in ultrasound images of the brachial plexus using a U-Net architecture, with a focus on how dataset composition and annotation strategy influence segmentation performance. We find that training on combined data from multiple ultrasound machines (SIEMENS ACUSON NX3 Elite and Philips EPIQ5) provides regularization benefits for lower-performing acquisition sources, though it does not surpass single-source training when matched to the target domain. Extending the task from binary nerve segmentation to multi-class supervision (artery, vein, nerve, muscle) results in decreased nerve-specific Dice scores, with performance drops ranging from 9% to 61% depending on dataset, likely due to class imbalance and boundary ambiguity. Additionally, we observe a moderate positive correlation between nerve size and segmentation accuracy (Pearson r=0.587, p<0.001), indicating that smaller nerves remain a primary challenge. These findings provide methodological guidance for developing robust ultrasound nerve segmentation systems under realistic clinical data constraints.

</details>


### [103] [DVLA-RL: Dual-Level Vision-Language Alignment with Reinforcement Learning Gating for Few-Shot Learning](https://arxiv.org/abs/2602.00795)
*Wenhao Li,Xianjing Meng,Qiangchang Wang,Zhongyi Han,Zhibin Wu,Yilong Yin*

Main category: cs.CV

TL;DR: DVLA-RL提出双层次视觉-语言对齐与强化学习门控机制，通过渐进式语义构建和自适应注意力融合，在少样本学习中实现更精确的跨模态对齐，在多个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有少样本学习方法虽然利用大语言模型增强视觉表示，但忽视了从低层到高层的渐进式、自适应视觉-语言对齐，导致语义增益有限。

Method: 提出DVLA-RL框架：1) 双层次语义构建(DSC)：基于类别名称和支持样本生成判别性属性，渐进选择最相关属性并合成连贯类别描述；2) RL门控注意力(RLA)：将跨模态融合建模为序列决策过程，通过强化学习训练轻量策略自适应调整自注意力和交叉注意力的贡献。

Result: 在三种不同少样本学习场景的九个基准测试中均达到新的最先进性能。

Conclusion: DVLA-RL通过双层次语义构建和自适应注意力融合，实现了更精确的跨模态对齐，能够在仅使用少量支持样本的情况下获得类别特定的判别性和泛化表示。

Abstract: Few-shot learning (FSL) aims to generalize to novel categories with only a few samples. Recent approaches incorporate large language models (LLMs) to enrich visual representations with semantic embeddings derived from class names. However, they overlook progressive and adaptive alignment between vision and language from low-level to high-level semantics, resulting in limited semantic gains. To address these challenges, we propose Dual-level Vision-Language Alignment with Reinforcement Learning gating (DVLA-RL), which consists of Dual-level Semantic Construction (DSC) and RL-gated Attention (RLA). Specifically, DSC conditions LLMs on both class names and support samples to generate discriminative attributes, progressively selects the most relevant ones, and then synthesizes them into coherent class descriptions. This process provides complementary low-level attributes and high-level descriptions, enabling both fine-grained grounding and holistic class understanding. To dynamically integrate dual-level semantics along with the visual network layers, RLA formulates cross-modal fusion as a sequential decision process. A lightweight policy trained with episodic REINFORCE adaptively adjusts the contributions of self-attention and cross-attention to integrate textual and visual tokens. As a result, shallow layers refine local attributes and deep layers emphasize global semantics, enabling more precise cross-modal alignment. This achieves class-specific discrimination and generalized representations with merely a few support samples. DVLA-RL achieves new state-of-the-art performance across nine benchmarks in three diverse FSL scenarios.

</details>


### [104] [Any3D-VLA: Enhancing VLA Robustness via Diverse Point Clouds](https://arxiv.org/abs/2602.00807)
*Xianzhe Fan,Shengliang Deng,Xiaoyang Wu,Yuxiang Lu,Zhuoling Li,Mi Yan,Yujia Zhang,Zhizheng Zhang,He Wang,Hengshuang Zhao*

Main category: cs.CV

TL;DR: Any3D-VLA通过融合2D图像和3D点云表示，提升视觉-语言-动作模型的空间理解能力，解决了3D数据稀缺和跨环境域差异问题。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型主要使用2D图像作为视觉输入，限制了其在复杂场景中的空间理解能力。需要探索如何融入3D信息来增强VLA模型的能力。

Method: 提出Any3D-VLA方法：1）将视觉输入显式提升为点云表示；2）统一模拟器、传感器和模型估计的点云训练流程；3）构建多样化输入并学习领域无关的3D表示；4）将3D表示与对应的2D表示融合。

Result: 实验表明，显式将视觉输入提升为点云能产生更好的表示，与2D表示形成互补。Any3D-VLA在模拟和真实世界实验中展现出性能提升和域差异缓解的优势。

Conclusion: 通过融合2D和3D表示，Any3D-VLA有效增强了VLA模型的空间理解能力，解决了3D数据稀缺和跨环境域差异的挑战。

Abstract: Existing Vision-Language-Action (VLA) models typically take 2D images as visual input, which limits their spatial understanding in complex scenes. How can we incorporate 3D information to enhance VLA capabilities? We conduct a pilot study across different observation spaces and visual representations. The results show that explicitly lifting visual input into point clouds yields representations that better complement their corresponding 2D representations. To address the challenges of (1) scarce 3D data and (2) the domain gap induced by cross-environment differences and depth-scale biases, we propose Any3D-VLA. It unifies the simulator, sensor, and model-estimated point clouds within a training pipeline, constructs diverse inputs, and learns domain-agnostic 3D representations that are fused with the corresponding 2D representations. Simulation and real-world experiments demonstrate Any3D-VLA's advantages in improving performance and mitigating the domain gap. Our project homepage is available at https://xianzhefan.github.io/Any3D-VLA.github.io.

</details>


### [105] [VVLoc: Prior-free 3-DoF Vehicle Visual Localization](https://arxiv.org/abs/2602.00810)
*Ze Huang,Zhongyang Xiao,Mingliang Song,Longan Yang,Hongyuan Yuan,Li Sun*

Main category: cs.CV

TL;DR: VVLoc是一个统一的多摄像头车辆定位系统，使用单一神经网络同时实现拓扑和度量定位，并提供置信度评估，训练仅需视觉数据和位姿真值。


<details>
  <summary>Details</summary>
Motivation: 传统定位方法通常独立处理拓扑和度量定位，依赖单摄像头设置，需要额外3D语义或位姿先验，且缺乏置信度量化机制，难以满足实际工业应用需求。

Method: 使用单一神经网络处理多摄像头系统，首先评估视觉观测之间的地理邻近度，然后通过匹配策略估计相对度量位姿，同时提供置信度测量。训练仅需视觉数据和对应位姿真值对。

Result: 在公开数据集和更具挑战性的自采集数据集上评估，VVLoc在各种定位任务中实现了最先进的定位精度。

Conclusion: VVLoc提供了一个高效、统一的车辆定位解决方案，能够同时处理拓扑和度量定位，具有实际工业应用的可行性。

Abstract: Localization is a critical technology in autonomous driving, encompassing both topological localization, which identifies the most similar map keyframe to the current observation, and metric localization, which provides precise spatial coordinates. Conventional methods typically address these tasks independently, rely on single-camera setups, and often require additional 3D semantic or pose priors, while lacking mechanisms to quantify the confidence of localization results, making them less feasible for real industrial applications. In this paper, we propose VVLoc, a unified pipeline that employs a single neural network to concurrently achieve topological and metric vehicle localization using multi-camera system. VVLoc first evaluates the geo-proximity between visual observations, then estimates their relative metric poses using a matching strategy, while also providing a confidence measure. Additionally, the training process for VVLoc is highly efficient, requiring only pairs of visual data and corresponding ground-truth poses, eliminating the need for complex supplementary data. We evaluate VVLoc not only on the publicly available datasets, but also on a more challenging self-collected dataset, demonstrating its ability to deliver state-of-the-art localization accuracy across a wide range of localization tasks.

</details>


### [106] [Generating a Paracosm for Training-Free Zero-Shot Composed Image Retrieval](https://arxiv.org/abs/2602.00813)
*Tong Wang,Yunhan Zhao,Shu Kong*

Main category: cs.CV

TL;DR: 提出Paracosm方法，通过大语言模型直接生成"心理图像"来改进零样本组合图像检索，在多个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 组合图像检索(CIR)的核心挑战是"心理图像"无法直接获取，现有方法使用大语言模型生成文本描述再进行匹配，但这种方法不够直接准确。

Method: Paracosm方法：1) 使用大语言模型为多模态查询直接生成"心理图像"；2) 为数据库中的真实图像生成对应的合成版本以减少域差距；3) 在"虚拟世界"中进行图像匹配。

Result: 在四个具有挑战性的基准测试中显著优于现有的零样本方法，实现了零样本CIR的最先进性能。

Conclusion: 通过直接生成"心理图像"而非文本描述，Paracosm方法为组合图像检索提供了更准确有效的解决方案，且无需训练。

Abstract: Composed Image Retrieval (CIR) is the task of retrieving a target image from a database using a multimodal query, which consists of a reference image and a modification text. The text specifies how to alter the reference image to form a ``mental image'', based on which CIR should find the target image in the database. The fundamental challenge of CIR is that this ``mental image'' is not physically available and is only implicitly defined by the query. The contemporary literature pursues zero-shot methods and uses a Large Multimodal Model (LMM) to generate a textual description for a given multimodal query, and then employs a Vision-Language Model (VLM) for textual-visual matching to search the target image. In contrast, we address CIR from first principles by directly generating the ``mental image'' for more accurate matching. Particularly, we prompt an LMM to generate a ``mental image'' for a given multimodal query and propose to use this ``mental image'' to search for the target image. As the ``mental image'' has a synthetic-to-real domain gap with real images, we also generate a synthetic counterpart for each real image in the database to facilitate matching. In this sense, our method uses LMM to construct a ``paracosm'', where it matches the multimodal query and database images. Hence, we call this method Paracosm. Notably, Paracosm is a training-free zero-shot CIR method. It significantly outperforms existing zero-shot methods on four challenging benchmarks, achieving state-of-the-art performance for zero-shot CIR.

</details>


### [107] [Edge-Native Generative De-identification: Inversion-Free Flow for Privacy-Preserving Federated Skin Image Analysis](https://arxiv.org/abs/2602.00821)
*Konstantinos Moutselos,Ilias Maglogiannis*

Main category: cs.CV

TL;DR: 提出一个用于临床皮肤病学的联邦学习隐私保护框架，通过无反转的Rectified Flow Transformers在边缘设备上快速生成身份无关的病理保留图像，实现隐私合规的合成替代数据。


<details>
  <summary>Details</summary>
Motivation: 临床皮肤病学中联邦学习的部署面临患者隐私保护与诊断特征保留的双重挑战。传统去识别方法会降低病理保真度，而标准生成编辑技术需要计算密集的反转过程，不适合资源受限的边缘设备。

Method: 采用基于Rectified Flow Transformers的FlowEdit框架，实现无反转的高保真身份转换（<20秒）。引入"Segment-by-Synthesis"机制，在本地生成反事实的健康和病理双胞胎对，提取与生物特征标记和语义伪影解耦的差异红斑掩码。

Result: 在高分辨率临床样本上的初步验证显示，合成身份间的IoU稳定性大于0.67。框架能够在边缘生成隐私合规的合成替代数据，从源头减轻梯度泄漏风险。

Conclusion: 该框架为联邦环境中的高精度皮肤图像分析提供了安全途径，通过边缘生成身份无关的病理保留图像，平衡了隐私保护与诊断效用，适合临床节点本地部署。

Abstract: The deployment of Federated Learning (FL) for clinical dermatology is hindered by the competing requirements of protecting patient privacy and preserving diagnostic features. Traditional de-identification methods often degrade pathological fidelity, while standard generative editing techniques rely on computationally intensive inversion processes unsuitable for resource-constrained edge devices. We propose a framework for identity-agnostic pathology preservation that serves as a client-side privacy-preserving utility. By leveraging inversion-free Rectified Flow Transformers (FlowEdit), the system performs high-fidelity identity transformation in near real-time (less than 20s), facilitating local deployment on clinical nodes. We introduce a "Segment-by-Synthesis" mechanism that generates counterfactual healthy and pathological twin pairs locally. This enables the extraction of differential erythema masks that are decoupled from biometric markers and semantic artifacts (e.g. jewelry). Pilot validation on high-resolution clinical samples demonstrates an Intersection over Union (IoU) stability greater than 0.67 across synthetic identities. By generating privacy-compliant synthetic surrogates at the edge, this framework mitigates the risk of gradient leakage at the source, providing a secure pathway for high-precision skin image analysis in federated environments.

</details>


### [108] [TransNormal: Dense Visual Semantics for Diffusion-based Transparent Object Normal Estimation](https://arxiv.org/abs/2602.00839)
*Mingwei Li,Hehe Fan,Yi Yang*

Main category: cs.CV

TL;DR: TransNormal：利用预训练扩散先验和DINOv3视觉语义的单步法向估计框架，针对透明物体，在ClearGrasp和ClearPose基准上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 透明物体的单目法向估计对实验室自动化至关重要，但由于复杂的光线折射和反射，传统深度和法向传感器经常失败，阻碍了具身AI在科学环境中的部署。

Method: 提出TransNormal框架：1）适配预训练扩散先验进行单步法向回归；2）通过交叉注意力机制集成DINOv3的密集视觉语义以处理透明表面缺乏纹理的问题；3）采用多任务学习目标和基于小波的正则化来保持细粒度结构细节。

Result: 在ClearGrasp基准上，平均误差降低24.4%，11.25°准确率提升22.8%；在ClearPose基准上，平均误差降低15.2%。同时发布了物理仿真的TransNormal-Synthetic数据集。

Conclusion: TransNormal通过结合扩散先验和视觉语义，有效解决了透明物体法向估计的挑战，显著优于现有方法，为实验室自动化中的透明物体处理提供了有力工具。

Abstract: Monocular normal estimation for transparent objects is critical for laboratory automation, yet it remains challenging due to complex light refraction and reflection. These optical properties often lead to catastrophic failures in conventional depth and normal sensors, hindering the deployment of embodied AI in scientific environments. We propose TransNormal, a novel framework that adapts pre-trained diffusion priors for single-step normal regression. To handle the lack of texture in transparent surfaces, TransNormal integrates dense visual semantics from DINOv3 via a cross-attention mechanism, providing strong geometric cues. Furthermore, we employ a multi-task learning objective and wavelet-based regularization to ensure the preservation of fine-grained structural details. To support this task, we introduce TransNormal-Synthetic, a physics-based dataset with high-fidelity normal maps for transparent labware. Extensive experiments demonstrate that TransNormal significantly outperforms state-of-the-art methods: on the ClearGrasp benchmark, it reduces mean error by 24.4% and improves 11.25° accuracy by 22.8%; on ClearPose, it achieves a 15.2% reduction in mean error. The code and dataset will be made publicly available at https://longxiang-ai.github.io/TransNormal.

</details>


### [109] [Invariance on Manifolds: Understanding Robust Visual Representations for Place Recognition](https://arxiv.org/abs/2602.00841)
*Jintao Cheng,Weibin Li,Zhijian He,Jin Wu,Chi Man Vong,Wei Zhang*

Main category: cs.CV

TL;DR: 提出了一种基于二阶几何统计的视觉地点识别框架，无需训练即可在SPD流形上捕捉几何稳定性，实现零样本泛化


<details>
  <summary>Details</summary>
Motivation: 当前视觉地点识别方法要么依赖大量监督数据，要么使用简单的一阶统计量，忽略了内在的结构相关性，难以应对剧烈的环境和视角变化

Method: 将场景建模为SPD流形上的协方差描述符，扰动表现为可处理的同余变换；通过几何感知的黎曼映射将描述符投影到线性化欧几里得嵌入中，分离信号结构与噪声；基于固定预训练骨干构建无需训练框架

Result: 在广泛实验中表现出与最先进基线方法高度竞争的性能，特别是在具有挑战性的零样本场景中表现优异

Conclusion: 提出的二阶几何统计框架能够有效捕捉几何稳定性，无需训练即可实现强大的零样本泛化能力，为视觉地点识别提供了一种新颖且高效的方法

Abstract: Visual Place Recognition (VPR) demands representations robust to drastic environmental and viewpoint shifts. Current aggregation paradigms, however, either rely on data-hungry supervision or simplistic first-order statistics, often neglecting intrinsic structural correlations. In this work, we propose a Second-Order Geometric Statistics framework that inherently captures geometric stability without training. We conceptualize scenes as covariance descriptors on the Symmetric Positive Definite (SPD) manifold, where perturbations manifest as tractable congruence transformations. By leveraging geometry-aware Riemannian mappings, we project these descriptors into a linearized Euclidean embedding, effectively decoupling signal structure from noise. Our approach introduces a training-free framework built upon fixed, pre-trained backbones, achieving strong zero-shot generalization without parameter updates. Extensive experiments confirm that our method achieves highly competitive performance against state-of-the-art baselines, particularly excelling in challenging zero-shot scenarios.

</details>


### [110] [Distill3R: A Pipeline for Democratizing 3D Foundation Models on Commodity Hardware](https://arxiv.org/abs/2602.00865)
*Brandon Leblanc,Charalambos Poullis*

Main category: cs.CV

TL;DR: Distill3R：一个将大型3D基础模型的几何推理能力蒸馏到可在单工作站上训练的小型学生模型的框架，旨在降低3D视觉研究的计算门槛。


<details>
  <summary>Details</summary>
Motivation: 当前多视图3D重建依赖于需要大规模计算集群训练的大型基础模型，这为大多数学术实验室设置了很高的进入门槛。为了弥合计算鸿沟，需要一种能在有限硬件上训练的高效方法。

Method: 提出两个核心创新：1）离线缓存管道，通过压缩监督信号将繁重的教师推理与训练循环解耦；2）置信度感知蒸馏损失，利用教师不确定性在普通硬件上实现训练。构建了一个7200万参数的学生模型。

Result: 学生模型相比650M参数的教师模型，参数量减少9倍，推理速度提升5倍。可在单工作站上3天内完成训练，而教师模型需要大规模GPU集群训练一周。学生模型保持了结构一致性和定性几何理解能力。

Conclusion: Distill3R为没有大规模计算资源的实验室提供了一个可复现的单工作站训练方案，作为民主化3D视觉研究的探索入口和高效边缘部署的基础，旨在提供可访问的研究基线而非与最先进模型竞争。

Abstract: While multi-view 3D reconstruction has shifted toward large-scale foundation models capable of inferring globally consistent geometry, their reliance on massive computational clusters for training has created a significant barrier to entry for most academic laboratories. To bridge this compute divide, we introduce Distill3R, a framework designed to distill the geometric reasoning of 3D foundation models into compact students fully trainable on a single workstation. Our methodology centers on two primary innovations: (1) an offline caching pipeline that decouples heavy teacher inference from the training loop through compressed supervision signals, and (2) a confidence-aware distillation loss that leverages teacher uncertainty to enable training on commodity hardware. We propose a 72M-parameter student model which achieves a 9x reduction in parameters and a 5x inference speedup compared to its 650M-parameter teacher. The student is fully trainable in under 3 days on a single workstation, whereas its teacher requires massive GPU clusters for up to a week. We demonstrate that the student preserves the structural consistency and qualitative geometric understanding required for functional 3D awareness. By providing a reproducible, single-workstation training recipe, Distill3R serves as an exploratory entry point for democratized 3D vision research and efficient edge deployment. This work is not intended to compete with state-of-the-art foundation models, but to provide an accessible research baseline for laboratories without access to large-scale compute to train and specialize models on their own domain-specific data at minimal cost.

</details>


### [111] [DIAMOND: Directed Inference for Artifact Mitigation in Flow Matching Models](https://arxiv.org/abs/2602.00883)
*Alicja Polowczyk,Agnieszka Polowczyk,Piotr Borycki,Joanna Waczyńska,Jacek Tabor,Przemysław Spurek*

Main category: cs.CV

TL;DR: DIAMOND是一种无需训练的轨迹校正方法，通过在推理过程中主动引导生成轨迹远离可能导致伪影的潜在状态，实现高质量、无伪影的图像合成。


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像模型（如FLUX）存在视觉和解剖伪影问题，现有后处理方法无法在核心图像形成过程中有效干预，且通常需要修改模型权重或依赖计算昂贵的区域细化过程。

Method: 提出DIAMOND方法，通过在每个生成步骤中重建干净样本的估计值，对生成轨迹进行校正，主动引导生成过程远离可能导致伪影的潜在状态。该方法无需训练，可扩展到标准扩散模型。

Result: DIAMOND提供了一种稳健的零样本路径，可在现代生成架构中实现高保真、无伪影的图像合成，无需额外训练或权重修改。

Conclusion: DIAMOND通过轨迹校正有效减少了文本到图像生成中的伪影问题，为高质量图像合成提供了一种无需训练、计算高效的解决方案。

Abstract: Despite impressive results from recent text-to-image models like FLUX, visual and anatomical artifacts remain a significant hurdle for practical and professional use. Existing methods for artifact reduction, typically work in a post-hoc manner, consequently failing to intervene effectively during the core image formation process. Notably, current techniques require problematic and invasive modifications to the model weights, or depend on a computationally expensive and time-consuming process of regional refinement. To address these limitations, we propose DIAMOND, a training-free method that applies trajectory correction to mitigate artifacts during inference. By reconstructing an estimate of the clean sample at every step of the generative trajectory, DIAMOND actively steers the generation process away from latent states that lead to artifacts. Furthermore, we extend the proposed method to standard Diffusion Models, demonstrating that DIAMOND provides a robust, zero-shot path to high-fidelity, artifact-free image synthesis without the need for additional training or weight modifications in modern generative architectures. Code is available at https://gmum.github.io/DIAMOND/

</details>


### [112] [OCTOPUS: Enhancing the Spatial-Awareness of Vision SSMs with Multi-Dimensional Scans and Traversal Selection](https://arxiv.org/abs/2602.00904)
*Kunal Mahatha,Ali Bahri,Pierre Marza,Sahar Dastani,Maria Vakalopoulou,Stergios Christodoulidis,Jose Dolz,Christian Desrosiers*

Main category: cs.CV

TL;DR: OCTOPUS是一种新颖的视觉架构，通过八方向离散递归在保持SSM线性复杂度的同时，解决了传统状态空间模型在视觉任务中因因果性破坏空间关系的问题。


<details>
  <summary>Details</summary>
Motivation: 传统状态空间模型（SSMs）在视觉任务中表现有限，因为其因果性设计破坏了图像中固有的空间关系，导致无法捕捉局部空间连贯性，经常连接不相邻的补丁而忽略视觉相关的邻近区域。

Method: 提出OCTOPUS架构，沿八个主要方向（水平、垂直和对角线方向的前后）执行离散递归，允许所有空间连接区域之间的有效信息交换，同时保持不相关补丁之间的独立性。

Result: 在分类和分割基准测试中，OCTOPUS在边界保持和区域一致性方面表现出显著改进，同时相比现有V-SSM模型保持了相对更好的分类准确性。

Conclusion: OCTOPUS作为多方向递归的基础方法，为构建空间感知且计算高效的视觉架构提供了可扩展且有效的机制。

Abstract: State space models (SSMs) have recently emerged as an alternative to transformers due to their unique ability of modeling global relationships in text with linear complexity. However, their success in vision tasks has been limited due to their causal formulation, which is suitable for sequential text but detrimental in the spatial domain where causality breaks the inherent spatial relationships among pixels or patches. As a result, standard SSMs fail to capture local spatial coherence, often linking non-adjacent patches while ignoring neighboring ones that are visually correlated. To address these limitations, we introduce OCTOPUS , a novel architecture that preserves both global context and local spatial structure within images, while maintaining the linear complexity of SSMs. OCTOPUS performs discrete reoccurrence along eight principal orientations, going forward or backward in the horizontal, vertical, and diagonal directions, allowing effective information exchange across all spatially connected regions while maintaining independence among unrelated patches. This design enables multi-directional recurrence, capturing both global context and local spatial structure with SSM-level efficiency. In our classification and segmentation benchmarks, OCTOPUS demonstrates notable improvements in boundary preservation and region consistency, as evident from the segmentation results, while maintaining relatively better classification accuracy compared to existing V-SSM based models. These results suggest that OCTOPUS appears as a foundation method for multi-directional recurrence as a scalable and effective mechanism for building spatially aware and computationally efficient vision architectures.

</details>


### [113] [ConsensusDrop: Fusing Visual and Cross-Modal Saliency for Efficient Vision Language Models](https://arxiv.org/abs/2602.00946)
*Dhruv Parikh,Haoyang Fan,Rajgopal Kannan,Viktor Prasanna*

Main category: cs.CV

TL;DR: ConsensusDrop：一种无需训练的视觉语言模型token压缩框架，通过融合视觉编码器显著性和LLM跨注意力信号，实现高效token剪枝与合并


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型处理大量冗余视觉token成本高昂，现有token减少方法要么使用视觉编码器显著性（广泛但查询无关），要么使用LLM跨注意力（查询感知但稀疏且昂贵），两者单独使用都不够充分

Method: 提出ConsensusDrop框架，通过协调视觉编码器显著性和查询感知的跨注意力信号，生成共识排名，保留最具信息量的token，同时通过编码器引导的token合并压缩其余token

Result: 在LLaVA-1.5/NeXT、Video-LLaVA等开源VLM上，ConsensusDrop在相同token预算下优于现有剪枝方法，提供更强的准确率-效率帕累托前沿，即使在激进token减少下也能保持接近基线的准确率，同时减少TTFT和KV缓存占用

Conclusion: 融合视觉编码器显著性和LLM跨注意力信号能有效提升视觉token选择性能，ConsensusDrop提供了一种实用且高效的训练免费token压缩解决方案

Abstract: Vision-Language Models (VLMs) are expensive because the LLM processes hundreds of largely redundant visual tokens. Existing token reduction methods typically exploit \textit{either} vision-encoder saliency (broad but query-agnostic) \textit{or} LLM cross-attention (query-aware but sparse and costly). We show that neither signal alone is sufficient: fusing them consistently improves performance compared to unimodal visual token selection (ranking). However, making such fusion practical is non-trivial: cross-modal saliency is usually only available \emph{inside} the LLM (too late for efficient pre-LLM pruning), and the two signals are inherently asymmetric, so naive fusion underutilizes their complementary strengths. We propose \textbf{ConsensusDrop}, a training-free framework that derives a \emph{consensus} ranking by reconciling vision encoder saliency with query-aware cross-attention, retaining the most informative tokens while compressing the remainder via encoder-guided token merging. Across LLaVA-1.5/NeXT, Video-LLaVA, and other open-source VLMs, ConsensusDrop consistently outperforms prior pruning methods under identical token budgets and delivers a stronger accuracy-efficiency Pareto frontier -- preserving near-baseline accuracy even at aggressive token reductions while reducing TTFT and KV cache footprint. Our code will be open-sourced.

</details>


### [114] [Data Augmentation for High-Fidelity Generation of CAR-T/NK Immunological Synapse Images](https://arxiv.org/abs/2602.00949)
*Xiang Zhang,Boxuan Zhang,Alireza Naghizadeh,Mohab Mohamed,Dongfang Liu,Ruixiang Tang,Dimitris Metaxas,Dongfang Liu*

Main category: cs.CV

TL;DR: 该论文提出两种数据增强框架（IAAA和SAAA）来生成合成CAR-T/NK免疫突触图像，解决标注数据有限问题，提升免疫突触检测和分割性能。


<details>
  <summary>Details</summary>
Motivation: CAR-T/NK免疫突触质量可作为预测治疗效果的功能性生物标志物，但标注显微图像数据集有限限制了人工神经网络在免疫突触检测和分割中的泛化能力。

Method: 集成两种互补数据增强框架：1）实例感知自动增强（IAAA），通过优化增强策略生成合成图像和分割掩码；2）语义感知AI增强（SAAA），结合扩散掩码生成器和Pix2Pix条件图像合成器，创建解剖学真实的合成数据。

Result: 两种增强策略生成的合成图像在视觉和结构特性上与真实免疫突触数据高度匹配，显著提高了CAR-T/NK免疫突触的检测和分割性能。

Conclusion: 通过增强免疫突触量化的鲁棒性和准确性，该工作支持开发更可靠的基于成像的生物标志物，用于预测患者对CAR-T/NK免疫疗法的反应。

Abstract: Chimeric antigen receptor (CAR)-T and NK cell immunotherapies have transformed cancer treatment, and recent studies suggest that the quality of the CAR-T/NK cell immunological synapse (IS) may serve as a functional biomarker for predicting therapeutic efficacy. Accurate detection and segmentation of CAR-T/NK IS structures using artificial neural networks (ANNs) can greatly increase the speed and reliability of IS quantification. However, a persistent challenge is the limited size of annotated microscopy datasets, which restricts the ability of ANNs to generalize. To address this challenge, we integrate two complementary data-augmentation frameworks. First, we employ Instance Aware Automatic Augmentation (IAAA), an automated, instance-preserving augmentation method that generates synthetic CAR-T/NK IS images and corresponding segmentation masks by applying optimized augmentation policies to original IS data. IAAA supports multiple imaging modalities (e.g., fluorescence and brightfield) and can be applied directly to CAR-T/NK IS images derived from patient samples. In parallel, we introduce a Semantic-Aware AI Augmentation (SAAA) pipeline that combines a diffusion-based mask generator with a Pix2Pix conditional image synthesizer. This second method enables the creation of diverse, anatomically realistic segmentation masks and produces high-fidelity CAR-T/NK IS images aligned with those masks, further expanding the training corpus beyond what IAAA alone can provide. Together, these augmentation strategies generate synthetic images whose visual and structural properties closely match real IS data, significantly improving CAR-T/NK IS detection and segmentation performance. By enhancing the robustness and accuracy of IS quantification, this work supports the development of more reliable imaging-based biomarkers for predicting patient response to CAR-T/NK immunotherapy.

</details>


### [115] [Hybrid Topological and Deep Feature Fusion for Accurate MRI-Based Alzheimer's Disease Severity Classification](https://arxiv.org/abs/2602.00956)
*Faisal Ahmed*

Main category: cs.CV

TL;DR: 提出结合拓扑数据分析(TDA)和DenseNet121的混合深度学习框架，用于阿尔茨海默病的四阶段分类，在OASIS数据集上达到99.93%准确率和100% AUC。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病的早期准确诊断在神经影像临床决策支持系统中仍是关键挑战。传统神经网络常忽略大脑结构的拓扑特征，需要捕捉这些补充信息来提升分类性能。

Method: 提出新颖的混合深度学习框架：1) 使用拓扑数据分析(TDA)捕捉大脑结构的拓扑特征；2) 使用DenseNet121从MRI切片学习层次空间特征；3) 将深度特征和拓扑特征融合，增强四个AD阶段的可分性。

Result: 在OASIS-1 Kaggle MRI数据集上的实验表明，TDA+DenseNet121模型显著优于现有方法，达到99.93%准确率和100% AUC，超越了最近的CNN、迁移学习、集成和多尺度架构。

Conclusion: 拓扑分析融入深度学习流程的有效性得到证实，该框架可作为自动阿尔茨海默病诊断的鲁棒高精度工具，展示了拓扑洞察在医疗影像分析中的潜力。

Abstract: Early and accurate diagnosis of Alzheimer's disease (AD) remains a critical challenge in neuroimaging-based clinical decision support systems. In this work, we propose a novel hybrid deep learning framework that integrates Topological Data Analysis (TDA) with a DenseNet121 backbone for four-class Alzheimer's disease classification using structural MRI data from the OASIS dataset. TDA is employed to capture complementary topological characteristics of brain structures that are often overlooked by conventional neural networks, while DenseNet121 efficiently learns hierarchical spatial features from MRI slices. The extracted deep and topological features are fused to enhance class separability across the four AD stages.
  Extensive experiments conducted on the OASIS-1 Kaggle MRI dataset demonstrate that the proposed TDA+DenseNet121 model significantly outperforms existing state-of-the-art approaches. The model achieves an accuracy of 99.93% and an AUC of 100%, surpassing recently published CNN-based, transfer learning, ensemble, and multi-scale architectures. These results confirm the effectiveness of incorporating topological insights into deep learning pipelines and highlight the potential of the proposed framework as a robust and highly accurate tool for automated Alzheimer's disease diagnosis.

</details>


### [116] [Unveiling the Cognitive Compass: Theory-of-Mind-Guided Multimodal Emotion Reasoning](https://arxiv.org/abs/2602.00971)
*Meng Luo,Bobo Li,Shanqing Xu,Shize Zhang,Qiuchan Chen,Menglu Han,Wenhao Chen,Yanxiang Huang,Hao Fei,Mong-Li Lee,Wynne Hsu*

Main category: cs.CV

TL;DR: 论文提出HitEmotion基准测试和ToM引导推理方法，用于评估和增强多模态大语言模型的深度情感理解能力


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在深度情感理解方面能力有限，需要基于心理理论来建模情感认知基础

Method: 1) 提出HitEmotion基准测试，分层诊断认知深度能力断点；2) 设计ToM引导的推理链跟踪心理状态并校准跨模态证据；3) 提出TMPO强化学习方法，使用中间心理状态作为过程级监督

Result: HitEmotion暴露了最先进模型在认知要求高的任务上的深度情感推理缺陷；ToM引导推理链和TMPO提高了任务准确性，并产生更忠实、更连贯的推理过程

Conclusion: 该工作为研究社区提供了实用的工具包，用于评估和增强多模态大语言模型基于认知的情感理解能力

Abstract: Despite rapid progress in multimodal large language models (MLLMs), their capability for deep emotional understanding remains limited. We argue that genuine affective intelligence requires explicit modeling of Theory of Mind (ToM), the cognitive substrate from which emotions arise. To this end, we introduce HitEmotion, a ToM-grounded hierarchical benchmark that diagnoses capability breakpoints across increasing levels of cognitive depth. Second, we propose a ToM-guided reasoning chain that tracks mental states and calibrates cross-modal evidence to achieve faithful emotional reasoning. We further introduce TMPO, a reinforcement learning method that uses intermediate mental states as process-level supervision to guide and strengthen model reasoning. Extensive experiments show that HitEmotion exposes deep emotional reasoning deficits in state-of-the-art models, especially on cognitively demanding tasks. In evaluation, the ToM-guided reasoning chain and TMPO improve end-task accuracy and yield more faithful, more coherent rationales. In conclusion, our work provides the research community with a practical toolkit for evaluating and enhancing the cognition-based emotional understanding capabilities of MLLMs. Our dataset and code are available at: https://HitEmotion.github.io/.

</details>


### [117] [Navigating Simply, Aligning Deeply: Winning Solutions for Mouse vs. AI 2025](https://arxiv.org/abs/2602.00982)
*Phu-Hoa Pham,Chi-Nguyen Tran,Dao Sy Duy Minh,Nguyen Lam Phu Quy,Huynh Trung Kiet*

Main category: cs.CV

TL;DR: 该论文介绍了NeurIPS 2025 Mouse vs. AI竞赛中获胜的方法，展示了简单架构在视觉鲁棒性方面的优势，以及深度架构在神经对齐方面的优越性。


<details>
  <summary>Details</summary>
Motivation: 视觉鲁棒性和神经对齐是开发能与生物视觉系统匹配的人工智能代理的关键挑战。该研究旨在通过系统分析不同架构在视觉鲁棒性和神经对齐任务上的表现，为开发稳健、受生物启发的视觉代理提供指导。

Method: 对于Track 1（视觉鲁棒性）：采用轻量级两层CNN架构，增强门控线性单元和观测归一化。对于Track 2（神经对齐）：开发了类似ResNet的深度架构，包含16个卷积层和基于GLU的门控机制。系统分析了10个在60K到1.14M步之间训练的模型检查点。

Result: Track 1获得95.4%的最终得分，Track 2获得top-1神经预测性能（1780万参数）。研究发现训练持续时间与性能呈非单调关系，最佳结果出现在约200K步左右。简单架构在视觉鲁棒性方面表现优异，而深度模型在神经对齐方面表现更好。

Conclusion: 研究结果挑战了关于模型复杂度在视觉运动学习中作用的传统假设，为开发稳健、受生物启发的视觉代理提供了实用指导。简单架构在视觉鲁棒性方面具有优势，而深度架构在神经对齐方面表现更佳。

Abstract: Visual robustness and neural alignment remain critical challenges in developing artificial agents that can match biological vision systems. We present the winning approaches from Team HCMUS_TheFangs for both tracks of the NeurIPS 2025 Mouse vs. AI: Robust Visual Foraging Competition. For Track 1 (Visual Robustness), we demonstrate that architectural simplicity combined with targeted components yields superior generalization, achieving 95.4% final score with a lightweight two-layer CNN enhanced by Gated Linear Units and observation normalization. For Track 2 (Neural Alignment), we develop a deep ResNet-like architecture with 16 convolutional layers and GLU-based gating that achieves top-1 neural prediction performance with 17.8 million parameters. Our systematic analysis of ten model checkpoints trained between 60K to 1.14M steps reveals that training duration exhibits a non-monotonic relationship with performance, with optimal results achieved around 200K steps. Through comprehensive ablation studies and failure case analysis, we provide insights into why simpler architectures excel at visual robustness while deeper models with increased capacity achieve better neural alignment. Our results challenge conventional assumptions about model complexity in visuomotor learning and offer practical guidance for developing robust, biologically-inspired visual agents.

</details>


### [118] [VAMOS-OCTA: Vessel-Aware Multi-Axis Orthogonal Supervision for Inpainting Motion-Corrupted OCT Angiography Volumes](https://arxiv.org/abs/2602.00995)
*Nick DiSanto,Ehsan Khodapanah Aghdam,Han Liu,Jacob Watson,Yuankai K. Tao,Hao Li,Ipek Oguz*

Main category: cs.CV

TL;DR: VAMOS-OCTA：一种用于修复运动伪影OCTA图像的深度学习框架，通过血管感知多轴监督实现B扫描修复


<details>
  <summary>Details</summary>
Motivation: 手持式OCTA在非合作或儿科患者中容易产生运动伪影，导致B扫描中出现空白区域，严重影响3D图像质量和血管连续性分析

Method: 使用2.5D U-Net架构，以相邻B扫描堆栈为输入重建受损中心B扫描，采用新颖的血管感知多轴正交监督损失函数，结合血管加权强度重建与轴向和横向投影一致性约束

Result: VAMOS-OCTA在合成和真实世界受损数据上均优于现有方法，能恢复清晰的毛细血管、血管连续性，并产生干净的en face投影

Conclusion: 多轴监督为修复运动退化的3D OCTA数据提供了强大的约束，该框架能同时提升B扫描清晰度和体积投影准确性

Abstract: Handheld Optical Coherence Tomography Angiography (OCTA) enables noninvasive retinal imaging in uncooperative or pediatric subjects, but is highly susceptible to motion artifacts that severely degrade volumetric image quality. Sudden motion during 3D acquisition can lead to unsampled retinal regions across entire B-scans (cross-sectional slices), resulting in blank bands in en face projections. We propose VAMOS-OCTA, a deep learning framework for inpainting motion-corrupted B-scans using vessel-aware multi-axis supervision. We employ a 2.5D U-Net architecture that takes a stack of neighboring B-scans as input to reconstruct a corrupted center B-scan, guided by a novel Vessel-Aware Multi-Axis Orthogonal Supervision (VAMOS) loss. This loss combines vessel-weighted intensity reconstruction with axial and lateral projection consistency, encouraging vascular continuity in native B-scans and across orthogonal planes. Unlike prior work that focuses primarily on restoring the en face MIP, VAMOS-OCTA jointly enhances both cross-sectional B-scan sharpness and volumetric projection accuracy, even under severe motion corruptions. We trained our model on both synthetic and real-world corrupted volumes and evaluated its performance using both perceptual quality and pixel-wise accuracy metrics. VAMOS-OCTA consistently outperforms prior methods, producing reconstructions with sharp capillaries, restored vessel continuity, and clean en face projections. These results demonstrate that multi-axis supervision offers a powerful constraint for restoring motion-degraded 3D OCTA data. Our source code is available at https://github.com/MedICL-VU/VAMOS-OCTA.

</details>


### [119] [CortiNet: A Physics-Perception Hybrid Cortical-Inspired Dual-Stream Network for Gallbladder Disease Diagnosis from Ultrasound](https://arxiv.org/abs/2602.01000)
*Vagish Kumar,Souvik Chakraborty*

Main category: cs.CV

TL;DR: CortiNet：一种轻量级、皮层启发的双流神经网络架构，用于胆囊疾病诊断，通过物理可解释的多尺度信号分解和感知驱动的特征学习，在参数极少的情况下达到高诊断准确率。


<details>
  <summary>Details</summary>
Motivation: 超声成像是胆囊疾病的主要诊断方式，但其低分辨率和斑点噪声影响了诊断可靠性。现有的大型卷积神经网络难以在常规临床环境中部署，需要轻量级且高效的解决方案。

Method: 提出CortiNet架构，受人类视觉皮层并行处理通路启发，将低频结构信息与高频感知细节分离，通过专门的编码流处理。采用物理可解释的多尺度信号分解，直接处理结构化、频率选择性表示而非原始像素强度。包含晚期皮层式融合机制，集成互补的结构和纹理线索。还提出结构感知可解释性框架，仅对结构分支应用梯度加权类激活映射。

Result: 在10,692张专家标注图像（涵盖9个临床相关胆囊疾病类别）上评估，CortiNet达到98.74%的高诊断准确率，且参数数量仅为传统深度卷积模型的一小部分。

Conclusion: CortiNet通过结合物理可解释的信号分解和感知驱动的特征学习，实现了轻量级、高效的胆囊疾病诊断，具有临床部署潜力，并通过结构感知可解释性框架增强了抗斑点噪声的鲁棒性。

Abstract: Ultrasound imaging is the primary diagnostic modality for detecting Gallbladder diseases due to its non-invasive nature, affordability, and wide accessibility. However, the low resolution and speckle noise inherent to ultrasound images hinder diagnostic reliability, prompting the use of large convolutional neural networks that are difficult to deploy in routine clinical settings. In this work, we propose CortiNet, a lightweight, cortical-inspired dual-stream neural architecture for gallbladder disease diagnosis that integrates physically interpretable multi-scale signal decomposition with perception-driven feature learning. Inspired by parallel processing pathways in the human visual cortex, CortiNet explicitly separates low-frequency structural information from high-frequency perceptual details and processes them through specialized encoding streams. By operating directly on structured, frequency-selective representations rather than raw pixel intensities, the architecture embeds strong physics-based inductive bias, enabling efficient feature learning with a significantly reduced parameter footprint. A late-stage cortical-style fusion mechanism integrates complementary structural and textural cues while preserving computational efficiency. Additionally, we propose a structure-aware explainability framework wherein gradient-weighted class activation mapping is only applied to the structural branch of the proposed CortiNet architecture. This choice allows the model to only focus on the structural features, making it robust against speckle noise. We evaluate CortiNet on 10,692 expert-annotated images spanning nine clinically relevant gallbladder disease categories. Experimental results demonstrate that CortiNet achieves high diagnostic accuracy (98.74%) with only a fraction of the parameters required by conventional deep convolutional models.

</details>


### [120] [SRVAU-R1: Enhancing Video Anomaly Understanding via Reflection-Aware Learning](https://arxiv.org/abs/2602.01004)
*Zihao Zhao,Shengting Cao,Muchao Ye*

Main category: cs.CV

TL;DR: SRVAU-R1提出了一种基于自反思增强推理的视频异常理解框架，通过反思导向的思维链数据集和反思感知学习范式，显著提升了异常定位准确性和推理质量。


<details>
  <summary>Details</summary>
Motivation: 现有基于多模态大语言模型的方法主要关注异常的表面描述，缺乏对异常行为的深度推理，如显式的自我反思和自我纠正能力。

Method: 提出SRVAU-R1框架：1）创建首个面向反思的视频异常理解思维链数据集，包含初始推理、自我反思和修订推理；2）采用反思感知学习范式，结合监督微调和强化微调来增强多模态推理能力。

Result: 在多个视频异常基准测试中，SRVAU-R1持续优于现有方法，在时间异常定位准确性和推理质量方面均取得显著提升。

Conclusion: 通过引入反思机制，SRVAU-R1成功增强了多模态大语言模型在视频异常理解任务中的深度推理能力，为异常行为分析提供了更有效的解决方案。

Abstract: Multi-modal large language models (MLLMs) have demonstrated significant progress in reasoning capabilities and shown promising effectiveness in video anomaly understanding (VAU) tasks. However, existing MLLM-based approaches remain largely focused on surface-level descriptions of anomalies, lacking deep reasoning over abnormal behaviors like explicit self-reflection and self-correction. To address that, we propose Self-Reflection-Enhanced Reasoning for Video Anomaly Understanding (SRVAU-R1), a reflection-aware learning framework that incorporates reflection in MLLM reasoning. Specifically, SRVAU-R1 introduces the first reflection-oriented Chain-of-Thought dataset tailored for VAU, providing structured supervision with initial reasoning, self-reflection, and revised reasoning. Based on that, it includes a novel reflection-aware learning paradigm with supervised fine-tuning and reinforcement fine-tuning to enhance multi-modal reasoning for VAU. Extensive experiments on multiple video anomaly benchmarks demonstrate that SRVAU-R1 consistently outperforms existing methods, achieving significant improvements in both temporal anomaly localization accuracy and reasoning quality.

</details>


### [121] [LocalScore: Local Density-Aware Similarity Scoring for Biometrics](https://arxiv.org/abs/2602.01012)
*Yiyang Su,Minchul Kim,Jie Zhu,Christopher Perry,Feng Liu,Anil Jain,Xiaoming Liu*

Main category: cs.CV

TL;DR: LocalScore：一种利用k近邻局部密度改进开放集生物识别的简单评分算法，无需修改模型架构，显著提升开放集检索和验证性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界生物识别系统面临开放集挑战，即探针可能不在注册库中。现有方法通常将同一主体的多个样本压缩为单一全局表示，忽略了特征分布的局部密度，导致决策边界不理想和开放集鲁棒性差。

Method: 提出LocalScore评分算法，通过k近邻显式地结合注册库特征分布的局部密度。该方法与架构无关、损失函数独立、计算开销可忽略，可作为即插即用方案应用于现有生物识别系统。

Result: 在多模态实验中，LocalScore显著提升性能：开放集检索的FNIR@FPIR从53%降至40%，验证的TAR@FAR从51%提升至74%。理论分析和实验验证解释了方法在不同数据集特性下的增益机制。

Conclusion: LocalScore通过考虑特征空间的局部密度，有效解决了开放集生物识别中非注册探针检测的挑战，为现有系统提供了简单高效的改进方案。

Abstract: Open-set biometrics faces challenges with probe subjects who may not be enrolled in the gallery, as traditional biometric systems struggle to detect these non-mated probes. Despite the growing prevalence of multi-sample galleries in real-world deployments, most existing methods collapse intra-subject variability into a single global representation, leading to suboptimal decision boundaries and poor open-set robustness. To address this issue, we propose LocalScore, a simple yet effective scoring algorithm that explicitly incorporates the local density of the gallery feature distribution using the k-th nearest neighbors. LocalScore is architecture-agnostic, loss-independent, and incurs negligible computational overhead, making it a plug-and-play solution for existing biometric systems. Extensive experiments across multiple modalities demonstrate that LocalScore consistently achieves substantial gains in open-set retrieval (FNIR@FPIR reduced from 53% to 40%) and verification (TAR@FAR improved from 51% to 74%). We further provide theoretical analysis and empirical validation explaining when and why the method achieves the most significant gains based on dataset characteristics.

</details>


### [122] [Effectiveness of Automatically Curated Dataset in Thyroid Nodules Classification Algorithms Using Deep Learning](https://arxiv.org/abs/2602.01020)
*Jichen Yang,Jikai Zhang,Benjamin Wildman-Tobriner,Maciej A. Mazurowski*

Main category: cs.CV

TL;DR: 自动标注的甲状腺结节数据集能显著提升深度学习模型性能，且使用全部数据比仅用高精度子集效果更好


<details>
  <summary>Details</summary>
Motivation: 甲状腺结节癌症诊断常用超声图像，但深度学习模型训练数据有限。先前研究提出了自动标注甲状腺结节数据集的方法（63%产出率，83%准确率），但其对深度学习训练的实际效果未知。

Method: 训练深度学习模型对比三种数据集：1）手动标注数据集；2）自动标注完整数据集；3）自动标注高精度子集。评估模型在甲状腺结节良恶性分类上的性能。

Result: 手动标注数据集训练的模型AUC为0.643（95% CI: 0.62-0.66）。自动标注完整数据集训练的模型AUC为0.694（95% CI: 0.67-0.73），显著优于手动标注（P<0.001）。高精度子集训练的模型AUC为0.689（95% CI: 0.66-0.72），与完整数据集无显著差异（P>0.43）。

Conclusion: 自动标注数据集能显著提升深度学习算法性能，且建议使用全部自动标注数据而非仅用高精度子集。

Abstract: The diagnosis of thyroid nodule cancers commonly utilizes ultrasound images. Several studies showed that deep learning algorithms designed to classify benign and malignant thyroid nodules could match radiologists' performance. However, data availability for training deep learning models is often limited due to the significant effort required to curate such datasets. The previous study proposed a method to curate thyroid nodule datasets automatically. It was tested to have a 63% yield rate and 83% accuracy. However, the usefulness of the generated data for training deep learning models remains unknown. In this study, we conducted experiments to determine whether using a automatically-curated dataset improves deep learning algorithms' performance. We trained deep learning models on the manually annotated and automatically-curated datasets. We also trained with a smaller subset of the automatically-curated dataset that has higher accuracy to explore the optimum usage of such dataset. As a result, the deep learning model trained on the manually selected dataset has an AUC of 0.643 (95% confidence interval [CI]: 0.62, 0.66). It is significantly lower than the AUC of the 6automatically-curated dataset trained deep learning model, 0.694 (95% confidence interval [CI]: 0.67, 0.73, P < .001). The AUC of the accurate subset trained deep learning model is 0.689 (95% confidence interval [CI]: 0.66, 0.72, P > .43), which is insignificantly worse than the AUC of the full automatically-curated dataset. In conclusion, we showed that using a automatically-curated dataset can substantially increase the performance of deep learning algorithms, and it is suggested to use all the data rather than only using the accurate subset.

</details>


### [123] [GMAC: Global Multi-View Constraint for Automatic Multi-Camera Extrinsic Calibration](https://arxiv.org/abs/2602.01033)
*Chentian Sun*

Main category: cs.CV

TL;DR: GMAC是一个基于多视图重建网络隐式几何表示的多相机外参估计框架，无需显式3D重建或手动标定，通过联合优化重投影一致性和多视图循环一致性实现准确稳定的外参估计。


<details>
  <summary>Details</summary>
Motivation: 现有多相机系统标定方法通常依赖标定板、显式几何建模或特定任务神经网络，在复杂动态环境或在线场景中鲁棒性和适用性有限，难以在实际应用中部署。

Method: GMAC将外参建模为受潜在多视图几何结构约束的全局变量，通过剪枝和重构现有网络使其潜在特征能直接支持外参预测，使用轻量级回归头，无需全新网络设计。联合优化跨视图重投影一致性和多视图循环一致性。

Result: 在合成和真实世界多相机数据集上的实验表明，GMAC无需显式3D重建或手动标定即可实现准确稳定的外参估计。

Conclusion: GMAC为多相机系统的高效部署和在线标定提供了新解决方案，通过隐式几何表示和一致性约束实现了鲁棒的外参估计。

Abstract: Automatic calibration of multi-camera systems, namely the accurate estimation of spatial extrinsic parameters, is fundamental for 3D reconstruction, panoramic perception, and multi-view data fusion. Existing methods typically rely on calibration targets, explicit geometric modeling, or task-specific neural networks. Such approaches often exhibit limited robustness and applicability in complex dynamic environments or online scenarios, making them difficult to deploy in practical applications. To address this, this paper proposes GMAC, a multi-camera extrinsic estimation framework based on the implicit geometric representations learned by multi-view reconstruction networks. GMAC models extrinsics as global variables constrained by the latent multi-view geometric structure and prunes and structurally reconfigures existing networks so that their latent features can directly support extrinsic prediction through a lightweight regression head, without requiring a completely new network design. Furthermore, GMAC jointly optimizes cross-view reprojection consistency and multi-view cycle consistency, ensuring geometric coherence across cameras while improving prediction accuracy and optimization stability. Experiments on both synthetic and real-world multi-camera datasets demonstrate that GMAC achieves accurate and stable extrinsic estimation without explicit 3D reconstruction or manual calibration, providing a new solution for efficient deployment and online calibration of multi-camera systems.

</details>


### [124] [FUSE-Flow: Scalable Real-Time Multi-View Point Cloud Reconstruction Using Confidence](https://arxiv.org/abs/2602.01035)
*Chentian Sun*

Main category: cs.CV

TL;DR: FUSE-Flow：实时多视角点云重建框架，通过自适应空间哈希加权聚合实现线性复杂度，在保持实时性能的同时提升重建质量和稳定性。


<details>
  <summary>Details</summary>
Motivation: 实时多视角点云重建在VR/AR、机器人导航、数字孪生等领域有广泛应用，但现有方法（体素融合、时间累积、全局优化）存在计算复杂度高、内存占用大、可扩展性差的问题，难以同时实现实时性能、重建质量和多相机可扩展性。

Method: 提出FUSE-Flow框架：1）帧间独立生成点云片段，通过测量置信度和3D距离一致性两个权重进行融合以抑制噪声；2）引入自适应空间哈希加权聚合方法，根据局部点云密度自适应划分3D空间，每个单元选择代表性点进行加权融合；3）GPU并行化实现高吞吐、低延迟的线性复杂度处理。

Result: 实验表明，该框架在重叠区域、深度不连续和动态场景中提高了重建稳定性和几何保真度，同时在现代GPU上保持实时帧率，验证了其有效性、鲁棒性和可扩展性。

Conclusion: FUSE-Flow成功解决了实时多视角点云重建中的性能-质量权衡问题，通过无状态、帧间独立的线性可扩展架构，为大规模多相机系统提供了高效解决方案。

Abstract: Real-time multi-view point cloud reconstruction is a core problem in 3D vision and immersive perception, with wide applications in VR, AR, robotic navigation, digital twins, and computer interaction. Despite advances in multi-camera systems and high-resolution depth sensors, fusing large-scale multi-view depth observations into high-quality point clouds under strict real-time constraints remains challenging. Existing methods relying on voxel-based fusion, temporal accumulation, or global optimization suffer from high computational complexity, excessive memory usage, and limited scalability, failing to simultaneously achieve real-time performance, reconstruction quality, and multi-camera extensibility. We propose FUSE-Flow, a frame-wise, stateless, and linearly scalable point cloud streaming reconstruction framework. Each frame independently generates point cloud fragments, fused via two weights, measurement confidence and 3D distance consistency to suppress noise while preserving geometric details. For large-scale multi-camera efficiency, we introduce an adaptive spatial hashing-based weighted aggregation method: 3D space is adaptively partitioned by local point cloud density, representative points are selected per cell, and weighted fusion is performed to handle both sparse and dense regions. With GPU parallelization, FUSE-Flow achieves high-throughput, low-latency point cloud generation and fusion with linear complexity. Experiments demonstrate that the framework improves reconstruction stability and geometric fidelity in overlapping, depth-discontinuous, and dynamic scenes, while maintaining real-time frame rates on modern GPUs, verifying its effectiveness, robustness, and scalability.

</details>


### [125] [VEQ: Modality-Adaptive Quantization for MoE Vision-Language Models](https://arxiv.org/abs/2602.01037)
*Guangshuo Qin,Zhiteng Li,Zheng Chen,Weihang Zhang,Linghe Kong,Yulun Zhang*

Main category: cs.CV

TL;DR: VEQ提出了一种针对MoE视觉语言模型的双感知量化框架，通过模态-专家感知量化和模态亲和力感知量化，同时处理跨模态差异和专家异质性，显著提升量化性能。


<details>
  <summary>Details</summary>
Motivation: MoE视觉语言模型虽然性能优异但计算和内存成本极高，需要压缩。现有量化方法未能处理两个关键异质性：视觉和语言token之间的固有差异，以及不同专家的非均匀贡献。

Method: 提出视觉专家量化(VEQ)框架：1) 模态-专家感知量化：利用专家激活频率优先最小化关键专家的误差；2) 模态亲和力感知量化：通过整合token-专家亲和力与模态信息构建增强的Hessian矩阵来指导校准过程。

Result: 在W3A16配置下，相比之前SOTA量化方法，在Kimi-VL上平均准确率提升2.04%，在Qwen3-VL上提升3.09%，在各种多模态任务上表现出优越的鲁棒性。

Conclusion: VEQ通过同时适应跨模态差异和专家异质性，为MoE视觉语言模型提供了一种有效的训练后量化解决方案，显著优于现有基线方法。

Abstract: Mixture-of-Experts(MoE) Vision-Language Models (VLMs) offer remarkable performance but incur prohibitive memory and computational costs, making compression essential. Post-Training Quantization (PTQ) is an effective training-free technique to address the massive memory and computation overhead. Existing quantization paradigms fall short as they are oblivious to two critical forms of heterogeneity: the inherent discrepancy between vision and language tokens, and the non-uniform contribution of different experts. To bridge this gap, we propose Visual Expert Quantization (VEQ), a dual-aware quantization framework designed to simultaneously accommodate cross-modal differences and heterogeneity between experts. Specifically, VEQ incorporates 1)Modality-expert-aware Quantization, which utilizes expert activation frequency to prioritize error minimization for pivotal experts, and 2)Modality-affinity-aware Quantization, which constructs an enhanced Hessian matrix by integrating token-expert affinity with modality information to guide the calibration process. Extensive experiments across diverse benchmarks verify that VEQ consistently outperforms state-of-the-art baselines. Specifically, under the W3A16 configuration, our method achieves significant average accuracy gains of 2.04\% on Kimi-VL and 3.09\% on Qwen3-VL compared to the previous SOTA quantization methods, demonstrating superior robustness across various multimodal tasks. Our code will be available at https://github.com/guangshuoqin/VEQ.

</details>


### [126] [From Videos to Conversations: Egocentric Instructions for Task Assistance](https://arxiv.org/abs/2602.01038)
*Lavisha Aggarwal,Vikas Bahirwani,Andrea Colaco*

Main category: cs.CV

TL;DR: 本文提出了一个自动将单人教学视频转换为双人多模态任务指导对话的框架，并发布了HowToDIV数据集，包含507个对话、6,636个问答对和24小时视频，为多模态程序性任务辅助提供了基准。


<details>
  <summary>Details</summary>
Motivation: 许多日常任务需要专业知识，但AI助手在AR辅助方面进展受限，主要因为缺乏大规模、基于真实世界任务执行的多模态对话数据集，而人工收集数据成本高、复杂度大。

Method: 提出基于大语言模型的完全自动流水线，将单人教学视频自动转换为专家-新手双人多模态任务指导对话，提供可扩展且成本高效的数据收集替代方案。

Result: 创建了HowToDIV多模态数据集，包含507个对话、6,636个问答对和24小时视频，涵盖多个领域，每个会话包含多轮专家-新手交互。使用Gemma 3和Qwen 2.5提供了基准结果。

Conclusion: 该框架为多模态程序性任务辅助提供了可扩展的数据生成解决方案，HowToDIV数据集和基准结果为该领域研究提供了重要资源。

Abstract: Many everyday tasks, ranging from appliance repair and cooking to car maintenance, require expert knowledge, particularly for complex, multi-step procedures. Despite growing interest in AI agents for augmented reality (AR) assistance, progress remains limited by the scarcity of large-scale multimodal conversational datasets grounded in real-world task execution, in part due to the cost and logistical complexity of human-assisted data collection. In this paper, we present a framework to automatically transform single person instructional videos into two-person multimodal task-guidance conversations. Our fully automatic pipeline, based on large language models, provides a scalable and cost efficient alternative to traditional data collection approaches. Using this framework, we introduce HowToDIV, a multimodal dataset comprising 507 conversations, 6,636 question answer pairs, and 24 hours of video spanning multiple domains. Each session consists of a multi-turn expert-novice interaction. Finally, we report baseline results using Gemma 3 and Qwen 2.5 on HowToDIV, providing an initial benchmark for multimodal procedural task assistance.

</details>


### [127] [ReLayout: Versatile and Structure-Preserving Design Layout Editing via Relation-Aware Design Reconstruction](https://arxiv.org/abs/2602.01046)
*Jiawei Lin,Shizhao Sun,Danqing Huang,Ting Liu,Ji Li,Jiang Bian*

Main category: cs.CV

TL;DR: ReLayout：无需三元组数据的结构保持式设计布局编辑框架，通过关系图和自监督学习实现多种编辑操作


<details>
  <summary>Details</summary>
Motivation: 设计布局编辑是自动化设计中的关键任务，但面临用户需求表达模糊、缺乏编辑样本数据、需要保持未编辑元素布局结构等挑战

Method: 提出ReLayout框架：1) 引入关系图表示未编辑元素间的位置大小关系作为结构约束；2) 提出关系感知设计重建(RADR)方法，通过自监督学习从元素、关系图和合成编辑操作重建设计；3) 使用多模态大语言模型作为主干，统一多种编辑操作

Result: 定性和定量实验以及用户研究表明，ReLayout在编辑质量、准确性和布局结构保持方面显著优于基线模型

Conclusion: ReLayout成功解决了设计布局编辑中的数据稀缺和结构保持问题，实现了无需手动调整的自动化设计编辑，为设计工作流程提供了重要进展

Abstract: Automated redesign without manual adjustments marks a key step forward in the design workflow. In this work, we focus on a foundational redesign task termed design layout editing, which seeks to autonomously modify the geometric composition of a design based on user intents. To overcome the ambiguity of user needs expressed in natural language, we introduce four basic and important editing actions and standardize the format of editing operations. The underexplored task presents a unique challenge: satisfying specified editing operations while simultaneously preserving the layout structure of unedited elements. Besides, the scarcity of triplet (original design, editing operation, edited design) samples poses another formidable challenge. To this end, we present ReLayout, a novel framework for versatile and structure-preserving design layout editing that operates without triplet data. Specifically, ReLayout first introduces the relation graph, which contains the position and size relationships among unedited elements, as the constraint for layout structure preservation. Then, relation-aware design reconstruction (RADR) is proposed to bypass the data challenge. By learning to reconstruct a design from its elements, a relation graph, and a synthesized editing operation, RADR effectively emulates the editing process in a self-supervised manner. A multi-modal large language model serves as the backbone for RADR, unifying multiple editing actions within a single model and thus achieving versatile editing after fine-tuning. Qualitative, quantitative results and user studies show that ReLayout significantly outperforms the baseline models in terms of editing quality, accuracy, and layout structure preservation.

</details>


### [128] [Residual Decoding: Mitigating Hallucinations in Large Vision-Language Models via History-Aware Residual Guidance](https://arxiv.org/abs/2602.01047)
*Xinrong Chen,Xu Chu,Yingmin Qiu,Hengyuan Zhang,Jing Xiong,Shiyu Tang,Shuai Liu,Shaokang Yang,Cheng Yang,Hayden Kwok-Hay So,Ngai Wong*

Main category: cs.CV

TL;DR: ResDec是一种无需训练的解码方法，利用历史信息和LVLM的内部机制来减少视觉语言模型中的幻觉问题


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型虽然在多模态任务中表现良好，但受到语言先验的影响，经常产生与视觉输入不匹配的幻觉内容

Method: 提出ResDec（残差解码），这是一种无需训练的方法，利用历史信息辅助解码，依靠LVLM的内部隐式推理机制和token logits演化机制来纠正偏差

Result: ResDec有效抑制了语言先验引起的幻觉，显著改善了视觉基础，减少了物体幻觉，同时在综合LVLM基准测试中表现优异

Conclusion: ResDec是一种有效的训练免费方法，能够减少LVLM中的幻觉问题，并具有广泛的适用性

Abstract: Large Vision-Language Models (LVLMs) can reason effectively from image-text inputs and perform well in various multimodal tasks. Despite this success, they are affected by language priors and often produce hallucinations. Hallucinations denote generated content that is grammatically and syntactically coherent, yet bears no match or direct relevance to actual visual input. To address this problem, we propose Residual Decoding (ResDec). It is a novel training-free method that uses historical information to aid decoding. The method relies on the internal implicit reasoning mechanism and token logits evolution mechanism of LVLMs to correct biases. Extensive experiments demonstrate that ResDec effectively suppresses hallucinations induced by language priors, significantly improves visual grounding, and reduces object hallucinations. In addition to mitigating hallucinations, ResDec also performs exceptionally well on comprehensive LVLM benchmarks, highlighting its broad applicability.

</details>


### [129] [Baseline Method of the Foundation Model Challenge for Ultrasound Image Analysis](https://arxiv.org/abs/2602.01055)
*Bo Deng,Yitong Tang,Jiake Li,Yuxin Huang,Li Wang,Yu Zhang,Yufei Zhan,Hua Lu,Xiaoshen Zhang,Jieyun Bai*

Main category: cs.CV

TL;DR: 本文提出了FM_UIA 2026超声图像分析基础模型挑战的官方基线，基于统一的多头多任务学习框架，支持27个子任务，使用EfficientNet-B4和FPN进行特征提取，通过任务特定路由策略实现不同任务的优化。


<details>
  <summary>Details</summary>
Motivation: 超声图像在解剖结构和采集协议上存在显著异质性，现有方法多为任务特定型，限制了其作为临床可部署基础模型的适用性。需要开发能够处理多种任务的统一模型。

Method: 采用统一的多头多任务学习框架，使用ImageNet预训练的EfficientNet-B4作为骨干网络，结合特征金字塔网络提取多尺度特征。通过任务特定路由策略，全局任务使用高级语义特征，密集预测任务利用空间细节特征。训练采用复合损失函数、任务自适应学习率缩放和余弦退火调度。

Result: 验证结果表明该统一设计的可行性和鲁棒性，为超声基础模型研究建立了强大且可扩展的基线。代码和数据集已公开。

Conclusion: 提出的MH-MTL框架为超声图像分析基础模型研究提供了有效的统一解决方案，能够处理多种任务，为临床部署奠定了基础。

Abstract: Ultrasound (US) imaging exhibits substantial heterogeneity across anatomical structures and acquisition protocols, posing significant challenges to the development of generalizable analysis models. Most existing methods are task-specific, limiting their suitability as clinically deployable foundation models. To address this limitation, the Foundation Model Challenge for Ultrasound Image Analysis (FM\_UIA~2026) introduces a large-scale multi-task benchmark comprising 27 subtasks across segmentation, classification, detection, and regression. In this paper, we present the official baseline for FM\_UIA~2026 based on a unified Multi-Head Multi-Task Learning (MH-MTL) framework that supports all tasks within a single shared network. The model employs an ImageNet-pretrained EfficientNet--B4 backbone for robust feature extraction, combined with a Feature Pyramid Network (FPN) to capture multi-scale contextual information. A task-specific routing strategy enables global tasks to leverage high-level semantic features, while dense prediction tasks exploit spatially detailed FPN representations. Training incorporates a composite loss with task-adaptive learning rate scaling and a cosine annealing schedule. Validation results demonstrate the feasibility and robustness of this unified design, establishing a strong and extensible baseline for ultrasound foundation model research. The code and dataset are publicly available at \href{https://github.com/lijiake2408/Foundation-Model-Challenge-for-Ultrasound-Image-Analysis}{GitHub}.

</details>


### [130] [Radioactive 3D Gaussian Ray Tracing for Tomographic Reconstruction](https://arxiv.org/abs/2602.01057)
*Ling Chen,Bao Yang*

Main category: cs.CV

TL;DR: 提出基于3D高斯射线追踪的断层重建框架，替代基于仿射近似的splatting方法，提供更精确的线积分计算和几何校正能力


<details>
  <summary>Details</summary>
Motivation: 现有R2-Gaussian方法使用局部仿射近似将3D高斯映射到2D探测器，这会导致重建定量精度下降，且难以整合非线性几何校正（如PET中的弧校正）

Method: 提出基于3D高斯射线追踪的断层重建框架：1）解析计算通过3D高斯基元的线积分，避免局部仿射塌缩；2）射线追踪公式提供对射线起点和方向的显式控制，便于精确应用非线性几何校正

Result: 相比splatting模型，该方法提供更物理一致的前向投影模型，扩展了高斯基重建在更广泛真实断层系统（如PET）中的适用性，同时提高了投影精度

Conclusion: 3D高斯射线追踪框架克服了仿射近似的局限性，为断层重建提供了更精确、更灵活的解决方案，特别适用于需要非线性几何校正的先进成像系统

Abstract: 3D Gaussian Splatting (3DGS) has recently emerged in computer vision as a promising rendering technique. By adapting the principles of Elliptical Weighted Average (EWA) splatting to a modern differentiable pipeline, 3DGS enables real-time, high-quality novel view synthesis. Building upon this, R2-Gaussian extended the 3DGS paradigm to tomographic reconstruction by rectifying integration bias, achieving state-of-the-art performance in computed tomography (CT). To enable differentiability, R2-Gaussian adopts a local affine approximation: each 3D Gaussian is locally mapped to a 2D Gaussian on the detector and composed via alpha blending to form projections. However, the affine approximation can degrade reconstruction quantitative accuracy and complicate the incorporation of nonlinear geometric corrections. To address these limitations, we propose a tomographic reconstruction framework based on 3D Gaussian ray tracing. Our approach provides two key advantages over splatting-based models: (i) it computes the line integral through 3D Gaussian primitives analytically, avoiding the local affine collapse and thus yielding a more physically consistent forward projection model; and (ii) the ray-tracing formulation gives explicit control over ray origins and directions, which facilitates the precise application of nonlinear geometric corrections, e.g., arc-correction used in positron emission tomography (PET). These properties extend the applicability of Gaussian-based reconstruction to a wider range of realistic tomography systems while improving projection accuracy.

</details>


### [131] [DRFormer: A Dual-Regularized Bidirectional Transformer for Person Re-identification](https://arxiv.org/abs/2602.01059)
*Ying Shu,Pujian Zhan,Huiqi Yang,Hehe Fan,Youfang Lin,Kai Lv*

Main category: cs.CV

TL;DR: 提出DRFormer框架，通过双正则化双向Transformer融合DINO的局部纹理特征和CLIP的全局语义特征，解决行人重识别中的遮挡和姿态变化问题


<details>
  <summary>Details</summary>
Motivation: 现有方法通常只依赖单一范式（要么基于局部纹理特征，要么基于全局语义特征），忽略了DINO和CLIP两种模型的互补优势。细粒度判别细节和全局语义特征都能帮助解决行人重识别中的遮挡和姿态变化问题

Method: 提出DRFormer（双正则化双向Transformer）框架，通过双正则化机制确保特征提取的多样性，平衡DINO（擅长局部纹理）和CLIP（擅长全局语义）两种模型的贡献

Result: 在五个基准数据集上的大量实验表明，该方法能有效协调局部和全局表示，取得了与最先进方法相竞争的性能

Conclusion: 通过融合视觉基础模型（DINO）和视觉语言模型（CLIP）的互补优势，提出的DRFormer框架能够更好地解决行人重识别中的挑战性问题

Abstract: Both fine-grained discriminative details and global semantic features can contribute to solving person re-identification challenges, such as occlusion and pose variations. Vision foundation models (\textit{e.g.}, DINO) excel at mining local textures, and vision-language models (\textit{e.g.}, CLIP) capture strong global semantic difference. Existing methods predominantly rely on a single paradigm, neglecting the potential benefits of their integration. In this paper, we analyze the complementary roles of these two architectures and propose a framework to synergize their strengths by a \textbf{D}ual-\textbf{R}egularized Bidirectional \textbf{Transformer} (\textbf{DRFormer}). The dual-regularization mechanism ensures diverse feature extraction and achieves a better balance in the contributions of the two models. Extensive experiments on five benchmarks show that our method effectively harmonizes local and global representations, achieving competitive performance against state-of-the-art methods.

</details>


### [132] [PDE-Constrained Optimization for Neural Image Segmentation with Physics Priors](https://arxiv.org/abs/2602.01069)
*Seema K. Poudel,Sunny K. Khadka*

Main category: cs.CV

TL;DR: 该论文提出了一种将图像分割作为PDE约束优化问题的方法，通过变分正则化将物理先验整合到深度学习模型中，在显微镜图像分割任务上取得了更好的泛化性能和边界保真度。


<details>
  <summary>Details</summary>
Motivation: 显微镜图像分割由于测量噪声、弱物体边界和有限标记数据而成为一个不适定逆问题。虽然深度神经网络提供了灵活的非参数估计器，但无约束的经验风险最小化通常导致不稳定解和泛化能力差。

Method: 将图像分割表述为PDE约束优化问题，通过变分正则化将物理先验整合到深度学习模型中。最小化由数据保真度项和来自反应-扩散方程和相场界面能量的惩罚项组成的复合目标函数，所有项都实现为可微分残差损失。

Result: 在LIVECell数据集上的实验表明，相比无约束的UNet基线模型，PDE正则化模型在分割精度和边界保真度方面取得了一致的改进。特别是在低样本情况下，模型表现出增强的稳定性和改进的泛化能力。

Conclusion: 该方法展示了PDE约束优化如何加强数据驱动的学习框架，为变分方法、统计学习和科学机器学习之间提供了原则性的桥梁。结构化先验的整合显著提高了分割性能。

Abstract: Segmentation of microscopy images constitutes an ill-posed inverse problem due to measurement noise, weak object boundaries, and limited labeled data. Although deep neural networks provide flexible nonparametric estimators, unconstrained empirical risk minimization often leads to unstable solutions and poor generalization. In this work, image segmentation is formulated as a PDE-constrained optimization problem that integrates physically motivated priors into deep learning models through variational regularization. The proposed framework minimizes a composite objective function consisting of a data fidelity term and penalty terms derived from reaction-diffusion equations and phase-field interface energies, all implemented as differentiable residual losses. Experiments are conducted on the LIVECell dataset, a high-quality, manually annotated collection of phase-contrast microscopy images. Training is performed on two cell types, while evaluation is carried out on a distinct, unseen cell type to assess generalization. A UNet architecture is used as the unconstrained baseline model. Experimental results demonstrate consistent improvements in segmentation accuracy and boundary fidelity compared to unconstrained deep learning baselines. Moreover, the PDE-regularized models exhibit enhanced stability and improved generalization in low-sample regimes, highlighting the advantages of incorporating structured priors. The proposed approach illustrates how PDE-constrained optimization can strengthen data-driven learning frameworks, providing a principled bridge between variational methods, statistical learning, and scientific machine learning.

</details>


### [133] [PISA: Piecewise Sparse Attention Is Wiser for Efficient Diffusion Transformers](https://arxiv.org/abs/2602.01077)
*Haopeng Li,Shitong Shao,Wenliang Zhong,Zikai Zhou,Lichen Bai,Hui Xiong,Zeke Xie*

Main category: cs.CV

TL;DR: PISA提出一种训练免费的分段稀疏注意力机制，通过精确计算关键块+泰勒展开近似非关键块，在保持质量的同时实现亚二次复杂度，显著加速扩散Transformer生成


<details>
  <summary>Details</summary>
Motivation: 扩散Transformer在视频和图像生成中至关重要，但其注意力机制的二次复杂度成为效率瓶颈。现有块稀疏注意力通过丢弃非关键块来加速，但在高稀疏度下会因丢失上下文而质量下降

Method: 提出PISA（Piecewise Sparse Attention），采用"精确或近似"策略而非传统的"保留或丢弃"范式：对关键块进行精确计算，对非关键块通过块级泰勒展开进行高效近似，从而覆盖完整注意力范围

Result: 在Wan2.1-14B上实现1.91倍加速，在Hunyuan-Video上实现2.57倍加速，在所有稀疏注意力方法中保持最高质量。在FLUX图像生成上实现1.2倍加速且不损害视觉质量

Conclusion: PISA通过发现非关键块注意力分数的分布稳定性，提出创新的分段稀疏注意力设计，有效平衡了速度与质量，为扩散Transformer的高效生成提供了新解决方案

Abstract: Diffusion Transformers are fundamental for video and image generation, but their efficiency is bottlenecked by the quadratic complexity of attention. While block sparse attention accelerates computation by attending only critical key-value blocks, it suffers from degradation at high sparsity by discarding context. In this work, we discover that attention scores of non-critical blocks exhibit distributional stability, allowing them to be approximated accurately and efficiently rather than discarded, which is essentially important for sparse attention design. Motivated by this key insight, we propose PISA, a training-free Piecewise Sparse Attention that covers the full attention span with sub-quadratic complexity. Unlike the conventional keep-or-drop paradigm that directly drop the non-critical block information, PISA introduces a novel exact-or-approximate strategy: it maintains exact computation for critical blocks while efficiently approximating the remainder through block-wise Taylor expansion. This design allows PISA to serve as a faithful proxy to full attention, effectively bridging the gap between speed and quality. Experimental results demonstrate that PISA achieves 1.91 times and 2.57 times speedups on Wan2.1-14B and Hunyuan-Video, respectively, while consistently maintaining the highest quality among sparse attention methods. Notably, even for image generation on FLUX, PISA achieves a 1.2 times acceleration without compromising visual quality. Code is available at: https://github.com/xie-lab-ml/piecewise-sparse-attention.

</details>


### [134] [MedAD-R1: Eliciting Consistent Reasoning in Interpretible Medical Anomaly Detection via Consistency-Reinforced Policy Optimization](https://arxiv.org/abs/2602.01081)
*Haitao Zhang,Yingying Wang,Jiaxiang Wang,Haote Xu,Hongyang Zhang,Yirong Chen,Yue Huang,Xinghao Ding*

Main category: cs.CV

TL;DR: 本文提出了MedAD-38K基准数据集和MedAD-R1模型，通过两阶段训练框架（认知注入和一致性组相对策略优化）实现医学异常检测的SOTA性能，提升AI临床决策的可解释性和可信度。


<details>
  <summary>Details</summary>
Motivation: 当前医学异常检测（MedAD）依赖监督微调在简单数据集上，导致模型缺乏合理的推理能力和鲁棒的多模态泛化能力，限制了AI在临床决策中的可信度和可解释性。

Method: 1. 构建MedAD-38K基准：首个大规模、多模态、多中心的MedAD基准，包含诊断思维链注释和结构化视觉问答对；2. 两阶段训练框架：第一阶段认知注入（SFT）注入基础医学知识并对齐思维-回答范式；第二阶段一致性组相对策略优化（Con-GRPO）引入一致性奖励确保推理过程与最终诊断相关且逻辑一致。

Result: 提出的MedAD-R1模型在MedAD-38K基准上达到SOTA性能，超越强基线10%以上，能够生成透明且逻辑一致的推理路径。

Conclusion: 该方法通过增强推理过程的相关性和逻辑一致性，为提高AI临床决策支持的可信度和可解释性提供了有前景的途径。

Abstract: Medical Anomaly Detection (MedAD) presents a significant opportunity to enhance diagnostic accuracy using Large Multimodal Models (LMMs) to interpret and answer questions based on medical images. However, the reliance on Supervised Fine-Tuning (SFT) on simplistic and fragmented datasets has hindered the development of models capable of plausible reasoning and robust multimodal generalization. To overcome this, we introduce MedAD-38K, the first large-scale, multi-modal, and multi-center benchmark for MedAD featuring diagnostic Chain-of-Thought (CoT) annotations alongside structured Visual Question-Answering (VQA) pairs. On this foundation, we propose a two-stage training framework. The first stage, Cognitive Injection, uses SFT to instill foundational medical knowledge and align the model with a structured think-then-answer paradigm. Given that standard policy optimization can produce reasoning that is disconnected from the final answer, the second stage incorporates Consistency Group Relative Policy Optimization (Con-GRPO). This novel algorithm incorporates a crucial consistency reward to ensure the generated reasoning process is relevant and logically coherent with the final diagnosis. Our proposed model, MedAD-R1, achieves state-of-the-art (SOTA) performance on the MedAD-38K benchmark, outperforming strong baselines by more than 10\%. This superior performance stems from its ability to generate transparent and logically consistent reasoning pathways, offering a promising approach to enhancing the trustworthiness and interpretability of AI for clinical decision support.

</details>


### [135] [Differential Vector Erasure: Unified Training-Free Concept Erasure for Flow Matching Models](https://arxiv.org/abs/2602.01089)
*Zhiqi Zhang,Xinhao Zhong,Yi Sun,Shuoyang Sun,Bin Chen,Shu-Tao Xia,Xuan Wang*

Main category: cs.CV

TL;DR: 提出DVE方法，一种无需训练的概念擦除技术，专门针对流匹配模型，通过投影速度场到差分方向来选择性移除特定概念。


<details>
  <summary>Details</summary>
Motivation: 文本到图像扩散模型虽然能生成高质量图像，但会再现不良概念（如NSFW内容、版权风格或特定对象），这对安全可控部署构成担忧。现有概念擦除方法主要针对DDPM模型且依赖昂贵的微调，而新兴的流匹配模型采用不同的生成范式，现有方法不适用。

Method: 提出差分向量擦除（DVE）方法，核心洞察是语义概念隐含在控制生成流的速度场的方向结构中。构建差分向量场来表征目标概念与精心选择的锚概念之间的方向差异。在推理时，DVE通过将速度场投影到差分方向来选择性移除概念特定组件。

Result: 在FLUX模型上的大量实验表明，DVE在多种概念擦除任务（包括NSFW抑制、艺术风格移除和对象擦除）上始终优于现有基线方法，同时保持图像质量和多样性。

Conclusion: DVE是一种专门为流匹配模型设计的无需训练的概念擦除方法，通过利用速度场中的方向结构差异，能够精确抑制特定概念而不影响无关语义，为安全可控的生成模型部署提供了有效解决方案。

Abstract: Text-to-image diffusion models have demonstrated remarkable capabilities in generating high-quality images, yet their tendency to reproduce undesirable concepts, such as NSFW content, copyrighted styles, or specific objects, poses growing concerns for safe and controllable deployment. While existing concept erasure approaches primarily focus on DDPM-based diffusion models and rely on costly fine-tuning, the recent emergence of flow matching models introduces a fundamentally different generative paradigm for which prior methods are not directly applicable. In this paper, we propose Differential Vector Erasure (DVE), a training-free concept erasure method specifically designed for flow matching models. Our key insight is that semantic concepts are implicitly encoded in the directional structure of the velocity field governing the generative flow. Leveraging this observation, we construct a differential vector field that characterizes the directional discrepancy between a target concept and a carefully chosen anchor concept. During inference, DVE selectively removes concept-specific components by projecting the velocity field onto the differential direction, enabling precise concept suppression without affecting irrelevant semantics. Extensive experiments on FLUX demonstrate that DVE consistently outperforms existing baselines on a wide range of concept erasure tasks, including NSFW suppression, artistic style removal, and object erasure, while preserving image quality and diversity.

</details>


### [136] [PandaPose: 3D Human Pose Lifting from a Single Image via Propagating 2D Pose Prior to 3D Anchor Space](https://arxiv.org/abs/2602.01095)
*Jinghong Zheng,Changlong Jiang,Yang Xiao,Jiaqi Li,Haohong Kuang,Hang Xu,Ran Wang,Zhiguo Cao,Min Du,Joey Tianyi Zhou*

Main category: cs.CV

TL;DR: PandaPose：通过将2D姿态先验传播到3D锚点空间作为统一中间表示，来解决单目RGB图像3D人体姿态估计中的误差传播和自遮挡问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法直接从2D到3D建立关节映射，存在两个根本限制：1）输入2D姿态预测误差会传播到3D预测；2）难以处理自遮挡情况。需要一种更鲁棒的方法来缓解这些问题。

Method: 提出3D锚点空间包含：1）规范坐标系中的关节级3D锚点，提供准确先验；2）深度感知的关节级特征提升，分层整合深度信息解决自遮挡歧义；3）锚点-特征交互解码器，将3D锚点与提升特征结合生成统一锚点查询，包含关节级3D锚点集、视觉线索和几何深度信息，用于锚点到关节的集成预测。

Result: 在Human3.6M、MPI-INF-3DHP和3DPW三个基准测试上验证了方法的优越性。在Human3.6M的挑战性条件下，相比SOTA方法误差显著降低14.7%，定性比较进一步展示了方法的有效性和鲁棒性。

Conclusion: PandaPose通过创新的3D锚点空间表示和深度感知特征提升，有效解决了传统2D到3D姿态估计中的误差传播和自遮挡问题，在多个基准测试上取得了显著性能提升。

Abstract: 3D human pose lifting from a single RGB image is a challenging task in 3D vision. Existing methods typically establish a direct joint-to-joint mapping from 2D to 3D poses based on 2D features. This formulation suffers from two fundamental limitations: inevitable error propagation from input predicted 2D pose to 3D predictions and inherent difficulties in handling self-occlusion cases. In this paper, we propose PandaPose, a 3D human pose lifting approach via propagating 2D pose prior to 3D anchor space as the unified intermediate representation. Specifically, our 3D anchor space comprises: (1) Joint-wise 3D anchors in the canonical coordinate system, providing accurate and robust priors to mitigate 2D pose estimation inaccuracies. (2) Depth-aware joint-wise feature lifting that hierarchically integrates depth information to resolve self-occlusion ambiguities. (3) The anchor-feature interaction decoder that incorporates 3D anchors with lifted features to generate unified anchor queries encapsulating joint-wise 3D anchor set, visual cues and geometric depth information. The anchor queries are further employed to facilitate anchor-to-joint ensemble prediction. Experiments on three well-established benchmarks (i.e., Human3.6M, MPI-INF-3DHP and 3DPW) demonstrate the superiority of our proposition. The substantial reduction in error by $14.7\%$ compared to SOTA methods on the challenging conditions of Human3.6M and qualitative comparisons further showcase the effectiveness and robustness of our approach.

</details>


### [137] [Robust Harmful Meme Detection under Missing Modalities via Shared Representation Learning](https://arxiv.org/abs/2602.01101)
*Felix Breiteneder,Mohammad Belal,Muhammad Saad Saeed,Shahed Masoudian,Usman Naseem,Kulshrestha Juhi,Markus Schedl,Shah Nawaz*

Main category: cs.CV

TL;DR: 该论文提出了首个全面研究模态不完整数据下有害表情包检测方法的工作，并提出了一种新的基线方法，通过独立投影学习多模态共享表示，在文本缺失时表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 互联网表情包是强大的传播工具，但可能被用于传播仇恨。现有检测方法通常依赖完整的模态数据（文本和图像），但在现实场景中，由于OCR质量差等问题，文本可能缺失，导致现有方法性能下降。

Method: 提出一种新的基线方法，通过独立投影学习多模态的共享表示，这些共享表示可以在模态不完整时被利用。该方法能更好地整合视觉特征，减少对文本的依赖。

Result: 在两个基准数据集上的实验结果表明，该方法在文本缺失时优于现有方法，能更好地整合视觉特征，提高在文本信息缺失场景下的鲁棒性。

Conclusion: 这项工作代表了有害表情包检测在现实世界应用中的重要进展，特别是在模态缺失的情况下，为实现更鲁棒的检测系统迈出了重要一步。

Abstract: Internet memes are powerful tools for communication, capable of spreading political, psychological, and sociocultural ideas. However, they can be harmful and can be used to disseminate hate toward targeted individuals or groups. Although previous studies have focused on designing new detection methods, these often rely on modal-complete data, such as text and images. In real-world settings, however, modalities like text may be missing due to issues like poor OCR quality, making existing methods sensitive to missing information and leading to performance deterioration. To address this gap, in this paper, we present the first-of-its-kind work to comprehensively investigate the behavior of harmful meme detection methods in the presence of modal-incomplete data. Specifically, we propose a new baseline method that learns a shared representation for multiple modalities by projecting them independently. These shared representations can then be leveraged when data is modal-incomplete. Experimental results on two benchmark datasets demonstrate that our method outperforms existing approaches when text is missing. Moreover, these results suggest that our method allows for better integration of visual features, reducing dependence on text and improving robustness in scenarios where textual information is missing. Our work represents a significant step forward in enabling the real-world application of harmful meme detection, particularly in situations where a modality is absent.

</details>


### [138] [LightCity: An Urban Dataset for Outdoor Inverse Rendering and Reconstruction under Multi-illumination Conditions](https://arxiv.org/abs/2602.01118)
*Jingjing Wang,Qirui Hu,Chong Bao,Yuke Zhu,Hujun Bao,Zhaopeng Cui,Guofeng Zhang*

Main category: cs.CV

TL;DR: LightCity是一个高质量合成城市数据集，包含多种光照条件和真实间接光/阴影效果，用于基准测试城市环境中的逆渲染任务。


<details>
  <summary>Details</summary>
Motivation: 城市场景逆渲染面临复杂光照条件（多光源、间接光、阴影）的挑战，但由于缺乏合适的数据集，这些挑战对内在分解和3D重建的影响尚未被探索。

Method: 创建了LightCity合成数据集，包含300多个天空贴图、高度可控的光照、街景和航拍视角的5万多张图像，以及深度、法线、材质组件、直接光和间接光等丰富属性。

Result: 提供了包含多样化光照条件和丰富属性的高质量城市数据集，并利用该数据集对城市环境中的三个基本任务进行了基准测试和综合分析。

Conclusion: LightCity数据集为推进城市逆渲染相关研究奠定了坚实基础，有助于解决复杂光照条件下的内在分解和3D重建挑战。

Abstract: Inverse rendering in urban scenes is pivotal for applications like autonomous driving and digital twins. Yet, it faces significant challenges due to complex illumination conditions, including multi-illumination and indirect light and shadow effects. However, the effects of these challenges on intrinsic decomposition and 3D reconstruction have not been explored due to the lack of appropriate datasets. In this paper, we present LightCity, a novel high-quality synthetic urban dataset featuring diverse illumination conditions with realistic indirect light and shadow effects. LightCity encompasses over 300 sky maps with highly controllable illumination, varying scales with street-level and aerial perspectives over 50K images, and rich properties such as depth, normal, material components, light and indirect light, etc. Besides, we leverage LightCity to benchmark three fundamental tasks in the urban environments and conduct a comprehensive analysis of these benchmarks, laying a robust foundation for advancing related research.

</details>


### [139] [Koo-Fu CLIP: Closed-Form Adaptation of Vision-Language Models via Fukunaga-Koontz Linear Discriminant Analysis](https://arxiv.org/abs/2602.01127)
*Matej Suchanek,Klara Janouskova,Ondrej Vasatko,Jiri Matas*

Main category: cs.CV

TL;DR: Koo-Fu CLIP：基于Fukunaga-Koontz线性判别分析的监督CLIP适配方法，通过白化嵌入空间抑制类内变异、增强类间区分，实现线性投影降维，提升分类性能。


<details>
  <summary>Details</summary>
Motivation: CLIP等视觉语言模型提供强大的通用表示，但其原始嵌入在监督分类任务中表现有限：类间分离度不足且维度冗余，需要优化适配。

Method: 提出Koo-Fu CLIP方法，基于Fukunaga-Koontz线性判别分析，在白化嵌入空间中操作，通过闭式线性投影重塑CLIP嵌入几何结构，抑制类内变异、增强类间区分，实现有效降维。

Result: 在ImageNet基准测试中，Koo-Fu CLIP空间中的最近视觉原型分类将ImageNet-1K的top-1准确率从75.1%提升至79.1%，在扩展到14K和21K类时保持稳定增益；支持10-12倍压缩而几乎无精度损失。

Conclusion: Koo-Fu CLIP提供了一种轻量高效的CLIP表示适配方法，通过线性投影改善类可分离性并实现有效降维，适用于大规模分类和检索任务。

Abstract: Visual-language models such as CLIP provide powerful general-purpose representations, but their raw embeddings are not optimized for supervised classification, often exhibiting limited class separation and excessive dimensionality. We propose Koo-Fu CLIP, a supervised CLIP adaptation method based on Fukunaga-Koontz Linear Discriminant Analysis, which operates in a whitened embedding space to suppress within-class variation and enhance between-class discrimination. The resulting closed-form linear projection reshapes the geometry of CLIP embeddings, improving class separability while performing effective dimensionality reduction, and provides a lightweight and efficient adaptation of CLIP representations.
  Across large-scale ImageNet benchmarks, nearest visual prototype classification in the Koo-Fu CLIP space improves top-1 accuracy from 75.1% to 79.1% on ImageNet-1K, with consistent gains persisting as the label space expands to 14K and 21K classes. The method supports substantial compression by up to 10-12x with little or no loss in accuracy, enabling efficient large-scale classification and retrieval.

</details>


### [140] [Improving Robustness of Vision-Language-Action Models by Restoring Corrupted Visual Inputs](https://arxiv.org/abs/2602.01158)
*Daniel Yezid Guarnizo Orjuela,Leonardo Scappatura,Veronica Di Gennaro,Riccardo Andrea Izzo,Gianluca Bardaro,Matteo Matteucci*

Main category: cs.CV

TL;DR: 本文提出CRT（Corruption Restoration Transformer）来解决VLA模型对图像损坏的脆弱性问题，通过对抗训练恢复被损坏的视觉输入，无需微调底层模型。


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型虽然在受控环境中表现良好，但在真实世界部署时对视觉干扰非常脆弱。现有研究主要关注物理遮挡，但图像损坏（传感器级伪影）这一关键问题尚未充分探索，这些损坏会直接影响视觉信号的完整性。

Method: 提出CRT（Corruption Restoration Transformer），这是一个即插即用、模型无关的视觉变换器，通过对抗训练目标从损坏的输入中恢复干净的观察结果，无需对底层模型进行计算昂贵的微调。

Result: 实验表明，最先进的VLA模型（如π₀.₅和SmolVLA）在常见信号伪影下性能从90%成功率骤降至2%。CRT能有效恢复丢失的性能，使VLA即使在严重视觉损坏下也能保持接近基线的成功率。

Conclusion: CRT为解决VLA模型对图像损坏的脆弱性提供了有效解决方案，通过恢复被损坏的视觉输入，显著提升了VLA模型在真实世界环境中的鲁棒性和可靠性。

Abstract: Vision-Language-Action (VLA) models have emerged as a dominant paradigm for generalist robotic manipulation, unifying perception and control within a single end-to-end architecture. However, despite their success in controlled environments, reliable real-world deployment is severely hindered by their fragility to visual disturbances. While existing literature extensively addresses physical occlusions caused by scene geometry, a critical mode remains largely unexplored: image corruptions. These sensor-level artifacts, ranging from electronic noise and dead pixels to lens contaminants, directly compromise the integrity of the visual signal prior to interpretation. In this work, we quantify this vulnerability, demonstrating that state-of-the-art VLAs such as $π_{0.5}$ and SmolVLA, suffer catastrophic performance degradation, dropping from 90\% success rates to as low as 2\%, under common signal artifacts. To mitigate this, we introduce the Corruption Restoration Transformer (CRT), a plug-and-play and model-agnostic vision transformer designed to immunize VLA models against sensor disturbances. Leveraging an adversarial training objective, CRT restores clean observations from corrupted inputs without requiring computationally expensive fine-tuning of the underlying model. Extensive experiments across the LIBERO and Meta-World benchmarks demonstrate that CRT effectively recovers lost performance, enabling VLAs to maintain near-baseline success rates, even under severe visual corruption.

</details>


### [141] [Semantically Aware UAV Landing Site Assessment from Remote Sensing Imagery via Multimodal Large Language Models](https://arxiv.org/abs/2602.01163)
*Chunliang Hua,Zeyuan Yang,Lei Zhang,Jiayang Sun,Fengwen Chen,Chunlan Zeng,Xiao Hu*

Main category: cs.CV

TL;DR: 提出结合遥感影像与多模态大语言模型的无人机紧急降落点评估框架，通过语义分割预筛选和视觉-语言推理检测风险，构建ELSS基准数据集验证效果优于几何方法


<details>
  <summary>Details</summary>
Motivation: 传统几何传感器无法识别复杂语义风险（如人群、临时结构），无人机紧急降落需要全局上下文感知的降落点评估，而不仅仅是平坦地形识别

Method: 采用粗到精的流程：1）轻量级语义分割模块预筛选候选区域；2）视觉-语言推理代理融合视觉特征与POI数据检测细微风险；基于遥感影像和多模态大语言模型

Result: 实验表明该框架在风险识别准确率上显著优于几何基线方法；定性结果证实能生成类人类的可解释理由，增强自动化决策的可信度

Conclusion: 提出的框架能有效识别传统几何方法无法检测的语义风险，构建的ELSS基准数据集公开可用，为无人机紧急降落点选择提供了更可靠的解决方案

Abstract: Safe UAV emergency landing requires more than just identifying flat terrain; it demands understanding complex semantic risks (e.g., crowds, temporary structures) invisible to traditional geometric sensors. In this paper, we propose a novel framework leveraging Remote Sensing (RS) imagery and Multimodal Large Language Models (MLLMs) for global context-aware landing site assessment. Unlike local geometric methods, our approach employs a coarse-to-fine pipeline: first, a lightweight semantic segmentation module efficiently pre-screens candidate areas; second, a vision-language reasoning agent fuses visual features with Point-of-Interest (POI) data to detect subtle hazards. To validate this approach, we construct and release the Emergency Landing Site Selection (ELSS) benchmark. Experiments demonstrate that our framework significantly outperforms geometric baselines in risk identification accuracy. Furthermore, qualitative results confirm its ability to generate human-like, interpretable justifications, enhancing trust in automated decision-making. The benchmark dataset is publicly accessible at https://anonymous.4open.science/r/ELSS-dataset-43D7.

</details>


### [142] [EEmo-Logic: A Unified Dataset and Multi-Stage Framework for Comprehensive Image-Evoked Emotion Assessment](https://arxiv.org/abs/2602.01173)
*Lancheng Gao,Ziheng Jia,Zixuan Xing,Wei Sun,Huiyu Duan,Guangtao Zhai,Xiongkuo Min*

Main category: cs.CV

TL;DR: 该论文提出了EEmoDB，这是目前最大的图像诱发情感理解数据集，包含5个分析维度和5个任务类别，以及EEmo-Logic模型，这是一个通过指令微调和GRPO优化的多模态大语言模型，在情感理解和细粒度评估方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有模型在图像诱发情感理解方面存在局限性，要么只能进行粗粒度的情感感知，要么缺乏推理能力。为了弥合这一差距，需要更全面的数据集和更强大的模型来理解图像的多维情感属性和强度细微差别。

Method: 1. 构建EEmoDB数据集：包含EEmoDB-QA（125k张图像的120万QA对）和EEmoDB-Assess（25k张图像的36k细粒度评估数据）；2. 提出EEmo-Logic模型：通过指令微调和任务定制的组相对偏好优化（GRPO）开发的多模态大语言模型，采用新颖的奖励设计。

Result: EEmo-Logic在领域内和跨领域数据集上都表现出稳健的性能，在情感问答和细粒度评估方面表现优异。模型代码已开源。

Conclusion: EEmoDB是目前最大的图像诱发情感理解数据集，EEmo-Logic模型通过创新的训练方法在情感理解任务上取得了显著进展，为机器共情和人机交互应用提供了有力支持。

Abstract: Understanding the multi-dimensional attributes and intensity nuances of image-evoked emotions is pivotal for advancing machine empathy and empowering diverse human-computer interaction applications. However, existing models are still limited to coarse-grained emotion perception or deficient reasoning capabilities. To bridge this gap, we introduce EEmoDB, the largest image-evoked emotion understanding dataset to date. It features $5$ analysis dimensions spanning $5$ distinct task categories, facilitating comprehensive interpretation. Specifically, we compile $1.2M$ question-answering (QA) pairs (EEmoDB-QA) from $125k$ images via automated generation, alongside a $36k$ dataset (EEmoDB-Assess) curated from $25k$ images for fine-grained assessment. Furthermore, we propose EEmo-Logic, an all-in-one multimodal large language model (MLLM) developed via instruction fine-tuning and task-customized group relative preference optimization (GRPO) with novel reward design. Extensive experiments demonstrate that EEmo-Logic achieves robust performance in in-domain and cross-domain datasets, excelling in emotion QA and fine-grained assessment. The code is available at https://anonymous.4open.science/r/EEmoLogic.

</details>


### [143] [Refining Context-Entangled Content Segmentation via Curriculum Selection and Anti-Curriculum Promotion](https://arxiv.org/abs/2602.01183)
*Chunming He,Rihan Zhang,Fengyang Xiao,Dingming Zhang,Zhiwen Cao,Sina Farsiu*

Main category: cs.CV

TL;DR: CurriSeg：一种结合课程学习和反课程学习的双阶段框架，用于解决上下文纠缠内容分割问题，通过动态样本选择和频谱盲化微调提升模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 受生物学习从易到难渐进过程的启发，针对上下文纠缠内容分割（CECS）这一挑战性任务，传统分割网络主要依赖架构改进而忽视学习动态，需要更有效的学习策略来提升在纠缠数据分布下的鲁棒性。

Method: 提出CurriSeg双阶段学习框架：1）课程选择阶段：基于样本损失的时间统计动态选择训练数据，区分困难但信息丰富的样本与噪声/模糊样本；2）反课程提升阶段：设计频谱盲化微调，抑制高频成分以强制依赖低频结构和上下文线索。

Result: 在多个CECS基准测试中取得一致改进，无需增加参数或总训练时间，证明了课程与反课程原则结合能有效提升分割的鲁棒性和上下文感知能力。

Conclusion: CurriSeg通过统一课程和反课程学习原则，为如何通过渐进和挑战的相互作用来培养鲁棒且上下文感知的分割模型提供了原则性视角，代码将开源。

Abstract: Biological learning proceeds from easy to difficult tasks, gradually reinforcing perception and robustness. Inspired by this principle, we address Context-Entangled Content Segmentation (CECS), a challenging setting where objects share intrinsic visual patterns with their surroundings, as in camouflaged object detection. Conventional segmentation networks predominantly rely on architectural enhancements but often ignore the learning dynamics that govern robustness under entangled data distributions. We introduce CurriSeg, a dual-phase learning framework that unifies curriculum and anti-curriculum principles to improve representation reliability. In the Curriculum Selection phase, CurriSeg dynamically selects training data based on the temporal statistics of sample losses, distinguishing hard-but-informative samples from noisy or ambiguous ones, thus enabling stable capability enhancement. In the Anti-Curriculum Promotion phase, we design Spectral-Blindness Fine-Tuning, which suppresses high-frequency components to enforce dependence on low-frequency structural and contextual cues and thus strengthens generalization. Extensive experiments demonstrate that CurriSeg achieves consistent improvements across diverse CECS benchmarks without adding parameters or increasing total training time, offering a principled view of how progression and challenge interplay to foster robust and context-aware segmentation. Code will be released.

</details>


### [144] [EMFormer: Efficient Multi-Scale Transformer for Accumulative Context Weather Forecasting](https://arxiv.org/abs/2602.01194)
*Hao Chen,Tao Han,Jie Zhang,Song Guo,Fenghua Ling,Lei Bai*

Main category: cs.CV

TL;DR: 提出EMFormer架构和累积上下文微调方法，通过多尺度特征提取和动态损失平衡，显著提升长期天气预报准确性并降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有长期天气预报方法存在灾难性遗忘、误差累积和高训练开销等问题，需要新的解决方案来提升长期上下文建模能力并降低计算成本。

Method: 1) 提出高效多尺度Transformer(EMFormer)，通过单次卷积提取多尺度特征；2) 采用累积上下文微调提升时间一致性；3) 提出正弦加权动态平衡的复合损失函数。

Result: 在天气预报和极端事件预测中表现优异，显著提升长期预测准确性；在视觉基准测试(ImageNet-1K和ADE20K)上展现强泛化能力，相比传统多尺度模块实现5.69倍加速。

Conclusion: 提出的跨预训练、微调和预测的完整管道有效解决了长期天气预报中的关键挑战，在保持准确性的同时大幅降低了计算开销，具有实际应用价值。

Abstract: Long-term weather forecasting is critical for socioeconomic planning and disaster preparedness. While recent approaches employ finetuning to extend prediction horizons, they remain constrained by the issues of catastrophic forgetting, error accumulation, and high training overhead. To address these limitations, we present a novel pipeline across pretraining, finetuning and forecasting to enhance long-context modeling while reducing computational overhead. First, we introduce an Efficient Multi-scale Transformer (EMFormer) to extract multi-scale features through a single convolution in both training and inference. Based on the new architecture, we further employ an accumulative context finetuning to improve temporal consistency without degrading short-term accuracy. Additionally, we propose a composite loss that dynamically balances different terms via a sinusoidal weighting, thereby adaptively guiding the optimization trajectory throughout pretraining and finetuning. Experiments show that our approach achieves strong performance in weather forecasting and extreme event prediction, substantially improving long-term forecast accuracy. Moreover, EMFormer demonstrates strong generalization on vision benchmarks (ImageNet-1K and ADE20K) while delivering a 5.69x speedup over conventional multi-scale modules.

</details>


### [145] [Med3D-R1: Incentivizing Clinical Reasoning in 3D Medical Vision-Language Models for Abnormality Diagnosis](https://arxiv.org/abs/2602.01200)
*Haoran Lai,Zihang Jiang,Kun Zhang,Qingsong Yao,Rongsheng Wang,Zhiyang He,Xiaodong Tao,Wei Wei,Shaohua Kevin Zhou*

Main category: cs.CV

TL;DR: Med3D-R1：一个用于3D医学视觉语言模型的强化学习框架，通过两阶段训练（监督微调和强化学习）提升临床推理能力，在CT-RATE和RAD-ChestCT基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 开发具有稳健临床推理能力的3D视觉语言模型面临挑战：1）体素医学影像的固有复杂性；2）模型容易过拟合表面报告模式；3）缺乏可解释性感知的奖励设计。

Method: 提出Med3D-R1框架，包含两阶段训练：1）监督微调阶段：引入残差对齐机制连接3D特征与文本嵌入，采用异常重新加权策略强调临床信息标记；2）强化学习阶段：重新设计一致性奖励以促进连贯的逐步诊断推理。

Result: 在两个3D诊断基准测试中达到SOTA：CT-RATE上41.92%准确率，RAD-ChestCT上44.99%准确率。结果表明在异常诊断和临床推理方面有改进，优于先前方法。

Conclusion: 该方法有望通过实现更可靠、透明的3D医学视觉语言系统来增强真实世界的诊断工作流程。

Abstract: Developing 3D vision-language models with robust clinical reasoning remains a challenge due to the inherent complexity of volumetric medical imaging, the tendency of models to overfit superficial report patterns, and the lack of interpretability-aware reward designs. In this paper, we propose Med3D-R1, a reinforcement learning framework with a two-stage training process: Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL). During SFT stage, we introduce a residual alignment mechanism to bridge the gap between high-dimensional 3D features and textual embeddings, and an abnormality re-weighting strategy to emphasize clinically informative tokens and reduce structural bias in reports. In RL stage, we redesign the consistency reward to explicitly promote coherent, step-by-step diagnostic reasoning. We evaluate our method on medical multiple-choice visual question answering using two 3D diagnostic benchmarks, CT-RATE and RAD-ChestCT, where our model attains state-of-the-art accuracies of 41.92\% on CT-RATE and 44.99\% on RAD-ChestCT. These results indicate improved abnormality diagnosis and clinical reasoning and outperform prior methods on both benchmarks. Overall, our approach holds promise for enhancing real-world diagnostic workflows by enabling more reliable and transparent 3D medical vision-language systems.

</details>


### [146] [Boosting Point-supervised Temporal Action Localization via Text Refinement and Alignment](https://arxiv.org/abs/2602.01257)
*Yunchuan Ma,Laiyun Qing,Guorong Li,Yuqing Liu,Yuankai Qi,Qingming Huang*

Main category: cs.CV

TL;DR: 提出TRA框架，利用文本特征增强点监督时序动作定位，通过文本精炼和对齐模块提升定位精度。


<details>
  <summary>Details</summary>
Motivation: 当前点监督时序动作定位方法仅考虑视觉特征，忽略了文本侧的语义信息。文本描述包含丰富的语义信息，可以补充视觉特征。

Method: 提出文本精炼与对齐框架：1) 使用预训练多模态模型为视频帧生成描述；2) PTR模块利用点标注和多个预训练模型精炼初始描述；3) PMA模块将所有特征投影到统一语义空间，通过点级多模态特征对比学习减少视觉与语言模态的差距；4) 增强的多模态特征输入动作检测器进行精确定位。

Result: 在五个广泛使用的基准测试上取得了优于多个SOTA方法的性能，计算开销分析表明框架可在单张24GB RTX 3090 GPU上运行，具有实用性和可扩展性。

Conclusion: 提出的TRA框架有效利用文本特征增强点监督时序动作定位，通过文本精炼和对齐模块显著提升性能，同时保持计算效率。

Abstract: Recently, point-supervised temporal action localization has gained significant attention for its effective balance between labeling costs and localization accuracy. However, current methods only consider features from visual inputs, neglecting helpful semantic information from the text side. To address this issue, we propose a Text Refinement and Alignment (TRA) framework that effectively utilizes textual features from visual descriptions to complement the visual features as they are semantically rich. This is achieved by designing two new modules for the original point-supervised framework: a Point-based Text Refinement module (PTR) and a Point-based Multimodal Alignment module (PMA). Specifically, we first generate descriptions for video frames using a pre-trained multimodal model. Next, PTR refines the initial descriptions by leveraging point annotations together with multiple pre-trained models. PMA then projects all features into a unified semantic space and leverages a point-level multimodal feature contrastive learning to reduce the gap between visual and linguistic modalities. Last, the enhanced multi-modal features are fed into the action detector for precise localization. Extensive experimental results on five widely used benchmarks demonstrate the favorable performance of our proposed framework compared to several state-of-the-art methods. Moreover, our computational overhead analysis shows that the framework can run on a single 24 GB RTX 3090 GPU, indicating its practicality and scalability.

</details>


### [147] [OASIS-DC: Generalizable Depth Completion via Output-level Alignment of Sparse-Integrated Monocular Pseudo Depth](https://arxiv.org/abs/2602.01268)
*Jaehyeon Cho,Jhonghyun An*

Main category: cs.CV

TL;DR: 利用单目基础模型的相对深度输出，通过稀疏测距测量校准为伪度量深度先验，再设计细化网络实现少样本下的准确度量深度预测


<details>
  <summary>Details</summary>
Motivation: 当前单目基础模型在零样本深度估计方面表现出色，但其输出是相对深度而非度量深度，限制了在机器人和自动驾驶中的直接应用。需要解决在真实世界标签稀缺情况下实现稳健、可部署的深度补全问题。

Method: 利用相对深度保持全局布局和边界的特性，通过稀疏测距测量校准将其转化为伪度量深度先验。基于此先验设计细化网络，在可靠区域遵循先验，在必要时偏离，从而从极少标注样本中实现准确度量预测。

Result: 该系统在缺乏精心策划验证数据的情况下特别有效，能在少样本场景下保持稳定的尺度和锐利边缘。结果表明，将基础先验与稀疏锚点结合是实现真实世界标签稀缺情况下稳健、可部署深度补全的实用途径。

Conclusion: 通过将单目基础模型的相对深度输出与稀疏测距测量校准相结合，构建伪度量深度先验并设计自适应细化网络，能够在标签稀缺情况下实现准确、稳健的度量深度预测，为机器人和自动驾驶应用提供实用解决方案。

Abstract: Recent monocular foundation models excel at zero-shot depth estimation, yet their outputs are inherently relative rather than metric, limiting direct use in robotics and autonomous driving. We leverage the fact that relative depth preserves global layout and boundaries: by calibrating it with sparse range measurements, we transform it into a pseudo metric depth prior. Building on this prior, we design a refinement network that follows the prior where reliable and deviates where necessary, enabling accurate metric predictions from very few labeled samples. The resulting system is particularly effective when curated validation data are unavailable, sustaining stable scale and sharp edges across few-shot regimes. These findings suggest that coupling foundation priors with sparse anchors is a practical route to robust, deployment-ready depth completion under real-world label scarcity.

</details>


### [148] [Q-DiT4SR: Exploration of Detail-Preserving Diffusion Transformer Quantization for Real-World Image Super-Resolution](https://arxiv.org/abs/2602.01273)
*Xun Zhang,Kaicheng Yang,Hongliang Lu,Haotong Qin,Yong Guo,Yulun Zhang*

Main category: cs.CV

TL;DR: 提出了Q-DiT4SR，首个专门为基于DiT的真实世界图像超分辨率设计的后训练量化框架，通过层次SVD和方差感知混合精度分配，在W4A4配置下实现5.8倍模型压缩和60倍计算加速。


<details>
  <summary>Details</summary>
Motivation: 扩散变换器(DiTs)在真实世界图像超分辨率中能生成高质量纹理，但推理负担重阻碍实际部署。现有量化方法主要针对U-Net架构或文本到图像任务的通用DiT量化，直接应用于DiT超分辨率模型会导致局部纹理严重退化。

Method: 提出Q-DiT4SR框架：1) H-SVD层次SVD，集成全局低秩分支和局部块级秩1分支；2) 方差感知时空混合精度：VaSMP基于率失真理论数据自由分配跨层权重比特宽度，VaTMP通过动态规划调度扩散时间步的层内激活精度。

Result: 在多个真实世界数据集上，Q-DiT4SR在W4A6和W4A4设置下均达到SOTA性能。W4A4量化配置实现5.8倍模型大小压缩和超过60倍计算操作减少。

Conclusion: Q-DiT4SR是首个专门为DiT超分辨率设计的PTQ框架，通过创新的量化策略在保持纹理质量的同时显著加速推理，为真实世界部署提供了实用解决方案。

Abstract: Recently, Diffusion Transformers (DiTs) have emerged in Real-World Image Super-Resolution (Real-ISR) to generate high-quality textures, yet their heavy inference burden hinders real-world deployment. While Post-Training Quantization (PTQ) is a promising solution for acceleration, existing methods in super-resolution mostly focus on U-Net architectures, whereas generic DiT quantization is typically designed for text-to-image tasks. Directly applying these methods to DiT-based super-resolution models leads to severe degradation of local textures. Therefore, we propose Q-DiT4SR, the first PTQ framework specifically tailored for DiT-based Real-ISR. We propose H-SVD, a hierarchical SVD that integrates a global low-rank branch with a local block-wise rank-1 branch under a matched parameter budget. We further propose Variance-aware Spatio-Temporal Mixed Precision: VaSMP allocates cross-layer weight bit-widths in a data-free manner based on rate-distortion theory, while VaTMP schedules intra-layer activation precision across diffusion timesteps via dynamic programming (DP) with minimal calibration. Experiments on multiple real-world datasets demonstrate that our Q-DiT4SR achieves SOTA performance under both W4A6 and W4A4 settings. Notably, the W4A4 quantization configuration reduces model size by 5.8$\times$ and computational operations by over 60$\times$. Our code and models will be available at https://github.com/xunzhang1128/Q-DiT4SR.

</details>


### [149] [TF-Lane: Traffic Flow Module for Robust Lane Perception](https://arxiv.org/abs/2602.01277)
*Yihan Xie,Han Xia,Zhen Yang*

Main category: cs.CV

TL;DR: 提出TFM模块，利用实时交通流信息增强车道感知，在遮挡或车道缺失场景下提升自动驾驶系统的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉的车道检测方法在遮挡或车道缺失场景下性能显著下降，而使用高精地图作为补充信息存在订阅成本高和实时性有限的问题。

Method: 提出交通流感知车道感知模块(TFM)，有效提取实时交通流特征，并将其与现有车道感知算法无缝集成。

Result: 在四个主流模型和两个公开数据集(Nuscenes和OpenLaneV2)上的实验表明，TFM能持续提升性能，在Nuscenes数据集上最高获得+4.1% mAP增益。

Conclusion: TFM通过利用实时交通流信息作为补充特征，有效解决了视觉传感器在遮挡场景下的局限性，为自动驾驶车道感知提供了经济高效的增强方案。

Abstract: Autonomous driving systems require robust lane perception capabilities, yet existing vision-based detection methods suffer significant performance degradation when visual sensors provide insufficient cues, such as in occluded or lane-missing scenarios. While some approaches incorporate high-definition maps as supplementary information, these solutions face challenges of high subscription costs and limited real-time performance. To address these limitations, we explore an innovative information source: traffic flow, which offers real-time capabilities without additional costs. This paper proposes a TrafficFlow-aware Lane perception Module (TFM) that effectively extracts real-time traffic flow features and seamlessly integrates them with existing lane perception algorithms. This solution originated from real-world autonomous driving conditions and was subsequently validated on open-source algorithms and datasets. Extensive experiments on four mainstream models and two public datasets (Nuscenes and OpenLaneV2) using standard evaluation metrics show that TFM consistently improves performance, achieving up to +4.1% mAP gain on the Nuscenes dataset.

</details>


### [150] [DSFC-Net: A Dual-Encoder Spatial and Frequency Co-Awareness Network for Rural Road Extraction](https://arxiv.org/abs/2602.01278)
*Zhengbo Zhang,Yihe Tian,Wanke Xia,Lin Chen,Yue Sun,Kun Ding,Ying Wang,Bing Xu,Shiming Xiang*

Main category: cs.CV

TL;DR: DSFC-Net：一种用于农村道路提取的双编码器网络，通过融合空间和频域信息解决农村道路特有的挑战，包括高类内变异、植被遮挡和狭窄道路等问题。


<details>
  <summary>Details</summary>
Motivation: 农村道路提取面临独特挑战：道路表面材料多样导致类内变异大、类间区分度低；植被遮挡频繁破坏空间连续性；道路狭窄加剧检测难度。现有方法主要针对结构化城市环境优化，在农村场景中表现不佳。

Method: 提出DSFC-Net双编码器框架：1) CNN分支捕捉细粒度局部道路边界和短程连续性；2) 新颖的空间-频率混合变换器(SFT)通过交叉频率交互注意力(CFIA)模块，使用拉普拉斯金字塔策略显式解耦高低频信息，建模全局拓扑依赖；3) 通道特征融合模块(CFFM)自适应重新校准通道特征响应，无缝整合局部纹理和全局语义。

Result: 在WHU-RuR+、DeepGlobe和Massachusetts数据集上的综合实验验证了DSFC-Net优于现有最先进方法。

Conclusion: DSFC-Net通过协同融合空间和频域信息，有效解决了农村道路提取的独特挑战，在保持狭窄道路连通性方面表现出色，为农村基础设施规划和可持续发展提供了准确的道路提取解决方案。

Abstract: Accurate extraction of rural roads from high-resolution remote sensing imagery is essential for infrastructure planning and sustainable development. However, this task presents unique challenges in rural settings due to several factors. These include high intra-class variability and low inter-class separability from diverse surface materials, frequent vegetation occlusions that disrupt spatial continuity, and narrow road widths that exacerbate detection difficulties. Existing methods, primarily optimized for structured urban environments, often underperform in these scenarios as they overlook such distinctive characteristics. To address these challenges, we propose DSFC-Net, a dual-encoder framework that synergistically fuses spatial and frequency-domain information. Specifically, a CNN branch is employed to capture fine-grained local road boundaries and short-range continuity, while a novel Spatial-Frequency Hybrid Transformer (SFT) is introduced to robustly model global topological dependencies against vegetation occlusions. Distinct from standard attention mechanisms that suffer from frequency bias, the SFT incorporates a Cross-Frequency Interaction Attention (CFIA) module that explicitly decouples high- and low-frequency information via a Laplacian Pyramid strategy. This design enables the dynamic interaction between spatial details and frequency-aware global contexts, effectively preserving the connectivity of narrow roads. Furthermore, a Channel Feature Fusion Module (CFFM) is proposed to bridge the two branches by adaptively recalibrating channel-wise feature responses, seamlessly integrating local textures with global semantics for accurate segmentation. Comprehensive experiments on the WHU-RuR+, DeepGlobe, and Massachusetts datasets validate the superiority of DSFC-Net over state-of-the-art approaches.

</details>


### [151] [Who Transfers Safety? Identifying and Targeting Cross-Lingual Shared Safety Neurons](https://arxiv.org/abs/2602.01283)
*Xianhui Zhang,Chengyu Xie,Linxia Zhu,Yonghui Yang,Weixiang Zhao,Zifeng Cheng,Cong Wang,Fei Shen,Tat-Seng Chua*

Main category: cs.CV

TL;DR: 论文发现LLMs中存在跨语言共享的安全神经元(SS-Neurons)，这个小而关键的神经元子集共同调节跨语言安全行为。通过针对这些神经元的训练策略，可以显著提升非高资源语言的安全性。


<details>
  <summary>Details</summary>
Motivation: 多语言安全性存在显著不平衡，非高资源语言的安全性远弱于高资源语言。同时，尽管观察到跨语言表示迁移，但安全对齐的神经机制仍不清楚。

Method: 首先识别单语言安全神经元(MS-Neurons)并验证其在安全拒绝行为中的因果作用。然后通过跨语言分析识别SS-Neurons作为MS-Neurons在高资源和非高资源语言间的共享子集。基于此提出针对SS-Neurons的神经元导向训练策略。

Result: 抑制SS-Neurons会导致非高资源语言安全性同时下降，而增强它们能提高跨语言防御一致性。针对这一小神经元子集的微调优于现有方法，显著提升非高资源语言安全性，同时保持模型通用能力。

Conclusion: LLMs中存在跨语言共享的安全神经元子集，这些神经元作为桥梁将安全能力从高资源语言转移到非高资源语言。针对这些神经元的训练策略能有效解决多语言安全不平衡问题。

Abstract: Multilingual safety remains significantly imbalanced, leaving non-high-resource (NHR) languages vulnerable compared to robust high-resource (HR) ones. Moreover, the neural mechanisms driving safety alignment remain unclear despite observed cross-lingual representation transfer.
  In this paper, we find that LLMs contain a set of cross-lingual shared safety neurons (SS-Neurons), a remarkably small yet critical neuronal subset that jointly regulates safety behavior across languages.
  We first identify monolingual safety neurons (MS-Neurons) and validate their causal role in safety refusal behavior through targeted activation and suppression.
  Our cross-lingual analyses then identify SS-Neurons as the subset of MS-Neurons shared between HR and NHR languages, serving as a bridge to transfer safety capabilities from HR to NHR domains.
  We observe that suppressing these neurons causes concurrent safety drops across NHR languages, whereas reinforcing them improves cross-lingual defensive consistency.
  Building on these insights, we propose a simple neuron-oriented training strategy that targets SS-Neurons based on language resource distribution and model architecture. Experiments demonstrate that fine-tuning this tiny neuronal subset outperforms state-of-the-art methods, significantly enhancing NHR safety while maintaining the model's general capabilities.
  The code and dataset will be available athttps://github.com/1518630367/SS-Neuron-Expansion.

</details>


### [152] [Interacted Planes Reveal 3D Line Mapping](https://arxiv.org/abs/2602.01296)
*Zeran Ke,Bin Tan,Gui-Song Xia,Yujun Shen,Nan Xue*

Main category: cs.CV

TL;DR: LiP-Map 是一个联合优化线和平面的3D重建框架，通过显式建模可学习的线和平面基元，实现准确详细的3D线映射，在多个数据集上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 从物理和拓扑角度研究3D线映射问题：3D线最自然地作为有限3D平面块的边缘出现。现有方法缺乏对线-平面关系的显式建模，限制了在人工环境中的结构化重建能力。

Method: 提出LiP-Map框架，显式建模可学习的线和平面基元，通过构建平面和线基元之间的相互作用，将平面拓扑集成到3D线映射中，而不是施加成对共面约束。

Result: 在ScanNetV2、ScanNet++、Hypersim、7Scenes和Tanks&Temple等100多个场景上，LiP-Map在准确性和完整性方面均优于最先进方法。同时显著提升了线辅助的视觉定位性能，在7Scenes上表现优异。

Conclusion: LiP-Map通过线-平面联合优化框架，为人工环境中的结构化重建提供了原则性途径，实现了高效（每场景3-5分钟）且高质量的3D线映射，推动了线辅助视觉定位的发展。

Abstract: 3D line mapping from multi-view RGB images provides a compact and structured visual representation of scenes. We study the problem from a physical and topological perspective: a 3D line most naturally emerges as the edge of a finite 3D planar patch. We present LiP-Map, a line-plane joint optimization framework that explicitly models learnable line and planar primitives. This coupling enables accurate and detailed 3D line mapping while maintaining strong efficiency (typically completing a reconstruction in 3 to 5 minutes per scene). LiP-Map pioneers the integration of planar topology into 3D line mapping, not by imposing pairwise coplanarity constraints but by explicitly constructing interactions between plane and line primitives, thus offering a principled route toward structured reconstruction in man-made environments. On more than 100 scenes from ScanNetV2, ScanNet++, Hypersim, 7Scenes, and Tanks\&Temple, LiP-Map improves both accuracy and completeness over state-of-the-art methods. Beyond line mapping quality, LiP-Map significantly advances line-assisted visual localization, establishing strong performance on 7Scenes. Our code is released at https://github.com/calmke/LiPMAP for reproducible research.

</details>


### [153] [Interaction-Consistent Object Removal via MLLM-Based Reasoning](https://arxiv.org/abs/2602.01298)
*Ching-Kai Huang,Wen-Chieh Lin,Yan-Cen Lee*

Main category: cs.CV

TL;DR: 提出ICOR问题：图像中移除目标物体时需同时移除相关的交互元素，并提出REORM框架利用多模态大语言模型推理需要联合移除的元素


<details>
  <summary>Details</summary>
Motivation: 现有图像物体移除方法通常只移除指定目标，但忽略了目标与其他元素之间的交互关系，导致结果语义不一致。需要解决交互一致性的物体移除问题

Method: 提出REORM框架：1) 使用多模态大语言模型分析图像，推理需要联合移除的交互元素；2) 模块化设计包含MLLM驱动分析、掩码引导移除和自校正机制；3) 提供本地部署版本支持有限资源下的精确编辑

Result: 在ICOREval基准测试中，REORM超越了最先进的图像编辑系统，证明其在产生交互一致性结果方面的有效性

Conclusion: ICOR问题需要同时移除目标物体及其相关交互元素，REORM框架通过多模态大语言模型的推理能力有效解决了这一问题，为交互一致的图像编辑提供了新方法

Abstract: Image-based object removal often erases only the named target, leaving behind interaction evidence that renders the result semantically inconsistent. We formalize this problem as Interaction-Consistent Object Removal (ICOR), which requires removing not only the target object but also associated interaction elements, such as lighting-dependent effects, physically connected objects, targetproduced elements, and contextually linked objects. To address this task, we propose Reasoning-Enhanced Object Removal with MLLM (REORM), a reasoningenhanced object removal framework that leverages multimodal large language models to infer which elements must be jointly removed. REORM features a modular design that integrates MLLM-driven analysis, mask-guided removal, and a self-correction mechanism, along with a local-deployment variant that supports accurate editing under limited resources. To support evaluation, we introduce ICOREval, a benchmark consisting of instruction-driven removals with rich interaction dependencies. On ICOREval, REORM outperforms state-of-the-art image editing systems, demonstrating its effectiveness in producing interactionconsistent results.

</details>


### [154] [ReDiStory: Region-Disentangled Diffusion for Consistent Visual Story Generation](https://arxiv.org/abs/2602.01303)
*Ayushman Sarkar,Zhenyu Yu,Chu Chen,Wei Tang,Kangning Cui,Mohd Yamani Idna Idris*

Main category: cs.CV

TL;DR: ReDiStory：通过推理时提示嵌入重组改进多帧故事生成的训练免费框架，减少帧间语义干扰，提升身份一致性


<details>
  <summary>Details</summary>
Motivation: 生成连贯视觉故事需要在多张图像中保持主体身份同时保留帧特定语义。现有训练免费方法将身份和帧提示连接为统一表示，但在复杂故事中常引入帧间语义干扰，削弱身份保持能力。

Method: 提出ReDiStory框架，在推理时明确将文本嵌入分解为身份相关和帧特定组件，然后通过抑制跨帧共享方向来去相关帧嵌入，减少交叉帧干扰，无需修改扩散参数或额外监督。

Result: 在相同扩散骨干和推理设置下，ReDiStory在ConsiStory+基准测试中相比1Prompt1Story在多个身份一致性指标上获得一致提升，改善身份一致性同时保持提示保真度。

Conclusion: ReDiStory通过推理时提示嵌入重组有效减少多帧故事生成中的跨帧语义干扰，在保持提示保真度的同时显著提升身份一致性，为训练免费的故事生成方法提供了新思路。

Abstract: Generating coherent visual stories requires maintaining subject identity across multiple images while preserving frame-specific semantics. Recent training-free methods concatenate identity and frame prompts into a unified representation, but this often introduces inter-frame semantic interference that weakens identity preservation in complex stories. We propose ReDiStory, a training-free framework that improves multi-frame story generation via inference-time prompt embedding reorganization. ReDiStory explicitly decomposes text embeddings into identity-related and frame-specific components, then decorrelates frame embeddings by suppressing shared directions across frames. This reduces cross-frame interference without modifying diffusion parameters or requiring additional supervision. Under identical diffusion backbones and inference settings, ReDiStory improves identity consistency while maintaining prompt fidelity. Experiments on the ConsiStory+ benchmark show consistent gains over 1Prompt1Story on multiple identity consistency metrics. Code is available at: https://github.com/YuZhenyuLindy/ReDiStory

</details>


### [155] [StoryState: Agent-Based State Control for Consistent and Editable Storybooks](https://arxiv.org/abs/2602.01305)
*Ayushman Sarkar,Zhenyu Yu,Wei Tang,Chu Chen,Kangning Cui,Mohd Yamani Idna Idris*

Main category: cs.CV

TL;DR: StoryState是一个基于代理的编排层，为无训练文本到图像生成引入可编辑的显式故事状态，通过结构化对象表示故事，提升多页编辑的局部性、一致性和效率。


<details>
  <summary>Details</summary>
Motivation: 当前多模态模型支持一键生成故事书，但故事状态（角色、世界设定、页面对象）是隐式的，导致编辑粒度粗、容易破坏视觉一致性，需要更好的编辑控制机制。

Method: 引入StoryState编排层，将故事表示为结构化对象（角色表、全局设置、页面场景约束），使用少量LLM代理维护状态并生成1Prompt1Story风格的提示，纯提示操作，模型无关。

Result: 在多页编辑任务中，StoryState支持局部页面编辑，提升跨页一致性，减少意外更改、交互轮次和编辑时间，接近Gemini Storybook的一次性一致性效果。

Conclusion: StoryState通过显式故事状态和代理编排，显著改善了多页故事生成的编辑控制、一致性和效率，为训练免费文本到图像生成提供了实用的结构化解决方案。

Abstract: Large multimodal models have enabled one-click storybook generation, where users provide a short description and receive a multi-page illustrated story. However, the underlying story state, such as characters, world settings, and page-level objects, remains implicit, making edits coarse-grained and often breaking visual consistency. We present StoryState, an agent-based orchestration layer that introduces an explicit and editable story state on top of training-free text-to-image generation. StoryState represents each story as a structured object composed of a character sheet, global settings, and per-page scene constraints, and employs a small set of LLM agents to maintain this state and derive 1Prompt1Story-style prompts for generation and editing. Operating purely through prompts, StoryState is model-agnostic and compatible with diverse generation backends. System-level experiments on multi-page editing tasks show that StoryState enables localized page edits, improves cross-page consistency, and reduces unintended changes, interaction turns, and editing time compared to 1Prompt1Story, while approaching the one-shot consistency of Gemini Storybook. Code is available at https://github.com/YuZhenyuLindy/StoryState

</details>


### [156] [DeCorStory: Gram-Schmidt Prompt Embedding Decorrelation for Consistent Storytelling](https://arxiv.org/abs/2602.01306)
*Ayushman Sarkar,Zhenyu Yu,Mohd Yamani Idna Idris*

Main category: cs.CV

TL;DR: DeCorStory：一种无需训练的推理时框架，通过提示嵌入去相关减少跨帧语义干扰，提升文本到图像故事生成的视觉和语义一致性


<details>
  <summary>Details</summary>
Motivation: 现有无需训练的方法（如One-Prompt-One-Story）将所有提示串联成单一序列，导致强嵌入相关性，引起颜色泄漏、背景混合和身份漂移等问题，需要解决跨帧语义干扰问题

Method: 使用Gram-Schmidt提示嵌入去相关正交化帧级语义，然后通过奇异值重加权增强提示特定信息，并结合身份保持交叉注意力在扩散过程中稳定角色身份

Result: 实验显示在提示-图像对齐、身份一致性和视觉多样性方面均有持续改进，在无需训练的基线方法中达到最先进性能

Conclusion: DeCorStory无需模型修改或微调，可无缝集成到现有扩散管道中，有效解决文本到图像故事生成中的跨帧语义干扰问题

Abstract: Maintaining visual and semantic consistency across frames is a key challenge in text-to-image storytelling. Existing training-free methods, such as One-Prompt-One-Story, concatenate all prompts into a single sequence, which often induces strong embedding correlation and leads to color leakage, background blending, and identity drift. We propose DeCorStory, a training-free inference-time framework that explicitly reduces inter-frame semantic interference. DeCorStory applies Gram-Schmidt prompt embedding decorrelation to orthogonalize frame-level semantics, followed by singular value reweighting to strengthen prompt-specific information and identity-preserving cross-attention to stabilize character identity during diffusion. The method requires no model modification or fine-tuning and can be seamlessly integrated into existing diffusion pipelines. Experiments demonstrate consistent improvements in prompt-image alignment, identity consistency, and visual diversity, achieving state-of-the-art performance among training-free baselines. Code is available at: https://github.com/YuZhenyuLindy/DeCorStory

</details>


### [157] [FlowCast: Trajectory Forecasting for Scalable Zero-Cost Speculative Flow Matching](https://arxiv.org/abs/2602.01329)
*Divya Jyoti Bajpai,Shubham Agarwal,Apoorv Saxena,Kuldeep Kulkarni,Subrata Mitra,Manjesh Kumar Hanawal*

Main category: cs.CV

TL;DR: FlowCast是一种无需训练、即插即用的推测生成框架，通过利用流匹配模型保持恒定速度的特性，在稳定区域跳过冗余步骤，实现2.5倍以上的加速，且不损失生成质量。


<details>
  <summary>Details</summary>
Motivation: 流匹配（FM）模型在视觉生成方面表现出色，但推理速度过慢（需要大量去噪步骤），限制了其在实时或交互应用中的使用。现有加速方法（如蒸馏、截断或一致性训练）要么降低质量，要么需要昂贵重训练，要么缺乏泛化性。

Method: FlowCast利用FM模型训练时保持恒定速度的特性，通过外推当前速度来推测未来速度（不增加时间成本），如果均方误差在阈值内则接受该推测。这种恒定速度预测允许在稳定区域激进跳过冗余步骤，同时在复杂区域保持精度。该框架无需训练、即插即用，可与任何FM模型无缝集成。

Result: FlowCast在图像生成、视频生成和编辑任务中实现了超过2.5倍的加速，优于现有基线方法，且与标准完整生成相比没有质量损失。论文还提供了理论分析，界定了推测轨迹与完整FM轨迹之间的最坏情况偏差。

Conclusion: FlowCast是一种有效的训练免费加速框架，通过利用FM模型的恒定速度特性实现显著加速，同时保持生成质量，为实时应用提供了实用解决方案。

Abstract: Flow Matching (FM) has recently emerged as a powerful approach for high-quality visual generation. However, their prohibitively slow inference due to a large number of denoising steps limits their potential use in real-time or interactive applications. Existing acceleration methods, like distillation, truncation, or consistency training, either degrade quality, incur costly retraining, or lack generalization. We propose FlowCast, a training-free speculative generation framework that accelerates inference by exploiting the fact that FM models are trained to preserve constant velocity. FlowCast speculates future velocity by extrapolating current velocity without incurring additional time cost, and accepts it if it is within a mean-squared error threshold. This constant-velocity forecasting allows redundant steps in stable regions to be aggressively skipped while retaining precision in complex ones. FlowCast is a plug-and-play framework that integrates seamlessly with any FM model and requires no auxiliary networks. We also present a theoretical analysis and bound the worst-case deviation between speculative and full FM trajectories. Empirical evaluations demonstrate that FlowCast achieves $>2.5\times$ speedup in image generation, video generation, and editing tasks, outperforming existing baselines with no quality loss as compared to standard full generation.

</details>


### [158] [What Does Vision Tool-Use Reinforcement Learning Really Learn? Disentangling Tool-Induced and Intrinsic Effects for Crop-and-Zoom](https://arxiv.org/abs/2602.01334)
*Yan Ma,Weiyu Zhang,Tianle Li,Linge Du,Xuyang Shen,Pengfei Liu*

Main category: cs.CV

TL;DR: MED框架分析发现，当前视觉工具使用强化学习主要是学习与工具安全共存，而非真正掌握工具，性能提升主要来自模型内在能力改进而非工具使用能力提升。


<details>
  <summary>Details</summary>
Motivation: 当前视觉工具使用强化学习（如裁剪缩放等操作）虽然能带来性能提升，但不清楚这些提升是来自工具使用能力的改进还是模型内在能力的演化。需要一种方法来解耦这两种效应。

Method: 提出MED（测量-解释-诊断）框架：1）粗粒度分离内在能力变化与工具诱导效应；2）将工具诱导的性能差异分解为增益和损害项；3）探究驱动这些项演化的机制。在两个具有不同工具先验的VLM和六个基准上进行了检查点级分析。

Result: 发现性能改进主要由内在学习主导，工具使用RL主要减少工具诱导的损害（如减少调用错误和减弱工具模式干扰），在基于工具纠正内在失败方面进展有限。当前视觉工具使用RL主要是学习与工具安全共存而非掌握工具。

Conclusion: 当前视觉工具使用强化学习更多是学习如何与工具安全共存，而非真正掌握工具使用。性能提升主要来自模型内在能力的改进，工具使用RL主要作用是减少工具带来的负面影响。

Abstract: Vision tool-use reinforcement learning (RL) can equip vision-language models with visual operators such as crop-and-zoom and achieves strong performance gains, yet it remains unclear whether these gains are driven by improvements in tool use or evolving intrinsic capabilities.We introduce MED (Measure-Explain-Diagnose), a coarse-to-fine framework that disentangles intrinsic capability changes from tool-induced effects, decomposes the tool-induced performance difference into gain and harm terms, and probes the mechanisms driving their evolution. Across checkpoint-level analyses on two VLMs with different tool priors and six benchmarks, we find that improvements are dominated by intrinsic learning, while tool-use RL mainly reduces tool-induced harm (e.g., fewer call-induced errors and weaker tool schema interference) and yields limited progress in tool-based correction of intrinsic failures. Overall, current vision tool-use RL learns to coexist safely with tools rather than master them.

</details>


### [159] [Beyond Pixels: Visual Metaphor Transfer via Schema-Driven Agentic Reasoning](https://arxiv.org/abs/2602.01335)
*Yu Xu,Yuxin Zhang,Juan Cao,Lin Gao,Chunyu Wang,Oliver Deussen,Tong-Yee Lee,Fan Tang*

Main category: cs.CV

TL;DR: 提出视觉隐喻迁移任务(VMT)，通过多智能体框架实现从参考图像中解耦"创意本质"并重新实例化到目标主体的抽象逻辑，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有生成AI模型局限于像素级指令对齐和表面外观保持，无法捕捉隐喻生成所需的抽象逻辑，需要解决视觉隐喻的创造性生成问题。

Method: 提出认知启发的多智能体框架，基于概念融合理论(CBT)和模式语法(G)，通过感知、迁移、生成和诊断四个智能体协作实现视觉隐喻迁移。

Result: 实验和人工评估表明，该方法在隐喻一致性、类比适当性和视觉创造性方面显著优于现有最先进基线方法。

Conclusion: 该方法为广告和媒体领域的自动化高影响力创意应用铺平了道路，实现了真正的视觉隐喻生成能力。

Abstract: A visual metaphor constitutes a high-order form of human creativity, employing cross-domain semantic fusion to transform abstract concepts into impactful visual rhetoric. Despite the remarkable progress of generative AI, existing models remain largely confined to pixel-level instruction alignment and surface-level appearance preservation, failing to capture the underlying abstract logic necessary for genuine metaphorical generation. To bridge this gap, we introduce the task of Visual Metaphor Transfer (VMT), which challenges models to autonomously decouple the "creative essence" from a reference image and re-materialize that abstract logic onto a user-specified target subject. We propose a cognitive-inspired, multi-agent framework that operationalizes Conceptual Blending Theory (CBT) through a novel Schema Grammar ("G"). This structured representation decouples relational invariants from specific visual entities, providing a rigorous foundation for cross-domain logic re-instantiation. Our pipeline executes VMT through a collaborative system of specialized agents: a perception agent that distills the reference into a schema, a transfer agent that maintains generic space invariance to discover apt carriers, a generation agent for high-fidelity synthesis and a hierarchical diagnostic agent that mimics a professional critic, performing closed-loop backtracking to identify and rectify errors across abstract logic, component selection, and prompt encoding. Extensive experiments and human evaluations demonstrate that our method significantly outperforms SOTA baselines in metaphor consistency, analogy appropriateness, and visual creativity, paving the way for automated high-impact creative applications in advertising and media. Source code will be made publicly available.

</details>


### [160] [MTC-VAE: Multi-Level Temporal Compression with Content Awareness](https://arxiv.org/abs/2602.01340)
*Yubo Dong,Linchao Zhu*

Main category: cs.CV

TL;DR: 提出一种将固定压缩率VAE转换为支持多级时间压缩模型的技术，通过简单微调解决高压缩率下的性能下降问题，并探索了与扩散模型的集成。


<details>
  <summary>Details</summary>
Motivation: 对于连续变分自编码器（VAEs），实现更高压缩率是可取的，但当添加额外采样层而不扩展隐藏通道维度时，效率会显著下降。需要一种方法来提升高压缩率下的性能。

Method: 提出一种技术将固定压缩率VAE转换为支持多级时间压缩的模型，提供简单的最小微调方法来对抗高压缩率下的性能下降。研究了不同压缩级别对视频片段性能的影响，并探索了多级时间压缩VAE与扩散模型（DiT）的集成。

Result: 提供了关于所提方法有效性的实证证据，展示了多级时间压缩VAE与扩散模型框架的成功并发训练和兼容性。

Conclusion: 这项研究展示了多级时间压缩的潜在应用，为视频压缩和生成模型提供了新的技术方向。

Abstract: Latent Video Diffusion Models (LVDMs) rely on Variational Autoencoders (VAEs) to compress videos into compact latent representations. For continuous Variational Autoencoders (VAEs), achieving higher compression rates is desirable; yet, the efficiency notably declines when extra sampling layers are added without expanding the dimensions of hidden channels. In this paper, we present a technique to convert fixed compression rate VAEs into models that support multi-level temporal compression, providing a straightforward and minimal fine-tuning approach to counteract performance decline at elevated compression rates.Moreover, we examine how varying compression levels impact model performance over video segments with diverse characteristics, offering empirical evidence on the effectiveness of our proposed approach. We also investigate the integration of our multi-level temporal compression VAE with diffusion-based generative models, DiT, highlighting successful concurrent training and compatibility within these frameworks. This investigation illustrates the potential uses of multi-level temporal compression.

</details>


### [161] [Adaptive Visual Autoregressive Acceleration via Dual-Linkage Entropy Analysis](https://arxiv.org/abs/2602.01345)
*Yu Zhang,Jingyi Liu,Feng Liu,Duoqian Miao,Qi Zhang,Kexue Fu,Changwei Wang,Longbing Cao*

Main category: cs.CV

TL;DR: NOVA是一个基于熵分析的无训练token缩减加速框架，用于视觉自回归模型，通过自适应识别尺度熵增长拐点来动态确定token缩减比例，加速推理同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有VAR token缩减方法存在三个关键限制：启发式阶段划分、非自适应调度和有限加速范围，未能充分利用加速潜力。熵变化能反映预测不确定性的转变，为捕捉建模动态演化提供了原则性度量。

Method: 通过在线识别尺度熵增长拐点自适应确定加速激活尺度；通过尺度链接和层链接比例调整，动态计算每个尺度和层的不同token缩减比例；剪枝低熵token，重用先前尺度残差的缓存来加速推理。

Result: 大量实验和分析验证了NOVA作为一个简单而有效的无训练加速框架的有效性。

Conclusion: NOVA通过熵分析实现了VAR模型的无训练token缩减加速，自适应地处理建模动态演化，在加速推理的同时保持了生成质量。

Abstract: Visual AutoRegressive modeling (VAR) suffers from substantial computational cost due to the massive token count involved. Failing to account for the continuous evolution of modeling dynamics, existing VAR token reduction methods face three key limitations: heuristic stage partition, non-adaptive schedules, and limited acceleration scope, thereby leaving significant acceleration potential untapped. Since entropy variation intrinsically reflects the transition of predictive uncertainty, it offers a principled measure to capture modeling dynamics evolution. Therefore, we propose NOVA, a training-free token reduction acceleration framework for VAR models via entropy analysis. NOVA adaptively determines the acceleration activation scale during inference by online identifying the inflection point of scale entropy growth. Through scale-linkage and layer-linkage ratio adjustment, NOVA dynamically computes distinct token reduction ratios for each scale and layer, pruning low-entropy tokens while reusing the cache derived from the residuals at the prior scale to accelerate inference and maintain generation quality. Extensive experiments and analyses validate NOVA as a simple yet effective training-free acceleration framework.

</details>


### [162] [T2M Mamba: Motion Periodicity-Saliency Coupling Approach for Stable Text-Driven Motion Generation](https://arxiv.org/abs/2602.01352)
*Xingzu Zhan,Chen Xie,Honghang Chen,Yixun Lin,Xiaochun Mai*

Main category: cs.CV

TL;DR: 本文提出T2M Mamba模型，通过周期-显著性感知Mamba模块和周期性差分跨模态对齐模块，解决现有文本到运动生成模型在长序列生成和语义等价表达鲁棒性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有文本到运动生成模型存在两个核心局限：1) 将运动周期性和关键帧显著性视为独立因素，忽略了它们的耦合关系，导致长序列生成漂移；2) 对语义等价表达（同义词替换）脆弱，微小的文本嵌入变化会传播到解码器，产生不稳定或错误的运动。

Method: 提出T2M Mamba模型，包含两个核心组件：1) 周期-显著性感知Mamba模块，通过增强的密度峰值聚类进行关键帧权重估计，通过FFT加速自相关进行运动周期性估计，以最小计算开销捕获耦合动态；2) 周期性差分跨模态对齐模块(PDCAM)，增强文本和运动嵌入的鲁棒对齐。

Result: 在HumanML3D和KIT-ML数据集上的广泛实验证实了方法的有效性，实现了0.068的FID分数，并在所有其他指标上取得一致增益。

Conclusion: T2M Mamba通过有效建模运动周期性和关键帧显著性的耦合关系，并增强跨模态对齐的鲁棒性，显著提升了文本到运动生成的性能，特别是在长序列生成和语义等价表达处理方面。

Abstract: Text-to-motion generation, which converts motion language descriptions into coherent 3D human motion sequences, has attracted increasing attention in fields, such as avatar animation and humanoid robotic interaction. Though existing models have achieved significant fidelity, they still suffer from two core limitations: (i) They treat motion periodicity and keyframe saliency as independent factors, overlooking their coupling and causing generation drift in long sequences. (ii) They are fragile to semantically equivalent paraphrases, where minor synonym substitutions distort textual embeddings, propagating through the decoder and producing unstable or erroneous motions. In this work, we propose T2M Mamba to address these limitations by (i) proposing Periodicity-Saliency Aware Mamba, which utilizes novel algorithms for keyframe weight estimation via enhanced Density Peaks Clustering and motion periodicity estimation via FFT-accelerated autocorrelation to capture coupled dynamics with minimal computational overhead, and (ii) constructing a Periodic Differential Cross-modal Alignment Module (PDCAM) to enhance robust alignment of textual and motion embeddings. Extensive experiments on HumanML3D and KIT-ML datasets have been conducted, confirming the effectiveness of our approach, achieving an FID of 0.068 and consistent gains on all other metrics.

</details>


### [163] [Exposing and Defending the Achilles' Heel of Video Mixture-of-Experts](https://arxiv.org/abs/2602.01369)
*Songping Wang,Qinglong Liu,Yueming Lyu,Ning Li,Ziwen He,Caifeng Shan*

Main category: cs.CV

TL;DR: 本文提出了一种针对视频MoE模型的对抗攻击与防御框架，通过分析路由器与专家模块的独立和协同弱点，设计了TLGA攻击和J-TLAT防御方法，显著提升了模型鲁棒性并降低了推理成本。


<details>
  <summary>Details</summary>
Motivation: 尽管Mixture-of-Experts在视频理解任务中表现出色，但其对抗鲁棒性尚未得到充分研究。现有攻击方法通常将MoE视为统一架构，忽略了路由器与专家模块的独立和协同弱点，需要系统性研究这些组件的脆弱性。

Method: 提出Temporal Lipschitz-Guided Attacks (TLGA)框架：1）设计针对路由器的独立攻击；2）提出Joint Temporal Lipschitz-Guided Attacks (J-TLGA)，协同扰动路由器和专家模块；3）基于攻击洞察，提出Joint Temporal Lipschitz Adversarial Training (J-TLAT)进行联合防御训练。

Result: TLGA攻击揭示了MoE组件的独立弱点，J-TLGA攻击显著放大了对抗效果并暴露了MoE架构的协同弱点。J-TLAT防御框架具有即插即用特性，相比密集模型减少60%以上推理成本，在多种数据集和架构上一致提升对抗鲁棒性。

Conclusion: 该研究系统分析了视频MoE模型的组件级脆弱性，提出的攻击与防御框架有效缓解了MoE的独立和协同弱点，为构建鲁棒的MoE架构提供了重要见解和实践方案。

Abstract: Mixture-of-Experts (MoE) has demonstrated strong performance in video understanding tasks, yet its adversarial robustness remains underexplored. Existing attack methods often treat MoE as a unified architecture, overlooking the independent and collaborative weaknesses of key components such as routers and expert modules. To fill this gap, we propose Temporal Lipschitz-Guided Attacks (TLGA) to thoroughly investigate component-level vulnerabilities in video MoE models. We first design attacks on the router, revealing its independent weaknesses. Building on this, we introduce Joint Temporal Lipschitz-Guided Attacks (J-TLGA), which collaboratively perturb both routers and experts. This joint attack significantly amplifies adversarial effects and exposes the Achilles' Heel (collaborative weaknesses) of the MoE architecture. Based on these insights, we further propose Joint Temporal Lipschitz Adversarial Training (J-TLAT). J-TLAT performs joint training to further defend against collaborative weaknesses, enhancing component-wise robustness. Our framework is plug-and-play and reduces inference cost by more than 60% compared with dense models. It consistently enhances adversarial robustness across diverse datasets and architectures, effectively mitigating both the independent and collaborative weaknesses of MoE.

</details>


### [164] [PolyGen: Fully Synthetic Vision-Language Training via Multi-Generator Ensembles](https://arxiv.org/abs/2602.01370)
*Leonardo Brusini,Cristian Sbrolli,Eugenio Lomurno,Toshihiko Yamasaki,Matteo Matteucci*

Main category: cs.CV

TL;DR: PolyGen框架通过多生成器集成和程序化负样本课程，在合成数据生成中强调结构多样性而非单纯数据量，显著提升视觉-语言预训练性能


<details>
  <summary>Details</summary>
Motivation: 当前合成数据方法主要依赖单一生成器扩展，导致频谱偏差和特征多样性受限。需要解决生成器特定伪影问题，通过结构多样性而非单纯数据量来提升合成数据质量

Method: 采用多生成器集成方法，在不同架构生成器的交集上进行训练，消除模型特定伪影；引入程序化硬负样本课程，强制细粒度语法理解；重新分配数据预算，从单一描述转向多源变体

Result: 在聚合多任务基准上比领先的单源基线(SynthCLIP)提升19.0%；在SugarCrepe++组合性基准上提升9.1%；证明结构多样性比单纯增加单源样本量更高效

Conclusion: 结构多样性是比单纯增加数据量更高效的数据扩展法则；多生成器集成和程序化负样本课程能有效提升合成数据质量，构建更鲁棒的特征空间

Abstract: Synthetic data offers a scalable solution for vision-language pre-training, yet current state-of-the-art methods typically rely on scaling up a single generative backbone, which introduces generator-specific spectral biases and limits feature diversity. In this work, we introduce PolyGen, a framework that redefines synthetic data construction by prioritizing manifold coverage and compositional rigor over simple dataset size. PolyGen employs a Polylithic approach to train on the intersection of architecturally distinct generators, effectively marginalizing out model-specific artifacts. Additionally, we introduce a Programmatic Hard Negative curriculum that enforces fine-grained syntactic understanding. By structurally reallocating the same data budget from unique captions to multi-source variations, PolyGen achieves a more robust feature space, outperforming the leading single-source baseline (SynthCLIP) by +19.0% on aggregate multi-task benchmarks and on the SugarCrepe++ compositionality benchmark (+9.1%). These results demonstrate that structural diversity is a more data-efficient scaling law than simply increasing the volume of single-source samples.

</details>


### [165] [PromptRL: Prompt Matters in RL for Flow-Based Image Generation](https://arxiv.org/abs/2602.01382)
*Fu-Yun Wang,Han Zhang,Michael Gharbi,Hongsheng Li,Taesung Park*

Main category: cs.CV

TL;DR: PromptRL框架通过将语言模型作为可训练的提示优化代理集成到流匹配模型的强化学习循环中，解决了现有RL方法在文本到图像生成中的样本效率低和提示过拟合问题，显著提升了性能并减少了训练成本。


<details>
  <summary>Details</summary>
Motivation: 当前流匹配模型的强化学习后训练存在两个被低估但重要的问题：1）由于生成多样性不足导致的样本效率低下；2）严重的提示过拟合，模型会记忆特定的训练提示，在语义相同但风格不同的提示上表现急剧下降。

Method: 提出PromptRL框架，将语言模型作为可训练的提示优化代理直接集成到流匹配模型的强化学习优化循环中。这种设计实现了两个互补优势：快速开发复杂的提示重写能力，以及关键的协同训练机制，重塑优化动态。

Result: 在多个基准测试中达到最先进性能：GenEval得分0.97，OCR准确率0.98，PickScore得分24.05。在大型图像编辑模型上验证有效性，将FLUX.1-Kontext的EditReward从1.19提升到1.43，仅需0.06百万次rollout，超越了Gemini 2.5 Flash Image（1.37），与需要精细数据标注和多阶段训练的ReasonNet（1.44）性能相当。相比朴素流匹配RL，PromptRL在达到更高性能上限的同时，所需rollout次数减少2倍以上。

Conclusion: PromptRL通过语言模型驱动的提示优化与流匹配模型的协同训练，有效解决了当前RL方法在文本到图像生成中的关键限制，实现了更高的样本效率和更好的泛化能力，为流匹配模型的强化学习对齐提供了新的有效框架。

Abstract: Flow matching models (FMs) have revolutionized text-to-image (T2I) generation, with reinforcement learning (RL) serving as a critical post-training strategy for alignment with reward objectives. In this research, we show that current RL pipelines for FMs suffer from two underappreciated yet important limitations: sample inefficiency due to insufficient generation diversity, and pronounced prompt overfitting, where models memorize specific training formulations and exhibit dramatic performance collapse when evaluated on semantically equivalent but stylistically varied prompts. We present PromptRL (Prompt Matters in RL for Flow-Based Image Generation), a framework that incorporates language models (LMs) as trainable prompt refinement agents directly within the flow-based RL optimization loop. This design yields two complementary benefits: rapid development of sophisticated prompt rewriting capabilities and, critically, a synergistic training regime that reshapes the optimization dynamics. PromptRL achieves state-of-the-art performance across multiple benchmarks, obtaining scores of 0.97 on GenEval, 0.98 on OCR accuracy, and 24.05 on PickScore.
  Furthermore, we validate the effectiveness of our RL approach on large-scale image editing models, improving the EditReward of FLUX.1-Kontext from 1.19 to 1.43 with only 0.06 million rollouts, surpassing Gemini 2.5 Flash Image (also known as Nano Banana), which scores 1.37, and achieving comparable performance with ReasonNet (1.44), which relied on fine-grained data annotations along with a complex multi-stage training. Our extensive experiments empirically demonstrate that PromptRL consistently achieves higher performance ceilings while requiring over 2$\times$ fewer rollouts compared to naive flow-only RL. Our code is available at https://github.com/G-U-N/UniRL.

</details>


### [166] [Stronger Semantic Encoders Can Harm Relighting Performance: Probing Visual Priors via Augmented Latent Intrinsics](https://arxiv.org/abs/2602.01391)
*Xiaoyan Xing,Xiao Zhang,Sezer Karaoglu,Theo Gevers,Anand Bhattad*

Main category: cs.CV

TL;DR: ALI通过融合像素对齐的视觉特征到潜在内在表示框架中，平衡语义抽象和光度保真度，显著提升了图像重照明效果，特别是在复杂镜面材料上。


<details>
  <summary>Details</summary>
Motivation: 现有基于潜在内在表示的图像重照明方法在金属和玻璃等挑战性材料上效果不佳，研究发现顶级语义编码器的特征反而会降低重照明质量，揭示了语义抽象与光度保真度之间的基本权衡。

Method: 提出增强潜在内在表示（ALI），通过将像素对齐的视觉编码器特征融合到潜在内在框架中，平衡语义上下文和密集光度结构，并采用自监督细化策略缓解配对真实世界数据的稀缺问题。

Result: ALI在重照明方面实现了显著改进，在复杂镜面材料上获得最大增益，仅使用未标记的真实世界图像对进行训练，配合密集像素对齐的视觉先验。

Conclusion: 通过平衡语义抽象和光度保真度的权衡，ALI框架有效解决了图像重照明中的材料挑战，为复杂场景的重照明提供了更强大的解决方案。

Abstract: Image-to-image relighting requires representations that disentangle scene properties from illumination. Recent methods rely on latent intrinsic representations but remain under-constrained and often fail on challenging materials such as metal and glass. A natural hypothesis is that stronger pretrained visual priors should resolve these failures. We find the opposite: features from top-performing semantic encoders often degrade relighting quality, revealing a fundamental trade-off between semantic abstraction and photometric fidelity. We study this trade-off and introduce Augmented Latent Intrinsics (ALI), which balances semantic context and dense photometric structure by fusing features from a pixel-aligned visual encoder into a latent-intrinsic framework, together with a self-supervised refinement strategy to mitigate the scarcity of paired real-world data. Trained only on unlabeled real-world image pairs and paired with a dense, pixel-aligned visual prior, ALI achieves strong improvements in relighting, with the largest gains on complex, specular materials. Project page: https:\\augmented-latent-intrinsics.github.io

</details>


### [167] [Where to Attend: A Principled Vision-Centric Position Encoding with Parabolas](https://arxiv.org/abs/2602.01418)
*Christoffer Koo Øhrstrøm,Rafael I. Cabral Muchacho,Yifei Dong,Filippos Moumtzidellis,Ronja Güldenring,Florian T. Pokorny,Lazaros Nalpantidis*

Main category: cs.CV

TL;DR: PaPE是一种基于抛物线的位置编码方法，专门为视觉模态设计，在8个数据集上7个取得最佳性能，在ImageNet-1K上外推性能提升10.5%


<details>
  <summary>Details</summary>
Motivation: 现有位置编码方法主要从语言处理的一维序列扩展到视觉的n维结构，但对视觉特性的考虑不充分。需要设计能更好适应视觉模态特性的位置编码方法。

Method: 提出抛物线位置编码(PaPE)，基于五个设计原则：平移不变性、旋转不变性(PaPE-RI)、距离衰减、方向性和上下文感知。该方法适用于图像、点云、视频和事件相机等多种视觉模态。

Result: 在涵盖4种模态的8个数据集上，PaPE或PaPE-RI在7个数据集上取得最佳性能。在ImageNet-1K的外推实验中，PaPE比次优位置编码绝对提升高达10.5%。

Conclusion: PaPE是一种有效的视觉位置编码方法，能更好地适应视觉模态特性，在多种任务和数据集上表现优异，且具有良好的外推能力。

Abstract: We propose Parabolic Position Encoding (PaPE), a parabola-based position encoding for vision modalities in attention-based architectures. Given a set of vision tokens-such as images, point clouds, videos, or event camera streams-our objective is to encode their positions while accounting for the characteristics of vision modalities. Prior works have largely extended position encodings from 1D-sequences in language to nD-structures in vision, but only with partial account of vision characteristics. We address this gap by designing PaPE from principles distilled from prior work: translation invariance, rotation invariance (PaPE-RI), distance decay, directionality, and context awareness. We evaluate PaPE on 8 datasets that span 4 modalities. We find that either PaPE or PaPE-RI achieves the top performance on 7 out of 8 datasets. Extrapolation experiments on ImageNet-1K show that PaPE extrapolates remarkably well, improving in absolute terms by up to 10.5% over the next-best position encoding. Code is available at https://github.com/DTU-PAS/parabolic-position-encoding.

</details>


### [168] [BioTamperNet: Affinity-Guided State-Space Model Detecting Tampered Biomedical Images](https://arxiv.org/abs/2602.01435)
*Soumyaroop Nandi,Prem Natarajan*

Main category: cs.CV

TL;DR: BioTamperNet：基于亲和力引导注意力的生物医学图像篡改检测框架，利用SSM近似实现高效细粒度定位


<details>
  <summary>Details</summary>
Motivation: 现有取证模型主要在自然图像上训练，在生物医学数据上表现不佳，而生物医学图像中的细微篡改可能损害实验有效性，需要专门针对生物医学图像篡改检测的解决方案

Method: 提出BioTamperNet框架，包含亲和力引导自注意力模块捕获图像内相似性，亲和力引导交叉注意力模块建模图像间对应关系，集成轻量级SSM启发线性注意力机制实现高效细粒度定位

Result: 在基准生物取证数据集上的广泛实验表明，BioTamperNet相比竞争基线在准确检测重复区域方面有显著改进

Conclusion: BioTamperNet通过亲和力引导注意力和SSM启发机制，有效解决了生物医学图像篡改检测问题，能够同时识别篡改区域及其来源对应部分

Abstract: We propose BioTamperNet, a novel framework for detecting duplicated regions in tampered biomedical images, leveraging affinity-guided attention inspired by State Space Model (SSM) approximations. Existing forensic models, primarily trained on natural images, often underperform on biomedical data where subtle manipulations can compromise experimental validity. To address this, BioTamperNet introduces an affinity-guided self-attention module to capture intra-image similarities and an affinity-guided cross-attention module to model cross-image correspondences. Our design integrates lightweight SSM-inspired linear attention mechanisms to enable efficient, fine-grained localization. Trained end-to-end, BioTamperNet simultaneously identifies tampered regions and their source counterparts. Extensive experiments on the benchmark bio-forensic datasets demonstrate significant improvements over competitive baselines in accurately detecting duplicated regions. Code - https://github.com/SoumyaroopNandi/BioTamperNet

</details>


### [169] [Cross-Paradigm Evaluation of Gaze-Based Semantic Object Identification for Intelligent Vehicles](https://arxiv.org/abs/2602.01452)
*Penghao Deng,Jidong J. Yang,Jiachen Bian*

Main category: cs.CV

TL;DR: 该论文比较了三种视觉方法（直接目标检测、分割辅助分类、查询式视觉语言模型）来识别驾驶员注视点对应的道路场景语义对象，发现YOLOv13和Qwen2.5-VL-32b表现最佳，大型VLM在夜间和小目标识别上更具鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 理解驾驶员在驾驶时的视觉注意力分布（通过注视行为表征）对于开发下一代高级驾驶辅助系统和提高道路安全至关重要。需要从车辆前视摄像头捕获的道路场景中识别注视点对应的语义对象。

Method: 采用三种视觉方法：1）直接目标检测（YOLOv13）；2）分割辅助分类（SAM2+EfficientNetV2 vs YOLOv13）；3）查询式视觉语言模型（Qwen2.5-VL-7b vs Qwen2.5-VL-32b）。通过注视点与对象语义的共现关系进行研究。

Result: 直接目标检测（YOLOv13）和Qwen2.5-VL-32b显著优于其他方法，Macro F1分数超过0.84。大型VLM（Qwen2.5-VL-32b）在识别小尺寸、安全关键对象（如交通信号灯）方面表现出更强的鲁棒性，尤其在夜间恶劣条件下。分割辅助方法因"部分vs整体"语义差距导致召回率大幅下降。

Conclusion: 研究揭示了传统检测器的实时效率与大型VLM提供的更丰富上下文理解和鲁棒性之间的基本权衡。这些发现为未来人类感知智能驾驶员监控系统的设计提供了关键见解和实践指导。

Abstract: Understanding where drivers direct their visual attention during driving, as characterized by gaze behavior, is critical for developing next-generation advanced driver-assistance systems and improving road safety. This paper tackles this challenge as a semantic identification task from the road scenes captured by a vehicle's front-view camera. Specifically, the collocation of gaze points with object semantics is investigated using three distinct vision-based approaches: direct object detection (YOLOv13), segmentation-assisted classification (SAM2 paired with EfficientNetV2 versus YOLOv13), and query-based Vision-Language Models, VLMs (Qwen2.5-VL-7b versus Qwen2.5-VL-32b). The results demonstrate that the direct object detection (YOLOv13) and Qwen2.5-VL-32b significantly outperform other approaches, achieving Macro F1-Scores over 0.84. The large VLM (Qwen2.5-VL-32b), in particular, exhibited superior robustness and performance for identifying small, safety-critical objects such as traffic lights, especially in adverse nighttime conditions. Conversely, the segmentation-assisted paradigm suffers from a "part-versus-whole" semantic gap that led to large failure in recall. The results reveal a fundamental trade-off between the real-time efficiency of traditional detectors and the richer contextual understanding and robustness offered by large VLMs. These findings provide critical insights and practical guidance for the design of future human-aware intelligent driver monitoring systems.

</details>


### [170] [Understanding vision transformer robustness through the lens of out-of-distribution detection](https://arxiv.org/abs/2602.01459)
*Joey Kuang,Alexander Wong*

Main category: cs.CV

TL;DR: 研究量化视觉Transformer在分布外检测中的表现，发现大规模预训练可能损害低比特量化的鲁棒性，而数据增强是更好的选择。


<details>
  <summary>Details</summary>
Motivation: 视觉Transformer在视觉任务中表现出色，但实现可访问和实时使用仍具挑战。量化能降低内存和推理成本，但可能导致性能损失。现有研究主要关注分布内任务行为，而注意力机制可能通过探索分布外情况提供量化属性的新见解。

Method: 研究量化的小型流行视觉Transformer（DeiT、DeiT3和ViT）在常见分布外数据集上的行为。分析分布内任务表现，并特别关注分布外检测中量化模型的表现。

Result: 分布内分析显示4位模型存在初始不稳定性，特别是在ImageNet-22k上预训练的模型。最强的FP32模型DeiT3在量化后性能下降17%，成为最弱的4位模型之一。分布外检测揭示：在ImageNet-22k预训练的ViT和DeiT3分别经历了15.0%和19.2%的平均量化性能下降，而仅在ImageNet-1k预训练的对应模型仅下降9.5%和12.0%。

Conclusion: 大规模数据集预训练可能损害低比特量化在分布外检测中的鲁棒性，数据增强可能是更有益的选择。

Abstract: Vision transformers have shown remarkable performance in vision tasks, but enabling them for accessible and real-time use is still challenging. Quantization reduces memory and inference costs at the risk of performance loss. Strides have been made to mitigate low precision issues mainly by understanding in-distribution (ID) task behaviour, but the attention mechanism may provide insight on quantization attributes by exploring out-of-distribution (OOD) situations. We investigate the behaviour of quantized small-variant popular vision transformers (DeiT, DeiT3, and ViT) on common OOD datasets. ID analyses show the initial instabilities of 4-bit models, particularly of those trained on the larger ImageNet-22k, as the strongest FP32 model, DeiT3, sharply drop 17% from quantization error to be one of the weakest 4-bit models. While ViT shows reasonable quantization robustness for ID calibration, OOD detection reveals more: ViT and DeiT3 pretrained on ImageNet-22k respectively experienced a 15.0% and 19.2% average quantization delta in AUPR-out between full precision to 4-bit while their ImageNet-1k-only counterparts experienced a 9.5% and 12.0% delta. Overall, our results suggest pretraining on large scale datasets may hinder low-bit quantization robustness in OOD detection and that data augmentation may be a more beneficial option.

</details>


### [171] [Preserving Localized Patch Semantics in VLMs](https://arxiv.org/abs/2602.01530)
*Parsa Esmaeilkhani,Longin Jan Latecki*

Main category: cs.CV

TL;DR: 提出Logit Lens Loss (LLL)来增强视觉语言模型中视觉token的语义对齐，使Logit Lens可视化在图像解释中变得实用


<details>
  <summary>Details</summary>
Motivation: 现有的Logit Lens方法在视觉语言模型中存在局限性：视觉token的视觉信息会扩散到语言token中，导致视觉信息的局部性被破坏，使得Logit Lens可视化在可解释性方面变得不可用

Method: 提出Logit Lens Loss (LLL)，作为next-token prediction (NTP)的补充损失函数，使视觉token嵌入更语义对齐于描述其图像区域的文本概念，无需架构修改或大规模训练

Result: LLL不仅使Logit Lens变得实用，能生成有意义的对象置信度图，还提高了分割等视觉中心任务的性能，无需附加特殊头部

Conclusion: Logit Lens Loss通过约束图像和文本token在自注意力层中的混合，防止视觉token失去局部视觉信息，从而增强了视觉语言模型的可解释性和视觉任务性能

Abstract: Logit Lens has been proposed for visualizing tokens that contribute most to LLM answers. Recently, Logit Lens was also shown to be applicable in autoregressive Vision-Language Models (VLMs), where it illustrates the conceptual content of image tokens in the form of heatmaps, e.g., which image tokens are likely to depict the concept of cat in a given image. However, the visual content of image tokens often gets diffused to language tokens, and consequently, the locality of visual information gets mostly destroyed, which renders Logit Lens visualization unusable for explainability. To address this issue, we introduce a complementary loss to next-token prediction (NTP) to prevent the visual tokens from losing the visual representation inherited from corresponding image patches. The proposed Logit Lens Loss (LLL) is designed to make visual token embeddings more semantically aligned with the textual concepts that describe their image regions (e.g., patches containing a cat with the word "cat"), without requiring any architectural modification or large-scale training. This way, LLL constrains the mixing of image and text tokens in the self-attention layers in order to prevent image tokens from losing their localized visual information. As our experiments show, LLL not only makes Logit Lens practically relevant by producing meaningful object confidence maps in images, but also improves performance on vision-centric tasks like segmentation without attaching any special heads.

</details>


### [172] [Rotation-free Online Handwritten Character Recognition Using Linear Recurrent Units](https://arxiv.org/abs/2602.01533)
*Zhe Ling,Sicheng Yu,Danyu Yang*

Main category: cs.CV

TL;DR: 提出SW-PS+LRU框架，通过滑动窗口路径签名提取旋转不变特征，结合线性循环单元分类器，在旋转变形手写字符识别中取得优异性能。


<details>
  <summary>Details</summary>
Motivation: 在线手写字符识别虽然利用笔画顺序和动态特征有更高准确性，但实际应用中旋转变形会破坏笔画空间布局，显著降低识别准确率。提取旋转不变特征仍是一个具有挑战性的开放问题。

Method: 采用滑动窗口路径签名(SW-PS)捕捉字符的局部结构特征，引入轻量级线性循环单元(LRU)作为分类器。LRU结合了循环神经网络的快速增量处理能力和状态空间模型的高效并行训练优势，同时可靠地建模动态笔画特征。

Result: 在CASIA-OLHWDB1.1数据集的三个子集（数字、英文大写字母、中文部首）上进行随机旋转角度达±180°的识别实验。集成学习后的准确率分别为99.62%、96.67%和94.33%。

Conclusion: 实验结果表明，提出的SW-PS+LRU框架在收敛速度和测试准确率方面均优于竞争模型，有效解决了旋转变形手写字符识别问题。

Abstract: Online handwritten character recognition leverages stroke order and dynamic features, which generally provide higher accuracy and robustness compared with offline recognition. However, in practical applications, rotational deformations can disrupt the spatial layout of strokes, substantially reducing recognition accuracy. Extracting rotation-invariant features therefore remains a challenging open problem. In this work, we employ the Sliding Window Path Signature (SW-PS) to capture local structural features of characters, and introduce the lightweight Linear Recurrent Units (LRU) as the classifier. The LRU combine the fast incremental processing capability of recurrent neural networks (RNN) with the efficient parallel training of state space models (SSM), while reliably modelling dynamic stroke characteristics. We conducted recognition experiments with random rotation angle up to $\pm 180^{\circ}$ on three subsets of the CASIA-OLHWDB1.1 dataset: digits, English upper letters, and Chinese radicals. The accuracies achieved after ensemble learning were $99.62\%$, $96.67\%$, and $94.33\%$, respectively. Experimental results demonstrate that the proposed SW-PS+LRU framework consistently surpasses competing models in both convergence speed and test accuracy.

</details>


### [173] [Making Avatars Interact: Towards Text-Driven Human-Object Interaction for Controllable Talking Avatars](https://arxiv.org/abs/2602.01538)
*Youliang Zhang,Zhengguang Zhou,Zhentao Yu,Ziyao Huang,Teng Hu,Sen Liang,Guozhen Zhang,Ziqiao Peng,Shunkai Li,Yi Chen,Zixiang Zhou,Yuan Zhou,Qinglin Lu,Xiu Li*

Main category: cs.CV

TL;DR: InteractAvatar：一种用于生成执行文本对齐物体交互的说话虚拟人的双流框架，通过感知规划与视频合成解耦来解决接地人-物交互生成的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有方法能生成具有简单人体运动的说话虚拟人，但扩展到接地人-物交互（GHOI）仍具挑战，需要虚拟人与周围物体进行文本对齐的交互，这涉及环境感知和控制-质量困境。

Method: 提出双流框架InteractAvatar，包含感知与交互模块（PIM）生成文本对齐的交互运动，以及音频-交互感知生成模块（AIM）合成执行物体交互的生动说话虚拟人，通过运动-视频对齐器实现并行协同生成。

Result: 建立了GHOI视频生成基准GroundedInter，大量实验证明该方法能有效生成说话虚拟人的接地人-物交互。

Conclusion: InteractAvatar通过解耦感知规划和视频合成，有效解决了GHOI生成的挑战，能够生成文本对齐的交互运动和生动的说话虚拟人视频。

Abstract: Generating talking avatars is a fundamental task in video generation. Although existing methods can generate full-body talking avatars with simple human motion, extending this task to grounded human-object interaction (GHOI) remains an open challenge, requiring the avatar to perform text-aligned interactions with surrounding objects. This challenge stems from the need for environmental perception and the control-quality dilemma in GHOI generation. To address this, we propose a novel dual-stream framework, InteractAvatar, which decouples perception and planning from video synthesis for grounded human-object interaction. Leveraging detection to enhance environmental perception, we introduce a Perception and Interaction Module (PIM) to generate text-aligned interaction motions. Additionally, an Audio-Interaction Aware Generation Module (AIM) is proposed to synthesize vivid talking avatars performing object interactions. With a specially designed motion-to-video aligner, PIM and AIM share a similar network structure and enable parallel co-generation of motions and plausible videos, effectively mitigating the control-quality dilemma. Finally, we establish a benchmark, GroundedInter, for evaluating GHOI video generation. Extensive experiments and comparisons demonstrate the effectiveness of our method in generating grounded human-object interactions for talking avatars. Project page: https://interactavatar.github.io

</details>


### [174] [FSCA-Net: Feature-Separated Cross-Attention Network for Robust Multi-Dataset Training](https://arxiv.org/abs/2602.01540)
*Yuehai Chen*

Main category: cs.CV

TL;DR: FSCA-Net：通过特征分离和交叉注意力机制解决人群计数中的负迁移问题，提升跨数据集泛化能力


<details>
  <summary>Details</summary>
Motivation: CNN和Transformer模型在人群计数中表现良好，但在跨域应用时性能下降。多数据集联合训练会导致负迁移问题，因为共享特征和域特定特征纠缠在一起。

Method: 提出FSCA-Net框架：1）将特征显式解耦为域不变和域特定组件；2）交叉注意力融合模块自适应建模组件间交互；3）互信息优化目标最大化域不变特征一致性，最小化域特定特征冗余。

Result: 在多个人群计数基准测试中，FSCA-Net有效缓解负迁移问题，实现了最先进的跨数据集泛化性能。

Conclusion: FSCA-Net为现实世界人群分析提供了鲁棒且可扩展的解决方案，通过特征解耦和自适应融合机制解决了跨域泛化挑战。

Abstract: Crowd counting plays a vital role in public safety, traffic regulation, and smart city management. However, despite the impressive progress achieved by CNN- and Transformer-based models, their performance often deteriorates when applied across diverse environments due to severe domain discrepancies. Direct joint training on multiple datasets, which intuitively should enhance generalization, instead results in negative transfer, as shared and domain-specific representations become entangled. To address this challenge, we propose the Feature Separation and Cross-Attention Network FSCA-Net, a unified framework that explicitly disentangles feature representations into domain-invariant and domain-specific components. A novel cross-attention fusion module adaptively models interactions between these components, ensuring effective knowledge transfer while preserving dataset-specific discriminability. Furthermore, a mutual information optimization objective is introduced to maximize consistency among domain-invariant features and minimize redundancy among domain-specific ones, promoting complementary shared-private representations. Extensive experiments on multiple crowd counting benchmarks demonstrate that FSCA-Net effectively mitigates negative transfer and achieves state-of-the-art cross-dataset generalization, providing a robust and scalable solution for real-world crowd analysis.

</details>


### [175] [Toward Cognitive Supersensing in Multimodal Large Language Model](https://arxiv.org/abs/2602.01541)
*Boyi Li,Yifan Shen,Yuanzhe Liu,Yifan Xu,Jiateng Liu,Xinzhuo Li,Zhengyuan Li,Jingyuan Zhu,Yunhan Zhong,Fangzhou Lan,Jianguo Cao,James M. Rehg,Heng Ji,Ismini Lourentzou,Xu Cao*

Main category: cs.CV

TL;DR: 提出Cognitive Supersensing训练范式，通过视觉意象预测头赋予MLLMs人类般的视觉意象能力，显著提升复杂认知问题解决能力


<details>
  <summary>Details</summary>
Motivation: 当前MLLMs在开放词汇感知任务上成功，但在需要视觉记忆和抽象视觉细节的复杂认知问题上能力有限。现有方法主要在文本空间扩展思维链推理，忽视了类似人类视觉空间画板和视觉意象的视觉推理机制

Method: 1) 引入Cognitive Supersensing训练范式，集成潜在视觉意象预测头，联合学习视觉认知潜在嵌入序列并与答案对齐，形成基于视觉的内部推理链；2) 引入强化学习阶段，基于接地的视觉潜在优化文本推理路径；3) 提出CogSense-Bench基准，评估五个认知维度

Result: Cognitive Supersensing训练的MLLMs在CogSense-Bench上显著优于最先进基线，在域外数学和科学VQA基准上表现出优越的泛化能力

Conclusion: 内部视觉意象可能是弥合感知识别与认知理解之间差距的关键，视觉推理机制对提升MLLMs的认知能力至关重要

Abstract: Multimodal Large Language Models (MLLMs) have achieved remarkable success in open-vocabulary perceptual tasks, yet their ability to solve complex cognitive problems remains limited, especially when visual details are abstract and require visual memory. Current approaches primarily scale Chain-of-Thought (CoT) reasoning in the text space, even when language alone is insufficient for clear and structured reasoning, and largely neglect visual reasoning mechanisms analogous to the human visuospatial sketchpad and visual imagery. To mitigate this deficiency, we introduce Cognitive Supersensing, a novel training paradigm that endows MLLMs with human-like visual imagery capabilities by integrating a Latent Visual Imagery Prediction (LVIP) head that jointly learns sequences of visual cognitive latent embeddings and aligns them with the answer, thereby forming vision-based internal reasoning chains. We further introduce a reinforcement learning stage that optimizes text reasoning paths based on this grounded visual latent. To evaluate the cognitive capabilities of MLLMs, we present CogSense-Bench, a comprehensive visual question answering (VQA) benchmark assessing five cognitive dimensions. Extensive experiments demonstrate that MLLMs trained with Cognitive Supersensing significantly outperform state-of-the-art baselines on CogSense-Bench and exhibit superior generalization on out-of-domain mathematics and science VQA benchmarks, suggesting that internal visual imagery is potentially key to bridging the gap between perceptual recognition and cognitive understanding. We will open-source the CogSense-Bench and our model weights.

</details>


### [176] [Combined Flicker-banding and Moire Removal for Screen-Captured Images](https://arxiv.org/abs/2602.01559)
*Libo Zhu,Zihan Zhou,Zhiyi Zhou,Yiyang Qu,Weihang Zhang,Keyu Shi,Yifan Fu,Yulun Zhang*

Main category: cs.CV

TL;DR: 提出CLEAR框架，首次系统研究屏幕截图图像中摩尔纹和闪烁条纹的联合去除，构建大规模数据集并设计频率域分解重组模块，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 移动设备拍摄屏幕图像时，摩尔纹和闪烁条纹同时存在且相互耦合，导致严重视觉质量下降。现有单退化方法无法处理这种复合场景，需要专门解决方案。

Method: 1) 构建包含摩尔纹和闪烁条纹的大规模数据集；2) 设计基于ISP的闪烁模拟流程稳定训练并扩展退化分布；3) 提出频率域分解重组模块和轨迹对齐损失来增强复合伪影建模。

Result: 在多个评估指标上，CLEAR方法一致优于现有图像恢复方法，验证了其在复杂真实场景中的有效性。

Conclusion: 该研究首次系统解决了屏幕截图图像中摩尔纹和闪烁条纹的联合去除问题，提出的CLEAR框架通过创新的数据集构建、模拟流程和网络设计，在复杂退化场景中取得了显著效果。

Abstract: Capturing display screens with mobile devices has become increasingly common, yet the resulting images often suffer from severe degradations caused by the coexistence of moiré patterns and flicker-banding, leading to significant visual quality degradation. Due to the strong coupling of these two artifacts in real imaging processes, existing methods designed for single degradations fail to generalize to such compound scenarios. In this paper, we present the first systematic study on joint removal of moiré patterns and flicker-banding in screen-captured images, and propose a unified restoration framework, named CLEAR. To support this task, we construct a large-scale dataset containing both moiré patterns and flicker-banding, and introduce an ISP-based flicker simulation pipeline to stabilize model training and expand the degradation distribution. Furthermore, we design a frequency-domain decomposition and re-composition module together with a trajectory alignment loss to enhance the modeling of compound artifacts. Extensive experiments demonstrate that the proposed method consistently. outperforms existing image restoration approaches across multiple evaluation metrics, validating its effectiveness in complex real-world scenarios.

</details>


### [177] [Multimodal UNcommonsense: From Odd to Ordinary and Ordinary to Odd](https://arxiv.org/abs/2602.01561)
*Yejin Son,Saejin Kim,Dongjun Min,Younjae Yu*

Main category: cs.CV

TL;DR: 论文提出了MUN基准测试来评估模型处理非常规多模态场景的能力，并开发了R-ICL框架通过检索相关示例提升小模型在不常见情况下的推理表现。


<details>
  <summary>Details</summary>
Motivation: 多模态常识推理是AI的基础挑战，现有模型在处理偏离典型视觉或上下文预期的场景时表现不佳。需要评估和改进模型在非典型、文化多样、非原型化现实场景中的鲁棒性和适应性。

Method: 1) 提出MUN基准测试，包含视觉场景与意外结果的配对；2) 开发检索式上下文学习(R-ICL)框架，将大模型推理能力迁移到小模型；3) 设计多模态集成检索器(MER)，即使在图像-文本不匹配时也能识别语义相关示例。

Result: 实验显示R-ICL方法比基线ICL方法平均提升8.3%，在多模态非常规场景中表现显著更好。MUN基准为评估视觉-语言模型在非典型场景中的能力提供了新工具。

Conclusion: MUN基准和R-ICL框架为评估和改进多模态模型在现实世界、文化多样、非原型化场景中的鲁棒性和适应性开辟了新方向，特别是在处理低频、非典型情况时表现出色。

Abstract: Commonsense reasoning in multimodal contexts remains a foundational challenge in artificial intelligence. We introduce Multimodal UNcommonsense(MUN), a benchmark designed to evaluate models' ability to handle scenarios that deviate from typical visual or contextual expectations. MUN pairs visual scenes with surprising or unlikely outcomes described in natural language, prompting models to either rationalize seemingly odd images using everyday logic or uncover unexpected interpretations in ordinary scenes. To support this task, we propose a retrieval-based in-context learning (R-ICL) framework that transfers reasoning capabilities from larger models to smaller ones without additional training. Leveraging a novel Multimodal Ensemble Retriever (MER), our method identifies semantically relevant exemplars even when image and text pairs are deliberately discordant. Experiments show an average improvement of 8.3% over baseline ICL methods, highlighting the effectiveness of R-ICL in low-frequency, atypical settings. MUN opens new directions for evaluating and improving visual-language models' robustness and adaptability in real-world, culturally diverse, and non-prototypical scenarios.

</details>


### [178] [One-Step Diffusion for Perceptual Image Compression](https://arxiv.org/abs/2602.01570)
*Yiwen Jia,Hao Wei,Yanhui Zhou,Chenyang Ge*

Main category: cs.CV

TL;DR: 提出单步扩散图像压缩方法，显著提升推理速度，同时保持压缩性能


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的图像压缩方法虽然能在低比特率下获得高质量感知效果，但由于解码时需要大量去噪步骤，导致推理延迟高、计算开销大，阻碍了实际部署

Method: 提出仅需单步扩散过程的图像压缩方法；引入在紧凑特征表示上操作的判别器，利用特征更好地捕捉高层纹理和结构细节来提升重建图像的感知质量

Result: 实验结果显示，该方法在保持可比压缩性能的同时，相比最近的扩散方法提供46倍的推理速度提升

Conclusion: 通过单步扩散过程和基于特征的判别器设计，成功解决了扩散图像压缩的推理延迟问题，实现了高效实用的图像压缩方案

Abstract: Diffusion-based image compression methods have achieved notable progress, delivering high perceptual quality at low bitrates. However, their practical deployment is hindered by significant inference latency and heavy computational overhead, primarily due to the large number of denoising steps required during decoding. To address this problem, we propose a diffusion-based image compression method that requires only a single-step diffusion process, significantly improving inference speed. To enhance the perceptual quality of reconstructed images, we introduce a discriminator that operates on compact feature representations instead of raw pixels, leveraging the fact that features better capture high-level texture and structural details. Experimental results show that our method delivers comparable compression performance while offering a 46$\times$ faster inference speed compared to recent diffusion-based approaches. The source code and models are available at https://github.com/cheesejiang/OSDiff.

</details>


### [179] [SGHA-Attack: Semantic-Guided Hierarchical Alignment for Transferable Targeted Attacks on Vision-Language Models](https://arxiv.org/abs/2602.01574)
*Haobo Wang,Weiqi Luo,Xiaojun Jia,Xiaochun Cao*

Main category: cs.CV

TL;DR: SGHA-Attack：一种语义引导的分层对齐对抗攻击框架，通过多参考锚点和中间层语义对齐提升对抗样本在异构视觉语言模型间的可迁移性。


<details>
  <summary>Details</summary>
Motivation: 现有基于迁移的对抗攻击方法通常依赖单一参考目标，过度拟合代理模型的嵌入空间，强调最终层对齐而未能充分利用中间语义信息，导致在异构视觉语言模型间的可迁移性较差。

Method: 提出语义引导的分层对齐框架：1) 使用冻结的文生图模型生成视觉基础参考池，选择Top-K语义相关锚点形成加权混合指导；2) 在特征层次结构的多深度上对齐中间视觉表示（全局和空间粒度）；3) 在共享潜在子空间中同步中间视觉和文本特征，提供早期跨模态监督。

Result: 在开源和商业黑盒视觉语言模型上的广泛实验表明，SGHA-Attack相比先前方法实现了更强的目标可迁移性，并且在预处理和净化防御下仍保持鲁棒性。

Conclusion: 通过多参考锚点和分层语义对齐，SGHA-Attack有效解决了现有对抗攻击方法在异构视觉语言模型间可迁移性不足的问题，为黑盒攻击提供了更强大的框架。

Abstract: Large vision-language models (VLMs) are vulnerable to transfer-based adversarial perturbations, enabling attackers to optimize on surrogate models and manipulate black-box VLM outputs. Prior targeted transfer attacks often overfit surrogate-specific embedding space by relying on a single reference and emphasizing final-layer alignment, which underutilizes intermediate semantics and degrades transfer across heterogeneous VLMs. To address this, we propose SGHA-Attack, a Semantic-Guided Hierarchical Alignment framework that adopts multiple target references and enforces intermediate-layer consistency. Concretely, we generate a visually grounded reference pool by sampling a frozen text-to-image model conditioned on the target prompt, and then carefully select the Top-K most semantically relevant anchors under the surrogate to form a weighted mixture for stable optimization guidance. Building on these anchors, SGHA-Attack injects target semantics throughout the feature hierarchy by aligning intermediate visual representations at both global and spatial granularities across multiple depths, and by synchronizing intermediate visual and textual features in a shared latent subspace to provide early cross-modal supervision before the final projection. Extensive experiments on open-source and commercial black-box VLMs show that SGHA-Attack achieves stronger targeted transferability than prior methods and remains robust under preprocessing and purification defenses.

</details>


### [180] [HandMCM: Multi-modal Point Cloud-based Correspondence State Space Model for 3D Hand Pose Estimation](https://arxiv.org/abs/2602.01586)
*Wencan Cheng,Gim Hee Lee*

Main category: cs.CV

TL;DR: 提出基于状态空间模型Mamba的HandMCM方法，通过局部信息注入/过滤和对应关系建模模块，有效学习关键点动态运动拓扑，结合多模态图像特征提升3D手部姿态估计精度，在遮挡场景下表现优异。


<details>
  <summary>Details</summary>
Motivation: 3D手部姿态估计对增强现实等人机交互应用至关重要，但由于手部自遮挡和与物体交互导致的遮挡，该任务面临显著挑战。

Method: 提出HandMCM方法，基于状态空间模型Mamba，包含局部信息注入/过滤模块和对应关系建模模块，有效学习关键点动态运动拓扑，并整合多模态图像特征增强输入鲁棒性。

Result: 在三个基准数据集上的实证评估表明，该方法显著优于当前最先进方法，特别是在涉及严重遮挡的挑战性场景中。

Conclusion: 该方法有潜力在实际应用中提升3D手部姿态估计的准确性和可靠性，特别是在遮挡场景下表现优异。

Abstract: 3D hand pose estimation that involves accurate estimation of 3D human hand keypoint locations is crucial for many human-computer interaction applications such as augmented reality. However, this task poses significant challenges due to self-occlusion of the hands and occlusions caused by interactions with objects. In this paper, we propose HandMCM to address these challenges. Our HandMCM is a novel method based on the powerful state space model (Mamba). By incorporating modules for local information injection/filtering and correspondence modeling, the proposed correspondence Mamba effectively learns the highly dynamic kinematic topology of keypoints across various occlusion scenarios. Moreover, by integrating multi-modal image features, we enhance the robustness and representational capacity of the input, leading to more accurate hand pose estimation. Empirical evaluations on three benchmark datasets demonstrate that our model significantly outperforms current state-of-the-art methods, particularly in challenging scenarios involving severe occlusions. These results highlight the potential of our approach to advance the accuracy and reliability of 3D hand pose estimation in practical applications.

</details>


### [181] [Know Your Step: Faster and Better Alignment for Flow Matching Models via Step-aware Advantages](https://arxiv.org/abs/2602.01591)
*Zhixiong Yue,Zixuan Ni,Feiyang Ye,Jinshan Zhang,Sheng Shen,Zhenpeng Mi*

Main category: cs.CV

TL;DR: 提出TAFS-GRPO框架，通过温度退火采样和组相对策略优化，解决流匹配模型在少步文本到图像生成中奖励信号稀疏、不精确的问题，实现更高效的人偏好对齐。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的流匹配模型通常需要大量去噪步骤，且面临稀疏和不精确的奖励信号，导致人偏好对齐效果不佳。需要开发更高效的少步生成方法。

Method: 提出TAFS-GRPO框架：1）温度退火少步采样：在单步采样结果上迭代注入自适应时间噪声，通过退火引入随机性同时保持图像语义完整性；2）步感知优势集成机制：结合GRPO避免奖励函数可微性要求，提供密集且步特定的奖励信号。

Result: 实验表明TAFS-GRPO在少步文本到图像生成中表现优异，显著提高了生成图像与人偏好的对齐度。代码和模型将开源以促进进一步研究。

Conclusion: TAFS-GRPO通过创新的温度退火采样和组相对策略优化，有效解决了流匹配模型在少步生成中的奖励稀疏问题，实现了更高效的人偏好对齐，为少步文本到图像生成提供了新思路。

Abstract: Recent advances in flow matching models, particularly with reinforcement learning (RL), have significantly enhanced human preference alignment in few step text to image generators. However, existing RL based approaches for flow matching models typically rely on numerous denoising steps, while suffering from sparse and imprecise reward signals that often lead to suboptimal alignment. To address these limitations, we propose Temperature Annealed Few step Sampling with Group Relative Policy Optimization (TAFS GRPO), a novel framework for training flow matching text to image models into efficient few step generators well aligned with human preferences. Our method iteratively injects adaptive temporal noise onto the results of one step samples. By repeatedly annealing the model's sampled outputs, it introduces stochasticity into the sampling process while preserving the semantic integrity of each generated image. Moreover, its step aware advantage integration mechanism combines the GRPO to avoid the need for the differentiable of reward function and provide dense and step specific rewards for stable policy optimization. Extensive experiments demonstrate that TAFS GRPO achieves strong performance in few step text to image generation and significantly improves the alignment of generated images with human preferences. The code and models of this work will be available to facilitate further research.

</details>


### [182] [Samba+: General and Accurate Salient Object Detection via A More Unified Mamba-based Framework](https://arxiv.org/abs/2602.01593)
*Wenzhuo Zhao,Keren Fu,Jiahao He,Xiaohong Liu,Qijun Zhao,Guangtao Zhai*

Main category: cs.CV

TL;DR: Samba：基于Mamba的纯架构，通过空间邻域扫描和上下文感知上采样处理多种显著性检测任务；Samba+通过多任务联合训练实现统一模型，采用图注意力模块和模态锚定持续学习策略


<details>
  <summary>Details</summary>
Motivation: 现有显著性检测模型受限于CNN的有限感受野和Transformer的二次计算复杂度，需要平衡全局感受野和计算效率

Method: 提出Saliency Mamba (Samba)：基于Mamba的纯架构，包含显著性引导的Mamba块（SGMB）采用空间邻域扫描算法，以及上下文感知上采样（CAU）方法。Samba+通过多任务联合训练，包含hub-and-spoke图注意力模块和模态锚定持续学习策略

Result: Samba在6个显著性检测任务的22个数据集上超越现有方法且计算成本更低；Samba+使用单一训练模型在这些任务和数据集上取得更优结果

Conclusion: 提出的Samba框架在平衡全局感受野和计算效率方面表现出色，Samba+通过多任务联合训练实现了更统一和通用的模型，为显著性检测提供了有前景的解决方案

Abstract: Existing salient object detection (SOD) models are generally constrained by the limited receptive fields of convolutional neural networks (CNNs) and quadratic computational complexity of Transformers. Recently, the emerging state-space model, namely Mamba, has shown great potential in balancing global receptive fields and computational efficiency. As a solution, we propose Saliency Mamba (Samba), a pure Mamba-based architecture that flexibly handles various distinct SOD tasks, including RGB/RGB-D/RGB-T SOD, video SOD (VSOD), RGB-D VSOD, and visible-depth-thermal SOD. Specifically, we rethink the scanning strategy of Mamba for SOD, and introduce a saliency-guided Mamba block (SGMB) that features a spatial neighborhood scanning (SNS) algorithm to preserve the spatial continuity of salient regions. A context-aware upsampling (CAU) method is also proposed to promote hierarchical feature alignment and aggregation by modeling contextual dependencies. As one step further, to avoid the "task-specific" problem as in previous SOD solutions, we develop Samba+, which is empowered by training Samba in a multi-task joint manner, leading to a more unified and versatile model. Two crucial components that collaboratively tackle challenges encountered in input of arbitrary modalities and continual adaptation are investigated. Specifically, a hub-and-spoke graph attention (HGA) module facilitates adaptive cross-modal interactive fusion, and a modality-anchored continual learning (MACL) strategy alleviates inter-modal conflicts together with catastrophic forgetting. Extensive experiments demonstrate that Samba individually outperforms existing methods across six SOD tasks on 22 datasets with lower computational cost, whereas Samba+ achieves even superior results on these tasks and datasets by using a single trained versatile model. Additional results further demonstrate the potential of our Samba framework.

</details>


### [183] [UV-M3TL: A Unified and Versatile Multimodal Multi-Task Learning Framework for Assistive Driving Perception](https://arxiv.org/abs/2602.01594)
*Wenzhuo Liu,Qiannan Guo,Zhen Wang,Wenshuo Wang,Lei Yang,Yicheng Qiao,Lening Wang,Zhiwei Li,Chen Lv,Shanghang Zhang,Junqiang Xi,Huaping Liu*

Main category: cs.CV

TL;DR: 提出UV-M3TL框架，通过双分支空间通道多模态嵌入和自适应特征解耦多任务损失，同时识别驾驶员行为、情绪、车辆行为和交通环境，缓解任务间负迁移问题。


<details>
  <summary>Details</summary>
Motivation: 高级驾驶辅助系统需要同时理解驾驶员行为和感知导航环境，但联合学习这些异构任务会导致任务间负迁移，损害系统性能。

Method: 提出统一多功能多模态多任务学习框架，包含两个核心组件：双分支空间通道多模态嵌入（DB-SCME）显式建模任务共享和任务特定特征；自适应特征解耦多任务损失（AFD-Loss）基于学习动态和特征解耦约束的自适应加权机制。

Result: 在AIDE数据集上实现四个任务的最先进性能；在BDD100K、CityScapes、NYUD-v2和PASCAL-Context等多个公开基准测试中，对不同任务组合均表现优异，在大多数任务上达到最先进结果。

Conclusion: UV-M3TL框架能有效缓解多任务学习中的负迁移问题，在驾驶员行为理解和环境感知任务上表现出色，具有很好的通用性和多功能性。

Abstract: Advanced Driver Assistance Systems (ADAS) need to understand human driver behavior while perceiving their navigation context, but jointly learning these heterogeneous tasks would cause inter-task negative transfer and impair system performance. Here, we propose a Unified and Versatile Multimodal Multi-Task Learning (UV-M3TL) framework to simultaneously recognize driver behavior, driver emotion, vehicle behavior, and traffic context, while mitigating inter-task negative transfer. Our framework incorporates two core components: dual-branch spatial channel multimodal embedding (DB-SCME) and adaptive feature-decoupled multi-task loss (AFD-Loss). DB-SCME enhances cross-task knowledge transfer while mitigating task conflicts by employing a dual-branch structure to explicitly model salient task-shared and task-specific features. AFD-Loss improves the stability of joint optimization while guiding the model to learn diverse multi-task representations by introducing an adaptive weighting mechanism based on learning dynamics and feature decoupling constraints. We evaluate our method on the AIDE dataset, and the experimental results demonstrate that UV-M3TL achieves state-of-the-art performance across all four tasks. To further prove the versatility, we evaluate UV-M3TL on additional public multi-task perception benchmarks (BDD100K, CityScapes, NYUD-v2, and PASCAL-Context), where it consistently delivers strong performance across diverse task combinations, attaining state-of-the-art results on most tasks.

</details>


### [184] [Token Pruning for In-Context Generation in Diffusion Transformers](https://arxiv.org/abs/2602.01609)
*Junqing Lin,Xingyu Zheng,Pei Cheng,Bin Fu,Jingwei Sun,Guangzhong Sun*

Main category: cs.CV

TL;DR: ToPi：针对DiT中上下文生成任务的训练无关token剪枝框架，通过校准驱动的敏感性分析识别关键注意力层，量化每个上下文token的贡献度进行选择性剪枝，实现超过30%的推理加速同时保持图像质量。


<details>
  <summary>Details</summary>
Motivation: DiT中的上下文生成通过参考示例实现可控的图像到图像生成，但输入拼接导致序列长度急剧增加，造成显著计算瓶颈。现有token缩减技术主要针对文本到图像合成，采用统一缩减策略，忽略了参考上下文和目标潜在表示在空间、时间和功能维度上的角色不对称性。

Method: ToPi框架包含：1）离线校准驱动的敏感性分析识别关键注意力层作为冗余估计的鲁棒代理；2）基于这些层推导新颖的影响度量来量化每个上下文token的贡献度；3）选择性剪枝策略结合适应扩散轨迹演化的时间更新策略。

Result: 经验评估表明，ToPi在复杂图像生成任务中能够实现超过30%的推理加速，同时保持结构保真度和视觉一致性。

Conclusion: ToPi是针对DiT中上下文生成的有效训练无关token剪枝框架，通过考虑上下文token的角色不对称性，在保持生成质量的同时显著提升计算效率。

Abstract: In-context generation significantly enhances Diffusion Transformers (DiTs) by enabling controllable image-to-image generation through reference examples. However, the resulting input concatenation drastically increases sequence length, creating a substantial computational bottleneck. Existing token reduction techniques, primarily tailored for text-to-image synthesis, fall short in this paradigm as they apply uniform reduction strategies, overlooking the inherent role asymmetry between reference contexts and target latents across spatial, temporal, and functional dimensions. To bridge this gap, we introduce ToPi, a training-free token pruning framework tailored for in-context generation in DiTs. Specifically, ToPi utilizes offline calibration-driven sensitivity analysis to identify pivotal attention layers, serving as a robust proxy for redundancy estimation. Leveraging these layers, we derive a novel influence metric to quantify the contribution of each context token for selective pruning, coupled with a temporal update strategy that adapts to the evolving diffusion trajectory. Empirical evaluations demonstrate that ToPi can achieve over 30\% speedup in inference while maintaining structural fidelity and visual consistency across complex image generation tasks.

</details>


### [185] [Omni-Judge: Can Omni-LLMs Serve as Human-Aligned Judges for Text-Conditioned Audio-Video Generation?](https://arxiv.org/abs/2602.01623)
*Susan Liang,Chao Huang,Filippos Bellos,Yolo Yunlong Tang,Qianxiang Shen,Jing Bi,Luchuan Song,Zeliang Zhang,Jason Corso,Chenliang Xu*

Main category: cs.CV

TL;DR: Omni-Judge 研究评估全模态大语言模型能否作为文本条件音频-视频生成的人类对齐评判者，在语义对齐任务上表现出色，但在高帧率感知指标上存在局限。


<details>
  <summary>Details</summary>
Motivation: 当前文本到视频生成模型（如Sora 2和Veo 3）能产生高质量带音频的视频，但评估这种三模态输出仍是一个未解决的挑战。人工评估可靠但成本高难扩展，传统自动指标（如FVD、CLAP、ViCLIP）只关注孤立模态对，处理复杂提示困难且可解释性有限。

Method: 引入Omni-Judge研究，评估全模态大语言模型作为文本条件音频-视频生成评判者的能力。研究涵盖九个感知和对齐指标，比较全模态LLMs与传统指标的相关性，并分析其在语义要求高的任务上的表现。

Result: Omni-Judge在九个指标上达到与传统指标相当的相关性，在音频-文本对齐、视频-文本对齐和音频-视频-文本一致性等语义要求高的任务上表现优异。但在视频质量和音频-视频同步等高帧率感知指标上表现不佳，主要受限于时间分辨率。

Conclusion: 全模态大语言模型作为多模态生成的统一评估者具有潜力，特别是在提供可解释的推理和暴露语义或物理不一致性方面。然而，当前在时间分辨率相关的高帧率感知指标上存在局限，需要进一步改进。

Abstract: State-of-the-art text-to-video generation models such as Sora 2 and Veo 3 can now produce high-fidelity videos with synchronized audio directly from a textual prompt, marking a new milestone in multi-modal generation. However, evaluating such tri-modal outputs remains an unsolved challenge. Human evaluation is reliable but costly and difficult to scale, while traditional automatic metrics, such as FVD, CLAP, and ViCLIP, focus on isolated modality pairs, struggle with complex prompts, and provide limited interpretability. Omni-modal large language models (omni-LLMs) present a promising alternative: they naturally process audio, video, and text, support rich reasoning, and offer interpretable chain-of-thought feedback. Driven by this, we introduce Omni-Judge, a study assessing whether omni-LLMs can serve as human-aligned judges for text-conditioned audio-video generation. Across nine perceptual and alignment metrics, Omni-Judge achieves correlation comparable to traditional metrics and excels on semantically demanding tasks such as audio-text alignment, video-text alignment, and audio-video-text coherence. It underperforms on high-FPS perceptual metrics, including video quality and audio-video synchronization, due to limited temporal resolution. Omni-Judge provides interpretable explanations that expose semantic or physical inconsistencies, enabling practical downstream uses such as feedback-based refinement. Our findings highlight both the potential and current limitations of omni-LLMs as unified evaluators for multi-modal generation.

</details>


### [186] [PISCES: Annotation-free Text-to-Video Post-Training via Optimal Transport-Aligned Rewards](https://arxiv.org/abs/2602.01624)
*Minh-Quan Le,Gaurav Mittal,Cheng Zhao,David Gu,Dimitris Samaras,Mei Chen*

Main category: cs.CV

TL;DR: PISCES提出一种无标注的后训练算法，通过双最优传输对齐奖励模块改进文本到视频生成的质量和语义对齐


<details>
  <summary>Details</summary>
Motivation: 现有基于奖励的后训练方法要么依赖大规模人工偏好标注，要么使用预训练视觉语言模型中的未对齐嵌入，导致可扩展性有限或监督效果不佳

Method: 提出PISCES算法，通过双最优传输对齐奖励模块：1）分布级OT对齐质量奖励，捕捉整体视觉质量和时间一致性；2）离散令牌级OT对齐语义奖励，强制文本和视频令牌间的语义时空对应

Result: 在短视频和长视频生成任务中，PISCES在VBench的质量和语义得分上优于基于标注和无标注方法，人类偏好研究进一步验证其有效性

Conclusion: PISCES是首个通过最优传输视角改进生成后训练中无标注奖励监督的方法，其双OT对齐奖励模块兼容多种优化范式

Abstract: Text-to-video (T2V) generation aims to synthesize videos with high visual quality and temporal consistency that are semantically aligned with input text. Reward-based post-training has emerged as a promising direction to improve the quality and semantic alignment of generated videos. However, recent methods either rely on large-scale human preference annotations or operate on misaligned embeddings from pre-trained vision-language models, leading to limited scalability or suboptimal supervision. We present $\texttt{PISCES}$, an annotation-free post-training algorithm that addresses these limitations via a novel Dual Optimal Transport (OT)-aligned Rewards module. To align reward signals with human judgment, $\texttt{PISCES}$ uses OT to bridge text and video embeddings at both distributional and discrete token levels, enabling reward supervision to fulfill two objectives: (i) a Distributional OT-aligned Quality Reward that captures overall visual quality and temporal coherence; and (ii) a Discrete Token-level OT-aligned Semantic Reward that enforces semantic, spatio-temporal correspondence between text and video tokens. To our knowledge, $\texttt{PISCES}$ is the first to improve annotation-free reward supervision in generative post-training through the lens of OT. Experiments on both short- and long-video generation show that $\texttt{PISCES}$ outperforms both annotation-based and annotation-free methods on VBench across Quality and Semantic scores, with human preference studies further validating its effectiveness. We show that the Dual OT-aligned Rewards module is compatible with multiple optimization paradigms, including direct backpropagation and reinforcement learning fine-tuning.

</details>


### [187] [Research on World Models Is Not Merely Injecting World Knowledge into Specific Tasks](https://arxiv.org/abs/2602.01630)
*Bohan Zeng,Kaixin Zhu,Daili Hua,Bozhou Li,Chengzhuo Tong,Yuran Wang,Xinyi Huang,Yifan Dai,Zixiang Zhang,Yifan Yang,Zhou Liu,Hao Liang,Xiaochen Ma,Ruichuan An,Tianyi Bai,Hongcheng Gao,Junbo Niu,Yang Shi,Xinlong Chen,Yue Ding,Minglei Shi,Kai Zeng,Yiwen Tang,Yuanxing Zhang,Pengfei Wan,Xintao Wang,Wentao Zhang*

Main category: cs.CV

TL;DR: 该论文分析了当前世界模型研究的碎片化现状，提出了统一的设计规范，强调世界模型应是整合交互、感知、符号推理和空间表示的规范性框架。


<details>
  <summary>Details</summary>
Motivation: 当前世界模型研究呈现碎片化，主要集中在将世界知识注入孤立任务（如视觉预测、3D估计、符号接地），缺乏统一的定义和框架。这些任务特定的集成虽然能提升性能，但缺乏系统性连贯性，无法实现整体的世界理解。

Method: 分析现有碎片化方法的局限性，提出统一的世界模型设计规范。强调世界模型不应是能力的松散集合，而应是整合交互、感知、符号推理和空间表示的规范性框架。

Result: 提出了一个结构化的视角，为未来研究提供指导，旨在推动开发更通用、鲁棒和原则性的世界模型。

Conclusion: 需要建立统一的世界模型框架，整合多个关键能力，为AI研究提供更系统化的发展方向，实现真正的世界理解和交互能力。

Abstract: World models have emerged as a critical frontier in AI research, aiming to enhance large models by infusing them with physical dynamics and world knowledge. The core objective is to enable agents to understand, predict, and interact with complex environments. However, current research landscape remains fragmented, with approaches predominantly focused on injecting world knowledge into isolated tasks, such as visual prediction, 3D estimation, or symbol grounding, rather than establishing a unified definition or framework. While these task-specific integrations yield performance gains, they often lack the systematic coherence required for holistic world understanding. In this paper, we analyze the limitations of such fragmented approaches and propose a unified design specification for world models. We suggest that a robust world model should not be a loose collection of capabilities but a normative framework that integrally incorporates interaction, perception, symbolic reasoning, and spatial representation. This work aims to provide a structured perspective to guide future research toward more general, robust, and principled models of the world.

</details>


### [188] [Federated Vision Transformer with Adaptive Focal Loss for Medical Image Classification](https://arxiv.org/abs/2602.01633)
*Xinyuan Zhao,Yihang Wu,Ahmad Chaddad,Tareef Daqqaq,Reem Kateb*

Main category: cs.CV

TL;DR: 提出一个联邦学习框架，结合动态自适应焦点损失和客户端感知聚合策略，解决医疗图像分类中的数据异质性和类别不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 在数据隐私法规限制下，医疗图像等敏感数据难以集中访问。联邦学习虽然能保护隐私，但面临客户端数据异质性和类别不平衡的挑战，影响模型泛化能力。

Method: 1) 设计动态类别不平衡系数，根据每个客户端的样本分布和类别数据分布调整，确保少数类获得足够关注；2) 采用加权聚合策略，适应数据规模和特征，捕捉客户端间差异。

Result: 在ISIC、Ocular Disease和RSNA-ICH三个公开数据集上，提出的框架在大多数情况下优于DenseNet121、ResNet50、ViT-S/16、ViT-L/32、FedCLIP、Swin Transformer、CoAtNet和MixNet，准确率提升0.98%到41.69%。

Conclusion: 提出的动态自适应焦点损失和客户端感知聚合策略能有效解决联邦学习中的类别不平衡和客户端异质性问题，在医疗图像分类任务中表现优异。

Abstract: While deep learning models like Vision Transformer (ViT) have achieved significant advances, they typically require large datasets. With data privacy regulations, access to many original datasets is restricted, especially medical images. Federated learning (FL) addresses this challenge by enabling global model aggregation without data exchange. However, the heterogeneity of the data and the class imbalance that exist in local clients pose challenges for the generalization of the model. This study proposes a FL framework leveraging a dynamic adaptive focal loss (DAFL) and a client-aware aggregation strategy for local training. Specifically, we design a dynamic class imbalance coefficient that adjusts based on each client's sample distribution and class data distribution, ensuring minority classes receive sufficient attention and preventing sparse data from being ignored. To address client heterogeneity, a weighted aggregation strategy is adopted, which adapts to data size and characteristics to better capture inter-client variations. The classification results on three public datasets (ISIC, Ocular Disease and RSNA-ICH) show that the proposed framework outperforms DenseNet121, ResNet50, ViT-S/16, ViT-L/32, FedCLIP, Swin Transformer, CoAtNet, and MixNet in most cases, with accuracy improvements ranging from 0.98\% to 41.69\%. Ablation studies on the imbalanced ISIC dataset validate the effectiveness of the proposed loss function and aggregation strategy compared to traditional loss functions and other FL approaches. The codes can be found at: https://github.com/AIPMLab/ViT-FLDAF.

</details>


### [189] [ReCALL: Recalibrating Capability Degradation for MLLM-based Composed Image Retrieval](https://arxiv.org/abs/2602.01639)
*Tianyu Yang,ChenWei He,Xiangzhao Hao,Tianyue Wang,Jiarui Guo,Haiyun Guo,Leigang Qu,Jinqiao Wang,Tat-Seng Chua*

Main category: cs.CV

TL;DR: ReCALL框架解决生成式MLLM适配为检索器时的能力退化问题，通过诊断-生成-精炼流程提升组合图像检索性能


<details>
  <summary>Details</summary>
Motivation: 现有方法将生成式多模态大语言模型（MLLM）适配为单嵌入判别式检索器时，会引发范式冲突，导致原生细粒度推理能力退化，影响组合图像检索效果

Method: 提出ReCALL框架：1) 通过自引导信息实例挖掘诊断检索器的认知盲点；2) 使用CoT提示基础MLLM生成纠正指令和三元组，并通过VQA一致性过滤进行质量控制；3) 采用分组对比方案在生成的三元组上进行持续训练，将细粒度视觉语义区分内化到检索器中

Result: 在CIRR和FashionIQ数据集上的大量实验表明，ReCALL能持续校准退化能力，并达到最先进的性能

Conclusion: ReCALL通过诊断-生成-精炼流程有效解决了生成式MLLM适配为检索器时的能力退化问题，实现了判别式嵌入空间与MLLM内在组合推理能力的重新对齐

Abstract: Composed Image Retrieval (CIR) aims to retrieve target images based on a hybrid query comprising a reference image and a modification text. Early dual-tower Vision-Language Models (VLMs) struggle with cross-modality compositional reasoning required for this task. Recently, adapting generative Multimodal Large Language Models (MLLMs) for retrieval offers a promising direction. However, we identify that this adaptation strategy overlooks a fundamental issue: adapting a generative MLLM into a single-embedding discriminative retriever triggers a paradigm conflict, which leads to Capability Degradation - the deterioration of native fine-grained reasoning after retrieval adaptation. To address this challenge, we propose ReCALL (Recalibrating Capability Degradation), a model-agnostic framework that follows a diagnose-generate-refine pipeline: Firstly, we diagnose cognitive blind spots of the retriever via self-guided informative instance mining. Next, we generate corrective instructions and triplets by CoT prompting the foundation MLLM and conduct quality control with VQA-based consistency filtering. Finally, we refine the retriever through continual training on these triplets with a grouped contrastive scheme, thereby internalizing fine-grained visual-semantic distinctions and realigning the discriminative embedding space of retriever with intrinsic compositional reasoning within the MLLM. Extensive experiments on CIRR and FashionIQ show that ReCALL consistently recalibrates degraded capabilities and achieves state-of-the-art performance. Code will be released soon.

</details>


### [190] [Contribution-aware Token Compression for Efficient Video Understanding via Reinforcement Learning](https://arxiv.org/abs/2602.01649)
*Yinchao Ma,Qiang Zhou,Zhibin Wang,Xianing Chen,Hanqing Yang,Jun Song,Bo Zheng*

Main category: cs.CV

TL;DR: CaCoVID提出了一种基于贡献感知的视频token压缩算法，通过强化学习优化token选择策略，显著降低视频大语言模型的推理计算开销。


<details>
  <summary>Details</summary>
Motivation: 视频大语言模型在视频理解任务中表现出色，但视频token的冗余性导致推理时计算开销巨大，限制了实际部署。现有压缩算法通常基于注意力分数保留特征，但注意力分数与对正确答案的实际贡献之间的关系不明确。

Method: 1. 提出基于强化学习的框架，优化策略网络以选择对正确预测贡献最大的视频token组合；2. 提出在线组合空间采样的组合策略优化算法，大幅减少视频token组合的探索空间并加速策略收敛。

Result: 在多个视频理解基准测试上的广泛实验证明了CaCoVID的有效性。

Conclusion: CaCoVID通过明确优化基于token贡献的选择策略，实现了从被动token保留到主动发现最优压缩token组合的范式转变，显著提升了视频大语言模型的推理效率。

Abstract: Video large language models have demonstrated remarkable capabilities in video understanding tasks. However, the redundancy of video tokens introduces significant computational overhead during inference, limiting their practical deployment. Many compression algorithms are proposed to prioritize retaining features with the highest attention scores to minimize perturbations in attention computations. However, the correlation between attention scores and their actual contribution to correct answers remains ambiguous. To address the above limitation, we propose a novel \textbf{C}ontribution-\textbf{a}ware token \textbf{Co}mpression algorithm for \textbf{VID}eo understanding (\textbf{CaCoVID}) that explicitly optimizes the token selection policy based on the contribution of tokens to correct predictions. First, we introduce a reinforcement learning-based framework that optimizes a policy network to select video token combinations with the greatest contribution to correct predictions. This paradigm shifts the focus from passive token preservation to active discovery of optimal compressed token combinations. Secondly, we propose a combinatorial policy optimization algorithm with online combination space sampling, which dramatically reduces the exploration space for video token combinations and accelerates the convergence speed of policy optimization. Extensive experiments on diverse video understanding benchmarks demonstrate the effectiveness of CaCoVID. Codes will be released.

</details>


### [191] [Rethinking Genomic Modeling Through Optical Character Recognition](https://arxiv.org/abs/2602.02014)
*Hongxin Xiang,Pengsen Ma,Yunkang Cao,Di Yu,Haowen Chen,Xinyu Yang,Xiangxiang Zeng*

Main category: cs.CV

TL;DR: OpticalDNA：基于视觉的基因组建模框架，将DNA视为OCR风格的文档进行理解，通过视觉DNA编码器实现高效压缩，在长序列任务中性能优于传统语言模型方法


<details>
  <summary>Details</summary>
Motivation: 当前基因组基础模型大多采用语言模型架构，将DNA视为一维token序列，但这种方法与稀疏、不连续的基因组语义结构不匹配，导致在低信息背景上浪费计算资源，且无法实现理解驱动的长上下文压缩

Method: 将DNA渲染为结构化视觉布局，训练OCR能力的视觉-语言模型，包含视觉DNA编码器和文档解码器。编码器生成紧凑、可重构的视觉token实现高保真压缩，定义基于核心基因组原语的提示条件目标（读取、区域定位、子序列检索、掩码跨度补全）

Result: 在多样化基因组基准测试中持续优于近期基线；在长达45万个碱基的序列上，以近20倍更少的有效token实现最佳整体性能；仅使用256k可训练参数即可超越激活参数多达985倍的模型

Conclusion: OpticalDNA通过视觉文档理解范式重新构建基因组建模，实现了布局感知的DNA表示，在减少有效token预算的同时保留细粒度基因组信息，为长序列基因组分析提供了高效解决方案

Abstract: Recent genomic foundation models largely adopt large language model architectures that treat DNA as a one-dimensional token sequence. However, exhaustive sequential reading is structurally misaligned with sparse and discontinuous genomic semantics, leading to wasted computation on low-information background and preventing understanding-driven compression for long contexts. Here, we present OpticalDNA, a vision-based framework that reframes genomic modeling as Optical Character Recognition (OCR)-style document understanding. OpticalDNA renders DNA into structured visual layouts and trains an OCR-capable vision--language model with a \emph{visual DNA encoder} and a \emph{document decoder}, where the encoder produces compact, reconstructible visual tokens for high-fidelity compression. Building on this representation, OpticalDNA defines prompt-conditioned objectives over core genomic primitives-reading, region grounding, subsequence retrieval, and masked span completion-thereby learning layout-aware DNA representations that retain fine-grained genomic information under a reduced effective token budget. Across diverse genomic benchmarks, OpticalDNA consistently outperforms recent baselines; on sequences up to 450k bases, it achieves the best overall performance with nearly $20\times$ fewer effective tokens, and surpasses models with up to $985\times$ more activated parameters while tuning only 256k \emph{trainable} parameters.

</details>


### [192] [From Frames to Sequences: Temporally Consistent Human-Centric Dense Prediction](https://arxiv.org/abs/2602.01661)
*Xingyu Miao,Junting Dong,Qin Zhao,Yuhang Yang,Junhao Chen,Yang Long*

Main category: cs.CV

TL;DR: 提出一个合成数据流水线和统一ViT密集预测模型，用于视频中时间一致的人体中心密集预测，通过两阶段训练实现空间表示和时间一致性。


<details>
  <summary>Details</summary>
Motivation: 现有模型在单帧预测上表现良好，但在运动、遮挡和光照变化下会出现闪烁问题，且缺乏针对多个密集任务的配对人体视频监督数据。

Method: 1) 构建可扩展的合成数据流水线，生成真实感人体帧和运动对齐序列，提供像素级深度、法线和掩码标签；2) 训练统一的ViT密集预测器，通过CSE嵌入注入显式人体几何先验，并使用轻量级通道重加权模块提升几何特征可靠性；3) 采用两阶段训练策略：静态预训练+动态序列监督。

Result: 在THuman2.1和Hi4D数据集上达到最先进性能，并能有效泛化到真实世界视频中。

Conclusion: 提出的合成数据流水线和统一密集预测模型解决了视频中人体中心密集预测的时间一致性问题，通过几何先验和两阶段训练实现了优异的性能和泛化能力。

Abstract: In this work, we focus on the challenge of temporally consistent human-centric dense prediction across video sequences. Existing models achieve strong per-frame accuracy but often flicker under motion, occlusion, and lighting changes, and they rarely have paired human video supervision for multiple dense tasks. We address this gap with a scalable synthetic data pipeline that generates photorealistic human frames and motion-aligned sequences with pixel-accurate depth, normals, and masks. Unlike prior static data synthetic pipelines, our pipeline provides both frame-level labels for spatial learning and sequence-level supervision for temporal learning. Building on this, we train a unified ViT-based dense predictor that (i) injects an explicit human geometric prior via CSE embeddings and (ii) improves geometry-feature reliability with a lightweight channel reweighting module after feature fusion. Our two-stage training strategy, combining static pretraining with dynamic sequence supervision, enables the model first to acquire robust spatial representations and then refine temporal consistency across motion-aligned sequences. Extensive experiments show that we achieve state-of-the-art performance on THuman2.1 and Hi4D and generalize effectively to in-the-wild videos.

</details>


### [193] [Moonworks Lunara Aesthetic II: An Image Variation Dataset](https://arxiv.org/abs/2602.01666)
*Yan Wang,Partho Hassan,Samiha Sadeka,Nada Soliman,M M Sayeef Abdullah,Sabit Hassan*

Main category: cs.CV

TL;DR: Lunara Aesthetic II是一个公开的图像数据集，包含2,854个锚点链接的变体对，用于评估和学习图像生成系统中的上下文一致性，同时保持身份稳定性和高美学质量。


<details>
  <summary>Details</summary>
Motivation: 现代图像生成和编辑系统需要评估上下文一致性的能力，但缺乏专门用于此目的的高质量、伦理来源的数据集。现有数据集往往在身份保持和美学质量方面存在不足。

Method: 数据集基于Moonworks原创的艺术和摄影作品，通过应用照明、天气、视角、场景构图、色调或情绪等上下文变换，创建锚点链接的变体对，同时保持底层身份稳定。

Result: 数据集显示出高身份稳定性、强目标属性实现能力，以及超越大规模网络数据集的稳健美学特征。在Apache 2.0许可下公开，可用于基准测试、微调和分析。

Conclusion: Lunara Aesthetic II为图像生成和图像到图像系统提供了可解释的关系监督，支持上下文泛化、身份保持和编辑鲁棒性的评估与学习。

Abstract: We introduce Lunara Aesthetic II, a publicly released, ethically sourced image dataset designed to support controlled evaluation and learning of contextual consistency in modern image generation and editing systems. The dataset comprises 2,854 anchor-linked variation pairs derived from original art and photographs created by Moonworks. Each variation pair applies contextual transformations, such as illumination, weather, viewpoint, scene composition, color tone, or mood; while preserving a stable underlying identity. Lunara Aesthetic II operationalizes identity-preserving contextual variation as a supervision signal while also retaining Lunara's signature high aesthetic scores. Results show high identity stability, strong target attribute realization, and a robust aesthetic profile that exceeds large-scale web datasets. Released under the Apache 2.0 license, Lunara Aesthetic II is intended for benchmarking, fine-tuning, and analysis of contextual generalization, identity preservation, and edit robustness in image generation and image-to-image systems with interpretable, relational supervision. The dataset is publicly available at: https://huggingface.co/datasets/moonworks/lunara-aesthetic-image-variations.

</details>


### [194] [Real-Time Loop Closure Detection in Visual SLAM via NetVLAD and Faiss](https://arxiv.org/abs/2602.01673)
*Enguang Fan*

Main category: cs.CV

TL;DR: 本文评估了NetVLAD作为回环检测模块，相比传统DBoW方法在KITTI数据集上表现更优，通过Faiss加速实现实时查询，成为SLAM中实用的回环检测替代方案。


<details>
  <summary>Details</summary>
Motivation: 传统词袋方法（如DBoW）在回环检测中效率高但容易受外观变化和感知混淆影响，而深度学习视觉位置识别方法（如NetVLAD）虽然鲁棒性强，但计算成本高，被认为难以实时运行。本文旨在评估NetVLAD作为回环检测模块的实际可行性。

Method: 在KITTI数据集上对NetVLAD作为回环检测模块进行实证评估，并与DBoW进行对比。引入了细粒度Top-K精确率-召回率曲线来更好地反映回环检测场景（查询可能有零个或多个有效匹配）。使用Faiss加速的最近邻搜索实现实时查询速度。

Result: 通过Faiss加速，NetVLAD实现了实时查询速度，同时在准确性和鲁棒性方面优于DBoW。细粒度Top-K评估方法更好地反映了回环检测的实际性能。

Conclusion: NetVLAD通过Faiss加速能够实现实时性能，在准确性和鲁棒性上超越传统DBoW方法，成为SLAM系统中实用的回环检测替代方案，解决了深度学习方法计算成本高的障碍。

Abstract: Loop closure detection (LCD) is a core component of simultaneous localization and mapping (SLAM): it identifies revisited places and enables pose-graph constraints that correct accumulated drift. Classic bag-of-words approaches such as DBoW are efficient but often degrade under appearance change and perceptual aliasing. In parallel, deep learning-based visual place recognition (VPR) descriptors (e.g., NetVLAD and Transformer-based models) offer stronger robustness, but their computational cost is often viewed as a barrier to real-time SLAM. In this paper, we empirically evaluate NetVLAD as an LCD module and compare it against DBoW on the KITTI dataset. We introduce a Fine-Grained Top-K precision-recall curve that better reflects LCD settings where a query may have zero or multiple valid matches. With Faiss-accelerated nearestneighbor search, NetVLAD achieves real-time query speed while improving accuracy and robustness over DBoW, making it a practical drop-in alternative for LCD in SLAM.

</details>


### [195] [Vision-DeepResearch Benchmark: Rethinking Visual and Textual Search for Multimodal Large Language Models](https://arxiv.org/abs/2602.02185)
*Yu Zeng,Wenxuan Huang,Zhen Fang,Shuang Chen,Yufan Shen,Yishuo Cai,Xiaoman Wang,Zhenfei Yin,Lin Chen,Zehui Chen,Shiting Huang,Yiming Zhao,Yao Hu,Philip Torr,Wanli Ouyang,Shaosheng Cao*

Main category: cs.CV

TL;DR: 提出了Vision-DeepResearch基准(VDR-Bench)，包含2000个VQA实例，用于评估多模态大语言模型的视觉和文本搜索能力，并提出了多轮裁剪搜索工作流程来提升视觉检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有评估基准存在两个主要问题：1) 不是以视觉搜索为中心，答案经常通过文本问题中的跨文本线索泄露，或可以从当前MLLMs的先验世界知识中推断；2) 评估场景过于理想化，图像搜索可以通过近似完全匹配获取信息，文本搜索则过于直接且挑战性不足。

Method: 构建了VDR-Bench基准，包含2000个VQA实例，采用精心设计的多阶段策划流程和严格的专家评审。同时提出了简单的多轮裁剪搜索工作流程，以提升当前MLLMs在真实视觉检索场景中的能力。

Result: VDR-Bench基准能够有效评估Vision-DeepResearch系统在真实世界条件下的行为。多轮裁剪搜索策略被证明能够有效提升模型在真实视觉检索场景中的性能。

Conclusion: 该研究为未来多模态深度研究系统的设计提供了实用指导，提出的基准和工作流程有助于更准确地评估和提升多模态大语言模型的视觉和文本搜索能力。

Abstract: Multimodal Large Language Models (MLLMs) have advanced VQA and now support Vision-DeepResearch systems that use search engines for complex visual-textual fact-finding. However, evaluating these visual and textual search abilities is still difficult, and existing benchmarks have two major limitations. First, existing benchmarks are not visual search-centric: answers that should require visual search are often leaked through cross-textual cues in the text questions or can be inferred from the prior world knowledge in current MLLMs. Second, overly idealized evaluation scenario: On the image-search side, the required information can often be obtained via near-exact matching against the full image, while the text-search side is overly direct and insufficiently challenging. To address these issues, we construct the Vision-DeepResearch benchmark (VDR-Bench) comprising 2,000 VQA instances. All questions are created via a careful, multi-stage curation pipeline and rigorous expert review, designed to assess the behavior of Vision-DeepResearch systems under realistic real-world conditions. Moreover, to address the insufficient visual retrieval capabilities of current MLLMs, we propose a simple multi-round cropped-search workflow. This strategy is shown to effectively improve model performance in realistic visual retrieval scenarios. Overall, our results provide practical guidance for the design of future multimodal deep-research systems. The code will be released in https://github.com/Osilly/Vision-DeepResearch.

</details>


### [196] [VRGaussianAvatar: Integrating 3D Gaussian Avatars into VR](https://arxiv.org/abs/2602.01674)
*Hail Song,Boram Yoon,Seokhwan Yang,Seoyoung Kang,Hyunjeong Kim,Henning Metzmacher,Woontack Woo*

Main category: cs.CV

TL;DR: VRGaussianAvatar：一个实时全身3D高斯溅射虚拟现实系统，仅使用头戴显示器追踪信号，通过并行管道实现高效渲染


<details>
  <summary>Details</summary>
Motivation: 现有虚拟现实中的虚拟化身系统通常需要复杂的传感器或难以实现实时渲染，特别是对于高质量的3D高斯溅射表示。需要一种仅使用头戴显示器追踪信号就能实现实时全身3D高斯溅射虚拟化身的系统。

Method: 采用并行管道架构，包含VR前端和GA后端。前端使用逆运动学估计全身姿态并传输数据，后端从单张图像重建3D高斯溅射虚拟化身。引入双目批处理技术，在单批次中联合处理左右眼视图以提高立体渲染效率。

Result: 系统能够维持交互式VR性能，在用户研究中相比基于图像和网格的虚拟化身基线，获得了更高的感知外观相似性、体现感和合理性评分。

Conclusion: VRGaussianAvatar展示了仅使用头戴显示器追踪信号实现实时全身3D高斯溅射虚拟化身的可行性，为虚拟现实中的高质量虚拟化身提供了高效解决方案。

Abstract: We present VRGaussianAvatar, an integrated system that enables real-time full-body 3D Gaussian Splatting (3DGS) avatars in virtual reality using only head-mounted display (HMD) tracking signals. The system adopts a parallel pipeline with a VR Frontend and a GA Backend. The VR Frontend uses inverse kinematics to estimate full-body pose and streams the resulting pose along with stereo camera parameters to the backend. The GA Backend stereoscopically renders a 3DGS avatar reconstructed from a single image. To improve stereo rendering efficiency, we introduce Binocular Batching, which jointly processes left and right eye views in a single batched pass to reduce redundant computation and support high-resolution VR displays. We evaluate VRGaussianAvatar with quantitative performance tests and a within-subject user study against image- and video-based mesh avatar baselines. Results show that VRGaussianAvatar sustains interactive VR performance and yields higher perceived appearance similarity, embodiment, and plausibility. Project page and source code are available at https://vrgaussianavatar.github.io.

</details>


### [197] [SMTrack: State-Aware Mamba for Efficient Temporal Modeling in Visual Tracking](https://arxiv.org/abs/2602.01677)
*Yinchao Ma,Dengqing Yang,Zhangyu He,Wenfei Yang,Tianzhu Zhang*

Main category: cs.CV

TL;DR: SMTrack：基于状态空间模型的新型视觉跟踪方法，通过选择性状态感知空间模型和隐藏状态传播，以线性计算复杂度实现长程时序建模


<details>
  <summary>Details</summary>
Motivation: 传统CNN和Transformer架构在视觉跟踪中建模长程时序依赖存在固有局限性，需要复杂定制模块或高昂计算成本。受状态空间模型成功启发，需要一种简洁高效的时序建模范式。

Method: 提出状态感知Mamba跟踪器(SMTrack)：1) 选择性状态感知空间模型，具有状态级参数以捕捉多样化时序线索；2) 训练时线性计算复杂度的长程时序交互；3) 通过隐藏状态传播和更新实现帧间交互，降低跟踪时计算成本

Result: 大量实验结果表明，SMTrack在低计算成本下实现了有前景的性能表现

Conclusion: SMTrack为视觉跟踪提供了一种简洁高效的时序建模范式，无需复杂定制模块即可构建长程时序依赖，在计算效率和性能间取得良好平衡

Abstract: Visual tracking aims to automatically estimate the state of a target object in a video sequence, which is challenging especially in dynamic scenarios. Thus, numerous methods are proposed to introduce temporal cues to enhance tracking robustness. However, conventional CNN and Transformer architectures exhibit inherent limitations in modeling long-range temporal dependencies in visual tracking, often necessitating either complex customized modules or substantial computational costs to integrate temporal cues. Inspired by the success of the state space model, we propose a novel temporal modeling paradigm for visual tracking, termed State-aware Mamba Tracker (SMTrack), providing a neat pipeline for training and tracking without needing customized modules or substantial computational costs to build long-range temporal dependencies. It enjoys several merits. First, we propose a novel selective state-aware space model with state-wise parameters to capture more diverse temporal cues for robust tracking. Second, SMTrack facilitates long-range temporal interactions with linear computational complexity during training. Third, SMTrack enables each frame to interact with previously tracked frames via hidden state propagation and updating, which releases computational costs of handling temporal cues during tracking. Extensive experimental results demonstrate that SMTrack achieves promising performance with low computational costs.

</details>


### [198] [FreshMem: Brain-Inspired Frequency-Space Hybrid Memory for Streaming Video Understanding](https://arxiv.org/abs/2602.01683)
*Kangcong Li,Peng Ye,Lin Zhang,Chao Wang,Huafeng Qin,Tao Chen*

Main category: cs.CV

TL;DR: FreshMem提出了一种频率-空间混合记忆网络，用于多模态大语言模型的在线流式视频理解，通过多尺度频率记忆和空间缩略图记忆模块，在保持短期保真度的同时实现长期连贯性，无需训练即可显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法缺乏灵活的自适应性，导致不可逆的细节丢失和上下文碎片化问题。需要将多模态大语言模型从离线理解过渡到在线流式视频理解，以实现连续感知。

Method: 提出FreshMem频率-空间混合记忆网络，受大脑对数感知和记忆巩固机制启发。包含两个协同模块：1) 多尺度频率记忆(MFM)：将溢出的帧投影为代表频率系数，辅以残差细节重构全局历史"要点"；2) 空间缩略图记忆(STM)：通过自适应压缩策略将连续流离散化为情节聚类，蒸馏为高密度空间缩略图。

Result: 在StreamingBench、OV-Bench和OVO-Bench上分别获得5.20%、4.52%和2.34%的性能提升。作为无需训练的方法，优于多个完全微调的方法，为长时域流式视频理解提供了高效范式。

Conclusion: FreshMem通过频率-空间混合记忆网络有效解决了流式视频理解中的细节丢失和上下文碎片化问题，实现了短期保真度与长期连贯性的平衡，为在线视频理解提供了高效解决方案。

Abstract: Transitioning Multimodal Large Language Models (MLLMs) from offline to online streaming video understanding is essential for continuous perception. However, existing methods lack flexible adaptivity, leading to irreversible detail loss and context fragmentation. To resolve this, we propose FreshMem, a Frequency-Space Hybrid Memory network inspired by the brain's logarithmic perception and memory consolidation. FreshMem reconciles short-term fidelity with long-term coherence through two synergistic modules: Multi-scale Frequency Memory (MFM), which projects overflowing frames into representative frequency coefficients, complemented by residual details to reconstruct a global historical "gist"; and Space Thumbnail Memory (STM), which discretizes the continuous stream into episodic clusters by employing an adaptive compression strategy to distill them into high-density space thumbnails. Extensive experiments show that FreshMem significantly boosts the Qwen2-VL baseline, yielding gains of 5.20%, 4.52%, and 2.34% on StreamingBench, OV-Bench, and OVO-Bench, respectively. As a training-free solution, FreshMem outperforms several fully fine-tuned methods, offering a highly efficient paradigm for long-horizon streaming video understanding.

</details>


### [199] [Cross-Modal Alignment and Fusion for RGB-D Transmission-Line Defect Detection](https://arxiv.org/abs/2602.01696)
*Jiaming Cui,Shuai Zhou,Wenqiang Li,Ruifeng Qin,Feng Shen*

Main category: cs.CV

TL;DR: CMAFNet：用于输电线路缺陷检测的跨模态对齐融合网络，通过RGB外观与深度几何信息融合，在复杂背景下显著提升小尺度缺陷检测性能。


<details>
  <summary>Details</summary>
Motivation: 输电线路缺陷检测面临三大挑战：小尺度缺陷占主导（94.5%为小目标）、复杂背景干扰、光照变化。现有RGB检测器在几何特征微弱的缺陷与视觉相似背景结构之间难以区分，特别是在色彩对比度有限的情况下。

Method: 提出CMAFNet跨模态对齐融合网络，采用"先净化后融合"范式：1) 语义重组模块通过学习码本进行基于字典的特征净化，抑制模态特定噪声同时保留缺陷判别信息；2) 上下文语义集成框架使用部分通道注意力捕获全局空间依赖，增强结构语义推理；3) 净化阶段的位置归一化强制显式重建驱动的跨模态对齐，确保异构特征在融合前的统计兼容性。

Result: 在TLRGBD基准测试中（94.5%为小目标），CMAFNet达到32.2% mAP@50和12.5% APs，分别比最强基线提升9.8和4.0个百分点。轻量级变体仅4.9M参数，在228 FPS下达到24.8% mAP50，超越所有YOLO检测器，同时以显著更低计算成本匹配基于Transformer的方法。

Conclusion: CMAFNet通过跨模态特征对齐与融合，有效解决了输电线路小尺度缺陷检测难题，在复杂背景和光照变化下表现出色，同时提供了高效实用的轻量级版本。

Abstract: Transmission line defect detection remains challenging for automated UAV inspection due to the dominance of small-scale defects, complex backgrounds, and illumination variations. Existing RGB-based detectors, despite recent progress, struggle to distinguish geometrically subtle defects from visually similar background structures under limited chromatic contrast. This paper proposes CMAFNet, a Cross-Modal Alignment and Fusion Network that integrates RGB appearance and depth geometry through a principled purify-then-fuse paradigm. CMAFNet consists of a Semantic Recomposition Module that performs dictionary-based feature purification via a learned codebook to suppress modality-specific noise while preserving defect-discriminative information, and a Contextual Semantic Integration Framework that captures global spatial dependencies using partial-channel attention to enhance structural semantic reasoning. Position-wise normalization within the purification stage enforces explicit reconstruction-driven cross-modal alignment, ensuring statistical compatibility between heterogeneous features prior to fusion. Extensive experiments on the TLRGBD benchmark, where 94.5% of instances are small objects, demonstrate that CMAFNet achieves 32.2% mAP@50 and 12.5% APs, outperforming the strongest baseline by 9.8 and 4.0 percentage points, respectively. A lightweight variant reaches 24.8% mAP50 at 228 FPS with only 4.9M parameters, surpassing all YOLO-based detectors while matching transformer-based methods at substantially lower computational cost.

</details>


### [200] [Physics Informed Generative AI Enabling Labour Free Segmentation For Microscopy Analysis](https://arxiv.org/abs/2602.01710)
*Salma Zahran,Zhou Ao,Zhengyang Zhang,Chen Chi,Chenchen Yuan,Yanming Wang*

Main category: cs.CV

TL;DR: 提出一个无需人工标注的显微图像语义分割框架，通过相场模拟生成微观结构形态，用CycleGAN将模拟数据转换为逼真的SEM图像，训练U-Net模型在实验图像上取得优异泛化性能。


<details>
  <summary>Details</summary>
Motivation: 显微图像语义分割对高通量材料表征至关重要，但专家标注数据成本高、主观性强且稀缺。基于物理的模拟虽然可扩展，但训练模型因领域差距（缺乏复杂纹理、噪声和成像伪影）而无法泛化到实验数据。

Method: 1) 使用相场模拟生成大量微观结构形态和完美标注掩码；2) 采用CycleGAN进行非配对图像转换，将干净模拟数据转换为逼真的SEM图像；3) 仅用合成数据训练U-Net分割模型。

Result: 在未见实验图像上，模型取得平均边界F1分数0.90和交并比0.88。t-SNE特征空间投影和香农熵分析证实合成图像在统计和特征上与真实数据无法区分。

Conclusion: 该生成框架完全解耦模型训练与人工标注，将数据稀缺问题转化为数据丰富问题，为加速材料发现和分析提供了鲁棒、全自动的解决方案。

Abstract: Semantic segmentation of microscopy images is a critical task for high-throughput materials characterisation, yet its automation is severely constrained by the prohibitive cost, subjectivity, and scarcity of expert-annotated data. While physics-based simulations offer a scalable alternative to manual labelling, models trained on such data historically fail to generalise due to a significant domain gap, lacking the complex textures, noise patterns, and imaging artefacts inherent to experimental data. This paper introduces a novel framework for labour-free segmentation that successfully bridges this simulation-to-reality gap. Our pipeline leverages phase-field simulations to generate an abundant source of microstructural morphologies with perfect, intrinsically-derived ground-truth masks. We then employ a Cycle-Consistent Generative Adversarial Network (CycleGAN) for unpaired image-to-image translation, transforming the clean simulations into a large-scale dataset of high-fidelity, realistic SEM images. A U-Net model, trained exclusively on this synthetic data, demonstrated remarkable generalisation when deployed on unseen experimental images, achieving a mean Boundary F1-Score of 0.90 and an Intersection over Union (IOU) of 0.88. Comprehensive validation using t-SNE feature-space projection and Shannon entropy analysis confirms that our synthetic images are statistically and featurally indistinguishable from the real data manifold. By completely decoupling model training from manual annotation, our generative framework transforms a data-scarce problem into one of data abundance, providing a robust and fully automated solution to accelerate materials discovery and analysis.

</details>


### [201] [FastPhysGS: Accelerating Physics-based Dynamic 3DGS Simulation via Interior Completion and Adaptive Optimization](https://arxiv.org/abs/2602.01723)
*Yikun Ma,Yiqing Li,Jingwen Ye,Zhongkai Wu,Weidong Zhang,Lin Gao,Zhi Jin*

Main category: cs.CV

TL;DR: FastPhysGS：基于3D高斯泼溅的快速物理模拟框架，通过实例感知粒子填充和双向图解耦优化，在1分钟内实现高保真物理模拟


<details>
  <summary>Details</summary>
Motivation: 现有方法将3D高斯泼溅扩展到4D物理模拟存在挑战：要么依赖手动参数调整，要么从视频扩散模型蒸馏动态，限制了泛化能力和优化效率。基于LLMs/VLMs的方法存在文本/图像到3D的感知差距，导致不稳定的物理行为，且往往忽略3DGS的表面结构，产生不合理的运动。

Method: 提出FastPhysGS框架：1）实例感知粒子填充（IPF）结合蒙特卡洛重要性采样（MCIS），高效填充内部粒子同时保持几何保真度；2）双向图解耦优化（BGDO），自适应策略快速优化从VLM预测的材料参数。

Result: FastPhysGS在仅使用7GB运行时内存的情况下，1分钟内实现高保真物理模拟，优于先前工作，具有广泛的应用潜力。

Conclusion: FastPhysGS提供了一个快速、鲁棒的物理动态3D高斯泼溅模拟框架，通过创新的粒子填充和优化策略，解决了现有方法的局限性，实现了高效的物理模拟。

Abstract: Extending 3D Gaussian Splatting (3DGS) to 4D physical simulation remains challenging. Based on the Material Point Method (MPM), existing methods either rely on manual parameter tuning or distill dynamics from video diffusion models, limiting the generalization and optimization efficiency. Recent attempts using LLMs/VLMs suffer from a text/image-to-3D perceptual gap, yielding unstable physics behavior. In addition, they often ignore the surface structure of 3DGS, leading to implausible motion. We propose FastPhysGS, a fast and robust framework for physics-based dynamic 3DGS simulation:(1) Instance-aware Particle Filling (IPF) with Monte Carlo Importance Sampling (MCIS) to efficiently populate interior particles while preserving geometric fidelity; (2) Bidirectional Graph Decoupling Optimization (BGDO), an adaptive strategy that rapidly optimizes material parameters predicted from a VLM. Experiments show FastPhysGS achieves high-fidelity physical simulation in 1 minute using only 7 GB runtime memory, outperforming prior works with broad potential applications.

</details>


### [202] [DenVisCoM: Dense Vision Correspondence Mamba for Efficient and Real-time Optical Flow and Stereo Estimation](https://arxiv.org/abs/2602.01724)
*Tushar Anand,Maheswar Bora,Antitza Dantcheva,Abhijit Das*

Main category: cs.CV

TL;DR: 提出DenVisCoM Mamba块和混合架构，用于实时联合估计光流和视差


<details>
  <summary>Details</summary>
Motivation: 多视图几何和运动任务本质相关，需要统一架构同时处理，并解决实时推理、内存占用和准确性的平衡问题

Method: 基于DenVisCoM Mamba块和Transformer注意力块的混合架构，专门为光流和视差联合估计设计

Result: 在大量数据集上验证了准确性和实时处理的平衡，模型能够实时准确估计光流和视差

Conclusion: 提出的混合架构有效解决了运动估计和3D密集感知任务的联合实时处理问题，代码已开源

Abstract: In this work, we propose a novel Mamba block DenVisCoM, as well as a novel hybrid architecture specifically tailored for accurate and real-time estimation of optical flow and disparity estimation. Given that such multi-view geometry and motion tasks are fundamentally related, we propose a unified architecture to tackle them jointly. Specifically, the proposed hybrid architecture is based on DenVisCoM and a Transformer-based attention block that efficiently addresses real-time inference, memory footprint, and accuracy at the same time for joint estimation of motion and 3D dense perception tasks. We extensively analyze the benchmark trade-off of accuracy and real-time processing on a large number of datasets. Our experimental results and related analysis suggest that our proposed model can accurately estimate optical flow and disparity estimation in real time. All models and associated code are available at https://github.com/vimstereo/DenVisCoM.

</details>


### [203] [Simplicity Prevails: The Emergence of Generalizable AIGI Detection in Visual Foundation Models](https://arxiv.org/abs/2602.01738)
*Yue Zhou,Xinan He,Kaiqing Lin,Bing Fan,Feng Ding,Bin Li*

Main category: cs.CV

TL;DR: 基于现代视觉基础模型冻结特征的简单线性分类器，在AI生成图像检测任务中超越了复杂专用检测器，特别是在真实场景下表现优异，但存在重捕获、传输等局限性。


<details>
  <summary>Details</summary>
Motivation: 现有AI生成图像检测器在精心设计的基准测试中表现优异，但在真实场景中性能急剧下降。研究者希望探索更简单有效的方法来解决这一现实世界应用问题。

Method: 使用现代视觉基础模型（包括Perception Encoder、MetaCLIP 2、DINOv3）的冻结特征，仅训练一个简单的线性分类器进行AI生成图像检测。

Result: 该方法不仅在标准基准测试中匹配专用检测器，在真实场景数据集上更是大幅超越，准确率提升超过30%。研究发现这种能力源于预训练数据中包含合成内容，视觉语言模型内化了伪造的显式语义概念，而自监督学习模型则隐式学习了判别性取证特征。

Conclusion: AI取证领域需要范式转变：从过度拟合静态基准测试转向利用基础模型不断演进的世界知识，以实现真实世界的可靠性。虽然基础模型方法表现出色，但仍存在重捕获、传输、VAE重建和局部编辑检测等局限性。

Abstract: While specialized detectors for AI-Generated Images (AIGI) achieve near-perfect accuracy on curated benchmarks, they suffer from a dramatic performance collapse in realistic, in-the-wild scenarios. In this work, we demonstrate that simplicity prevails over complex architectural designs. A simple linear classifier trained on the frozen features of modern Vision Foundation Models , including Perception Encoder, MetaCLIP 2, and DINOv3, establishes a new state-of-the-art. Through a comprehensive evaluation spanning traditional benchmarks, unseen generators, and challenging in-the-wild distributions, we show that this baseline not only matches specialized detectors on standard benchmarks but also decisively outperforms them on in-the-wild datasets, boosting accuracy by striking margins of over 30\%. We posit that this superior capability is an emergent property driven by the massive scale of pre-training data containing synthetic content. We trace the source of this capability to two distinct manifestations of data exposure: Vision-Language Models internalize an explicit semantic concept of forgery, while Self-Supervised Learning models implicitly acquire discriminative forensic features from the pretraining data. However, we also reveal persistent limitations: these models suffer from performance degradation under recapture and transmission, remain blind to VAE reconstruction and localized editing. We conclude by advocating for a paradigm shift in AI forensics, moving from overfitting on static benchmarks to harnessing the evolving world knowledge of foundation models for real-world reliability.

</details>


### [204] [Tail-Aware Post-Training Quantization for 3D Geometry Models](https://arxiv.org/abs/2602.01741)
*Sicheng Pan,Chen Tang,Shuzhao Xie,Ke Yang,Weixiang Zhang,Jiawei Li,Bin Chen,Shu-Tao Xia,Zhi Wang*

Main category: cs.CV

TL;DR: TAPTQ是一种专门为3D几何学习设计的尾部感知后训练量化方法，通过渐进校准构建、三元搜索优化和尾部误差引导的模块补偿，在保持精度的同时显著减少校准时间。


<details>
  <summary>Details</summary>
Motivation: 3D几何模型的复杂性和规模对资源受限平台的部署提出了挑战。传统的后训练量化方法主要针对2D视觉Transformer优化，无法有效迁移到3D模型，因为3D模型具有复杂的特征分布和过高的校准开销。

Method: 提出TAPTQ方法，包含三个核心创新：1）渐进粗到细校准构建策略，解决3D数据集的数据规模瓶颈；2）将量化区间搜索重新定义为优化问题，采用三元搜索求解器降低计算复杂度；3）尾部相对误差引导的模块补偿机制，自适应识别和修正对长尾激活异常值敏感的模块。

Result: 在VGGT和Pi3基准测试上的大量实验表明，TAPTQ在准确度上持续优于最先进的后训练量化方法，同时显著减少了校准时间。

Conclusion: TAPTQ为3D几何学习的量化部署提供了一种高效解决方案，解决了传统方法在3D场景下的局限性，代码即将发布。

Abstract: The burgeoning complexity and scale of 3D geometry models pose significant challenges for deployment on resource-constrained platforms. While Post-Training Quantization (PTQ) enables efficient inference without retraining, conventional methods, primarily optimized for 2D Vision Transformers, fail to transfer effectively to 3D models due to intricate feature distributions and prohibitive calibration overhead. To address these challenges, we propose TAPTQ, a Tail-Aware Post-Training Quantization pipeline specifically engineered for 3D geometric learning. Our contribution is threefold: (1) To overcome the data-scale bottleneck in 3D datasets, we develop a progressive coarse-to-fine calibration construction strategy that constructs a highly compact subset to achieve both statistical purity and geometric representativeness. (2) We reformulate the quantization interval search as an optimization problem and introduce a ternary-search-based solver, reducing the computational complexity from $\mathcal{O}(N)$ to $\mathcal{O}(\log N)$ for accelerated deployment. (3) To mitigate quantization error accumulation, we propose TRE-Guided Module-wise Compensation, which utilizes a Tail Relative Error (TRE) metric to adaptively identify and rectify distortions in modules sensitive to long-tailed activation outliers. Extensive experiments on the VGGT and Pi3 benchmarks demonstrate that TAPTQ consistently outperforms state-of-the-art PTQ methods in accuracy while significantly reducing calibration time. The code will be released soon.

</details>


### [205] [ObjEmbed: Towards Universal Multimodal Object Embeddings](https://arxiv.org/abs/2602.01753)
*Shenghao Fu,Yukun Su,Fengyun Rao,Jing Lyu,Xiaohua Xie,Wei-Shi Zheng*

Main category: cs.CV

TL;DR: ObjEmbed是一个新颖的多模态大语言模型嵌入方法，通过将图像分解为多个区域嵌入（每个对应一个对象）和全局嵌入，实现细粒度的图像-文本对齐，支持视觉定位、局部图像检索和全局图像检索等多种任务。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态嵌入模型虽然在全局图像-文本对齐方面表现出色，但在图像区域与特定短语之间的细粒度对齐方面存在困难。需要一种能够同时处理对象级语义和空间信息，并支持多种视觉理解任务的统一模型。

Method: ObjEmbed将输入图像分解为多个区域嵌入（每个对应一个对象）和全局嵌入。为每个区域生成两个互补的嵌入：用于语义匹配的对象嵌入和预测定位质量的IoU嵌入。最终的对象匹配分数结合了语义相似度和预测的IoU，实现更准确的检索。所有对象和完整图像都在单次前向传播中编码，效率高。

Result: 在18个不同的基准测试中表现出优越性能，展示了强大的语义区分能力。模型能够同时处理区域级和图像级任务，在视觉定位、局部图像检索和全局图像检索等任务上表现优异。

Conclusion: ObjEmbed通过对象导向的表示方法，成功解决了细粒度图像-文本对齐的挑战，提供了一个统一、高效且多功能的视觉理解框架，在多种任务上实现了优越性能。

Abstract: Aligning objects with corresponding textual descriptions is a fundamental challenge and a realistic requirement in vision-language understanding. While recent multimodal embedding models excel at global image-text alignment, they often struggle with fine-grained alignment between image regions and specific phrases. In this work, we present ObjEmbed, a novel MLLM embedding model that decomposes the input image into multiple regional embeddings, each corresponding to an individual object, along with global embeddings. It supports a wide range of visual understanding tasks like visual grounding, local image retrieval, and global image retrieval. ObjEmbed enjoys three key properties: (1) Object-Oriented Representation: It captures both semantic and spatial aspects of objects by generating two complementary embeddings for each region: an object embedding for semantic matching and an IoU embedding that predicts localization quality. The final object matching score combines semantic similarity with the predicted IoU, enabling more accurate retrieval. (2) Versatility: It seamlessly handles both region-level and image-level tasks. (3) Efficient Encoding: All objects in an image, along with the full image, are encoded in a single forward pass for high efficiency. Superior performance on 18 diverse benchmarks demonstrates its strong semantic discrimination.

</details>


### [206] [Spot-Wise Smart Parking: An Edge-Enabled Architecture with YOLOv11 and Digital Twin Integration](https://arxiv.org/abs/2602.01754)
*Gustavo P. C. P. da Luz,Alvaro M. Aspilcueta Narvaez,Tiago Godoi Bannwart,Gabriel Massuyoshi Sato,Luis Fernando Gomez Gonzalez,Juliana Freitag Borin*

Main category: cs.CV

TL;DR: 论文提出了一种基于距离感知匹配和自适应边界框分区的智能停车位级监控系统，在边缘设备上实现98.80%的平衡准确率和8秒推理时间，并引入了数字孪生雏形和基于电视盒子的应用支持服务器。


<details>
  <summary>Details</summary>
Motivation: 现有基于区域车辆计数的停车监控系统虽然准确率高，但无法提供车位级洞察和支持更高级应用。需要开发能够实现车位级监控、支持数字孪生演进且能在资源受限边缘设备上运行的系统。

Method: 1) 基于空间容差的距离感知匹配方法实现车位级监控；2) 针对挑战性空间的自适应边界框分区方法；3) 引入数字孪生雏形（Digital Shadow）可视化停车场实体；4) 基于改造电视盒子的应用支持服务器实现云服务、停车终端和统计机器人的可扩展通信。

Result: 系统在资源受限边缘设备上达到98.80%的平衡准确率，推理时间仅8秒。YOLOv11m模型大小40.5MB。实现了车位级监控能力，支持数字孪生演进，并通过硬件重用提升可持续性。

Conclusion: 提出的车位级监控系统成功克服了区域计数方法的局限性，在保持高准确率的同时实现实时性能，支持数字孪生演进，并通过硬件重用促进可持续性，为智能停车系统提供了更先进的解决方案。

Abstract: Smart parking systems help reduce congestion and minimize users' search time, thereby contributing to smart city adoption and enhancing urban mobility. In previous works, we presented a system developed on a university campus to monitor parking availability by estimating the number of free spaces from vehicle counts within a region of interest. Although this approach achieved good accuracy, it restricted the system's ability to provide spot-level insights and support more advanced applications. To overcome this limitation, we extend the system with a spot-wise monitoring strategy based on a distance-aware matching method with spatial tolerance, enhanced through an Adaptive Bounding Box Partitioning method for challenging spaces. The proposed approach achieves a balanced accuracy of 98.80% while maintaining an inference time of 8 seconds on a resource-constrained edge device, enhancing the capabilities of YOLOv11m, a model that has a size of 40.5 MB. In addition, two new components were introduced: (i) a Digital Shadow that visually represents parking lot entities as a base to evolve to a full Digital Twin, and (ii) an application support server based on a repurposed TV box. The latter not only enables scalable communication among cloud services, the parking totem, and a bot that provides detailed spot occupancy statistics, but also promotes hardware reuse as a step towards greater sustainability.

</details>


### [207] [Mind-Brush: Integrating Agentic Cognitive Search and Reasoning into Image Generation](https://arxiv.org/abs/2602.01756)
*Jun He,Junyan Ye,Zilong Huang,Dongzhi Jiang,Chenjue Zhang,Leqi Zhu,Renrui Zhang,Xiang Zhang,Weijia Li*

Main category: cs.CV

TL;DR: Mind-Brush是一个统一的智能框架，将图像生成转化为动态的知识驱动工作流，通过"思考-研究-创造"范式主动检索多模态证据并使用推理工具解决隐含视觉约束，显著提升了意图理解和复杂知识推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像生成模型主要是静态的文本到像素解码器，难以理解用户的隐含意图。虽然新兴的统一理解-生成模型改进了意图理解，但仍难以处理涉及复杂知识推理的任务，且受限于静态内部先验，无法适应现实世界的动态变化。

Method: 提出Mind-Brush统一智能框架，模拟人类"思考-研究-创造"范式：1) 主动检索多模态证据来锚定分布外概念；2) 使用推理工具解决隐含视觉约束；3) 将生成过程转化为动态的知识驱动工作流。同时提出Mind-Bench基准测试，包含500个样本，涵盖实时新闻、新兴概念以及数学和地理推理等领域。

Result: 实验表明，Mind-Brush显著增强了统一模型的能力，在Mind-Bench基准上实现了Qwen-Image基线的从零到一能力跃升，同时在WISE和RISE等现有基准测试中取得了优越结果。

Conclusion: Mind-Brush通过将生成过程转化为动态的知识驱动工作流，有效解决了现有模型在理解隐含意图、处理复杂知识推理和适应现实世界动态变化方面的局限性，为文本到图像生成领域带来了重要进展。

Abstract: While text-to-image generation has achieved unprecedented fidelity, the vast majority of existing models function fundamentally as static text-to-pixel decoders. Consequently, they often fail to grasp implicit user intentions. Although emerging unified understanding-generation models have improved intent comprehension, they still struggle to accomplish tasks involving complex knowledge reasoning within a single model. Moreover, constrained by static internal priors, these models remain unable to adapt to the evolving dynamics of the real world. To bridge these gaps, we introduce Mind-Brush, a unified agentic framework that transforms generation into a dynamic, knowledge-driven workflow. Simulating a human-like 'think-research-create' paradigm, Mind-Brush actively retrieves multimodal evidence to ground out-of-distribution concepts and employs reasoning tools to resolve implicit visual constraints. To rigorously evaluate these capabilities, we propose Mind-Bench, a comprehensive benchmark comprising 500 distinct samples spanning real-time news, emerging concepts, and domains such as mathematical and Geo-Reasoning. Extensive experiments demonstrate that Mind-Brush significantly enhances the capabilities of unified models, realizing a zero-to-one capability leap for the Qwen-Image baseline on Mind-Bench, while achieving superior results on established benchmarks like WISE and RISE.

</details>


### [208] [MagicFuse: Single Image Fusion for Visual and Semantic Reinforcement](https://arxiv.org/abs/2602.01760)
*Hao Zhang,Yanping Zha,Zizhuo Li,Meiqi Gong,Jiayi Ma*

Main category: cs.CV

TL;DR: MagicFuse：一种从单张低质量可见光图像生成跨光谱场景表示的单图像融合框架，在仅有可见光传感器时仍能获得多模态融合的优势


<details>
  <summary>Details</summary>
Motivation: 解决在恶劣条件下仅有可见光成像传感器可用时，如何继续受益于多模态图像融合优势的实际问题

Method: 提出单图像融合概念，将数据级融合扩展到知识级。基于扩散模型设计三个分支：1）光谱内知识增强分支挖掘可见光谱中被遮挡的场景信息；2）跨光谱知识生成分支学习转移到红外光谱的热辐射分布模式；3）多域知识融合分支整合两个分支的扩散流概率噪声，通过连续采样获得跨光谱场景表示

Result: MagicFuse仅依赖单张退化可见光图像，就能实现与最先进多模态输入融合方法相当甚至更好的视觉和语义表示性能

Conclusion: 该研究成功将传统数据级融合扩展到知识级，提出的MagicFuse框架在仅有可见光图像的情况下仍能获得有效的跨光谱场景表示，具有重要的实际应用价值

Abstract: This paper focuses on a highly practical scenario: how to continue benefiting from the advantages of multi-modal image fusion under harsh conditions when only visible imaging sensors are available. To achieve this goal, we propose a novel concept of single-image fusion, which extends conventional data-level fusion to the knowledge level. Specifically, we develop MagicFuse, a novel single image fusion framework capable of deriving a comprehensive cross-spectral scene representation from a single low-quality visible image. MagicFuse first introduces an intra-spectral knowledge reinforcement branch and a cross-spectral knowledge generation branch based on the diffusion models. They mine scene information obscured in the visible spectrum and learn thermal radiation distribution patterns transferred to the infrared spectrum, respectively. Building on them, we design a multi-domain knowledge fusion branch that integrates the probabilistic noise from the diffusion streams of these two branches, from which a cross-spectral scene representation can be obtained through successive sampling. Then, we impose both visual and semantic constraints to ensure that this scene representation can satisfy human observation while supporting downstream semantic decision-making. Extensive experiments show that our MagicFuse achieves visual and semantic representation performance comparable to or even better than state-of-the-art fusion methods with multi-modal inputs, despite relying solely on a single degraded visible image.

</details>


### [209] [GDPR-Compliant Person Recognition in Industrial Environments Using MEMS-LiDAR and Hybrid Data](https://arxiv.org/abs/2602.01764)
*Dennis Basile,Dennis Sprute,Helene Dörksen,Holger Flatt*

Main category: cs.CV

TL;DR: 提出基于MEMS-LiDAR的隐私合规人员检测方法，通过合成数据增强减少真实数据需求，在工业环境中实现高精度GDPR合规检测


<details>
  <summary>Details</summary>
Motivation: 工业室内空间需要可靠检测未经授权人员以避免安全事故，但传统视觉方法受光照条件限制且违反隐私法规（如GDPR），同时深度学习需要大量标注数据，收集和标注过程耗时且易出错

Method: 使用MEMS-LiDAR捕获匿名3D点云数据，避免个人识别特征；通过CARLA仿真框架生成合成场景数据，将真实数据与合成数据混合训练，减少真实数据收集和标注工作量

Result: 混合数据训练模型相比仅使用真实数据的模型，平均精度提高44个百分点，同时将人工标注工作量减少50%

Conclusion: 该方法提供了可扩展、成本效益高的替代方案，系统展示了合成LiDAR数据如何在工业环境中结合高性能人员检测与GDPR合规性

Abstract: The reliable detection of unauthorized individuals in safety-critical industrial indoor spaces is crucial to avoid plant shutdowns, property damage, and personal hazards. Conventional vision-based methods that use deep-learning approaches for person recognition provide image information but are sensitive to lighting and visibility conditions and often violate privacy regulations, such as the General Data Protection Regulation (GDPR) in the European Union. Typically, detection systems based on deep learning require annotated data for training. Collecting and annotating such data, however, is highly time-consuming and due to manual treatments not necessarily error free. Therefore, this paper presents a privacy-compliant approach based on Micro-Electro-Mechanical Systems LiDAR (MEMS-LiDAR), which exclusively captures anonymized 3D point clouds and avoids personal identification features. To compensate for the large amount of time required to record real LiDAR data and for post-processing and annotation, real recordings are augmented with synthetically generated scenes from the CARLA simulation framework. The results demonstrate that the hybrid data improves the average precision by 44 percentage points compared to a model trained exclusively with real data while reducing the manual annotation effort by 50 %. Thus, the proposed approach provides a scalable, cost-efficient alternative to purely real-data-based methods and systematically shows how synthetic LiDAR data can combine high performance in person detection with GDPR compliance in an industrial environment.

</details>


### [210] [DDP-WM: Disentangled Dynamics Prediction for Efficient World Models](https://arxiv.org/abs/2602.01780)
*Shicheng Yin,Kaixuan Yin,Weixing Chen,Yang Liu,Guanbin Li,Liang Lin*

Main category: cs.CV

TL;DR: DDP-WM提出解耦动态预测的世界模型，通过分离主要物理动态和次要背景更新，实现高效推理和性能提升


<details>
  <summary>Details</summary>
Motivation: 现有密集Transformer世界模型计算开销大，阻碍实时部署，需要解决效率-性能瓶颈

Method: 基于解耦动态预测原则，将潜在状态演化分解为稀疏的主要物理动态和次要背景更新，采用高效历史处理和动态定位架构，使用交叉注意力机制进行背景更新

Result: 在导航、桌面操作、可变形物体和多体交互等任务中表现优异，在Push-T任务上实现约9倍推理加速，MPC成功率从90%提升至98%

Conclusion: DDP-WM为开发高效、高保真世界模型提供了有前景的路径

Abstract: World models are essential for autonomous robotic planning. However, the substantial computational overhead of existing dense Transformerbased models significantly hinders real-time deployment. To address this efficiency-performance bottleneck, we introduce DDP-WM, a novel world model centered on the principle of Disentangled Dynamics Prediction (DDP). We hypothesize that latent state evolution in observed scenes is heterogeneous and can be decomposed into sparse primary dynamics driven by physical interactions and secondary context-driven background updates. DDP-WM realizes this decomposition through an architecture that integrates efficient historical processing with dynamic localization to isolate primary dynamics. By employing a crossattention mechanism for background updates, the framework optimizes resource allocation and provides a smooth optimization landscape for planners. Extensive experiments demonstrate that DDP-WM achieves significant efficiency and performance across diverse tasks, including navigation, precise tabletop manipulation, and complex deformable or multi-body interactions. Specifically, on the challenging Push-T task, DDP-WM achieves an approximately 9 times inference speedup and improves the MPC success rate from 90% to98% compared to state-of-the-art dense models. The results establish a promising path for developing efficient, high-fidelity world models. Codes will be available at https://github.com/HCPLabSYSU/DDP-WM.

</details>


### [211] [Automated Discontinuity Set Characterisation in Enclosed Rock Face Point Clouds Using Single-Shot Filtering and Cyclic Orientation Transformation](https://arxiv.org/abs/2602.01783)
*Dibyayan Patra,Pasindu Ranasinghe,Bikram Banerjee,Simit Raval*

Main category: cs.CV

TL;DR: 提出了一种用于地下矿山岩体结构面自动识别的新方法，结合单次滤波、循环方向变换和层次聚类技术，在真实矿山采场数据上取得了优于现有方法的精度。


<details>
  <summary>Details</summary>
Motivation: 地下矿山岩体结构面的准确表征对岩体稳定性评估、开挖安全和运营效率至关重要。虽然无人机和移动激光扫描技术能高效采集岩面点云数据，但在完全封闭的岩体环境中实现自动、鲁棒的结构面表征仍是一个未解决的研究问题。

Method: 提出了一种新的自动结构面表征方法，包含三个核心步骤：1) 单次滤波策略，使用信号处理技术一次性隔离平面区域并抑制噪声和高曲率伪影；2) 创新的循环方向变换方案，将倾角和倾向的极坐标数据准确映射到笛卡尔空间；3) 层次聚类技术，处理不同密度分布，无需用户预设聚类数量即可识别结构面组。

Result: 在真实矿山采场数据上验证了方法的准确性，与使用Virtual Compass工具手动选取的结构面以及广泛使用的自动结构映射技术进行对比。提出的方法在估计结构面产状方面表现出最低的平均绝对误差：倾角误差1.95°，倾向误差2.20°，离散误差低于3°。

Conclusion: 该方法为地下矿山岩体结构面的自动表征提供了一种鲁棒高效的解决方案，在真实复杂环境中优于现有技术，为岩体稳定性评估和矿山安全提供了可靠的技术支持。

Abstract: Characterisation of structural discontinuity sets in exposed rock faces of underground mine cavities is essential for assessing rock-mass stability, excavation safety, and operational efficiency. UAV and other mobile laser-scanning techniques provide efficient means of collecting point clouds from rock faces. However, the development of a robust and efficient approach for automatic characterisation of discontinuity sets in real-world scenarios, like fully enclosed rock faces in cavities, remains an open research problem. In this study, a new approach is proposed for automatic discontinuity set characterisation that uses a single-shot filtering strategy, an innovative cyclic orientation transformation scheme and a hierarchical clustering technique. The single-shot filtering step isolates planar regions while robustly suppressing noise and high-curvature artefacts in one pass using a signal-processing technique. To address the limitations of Cartesian clustering on polar orientation data, a cyclic orientation transformation scheme is developed, enabling accurate representation of dip angle and dip direction in Cartesian space. The transformed orientations are then characterised into sets using a hierarchical clustering technique, which handles varying density distributions and identifies clusters without requiring user-defined set numbers. The accuracy of the method is validated on real-world mine stope and against ground truth obtained using manually handpicked discontinuity planes identified with the Virtual Compass tool, as well as widely used automated structure mapping techniques. The proposed approach outperforms the other techniques by exhibiting the lowest mean absolute error in estimating discontinuity set orientations in real-world stope data with errors of 1.95° and 2.20° in nominal dip angle and dip direction, respectively, and dispersion errors lying below 3°.

</details>


### [212] [Spatio-Temporal Transformers for Long-Term NDVI Forecasting](https://arxiv.org/abs/2602.01799)
*Ido Faran,Nathan S. Netanyahu,Maxim Shoshany*

Main category: cs.CV

TL;DR: STT-LTF是一个时空Transformer框架，用于处理地中海地区异质景观的长时序卫星影像分析，通过统一架构整合空间上下文建模与时间序列预测，在40年Landsat数据上实现优于传统方法的预测性能。


<details>
  <summary>Details</summary>
Motivation: 地中海地区异质景观的长时序卫星影像分析面临复杂挑战：空间模式复杂、季节变化显著、多年代环境变化在不同尺度上相互作用。现有方法难以同时处理空间异质性、长期时间依赖性和不规则采样。

Method: 提出STT-LTF框架，通过统一Transformer架构处理多尺度空间斑块和长时间序列（最长20年）。采用空间掩码、时间掩码和水平采样的自监督学习策略，结合空间斑块嵌入、循环时间编码和地理坐标，直接预测任意未来时间点而非自回归方式。

Result: 在1984-2024年Landsat数据上的实验表明，STT-LTF在次年预测中达到MAE 0.0328和R² 0.8412，优于传统统计方法、CNN、LSTM和标准Transformer。框架能处理不规则时间采样和可变预测范围。

Conclusion: STT-LTF通过整合空间上下文与时间序列预测，为异质景观的长时序卫星影像分析提供了有效解决方案，特别适用于经历快速生态转变的地中海地区，能够处理复杂时空依赖关系。

Abstract: Long-term satellite image time series (SITS) analysis in heterogeneous landscapes faces significant challenges, particularly in Mediterranean regions where complex spatial patterns, seasonal variations, and multi-decade environmental changes interact across different scales. This paper presents the Spatio-Temporal Transformer for Long Term Forecasting (STT-LTF ), an extended framework that advances beyond purely temporal analysis to integrate spatial context modeling with temporal sequence prediction. STT-LTF processes multi-scale spatial patches alongside temporal sequences (up to 20 years) through a unified transformer architecture, capturing both local neighborhood relationships and regional climate influences. The framework employs comprehensive self-supervised learning with spatial masking, temporal masking, and horizon sampling strategies, enabling robust model training from 40 years of unlabeled Landsat imagery. Unlike autoregressive approaches, STT-LTF directly predicts arbitrary future time points without error accumulation, incorporating spatial patch embeddings, cyclical temporal encoding, and geographic coordinates to learn complex dependencies across heterogeneous Mediterranean ecosystems. Experimental evaluation on Landsat data (1984-2024) demonstrates that STT-LTF achieves a Mean Absolute Error (MAE) of 0.0328 and R^2 of 0.8412 for next-year predictions, outperforming traditional statistical methods, CNN-based approaches, LSTM networks, and standard transformers. The framework's ability to handle irregular temporal sampling and variable prediction horizons makes it particularly suitable for analysis of heterogeneous landscapes experiencing rapid ecological transitions.

</details>


### [213] [Fast Autoregressive Video Diffusion and World Models with Temporal Cache Compression and Sparse Attention](https://arxiv.org/abs/2602.01801)
*Dvir Samuel,Issar Tzachor,Matan Levy,Micahel Green,Gal Chechik,Rami Ben-Ari*

Main category: cs.CV

TL;DR: 提出一种训练无关的注意力优化框架，通过时间缓存压缩、近似最近邻交叉注意力和自注意力稀疏化，解决自回归视频扩散模型中KV缓存增长导致的延迟和内存问题，实现5-10倍加速并保持稳定吞吐量。


<details>
  <summary>Details</summary>
Motivation: 自回归视频扩散模型在推理时面临核心瓶颈：随着生成进行，KV缓存不断增长，导致延迟增加、GPU内存占用上升，进而限制了可用时间上下文并损害长范围一致性。

Method: 提出统一训练无关注意力框架：1) TempCache通过时间对应压缩KV缓存；2) AnnCA使用近似最近邻匹配选择帧相关提示词加速交叉注意力；3) AnnSA通过限制查询到语义匹配的键来稀疏化自注意力。

Result: 实验显示实现5-10倍端到端加速，同时保持近似的视觉质量，并在长序列生成中维持稳定吞吐量和近乎恒定的峰值GPU内存使用，而先前方法会逐渐变慢且内存使用持续增加。

Conclusion: 提出的注意力优化框架有效解决了自回归视频扩散模型中的KV缓存瓶颈问题，实现了显著的加速和内存优化，同时保持生成质量，为长序列视频生成提供了实用解决方案。

Abstract: Autoregressive video diffusion models enable streaming generation, opening the door to long-form synthesis, video world models, and interactive neural game engines. However, their core attention layers become a major bottleneck at inference time: as generation progresses, the KV cache grows, causing both increasing latency and escalating GPU memory, which in turn restricts usable temporal context and harms long-range consistency. In this work, we study redundancy in autoregressive video diffusion and identify three persistent sources: near-duplicate cached keys across frames, slowly evolving (largely semantic) queries/keys that make many attention computations redundant, and cross-attention over long prompts where only a small subset of tokens matters per frame. Building on these observations, we propose a unified, training-free attention framework for autoregressive diffusion: TempCache compresses the KV cache via temporal correspondence to bound cache growth; AnnCA accelerates cross-attention by selecting frame-relevant prompt tokens using fast approximate nearest neighbor (ANN) matching; and AnnSA sparsifies self-attention by restricting each query to semantically matched keys, also using a lightweight ANN. Together, these modules reduce attention, compute, and memory and are compatible with existing autoregressive diffusion backbones and world models. Experiments demonstrate up to x5--x10 end-to-end speedups while preserving near-identical visual quality and, crucially, maintaining stable throughput and nearly constant peak GPU memory usage over long rollouts, where prior methods progressively slow down and suffer from increasing memory usage.

</details>


### [214] [FlowBypass: Rectified Flow Trajectory Bypass for Training-Free Image Editing](https://arxiv.org/abs/2602.01805)
*Menglin Han,Zhangkai Ni*

Main category: cs.CV

TL;DR: FlowBypass：基于Rectified Flow的训练免费图像编辑框架，通过构建连接反转和重建轨迹的旁路，避免误差累积，无需特征操作


<details>
  <summary>Details</summary>
Motivation: 现有训练免费图像编辑方法主要依赖反转-重建轨迹，存在固有权衡：长轨迹累积误差损害保真度，短轨迹无法确保与编辑提示充分对齐。先前解决方案通常使用特定于骨干网络的特征操作，限制了通用性。

Method: 提出FlowBypass框架，基于Rectified Flow构建直接连接反转和重建轨迹的旁路。通过形式化推导两个轨迹，获得近似旁路公式及其数值解，实现无缝轨迹转换，避免误差累积且不依赖特征操作。

Result: 大量实验表明，FlowBypass在图像编辑方法中表现优于现有技术，在保持无关区域高保真细节的同时，实现更强的提示对齐。

Conclusion: FlowBypass通过构建连接反转和重建轨迹的旁路，有效解决了训练免费图像编辑中的误差累积与提示对齐权衡问题，提供了一种通用且高效的解决方案。

Abstract: Training-free image editing has attracted increasing attention for its efficiency and independence from training data. However, existing approaches predominantly rely on inversion-reconstruction trajectories, which impose an inherent trade-off: longer trajectories accumulate errors and compromise fidelity, while shorter ones fail to ensure sufficient alignment with the edit prompt. Previous attempts to address this issue typically employ backbone-specific feature manipulations, limiting general applicability. To address these challenges, we propose FlowBypass, a novel and analytical framework grounded in Rectified Flow that constructs a bypass directly connecting inversion and reconstruction trajectories, thereby mitigating error accumulation without relying on feature manipulations. We provide a formal derivation of two trajectories, from which we obtain an approximate bypass formulation and its numerical solution, enabling seamless trajectory transitions. Extensive experiments demonstrate that FlowBypass consistently outperforms state-of-the-art image editing methods, achieving stronger prompt alignment while preserving high-fidelity details in irrelevant regions.

</details>


### [215] [LDRNet: Large Deformation Registration Model for Chest CT Registration](https://arxiv.org/abs/2602.01812)
*Cheng Wang,Qiyu Gao,Fandong Zhang,Shu Zhang,Yizhou Yu*

Main category: cs.CV

TL;DR: 提出LDRNet用于胸部CT大变形配准，通过粗到精的配准场优化，结合细化块和刚性块，在速度和精度上优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有深度学习配准方法主要针对脑部图像，而胸部CT配准面临更大变形、更复杂背景和区域重叠的挑战，需要专门的大变形配准方法

Method: 提出LDRNet：1）先预测粗分辨率配准场，然后从粗到精逐步细化；2）引入细化块在不同分辨率下优化配准场；3）使用刚性块从高层特征学习变换矩阵

Result: 在私有数据集和公开数据集SegTHOR上评估，相比传统方法和深度学习模型（VoxelMorph、RCN、LapIRN），在大变形图像配准上达到SOTA性能且速度更快

Conclusion: LDRNet能有效处理胸部CT的大变形配准问题，在精度和速度上都优于现有方法，为复杂医学图像配准提供了有效解决方案

Abstract: Most of the deep learning based medical image registration algorithms focus on brain image registration tasks.Compared with brain registration, the chest CT registration has larger deformation, more complex background and region over-lap. In this paper, we propose a fast unsupervised deep learning method, LDRNet, for large deformation image registration of chest CT images. We first predict a coarse resolution registration field, then refine it from coarse to fine. We propose two innovative technical components: 1) a refine block that is used to refine the registration field in different resolutions, 2) a rigid block that is used to learn transformation matrix from high-level features. We train and evaluate our model on the private dataset and public dataset SegTHOR. We compare our performance with state-of-the-art traditional registration methods as well as deep learning registration models VoxelMorph, RCN, and LapIRN. The results demonstrate that our model achieves state-of-the-art performance for large deformation images registration and is much faster.

</details>


### [216] [GPD: Guided Progressive Distillation for Fast and High-Quality Video Generation](https://arxiv.org/abs/2602.01814)
*Xiao Liang,Yunzhu Zhang,Linchao Zhu*

Main category: cs.CV

TL;DR: 提出GPD框架，通过渐进式蒸馏加速视频扩散模型，将采样步数从48减少到6，同时保持视觉质量


<details>
  <summary>Details</summary>
Motivation: 扩散模型在视频生成中表现出色，但去噪过程的高计算成本是主要瓶颈。现有方法在减少扩散步数时，视频生成质量会显著下降

Method: GPD框架包含两个关键组件：1）在线生成训练目标，降低优化难度并提高计算效率；2）潜在空间中的频域约束，促进细粒度细节和时间动态的保持。教师模型逐步指导学生模型使用更大的步长

Result: 应用于Wan2.1模型时，GPD将采样步数从48减少到6，同时在VBench上保持有竞争力的视觉质量。相比现有蒸馏方法，GPD在流程简单性和质量保持方面具有明显优势

Conclusion: GPD框架能够有效加速视频扩散模型的生成过程，在显著减少计算成本的同时保持高质量的生成结果，为快速高质量视频生成提供了有效解决方案

Abstract: Diffusion models have achieved remarkable success in video generation; however, the high computational cost of the denoising process remains a major bottleneck. Existing approaches have shown promise in reducing the number of diffusion steps, but they often suffer from significant quality degradation when applied to video generation. We propose Guided Progressive Distillation (GPD), a framework that accelerates the diffusion process for fast and high-quality video generation. GPD introduces a novel training strategy in which a teacher model progressively guides a student model to operate with larger step sizes. The framework consists of two key components: (1) an online-generated training target that reduces optimization difficulty while improving computational efficiency, and (2) frequency-domain constraints in the latent space that promote the preservation of fine-grained details and temporal dynamics. Applied to the Wan2.1 model, GPD reduces the number of sampling steps from 48 to 6 while maintaining competitive visual quality on VBench. Compared with existing distillation methods, GPD demonstrates clear advantages in both pipeline simplicity and quality preservation.

</details>


### [217] [Seeing Is Believing? A Benchmark for Multimodal Large Language Models on Visual Illusions and Anomalies](https://arxiv.org/abs/2602.01816)
*Wenjin Hou,Wei Liu,Han Hu,Xiaoxiao Sun,Serena Yeung-Levy,Hehe Fan*

Main category: cs.CV

TL;DR: VIA-Bench是一个针对多模态大语言模型的视觉幻觉和异常基准测试，揭示了MLLMs在面对违背常识先验的场景时存在显著脆弱性，即使最先进的模型也难以处理视觉错觉问题。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs评估主要基于标准分布内数据，缺乏对模型在面对违背常识先验的视觉幻觉和异常场景时的鲁棒性测试，这限制了我们对模型真实感知能力的理解。

Method: 构建包含六类视觉幻觉和异常的VIA-Bench基准：颜色幻觉、运动幻觉、格式塔幻觉、几何空间幻觉、一般视觉幻觉和视觉异常。通过人工参与循环审查，创建了超过1000个高质量问答对，评估了20多个最先进的MLLMs。

Result: 评估发现MLLMs在视觉幻觉和异常场景中存在显著脆弱性，思维链推理对鲁棒性提升有限，甚至产生"脆弱幻象"现象，即模型逻辑在幻觉刺激下崩溃。这表明机器与人类感知存在根本性差异。

Conclusion: 解决这种感知瓶颈对于人工智能通用智能的发展至关重要，VIA-Bench揭示了MLLMs在视觉幻觉处理方面的局限性，为未来模型改进提供了重要基准。

Abstract: Multimodal Large Language Models (MLLMs) have shown remarkable proficiency on general-purpose vision-language benchmarks, reaching or even exceeding human-level performance. However, these evaluations typically rely on standard in-distribution data, leaving the robustness of MLLMs largely unexamined when faced with scenarios that defy common-sense priors. To address this gap, we introduce VIA-Bench, a challenging benchmark designed to probe model performance on visual illusions and anomalies. It includes six core categories: color illusions, motion illusions, gestalt illusions, geometric and spatial illusions, general visual illusions, and visual anomalies. Through careful human-in-the-loop review, we construct over 1K high-quality question-answer pairs that require nuanced visual reasoning. Extensive evaluation of over 20 state-of-the-art MLLMs, including proprietary, open-source, and reasoning-enhanced models, uncovers significant vulnerabilities. Notably, we find that Chain-of-Thought (CoT) reasoning offers negligible robustness, often yielding ``brittle mirages'' where the model's logic collapses under illusory stimuli. Our findings reveal a fundamental divergence between machine and human perception, suggesting that resolving such perceptual bottlenecks is critical for the advancement of artificial general intelligence. The benchmark data and code will be released.

</details>


### [218] [Efficient Cross-Country Data Acquisition Strategy for ADAS via Street-View Imagery](https://arxiv.org/abs/2602.01836)
*Yin Wu,Daniel Slieter,Carl Esselborn,Ahmed Abouelazm,Tsung Yuan Tseng,J. Marius Zöllner*

Main category: cs.CV

TL;DR: 提出基于街景图像引导的数据采集策略，利用公开图像识别兴趣点，减少跨国家数据收集成本，在交通标志检测任务上仅用一半目标域数据达到与随机采样相当的性能。


<details>
  <summary>Details</summary>
Motivation: ADAS和ADS在不同国家部署面临挑战，由于立法、交通基础设施和视觉惯例差异导致域偏移，降低感知性能。传统跨国家数据收集依赖大量道路驾驶，成本高且效率低。

Method: 提出街景图像引导的数据采集策略，利用公开图像识别兴趣点。引入两种POI评分方法：基于视觉基础模型的KNN特征距离方法，以及基于视觉语言模型的视觉归因方法。采用收集-检测协议构建共定位数据集，将Zenseact开放数据集与Mapillary街景图像配对。

Result: 在交通标志检测任务上，该方法仅使用一半目标域数据就能达到与随机采样相当的性能。提供了全国范围分析的成本估算，证明大规模街景处理在经济上仍然可行。

Conclusion: 街景图像引导的数据采集策略为高效且经济有效的跨国家模型适应提供了潜力，能够显著降低数据收集成本并提高效率。

Abstract: Deploying ADAS and ADS across countries remains challenging due to differences in legislation, traffic infrastructure, and visual conventions, which introduce domain shifts that degrade perception performance. Traditional cross-country data collection relies on extensive on-road driving, making it costly and inefficient to identify representative locations. To address this, we propose a street-view-guided data acquisition strategy that leverages publicly available imagery to identify places of interest (POI). Two POI scoring methods are introduced: a KNN-based feature distance approach using a vision foundation model, and a visual-attribution approach using a vision-language model. To enable repeatable evaluation, we adopt a collect-detect protocol and construct a co-located dataset by pairing the Zenseact Open Dataset with Mapillary street-view images. Experiments on traffic sign detection, a task particularly sensitive to cross-country variations in sign appearance, show that our approach achieves performance comparable to random sampling while using only half of the target-domain data. We further provide cost estimations for full-country analysis, demonstrating that large-scale street-view processing remains economically feasible. These results highlight the potential of street-view-guided data acquisition for efficient and cost-effective cross-country model adaptation.

</details>


### [219] [SPIRIT: Adapting Vision Foundation Models for Unified Single- and Multi-Frame Infrared Small Target Detection](https://arxiv.org/abs/2602.01843)
*Qian Xu,Xi Li,Fei Gao,Jie Guo,Haojuan Yuan,Shuaipeng Fan,Mingjin Zhang*

Main category: cs.CV

TL;DR: SPIRIT是一个统一且兼容视觉基础模型的红外小目标检测框架，通过轻量级物理信息插件解决红外数据稀缺和模态差异问题，在单帧和多帧检测中均取得优异性能。


<details>
  <summary>Details</summary>
Motivation: 红外小目标检测面临数据稀缺、目标信号弱、语义线索有限等挑战，直接使用面向可见光图像的视觉基础模型存在模态差异，导致特征聚合淹没目标峰值，仅基于外观的跨帧关联不可靠。

Method: 提出SPIRIT框架，包含两个轻量级物理信息插件：空间上，PIFR通过近似秩稀疏分解抑制结构化背景并增强稀疏目标信号；时间上，PGMA将历史衍生的软空间先验注入记忆交叉注意力，约束跨帧关联。

Result: 在多个红外小目标检测基准测试中，SPIRIT相比基于视觉基础模型的基线方法取得一致提升，并达到最先进的性能水平。

Conclusion: SPIRIT通过物理信息插件有效弥合了红外与可见光模态差异，统一了单帧和多帧检测框架，为红外小目标检测提供了一种实用且高效的解决方案。

Abstract: Infrared small target detection (IRSTD) is crucial for surveillance and early-warning, with deployments spanning both single-frame analysis and video-mode tracking. A practical solution should leverage vision foundation models (VFMs) to mitigate infrared data scarcity, while adopting a memory-attention-based temporal propagation framework that unifies single- and multi-frame inference. However, infrared small targets exhibit weak radiometric signals and limited semantic cues, which differ markedly from visible-spectrum imagery. This modality gap makes direct use of semantics-oriented VFMs and appearance-driven cross-frame association unreliable for IRSTD: hierarchical feature aggregation can submerge localized target peaks, and appearance-only memory attention becomes ambiguous, leading to spurious clutter associations. To address these challenges, we propose SPIRIT, a unified and VFM-compatible framework that adapts VFMs to IRSTD via lightweight physics-informed plug-ins. Spatially, PIFR refines features by approximating rank-sparsity decomposition to suppress structured background components and enhance sparse target-like signals. Temporally, PGMA injects history-derived soft spatial priors into memory cross-attention to constrain cross-frame association, enabling robust video detection while naturally reverting to single-frame inference when temporal context is absent. Experiments on multiple IRSTD benchmarks show consistent gains over VFM-based baselines and SOTA performance.

</details>


### [220] [CloDS: Visual-Only Unsupervised Cloth Dynamics Learning in Unknown Conditions](https://arxiv.org/abs/2602.01844)
*Yuliang Zhan,Jian Li,Wenbing Huang,Wenbing Huang,Yang Liu,Hao Sun*

Main category: cs.CV

TL;DR: CloDS是一个无监督学习框架，通过多视角视觉观测学习布料动力学，无需已知物理属性作为监督，采用三阶段流程实现视频到几何的映射和动力学建模。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法需要已知物理属性作为监督或输入，这在未知条件下限制了其适用性。需要探索无监督学习布料动力学的新方法。

Method: 提出CloDS框架，采用三阶段流程：1)视频到几何映射，使用基于网格的高斯泼溅和双位置不透明度调制处理大变形和自遮挡；2)在映射的网格上训练动力学模型；3)支持2D观测与3D几何之间的双向映射。

Result: 综合实验评估表明，CloDS能有效从视觉数据中学习布料动力学，同时对未见配置保持强大的泛化能力。

Conclusion: CloDS成功解决了无监督学习布料动力学的挑战，为未知条件下的动态系统模拟提供了有效解决方案，具有良好泛化性能。

Abstract: Deep learning has demonstrated remarkable capabilities in simulating complex dynamic systems. However, existing methods require known physical properties as supervision or inputs, limiting their applicability under unknown conditions. To explore this challenge, we introduce Cloth Dynamics Grounding (CDG), a novel scenario for unsupervised learning of cloth dynamics from multi-view visual observations. We further propose Cloth Dynamics Splatting (CloDS), an unsupervised dynamic learning framework designed for CDG. CloDS adopts a three-stage pipeline that first performs video-to-geometry grounding and then trains a dynamics model on the grounded meshes. To cope with large non-linear deformations and severe self-occlusions during grounding, we introduce a dual-position opacity modulation that supports bidirectional mapping between 2D observations and 3D geometry via mesh-based Gaussian splatting in video-to-geometry grounding stage. It jointly considers the absolute and relative position of Gaussian components. Comprehensive experimental evaluations demonstrate that CloDS effectively learns cloth dynamics from visual data while maintaining strong generalization capabilities for unseen configurations. Our code is available at https://github.com/whynot-zyl/CloDS. Visualization results are available at https://github.com/whynot-zyl/CloDS_video}.%\footnote{As in this example.

</details>


### [221] [WS-IMUBench: Can Weakly Supervised Methods from Audio, Image, and Video Be Adapted for IMU-based Temporal Action Localization?](https://arxiv.org/abs/2602.01850)
*Pei Li,Jiaxi Yin,Lei Ouyang,Shihan Pan,Ge Wang,Han Ding,Fei Wang*

Main category: cs.CV

TL;DR: WS-IMUBench是首个系统性评估弱监督IMU时序动作定位的基准研究，在仅有序列级标签下评估了7种方法在7个公开IMU数据集上的表现，发现时序域方法比图像提案方法更稳定，弱监督在有利数据集上可达到竞争性性能。


<details>
  <summary>Details</summary>
Motivation: 当前IMU时序动作定位(IMU-TAL)进展受限于需要密集的帧级边界标注，这些标注成本高且难以扩展。为解决这一瓶颈，需要研究在仅有序列级标签下的弱监督方法。

Method: 不提出新算法，而是系统评估从音频、图像和视频领域迁移到IMU-TAL的7种代表性弱监督方法。在7个公开IMU数据集上进行超过3,540次模型训练和7,080次推理评估，通过三个研究问题分析可迁移性、有效性和洞察。

Result: 发现：(1)迁移具有模态依赖性，时序域方法通常比图像提案方法更稳定；(2)在有利数据集上弱监督可达到竞争性性能；(3)主要失败模式源于短动作、时序模糊和提案质量。建立了可复现的基准模板、数据集、协议和分析框架。

Conclusion: WS-IMUBench为加速社区在可扩展弱监督IMU-TAL方面的进展提供了系统基准，并指出了IMU特定提案生成、边界感知目标和更强时序推理等具体发展方向。

Abstract: IMU-based Human Activity Recognition (HAR) has enabled a wide range of ubiquitous computing applications, yet its dominant clip classification paradigm cannot capture the rich temporal structure of real-world behaviors. This motivates a shift toward IMU Temporal Action Localization (IMU-TAL), which predicts both action categories and their start/end times in continuous streams. However, current progress is strongly bottlenecked by the need for dense, frame-level boundary annotations, which are costly and difficult to scale. To address this bottleneck, we introduce WS-IMUBench, a systematic benchmark study of weakly supervised IMU-TAL (WS-IMU-TAL) under only sequence-level labels. Rather than proposing a new localization algorithm, we evaluate how well established weakly supervised localization paradigms from audio, image, and video transfer to IMU-TAL under only sequence-level labels. We benchmark seven representative weakly supervised methods on seven public IMU datasets, resulting in over 3,540 model training runs and 7,080 inference evaluations. Guided by three research questions on transferability, effectiveness, and insights, our findings show that (i) transfer is modality-dependent, with temporal-domain methods generally more stable than image-derived proposal-based approaches; (ii) weak supervision can be competitive on favorable datasets (e.g., with longer actions and higher-dimensional sensing); and (iii) dominant failure modes arise from short actions, temporal ambiguity, and proposal quality. Finally, we outline concrete directions for advancing WS-IMU-TAL (e.g., IMU-specific proposal generation, boundary-aware objectives, and stronger temporal reasoning). Beyond individual results, WS-IMUBench establishes a reproducible benchmarking template, datasets, protocols, and analyses, to accelerate community-wide progress toward scalable WS-IMU-TAL.

</details>


### [222] [How Well Do Models Follow Visual Instructions? VIBE: A Systematic Benchmark for Visual Instruction-Driven Image Editing](https://arxiv.org/abs/2602.01851)
*Huanyu Zhang,Xuehai Bai,Chengzu Li,Chen Liang,Haochen Tian,Haodong Li,Ruichuan An,Yifan Zhang,Anna Korhonen,Zhang Zhang,Liang Wang,Tieniu Tan*

Main category: cs.CV

TL;DR: VIBE是一个视觉指令图像编辑基准，包含三个层次的交互：指示性定位、形态操作和因果推理，用于评估模型在多模态视觉指令下的图像编辑能力。


<details>
  <summary>Details</summary>
Motivation: 现有图像编辑系统主要基于文本指导，但人类交流本质上是多模态的，视觉指令（如草图）能更有效地传达空间和结构意图。需要填补这一空白，评估模型在视觉指令下的编辑能力。

Method: 提出VIBE视觉指令基准，包含三个层次：指示性定位、形态操作和因果推理，收集高质量多样化测试用例。采用LMM-as-a-judge评估框架，使用任务特定指标进行细粒度评估。

Result: 评估了17个开源和专有图像编辑模型，发现专有模型展现出早期视觉指令跟随能力，表现优于开源模型。但随着任务难度增加，即使是最好系统的性能也显著下降。

Conclusion: 专有模型在视觉指令跟随方面表现更好，但所有模型在复杂任务上都存在困难，这为未来研究指明了方向。VIBE基准为评估和改进多模态图像编辑系统提供了重要工具。

Abstract: Recent generative models have achieved remarkable progress in image editing. However, existing systems and benchmarks remain largely text-guided. In contrast, human communication is inherently multimodal, where visual instructions such as sketches efficiently convey spatial and structural intent. To address this gap, we introduce VIBE, the Visual Instruction Benchmark for Image Editing with a three-level interaction hierarchy that captures deictic grounding, morphological manipulation, and causal reasoning. Across these levels, we curate high-quality and diverse test cases that reflect progressively increasing complexity in visual instruction following. We further propose a robust LMM-as-a-judge evaluation framework with task-specific metrics to enable scalable and fine-grained assessment. Through a comprehensive evaluation of 17 representative open-source and proprietary image editing models, we find that proprietary models exhibit early-stage visual instruction-following capabilities and consistently outperform open-source models. However, performance degrades markedly with increasing task difficulty even for the strongest systems, highlighting promising directions for future research.

</details>


### [223] [Fact or Fake? Assessing the Role of Deepfake Detectors in Multimodal Misinformation Detection](https://arxiv.org/abs/2602.01854)
*A S M Sharifuzzaman Sagar,Mohammed Bennamoun,Farid Boussaid,Naeha Sharif,Lian Xu,Shaaban Sahmoud,Ali Kishk*

Main category: cs.CV

TL;DR: 研究发现，在检测多模态虚假信息时，基于像素级的深度伪造检测器效果有限，甚至会降低事实核查系统的性能，而基于语义理解和外部证据的方法表现最佳。


<details>
  <summary>Details</summary>
Motivation: 多模态虚假信息中的欺骗通常来自图像-文本对共同表达的语义和上下文主张，而非单纯的像素级篡改。然而，大多数深度伪造检测器只关注像素级伪造，忽略了主张层面的含义，尽管它们越来越多地被集成到自动事实核查（AFC）流程中。这引发了一个核心问题：像素级检测器是否真的有助于验证图像-文本主张，还是会引入误导的真实性先验，破坏基于证据的推理？

Method: 使用两个互补的基准测试MMFakeBench和DGM4，评估：（1）最先进的仅图像深度伪造检测器；（2）基于证据的事实核查系统，通过蒙特卡洛树搜索（MCTS）进行工具引导检索，并通过多智能体辩论（MAD）进行深思熟虑的推理；（3）将检测器输出作为辅助证据注入的混合事实核查系统。

Result: 深度伪造检测器独立价值有限，在MMFakeBench上的F1分数为0.26-0.53，在DGM4上为0.33-0.49。将检测器预测纳入事实核查流程会因非因果真实性假设而持续降低性能0.04-0.08 F1。相比之下，基于证据的事实核查系统表现最佳，在MMFakeBench上达到约0.81的F1分数，在DGM4上达到0.55。

Conclusion: 多模态主张验证主要由语义理解和外部证据驱动，像素级伪影信号并不能可靠地增强对现实世界图像-文本虚假信息的推理。基于证据的方法优于依赖像素级检测器的方法。

Abstract: In multimodal misinformation, deception usually arises not just from pixel-level manipulations in an image, but from the semantic and contextual claim jointly expressed by the image-text pair. Yet most deepfake detectors, engineered to detect pixel-level forgeries, do not account for claim-level meaning, despite their growing integration in automated fact-checking (AFC) pipelines. This raises a central scientific and practical question: Do pixel-level detectors contribute useful signal for verifying image-text claims, or do they instead introduce misleading authenticity priors that undermine evidence-based reasoning? We provide the first systematic analysis of deepfake detectors in the context of multimodal misinformation detection. Using two complementary benchmarks, MMFakeBench and DGM4, we evaluate: (1) state-of-the-art image-only deepfake detectors, (2) an evidence-driven fact-checking system that performs tool-guided retrieval via Monte Carlo Tree Search (MCTS) and engages in deliberative inference through Multi-Agent Debate (MAD), and (3) a hybrid fact-checking system that injects detector outputs as auxiliary evidence. Results across both benchmark datasets show that deepfake detectors offer limited standalone value, achieving F1 scores in the range of 0.26-0.53 on MMFakeBench and 0.33-0.49 on DGM4, and that incorporating their predictions into fact-checking pipelines consistently reduces performance by 0.04-0.08 F1 due to non-causal authenticity assumptions. In contrast, the evidence-centric fact-checking system achieves the highest performance, reaching F1 scores of approximately 0.81 on MMFakeBench and 0.55 on DGM4. Overall, our findings demonstrate that multimodal claim verification is driven primarily by semantic understanding and external evidence, and that pixel-level artifact signals do not reliably enhance reasoning over real-world image-text misinformation.

</details>


### [224] [Trust but Verify: Adaptive Conditioning for Reference-Based Diffusion Super-Resolution via Implicit Reference Correlation Modeling](https://arxiv.org/abs/2602.01864)
*Yuan Wang,Yuhao Wan,Siming Zheng,Bo Li,Qibin Hou,Peng-Tao Jiang*

Main category: cs.CV

TL;DR: Ada-RefSR：基于"信任但验证"原则的单步扩散框架，通过自适应隐式关联门控机制，在参考图像可靠时利用参考信息，不可靠时抑制参考信息，解决参考图像与低质量输入对应关系不可靠的问题。


<details>
  <summary>Details</summary>
Motivation: 现有参考超分辨率方法面临真实世界退化导致低质量输入与参考图像对应关系不可靠的问题，现有方法要么忽略相关性，要么依赖脆弱的显式匹配，导致过度依赖误导性参考或未充分利用有价值线索。

Method: 提出Ada-RefSR单步扩散框架，核心是自适应隐式关联门控(AICG)，使用可学习的摘要令牌提取主要参考模式并捕获与低质量特征的隐式相关性，集成到注意力骨干网络中，提供轻量级的自适应参考引导调节。

Result: 在多个数据集上的实验表明，Ada-RefSR在保真度、自然度和效率之间实现了良好平衡，并在不同参考对齐条件下保持鲁棒性。

Conclusion: Ada-RefSR通过"信任但验证"原则和自适应隐式关联门控机制，有效解决了参考超分辨率中参考图像与低质量输入对应关系不可靠的问题，实现了鲁棒且高效的图像恢复。

Abstract: Recent works have explored reference-based super-resolution (RefSR) to mitigate hallucinations in diffusion-based image restoration. A key challenge is that real-world degradations make correspondences between low-quality (LQ) inputs and reference (Ref) images unreliable, requiring adaptive control of reference usage. Existing methods either ignore LQ-Ref correlations or rely on brittle explicit matching, leading to over-reliance on misleading references or under-utilization of valuable cues. To address this, we propose Ada-RefSR, a single-step diffusion framework guided by a "Trust but Verify" principle: reference information is leveraged when reliable and suppressed otherwise. Its core component, Adaptive Implicit Correlation Gating (AICG), employs learnable summary tokens to distill dominant reference patterns and capture implicit correlations with LQ features. Integrated into the attention backbone, AICG provides lightweight, adaptive regulation of reference guidance, serving as a built-in safeguard against erroneous fusion. Experiments on multiple datasets demonstrate that Ada-RefSR achieves a strong balance of fidelity, naturalness, and efficiency, while remaining robust under varying reference alignment.

</details>


### [225] [ProxyImg: Towards Highly-Controllable Image Representation via Hierarchical Disentangled Proxy Embedding](https://arxiv.org/abs/2602.01881)
*Ye Chen,Yupeng Zhu,Xiongzhen Zhang,Zhewen Wan,Yingzhe Li,Wenjun Zhang,Bingbing Ni*

Main category: cs.CV

TL;DR: 提出一种基于分层代理的参量化图像表示方法，将语义、几何和纹理属性解耦到独立可操作的参数空间，支持高效可控的图像编辑和实时物理驱动动画。


<details>
  <summary>Details</summary>
Motivation: 现有图像表示方法（如光栅图像、高斯基元等显式表示，或隐式表示）存在表示冗余导致手动编辑困难，或缺乏从隐变量到语义实例/部件的直接映射，难以进行细粒度操控，阻碍了高效可控的图像视频编辑。

Method: 基于输入图像的语义感知分解，通过自适应贝塞尔拟合和迭代内部区域细分网格化构建分层代理几何。将多尺度隐式纹理参数嵌入到几何感知的分布式代理节点中，实现像素域的连续高保真重建和实例/部件独立的语义编辑。引入局部自适应特征索引机制确保空间纹理一致性。

Result: 在ImageNet、OIR-Bench和HumanEdit等图像重建和编辑基准测试中，该方法以显著更少的参数实现了最先进的渲染保真度，同时支持直观、交互式和物理合理的操控。通过将代理节点与基于位置的动力学集成，支持实时物理驱动动画，相比生成方法具有更好的时间一致性和视觉真实感。

Conclusion: 提出的分层代理参量化图像表示方法有效解决了现有表示方法的局限性，实现了高效、可控的图像编辑和动画，为图像表示和操控提供了新的解决方案。

Abstract: Prevailing image representation methods, including explicit representations such as raster images and Gaussian primitives, as well as implicit representations such as latent images, either suffer from representation redundancy that leads to heavy manual editing effort, or lack a direct mapping from latent variables to semantic instances or parts, making fine-grained manipulation difficult. These limitations hinder efficient and controllable image and video editing. To address these issues, we propose a hierarchical proxy-based parametric image representation that disentangles semantic, geometric, and textural attributes into independent and manipulable parameter spaces. Based on a semantic-aware decomposition of the input image, our representation constructs hierarchical proxy geometries through adaptive Bezier fitting and iterative internal region subdivision and meshing. Multi-scale implicit texture parameters are embedded into the resulting geometry-aware distributed proxy nodes, enabling continuous high-fidelity reconstruction in the pixel domain and instance- or part-independent semantic editing. In addition, we introduce a locality-adaptive feature indexing mechanism to ensure spatial texture coherence, which further supports high-quality background completion without relying on generative models. Extensive experiments on image reconstruction and editing benchmarks, including ImageNet, OIR-Bench, and HumanEdit, demonstrate that our method achieves state-of-the-art rendering fidelity with significantly fewer parameters, while enabling intuitive, interactive, and physically plausible manipulation. Moreover, by integrating proxy nodes with Position-Based Dynamics, our framework supports real-time physics-driven animation using lightweight implicit rendering, achieving superior temporal consistency and visual realism compared with generative approaches.

</details>


### [226] [Q Cache: Visual Attention is Valuable in Less than Half of Decode Layers for Multimodal Large Language Model](https://arxiv.org/abs/2602.01901)
*Jiedong Zhuang,Lu Lu,Ming Dai,Rui Hu,Jian Chen,Qiang Liu,Haoji Hu*

Main category: cs.CV

TL;DR: 提出Lazy Attention机制，通过跨层共享相似注意力模式来减少MLLMs中的冗余计算，降低KV缓存使用并提升推理效率


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型(MLLMs)因视觉编码器产生大量视觉token而面临高昂推理成本，现有token剪枝方法会破坏KV缓存完整性，影响长文本生成任务

Method: 提出Lazy Attention机制，发现超过半数解码层的注意力语义相似，允许某些层继承前层的注意力模式；引入轻量级Q Cache实现跨层查询重用，与现有推理框架兼容

Result: 在多个基准测试中，该方法能减少超过35%的KV缓存使用，实现1.5倍吞吐量提升，仅牺牲约1%的性能；相比SOTA token剪枝方法，具有更好的精度保持

Conclusion: Lazy Attention通过跨层注意力共享有效解决了MLLMs推理效率问题，与现有token优化方法正交且兼容，为MLLMs高效推理提供了新思路

Abstract: Multimodal large language models (MLLMs) are plagued by exorbitant inference costs attributable to the profusion of visual tokens within the vision encoder. The redundant visual tokens engenders a substantial computational load and key-value (KV) cache footprint bottleneck. Existing approaches focus on token-wise optimization, leveraging diverse intricate token pruning techniques to eliminate non-crucial visual tokens. Nevertheless, these methods often unavoidably undermine the integrity of the KV cache, resulting in failures in long-text generation tasks. To this end, we conduct an in-depth investigation towards the attention mechanism of the model from a new perspective, and discern that attention within more than half of all decode layers are semantic similar. Upon this finding, we contend that the attention in certain layers can be streamlined by inheriting the attention from their preceding layers. Consequently, we propose Lazy Attention, an efficient attention mechanism that enables cross-layer sharing of similar attention patterns. It ingeniously reduces layer-wise redundant computation in attention. In Lazy Attention, we develop a novel layer-shared cache, Q Cache, tailored for MLLMs, which facilitates the reuse of queries across adjacent layers. In particular, Q Cache is lightweight and fully compatible with existing inference frameworks, including Flash Attention and KV cache. Additionally, our method is highly flexible as it is orthogonal to existing token-wise techniques and can be deployed independently or combined with token pruning approaches. Empirical evaluations on multiple benchmarks demonstrate that our method can reduce KV cache usage by over 35% and achieve 1.5x throughput improvement, while sacrificing only approximately 1% of performance on various MLLMs. Compared with SOTA token-wise methods, our technique achieves superior accuracy preservation.

</details>


### [227] [Learning Sparse Visual Representations via Spatial-Semantic Factorization](https://arxiv.org/abs/2602.01905)
*Theodore Zhengde Zhao,Sid Kiblawi,Jianwei Yang,Naoto Usuyama,Reuben Tan,Noel C Codella,Tristan Naumann,Hoifung Poon,Mu Wei*

Main category: cs.CV

TL;DR: STELLAR通过将视觉特征分解为语义概念与其空间分布的乘积，解决了自监督学习中语义理解与图像重建之间的冲突，实现了同时支持高质量重建和语义识别。


<details>
  <summary>Details</summary>
Motivation: 自监督学习面临语义理解与图像重建之间的根本冲突：语义SSL（如DINO）需要位置不变性而丢弃空间坐标，生成式SSL（如MAE）保留密集特征但无法产生高级抽象。

Method: 提出STELLAR框架，将视觉特征分解为语义概念和空间分布的低秩乘积，在语义token上执行DINO风格的数据增强对齐，同时在定位矩阵中保持精确的空间映射以支持像素级重建。

Result: 仅需16个稀疏token即可同时实现高质量重建（2.60 FID）和与密集骨干网络相当的语义性能（79.10% ImageNet准确率）。

Conclusion: STELLAR作为一种多功能稀疏表示，通过战略性地分离语义身份和空间几何，弥合了判别式与生成式视觉之间的差距。

Abstract: Self-supervised learning (SSL) faces a fundamental conflict between semantic understanding and image reconstruction. High-level semantic SSL (e.g., DINO) relies on global tokens that are forced to be location-invariant for augmentation alignment, a process that inherently discards the spatial coordinates required for reconstruction. Conversely, generative SSL (e.g., MAE) preserves dense feature grids for reconstruction but fails to produce high-level abstractions. We introduce STELLAR, a framework that resolves this tension by factorizing visual features into a low-rank product of semantic concepts and their spatial distributions. This disentanglement allows us to perform DINO-style augmentation alignment on the semantic tokens while maintaining the precise spatial mapping in the localization matrix necessary for pixel-level reconstruction. We demonstrate that as few as 16 sparse tokens under this factorized form are sufficient to simultaneously support high-quality reconstruction (2.60 FID) and match the semantic performance of dense backbones (79.10% ImageNet accuracy). Our results highlight STELLAR as a versatile sparse representation that bridges the gap between discriminative and generative vision by strategically separating semantic identity from spatial geometry. Code available at https://aka.ms/stellar.

</details>


### [228] [DSXFormer: Dual-Pooling Spectral Squeeze-Expansion and Dynamic Context Attention Transformer for Hyperspectral Image Classification](https://arxiv.org/abs/2602.01906)
*Farhan Ullah,Irfan Ullah,Khalil Khan,Giovanni Pau,JaKeoung Koo*

Main category: cs.CV

TL;DR: 提出DSXFormer用于高光谱图像分类，通过双池化谱压缩扩展块和动态上下文注意力机制，在四个基准数据集上达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 高光谱图像分类面临高光谱维度、复杂谱空相关性和有限标记样本的挑战。现有transformer方法在保持计算效率的同时难以获得足够的谱区分能力。

Method: 提出DSXFormer，包含双池化谱压缩扩展块（结合全局平均池化和最大池化自适应重校准谱特征通道）和动态上下文注意力机制（在窗口transformer架构中动态捕获局部谱空关系）。采用补丁提取、嵌入和合并策略实现高效多尺度特征学习。

Result: 在四个基准数据集上取得优异性能：Salinas (99.95%)、Indian Pines (98.91%)、Pavia University (99.85%)、Kennedy Space Center (98.52%)，均优于现有方法。

Conclusion: DSXFormer通过谱双池化压缩扩展和动态上下文注意力的联合集成，实现了谱强调和空间上下文表示的有效平衡，在高光谱图像分类任务中表现出色。

Abstract: Hyperspectral image classification (HSIC) is a challenging task due to high spectral dimensionality, complex spectral-spatial correlations, and limited labeled training samples. Although transformer-based models have shown strong potential for HSIC, existing approaches often struggle to achieve sufficient spectral discriminability while maintaining computational efficiency. To address these limitations, we propose a novel DSXFormer, a novel dual-pooling spectral squeeze-expansion transformer with Dynamic Context Attention for HSIC. The proposed DSXFormer introduces a Dual-Pooling Spectral Squeeze-Expansion (DSX) block, which exploits complementary global average and max pooling to adaptively recalibrate spectral feature channels, thereby enhancing spectral discriminability and inter-band dependency modeling. In addition, DSXFormer incorporates a Dynamic Context Attention (DCA) mechanism within a window-based transformer architecture to dynamically capture local spectral-spatial relationships while significantly reducing computational overhead. The joint integration of spectral dual-pooling squeeze-expansion and DCA enables DSXFormer to achieve an effective balance between spectral emphasis and spatial contextual representation. Furthermore, patch extraction, embedding, and patch merging strategies are employed to facilitate efficient multi-scale feature learning. Extensive experiments conducted on four widely used hyperspectral benchmark datasets, including Salinas (SA), Indian Pines (IP), Pavia University (PU), and Kennedy Space Center (KSC), demonstrate that DSXFormer consistently outperforms state-of-the-art methods, achieving classification accuracies of 99.95%, 98.91%, 99.85%, and 98.52%, respectively.

</details>


### [229] [Enabling Progressive Whole-slide Image Analysis with Multi-scale Pyramidal Network](https://arxiv.org/abs/2602.01951)
*Shuyang Wu,Yifu Qiu,Ines P. Nearchou,Sandrine Prost,Jonathan A Fallowfield,Hakan Bilen,Timothy J Kendall*

Main category: cs.CV

TL;DR: MSPN是一个轻量级、即插即用的多尺度金字塔网络，用于增强基于注意力的多实例学习在计算病理学任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有多尺度方法存在以下问题：1) 依赖制造商定义的固定放大倍数，不够灵活；2) 采用后期特征融合，无法保留跨尺度特征间的关联；3) 计算成本高。需要一种更灵活、高效且能保持跨尺度关联的多尺度学习方法。

Method: 提出MSPN（多尺度金字塔网络），包含两个核心组件：1) 基于网格的重映射，使用高放大倍数特征推导粗粒度特征；2) 粗粒度引导网络，学习粗粒度上下文信息。该模块可即插即用地集成到基于注意力的MIL框架中。

Result: 在4个临床相关任务、3种基础模型和4个注意力框架上进行了基准测试。MSPN在所有配置和任务中都能一致地提升MIL性能，同时保持轻量级和易用性。

Conclusion: MSPN是一种有效的多尺度增强模块，能够灵活、高效地提升基于注意力的MIL在计算病理学任务中的性能，解决了现有多尺度方法的局限性。

Abstract: Multiple-instance Learning (MIL) is commonly used to undertake computational pathology (CPath) tasks, and the use of multi-scale patches allows diverse features across scales to be learned. Previous studies using multi-scale features in clinical applications rely on multiple inputs across magnifications with late feature fusion, which does not retain the link between features across scales while the inputs are dependent on arbitrary, manufacturer-defined magnifications, being inflexible and computationally expensive. In this paper, we propose the Multi-scale Pyramidal Network (MSPN), which is plug-and-play over attention-based MIL that introduces progressive multi-scale analysis on WSI. Our MSPN consists of (1) grid-based remapping that uses high magnification features to derive coarse features and (2) the coarse guidance network (CGN) that learns coarse contexts. We benchmark MSPN as an add-on module to 4 attention-based frameworks using 4 clinically relevant tasks across 3 types of foundation model, as well as the pre-trained MIL framework. We show that MSPN consistently improves MIL across the compared configurations and tasks, while being lightweight and easy-to-use.

</details>


### [230] [Beyond Open Vocabulary: Multimodal Prompting for Object Detection in Remote Sensing Images](https://arxiv.org/abs/2602.01954)
*Shuai Yang,Ziyue Huang,Jiaxin Chen,Qingjie Liu,Yunhong Wang*

Main category: cs.CV

TL;DR: RS-MPOD：一种用于遥感图像的多模态开放词汇检测框架，通过结合视觉提示和文本提示来解决传统文本提示在遥感场景中语义不稳定的问题


<details>
  <summary>Details</summary>
Motivation: 遥感图像中的开放词汇检测通常依赖纯文本提示来指定目标类别，但这种方法在遥感场景中经常失效，因为任务和应用特定的类别语义会导致语义模糊和分布偏移，使得类别指定不稳定

Method: 提出RS-MPOD多模态开放词汇检测框架，包含：1）视觉提示编码器从示例实例中提取基于外观的类别线索，实现无文本的类别指定；2）多模态融合模块在两种模态都可用时整合视觉和文本信息

Result: 在标准、跨数据集和细粒度遥感基准测试上的广泛实验表明：视觉提示在语义模糊和分布偏移下提供更可靠的类别指定，而多模态提示在文本语义对齐良好时保持竞争力

Conclusion: RS-MPOD通过多模态提示机制显著改善了遥感场景中开放词汇检测的类别指定稳定性，为语义模糊和分布偏移问题提供了有效解决方案

Abstract: Open-vocabulary object detection in remote sensing commonly relies on text-only prompting to specify target categories, implicitly assuming that inference-time category queries can be reliably grounded through pretraining-induced text-visual alignment. In practice, this assumption often breaks down in remote sensing scenarios due to task- and application-specific category semantics, resulting in unstable category specification under open-vocabulary settings. To address this limitation, we propose RS-MPOD, a multimodal open-vocabulary detection framework that reformulates category specification beyond text-only prompting by incorporating instance-grounded visual prompts, textual prompts, and their multimodal integration. RS-MPOD introduces a visual prompt encoder to extract appearance-based category cues from exemplar instances, enabling text-free category specification, and a multimodal fusion module to integrate visual and textual information when both modalities are available. Extensive experiments on standard, cross-dataset, and fine-grained remote sensing benchmarks show that visual prompting yields more reliable category specification under semantic ambiguity and distribution shifts, while multimodal prompting provides a flexible alternative that remains competitive when textual semantics are well aligned.

</details>


### [231] [Your AI-Generated Image Detector Can Secretly Achieve SOTA Accuracy, If Calibrated](https://arxiv.org/abs/2602.01973)
*Muli Yang,Gabriel James Goenawan,Henan Wang,Huaiyuan Qin,Chenghao Xu,Yanhua Yang,Fen Fang,Ying Sun,Joo-Hwee Lim,Hongyuan Zhu*

Main category: cs.CV

TL;DR: 提出基于贝叶斯决策理论的后处理校准框架，通过可学习的标量校正模型logits，解决AI生成图像检测器在测试时的系统偏差问题。


<details>
  <summary>Details</summary>
Motivation: 现有AI生成图像检测器虽然在平衡数据集上训练，但在测试时经常表现出系统偏差，将假图像误分类为真图像。作者假设这种行为源于假样本的分布偏移和训练期间学到的隐式先验。

Method: 提出基于贝叶斯决策理论的后处理校准框架，引入可学习的标量校正模型logits，在目标分布的小验证集上优化，同时保持主干网络冻结。这种参数化调整补偿模型输出的分布偏移。

Result: 在具有挑战性的基准测试中，该方法显著提高了鲁棒性，无需重新训练，为开放世界中可靠且自适应的AI生成图像检测提供了轻量级、有理论依据的解决方案。

Conclusion: 提出的校准框架有效解决了AI生成图像检测器的系统偏差问题，通过理论驱动的后处理调整，实现了在分布偏移下的鲁棒检测，为实际应用提供了实用解决方案。

Abstract: Despite being trained on balanced datasets, existing AI-generated image detectors often exhibit systematic bias at test time, frequently misclassifying fake images as real. We hypothesize that this behavior stems from distributional shift in fake samples and implicit priors learned during training. Specifically, models tend to overfit to superficial artifacts that do not generalize well across different generation methods, leading to a misaligned decision threshold when faced with test-time distribution shift. To address this, we propose a theoretically grounded post-hoc calibration framework based on Bayesian decision theory. In particular, we introduce a learnable scalar correction to the model's logits, optimized on a small validation set from the target distribution while keeping the backbone frozen. This parametric adjustment compensates for distributional shift in model output, realigning the decision boundary even without requiring ground-truth labels. Experiments on challenging benchmarks show that our approach significantly improves robustness without retraining, offering a lightweight and principled solution for reliable and adaptive AI-generated image detection in the open world. Code is available at https://github.com/muliyangm/AIGI-Det-Calib.

</details>


### [232] [Enhancing Multi-Image Understanding through Delimiter Token Scaling](https://arxiv.org/abs/2602.01984)
*Minyoung Lee,Yeji Park,Dongjun Hwang,Yejin Kim,Seong Joon Oh,Junsuk Choe*

Main category: cs.CV

TL;DR: 提出一种通过缩放分隔符标记隐藏状态来增强LVLMs多图像理解能力的方法，无需额外训练成本


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在单图像任务上表现良好，但在多图像输入时性能下降，主要原因是跨图像信息泄漏问题

Method: 缩放分隔符标记的隐藏状态，增强模型保留图像特定信息的能力，强化图像内交互并限制不必要的跨图像交互

Result: 在Mantis、MuirBench、MIRB、QBench2等多图像基准测试中取得性能提升，在TQABench、MultiNews、WCEP-10等多文档多表理解任务中也表现更好

Conclusion: 通过简单缩放分隔符标记的隐藏状态，能有效解决跨图像信息泄漏问题，提升LVLMs的多模态理解能力，且无需额外训练或推理成本

Abstract: Large Vision-Language Models (LVLMs) achieve strong performance on single-image tasks, but their performance declines when multiple images are provided as input. One major reason is the cross-image information leakage, where the model struggles to distinguish information across different images. Existing LVLMs already employ delimiter tokens to mark the start and end of each image, yet our analysis reveals that these tokens fail to effectively block cross-image information leakage. To enhance their effectiveness, we propose a method that scales the hidden states of delimiter tokens. This enhances the model's ability to preserve image-specific information by reinforcing intra-image interaction and limiting undesired cross-image interactions. Consequently, the model is better able to distinguish between images and reason over them more accurately. Experiments show performance gains on multi-image benchmarks such as Mantis, MuirBench, MIRB, and QBench2. We further evaluate our method on text-only tasks that require clear distinction. The method improves performance on multi-document and multi-table understanding benchmarks, including TQABench, MultiNews, and WCEP-10. Notably, our method requires no additional training or inference cost.

</details>


### [233] [Leveraging Latent Vector Prediction for Localized Control in Image Generation via Diffusion Models](https://arxiv.org/abs/2602.01991)
*Pablo Domingo-Gregorio,Javier Ruiz-Hidalgo*

Main category: cs.CV

TL;DR: 提出一种新的扩散模型训练框架，通过掩码特征和额外损失项实现用户定义区域的精确局部控制，同时让模型自主生成其余区域


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像生成方法虽然能通过文本提示和图像级控制（如边缘、分割、深度图）生成高质量图像，但这些控制是全局均匀应用的，缺乏对图像特定区域的精确局部控制能力，用户需要通过反复试错才能获得理想结果

Method: 提出新的训练框架，包含掩码特征和额外损失项，该损失项利用在任何扩散步骤中对初始潜在向量的预测，增强当前步骤与潜在空间中最终样本之间的对应关系，从而实现用户定义区域的精确局部控制

Result: 大量实验表明，该方法能有效合成具有受控局部条件的高质量图像，实现了对用户指定区域的精确控制，同时保持模型对原始提示的响应能力

Conclusion: 该方法解决了现有扩散模型在局部控制方面的局限性，提供了一种更精确的图像生成控制机制，为文本到图像生成领域提供了新的局部控制解决方案

Abstract: Diffusion models emerged as a leading approach in text-to-image generation, producing high-quality images from textual descriptions. However, attempting to achieve detailed control to get a desired image solely through text remains a laborious trial-and-error endeavor. Recent methods have introduced image-level controls alongside with text prompts, using prior images to extract conditional information such as edges, segmentation and depth maps. While effective, these methods apply conditions uniformly across the entire image, limiting localized control. In this paper, we propose a novel methodology to enable precise local control over user-defined regions of an image, while leaving to the diffusion model the task of autonomously generating the remaining areas according to the original prompt. Our approach introduces a new training framework that incorporates masking features and an additional loss term, which leverages the prediction of the initial latent vector at any diffusion step to enhance the correspondence between the current step and the final sample in the latent space. Extensive experiments demonstrate that our method effectively synthesizes high-quality images with controlled local conditions.

</details>


### [234] [SurfSplat: Conquering Feedforward 2D Gaussian Splatting with Surface Continuity Priors](https://arxiv.org/abs/2602.02000)
*Bing He,Jingnan Gao,Yunuo Chen,Ning Cao,Gang Chen,Zhengxue Cheng,Li Song,Wenjun Zhang*

Main category: cs.CV

TL;DR: SurfSplat：基于2D高斯泼溅的稀疏图像3D重建框架，通过表面连续性先验和强制alpha混合策略，实现高几何精度和纹理保真度，并引入HRRC评估指标验证高分辨率重建质量。


<details>
  <summary>Details</summary>
Motivation: 现有基于3D高斯泼溅的通用模型在稀疏图像3D重建中存在问题：无法生成连续表面，只能产生离散、颜色偏差的点云，在近距离观察时出现严重伪影。

Method: 提出基于2D高斯泼溅原语的SurfSplat前馈框架，具有更强各向异性和更高几何精度。引入表面连续性先验和强制alpha混合策略，重建连贯几何和忠实纹理。同时提出HRRC评估指标衡量高分辨率重建质量。

Result: 在RealEstate10K、DL3DV和ScanNet数据集上的实验表明，SurfSplat在标准指标和新提出的HRRC指标上均优于现有方法，为稀疏输入的高保真3D重建提供了稳健解决方案。

Conclusion: SurfSplat通过2D高斯泼溅、表面连续性先验和强制alpha混合策略，成功解决了稀疏图像3D重建中的表面不连续和颜色偏差问题，实现了高质量、高保真的3D场景重建。

Abstract: Reconstructing 3D scenes from sparse images remains a challenging task due to the difficulty of recovering accurate geometry and texture without optimization. Recent approaches leverage generalizable models to generate 3D scenes using 3D Gaussian Splatting (3DGS) primitive. However, they often fail to produce continuous surfaces and instead yield discrete, color-biased point clouds that appear plausible at normal resolution but reveal severe artifacts under close-up views. To address this issue, we present SurfSplat, a feedforward framework based on 2D Gaussian Splatting (2DGS) primitive, which provides stronger anisotropy and higher geometric precision. By incorporating a surface continuity prior and a forced alpha blending strategy, SurfSplat reconstructs coherent geometry together with faithful textures. Furthermore, we introduce High-Resolution Rendering Consistency (HRRC), a new evaluation metric designed to evaluate high-resolution reconstruction quality. Extensive experiments on RealEstate10K, DL3DV, and ScanNet demonstrate that SurfSplat consistently outperforms prior methods on both standard metrics and HRRC, establishing a robust solution for high-fidelity 3D reconstruction from sparse inputs. Project page: https://hebing-sjtu.github.io/SurfSplat-website/

</details>


### [235] [UniDriveDreamer: A Single-Stage Multimodal World Model for Autonomous Driving](https://arxiv.org/abs/2602.02002)
*Guosheng Zhao,Yaozeng Wang,Xiaofeng Wang,Zheng Zhu,Tingdong Yu,Guan Huang,Yongchen Zai,Ji Jiao,Changliang Xue,Xiaole Wang,Zhen Yang,Futang Zhu,Xingang Wang*

Main category: cs.CV

TL;DR: UniDriveDreamer：首个单阶段统一多模态自动驾驶世界模型，直接生成多相机视频和LiDAR序列，无需中间表示或级联模块


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶世界模型主要专注于单模态生成（多相机视频或LiDAR序列），缺乏统一的多模态生成方法，限制了数据合成的完整性和实用性

Method: 1) 设计LiDAR专用VAE和视频VAE分别编码输入数据；2) 提出统一潜在锚定(ULA)显式对齐两种模态的潜在分布；3) 使用扩散transformer联合建模几何对应和时序演化；4) 引入结构化场景布局信息作为条件信号

Result: 在视频和LiDAR生成任务上均超越先前最先进方法，同时在下游任务中带来可测量的性能提升

Conclusion: UniDriveDreamer展示了统一多模态世界模型在自动驾驶数据合成中的有效性，为更完整的场景理解和预测提供了新途径

Abstract: World models have demonstrated significant promise for data synthesis in autonomous driving. However, existing methods predominantly concentrate on single-modality generation, typically focusing on either multi-camera video or LiDAR sequence synthesis. In this paper, we propose UniDriveDreamer, a single-stage unified multimodal world model for autonomous driving, which directly generates multimodal future observations without relying on intermediate representations or cascaded modules. Our framework introduces a LiDAR-specific variational autoencoder (VAE) designed to encode input LiDAR sequences, alongside a video VAE for multi-camera images. To ensure cross-modal compatibility and training stability, we propose Unified Latent Anchoring (ULA), which explicitly aligns the latent distributions of the two modalities. The aligned features are fused and processed by a diffusion transformer that jointly models their geometric correspondence and temporal evolution. Additionally, structured scene layout information is projected per modality as a conditioning signal to guide the synthesis. Extensive experiments demonstrate that UniDriveDreamer outperforms previous state-of-the-art methods in both video and LiDAR generation, while also yielding measurable improvements in downstream

</details>


### [236] [ClueTracer: Question-to-Vision Clue Tracing for Training-Free Hallucination Suppression in Multimodal Reasoning](https://arxiv.org/abs/2602.02004)
*Gongli Xi,Kun Wang,Zeming Gao,Huahui Yi,Haolang Lu,Ye Tian,Wendong Wang*

Main category: cs.CV

TL;DR: 提出ClueTracer方法，通过追踪推理路径中的关键线索传播来抑制多模态推理模型的幻觉问题，无需额外训练即可提升多种架构的性能。


<details>
  <summary>Details</summary>
Motivation: 多模态推理模型在长链推理过程中容易出现幻觉，生成与输入图像或问题无关的内容。研究发现这是由于"推理漂移"现象：模型过度关注与问题无关的实体，稀释了对任务相关线索的注意力，导致推理轨迹与视觉基础逐渐解耦。

Method: 提出ClueRecall评估指标来衡量视觉线索检索能力，并开发ClueTracer插件。该方法从问题出发，追踪关键线索在模型推理路径中的传播（问题→输出→视觉标记），定位任务相关图像区域，同时抑制对无关区域的虚假注意力。

Result: ClueTracer无需额外训练，在多种推理架构（包括R1-OneVision、Ocean-R1、MM-Eureka等）上，在推理基准测试中实现了1.21倍的性能提升。在非推理设置中转移使用时，也能获得1.14倍的增益。

Conclusion: 通过追踪推理路径中的线索传播，可以有效抑制多模态推理模型的幻觉问题，提升模型性能，且该方法具有训练无关、参数无关和架构无关的优势。

Abstract: Large multimodal reasoning models solve challenging visual problems via explicit long-chain inference: they gather visual clues from images and decode clues into textual tokens. Yet this capability also increases hallucinations, where the model generates content that is not supported by the input image or the question. To understand this failure mode, we identify \emph{reasoning drift}: during clue gathering, the model over-focuses on question-irrelevant entities, diluting focus on task-relevant cues and gradually decoupling the reasoning trace from visual grounding. As a consequence, many inference-time localization or intervention methods developed for non-reasoning models fail to pinpoint the true clues in reasoning settings. Motivated by these insights, we introduce ClueRecall, a metric for assessing visual clue retrieval, and present ClueTracer, a training-free, parameter-free, and architecture-agnostic plugin for hallucination suppression. ClueTracer starts from the question and traces how key clues propagate along the model's reasoning pathway (question $\rightarrow$ outputs $\rightarrow$ visual tokens), thereby localizing task-relevant patches while suppressing spurious attention to irrelevant regions. Remarkably, \textbf{without any additional training}, ClueTracer improves all \textbf{reasoning} architectures (including \texttt{R1-OneVision}, \texttt{Ocean-R1}, \texttt{MM-Eureka}, \emph{etc}.) by $\mathbf{1.21\times}$ on reasoning benchmarks. When transferred to \textbf{non-reasoning} settings, it yields a $\mathbf{1.14\times}$ gain.

</details>


### [237] [One Size, Many Fits: Aligning Diverse Group-Wise Click Preferences in Large-Scale Advertising Image Generation](https://arxiv.org/abs/2602.02033)
*Shuo Lu,Haohan Wang,Wei Feng,Weizhen Wang,Shen Zhang,Yaoyu Li,Ao Ma,Zheng Zhang,Jingjing Lv,Junjie Shen,Ching Law,Bing Zhan,Yuan Xu,Huizai Yao,Yongcan Yu,Chenyang Si,Jian Liang*

Main category: cs.CV

TL;DR: OSMF框架通过产品感知自适应分组和偏好条件图像生成，解决广告图像生成中忽视用户群体偏好多样性的问题，实现群体级CTR优化。


<details>
  <summary>Details</summary>
Motivation: 现有广告图像生成方法采用"一刀切"策略，只优化整体点击率而忽视不同用户群体的偏好多样性，导致针对特定群体的营销效果不佳。

Method: 1) 产品感知自适应分组：基于用户属性和产品特征动态组织用户群体；2) 偏好条件图像生成：使用群体感知多模态大语言模型(G-MLLM)为每个群体生成定制图像；3) 使用Group-DPO进行微调以实现群体偏好对齐。

Result: 框架在离线和在线设置中都达到最先进性能，并发布了首个大规模群体广告图像偏好数据集GAIP（包含约60万个群体，基于4000万用户）。

Conclusion: OSMF框架成功解决了广告图像生成中的群体偏好多样性问题，通过统一的群体感知方法显著提升了各用户群体的点击率，为精准营销提供了有效解决方案。

Abstract: Advertising image generation has increasingly focused on online metrics like Click-Through Rate (CTR), yet existing approaches adopt a ``one-size-fits-all" strategy that optimizes for overall CTR while neglecting preference diversity among user groups. This leads to suboptimal performance for specific groups, limiting targeted marketing effectiveness. To bridge this gap, we present \textit{One Size, Many Fits} (OSMF), a unified framework that aligns diverse group-wise click preferences in large-scale advertising image generation. OSMF begins with product-aware adaptive grouping, which dynamically organizes users based on their attributes and product characteristics, representing each group with rich collective preference features. Building on these groups, preference-conditioned image generation employs a Group-aware Multimodal Large Language Model (G-MLLM) to generate tailored images for each group. The G-MLLM is pre-trained to simultaneously comprehend group features and generate advertising images. Subsequently, we fine-tune the G-MLLM using our proposed Group-DPO for group-wise preference alignment, which effectively enhances each group's CTR on the generated images. To further advance this field, we introduce the Grouped Advertising Image Preference Dataset (GAIP), the first large-scale public dataset of group-wise image preferences, including around 600K groups built from 40M users. Extensive experiments demonstrate that our framework achieves the state-of-the-art performance in both offline and online settings. Our code and datasets will be released at https://github.com/JD-GenX/OSMF.

</details>


### [238] [Auto-Comp: An Automated Pipeline for Scalable Compositional Probing of Contrastive Vision-Language Models](https://arxiv.org/abs/2602.02043)
*Cristian Sbrolli,Matteo Matteucci,Toshihiko Yamasaki*

Main category: cs.CV

TL;DR: Auto-Comp是一个自动化合成基准生成管道，用于评估视觉语言模型在组合推理中的缺陷，特别是颜色绑定和空间关系理解方面的失败。


<details>
  <summary>Details</summary>
Motivation: 现代视觉语言模型在组合推理中存在关键缺陷，经常混淆"红色立方体和蓝色球体"与"蓝色立方体和红色球体"。需要细粒度、可控的分析方法来解构这些失败的视觉和语言根源。

Method: 引入Auto-Comp，一个完全自动化的合成管道，生成可扩展的基准。通过生成最小化描述和LLM生成的上下文描述配对的图像，实现受控的A/B测试，以解构核心绑定能力与视觉语言复杂性。

Result: 在20个VLM上评估颜色绑定和空间关系的新基准，发现CLIP和SigLIP模型家族普遍存在组合推理失败。混淆基准揭示模型对低熵干扰物（如重复对象或颜色）高度敏感，表明其组合失败超出了已知的词袋限制。

Conclusion: 发现了一个令人惊讶的权衡：视觉语言上下文提供全局场景线索，有助于空间推理，但通过引入视觉杂乱同时阻碍局部属性绑定。Auto-Comp管道和生成的基准已公开发布以促进未来研究。

Abstract: Modern Vision-Language Models (VLMs) exhibit a critical flaw in compositional reasoning, often confusing "a red cube and a blue sphere" with "a blue cube and a red sphere". Disentangling the visual and linguistic roots of these failures is a fundamental challenge for robust evaluation. To enable fine-grained, controllable analysis, we introduce Auto-Comp, a fully automated and synthetic pipeline for generating scalable benchmarks. Its controllable nature is key to dissecting and isolating different reasoning skills. Auto-Comp generates paired images from Minimal (e.g., "a monitor to the left of a bicycle on a white background") and LLM-generated Contextual captions (e.g., "In a brightly lit photography studio, a monitor is positioned to the left of a bicycle"), allowing a controlled A/B test to disentangle core binding ability from visio-linguistic complexity. Our evaluation of 20 VLMs on novel benchmarks for color binding and spatial relations reveals universal compositional failures in both CLIP and SigLIP model families. Crucially, our novel "Confusion Benchmark" reveals a deeper flaw beyond simple attribute swaps: models are highly susceptible to low-entropy distractors (e.g., repeated objects or colors), demonstrating their compositional failures extend beyond known bag-of-words limitations. we uncover a surprising trade-off: visio-linguistic context, which provides global scene cues, aids spatial reasoning but simultaneously hinders local attribute binding by introducing visual clutter. We release the Auto-Comp pipeline to facilitate future benchmark creation, alongside all our generated benchmarks (https://huggingface.co/AutoComp).

</details>


### [239] [Multi-View Stenosis Classification Leveraging Transformer-Based Multiple-Instance Learning Using Real-World Clinical Data](https://arxiv.org/abs/2602.02067)
*Nikola Cenikj,Özgün Turgut,Alexander Müller,Alexander Steger,Jan Kehrer,Marcus Brugger,Daniel Rueckert,Eimo Martens,Philip Müller*

Main category: cs.CV

TL;DR: 提出SegmentMIL，一种基于transformer的多视角多示例学习框架，用于患者级冠状动脉狭窄分类，无需视角级标注，能同时预测狭窄存在并定位受影响区域。


<details>
  <summary>Details</summary>
Motivation: 冠状动脉狭窄是心血管疾病的主要原因，现有深度学习模型需要昂贵的视角级标注，且无法捕捉多视角间的时序动态和依赖关系，而这些对临床诊断至关重要。

Method: 提出SegmentMIL框架，基于transformer的多视角多示例学习，使用患者级监督训练，无需任何视角级标注，能联合预测狭窄存在并定位受影响解剖区域（区分左右冠状动脉及其分段）。

Result: 在内部和外部评估中均获得高性能，优于视角级模型和经典MIL基线，展示了作为临床可行且可扩展解决方案的潜力。

Conclusion: SegmentMIL是一个有前景的临床可行且可扩展的冠状动脉狭窄诊断解决方案，通过患者级监督训练，无需视角级标注，能有效捕捉多视角动态并实现准确分类和定位。

Abstract: Coronary artery stenosis is a leading cause of cardiovascular disease, diagnosed by analyzing the coronary arteries from multiple angiography views. Although numerous deep-learning models have been proposed for stenosis detection from a single angiography view, their performance heavily relies on expensive view-level annotations, which are often not readily available in hospital systems. Moreover, these models fail to capture the temporal dynamics and dependencies among multiple views, which are crucial for clinical diagnosis. To address this, we propose SegmentMIL, a transformer-based multi-view multiple-instance learning framework for patient-level stenosis classification. Trained on a real-world clinical dataset, using patient-level supervision and without any view-level annotations, SegmentMIL jointly predicts the presence of stenosis and localizes the affected anatomical region, distinguishing between the right and left coronary arteries and their respective segments. SegmentMIL obtains high performance on internal and external evaluations and outperforms both view-level models and classical MIL baselines, underscoring its potential as a clinically viable and scalable solution for coronary stenosis diagnosis. Our code is available at https://github.com/NikolaCenic/mil-stenosis.

</details>


### [240] [UrbanGS: A Scalable and Efficient Architecture for Geometrically Accurate Large-Scene Reconstruction](https://arxiv.org/abs/2602.02089)
*Changbai Li,Haodong Zhu,Hanlin Chen,Xiuping Liang,Tongfei Chen,Shuwei Shao,Linlin Yang,Huobin Tan,Baochang Zhang*

Main category: cs.CV

TL;DR: UrbanGS：针对城市规模场景的3D高斯泼溅扩展框架，通过深度一致D-法线正则化和空间自适应高斯剪枝，解决了几何一致性、内存效率和计算可扩展性三大挑战。


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅（3DGS）在有限场景中能实现高质量实时渲染，但扩展到大规模城市环境时面临几何一致性差、内存效率低和计算可扩展性不足的挑战。

Method: 1. 深度一致D-法线正则化模块：结合D-法线约束与外部深度监督，通过基于梯度一致性和逆深度偏差的自适应置信度加权机制，全面更新几何参数；2. 空间自适应高斯剪枝策略：根据局部几何复杂度和可见性动态调整高斯密度；3. 统一分区和视图分配方案：消除边界伪影并优化计算负载。

Result: 在多个城市数据集上的实验表明，UrbanGS在渲染质量、几何精度和内存效率方面均达到优越性能，为高保真大规模场景重建提供了系统解决方案。

Conclusion: UrbanGS成功解决了3DGS扩展到城市规模场景时的关键挑战，通过创新的正则化和剪枝策略，实现了高质量、高效的大规模城市环境重建。

Abstract: While 3D Gaussian Splatting (3DGS) enables high-quality, real-time rendering for bounded scenes, its extension to large-scale urban environments gives rise to critical challenges in terms of geometric consistency, memory efficiency, and computational scalability. To address these issues, we present UrbanGS, a scalable reconstruction framework that effectively tackles these challenges for city-scale applications. First, we propose a Depth-Consistent D-Normal Regularization module. Unlike existing approaches that rely solely on monocular normal estimators, which can effectively update rotation parameters yet struggle to update position parameters, our method integrates D-Normal constraints with external depth supervision. This allows for comprehensive updates of all geometric parameters. By further incorporating an adaptive confidence weighting mechanism based on gradient consistency and inverse depth deviation, our approach significantly enhances multi-view depth alignment and geometric coherence, which effectively resolves the issue of geometric accuracy in complex large-scale scenes. To improve scalability, we introduce a Spatially Adaptive Gaussian Pruning (SAGP) strategy, which dynamically adjusts Gaussian density based on local geometric complexity and visibility to reduce redundancy. Additionally, a unified partitioning and view assignment scheme is designed to eliminate boundary artifacts and optimize computational load. Extensive experiments on multiple urban datasets demonstrate that UrbanGS achieves superior performance in rendering quality, geometric accuracy, and memory efficiency, providing a systematic solution for high-fidelity large-scale scene reconstruction.

</details>


### [241] [FSVideo: Fast Speed Video Diffusion Model in a Highly-Compressed Latent Space](https://arxiv.org/abs/2602.02092)
*FSVideo Team,Qingyu Chen,Zhiyuan Fang,Haibin Huang,Xinwei Huang,Tong Jin,Minxuan Lin,Bo Liu,Celong Liu,Chongyang Ma,Xing Mei,Xiaohui Shen,Yaojie Shen,Fuwen Tan,Angtian Wang,Xiao Yang,Yiding Yang,Jiamin Yuan,Lingxi Zhang,Yuxin Zhang*

Main category: cs.CV

TL;DR: FSVideo是一个基于Transformer的快速图像到视频扩散框架，通过高度压缩的潜在空间、改进的扩散Transformer架构和多分辨率生成策略，在保持竞争力的同时实现了一个数量级的加速。


<details>
  <summary>Details</summary>
Motivation: 开发一个高效的图像到视频生成框架，在保持生成质量的同时显著提升生成速度，解决现有方法速度较慢的问题。

Method: 1) 设计新的视频自动编码器，实现64×64×4的高压缩潜在空间；2) 采用带有层内存设计的扩散Transformer架构，增强层间信息流和上下文重用；3) 通过多分辨率生成策略，使用少量步骤的DIT上采样器提高视频保真度。

Result: 最终模型包含140亿参数的DIT基础模型和140亿参数的DIT上采样器，在保持与流行开源模型竞争力的同时，实现了数量级的速度提升。

Conclusion: FSVideo框架通过创新的架构设计和训练策略，成功实现了高质量且快速的图像到视频生成，为高效视频生成提供了有前景的解决方案。

Abstract: We introduce FSVideo, a fast speed transformer-based image-to-video (I2V) diffusion framework. We build our framework on the following key components: 1.) a new video autoencoder with highly-compressed latent space ($64\times64\times4$ spatial-temporal downsampling ratio), achieving competitive reconstruction quality; 2.) a diffusion transformer (DIT) architecture with a new layer memory design to enhance inter-layer information flow and context reuse within DIT, and 3.) a multi-resolution generation strategy via a few-step DIT upsampler to increase video fidelity. Our final model, which contains a 14B DIT base model and a 14B DIT upsampler, achieves competitive performance against other popular open-source models, while being an order of magnitude faster. We discuss our model design as well as training strategies in this report.

</details>


### [242] [Teacher-Guided Student Self-Knowledge Distillation Using Diffusion Model](https://arxiv.org/abs/2602.02107)
*Yu Wang,Chuanguang Yang,Zhulin An,Weilun Feng,Jiarui Zhao,Chengqing Yu,Libo Huang,Boyu Diao,Yongjun Xu*

Main category: cs.CV

TL;DR: 提出DSKD方法，通过教师引导的学生扩散自知识蒸馏，解决传统知识蒸馏中师生特征分布差异导致的不兼容信息学习问题


<details>
  <summary>Details</summary>
Motivation: 传统知识蒸馏方法直接对齐师生特征，但由于师生特征分布差异，学生模型可能从教师学习到不兼容信息，需要解决这一分布差异问题

Method: 1. 利用教师分类器引导轻量级扩散模型对学生特征进行去噪采样；2. 提出基于局部敏感哈希的特征蒸馏方法，在原始学生特征和去噪后特征之间进行蒸馏；3. 去噪后的学生特征包含教师知识，可视为教师角色

Result: 在视觉识别任务实验中，DSKD显著优于现有知识蒸馏方法，在不同模型和数据集上均表现出色

Conclusion: DSKD方法通过扩散自知识蒸馏消除了师生映射方式和特征分布的差异，同时从教师学习有意义的知识，提高了知识蒸馏效果

Abstract: Existing Knowledge Distillation (KD) methods often align feature information between teacher and student by exploring meaningful feature processing and loss functions. However, due to the difference in feature distributions between the teacher and student, the student model may learn incompatible information from the teacher. To address this problem, we propose teacher-guided student Diffusion Self-KD, dubbed as DSKD. Instead of the direct teacher-student alignment, we leverage the teacher classifier to guide the sampling process of denoising student features through a light-weight diffusion model. We then propose a novel locality-sensitive hashing (LSH)-guided feature distillation method between the original and denoised student features. The denoised student features encapsulate teacher knowledge and could be regarded as a teacher role. In this way, our DSKD method could eliminate discrepancies in mapping manners and feature distributions between the teacher and student, while learning meaningful knowledge from the teacher. Experiments on visual recognition tasks demonstrate that DSKD significantly outperforms existing KD methods across various models and datasets. Our code is attached in supplementary material.

</details>


### [243] [Enhancing Diffusion-Based Quantitatively Controllable Image Generation via Matrix-Form EDM and Adaptive Vicinal Training](https://arxiv.org/abs/2602.02114)
*Xin Ding,Yun Chen,Sen Zhang,Kao Zhang,Nenglun Chen,Peibei Cao,Yongwei Wang,Fei Wu*

Main category: cs.CV

TL;DR: iCCDM是一个改进的连续条件扩散模型，采用先进的EDM框架和自适应邻域训练策略，在图像生成质量和采样效率上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的CCDM方法虽然优于早期方法，但仍存在局限性：依赖过时的扩散框架、采样效率低（需要长采样轨迹），且最近被GAN方法CcGAN-AVAR超越。需要改进生成质量和采样效率。

Method: 提出iCCDM框架，采用先进的Elucidated Diffusion Model (EDM)框架并进行重大修改，引入新颖的矩阵形式EDM公式和自适应邻域训练策略。

Result: 在四个基准数据集（分辨率从64×64到256×256）上的实验表明，iCCDM一致优于现有方法，包括最先进的大规模文本到图像扩散模型（如Stable Diffusion 3、FLUX.1、Qwen-Image），在显著降低采样成本的同时获得更高的生成质量。

Conclusion: iCCDM通过整合先进的EDM框架和创新的训练策略，成功解决了CCDM的局限性，在连续回归标签条件下的图像生成任务中实现了更好的性能和效率。

Abstract: Continuous Conditional Diffusion Model (CCDM) is a diffusion-based framework designed to generate high-quality images conditioned on continuous regression labels. Although CCDM has demonstrated clear advantages over prior approaches across a range of datasets, it still exhibits notable limitations and has recently been surpassed by a GAN-based method, namely CcGAN-AVAR. These limitations mainly arise from its reliance on an outdated diffusion framework and its low sampling efficiency due to long sampling trajectories. To address these issues, we propose an improved CCDM framework, termed iCCDM, which incorporates the more advanced \textit{Elucidated Diffusion Model} (EDM) framework with substantial modifications to improve both generation quality and sampling efficiency. Specifically, iCCDM introduces a novel matrix-form EDM formulation together with an adaptive vicinal training strategy. Extensive experiments on four benchmark datasets, spanning image resolutions from $64\times64$ to $256\times256$, demonstrate that iCCDM consistently outperforms existing methods, including state-of-the-art large-scale text-to-image diffusion models (e.g., Stable Diffusion 3, FLUX.1, and Qwen-Image), achieving higher generation quality while significantly reducing sampling cost.

</details>


### [244] [MLV-Edit: Towards Consistent and Highly Efficient Editing for Minute-Level Videos](https://arxiv.org/abs/2602.02123)
*Yangyi Cao,Yuanhang Li,Lan Chen,Qi Mao*

Main category: cs.CV

TL;DR: MLV-Edit是一个无需训练、基于光流的分钟级视频编辑框架，通过分而治之的片段编辑策略解决长视频编辑的挑战，包含Velocity Blend和Attention Sink两个核心模块来保持时间一致性和结构稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有视频编辑技术擅长短视频处理，但在扩展到长时视频时面临计算开销过大和难以维持全局时间一致性的挑战，特别是在处理数千帧的长视频时。

Method: 采用分而治之的片段编辑策略，包含两个核心模块：1) Velocity Blend通过对齐相邻片段的光流场来纠正运动不一致性，消除边界伪影；2) Attention Sink将局部片段特征锚定到全局参考帧，抑制累积结构漂移。

Result: 大量定量和定性实验表明，MLV-Edit在时间稳定性和语义保真度方面持续优于现有最先进方法。

Conclusion: MLV-Edit提供了一个有效的训练无关框架，成功解决了分钟级视频编辑中的时间一致性和计算效率问题，为长视频编辑提供了实用解决方案。

Abstract: We propose MLV-Edit, a training-free, flow-based framework that address the unique challenges of minute-level video editing. While existing techniques excel in short-form video manipulation, scaling them to long-duration videos remains challenging due to prohibitive computational overhead and the difficulty of maintaining global temporal consistency across thousands of frames. To address this, MLV-Edit employs a divide-and-conquer strategy for segment-wise editing, facilitated by two core modules: Velocity Blend rectifies motion inconsistencies at segment boundaries by aligning the flow fields of adjacent chunks, eliminating flickering and boundary artifacts commonly observed in fragmented video processing; and Attention Sink anchors local segment features to global reference frames, effectively suppressing cumulative structural drift. Extensive quantitative and qualitative experiments demonstrate that MLV-Edit consistently outperforms state-of-the-art methods in terms of temporal stability and semantic fidelity.

</details>


### [245] [Toxicity Assessment in Preclinical Histopathology via Class-Aware Mahalanobis Distance for Known and Novel Anomalies](https://arxiv.org/abs/2602.02124)
*Olga Graf,Dhrupal Patel,Peter Groß,Charlotte Lempp,Matthias Hein,Fabian Heinemann*

Main category: cs.CV

TL;DR: 提出基于AI的病理切片异常检测框架，用于毒理学研究中啮齿动物肝脏组织病理学全切片图像分析，能检测已知和未知病理变化


<details>
  <summary>Details</summary>
Motivation: 药物诱导毒性是临床前开发和早期临床试验失败的主要原因，组织病理学评估依赖专家病理学家，成为大规模筛选的瓶颈

Method: 创建像素级标注数据集，使用预训练Vision Transformer（DINOv2）通过低秩适应（LoRA）进行组织分割，提取特征后使用马氏距离进行异常检测，并提出类别特异性阈值优化

Result: 仅0.16%的病理组织被误分类为健康，0.35%的健康组织被误分类为病理，能准确检测已知毒理学发现和罕见OOD形态

Conclusion: AI驱动的组织病理学有潜力支持临床前工作流程，减少后期失败，提高药物开发效率

Abstract: Drug-induced toxicity remains a leading cause of failure in preclinical development and early clinical trials. Detecting adverse effects at an early stage is critical to reduce attrition and accelerate the development of safe medicines. Histopathological evaluation remains the gold standard for toxicity assessment, but it relies heavily on expert pathologists, creating a bottleneck for large-scale screening. To address this challenge, we introduce an AI-based anomaly detection framework for histopathological whole-slide images (WSIs) in rodent livers from toxicology studies. The system identifies healthy tissue and known pathologies (anomalies) for which training data is available. In addition, it can detect rare pathologies without training data as out-of-distribution (OOD) findings. We generate a novel dataset of pixelwise annotations of healthy tissue and known pathologies and use this data to fine-tune a pre-trained Vision Transformer (DINOv2) via Low-Rank Adaptation (LoRA) in order to do tissue segmentation. Finally, we extract features for OOD detection using the Mahalanobis distance. To better account for class-dependent variability in histological data, we propose the use of class-specific thresholds. We optimize the thresholds using the mean of the false negative and false positive rates, resulting in only 0.16\% of pathological tissue classified as healthy and 0.35\% of healthy tissue classified as pathological. Applied to mouse liver WSIs with known toxicological findings, the framework accurately detects anomalies, including rare OOD morphologies. This work demonstrates the potential of AI-driven histopathology to support preclinical workflows, reduce late-stage failures, and improve efficiency in drug development.

</details>


### [246] [Eliminating Registration Bias in Synthetic CT Generation: A Physics-Based Simulation Framework](https://arxiv.org/abs/2602.02130)
*Lukas Zimmermann,Michael Rauter,Maximilian Schmid,Dietmar Georg,Barbara Knäusl*

Main category: cs.CV

TL;DR: 该论文提出使用基于物理的CBCT模拟生成几何对齐的训练数据对，结合几何对齐指标评估，相比传统基于配准的方法能更好地满足临床需求。


<details>
  <summary>Details</summary>
Motivation: 传统监督式CBCT合成CT生成方法需要配准的训练对，但完美配准无法实现，配准偏差会传播到训练模型中并污染标准评估指标，导致基准性能可能反映的是配准伪影而非解剖保真度。

Method: 提出基于物理的CBCT模拟方法，通过构造提供几何对齐的训练对，并使用几何对齐指标（如归一化互信息）相对于输入CBCT进行评估，而不是使用有偏差的ground truth。

Result: 在两个独立的盆腔数据集上，使用合成数据训练的模型实现了更优的几何对齐（归一化互信息：0.31 vs 0.22），尽管传统强度指标较低。几何对齐指标能一致预测观察者偏好，临床观察者在87%的案例中更偏好合成训练的输出。

Conclusion: 几何保真度而非与有偏差ground truth的强度一致性，更符合临床需求。基于物理的CBCT模拟结合几何对齐评估方法能提供更可靠的训练和评估框架。

Abstract: Supervised synthetic CT generation from CBCT requires registered training pairs, yet perfect registration between separately acquired scans remains unattainable. This registration bias propagates into trained models and corrupts standard evaluation metrics. This may suggest that superior benchmark performance indicates better reproduction of registration artifacts rather than anatomical fidelity. We propose physics-based CBCT simulation to provide geometrically aligned training pairs by construction, combined with evaluation using geometric alignment metrics against input CBCT rather than biased ground truth. On two independent pelvic datasets, models trained on synthetic data achieved superior geometric alignment (Normalized Mutual Information: 0.31 vs 0.22) despite lower conventional intensity scores. Intensity metrics showed inverted correlations with clinical assessment for deformably registered data, while Normalized Mutual Information consistently predicted observer preference across registration methodologies (rho = 0.31, p < 0.001). Clinical observers preferred synthetic-trained outputs in 87% of cases, demonstrating that geometric fidelity, not intensity agreement with biased ground truth, aligns with clinical requirements.

</details>


### [247] [Deep learning enables urban change profiling through alignment of historical maps](https://arxiv.org/abs/2602.02154)
*Sidi Wu,Yizi Chen,Maurizio Gribaudi,Konrad Schindler,Clément Mallet,Julien Perret,Lorenz Hurni*

Main category: cs.CV

TL;DR: 提出基于深度学习的自动化框架，从历史地图中提取细粒度城市变化信息，通过模块化设计整合密集地图对齐、多时相目标检测和变化分析


<details>
  <summary>Details</summary>
Motivation: 历史地图提供了城市长期转型的独特记录，但由于空间错位、制图差异和文档质量退化等问题，从历史地图系列中提取一致且细粒度的变化信息仍然具有挑战性，限制了大多数分析只能采用小规模或定性方法

Method: 提出完全自动化的深度学习框架，采用模块化设计，整合密集地图对齐、多时相目标检测和变化分析三个核心模块

Result: 实验证明所提出的对齐和目标检测方法具有鲁棒性能。应用于1868-1937年的巴黎，该框架揭示了城市转型的空间和时间异质性，展示了其在社会科学和人文研究中的相关性

Conclusion: 该框架将历史地图分析从临时视觉比较转向系统化、定量化的城市变化表征。模块化设计支持适应不同的制图背景和下游应用

Abstract: Prior to modern Earth observation technologies, historical maps provide a unique record of long-term urban transformation and offer a lens on the evolving identity of cities. However, extracting consistent and fine-grained change information from historical map series remains challenging due to spatial misalignment, cartographic variation, and degrading document quality, limiting most analyses to small-scale or qualitative approaches. We propose a fully automated, deep learning-based framework for fine-grained urban change analysis from large collections of historical maps, built on a modular design that integrates dense map alignment, multi-temporal object detection, and change profiling. This framework shifts the analysis of historical maps from ad hoc visual comparison toward systematic, quantitative characterization of urban change. Experiments demonstrate the robust performance of the proposed alignment and object detection methods. Applied to Paris between 1868 and 1937, the framework reveals the spatial and temporal heterogeneity in urban transformation, highlighting its relevance for research in the social sciences and humanities. The modular design of our framework further supports adaptation to diverse cartographic contexts and downstream applications.

</details>


### [248] [LoopViT: Scaling Visual ARC with Looped Transformers](https://arxiv.org/abs/2602.02156)
*Wen-Jie Shu,Xuerui Qiu,Rui-Jie Zhu,Harold Haodong Chen,Yexin Liu,Harry Yang*

Main category: cs.CV

TL;DR: 提出Loop-ViT递归架构，通过权重共享的循环机制解耦推理深度与模型容量，引入基于预测熵的动态退出机制，在ARC-AGI基准上以更小参数量取得更好性能


<details>
  <summary>Details</summary>
Motivation: 现有视觉推理方法使用前馈架构，其计算深度严格受限于参数规模，无法捕捉人类归纳推理的迭代算法特性。需要一种能解耦推理深度与模型容量的架构

Method: 提出Loop-ViT递归架构，迭代执行权重共享的混合块（结合局部卷积和全局注意力），形成潜在思维链。引入基于预测熵的参数无关动态退出机制，当内部状态达到低不确定性吸引子时停止推理

Result: 在ARC-AGI-1基准上，仅1800万参数的模型达到65.8%准确率，优于7300万参数的大型集成模型，证明自适应迭代计算比单纯增加网络宽度更高效

Conclusion: 自适应迭代计算为视觉推理提供了比单纯增加网络宽度更高效的扩展轴，递归架构能更好地捕捉人类归纳推理的算法特性

Abstract: Recent advances in visual reasoning have leveraged vision transformers to tackle the ARC-AGI benchmark. However, we argue that the feed-forward architecture, where computational depth is strictly bound to parameter size, falls short of capturing the iterative, algorithmic nature of human induction. In this work, we propose a recursive architecture called Loop-ViT, which decouples reasoning depth from model capacity through weight-tied recurrence. Loop-ViT iterates a weight-tied Hybrid Block, combining local convolutions and global attention, to form a latent chain of thought. Crucially, we introduce a parameter-free Dynamic Exit mechanism based on predictive entropy: the model halts inference when its internal state ``crystallizes" into a low-uncertainty attractor. Empirical results on the ARC-AGI-1 benchmark validate this perspective: our 18M model achieves 65.8% accuracy, outperforming massive 73M-parameter ensembles. These findings demonstrate that adaptive iterative computation offers a far more efficient scaling axis for visual reasoning than simply increasing network width. The code is available at https://github.com/WenjieShu/LoopViT.

</details>


### [249] [Reg4Pru: Regularisation Through Random Token Routing for Token Pruning](https://arxiv.org/abs/2602.02163)
*Julian Wyatt,Ronald Clark,Irina Voiculescu*

Main category: cs.CV

TL;DR: Reg4Pru是一种训练正则化技术，通过缓解token剪枝带来的性能损失，在保持计算效率的同时显著提升分割任务的精度。


<details>
  <summary>Details</summary>
Motivation: Transformer在视觉模型中计算复杂度随token数量呈二次方增长，现有token剪枝方法虽然提高了计算效率，但会导致保留的表征不稳定，在深层网络中影响密集预测性能。

Method: 提出Reg4Pru训练正则化技术，专门针对token剪枝策略进行优化，通过正则化手段缓解剪枝带来的性能损失。

Result: 在FIVES血管分割数据集上，Reg4Pru相比无路由训练的相同模型，平均精度绝对提升46%，同时实现29%的相对加速（相比非剪枝基线）。

Conclusion: Reg4Pru是token剪枝策略中一种有价值的正则化方法，能够在保持计算效率的同时显著提升分割性能。

Abstract: Transformers are widely adopted in modern vision models due to their strong ability to scale with dataset size and generalisability. However, this comes with a major drawback: computation scales quadratically to the total number of tokens. Numerous methods have been proposed to mitigate this. For example, we consider token pruning with reactivating tokens from preserved representations, but the increased computational efficiency of this method results in decreased stability from the preserved representations, leading to poorer dense prediction performance at deeper layers. In this work, we introduce Reg4Pru, a training regularisation technique that mitigates token-pruning performance loss for segmentation. We compare our models on the FIVES blood vessel segmentation dataset and find that Reg4Pru improves average precision by an absolute 46% compared to the same model trained without routing. This increase is observed using a configuration that achieves a 29% relative speedup in wall-clock time compared to the non-pruned baseline. These findings indicate that Reg4Pru is a valuable regulariser for token reduction strategies.

</details>


### [250] [Lung Nodule Image Synthesis Driven by Two-Stage Generative Adversarial Networks](https://arxiv.org/abs/2602.02171)
*Lu Cao,Xiquan He,Junying Zeng,Chaoyun Mai,Min Luo*

Main category: cs.CV

TL;DR: 提出TSGAN两阶段生成对抗网络，通过解耦肺结节形态结构和纹理特征，增强合成数据的多样性和空间可控性，提升检测模型性能


<details>
  <summary>Details</summary>
Motivation: 现有肺结节CT数据集样本量有限且多样性不足，限制了检测模型的性能和泛化能力。现有生成方法存在多样性不足、可控性差、纹理特征单调和解剖结构扭曲等问题

Method: 两阶段生成对抗网络：第一阶段使用StyleGAN生成语义分割掩码图像，控制肺结节解剖结构；第二阶段使用DL-Pix2Pix模型将掩码图转换为CT图像，采用局部重要性注意力捕获局部特征，动态权重多头窗口注意力增强纹理建模能力

Result: 在LUNA16数据集上，相比原始数据集，准确率提升4.6%，mAP提升4%。实验结果表明TSGAN能增强合成图像质量和检测模型性能

Conclusion: TSGAN通过解耦形态结构和纹理特征，有效提升了合成肺结节CT图像的多样性和空间可控性，显著改善了检测模型的性能表现

Abstract: The limited sample size and insufficient diversity of lung nodule CT datasets severely restrict the performance and generalization ability of detection models. Existing methods generate images with insufficient diversity and controllability, suffering from issues such as monotonous texture features and distorted anatomical structures. Therefore, we propose a two-stage generative adversarial network (TSGAN) to enhance the diversity and spatial controllability of synthetic data by decoupling the morphological structure and texture features of lung nodules. In the first stage, StyleGAN is used to generate semantic segmentation mask images, encoding lung nodules and tissue backgrounds to control the anatomical structure of lung nodule images; The second stage uses the DL-Pix2Pix model to translate the mask map into CT images, employing local importance attention to capture local features, while utilizing dynamic weight multi-head window attention to enhance the modeling capability of lung nodule texture and background. Compared to the original dataset, the accuracy improved by 4.6% and mAP by 4% on the LUNA16 dataset. Experimental results demonstrate that TSGAN can enhance the quality of synthetic images and the performance of detection models.

</details>


### [251] [CIEC: Coupling Implicit and Explicit Cues for Multimodal Weakly Supervised Manipulation Localization](https://arxiv.org/abs/2602.02175)
*Xinquan Yu,Wei Lu,Xiangyang Luo*

Main category: cs.CV

TL;DR: 提出CIEC框架，仅使用粗粒度图像/句子级标注实现多模态弱监督篡改定位，包含图像和文本两个分支，性能接近全监督方法。


<details>
  <summary>Details</summary>
Motivation: 当前多模态篡改定位方法依赖昂贵且耗时的细粒度标注（如补丁/标记级），需要开发仅使用粗粒度标注的弱监督方法。

Method: 提出CIEC框架，包含两个分支：1) 图像弱监督定位分支：使用TRPS模块整合视觉和文本伪造线索，结合空间先验锁定可疑区域，通过背景抑制和空间对比约束减少干扰；2) 文本弱监督定位分支：使用VCTG模块关注内容词，利用相对视觉偏差辅助标记定位，通过非对称稀疏和语义一致性约束缓解标签噪声。

Result: 大量实验证明CIEC的有效性，在多个评估指标上取得了与全监督方法相当的结果。

Conclusion: CIEC框架仅使用粗粒度标注就能实现有效的多模态篡改定位，性能接近全监督方法，为弱监督篡改检测提供了新思路。

Abstract: To mitigate the threat of misinformation, multimodal manipulation localization has garnered growing attention. Consider that current methods rely on costly and time-consuming fine-grained annotations, such as patch/token-level annotations. This paper proposes a novel framework named Coupling Implicit and Explicit Cues (CIEC), which aims to achieve multimodal weakly-supervised manipulation localization for image-text pairs utilizing only coarse-grained image/sentence-level annotations. It comprises two branches, image-based and text-based weakly-supervised localization. For the former, we devise the Textual-guidance Refine Patch Selection (TRPS) module. It integrates forgery cues from both visual and textual perspectives to lock onto suspicious regions aided by spatial priors. Followed by the background silencing and spatial contrast constraints to suppress interference from irrelevant areas. For the latter, we devise the Visual-deviation Calibrated Token Grounding (VCTG) module. It focuses on meaningful content words and leverages relative visual bias to assist token localization. Followed by the asymmetric sparse and semantic consistency constraints to mitigate label noise and ensure reliability. Extensive experiments demonstrate the effectiveness of our CIEC, yielding results comparable to fully supervised methods on several evaluation metrics.

</details>


### [252] [Learning Topology-Aware Implicit Field for Unified Pulmonary Tree Modeling with Incomplete Topological Supervision](https://arxiv.org/abs/2602.02186)
*Ziqiao Weng,Jiancheng Yang,Kangxian Xie,Bo Zhou,Weidong Cai*

Main category: cs.CV

TL;DR: TopoField：一种用于修复CT图像中肺树拓扑不完整性的隐式建模框架，通过稀疏点云表示和连续隐式场学习，实现拓扑修复、解剖标记和肺段重建的联合推理。


<details>
  <summary>Details</summary>
Motivation: CT图像提取的肺树经常存在拓扑不完整性（如缺失或断开的支气管分支），这会严重影响下游解剖分析，而现有方法依赖密集体积处理或显式图推理，效率低且对结构损坏鲁棒性差。

Method: 使用稀疏表面和骨架点云表示肺解剖结构，学习一个连续隐式场，通过在已有不完整树上引入合成结构破坏进行训练，无需完整或显式断开标注。基于修复后的隐式表示，通过任务特定的隐式函数在单次前向传播中联合推理解剖标记和肺段重建。

Result: 在Lung3D+数据集上的实验表明，TopoField能持续改善拓扑完整性，并在具有挑战性的不完整场景下实现准确的解剖标记和肺段重建。由于其隐式公式，计算效率高，每个病例所有任务仅需1秒多。

Conclusion: TopoField将拓扑修复作为首要建模问题，提供了一个统一的多任务推理框架，具有高计算效率和实用性，适合大规模和时间敏感的临床应用。

Abstract: Pulmonary trees extracted from CT images frequently exhibit topological incompleteness, such as missing or disconnected branches, which substantially degrades downstream anatomical analysis and limits the applicability of existing pulmonary tree modeling pipelines. Current approaches typically rely on dense volumetric processing or explicit graph reasoning, leading to limited efficiency and reduced robustness under realistic structural corruption. We propose TopoField, a topology-aware implicit modeling framework that treats topology repair as a first-class modeling problem and enables unified multi-task inference for pulmonary tree analysis. TopoField represents pulmonary anatomy using sparse surface and skeleton point clouds and learns a continuous implicit field that supports topology repair without relying on complete or explicit disconnection annotations, by training on synthetically introduced structural disruptions over \textit{already} incomplete trees. Building upon the repaired implicit representation, anatomical labeling and lung segment reconstruction are jointly inferred through task-specific implicit functions within a single forward pass.Extensive experiments on the Lung3D+ dataset demonstrate that TopoField consistently improves topological completeness and achieves accurate anatomical labeling and lung segment reconstruction under challenging incomplete scenarios. Owing to its implicit formulation, TopoField attains high computational efficiency, completing all tasks in just over one second per case, highlighting its practicality for large-scale and time-sensitive clinical applications. Code and data will be available at https://github.com/HINTLab/TopoField.

</details>


### [253] [SSI-DM: Singularity Skipping Inversion of Diffusion Models](https://arxiv.org/abs/2602.02193)
*Chen Min,Enze Jiang,Jishen Peng,Zheng Ma*

Main category: cs.CV

TL;DR: 提出SSI-DM方法，通过跳过奇异区域解决扩散模型反演中的数学奇异性问题，生成高斯噪声并保持重建质量


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型反演方法在早期去噪步骤中存在不准确性，导致生成非高斯噪声且编辑性差，根本原因是数学奇异性使反演问题本质不适定

Method: 提出SSI-DM方法，在标准反演前添加少量噪声来绕过奇异区域，生成具有自然高斯特性的反演噪声，同时保持重建保真度

Result: 在公共图像数据集上，SSI-DM在重建和插值任务中表现优异，作为即插即用技术与通用扩散模型兼容

Conclusion: SSI-DM为扩散模型反演提供了原理性且高效的解决方案，通过处理数学奇异性问题改善了反演噪声的高斯特性和编辑性

Abstract: Inverting real images into the noise space is essential for editing tasks using diffusion models, yet existing methods produce non-Gaussian noise with poor editability due to the inaccuracy in early noising steps. We identify the root cause: a mathematical singularity that renders inversion fundamentally ill-posed. We propose Singularity Skipping Inversion of Diffusion Models (SSI-DM), which bypasses this singular region by adding small noise before standard inversion. This simple approach produces inverted noise with natural Gaussian properties while maintaining reconstruction fidelity. As a plug-and-play technique compatible with general diffusion models, our method achieves superior performance on public image datasets for reconstruction and interpolation tasks, providing a principled and efficient solution to diffusion model inversion.

</details>


### [254] [MAIN-VLA: Modeling Abstraction of Intention and eNvironment for Vision-Language-Action Models](https://arxiv.org/abs/2602.02212)
*Zheyuan Zhou,Liang Du,Zixun Sun,Xiaoyu Zhou,Ruimin Ye,Qihao Chen,Yinda Chen,Lemiao Qiu*

Main category: cs.CV

TL;DR: MAIN-VLA框架通过意图抽象和环境语义抽象，在复杂动态环境中实现高效决策，在Minecraft和大型PvP游戏中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有VLA方法在高度复杂动态环境（如3D开放世界和大型PvP游戏）中，难以从冗余传感器流中提取动作关键信号，决策效率低下。

Method: 提出MAIN-VLA框架：1) 意图抽象(IA)将冗长语言指令压缩为显式语义原语；2) 环境语义抽象(ESA)将视觉流投影为结构化拓扑可供性表示；3) 对齐两种抽象模态产生注意力集中效应，实现无参数token剪枝。

Result: 在开放世界Minecraft和大型PvP环境（和平精英、Valorant）中达到新SOTA，具有优越决策质量、更强泛化能力和顶尖推理效率。

Conclusion: MAIN-VLA通过建模意图和环境抽象，在深层语义对齐而非表面模式匹配的基础上实现高效决策，为复杂动态环境中的VLA任务提供了有效解决方案。

Abstract: Despite significant progress in Visual-Language-Action (VLA), in highly complex and dynamic environments that involve real-time unpredictable interactions (such as 3D open worlds and large-scale PvP games), existing approaches remain inefficient at extracting action-critical signals from redundant sensor streams. To tackle this, we introduce MAIN-VLA, a framework that explicitly Models the Abstraction of Intention and eNvironment to ground decision-making in deep semantic alignment rather than superficial pattern matching. Specifically, our Intention Abstraction (IA) extracts verbose linguistic instructions and their associated reasoning into compact, explicit semantic primitives, while the Environment Semantics Abstraction (ESA) projects overwhelming visual streams into a structured, topological affordance representation. Furthermore, aligning these two abstract modalities induces an emergent attention-concentration effect, enabling a parameter-free token-pruning strategy that filters out perceptual redundancy without degrading performance. Extensive experiments in open-world Minecraft and large-scale PvP environments (Game for Peace and Valorant) demonstrate that MAIN-VLA sets a new state-of-the-art, which achieves superior decision quality, stronger generalization, and cutting-edge inference efficiency.

</details>


### [255] [Causal Forcing: Autoregressive Diffusion Distillation Done Right for High-Quality Real-Time Interactive Video Generation](https://arxiv.org/abs/2602.02214)
*Hongzhou Zhu,Min Zhao,Guande He,Hang Su,Chongxuan Li,Jun Zhu*

Main category: cs.CV

TL;DR: 提出Causal Forcing方法，通过使用自回归教师模型进行ODE初始化，解决双向视频扩散模型蒸馏到自回归模型时的架构差距问题，显著提升实时交互视频生成性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法将预训练的双向视频扩散模型蒸馏为少步自回归模型时存在架构差距，且没有理论上的解决方案。ODE蒸馏需要帧级单射性条件，而双向教师蒸馏到自回归学生违反了这一条件，导致性能下降。

Method: 提出Causal Forcing方法，使用自回归教师模型进行ODE初始化，从而弥合架构差距。该方法确保满足帧级单射性条件，能够恢复教师的流映射。

Result: 在各项指标上均优于所有基线方法，相比SOTA Self Forcing方法，在Dynamic Degree指标上提升19.3%，VisionReward指标上提升8.7%，Instruction Following指标上提升16.7%。

Conclusion: 通过使用自回归教师进行ODE初始化，Causal Forcing有效解决了双向视频扩散模型蒸馏到自回归模型的架构差距问题，显著提升了实时交互视频生成的性能。

Abstract: To achieve real-time interactive video generation, current methods distill pretrained bidirectional video diffusion models into few-step autoregressive (AR) models, facing an architectural gap when full attention is replaced by causal attention. However, existing approaches do not bridge this gap theoretically. They initialize the AR student via ODE distillation, which requires frame-level injectivity, where each noisy frame must map to a unique clean frame under the PF-ODE of an AR teacher. Distilling an AR student from a bidirectional teacher violates this condition, preventing recovery of the teacher's flow map and instead inducing a conditional-expectation solution, which degrades performance. To address this issue, we propose Causal Forcing that uses an AR teacher for ODE initialization, thereby bridging the architectural gap. Empirical results show that our method outperforms all baselines across all metrics, surpassing the SOTA Self Forcing by 19.3\% in Dynamic Degree, 8.7\% in VisionReward, and 16.7\% in Instruction Following. Project page and the code: \href{https://thu-ml.github.io/CausalForcing.github.io/}{https://thu-ml.github.io/CausalForcing.github.io/}

</details>


### [256] [LangMap: A Hierarchical Benchmark for Open-Vocabulary Goal Navigation](https://arxiv.org/abs/2602.02220)
*Bo Miao,Weijia Liu,Jun Luo,Lachlan Shinnick,Jian Liu,Thomas Hamilton-Smith,Yuhe Yang,Zijie Wu,Vanja Videnovic,Feras Dayoub,Anton van den Hengel*

Main category: cs.CV

TL;DR: HieraNav提出多粒度开放词汇目标导航任务，LangMap构建大规模真实3D室内扫描基准，包含四层语义目标和18K+导航任务，为语言驱动具身导航提供严格测试平台。


<details>
  <summary>Details</summary>
Motivation: 物体与语言关系对人与AI的有意义通信和实用具身智能至关重要，需要建立能够理解自然语言指令在多语义层级导航的测试基准。

Method: 提出HieraNav任务框架，包含场景、房间、区域、实例四层语义目标；构建LangMap基准，基于真实3D室内扫描，提供区域标签、区分性区域描述、覆盖414个对象类别的区分性实例描述。

Result: LangMap在区分性准确率上比GOAT-Bench提升23.8%，同时使用4倍少的词汇；评估显示丰富上下文和记忆能提升成功率，但长尾、小型、上下文依赖、远距离目标及多目标完成仍具挑战。

Conclusion: HieraNav和LangMap为推进语言驱动具身导航建立了严格测试平台，揭示了当前模型在复杂语义导航任务中的局限性。

Abstract: The relationships between objects and language are fundamental to meaningful communication between humans and AI, and to practically useful embodied intelligence. We introduce HieraNav, a multi-granularity, open-vocabulary goal navigation task where agents interpret natural language instructions to reach targets at four semantic levels: scene, room, region, and instance. To this end, we present Language as a Map (LangMap), a large-scale benchmark built on real-world 3D indoor scans with comprehensive human-verified annotations and tasks spanning these levels. LangMap provides region labels, discriminative region descriptions, discriminative instance descriptions covering 414 object categories, and over 18K navigation tasks. Each target features both concise and detailed descriptions, enabling evaluation across different instruction styles. LangMap achieves superior annotation quality, outperforming GOAT-Bench by 23.8% in discriminative accuracy using four times fewer words. Comprehensive evaluations of zero-shot and supervised models on LangMap reveal that richer context and memory improve success, while long-tailed, small, context-dependent, and distant goals, as well as multi-goal completion, remain challenging. HieraNav and LangMap establish a rigorous testbed for advancing language-driven embodied navigation. Project: https://bo-miao.github.io/LangMap

</details>


### [257] [MIRROR: Manifold Ideal Reference ReconstructOR for Generalizable AI-Generated Image Detection](https://arxiv.org/abs/2602.02222)
*Ruiqi Liu,Manni Cui,Ziheng Qin,Zhiyuan Yan,Ruoxin Chen,Yi Han,Zhiheng Li,Junkai Chen,ZhiJin Chen,Kaiqing Lin,Jialiang Shen,Lubin Weng,Jing Dong,Yan Wang,Shu Wu*

Main category: cs.CV

TL;DR: MIRROR将AI生成图像检测重新定义为参考比较问题，通过可学习的离散记忆库编码现实先验，生成流形一致的理想参考，利用残差作为检测信号，在多个基准测试中超越现有方法并接近人类感知极限。


<details>
  <summary>Details</summary>
Motivation: 现有AI生成图像检测器依赖基于伪影的分类方法，难以泛化到不断演化的生成痕迹。人类判断则依赖于稳定的现实世界规律，偏离人类认知流形提供了更通用的伪造信号。需要达到"超人交叉点"以替代人类专家。

Method: 提出MIRROR框架，将AIGI检测重新定义为参考比较问题。使用可学习的离散记忆库编码现实先验，通过稀疏线性组合将输入投影到流形一致的理想参考，利用残差作为鲁棒检测信号。

Result: 在14个基准测试中一致超越先前方法：标准基准提升2.1%，野外基准提升8.1%。在Human-AIGI基准上达到89.6%准确率，超越普通用户和视觉专家，随着预训练骨干网络规模扩大进一步接近人类感知极限。

Conclusion: MIRROR通过验证与真实图像流形的一致性而非拟合特定伪造线索，实现了更通用的AI生成图像检测。该方法在多个基准测试中表现出色，接近人类感知极限，为媒体安全提供了有效的解决方案。

Abstract: High-fidelity generative models have narrowed the perceptual gap between synthetic and real images, posing serious threats to media security. Most existing AI-generated image (AIGI) detectors rely on artifact-based classification and struggle to generalize to evolving generative traces. In contrast, human judgment relies on stable real-world regularities, with deviations from the human cognitive manifold serving as a more generalizable signal of forgery. Motivated by this insight, we reformulate AIGI detection as a Reference-Comparison problem that verifies consistency with the real-image manifold rather than fitting specific forgery cues. We propose MIRROR (Manifold Ideal Reference ReconstructOR), a framework that explicitly encodes reality priors using a learnable discrete memory bank. MIRROR projects an input into a manifold-consistent ideal reference via sparse linear combination, and uses the resulting residuals as robust detection signals. To evaluate whether detectors reach the "superhuman crossover" required to replace human experts, we introduce the Human-AIGI benchmark, featuring a psychophysically curated human-imperceptible subset. Across 14 benchmarks, MIRROR consistently outperforms prior methods, achieving gains of 2.1% on six standard benchmarks and 8.1% on seven in-the-wild benchmarks. On Human-AIGI, MIRROR reaches 89.6% accuracy across 27 generators, surpassing both lay users and visual experts, and further approaching the human perceptual limit as pretrained backbones scale. The code is publicly available at: https://github.com/349793927/MIRROR

</details>


### [258] [Evaluating OCR Performance for Assistive Technology: Effects of Walking Speed, Camera Placement, and Camera Type](https://arxiv.org/abs/2602.02223)
*Junchi Feng,Nikhil Ballem,Mahya Beheshti,Giles Hamilton-Fletcher,Todd Hudson,Maurizio Porfiri,William H. Seiple,John-Ross Rizzo*

Main category: cs.CV

TL;DR: 系统评估OCR在静态和动态条件下的性能，包括距离、视角、移动速度和设备位置的影响，比较不同OCR引擎和设备的准确率。


<details>
  <summary>Details</summary>
Motivation: 当前OCR评估多基于静态数据集，未能反映移动使用中的实际挑战，需要系统评估OCR在动态条件下的性能表现。

Method: 静态测试测量1-7米距离和0-75度水平视角下的检测范围；动态测试评估不同行走速度（0.8-1.8 m/s）和三种相机位置（头戴、肩戴、手持）的影响。评估智能手机和智能眼镜，使用四种OCR引擎（Google Vision、PaddleOCR 3.0、EasyOCR、Tesseract），以字符级Levenshtein比率计算准确率。

Result: 识别准确率随行走速度增加和视角变宽而下降；Google Vision整体准确率最高，PaddleOCR是最强的开源替代方案；手机主摄像头准确率最高，肩戴位置在身体位置中平均表现最佳，但肩、头、手之间的差异无统计学显著性。

Conclusion: OCR性能在动态条件下显著下降，移动使用需要考虑速度、视角和设备位置等因素；Google Vision表现最佳，PaddleOCR是可行的开源选择；肩戴式设备在移动场景中具有优势。

Abstract: Optical character recognition (OCR), which converts printed or handwritten text into machine-readable form, is widely used in assistive technology for people with blindness and low vision. Yet, most evaluations rely on static datasets that do not reflect the challenges of mobile use. In this study, we systematically evaluated OCR performance under both static and dynamic conditions. Static tests measured detection range across distances of 1-7 meters and viewing angles of 0-75 degrees horizontally. Dynamic tests examined the impact of motion by varying walking speed from slow (0.8 m/s) to very fast (1.8 m/s) and comparing three camera mounting positions: head-mounted, shoulder-mounted, and hand-held. We evaluated both a smartphone and smart glasses, using the phone's main and ultra-wide cameras. Four OCR engines were benchmarked to assess accuracy at different distances and viewing angles: Google Vision, PaddleOCR 3.0, EasyOCR, and Tesseract. PaddleOCR 3.0 was then used to evaluate accuracy at different walking speeds. Accuracy was computed at the character level using the Levenshtein ratio against manually defined ground truth. Results showed that recognition accuracy declined with increased walking speed and wider viewing angles. Google Vision achieved the highest overall accuracy, with PaddleOCR close behind as the strongest open-source alternative. Across devices, the phone's main camera achieved the highest accuracy, and a shoulder-mounted placement yielded the highest average among body positions; however, differences among shoulder, head, and hand were not statistically significant.

</details>


### [259] [Show, Don't Tell: Morphing Latent Reasoning into Image Generation](https://arxiv.org/abs/2602.02227)
*Harold Haodong Chen,Xinxiang Yin,Wen-Jie Shu,Hongfei Zhang,Zixin Zhang,Chenfei Liao,Litao Guo,Qifeng Chen,Ying-Cong Chen*

Main category: cs.CV

TL;DR: LatentMorph：一种在潜在空间中执行隐式推理的文本到图像生成框架，通过轻量级组件实现高效自适应生成，显著提升性能并减少计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像生成方法缺乏动态推理和精炼能力，而显式推理范式存在效率低下、信息丢失和认知不匹配的问题。需要一种更高效、更自然的推理集成方式。

Method: 提出LatentMorph框架，包含四个轻量级组件：冷凝器（总结中间生成状态为视觉记忆）、翻译器（将潜在思想转换为可操作指导）、塑形器（动态引导下一个图像token预测）和RL训练调用器（自适应决定何时调用推理）。

Result: 在Janus-Pro基础上提升16%（GenEval）和25%（T2I-CompBench）；在WISE和IPV-Txt等抽象推理任务上超越显式范式15%和11%；推理时间减少44%，token消耗减少51%；与人类推理调用直觉的认知对齐度达71%。

Conclusion: LatentMorph通过在连续潜在空间中执行隐式推理，避免了显式推理的瓶颈，实现了更高效、更自适应的文本到图像生成，在性能、效率和认知对齐方面均有显著提升。

Abstract: Text-to-image (T2I) generation has achieved remarkable progress, yet existing methods often lack the ability to dynamically reason and refine during generation--a hallmark of human creativity. Current reasoning-augmented paradigms most rely on explicit thought processes, where intermediate reasoning is decoded into discrete text at fixed steps with frequent image decoding and re-encoding, leading to inefficiencies, information loss, and cognitive mismatches. To bridge this gap, we introduce LatentMorph, a novel framework that seamlessly integrates implicit latent reasoning into the T2I generation process. At its core, LatentMorph introduces four lightweight components: (i) a condenser for summarizing intermediate generation states into compact visual memory, (ii) a translator for converting latent thoughts into actionable guidance, (iii) a shaper for dynamically steering next image token predictions, and (iv) an RL-trained invoker for adaptively determining when to invoke reasoning. By performing reasoning entirely in continuous latent spaces, LatentMorph avoids the bottlenecks of explicit reasoning and enables more adaptive self-refinement. Extensive experiments demonstrate that LatentMorph (I) enhances the base model Janus-Pro by $16\%$ on GenEval and $25\%$ on T2I-CompBench; (II) outperforms explicit paradigms (e.g., TwiG) by $15\%$ and $11\%$ on abstract reasoning tasks like WISE and IPV-Txt, (III) while reducing inference time by $44\%$ and token consumption by $51\%$; and (IV) exhibits $71\%$ cognitive alignment with human intuition on reasoning invocation.

</details>


### [260] [LiFlow: Flow Matching for 3D LiDAR Scene Completion](https://arxiv.org/abs/2602.02232)
*Andrea Matteazzi,Dietmar Tutsch*

Main category: cs.CV

TL;DR: LiFlow：首个用于3D LiDAR场景补全的流匹配框架，通过确保训练和推理初始分布一致性，超越扩散方法，实现最先进性能


<details>
  <summary>Details</summary>
Motivation: 自动驾驶场景中，LiDAR点云常受遮挡和远距离稀疏性影响，限制感知能力。现有基于扩散概率模型的方法存在训练和推理初始分布不匹配的问题

Method: 提出首个3D LiDAR场景补全的流匹配框架，采用最近邻流匹配损失和Chamfer距离损失，增强点云的局部结构和全局覆盖对齐

Result: LiFlow在多个指标上实现了最先进的性能表现

Conclusion: 流匹配框架通过确保训练和推理初始分布一致性，有效改进了3D LiDAR场景补全任务，超越了现有的扩散方法

Abstract: In autonomous driving scenarios, the collected LiDAR point clouds can be challenged by occlusion and long-range sparsity, limiting the perception of autonomous driving systems. Scene completion methods can infer the missing parts of incomplete 3D LiDAR scenes. Recent methods adopt local point-level denoising diffusion probabilistic models, which require predicting Gaussian noise, leading to a mismatch between training and inference initial distributions. This paper introduces the first flow matching framework for 3D LiDAR scene completion, improving upon diffusion-based methods by ensuring consistent initial distributions between training and inference. The model employs a nearest neighbor flow matching loss and a Chamfer distance loss to enhance both local structure and global coverage in the alignment of point clouds. LiFlow achieves state-of-the-art performance across multiple metrics. Code: https://github.com/matteandre/LiFlow.

</details>


### [261] [Enhancing Indoor Occupancy Prediction via Sparse Query-Based Multi-Level Consistent Knowledge Distillation](https://arxiv.org/abs/2602.02318)
*Xiang Li,Yupeng Zheng,Pengfei Li,Yilun Chen,Ya-Qin Zhang,Wenchao Ding*

Main category: cs.CV

TL;DR: DiScene是一个基于稀疏查询的占用预测框架，通过多级知识蒸馏实现高效鲁棒的占用预测，在Occ-Scannet基准上达到23.2 FPS，性能超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前密集方法在空体素上存在计算浪费，而稀疏查询方法在复杂室内场景中缺乏鲁棒性，需要解决效率与准确性的权衡问题。

Method: 提出DiScene框架，包含两个关键创新：1）多级一致知识蒸馏策略，通过编码器级特征对齐、查询级特征匹配、先验级空间引导和锚点级高置信度知识转移四个层次将大教师模型知识迁移到轻量学生模型；2）教师引导初始化策略，使用优化参数预热加速模型收敛。

Result: 在Occ-Scannet基准上，DiScene达到23.2 FPS，比基线方法OPUS提升36.1%，甚至优于深度增强版本OPUS†。集成深度信息后，DiScene†超越EmbodiedOcc 3.7%，推理速度提升1.62倍。在Occ3D-nuScenes基准和真实场景中也表现出良好泛化能力。

Conclusion: DiScene通过多级蒸馏策略有效解决了占用预测中的效率-准确性权衡问题，在各种环境中展现出优越性能和泛化能力，为机器人感知提供了高效鲁棒的几何语义理解方案。

Abstract: Occupancy prediction provides critical geometric and semantic understanding for robotics but faces efficiency-accuracy trade-offs. Current dense methods suffer computational waste on empty voxels, while sparse query-based approaches lack robustness in diverse and complex indoor scenes. In this paper, we propose DiScene, a novel sparse query-based framework that leverages multi-level distillation to achieve efficient and robust occupancy prediction. In particular, our method incorporates two key innovations: (1) a Multi-level Consistent Knowledge Distillation strategy, which transfers hierarchical representations from large teacher models to lightweight students through coordinated alignment across four levels, including encoder-level feature alignment, query-level feature matching, prior-level spatial guidance, and anchor-level high-confidence knowledge transfer and (2) a Teacher-Guided Initialization policy, employing optimized parameter warm-up to accelerate model convergence. Validated on the Occ-Scannet benchmark, DiScene achieves 23.2 FPS without depth priors while outperforming our baseline method, OPUS, by 36.1% and even better than the depth-enhanced version, OPUS†. With depth integration, DiScene† attains new SOTA performance, surpassing EmbodiedOcc by 3.7% with 1.62$\times$ faster inference speed. Furthermore, experiments on the Occ3D-nuScenes benchmark and in-the-wild scenarios demonstrate the versatility of our approach in various environments. Code and models can be accessed at https://github.com/getterupper/DiScene.

</details>


### [262] [VQ-Style: Disentangling Style and Content in Motion with Residual Quantized Representations](https://arxiv.org/abs/2602.02334)
*Fatemeh Zargarbashi,Dhruv Agrawal,Jakob Buhmann,Martin Guay,Stelian Coros,Robert W. Sumner*

Main category: cs.CV

TL;DR: 提出一种基于残差向量量化VAE的方法，通过分层表示和对比学习实现人体运动数据中内容与风格的有效解耦，支持无需微调的实时风格迁移


<details>
  <summary>Details</summary>
Motivation: 人体运动数据同时包含语义内容和细微风格特征，现有方法难以有效解耦这两种信息，限制了风格迁移等应用的效果

Method: 使用残差向量量化变分自编码器学习从粗到细的运动表示，结合对比学习和新颖的信息泄露损失，通过量化代码交换实现无需微调的风格迁移

Result: 该方法在风格迁移、风格移除和运动混合等多种推理应用中表现出强大性能，能够处理未见过的风格而无需额外训练

Conclusion: 提出的分层解耦框架有效分离了运动的内容和风格特征，为人体运动分析提供了灵活且强大的表示学习方案

Abstract: Human motion data is inherently rich and complex, containing both semantic content and subtle stylistic features that are challenging to model. We propose a novel method for effective disentanglement of the style and content in human motion data to facilitate style transfer. Our approach is guided by the insight that content corresponds to coarse motion attributes while style captures the finer, expressive details. To model this hierarchy, we employ Residual Vector Quantized Variational Autoencoders (RVQ-VAEs) to learn a coarse-to-fine representation of motion. We further enhance the disentanglement by integrating contrastive learning and a novel information leakage loss with codebook learning to organize the content and the style across different codebooks. We harness this disentangled representation using our simple and effective inference-time technique Quantized Code Swapping, which enables motion style transfer without requiring any fine-tuning for unseen styles. Our framework demonstrates strong versatility across multiple inference applications, including style transfer, style removal, and motion blending.

</details>


### [263] [LongVPO: From Anchored Cues to Self-Reasoning for Long-Form Video Preference Optimization](https://arxiv.org/abs/2602.02341)
*Zhenpeng Huang,Jiaqi Li,Zihan Jia,Xinhao Li,Desen Meng,Lingxue Song,Xi Chen,Liang Li,Limin Wang*

Main category: cs.CV

TL;DR: LongVPO是一个两阶段直接偏好优化框架，使短上下文视觉语言模型能够无需长视频标注即可理解超长视频，通过合成偏好数据和多段推理任务实现高效的长视频理解。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型主要针对短视频设计，缺乏对超长视频的理解能力，而获取长视频标注数据成本高昂。需要开发一种无需昂贵人工标注就能扩展模型长视频理解能力的方法。

Method: 采用两阶段框架：第一阶段合成偏好三元组，通过锚定问题到短片段、插入干扰项、视觉相似性和问题特异性过滤来减少位置偏差；第二阶段使用递归字幕生成场景级元数据，利用大语言模型创建多段推理查询和不受偏好的响应，通过多段推理任务对齐模型偏好。

Result: 仅使用16K合成示例且无需人工标注，LongVPO在多个长视频基准测试中超越了最先进的开源模型，同时在短视频性能（如MVBench）上保持强大表现。

Conclusion: LongVPO提供了一个可扩展的范式，能够高效实现长视频理解，仅需少量合成数据即可显著提升模型性能，为长视频理解任务提供了实用的解决方案。

Abstract: We present LongVPO, a novel two-stage Direct Preference Optimization framework that enables short-context vision-language models to robustly understand ultra-long videos without any long-video annotations. In Stage 1, we synthesize preference triples by anchoring questions to individual short clips, interleaving them with distractors, and applying visual-similarity and question-specificity filtering to mitigate positional bias and ensure unambiguous supervision. We also approximate the reference model's scoring over long contexts by evaluating only the anchor clip, reducing computational overhead. In Stage 2, we employ a recursive captioning pipeline on long videos to generate scene-level metadata, then use a large language model to craft multi-segment reasoning queries and dispreferred responses, aligning the model's preferences through multi-segment reasoning tasks. With only 16K synthetic examples and no costly human labels, LongVPO outperforms the state-of-the-art open-source models on multiple long-video benchmarks, while maintaining strong short-video performance (e.g., on MVBench), offering a scalable paradigm for efficient long-form video understanding.

</details>


### [264] [Implicit neural representation of textures](https://arxiv.org/abs/2602.02354)
*Albert Kwok,Zheyuan Hu,Dounia Hammou*

Main category: cs.CV

TL;DR: 该论文提出将不同神经网络设计为新的纹理隐式神经表示(INR)，在连续UV坐标空间而非离散空间上操作，在图像质量、内存使用和渲染推理时间之间取得平衡，并探索了实时渲染和下游任务的应用。


<details>
  <summary>Details</summary>
Motivation: 隐式神经表示(INR)已在多个领域证明其准确性和效率，但如何设计适合纹理表示的INR模型，在连续UV坐标空间而非离散空间上操作，并平衡图像质量、内存使用和渲染效率，是需要探索的问题。

Method: 设计不同的神经网络作为新的纹理INR，在连续UV坐标空间上操作，通过实验评估不同模型在图像质量、内存使用和渲染推理时间方面的表现，并分析这些目标之间的平衡关系。

Result: 实验表明这些INR在图像质量方面表现良好，同时具有相当的内存使用效率和渲染推理时间。研究分析了这些目标之间的平衡关系，并探索了在实时渲染和下游任务中的应用，如mipmap拟合和INR空间生成。

Conclusion: 通过设计适合纹理表示的隐式神经表示，可以在连续UV坐标空间上实现高效的纹理表示，在图像质量、内存使用和渲染效率之间取得良好平衡，为实时渲染和下游任务提供了新的可能性。

Abstract: Implicit neural representation (INR) has proven to be accurate and efficient in various domains. In this work, we explore how different neural networks can be designed as a new texture INR, which operates in a continuous manner rather than a discrete one over the input UV coordinate space. Through thorough experiments, we demonstrate that these INRs perform well in terms of image quality, with considerable memory usage and rendering inference time. We analyze the balance between these objectives. In addition, we investigate various related applications in real-time rendering and down-stream tasks, e.g. mipmap fitting and INR-space generation.

</details>


### [265] [NAB: Neural Adaptive Binning for Sparse-View CT reconstruction](https://arxiv.org/abs/2602.02356)
*Wangduo Xie,Matthew B. Blaschko*

Main category: cs.CV

TL;DR: 提出NAB方法，通过自适应分箱机制将矩形先验整合到稀疏视图CT重建中，提升工业对象重建质量


<details>
  <summary>Details</summary>
Motivation: 工业CT中许多物体具有矩形结构，但现有隐式神经网络方法无法有效利用形状先验。为了降低生产成本，需要从稀疏视图实现高质量重建。

Method: 提出神经自适应分箱(NAB)方法：1) 将坐标空间映射到分箱向量空间；2) 使用基于移位双曲正切函数差异的创新分箱机制；3) 扩展支持绕输入平面法向量旋转；4) 通过神经网络处理表示预测CT衰减系数；5) 端到端优化编码参数（位置、大小、陡度、旋转）。

Result: 在两个工业数据集上表现出优越性能，通过调整分箱函数平滑度可泛化到更复杂几何形状，在医学数据集上也保持鲁棒性。

Conclusion: NAB为将形状先验整合到基于神经网络的重建提供了新视角，能有效提升稀疏视图CT重建质量，代码将开源。

Abstract: Computed Tomography (CT) plays a vital role in inspecting the internal structures of industrial objects. Furthermore, achieving high-quality CT reconstruction from sparse views is essential for reducing production costs. While classic implicit neural networks have shown promising results for sparse reconstruction, they are unable to leverage shape priors of objects. Motivated by the observation that numerous industrial objects exhibit rectangular structures, we propose a novel \textbf{N}eural \textbf{A}daptive \textbf{B}inning (\textbf{NAB}) method that effectively integrates rectangular priors into the reconstruction process. Specifically, our approach first maps coordinate space into a binned vector space. This mapping relies on an innovative binning mechanism based on differences between shifted hyperbolic tangent functions, with our extension enabling rotations around the input-plane normal vector. The resulting representations are then processed by a neural network to predict CT attenuation coefficients. This design enables end-to-end optimization of the encoding parameters -- including position, size, steepness, and rotation -- via gradient flow from the projection data, thus enhancing reconstruction accuracy. By adjusting the smoothness of the binning function, NAB can generalize to objects with more complex geometries. This research provides a new perspective on integrating shape priors into neural network-based reconstruction. Extensive experiments demonstrate that NAB achieves superior performance on two industrial datasets. It also maintains robust on medical datasets when the binning function is extended to more general expression. The code will be made available.

</details>


### [266] [Uncertainty-Aware Image Classification In Biomedical Imaging Using Spectral-normalized Neural Gaussian Processes](https://arxiv.org/abs/2602.02370)
*Uma Meleti,Jeffrey J. Nirschl*

Main category: cs.CV

TL;DR: SNGP模型通过谱归一化和高斯过程层改进数字病理学中的不确定性估计和OOD检测，提升模型可信度和临床部署安全性。


<details>
  <summary>Details</summary>
Motivation: 当前数字病理学的深度学习模型在分布外（OOD）场景下往往过度自信且校准不佳，限制了临床信任和采用。医疗影像工作流需要能够准确拒绝OOD输入的内在不确定性感知特性。

Method: 实现谱归一化神经高斯过程（SNGP），通过轻量级修改应用谱归一化，并将最终密集层替换为高斯过程层，以改进单模型不确定性估计和OOD检测。与确定性模型和蒙特卡洛dropout方法进行比较。

Result: 在三个生物医学分类任务（白细胞、淀粉样斑块、结直肠组织病理学）的六个数据集上，SNGP在分布内性能相当的同时，显著改善了不确定性估计和OOD检测能力。

Conclusion: SNGP及相关模型为数字病理学中的不确定性感知分类提供了有用框架，支持安全部署并有助于建立与病理学家的信任。

Abstract: Accurate histopathologic interpretation is key for clinical decision-making; however, current deep learning models for digital pathology are often overconfident and poorly calibrated in out-of-distribution (OOD) settings, which limit trust and clinical adoption. Safety-critical medical imaging workflows benefit from intrinsic uncertainty-aware properties that can accurately reject OOD input. We implement the Spectral-normalized Neural Gaussian Process (SNGP), a set of lightweight modifications that apply spectral normalization and replace the final dense layer with a Gaussian process layer to improve single-model uncertainty estimation and OOD detection. We evaluate SNGP vs. deterministic and MonteCarlo dropout on six datasets across three biomedical classification tasks: white blood cells, amyloid plaques, and colorectal histopathology. SNGP has comparable in-distribution performance while significantly improving uncertainty estimation and OOD detection. Thus, SNGP or related models offer a useful framework for uncertainty-aware classification in digital pathology, supporting safe deployment and building trust with pathologists.

</details>


### [267] [Unified Personalized Reward Model for Vision Generation](https://arxiv.org/abs/2602.02380)
*Yibin Wang,Yuhang Zang,Feng Han,Jiazi Bu,Yujie Zhou,Cheng Jin,Jiaqi Wang*

Main category: cs.CV

TL;DR: 提出UnifiedReward-Flex，一个统一的个性化视觉生成奖励模型，通过上下文自适应推理解决现有奖励模型对内容特定视觉线索不敏感的问题。


<details>
  <summary>Details</summary>
Motivation: 现有多模态奖励模型通常采用一刀切的偏好建模或固定评估标准，对内容特定的视觉线索不敏感，导致与主观、上下文相关的人类偏好系统性错位。

Method: 1) 首先解释语义意图并基于视觉证据进行基础推理；2) 动态构建分层评估，在预定义和自生成的高维标准下实例化细粒度标准；3) 两阶段训练：从先进闭源VLM蒸馏结构化高质量推理轨迹进行SFT，然后对精心策划的偏好对进行DPO优化。

Result: 将UnifiedReward-Flex集成到GRPO框架中进行图像和视频合成，广泛结果证明了其优越性。

Conclusion: UnifiedReward-Flex通过结合奖励建模与灵活、上下文自适应的推理，解决了现有奖励模型的局限性，实现了更好的个性化视觉生成对齐。

Abstract: Recent advancements in multimodal reward models (RMs) have significantly propelled the development of visual generation. Existing frameworks typically adopt Bradley-Terry-style preference modeling or leverage generative VLMs as judges, and subsequently optimize visual generation models via reinforcement learning. However, current RMs suffer from inherent limitations: they often follow a one-size-fits-all paradigm that assumes a monolithic preference distribution or relies on fixed evaluation rubrics. As a result, they are insensitive to content-specific visual cues, leading to systematic misalignment with subjective and context-dependent human preferences. To this end, inspired by human assessment, we propose UnifiedReward-Flex, a unified personalized reward model for vision generation that couples reward modeling with flexible and context-adaptive reasoning. Specifically, given a prompt and the generated visual content, it first interprets the semantic intent and grounds on visual evidence, then dynamically constructs a hierarchical assessment by instantiating fine-grained criteria under both predefined and self-generated high-level dimensions. Our training pipeline follows a two-stage process: (1) we first distill structured, high-quality reasoning traces from advanced closed-source VLMs to bootstrap SFT, equipping the model with flexible and context-adaptive reasoning behaviors; (2) we then perform direct preference optimization (DPO) on carefully curated preference pairs to further strengthen reasoning fidelity and discriminative alignment. To validate the effectiveness, we integrate UnifiedReward-Flex into the GRPO framework for image and video synthesis, and extensive results demonstrate its superiority.

</details>


### [268] [Personalized Image Generation via Human-in-the-loop Bayesian Optimization](https://arxiv.org/abs/2602.02388)
*Rajalaxmi Rajagopalan,Debottam Dutta,Yu-Lin Wei,Romit Roy Choudhury*

Main category: cs.CV

TL;DR: 提出MultiBO方法，通过多轮用户偏好反馈优化个性化图像生成，弥补语言提示的局限性


<details>
  <summary>Details</summary>
Motivation: 当用户有特定图像想法时，仅靠语言提示难以精确生成目标图像，存在"提示差距"。观察到人类即使无法用语言描述，仍能判断哪个图像更接近目标

Method: 开发MultiBO（多选择偏好贝叶斯优化）方法：1）基于初始生成图像生成K个新图像；2）获取用户偏好反馈（哪个更接近目标）；3）利用反馈指导扩散模型；4）生成新的K个图像集；5）在B轮反馈中迭代优化

Result: 30名用户的定性评分和5个基线的定量指标显示，MultiBO能显著缩小与目标图像的差距，在有限反馈轮次内实现更接近用户心中图像的生成

Conclusion: 人类的多选择偏好反馈可有效用于个性化图像生成，弥补语言提示的局限性，为精确图像生成提供新途径

Abstract: Imagine Alice has a specific image $x^\ast$ in her mind, say, the view of the street in which she grew up during her childhood. To generate that exact image, she guides a generative model with multiple rounds of prompting and arrives at an image $x^{p*}$. Although $x^{p*}$ is reasonably close to $x^\ast$, Alice finds it difficult to close that gap using language prompts. This paper aims to narrow this gap by observing that even after language has reached its limits, humans can still tell when a new image $x^+$ is closer to $x^\ast$ than $x^{p*}$. Leveraging this observation, we develop MultiBO (Multi-Choice Preferential Bayesian Optimization) that carefully generates $K$ new images as a function of $x^{p*}$, gets preferential feedback from the user, uses the feedback to guide the diffusion model, and ultimately generates a new set of $K$ images. We show that within $B$ rounds of user feedback, it is possible to arrive much closer to $x^\ast$, even though the generative model has no information about $x^\ast$. Qualitative scores from $30$ users, combined with quantitative metrics compared across $5$ baselines, show promising results, suggesting that multi-choice feedback from humans can be effectively harnessed for personalized image generation.

</details>


### [269] [Infinite-World: Scaling Interactive World Models to 1000-Frame Horizons via Pose-Free Hierarchical Memory](https://arxiv.org/abs/2602.02393)
*Ruiqi Wu,Xuanhua He,Meng Cheng,Tianyu Yang,Yong Zhang,Zhuoliang Kang,Xunliang Cai,Xiaoming Wei,Chunle Guo,Chongyi Li,Ming-Ming Cheng*

Main category: cs.CV

TL;DR: Infinite-World是一个鲁棒的交互式世界模型，能够在复杂真实世界环境中维持超过1000帧的连贯视觉记忆，通过分层无姿态记忆压缩器和不确定性感知动作标注模块解决真实视频训练难题。


<details>
  <summary>Details</summary>
Motivation: 现有世界模型在合成数据上优化良好，但在真实世界视频中面临挑战：姿态估计噪声大、视角重访稀缺，缺乏有效的训练范式。

Method: 1. 分层无姿态记忆压缩器(HPMC)：递归将历史潜在表示蒸馏为固定预算表示，无需显式几何先验；2. 不确定性感知动作标注：将连续运动离散化为三态逻辑，最大化利用原始视频数据；3. 重访密集微调策略：使用30分钟数据集激活长距离闭环能力。

Result: 在客观指标和用户研究中，Infinite-World在视觉质量、动作可控性和空间一致性方面表现优异，能够维持1000+帧的连贯视觉记忆。

Conclusion: Infinite-World通过创新的记忆压缩和动作标注方法，成功解决了真实世界视频训练中的关键挑战，实现了鲁棒的长期视觉记忆和交互能力。

Abstract: We propose Infinite-World, a robust interactive world model capable of maintaining coherent visual memory over 1000+ frames in complex real-world environments. While existing world models can be efficiently optimized on synthetic data with perfect ground-truth, they lack an effective training paradigm for real-world videos due to noisy pose estimations and the scarcity of viewpoint revisits. To bridge this gap, we first introduce a Hierarchical Pose-free Memory Compressor (HPMC) that recursively distills historical latents into a fixed-budget representation. By jointly optimizing the compressor with the generative backbone, HPMC enables the model to autonomously anchor generations in the distant past with bounded computational cost, eliminating the need for explicit geometric priors. Second, we propose an Uncertainty-aware Action Labeling module that discretizes continuous motion into a tri-state logic. This strategy maximizes the utilization of raw video data while shielding the deterministic action space from being corrupted by noisy trajectories, ensuring robust action-response learning. Furthermore, guided by insights from a pilot toy study, we employ a Revisit-Dense Finetuning Strategy using a compact, 30-minute dataset to efficiently activate the model's long-range loop-closure capabilities. Extensive experiments, including objective metrics and user studies, demonstrate that Infinite-World achieves superior performance in visual quality, action controllability, and spatial consistency.

</details>


### [270] [Superman: Unifying Skeleton and Vision for Human Motion Perception and Generation](https://arxiv.org/abs/2602.02401)
*Xinshun Wang,Peiming Li,Ziyi Wang,Zhongbin Fang,Zhichao Deng,Songtao Wu,Jason Li,Mengyuan Liu*

Main category: cs.CV

TL;DR: Superman是一个统一框架，通过视觉引导的运动分词器和统一MLLM架构，将视觉感知与基于骨架的时序运动生成相结合，解决了运动分析领域的分割问题。


<details>
  <summary>Details</summary>
Motivation: 当前运动分析领域存在严重分割：感知模型只能从视频理解运动但仅输出文本，生成模型无法从原始视觉输入感知；生成式MLLM通常局限于使用密集参数化SMPL模型的单帧静态姿态，无法处理时序运动；现有运动词汇仅基于骨架数据构建，与视觉领域脱节。

Method: 提出视觉引导运动分词器，利用3D骨架与视觉数据之间的自然几何对齐，从两种模态进行联合学习，创建统一的跨模态运动词汇。基于此运动语言，训练单个统一的MLLM架构，灵活处理多样化时序输入，统一从视频进行3D骨架姿态估计（感知）与基于骨架的运动预测和插值（生成）。

Result: 在Human3.6M等标准基准测试中，该统一方法在所有运动任务上实现了最先进或具有竞争力的性能，展示了使用骨架进行生成式运动分析的更高效和可扩展路径。

Conclusion: Superman框架成功地将视觉感知与基于骨架的时序运动生成相结合，解决了运动分析领域的分割问题，为生成式运动分析提供了更高效和可扩展的解决方案。

Abstract: Human motion analysis tasks, such as temporal 3D pose estimation, motion prediction, and motion in-betweening, play an essential role in computer vision. However, current paradigms suffer from severe fragmentation. First, the field is split between ``perception'' models that understand motion from video but only output text, and ``generation'' models that cannot perceive from raw visual input. Second, generative MLLMs are often limited to single-frame, static poses using dense, parametric SMPL models, failing to handle temporal motion. Third, existing motion vocabularies are built from skeleton data alone, severing the link to the visual domain. To address these challenges, we introduce Superman, a unified framework that bridges visual perception with temporal, skeleton-based motion generation. Our solution is twofold. First, to overcome the modality disconnect, we propose a Vision-Guided Motion Tokenizer. Leveraging the natural geometric alignment between 3D skeletons and visual data, this module pioneers robust joint learning from both modalities, creating a unified, cross-modal motion vocabulary. Second, grounded in this motion language, a single, unified MLLM architecture is trained to handle all tasks. This module flexibly processes diverse, temporal inputs, unifying 3D skeleton pose estimation from video (perception) with skeleton-based motion prediction and in-betweening (generation). Extensive experiments on standard benchmarks, including Human3.6M, demonstrate that our unified method achieves state-of-the-art or competitive performance across all motion tasks. This showcases a more efficient and scalable path for generative motion analysis using skeletons.

</details>


### [271] [ReasonEdit: Editing Vision-Language Models using Human Reasoning](https://arxiv.org/abs/2602.02408)
*Jiaxing Qiu,Kaihua Hou,Roxana Daneshjou,Ahmed Alaa,Thomas Hartvigsen*

Main category: cs.CV

TL;DR: ReasonEdit是首个支持用户提供推理过程的视觉语言模型编辑器，通过存储人类推理代码本和拓扑平衡多模态嵌入检索，在推理密集型任务上实现最先进的编辑性能


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型编辑器无法处理需要复杂推理的任务，这些任务通常需要人类和模型对图像进行推理。缺乏能够利用人类推理过程的编辑器限制了在推理密集型任务上的编辑效果。

Method: 提出ReasonEdit框架：1）引入新的实用模型编辑设置，允许用户在编辑时提供推理解释；2）持续将人类推理存储在代码本中；3）使用受网络科学启发的拓扑平衡多模态嵌入方法，在推理时仅检索相关事实

Result: 在四个视觉语言模型和多个基于推理的视觉问答数据集上，ReasonEdit实现了最先进的编辑性能。结果表明，在编辑过程中使用人类推理能显著提高编辑的泛化能力

Conclusion: ReasonEdit是首个支持推理过程的视觉语言模型编辑器，通过利用人类推理和创新的嵌入检索方法，在推理密集型任务上取得了突破性的编辑效果，证明了人类推理对编辑泛化的重要性

Abstract: Model editing aims to correct errors in large, pretrained models without altering unrelated behaviors. While some recent works have edited vision-language models (VLMs), no existing editors tackle reasoning-heavy tasks, which typically require humans and models to reason about images.We therefore propose ReasonEdit, the first VLM editor to let users explain their reasoning during editing, introducing a new, practical model editing setup. ReasonEdit continuously stores human reasoning in a codebook, and retrieves only relevant facts during inference using a novel topology-balanced multimodal embedding method inspired by network science. Across four VLMs on multiple rationale-based visual question answering datasets, ReasonEdit achieves state-of-the-art editing performance, ultimately showing that using human reasoning during editing greatly improves edit generalization.

</details>


### [272] [Catalyst: Out-of-Distribution Detection via Elastic Scaling](https://arxiv.org/abs/2602.02409)
*Abid Hassan,Tuan Ngo,Saad Shafiq,Nenad Medvidovic*

Main category: cs.CV

TL;DR: Catalyst是一种后处理OOD检测框架，利用全局平均池化前特征图的原始通道统计信息，通过动态计算缩放因子γ来弹性缩放基线OOD分数，显著提升现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的后处理方法主要依赖输出logits或全局平均池化后的特征向量，忽略了池化前特征图的原始通道统计信息。这些被丢弃的统计信息包含丰富的互补信号，对OOD检测具有潜在价值。

Method: Catalyst框架从池化前特征图的原始统计信息（如均值、标准差、最大激活值）动态计算输入相关的缩放因子γ，然后将γ与现有基线OOD分数进行乘法融合，实现"弹性缩放"，从而增大ID和OOD分布之间的距离。

Result: Catalyst显著提升了OOD检测性能，在CIFAR-10（ResNet-18）上平均误报率降低32.87%，在CIFAR-100（ResNet-18）上降低27.94%，在ImageNet（ResNet-50）上降低22.25%。该框架与logit-based方法（如Energy、ReAct、SCALE）和距离方法（如KNN）都能无缝集成。

Conclusion: 池化前统计信息在OOD检测中具有未开发的潜力，Catalyst框架与现有OOD检测方法互补，通过利用这些被忽略的信号显著提升了检测性能。

Abstract: Out-of-distribution (OOD) detection is critical for the safe deployment of deep neural networks. State-of-the-art post-hoc methods typically derive OOD scores from the output logits or penultimate feature vector obtained via global average pooling (GAP). We contend that this exclusive reliance on the logit or feature vector discards a rich, complementary signal: the raw channel-wise statistics of the pre-pooling feature map lost in GAP. In this paper, we introduce Catalyst, a post-hoc framework that exploits these under-explored signals. Catalyst computes an input-dependent scaling factor ($γ$) on-the-fly from these raw statistics (e.g., mean, standard deviation, and maximum activation). This $γ$ is then fused with the existing baseline score, multiplicatively modulating it -- an ``elastic scaling'' -- to push the ID and OOD distributions further apart. We demonstrate Catalyst is a generalizable framework: it seamlessly integrates with logit-based methods (e.g., Energy, ReAct, SCALE) and also provides a significant boost to distance-based detectors like KNN. As a result, Catalyst achieves substantial and consistent performance gains, reducing the average False Positive Rate by 32.87 on CIFAR-10 (ResNet-18), 27.94% on CIFAR-100 (ResNet-18), and 22.25% on ImageNet (ResNet-50). Our results highlight the untapped potential of pre-pooling statistics and demonstrate that Catalyst is complementary to existing OOD detection approaches.

</details>


### [273] [SelvaMask: Segmenting Trees in Tropical Forests and Beyond](https://arxiv.org/abs/2602.02426)
*Simon-Olivier Duguay,Hugo Baudchon,Etienne Laliberté,Helene Muller-Landau,Gonzalo Rivas-Torres,Arthur Ouaknine*

Main category: cs.CV

TL;DR: 提出SelvaMask热带森林数据集和基于视觉基础模型的检测-分割流水线，显著提升热带森林树冠分割性能


<details>
  <summary>Details</summary>
Motivation: 热带森林树冠对碳储存和生态系统功能至关重要，但现有树冠分割方法在热带森林中性能低下，缺乏高质量数据集

Method: 1) 创建包含8,800多个手动标注树冠的SelvaMask热带数据集；2) 提出模块化检测-分割流水线，使用视觉基础模型和领域特定的检测提示器

Result: 方法在密集热带森林中达到最先进性能，优于零样本通用模型和全监督端到端方法，并在外部热带和温带数据集上验证了泛化能力

Conclusion: SelvaMask既是具有挑战性的基准，也是实现广义森林监测的关键推动者，代码和数据集将公开

Abstract: Tropical forests harbor most of the planet's tree biodiversity and are critical to global ecological balance. Canopy trees in particular play a disproportionate role in carbon storage and functioning of these ecosystems. Studying canopy trees at scale requires accurate delineation of individual tree crowns, typically performed using high-resolution aerial imagery. Despite advances in transformer-based models for individual tree crown segmentation, performance remains low in most forests, especially tropical ones. To this end, we introduce SelvaMask, a new tropical dataset containing over 8,800 manually delineated tree crowns across three Neotropical forest sites in Panama, Brazil, and Ecuador. SelvaMask features comprehensive annotations, including an inter-annotator agreement evaluation, capturing the dense structure of tropical forests and highlighting the difficulty of the task. Leveraging this benchmark, we propose a modular detection-segmentation pipeline that adapts vision foundation models (VFMs), using domain-specific detection-prompter. Our approach reaches state-of-the-art performance, outperforming both zero-shot generalist models and fully supervised end-to-end methods in dense tropical forests. We validate these gains on external tropical and temperate datasets, demonstrating that SelvaMask serves as both a challenging benchmark and a key enabler for generalized forest monitoring. Our code and dataset will be released publicly.

</details>


### [274] [UniReason 1.0: A Unified Reasoning Framework for World Knowledge Aligned Image Generation and Editing](https://arxiv.org/abs/2602.02437)
*Dianyi Wang,Chaofan Ma,Feng Han,Size Wu,Wei Song,Yibin Wang,Zhixiong Zhang,Tianhang Wang,Siyuan Wang,Zhongyu Wei,Jiaqi Wang*

Main category: cs.CV

TL;DR: UniReason是一个统一的多模态推理框架，通过双重推理范式将文本到图像生成和图像编辑整合起来，模拟人类"规划-精修"的认知过程，在推理密集型任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有统一多模态模型在处理需要深度推理的复杂合成任务时存在困难，通常将文本到图像生成和图像编辑视为孤立能力而非相互关联的推理步骤。

Method: 提出UniReason统一框架，采用双重推理范式：1) 将生成视为世界知识增强的规划，注入隐式约束；2) 利用编辑能力进行细粒度视觉精修，通过自我反思纠正视觉错误。构建大规模推理中心数据集(~30万样本)覆盖五个主要知识领域，以及代理生成的视觉自校正语料库。

Result: UniReason在推理密集型基准测试(WISE、KrisBench和UniREditBench)上取得先进性能，同时保持卓越的通用合成能力。

Conclusion: UniReason通过将生成和编辑统一在共享表示中，模拟人类认知过程，有效解决了多模态模型在复杂推理任务上的局限性，为统一多模态推理提供了新范式。

Abstract: Unified multimodal models often struggle with complex synthesis tasks that demand deep reasoning, and typically treat text-to-image generation and image editing as isolated capabilities rather than interconnected reasoning steps. To address this, we propose UniReason, a unified framework that harmonizes these two tasks through a dual reasoning paradigm. We formulate generation as world knowledge-enhanced planning to inject implicit constraints, and leverage editing capabilities for fine-grained visual refinement to further correct visual errors via self-reflection. This approach unifies generation and editing within a shared representation, mirroring the human cognitive process of planning followed by refinement. We support this framework by systematically constructing a large-scale reasoning-centric dataset (~300k samples) covering five major knowledge domains (e.g., cultural commonsense, physics, etc.) for planning, alongside an agent-generated corpus for visual self-correction. Extensive experiments demonstrate that UniReason achieves advanced performance on reasoning-intensive benchmarks such as WISE, KrisBench and UniREditBench, while maintaining superior general synthesis capabilities.

</details>


### [275] [Multi-head automated segmentation by incorporating detection head into the contextual layer neural network](https://arxiv.org/abs/2602.02471)
*Edwin Kys,Febian Febian*

Main category: cs.CV

TL;DR: 提出基于Swin U-Net的门控多头Transformer架构，通过切片级结构检测门控分割预测，有效抑制放疗自动分割中的解剖学不合理假阳性（幻觉）


<details>
  <summary>Details</summary>
Motivation: 深度学习自动分割在放疗中应用广泛，但传统模型常在缺乏目标结构的切片中产生解剖学不合理的假阳性（幻觉），影响临床可靠性

Method: 基于Swin U-Net的门控多头Transformer架构，增强切片间上下文集成和并行检测头，联合执行切片级结构检测（多层感知机）和像素级分割（上下文增强流），检测输出门控分割预测以抑制无效切片中的假阳性，训练使用切片级Tversky损失解决类别不平衡

Result: 在TCGA的Prostate-Anatomical-Edge-Cases数据集上，门控模型显著优于非门控基线，平均Dice损失为0.013±0.036 vs 0.732±0.314，检测概率与解剖存在强相关，有效消除虚假分割；而非门控模型在所有切片中表现出更高变异性和持续假阳性

Conclusion: 检测门控增强了自动分割的鲁棒性和解剖合理性，在不影响有效切片分割质量的情况下减少幻觉预测，为提高临床放疗自动勾画工作流程的可靠性提供了有前景的方法

Abstract: Deep learning based auto segmentation is increasingly used in radiotherapy, but conventional models often produce anatomically implausible false positives, or hallucinations, in slices lacking target structures. We propose a gated multi-head Transformer architecture based on Swin U-Net, augmented with inter-slice context integration and a parallel detection head, which jointly performs slice-level structure detection via a multi-layer perceptron and pixel-level segmentation through a context-enhanced stream. Detection outputs gate the segmentation predictions to suppress false positives in anatomically invalid slices, and training uses slice-wise Tversky loss to address class imbalance. Experiments on the Prostate-Anatomical-Edge-Cases dataset from The Cancer Imaging Archive demonstrate that the gated model substantially outperforms a non-gated segmentation-only baseline, achieving a mean Dice loss of $0.013 \pm 0.036$ versus $0.732 \pm 0.314$, with detection probabilities strongly correlated with anatomical presence, effectively eliminating spurious segmentations. In contrast, the non-gated model exhibited higher variability and persistent false positives across all slices. These results indicate that detection-based gating enhances robustness and anatomical plausibility in automated segmentation applications, reducing hallucinated predictions without compromising segmentation quality in valid slices, and offers a promising approach for improving the reliability of clinical radiotherapy auto-contouring workflows.

</details>


### [276] [PixelGen: Pixel Diffusion Beats Latent Diffusion with Perceptual Loss](https://arxiv.org/abs/2602.02493)
*Zehong Ma,Ruihan Xu,Shiliang Zhang*

Main category: cs.CV

TL;DR: PixelGen是一种简单的像素扩散框架，通过感知监督直接在高维像素空间生成图像，无需VAE或潜在表示，在ImageNet-256上达到FID 5.11，超越了潜在扩散模型。


<details>
  <summary>Details</summary>
Motivation: 现有的像素扩散方法在优化包含大量感知无关信号的高维像素流形时面临挑战，导致性能落后于两阶段的潜在扩散模型。作者希望开发一个更简单但更强大的生成范式，避免VAE引入的伪影和瓶颈。

Method: 提出PixelGen框架，引入两种互补的感知损失来引导扩散模型学习更有意义的感知流形：LPIPS损失促进学习更好的局部模式，基于DINO的感知损失增强全局语义。该方法直接在像素空间进行端到端训练，无需VAE、潜在表示或辅助阶段。

Result: 在ImageNet-256上不使用分类器无关指导，仅用80个训练周期就达到了FID 5.11；在大规模文本到图像生成中，GenEval得分为0.79，展示了良好的扩展性能，超越了强大的潜在扩散基线。

Conclusion: PixelGen通过感知监督简化了生成范式，无需VAE、潜在表示或辅助阶段，提供了一个更简单但更强大的像素扩散框架，在图像生成质量上超越了现有的潜在扩散模型。

Abstract: Pixel diffusion generates images directly in pixel space in an end-to-end manner, avoiding the artifacts and bottlenecks introduced by VAEs in two-stage latent diffusion. However, it is challenging to optimize high-dimensional pixel manifolds that contain many perceptually irrelevant signals, leaving existing pixel diffusion methods lagging behind latent diffusion models. We propose PixelGen, a simple pixel diffusion framework with perceptual supervision. Instead of modeling the full image manifold, PixelGen introduces two complementary perceptual losses to guide diffusion model towards learning a more meaningful perceptual manifold. An LPIPS loss facilitates learning better local patterns, while a DINO-based perceptual loss strengthens global semantics. With perceptual supervision, PixelGen surpasses strong latent diffusion baselines. It achieves an FID of 5.11 on ImageNet-256 without classifier-free guidance using only 80 training epochs, and demonstrates favorable scaling performance on large-scale text-to-image generation with a GenEval score of 0.79. PixelGen requires no VAEs, no latent representations, and no auxiliary stages, providing a simpler yet more powerful generative paradigm. Codes are publicly available at https://github.com/Zehong-Ma/PixelGen.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [277] [PPoGA: Predictive Plan-on-Graph with Action for Knowledge Graph Question Answering](https://arxiv.org/abs/2602.00007)
*MinGyu Jeon,SuWan Cho,JaeYoung Shu*

Main category: cs.CL

TL;DR: PPoGA是一个新颖的知识图谱问答框架，通过规划器-执行器架构和预测处理机制，实现了路径修正和计划修正的自校正能力，在复杂多跳KGQA任务上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM增强的知识图谱问答系统存在认知功能固着问题：当初始高层推理计划有缺陷时，系统无法重新调整策略，导致追求不可行的解决方案。这限制了AI系统的鲁棒性和灵活性。

Method: 提出PPoGA框架，采用规划器-执行器架构分离高层策略与低层执行，引入预测处理机制预测结果。核心创新是自校正机制，支持路径修正（局部执行错误）和计划修正（识别、丢弃并重新制定整个计划）。

Result: 在三个具有挑战性的多跳KGQA基准测试（GrailQA、CWQ、WebQSP）上进行广泛实验，PPoGA实现了最先进的性能，显著优于现有方法。

Conclusion: 研究表明，问题重构等元认知能力对于构建更鲁棒和灵活的AI推理系统至关重要。PPoGA通过自校正机制有效解决了认知功能固着问题。

Abstract: Large Language Models (LLMs) augmented with Knowledge Graphs (KGs) have advanced complex question answering, yet they often remain susceptible to failure when their initial high-level reasoning plan is flawed. This limitation, analogous to cognitive functional fixedness, prevents agents from restructuring their approach, leading them to pursue unworkable solutions. To address this, we propose PPoGA (Predictive Plan-on-Graph with Action), a novel KGQA framework inspired by human cognitive control and problem-solving. PPoGA incorporates a Planner-Executor architecture to separate high-level strategy from low-level execution and leverages a Predictive Processing mechanism to anticipate outcomes. The core innovation of our work is a self-correction mechanism that empowers the agent to perform not only Path Correction for local execution errors but also Plan Correction by identifying, discarding, and reformulating the entire plan when it proves ineffective. We conduct extensive experiments on three challenging multi-hop KGQA benchmarks: GrailQA, CWQ, and WebQSP. The results demonstrate that PPoGA achieves state-of-the-art performance, significantly outperforming existing methods. Our work highlights the critical importance of metacognitive abilities like problem restructuring for building more robust and flexible AI reasoning systems.

</details>


### [278] [Unlocking Electronic Health Records: A Hybrid Graph RAG Approach to Safe Clinical AI for Patient QA](https://arxiv.org/abs/2602.00009)
*Samuel Thio,Matthew Lewis,Spiros Denaxas,Richard JB Dobson*

Main category: cs.CL

TL;DR: MediGRAF是一个混合图检索增强框架，通过结合结构化关系遍历和非结构化语义搜索，实现医疗记录的自然语言查询，显著提升临床信息检索的准确性和安全性。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录系统包含大量临床信息，给医生带来认知负担，关键细节容易被忽略。现有LLM在临床环境中存在上下文基础和幻觉问题，而当前检索方法通常只关注结构化数据或非结构化语义搜索，未能同时整合两者。

Method: 提出MediGRAF混合图RAG系统，独特地结合Neo4j Text2Cypher进行结构化关系遍历和向量嵌入进行非结构化叙述检索，实现对患者完整旅程的自然语言查询。使用MIMIC-IV数据集的10名患者数据（生成5,973个节点和5,963个关系）。

Result: 事实查询达到100%召回率（所有相关信息都被检索并输出），复杂推理任务平均专家质量得分为4.25/5（满分5分），且零安全违规。表明混合图基础显著推进临床信息检索。

Conclusion: 混合图基础方法为标准的LLM部署提供了更安全、更全面的替代方案，能够有效解决临床信息检索中的关键挑战。

Abstract: Electronic health record (EHR) systems present clinicians with vast repositories of clinical information, creating a significant cognitive burden where critical details are easily overlooked. While Large Language Models (LLMs) offer transformative potential for data processing, they face significant limitations in clinical settings, particularly regarding context grounding and hallucinations. Current solutions typically isolate retrieval methods focusing either on structured data (SQL/Cypher) or unstructured semantic search but fail to integrate both simultaneously. This work presents MediGRAF (Medical Graph Retrieval Augmented Framework), a novel hybrid Graph RAG system that bridges this gap. By uniquely combining Neo4j Text2Cypher capabilities for structured relationship traversal with vector embeddings for unstructured narrative retrieval, MediGRAF enables natural language querying of the complete patient journey. Using 10 patients from the MIMIC-IV dataset (generating 5,973 nodes and 5,963 relationships), we generated enough nodes and data for patient level question answering (QA), and we evaluated this architecture across varying query complexities. The system demonstrated 100\% recall for factual queries which means all relevant information was retrieved and in the output, while complex inference tasks achieved a mean expert quality score of 4.25/5 with zero safety violations. These results demonstrate that hybrid graph-grounding significantly advances clinical information retrieval, offering a safer, more comprehensive alternative to standard LLM deployments.

</details>


### [279] [G-MemLLM: Gated Latent Memory Augmentation for Long-Context Reasoning in Large Language Models](https://arxiv.org/abs/2602.00015)
*Xun Xu*

Main category: cs.CL

TL;DR: G-MemLLM：一种基于门控更新的记忆增强架构，通过潜在记忆库解决LLMs上下文窗口有限和多跳推理中信息稀释的问题，显著提升多跳推理和关系抽取性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在自然语言理解方面表现出色，但受限于有限的上下文窗口容量，在多跳推理中难以保持长期事实一致性。现有方法使用上下文压缩或循环标记，但存在"上下文腐化"或信息稀释问题。

Method: 提出G-MemLLM记忆增强架构，将冻结的LLM主干与可训练的潜在记忆库结合。核心创新是GRU风格的门控更新逻辑，允许模型选择性地更新、保留或覆盖潜在记忆槽，防止循环系统中常见的知识梯度消失。

Result: 在GPT-2(124M)到Llama 3.1(8B)不同规模模型上评估，在HotpotQA和ZsRE基准测试中表现优异：Llama 3.1-8B在ZsRE上准确率提升13.3%；GPT-2在HotpotQA上答案F1提升8.56分；Llama 3.1-8B在HotpotQA上支持事实F1提升6.89分。

Conclusion: G-MemLLM通过门控记忆更新机制有效解决了LLMs在多跳推理中的信息保持问题，显著提升了不同规模模型的长序列推理能力，为增强LLMs的长期记忆和事实一致性提供了有效解决方案。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in natural language understanding, yet they remain constrained by the finite capacity of their context windows and the inherent difficulty of maintaining long-term factual consistency during multi-hop reasoning. While existing methods utilize context compression or recurrent tokens, they often suffer from ``context rot'' or the dilution of information over long horizons. In this paper, we propose \textbf{G-MemLLM}, a memory-augmented architecture that integrates a frozen LLM backbone with a trainable \textbf{Latent Memory Bank}. Our key innovation is a GRU-style gated update logic that allows the model to selectively update, preserve, or overwrite latent memory slots, preventing the vanishing gradients of knowledge common in recurrent systems. We evaluate G-MemLLM across scales, from GPT-2 (124M) to Llama 3.1 (8B), on the HotpotQA and Zero-Shot Relation Extraction (ZsRE) benchmarks. Our results demonstrate that G-MemLLM significantly enhances multi-hop reasoning and relational precision, achieving a 13.3\% accuracy boost on ZsRE for Llama 3.1-8B, and it also yields improvements across model scales, boosting Answer F1 by 8.56 points for GPT-2 and increasing Supporting Fact F1 by 6.89 points for Llama 3.1-8B on HotpotQA.

</details>


### [280] [PTCBENCH: Benchmarking Contextual Stability of Personality Traits in LLM Systems](https://arxiv.org/abs/2602.00016)
*Jiongchi Yu,Yuhan Ma,Xiaoyu Zhang,Junjie Wang,Qiang Hu,Chao Shen,Xiaofei Xie*

Main category: cs.CL

TL;DR: PTCBENCH是一个评估大语言模型人格一致性的基准测试，通过12种不同情境测试发现外部场景（如失业）会显著改变LLM的人格特质和推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究忽略了人格特质是动态和情境依赖的心理学共识，而随着LLM在情感代理和AI系统中的部署增加，保持一致和真实的人格对用户信任和参与至关重要。

Method: 引入PTCBENCH基准，在12种不同的外部情境（位置背景和生活事件）下测试模型，使用NEO五因素人格量表严格评估人格，共分析了39,240个人格特质记录。

Result: 研究发现某些外部场景（如"失业"）会触发LLM显著的人格变化，甚至改变其推理能力，揭示了LLM人格的不一致性。

Conclusion: PTCBENCH为评估现实演化环境中的人格一致性建立了可扩展框架，为开发稳健且心理对齐的AI系统提供了可操作的见解。

Abstract: With the increasing deployment of large language models (LLMs) in affective agents and AI systems, maintaining a consistent and authentic LLM personality becomes critical for user trust and engagement. However, existing work overlooks a fundamental psychological consensus that personality traits are dynamic and context-dependent. To bridge this gap, we introduce PTCBENCH, a systematic benchmark designed to quantify the consistency of LLM personalities under controlled situational contexts. PTCBENCH subjects models to 12 distinct external conditions spanning diverse location contexts and life events, and rigorously assesses the personality using the NEO Five-Factor Inventory. Our study on 39,240 personality trait records reveals that certain external scenarios (e.g., "Unemployment") can trigger significant personality changes of LLMs, and even alter their reasoning capabilities. Overall, PTCBENCH establishes an extensible framework for evaluating personality consistency in realistic, evolving environments, offering actionable insights for developing robust and psychologically aligned AI systems.

</details>


### [281] [SafeTalkCoach: Diversity-Driven Multi-Agent Simulation for Parent-Teen Health Conversations](https://arxiv.org/abs/2602.00017)
*Benyamin Tabarsi,Wenbo Li,Tahreem Yasir,Aryan Santhosh Kumar,Laura Widman,Dongkuan Xu,Tiffany Barnes*

Main category: cs.CL

TL;DR: SafeTalkCoach是一个多智能体对话生成框架，用于模拟父母与子女关于性健康的对话，并附带数据集，旨在解决现实数据稀缺和LLM对话缺乏真实性与多样性的问题。


<details>
  <summary>Details</summary>
Motivation: 父母与子女关于性健康的有效沟通很重要，但现实数据稀缺且难以收集，因为对话具有私密性和敏感性。虽然LLM已广泛用于对话生成，但它们可能偏离最佳实践，且经常缺乏真实性和多样性。

Method: SafeTalkCoach是一个多样性驱动的多智能体对话生成框架，整合了众包和合成场景、既定性健康指南、基于证据的人物设定、自适应控制模块和层次化多样化方法。

Result: 评估表明，SafeTalkCoach能够生成多样化的对话，同时在实践中保持真实性、沟通质量和可控性。

Conclusion: SafeTalkCoach框架和数据集旨在支持AI研究和健康沟通实践，为解决性健康教育中的对话生成问题提供工具。

Abstract: The importance of effective parent-child communication about sexual health is widely acknowledged, but real-world data on these conversations is scarce and challenging to collect, due to their private and sensitive nature. Although LLMs have been widely adopted in dialogue generation, they may deviate from best practices and frequently lack realism and diversity. We introduce SafeTalkCoach, a diversity-driven multi-agent dialogue generation framework that simulates parent-child conversations about sexual health, and present an accompanying dataset. SafeTalkCoach integrates crowd-sourced and synthesized scenarios, established sexual health guidelines, evidence-based personas, adaptive control modules, and hierarchical diversification. Through evaluations, we demonstrate that SafeTalkCoach generates diverse conversations while maintaining realism, communication quality, and controllability in practice. Our goal is that the SafeTalkCoach framework and the dataset support both AI research and health communications practices.

</details>


### [282] [Construct, Align, and Reason: Large Ontology Models for Enterprise Knowledge Management](https://arxiv.org/abs/2602.00029)
*Yao Zhang,Hongyin Zhu*

Main category: cs.CL

TL;DR: 提出大型本体模型(LOM)，通过构建-对齐-推理框架解决企业知识管理中多源异构数据整合和语义推理问题，在复杂图推理任务上表现优于DeepSeek-V3.2


<details>
  <summary>Details</summary>
Motivation: 企业级知识管理面临多源异构数据整合和有效语义推理的挑战。传统知识图谱在隐式关系发现和复杂问答的语义理解方面存在不足。

Method: 提出统一构建-对齐-推理框架的大型本体模型(LOM)：1)从结构化数据库和非结构化文本构建双层企业本体并融合；2)三阶段训练流程：本体指令微调、文本-本体对齐、多任务指令调优；3)构建全面的训练和评估数据集。

Result: 在构建的基准测试中，4B参数的LOM达到89.47%准确率，在复杂图推理任务上表现优于DeepSeek-V3.2，表明本体结构和语言的有效融合。

Conclusion: LOM框架成功解决了企业知识管理中的数据整合和语义推理问题，通过本体与语言的深度融合实现了有效的知识表示和推理能力。

Abstract: Enterprise-scale knowledge management faces significant challenges in integrating multi-source heterogeneous data and enabling effective semantic reasoning. Traditional knowledge graphs often struggle with implicit relationship discovery and lack sufficient semantic understanding for complex question answering. To address these limitations, we introduce a unified construct--align--reason framework, the large ontology model (LOM). We first build a dual-layer enterprise ontology from structured databases and unstructured text, subsequently fusing these sources into a comprehensive enterprise ontology. To enable instruction-aligned reasoning, we propose a unified three-stage training pipeline: ontology instruction fine-tuning to improve structural understanding; text-ontology grounding to strengthen node semantic encoding; and multi-task instruction tuning on ontology-language pairs with curriculum learning to enhance semantic reasoning and generation. We also construct comprehensive training and evaluation datasets covering diverse ontology reasoning tasks. On this benchmark, our 4B-parameter LOM achieves 89.47% accuracy and outperforms DeepSeek-V3.2 on complex graph reasoning, indicating effective fusion of ontology structure and language.

</details>


### [283] [Reversible Diffusion Decoding for Diffusion Language Models](https://arxiv.org/abs/2602.00150)
*Xinyun Wang,Min Zhang,Sen Cui,Zhikang Chen,Bo Jiang,Kun Kuang,Mingbao Lin*

Main category: cs.CL

TL;DR: 提出可逆扩散解码（RDD）框架，通过可逆机制解决扩散语言模型块解码中的停滞问题，允许回溯并重初始化不确定token，提升生成鲁棒性


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型的并行块解码虽然高效，但不可逆的承诺会导致停滞问题——当遇到次优上下文时，反向扩散过程无法继续进展

Method: RDD框架引入可逆性：1) 检测停滞作为反向过程的依赖状态失败；2) 通过缓存模型状态实现高效回溯到早期块；3) 应用置信度引导的重掩码，选择性重初始化不确定token同时保留可靠上下文

Result: 实验表明RDD在最小计算开销下，相比基线方法显著提升了生成鲁棒性和质量

Conclusion: 可逆扩散解码框架既保持了扩散生成的高效并行性，又能从早期承诺错误中恢复，解决了扩散语言模型解码的关键瓶颈

Abstract: Diffusion language models enable parallel token generation through block-wise decoding, but their irreversible commitments can lead to stagnation, where the reverse diffusion process fails to make further progress under a suboptimal context.We propose Reversible Diffusion Decoding (RDD), a decoding framework that introduces reversibility into block-wise diffusion generation. RDD detects stagnation as a state-dependent failure of the reverse process and enables efficient backtracking to earlier blocks without recomputation via cached model states. To avoid repeated failure trajectories, RDD applies confidence-guided re-masking to selectively reinitialize uncertain tokens while preserving reliable context.This reversible formulation allows decoding to recover from early commitment errors while maintaining the parallel efficiency of diffusion-based generation. Experiments show that RDD improves generation robustness and quality over baselines with minimal computational overhead.

</details>


### [284] [DIVERGE: Diversity-Enhanced RAG for Open-Ended Information Seeking](https://arxiv.org/abs/2602.00238)
*Tianyi Hu,Niket Tandon,Akhil Arora*

Main category: cs.CL

TL;DR: DIVERGE是一个用于开放性问题检索增强生成的插件式代理框架，通过反思引导生成和记忆增强迭代优化，在保持答案质量的同时促进观点多样性。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统假设每个查询只有一个正确答案，忽略了常见信息寻求场景中可能存在多个合理答案的情况。标准RAG系统未能充分利用检索到的上下文多样性，即使增加检索多样性也无法产生多样化的生成结果，这限制了创造力并损害了公平包容的信息获取。

Method: 提出DIVERGE框架，包含反思引导生成和记忆增强迭代优化机制。该框架是插件式的代理RAG系统，通过新颖的反思机制引导生成过程，利用记忆增强进行迭代优化，在保持答案质量的同时促进观点多样性。

Result: 在真实世界的Infinity-Chat数据集上，DIVERGE相比竞争基线和先前最先进方法实现了最佳多样性-质量权衡，显著提高了多样性同时保持了质量。新提出的多样性-质量权衡评估指标与人类判断有良好相关性。

Conclusion: 当前基于LLM的系统在开放信息寻求场景中存在系统性限制，而显式建模多样性可以缓解这一问题。DIVERGE框架通过反思引导生成和记忆增强迭代优化，有效解决了RAG系统在多样化答案生成方面的局限性。

Abstract: Existing retrieval-augmented generation (RAG) systems are primarily designed under the assumption that each query has a single correct answer. This overlooks common information-seeking scenarios with multiple plausible answers, where diversity is essential to avoid collapsing to a single dominant response, thereby constraining creativity and compromising fair and inclusive information access. Our analysis reveals a commonly overlooked limitation of standard RAG systems: they underutilize retrieved context diversity, such that increasing retrieval diversity alone does not yield diverse generations. To address this limitation, we propose DIVERGE, a plug-and-play agentic RAG framework with novel reflection-guided generation and memory-augmented iterative refinement, which promotes diverse viewpoints while preserving answer quality. We introduce novel metrics tailored to evaluating the diversity-quality trade-off in open-ended questions, and show that they correlate well with human judgments. We demonstrate that DIVERGE achieves the best diversity-quality trade-off compared to competitive baselines and previous state-of-the-art methods on the real-world Infinity-Chat dataset, substantially improving diversity while maintaining quality. More broadly, our results reveal a systematic limitation of current LLM-based systems for open-ended information-seeking and show that explicitly modeling diversity can mitigate it. Our code is available at: https://github.com/au-clan/Diverge

</details>


### [285] [Benchmarking Uncertainty Calibration in Large Language Model Long-Form Question Answering](https://arxiv.org/abs/2602.00279)
*Philip Müller,Nicholas Popovič,Michael Färber,Peter Steinbach*

Main category: cs.CL

TL;DR: 首个大规模基准测试评估LLM在科学QA中的不确定性量化方法，发现指令微调导致概率极化，口头化方法存在系统性偏差，答案频率是最可靠的校准方法。


<details>
  <summary>Details</summary>
Motivation: 现有不确定性量化方法在科学问答领域验证不足，而科学QA依赖事实检索和推理能力，需要可靠的不确定性量化来建立对生成答案的信任。

Method: 构建首个大规模基准测试框架，评估20个LLM在7个科学QA数据集上的不确定性量化方法校准性能，涵盖685,000个长格式回答，分析token级和序列级的不确定性估计。

Result: 指令微调导致token级置信度可靠性降低；口头化方法存在系统性偏差且与正确性相关性差；答案频率（跨样本一致性）提供最可靠的校准；仅依赖ECE作为评估指标会产生误导。

Conclusion: 当前LLM不确定性量化方法存在严重局限性，标准基准测试实践需要改进，答案频率是最有前景的校准方法，需要更全面的评估框架。

Abstract: Large Language Models (LLMs) are commonly used in Question Answering (QA) settings, increasingly in the natural sciences if not science at large. Reliable Uncertainty Quantification (UQ) is critical for the trustworthy uptake of generated answers. Existing UQ approaches remain weakly validated in scientific QA, a domain relying on fact-retrieval and reasoning capabilities. We introduce the first large-scale benchmark for evaluating UQ metrics in reasoning-demanding QA studying calibration of UQ methods, providing an extensible open-source framework to reproducibly assess calibration. Our study spans up to 20 large language models of base, instruction-tuned and reasoning variants. Our analysis covers seven scientific QA datasets, including both multiple-choice and arithmetic question answering tasks, using prompting to emulate an open question answering setting. We evaluate and compare methods representative of prominent approaches on a total of 685,000 long-form responses, spanning different reasoning complexities representative of domain-specific tasks. At the token level, we find that instruction tuning induces strong probability mass polarization, reducing the reliability of token-level confidences as estimates of uncertainty. Models further fine-tuned for reasoning are exposed to the same effect, but the reasoning process appears to mitigate it depending on the provider. At the sequence level, we show that verbalized approaches are systematically biased and poorly correlated with correctness, while answer frequency (consistency across samples) yields the most reliable calibration. In the wake of our analysis, we study and report the misleading effect of relying exclusively on ECE as a sole measure for judging performance of UQ methods on benchmark datasets. Our findings expose critical limitations of current UQ methods for LLMs and standard practices in benchmarking thereof.

</details>


### [286] [Faithful-Patchscopes: Understanding and Mitigating Model Bias in Hidden Representations Explanation of Large Language Models](https://arxiv.org/abs/2602.00300)
*Xilin Gong,Shu Yang,Zehua Cao,Lynne Billard,Di Wang*

Main category: cs.CL

TL;DR: 本文发现Patchscopes框架中LLMs倾向于依赖固有语言模式而非隐藏表示中的上下文信息，导致解释不忠实，并提出BALOR方法通过logit重校准来抑制模型偏见、增强上下文信息。


<details>
  <summary>Details</summary>
Motivation: Patchscopes框架使用LLMs从隐藏表示生成人类可读解释，但研究发现LLMs倾向于依赖固有语言模式，这会覆盖隐藏表示中的上下文信息，导致解释不忠实。例如，即使隐藏表示编码了"紫色"的上下文属性，LLMs仍会生成"绿色"这种固有联想。这种系统性不忠实问题需要解决。

Method: 首先设计数据集评估Patchscopes在偏见情况下的忠实性。然后提出Bias Alignment through Logit Recalibration (BALOR)方法：将未修补提示的输出logits视为捕获模型偏见，与修补上下文信息下的logits进行对比，通过这种对比重校准logit分布，从而抑制模型偏见、在生成过程中放大上下文信息。

Result: 评估显示Patchscopes在偏见情况下平均忠实性下降18.84%。BALOR在多个LLMs上的实验表明，该方法始终优于现有基线，实现了高达33%的相对性能提升。

Conclusion: LLMs在Patchscopes框架中存在系统性不忠实问题，倾向于依赖固有语言模式而非隐藏表示中的上下文信息。提出的BALOR方法通过logit重校准有效抑制模型偏见、增强上下文信息，显著提高了解释的忠实性。

Abstract: Large Language Models (LLMs) have demonstrated strong capabilities for hidden representation interpretation through Patchscopes, a framework that uses LLMs themselves to generate human-readable explanations by decoding from internal hidden representations. However, our work shows that LLMs tend to rely on inherent linguistic patterns, which can override contextual information encoded in the hidden representations during decoding. For example, even when a hidden representation encodes the contextual attribute "purple" for "broccoli", LLMs still generate "green" in their explanations, reflecting a strong prior association. This behavior reveals a systematic unfaithfulness in Patchscopes. To systematically study this issue, we first designed a dataset to evaluate the faithfulness of Patchscopes under biased cases, and our results show that there is an 18.84\% faithfulness decrease on average. We then propose Bias Alignment through Logit Recalibration (BALOR), which treats the output logits from an unpatched prompt as capturing model bias and contrasts them with logits obtained under patched contextual information. By recalibrating the logit distribution through this contrast, BALOR suppresses model bias and amplifies contextual information during generation. Experiments across multiple LLMs demonstrate that BALOR consistently outperforms existing baselines, achieving up to 33\% relative performance improvement.

</details>


### [287] [MiNER: A Two-Stage Pipeline for Metadata Extraction from Municipal Meeting Minutes](https://arxiv.org/abs/2602.00316)
*Rodrigo Batista,Luís Filipe Cunha,Purificação Silvano,Nuno Guimarães,Alípio Jorge,Evelin Amorim,Ricardo Campos*

Main category: cs.CL

TL;DR: 提出兩階段管線從市政會議記錄提取元數據，先定位開頭結尾段落，再用Transformer模型提取細粒度實體，性能優於大型通用LLM但跨市泛化能力有限。


<details>
  <summary>Details</summary>
Motivation: 市政會議記錄格式異質且缺乏標準化，現有NER模型不適用於此領域特定類別，需要專門方法來提取會議編號、日期、地點、參與者等元數據。

Method: 兩階段管線：1) QA模型識別包含元數據的開頭和結尾文本段；2) 使用BERTimbau和XLM-RoBERTa（有/無CRF層）進行細粒度實體提取，並通過去詞匯化增強。

Result: 在領域內表現優於大型通用LLM（包括開源Phi和閉源Gemini），但在跨市評估中泛化能力下降，反映了市政記錄的變異性和語言複雜性。

Conclusion: 建立了市政會議記錄元數據提取的首個基準，為該領域未來研究提供堅實基礎，但需要進一步改進跨市泛化能力。

Abstract: Municipal meeting minutes are official documents of local governance, exhibiting heterogeneous formats and writing styles. Effective information retrieval (IR) requires identifying metadata such as meeting number, date, location, participants, and start/end times, elements that are rarely standardized or easy to extract automatically. Existing named entity recognition (NER) models are ill-suited to this task, as they are not adapted to such domain-specific categories. In this paper, we propose a two-stage pipeline for metadata extraction from municipal minutes. First, a question answering (QA) model identifies the opening and closing text segments containing metadata. Transformer-based models (BERTimbau and XLM-RoBERTa with and without a CRF layer) are then applied for fine-grained entity extraction and enhanced through deslexicalization. To evaluate our proposed pipeline, we benchmark both open-weight (Phi) and closed-weight (Gemini) LLMs, assessing predictive performance, inference cost, and carbon footprint. Our results demonstrate strong in-domain performance, better than larger general-purpose LLMs. However, cross-municipality evaluation reveals reduced generalization reflecting the variability and linguistic complexity of municipal records. This work establishes the first benchmark for metadata extraction from municipal meeting minutes, providing a solid foundation for future research in this domain.

</details>


### [288] [Detecting AI-Generated Content in Academic Peer Reviews](https://arxiv.org/abs/2602.00319)
*Siyuan Shen,Kai Wang*

Main category: cs.CL

TL;DR: 研究发现AI生成内容在学术同行评审中快速增长，2025年ICLR约20%、Nature Communications约12%的评审被检测为AI生成


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLMs）的普及，需要了解AI在学术同行评审中的使用情况及其影响

Method: 使用基于历史评审数据训练检测模型，应用于ICLR和Nature Communications后续评审周期，分析AI生成内容的时间趋势

Result: 2022年前AI生成内容极少，之后显著增长；2025年ICLR约20%、Nature Communications约12%评审被分类为AI生成；Nature Communications在2024年第三至第四季度增长最明显

Conclusion: AI辅助内容在同行评审中快速增加，需要进一步研究其对学术评价的影响

Abstract: The growing availability of large language models (LLMs) has raised questions about their role in academic peer review. This study examines the temporal emergence of AI-generated content in peer reviews by applying a detection model trained on historical reviews to later review cycles at International Conference on Learning Representations (ICLR) and Nature Communications (NC). We observe minimal detection of AI-generated content before 2022, followed by a substantial increase through 2025, with approximately 20% of ICLR reviews and 12% of Nature Communications reviews classified as AI-generated in 2025. The most pronounced growth of AI-generated reviews in NC occurs between the third and fourth quarter of 2024. Together, these findings provide suggestive evidence of a rapidly increasing presence of AI-assisted content in peer review and highlight the need for further study of its implications for scholarly evaluation.

</details>


### [289] [DETOUR: An Interactive Benchmark for Dual-Agent Search and Reasoning](https://arxiv.org/abs/2602.00352)
*Li Siyan,Darshan Deshpande,Anand Kannappan,Rebecca Qian*

Main category: cs.CL

TL;DR: DETOUR是一个双代理评估基准，用于模拟"话到嘴边"的搜索过程，包含1011个提示，测试模型在模糊、未明确指定场景下的多模态检索能力。


<details>
  <summary>Details</summary>
Motivation: 现有评估代理在"话到嘴边"搜索过程能力的基准仅限于单轮设置，无法真实模拟人们在对话中通过多轮交互回忆信息的过程。

Method: 引入DETOUR双代理评估基准，包含一个被评估的主要代理（Primary Agent）和一个保持一致的记忆代理（Memory Agent）。主要代理通过查询记忆代理来识别回忆的实体，模拟真实对话中的多轮搜索过程。

Result: 当前最先进的模型在该基准上表现仍然困难，在所有模态（文本、图像、音频和视频）上仅达到36%的准确率，表明模型在未明确指定场景下的能力有待提升。

Conclusion: DETOUR基准更真实地模拟了"话到嘴边"的搜索过程，揭示了当前模型在模糊、未明确指定多模态检索场景中的局限性，强调了增强这些能力的重要性。

Abstract: When recalling information in conversation, people often arrive at the recollection after multiple turns. However, existing benchmarks for evaluating agent capabilities in such tip-of-the-tongue search processes are restricted to single-turn settings. To more realistically simulate tip-of-the-tongue search, we introduce Dual-agent based Evaluation Through Obscure Under-specified Retrieval (DETOUR), a dual-agent evaluation benchmark containing 1,011 prompts. The benchmark design involves a Primary Agent, which is the subject of evaluation, tasked with identifying the recollected entity through querying a Memory Agent that is held consistent across evaluations. Our results indicate that current state-of-the-art models still struggle with our benchmark, only achieving 36% accuracy when evaluated on all modalities (text, image, audio, and video), highlighting the importance of enhancing capabilities in underspecified scenarios.

</details>


### [290] [DecompressionLM: Deterministic, Diagnostic, and Zero-Shot Concept Graph Extraction from Language Models](https://arxiv.org/abs/2602.00377)
*Zhaochen Hong,Jiaxuan You*

Main category: cs.CL

TL;DR: DecompressionLM是一个无状态的零样本概念图提取框架，无需预定义查询即可发现语言模型编码的知识，解决了现有知识探测方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有知识探测方法依赖预定义查询，只能提取已知概念，限制了知识发现的广度。作者希望开发一种无需预定义查询或跨序列共享状态的方法，来发现语言模型实际编码的知识。

Method: 使用Van der Corput低差异序列与算术解码，实现确定性、可并行生成的无状态框架。该方法避免了传统解码方法的三个限制：跨序列耦合、竞争解码效应和可扩展性约束。

Result: 在不同模型家族和量化变体中发现：激活感知量化(AWQ-4bit)将概念覆盖范围扩大30-170%，而均匀量化(GPTQ-Int4)导致71-86%的覆盖崩溃。语料库验证显示MMLU-Pro Law模型之间存在17点的幻觉差距。

Conclusion: DecompressionLM建立了概念覆盖作为评估压缩模型知识广度和事实基础的新维度，为模型部署提供了补充评估指标。

Abstract: Existing knowledge probing methods rely on pre-defined queries, limiting extraction to known concepts. We introduce DecompressionLM, a stateless framework for zero-shot concept graph extraction that discovers what language models encode without pre-specified queries or shared cross-sequence state. Our method targets three limitations of common decoding-based probing approaches: cross-sequence coupling that concentrates probability mass on high-frequency prefixes, competitive decoding effects that suppress long-tail concepts, and scalability constraints arising from sequential exploration. Using Van der Corput low-discrepancy sequences with arithmetic decoding, DecompressionLM enables deterministic, embarrassingly parallel generation without shared state across sequences. Across two model families and five quantization variants, we find that activation-aware quantization (AWQ-4bit) expands concept coverage by 30-170%, while uniform quantization (GPTQ-Int4) induces 71-86% coverage collapse -- divergent behaviors not reliably reflected by explanation-level perplexity. Corpus-based verification further reveals a 17-point hallucination gap between top- and bottom-ranked MMLU-Pro Law models. DecompressionLM establishes concept coverage as a complementary evaluation dimension for assessing knowledge breadth and factual grounding in compressed models useful for their deployment.

</details>


### [291] [Clause-Internal or Clause-External? Testing Turkish Reflexive Binding in Adapted versus Chain of Thought Large Language Models](https://arxiv.org/abs/2602.00380)
*Sercan Karakaş*

Main category: cs.CL

TL;DR: 评估大型语言模型对土耳其语反身代词绑定关系的捕捉能力，发现两个模型在局部与长距离绑定偏好上存在显著差异


<details>
  <summary>Details</summary>
Motivation: 评估最先进的大型语言模型是否能够捕捉土耳其语反身代词(kendi和kendisi)的绑定关系，理解不同模型在语言结构理解上的差异

Method: 构建100个平衡句子集，对比局部与非局部先行词；测试两个系统：OpenAI链式思维模型和基于LLaMA-2的Trendyol-LLM-7B-base-v0.1；使用句子级困惑度和强制选择范式评估先行词选择

Result: Trendyol-LLM在约70%的试验中偏好局部绑定，表现出强烈的局部性偏差；而o1 Mini在局部和长距离解读之间的选择几乎均匀分布，显示出两个系统在绑定行为上的显著对比

Conclusion: 不同大型语言模型在土耳其语反身代词绑定关系理解上存在显著差异，模型架构和训练数据对语言结构理解有重要影响

Abstract: This study evaluates whether state-of-the-art large language models capture the binding relations of Turkish reflexive pronouns. We construct a balanced set of 100 sentences that pit local against non-local antecedents for the reflexives kendi and kendisi, and test two contrasting systems: an OpenAI chain-of-thought model designed for multi-step reasoning and Trendyol-LLM-7B-base-v0.1, a LLaMA-2-derived model extensively fine-tuned on Turkish data. Antecedent choice is assessed using a combined sentence-level perplexity and forced-choice paradigm. Trendyol-LLM favours local bindings in approximately 70% of trials, exhibiting a strong locality bias, whereas o1 Mini distributes its choices almost evenly between local and long-distance readings, revealing a marked contrast in binding behaviour across the two systems.

</details>


### [292] [Segment-Level Attribution for Selective Learning of Long Reasoning Traces](https://arxiv.org/abs/2602.00425)
*Siyuan Wang,Yanchen Liu,Xiang Ren*

Main category: cs.CL

TL;DR: 提出基于积分梯度归因的段级选择性学习框架，通过识别重要推理段来提升大型推理模型的效率和准确性


<details>
  <summary>Details</summary>
Motivation: 大型推理模型生成的思维链中存在大量冗余内容，只有小部分对答案预测有实质贡献。监督微调会模仿这些冗余模式，导致性能下降，需要更高效的学习方法

Method: 使用积分梯度归因量化每个token对最终答案的影响，聚合为两个段级指标：归因强度和方向一致性。基于此提出段级选择性学习框架，只对重要段进行监督微调，对不重要段掩码损失

Result: 在多个模型和数据集上的实验表明，该方法提高了准确性和输出效率，能够从长推理轨迹中更有效地学习

Conclusion: 提出的选择性学习框架通过识别和专注重要推理段，解决了大型推理模型中的输出冗余问题，实现了更高效和准确的学习

Abstract: Large Reasoning Models (LRMs) achieve strong reasoning performance by generating long chains of thought (CoTs), yet only a small fraction of these traces meaningfully contributes to answer prediction, while the majority contains repetitive or truncated content. Such output redundancy is further propagated after supervised finetuning (SFT), as models learn to imitate verbose but uninformative patterns, which can degrade performance. To this end, we incorporate integrated gradient attribution to quantify each token's influence on final answers and aggregate them into two segment-level metrics: (1) \textit{attribution strength} measures the overall attribution magnitude; and (2) \textit{direction consistency} captures whether tokens' attributions within a segment are uniformly positive or negative (high consistency), or a mixture of both (moderate consistency). Based on these two metrics, we propose a segment-level selective learning framework to identify important segments with high attribution strength but moderate consistency that indicate reflective rather than shallow reasoning. The framework then applies selective SFT on these important segments while masking loss for unimportant ones. Experiments across multiple models and datasets show that our approach improves accuracy and output efficiency, enabling more effective learning from long reasoning traces~\footnote{Code and data are available at https://github.com/SiyuanWangw/SegmentSelectiveSFT}.

</details>


### [293] [When Agents "Misremember" Collectively: Exploring the Mandela Effect in LLM-based Multi-Agent Systems](https://arxiv.org/abs/2602.00428)
*Naen Xu,Hengyu An,Shuo Shi,Jinghuai Zhang,Chunyi Zhou,Changjiang Li,Tianyu Du,Zhihui Fu,Jun Wang,Shouling Ji*

Main category: cs.CL

TL;DR: 该论文研究了基于大语言模型的多智能体系统中的曼德拉效应（集体记忆偏差），提出了MANBENCH基准来评估该效应，并提出了缓解策略，平均减少74.40%的效应。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统中智能体容易受到集体认知偏差的影响，特别是曼德拉效应（群体集体错误记忆现象），这限制了我们对多智能体系统中记忆偏差的理解，并引发了关于错误信息传播的伦理担忧。

Method: 提出了MANBENCH基准，包含四种易受曼德拉效应影响的任务类型和五种不同智能体角色与记忆时间尺度的交互协议。评估了多个LLM驱动的智能体，并提出了缓解策略：提示级防御（认知锚定和来源审查）和模型级对齐防御。

Result: 在MANBENCH上量化了曼德拉效应，分析了不同因素的影响，提出的缓解策略相比基线平均减少了74.40%的曼德拉效应。

Conclusion: 研究结果为开发更具韧性和伦理对齐的协作多智能体系统提供了有价值的见解，揭示了曼德拉效应在多智能体系统中的存在、影响因素和有效缓解方法。

Abstract: Recent advancements in large language models (LLMs) have significantly enhanced the capabilities of collaborative multi-agent systems, enabling them to address complex challenges. However, within these multi-agent systems, the susceptibility of agents to collective cognitive biases remains an underexplored issue. A compelling example is the Mandela effect, a phenomenon where groups collectively misremember past events as a result of false details reinforced through social influence and internalized misinformation. This vulnerability limits our understanding of memory bias in multi-agent systems and raises ethical concerns about the potential spread of misinformation. In this paper, we conduct a comprehensive study on the Mandela effect in LLM-based multi-agent systems, focusing on its existence, causing factors, and mitigation strategies. We propose MANBENCH, a novel benchmark designed to evaluate agent behaviors across four common task types that are susceptible to the Mandela effect, using five interaction protocols that vary in agent roles and memory timescales. We evaluate agents powered by several LLMs on MANBENCH to quantify the Mandela effect and analyze how different factors affect it. Moreover, we propose strategies to mitigate this effect, including prompt-level defenses (e.g., cognitive anchoring and source scrutiny) and model-level alignment-based defense, achieving an average 74.40% reduction in the Mandela effect compared to the baseline. Our findings provide valuable insights for developing more resilient and ethically aligned collaborative multi-agent systems.

</details>


### [294] [What Matters to an LLM? Behavioral and Computational Evidences from Summarization](https://arxiv.org/abs/2602.00459)
*Yongxin Zhou,Changshun Wu,Philippe Mulhem,Didier Schwab,Maxime Peyrard*

Main category: cs.CL

TL;DR: LLMs在摘要生成中表现出一致的内部重要性判断模式，与早期模型不同，且模型家族比规模更能影响重要性判断。研究发现某些注意力头与重要性分布对齐，中后层网络能预测重要性。


<details>
  <summary>Details</summary>
Motivation: 虽然LLMs在摘要生成任务上达到SOTA，但其内部的信息重要性判断机制仍然不透明。研究者希望揭示LLMs在摘要生成时如何选择和优先处理信息，理解其内部的重要性表示机制。

Method: 结合行为分析和计算分析：行为上，为每个文档生成一系列长度控制的摘要，基于每个信息单元被选择的频率推导经验重要性分布；计算上，识别与经验重要性分布对齐的注意力头，分析不同网络层对重要性的预测能力。

Result: LLMs在重要性判断上表现出高度一致性，与pre-LLM基线模型有显著差异；模型家族比模型规模更能影响重要性判断模式；某些注意力头与重要性分布对齐良好；中后层网络层能强烈预测重要性。

Conclusion: 研究初步揭示了LLMs在摘要生成中的信息优先级判断机制及其内部表示方式，为解释和最终控制这些模型的信息选择开辟了路径。

Abstract: Large Language Models (LLMs) are now state-of-the-art at summarization, yet the internal notion of importance that drives their information selections remains hidden. We propose to investigate this by combining behavioral and computational analyses. Behaviorally, we generate a series of length-controlled summaries for each document and derive empirical importance distributions based on how often each information unit is selected. These reveal that LLMs converge on consistent importance patterns, sharply different from pre-LLM baselines, and that LLMs cluster more by family than by size. Computationally, we identify that certain attention heads align well with empirical importance distributions, and that middle-to-late layers are strongly predictive of importance. Together, these results provide initial insights into what LLMs prioritize in summarization and how this priority is internally represented, opening a path toward interpreting and ultimately controlling information selection in these models.

</details>


### [295] [Words that make SENSE: Sensorimotor Norms in Learned Lexical Token Representations](https://arxiv.org/abs/2602.00469)
*Abhinav Gupta,Toben H. Mintz,Jesse Thomason*

Main category: cs.CL

TL;DR: SENSE模型通过将词嵌入映射到感官运动规范，探索语言理解与感知体验的联系，并在行为研究中验证其预测能力


<details>
  <summary>Details</summary>
Motivation: 传统词嵌入主要基于共现模式，但人类语言理解根植于感官和运动体验。研究旨在建立词汇表征与感知体验之间的计算联系

Method: 提出SENSE模型（感官运动嵌入规范评分引擎），通过学习投影将词嵌入预测为兰卡斯特感官运动规范。同时进行行为研究，让281名参与者从候选假词中选择具有特定感官运动联想的词汇

Result: SENSE评分与人类选择率在11个感官模态中的6个存在显著相关性。对假词选择率的亚词汇分析揭示了内感受规范的音素模式，为从文本数据计算提出候选音素提供了路径

Conclusion: SENSE模型成功建立了词汇表征与感官运动体验之间的计算联系，揭示了语言理解中感知基础的重要性，并为音素模式的计算发现提供了新方法

Abstract: While word embeddings derive meaning from co-occurrence patterns, human language understanding is grounded in sensory and motor experience. We present $\text{SENSE}$ $(\textbf{S}\text{ensorimotor }$ $\textbf{E}\text{mbedding }$ $\textbf{N}\text{orm }$ $\textbf{S}\text{coring }$ $\textbf{E}\text{ngine})$, a learned projection model that predicts Lancaster sensorimotor norms from word lexical embeddings. We also conducted a behavioral study where 281 participants selected which among candidate nonce words evoked specific sensorimotor associations, finding statistically significant correlations between human selection rates and $\text{SENSE}$ ratings across 6 of the 11 modalities. Sublexical analysis of these nonce words selection rates revealed systematic phonosthemic patterns for the interoceptive norm, suggesting a path towards computationally proposing candidate phonosthemes from text data.

</details>


### [296] [Intention-Adaptive LLM Fine-Tuning for Text Revision Generation](https://arxiv.org/abs/2602.00477)
*Zhexiong Liu,Diane Litman*

Main category: cs.CL

TL;DR: Intention-Tuning：一种基于意图的自适应分层LLM微调框架，用于在小型修订语料库上高效生成反映作者实际意图的修订文本。


<details>
  <summary>Details</summary>
Motivation: LLMs在基于上下文的文本生成任务中表现出色，但在基于意图的生成任务（如修订生成）中应用不足。现有方法难以处理复杂的多意图场景，而微调需要大量标注数据，这在修订领域既昂贵又稀缺。

Method: 提出Intention-Tuning框架：自适应地选择LLM的层子集来学习意图，然后将这些表示迁移到修订生成任务中。这是一种分层微调方法，能够动态调整模型结构以适应意图学习需求。

Result: 实验结果表明，Intention-Tuning在小型修订语料库上既有效又高效，优于多个参数高效微调（PEFT）基线方法。

Conclusion: Intention-Tuning为解决LLMs在意图驱动的修订生成任务中的局限性提供了一种有效解决方案，特别是在数据稀缺的情况下，通过自适应分层选择实现了更好的意图理解和修订生成。

Abstract: Large Language Models (LLMs) have achieved impressive capabilities in various context-based text generation tasks, such as summarization and reasoning; however, their applications in intention-based generation tasks remain underexplored. One such example is revision generation, which requires the generated text to explicitly reflect the writer's actual intentions. Identifying intentions and generating desirable revisions are challenging due to their complex and diverse nature. Although prior work has employed LLMs to generate revisions with few-shot learning, they struggle with handling entangled multi-intent scenarios. While fine-tuning LLMs using intention-based instructions appears promising, it demands large amounts of annotated data, which is expensive and scarce in the revision community. To address these challenges, we propose Intention-Tuning, an intention-adaptive layer-wise LLM fine-tuning framework that dynamically selects a subset of LLM layers to learn the intentions and subsequently transfers their representations to revision generation. Experimental results suggest that Intention-Tuning is effective and efficient on small revision corpora, outperforming several PEFT baselines.

</details>


### [297] [From Knowledge to Inference: Scaling Laws of Specialized Reasoning on GlobalHealthAtlas](https://arxiv.org/abs/2602.00491)
*Zhaokun Yan,Zhaohan Liu,Wuzheng Dong,Lijie Feng,Chengxiao Dai*

Main category: cs.CL

TL;DR: 提出了GlobalHealthAtlas数据集，包含28万条多语言公共卫生推理实例，涵盖15个领域和17种语言，并设计了LLM辅助的质量控制流程和领域对齐评估器。


<details>
  <summary>Details</summary>
Motivation: 公共卫生推理需要基于科学证据、专家共识和安全约束的群体层面推断，但作为结构化机器学习问题仍未被充分探索，缺乏监督信号和基准数据集。

Method: 1) 构建大规模多语言数据集GlobalHealthAtlas；2) 设计LLM辅助的构建和质量控制流程，包括检索、去重、证据基础和标签验证；3) 提出从多样化LLM高置信度判断中蒸馏的领域对齐评估器。

Result: 创建了包含280,210个实例的数据集，涵盖15个公共卫生领域和17种语言，按健康素养、流行病学推理和政策推理三个难度层次分层，支持监督学习和切片评估。

Conclusion: 这些贡献使得能够在安全关键的公共卫生推理领域进行可重复的LLM训练和评估，超越了传统的问答基准。

Abstract: Public health reasoning requires population level inference grounded in scientific evidence, expert consensus, and safety constraints. However, it remains underexplored as a structured machine learning problem with limited supervised signals and benchmarks. We introduce \textbf{GlobalHealthAtlas}, a large scale multilingual dataset of 280,210 instances spanning 15 public health domains and 17 languages, stratified into three difficulty levels from health literacy to epidemiological and policy reasoning. Instances are derived from openly available public health sources and labeled by language, domain, and difficulty to support supervised learning and slice based evaluation. We further propose large language model (LLM) assisted construction and quality control pipeline with retrieval, duplication, evidence grounding checks, and label validation to improve consistency at scale. Finally, we present a domain aligned evaluator distilled from high confidence judgments of diverse LLMs to assess outputs along six dimensions: Accuracy, Reasoning, Completeness, Consensus Alignment, Terminology Norms, and Insightfulness. Together, these contributions enable reproducible training and evaluation of LLMs for safety critical public health reasoning beyond conventional QA benchmarks.

</details>


### [298] [Culturally-Grounded Governance for Multilingual Language Models: Rights, Data Boundaries, and Accountable AI Design](https://arxiv.org/abs/2602.00497)
*Hanjing Shi,Dominic DiFranzo*

Main category: cs.CL

TL;DR: 多语言大语言模型(MLLMs)的治理框架存在英语中心主义问题，无法适应多元文化语境，本文提出基于文化背景的治理框架以解决语言不平等和本地规范错配问题。


<details>
  <summary>Details</summary>
Motivation: 当前多语言大语言模型的治理框架主要基于英语中心数据、同质化用户群体和抽象公平概念，这导致对低资源语言和文化边缘化社区的系统性风险。数据实践、模型行为和问责机制往往与本地规范、权利和期望不符。

Method: 本文综合了跨文化视角的人类中心计算和AI治理研究，整合了关于多语言模型行为、数据不对称和社会技术危害的现有证据，构建了一个基于文化的MLLMs治理框架。

Result: 识别出三个相互关联的治理挑战：1)训练数据和评估实践中的文化和语言不平等；2)全球部署与本地规范、价值观和权力结构之间的错配；3)针对边缘化语言社区所受危害的有限问责机制。

Conclusion: 本文提出了一个概念性议程，将多语言AI治理重新定义为社会文化和基于权利的问题，并概述了数据管理、透明度和参与式问责的设计和政策影响。基于文化的治理对于确保多语言语言模型不会在规模和中性幌子下复制现有全球不平等至关重要。

Abstract: Multilingual large language models (MLLMs) are increasingly deployed across cultural, linguistic, and political contexts, yet existing governance frameworks largely assume English-centric data, homogeneous user populations, and abstract notions of fairness. This creates systematic risks for low-resource languages and culturally marginalized communities, where data practices, model behavior, and accountability mechanisms often fail to align with local norms, rights, and expectations. Drawing on cross-cultural perspectives in human-centered computing and AI governance, this paper synthesizes existing evidence on multilingual model behavior, data asymmetries, and sociotechnical harm, and articulates a culturally grounded governance framework for MLLMs. We identify three interrelated governance challenges: cultural and linguistic inequities in training data and evaluation practices, misalignment between global deployment and locally situated norms, values, and power structures, and limited accountability mechanisms for addressing harms experienced by marginalized language communities. Rather than proposing new technical benchmarks, we contribute a conceptual agenda that reframes multilingual AI governance as a sociocultural and rights based problem. We outline design and policy implications for data stewardship, transparency, and participatory accountability, and argue that culturally grounded governance is essential for ensuring that multilingual language models do not reproduce existing global inequalities under the guise of scale and neutrality.

</details>


### [299] [Reasoning by Commented Code for Table Question Answering](https://arxiv.org/abs/2602.00543)
*Seho Pyo,Jiheon Seok,Jaejin Lee*

Main category: cs.CL

TL;DR: 提出一个带注释的逐步代码生成框架，通过多行可执行Python程序增强表格问答的数值准确性和可解释性，在WikiTableQuestions基准上达到70.9%准确率，结合端到端模型后提升至84.3%。


<details>
  <summary>Details</summary>
Motivation: 传统表格线性化方法破坏了结构化数据的二维关系，现有端到端答案生成或单行程序查询方法存在数值准确性有限和可解释性不足的问题。

Method: 提出带注释的逐步代码生成框架，将表格问答推理分解为多行可执行Python程序，每行代码附带简洁自然语言注释，促进清晰推理并提高正确代码生成概率。

Result: 在WikiTableQuestions基准上，使用Qwen2.5-Coder-7B-Instruct达到70.9%准确率，超过Repanda基线（67.6%）。通过轻量级答案选择机制与强大端到端表格问答模型结合后，准确率进一步提升至84.3%。

Conclusion: 带注释的逐步代码生成框架通过显式推理和多行程序分解，显著提升了表格问答的数值准确性和可解释性，结合端到端模型可达到最先进的性能。

Abstract: Table Question Answering (TableQA) poses a significant challenge for large language models (LLMs) because conventional linearization of tables often disrupts the two-dimensional relationships intrinsic to structured data. Existing methods, which depend on end-to-end answer generation or single-line program queries, typically exhibit limited numerical accuracy and reduced interpretability. This work introduces a commented, step-by-step code-generation framework that incorporates explicit reasoning into the Python program-generation process. The approach decomposes TableQA reasoning into multi-line executable programs with concise natural language comments, thereby promoting clearer reasoning and increasing the likelihood of generating correct code. On the WikiTableQuestions benchmark, the proposed method achieves 70.9\% accuracy using Qwen2.5-Coder-7B-Instruct, surpassing the Repanda baseline (67.6\%). Integrating the proposed framework with a robust end-to-end TableQA model via a lightweight answer-selection mechanism yields further improvements. This combined approach achieves up to 84.3\% accuracy on the WikiTableQuestions benchmark.

</details>


### [300] [A Hierarchical and Attentional Analysis of Argument Structure Constructions in BERT Using Naturalistic Corpora](https://arxiv.org/abs/2602.00554)
*Liu Kaipeng,Wu Ling*

Main category: cs.CL

TL;DR: BERT模型对四种基本论元结构构式的处理呈现层次化表征结构：早期层出现构式特定信息，中间层形成最大可分离聚类，后期层维持这些表征。


<details>
  <summary>Details</summary>
Motivation: 研究BERT模型如何处理四种基本论元结构构式，探索模型内部对语言结构的表征机制。

Method: 采用多维分析框架，包括MDS和t-SNE降维、广义判别值(GDV)作为聚类分离指标、Fisher判别比(FDR)作为线性诊断探测，以及注意力机制分析。

Result: 发现BERT对论元结构构式的表征呈现层次化结构：构式特定信息在早期层出现，在中间层形成最大可分离聚类，并在后期处理阶段得以维持。

Conclusion: BERT模型在处理论元结构构式时展现出系统的层次化表征模式，为理解Transformer模型的语言处理机制提供了新见解。

Abstract: This study investigates how the Bidirectional Encoder Representations from Transformers model processes four fundamental Argument Structure Constructions. We employ a multi-dimensional analytical framework, which integrates MDS, t-SNE as dimensionality reduction, Generalized Discrimination Value (GDV) as cluster separation metrics, Fisher Discriminant Ratio (FDR) as linear diagnostic probing, and attention mechanism analysis. Our results reveal a hierarchical representational structure. Construction-specific information emerges in early layers, forms maximally separable clusters in middle layers, and is maintained through later processing stages.

</details>


### [301] [The French Drama Revolution: Political Economy and Literary Production, 1700-1900](https://arxiv.org/abs/2602.00588)
*Thiago Dumont Oliveira*

Main category: cs.CL

TL;DR: 使用LDA和JS散度分析1700-1900年法国戏剧主题演变，发现法国大革命后戏剧主题分布发生深刻变化，资产阶级主题兴起，并与经济增长存在协同演化关系。


<details>
  <summary>Details</summary>
Motivation: 研究法国戏剧在1700-1900年间的演变，特别是法国大革命和工业化如何影响戏剧主题的变化，以及戏剧主题与经济增长之间的关联。

Method: 使用潜在狄利克雷分配(LDA)进行主题建模，结合Jensen-Shannon散度分析主题分布变化，并将主题年度流行度与法国GDP数据进行对比分析。

Result: 法国戏剧主题分布在法国大革命后（1789-1850年）发生深刻变化，资产阶级主题自18世纪末成为最流行主题之一，戏剧主题演变与法国经济增长存在时间上的协同性。

Conclusion: 法国戏剧的主题演变反映了社会政治经济变革，特别是法国大革命和工业化进程，戏剧主题与经济增长之间存在相互影响的协同演化关系。

Abstract: This paper investigates the changing nature of French drama between 1700-1900 using Latent Dirichlet Allocation and Jensen-Shannon Divergence. Results indicate that the topical distribution of French drama changed profoundly after the French Revolution, particularly between 1789 and 1850. Bourgeois themes emerged among the most prevalent topics since the late 18th century. To assess the coevolution of drama and economic growth, I plot the yearly prevalence of topics alongside French GDP between 1700-1900, and discuss these changes in light of the political and economic changes prompted by the French Revolution and the industrialization of the country.

</details>


### [302] [Kanade: A Simple Disentangled Tokenizer for Spoken Language Modeling](https://arxiv.org/abs/2602.00594)
*Zhijie Huang,Stephen McIntosh,Daisuke Saito,Nobuaki Minematsu*

Main category: cs.CL

TL;DR: Kanade是一个单层解耦语音分词器，能够分离声学常量，创建单一token流来捕获丰富的语音和韵律信息，无需现有解耦编解码器常用的辅助方法。


<details>
  <summary>Details</summary>
Motivation: 良好的语言模型始于良好的分词器。对于语音建模尤其重要，因为需要处理混合语言和非语言信息的连续信号。语音分词器应该提取语音和韵律，抑制与语言无关的信息（如说话人身份），并支持高质量合成。

Method: Kanade是一个单层解耦语音分词器，通过分离声学常量来创建单一token流，捕获丰富的语音和韵律信息。该方法不需要现有解耦编解码器常用的辅助方法。

Result: 实验表明，Kanade在说话人解耦和词汇可用性方面达到最先进水平，同时保持优秀的重建质量。

Conclusion: Kanade实现了理想的语音分词器设计，能够有效分离语音信息，为语音建模提供了高质量的token化解决方案。

Abstract: A good language model starts with a good tokenizer. Tokenization is especially important for speech modeling, which must handle continuous signals that mix linguistic and non-linguistic information. A speech tokenizer should extract phonetics and prosody, suppress linguistically irrelevant information like speaker identity, and enable high-quality synthesis. We present Kanade, a single-layer disentangled speech tokenizer that realizes this ideal. Kanade separates out acoustic constants to create a single stream of tokens that captures rich phonetics and prosody. It does so without the need for auxiliary methods that existing disentangled codecs often rely on. Experiments show that Kanade achieves state-of-the-art speaker disentanglement and lexical availability, while maintaining excellent reconstruction quality.

</details>


### [303] [Hermes the Polyglot: A Unified Framework to Enhance Expressiveness for Multimodal Interlingual Subtitling](https://arxiv.org/abs/2602.00597)
*Chaoqun Cui,Shijing Wang,Liangbin Huang,Qingqing Gu,Zhaolong Huang,Xiao Zeng,Wenji Mao*

Main category: cs.CL

TL;DR: Hermes是一个基于大语言模型的自动字幕翻译框架，通过说话人分离、术语识别和表达增强三个模块解决字幕翻译中的语义连贯性、代词术语翻译和表达力等挑战。


<details>
  <summary>Details</summary>
Motivation: 跨语言字幕翻译在娱乐本地化中至关重要，但尚未在机器翻译中得到充分探索。尽管大语言模型显著提升了机器翻译的一般能力，但字幕文本的独特特性（如语义连贯性、代词术语翻译和翻译表达力）仍然存在持续挑战。

Method: 提出Hermes框架，包含三个核心模块：1) 说话人分离模块处理说话人识别；2) 术语识别模块处理专业术语翻译；3) 表达增强模块提升翻译的表达力。这三个模块协同工作解决字幕翻译的特殊挑战。

Result: 实验表明Hermes在说话人分离方面达到最先进性能，并能生成表达力强、上下文连贯的翻译，从而推动了跨语言字幕翻译的研究进展。

Conclusion: Hermes框架有效解决了字幕翻译中的关键挑战，为基于大语言模型的跨语言字幕翻译提供了新的解决方案，在说话人分离性能和翻译质量方面都取得了显著进展。

Abstract: Interlingual subtitling, which translates subtitles of visual media into a target language, is essential for entertainment localization but has not yet been explored in machine translation. Although Large Language Models (LLMs) have significantly advanced the general capabilities of machine translation, the distinctive characteristics of subtitle texts pose persistent challenges in interlingual subtitling, particularly regarding semantic coherence, pronoun and terminology translation, and translation expressiveness. To address these issues, we present Hermes, an LLM-based automated subtitling framework. Hermes integrates three modules: Speaker Diarization, Terminology Identification, and Expressiveness Enhancement, which effectively tackle the above challenges. Experiments demonstrate that Hermes achieves state-of-the-art diarization performance and generates expressive, contextually coherent translations, thereby advancing research in interlingual subtitling.

</details>


### [304] [Lookahead-then-Verify: Reliable Constrained Decoding for Diffusion LLMs under Context-Free Grammars](https://arxiv.org/abs/2602.00612)
*Yitong Zhang,Yongmin Li,Yuetong Liu,Jia Li,Xiaoran Jia,Zherui Li,Ge Li*

Main category: cs.CL

TL;DR: LAVE是一种专门为扩散大语言模型设计的约束解码方法，通过前瞻验证确保生成语法正确的输出，显著提升句法正确性且运行时开销可忽略。


<details>
  <summary>Details</summary>
Motivation: 扩散大语言模型在生成形式语言（如源代码、化学表达式）时，作为概率模型仍难以可靠生成语法有效的输出。现有约束解码方法要么不适用于dLLMs的非自回归特性，要么无法确保中间输出能完成有效句子，限制了实际可靠性。

Method: LAVE利用dLLMs在每次前向传播中并行预测所有位置token分布的特性，当模型提出新token时，使用这些分布进行前瞻验证，高效可靠地检查提议token的有效性，确保中间输出始终能扩展为有效句子。

Result: 在四个广泛使用的dLLMs和三个代表性基准测试上的实验表明，LAVE始终优于现有基线方法，在句法正确性方面实现显著提升，同时运行时开销可忽略不计。

Conclusion: LAVE为扩散大语言模型提供了一种有效的约束解码方法，解决了现有方法在非自回归模型上的适用性问题，通过前瞻验证机制确保生成过程的可靠性，为dLLMs在形式语言生成任务中的实际应用提供了有力支持。

Abstract: Diffusion Large Language Models (dLLMs) have demonstrated promising generative capabilities and are increasingly used to produce formal languages defined by context-free grammars, such as source code and chemical expressions. However, as probabilistic models, they still struggle to generate syntactically valid outputs reliably. A natural and promising direction to address this issue is to adapt constrained decoding techniques to enforce grammatical correctness during generation. However, applying these techniques faces two primary obstacles. On the one hand, the non-autoregressive nature of dLLMs renders most existing constrained decoding approaches inapplicable. On the other hand, current approaches specifically designed for dLLMs may allow intermediate outputs that are impossible to complete into valid sentences, which significantly limits their reliability in practice.
  To address these challenges, we present LAVE, a constrained decoding approach specifically designed for dLLMs. Our approach leverages a key property of dLLMs, namely their ability to predict token distributions for all positions in parallel during each forward pass. Whenever a new token is proposed by model, LAVE performs lookahead using these distributions to efficiently and reliably verify the validity of the proposed token. This design ensures reliable constraints by reliably preserving the potential for intermediate outputs to be extended into valid sentences. Extensive experiments across four widely used dLLMs and three representative benchmarks demonstrate that LAVE consistently outperforms existing baselines and achieves substantial improvements in syntactic correctness, while incurring negligible runtime overhead.

</details>


### [305] [Transformer-Based Model for Multilingual Hope Speech Detection](https://arxiv.org/abs/2602.00613)
*Nsrin Ashraf,Mariam Labib,Hamada Nayel*

Main category: cs.CL

TL;DR: 本文介绍了提交给RANLP2025 "PolyHope-M"任务的系统，使用RoBERTa和XLM-RoBERTa进行英语和德语希望语音检测，RoBERTa在英语上表现更好


<details>
  <summary>Details</summary>
Motivation: 希望语音检测是自然语言处理中的重要任务，特别是在多语言环境下。本文旨在探索预训练大语言模型在英语和德语希望语音检测任务上的性能表现，比较单语言模型与多语言模型的效果。

Method: 为英语实现RoBERTa模型，为英语和德语实现多语言模型XLM-RoBERTa。在PolyHope-M数据集上进行评估，使用加权F1分数和准确率作为评价指标。

Result: RoBERTa在英语希望语音检测上获得加权F1分数0.818和准确率81.8%。XLM-RoBERTa获得加权F1分数0.786和准确率78.5%。结果表明单语言模型在特定语言任务上表现优于多语言模型。

Conclusion: 预训练大语言模型显著提升了自然语言处理任务的性能，特别是在希望语音检测任务上。单语言模型在特定语言任务上可能比多语言模型表现更好，这为未来模型选择和优化提供了参考。

Abstract: This paper describes a system that has been submitted to the "PolyHope-M" at RANLP2025. In this work various transformers have been implemented and evaluated for hope speech detection for English and Germany. RoBERTa has been implemented for English, while the multilingual model XLM-RoBERTa has been implemented for both English and German languages. The proposed system using RoBERTa reported a weighted f1-score of 0.818 and an accuracy of 81.8% for English. On the other hand, XLM-RoBERTa achieved a weighted f1-score of 0.786 and an accuracy of 78.5%. These results reflects the importance of improvement of pre-trained large language models and how these models enhancing the performance of different natural language processing tasks.

</details>


### [306] [Jailbreaking LLMs via Calibration](https://arxiv.org/abs/2602.00619)
*Yuxuan Lu,Yongkang Guo,Yuqing Kong*

Main category: cs.CL

TL;DR: 提出一个将安全对齐视为预对齐分布系统性扭曲的框架，将弱到强越狱建模为预测聚合问题，推导出最优聚合策略，并展示现有方法只是该框架在交叉熵损失下的特例。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的安全对齐会在模型对齐输出与底层预对齐数据分布之间产生系统性差异，需要理解这种对齐如何影响下一个标记预测，并开发更有效的越狱方法。

Method: 将安全对齐效应建模为预对齐分布的系统性扭曲，将弱到强越狱视为预测聚合问题，推导出损失诱导对偶空间中的梯度偏移最优聚合策略，并提出新的混合聚合规则。

Result: 在红队基准测试和数学效用任务中，该方法相比现有方法实现了更高的攻击成功率，特别是在安全强化的gpt-oss-120b模型上，同时降低了"越狱税"。

Conclusion: 提出的框架为理解安全对齐效应提供了理论基础，推导的最优聚合策略在实际越狱任务中表现出优越性能，特别是对安全强化模型，现有方法只是该框架的特殊情况。

Abstract: Safety alignment in Large Language Models (LLMs) often creates a systematic discrepancy between a model's aligned output and the underlying pre-aligned data distribution. We propose a framework in which the effect of safety alignment on next-token prediction is modeled as a systematic distortion of a pre-alignment distribution. We cast Weak-to-Strong Jailbreaking as a forecast aggregation problem and derive an optimal aggregation strategy characterized by a Gradient Shift in the loss-induced dual space. We show that logit-arithmetic jailbreaking methods are a special case of this framework under cross-entropy loss, and derive a broader family of aggregation rules corresponding to other proper losses. We also propose a new hybrid aggregation rule. Evaluations across red-teaming benchmarks and math utility tasks using frontier models demonstrate that our approach achieves superior Attack Success Rates and lower "Jailbreak Tax" compared with existing methods, especially on the safety-hardened gpt-oss-120b.

</details>


### [307] [Formal Semantic Control over Language Models](https://arxiv.org/abs/2602.00638)
*Yingji Zhang*

Main category: cs.CL

TL;DR: 该论文通过变分自编码器框架，从句子层面和推理层面两个方向，提升语言表示/模型的语义和几何可解释性，实现局部化、准符号化的组合控制。


<details>
  <summary>Details</summary>
Motivation: 使语言表示或模型在语义和几何上更具可解释性，并通过对潜在空间几何形状的有意塑造，实现局部化、准符号化、组合式的控制。

Method: 在VAE框架下探索两个互补研究方向：(1) 句子级学习与控制：在潜在空间中解耦和操作特定语义特征以指导句子生成；(2) 推理级学习与控制：在潜在空间中隔离和引导推理行为以控制自然语言推理。

Result: 提出了一套新颖的理论框架和实用方法，并通过相应实验证明，该方法能增强自然语言潜在空间的可解释性和可控性。

Conclusion: 该研究推动了语言模型向内部语义表示可系统解释、精确结构化、可靠引导的方向发展，为语义表示学习提供了新的理论框架和实践方法。

Abstract: This thesis advances semantic representation learning to render language representations or models more semantically and geometrically interpretable, and to enable localised, quasi-symbolic, compositional control through deliberate shaping of their latent space geometry. We pursue this goal within a VAE framework, exploring two complementary research directions: (i) Sentence-level learning and control: disentangling and manipulating specific semantic features in the latent space to guide sentence generation, with explanatory text serving as the testbed; and (ii) Reasoning-level learning and control: isolating and steering inference behaviours in the latent space to control NLI. In this direction, we focus on Explanatory NLI tasks, in which two premises (explanations) are provided to infer a conclusion. The overarching objective is to move toward language models whose internal semantic representations can be systematically interpreted, precisely structured, and reliably directed. We introduce a set of novel theoretical frameworks and practical methodologies, together with corresponding experiments, to demonstrate that our approaches enhance both the interpretability and controllability of latent spaces for natural language across the thesis.

</details>


### [308] [LegalOne: A Family of Foundation Models for Reliable Legal Reasoning](https://arxiv.org/abs/2602.00642)
*Haitao Li,Yifan Chen,Shuo Miao,Qian Dong,Jia Chen,Yiran Hu,Junjie Chen,Minghao Qin,Qingyao Ai,Yiqun Liu,Cheng Luo,Quan Zhou,Ya Zhang,Jikun Hu*

Main category: cs.CL

TL;DR: LegalOne是中国法律领域的专业基础模型，通过三阶段训练流程实现法律推理，在多项法律任务上超越通用大模型


<details>
  <summary>Details</summary>
Motivation: 通用大语言模型在法律领域应用受限，缺乏精确领域知识和复杂多步司法推理能力，需要专门的法律领域基础模型

Method: 三阶段训练流程：1) 中期训练阶段使用塑性调整采样平衡新知识获取与原有能力保留；2) 监督微调阶段采用法律代理思维链蒸馏从原始法律文本中提取显式推理；3) 课程强化学习策略，通过记忆、理解、推理的渐进过程实现自主可靠的法律推理

Result: LegalOne在广泛的法律任务上达到最先进性能，超越参数规模更大的通用大模型，通过增强知识密度和效率实现优异表现

Conclusion: LegalOne为法律AI领域提供了可信赖且可解释的基础模型，推动高风险司法应用中的部署，公开模型权重和LegalKit评估框架促进领域发展

Abstract: While Large Language Models (LLMs) have demonstrated impressive general capabilities, their direct application in the legal domain is often hindered by a lack of precise domain knowledge and complexity of performing rigorous multi-step judicial reasoning. To address this gap, we present LegalOne, a family of foundational models specifically tailored for the Chinese legal domain. LegalOne is developed through a comprehensive three-phase pipeline designed to master legal reasoning. First, during mid-training phase, we propose Plasticity-Adjusted Sampling (PAS) to address the challenge of domain adaptation. This perplexity-based scheduler strikes a balance between the acquisition of new knowledge and the retention of original capabilities, effectively establishing a robust legal foundation. Second, during supervised fine-tuning, we employ Legal Agentic CoT Distillation (LEAD) to distill explicit reasoning from raw legal texts. Unlike naive distillation, LEAD utilizes an agentic workflow to convert complex judicial processes into structured reasoning trajectories, thereby enforcing factual grounding and logical rigor. Finally, we implement a Curriculum Reinforcement Learning (RL) strategy. Through a progressive reinforcement process spanning memorization, understanding, and reasoning, LegalOne evolves from simple pattern matching to autonomous and reliable legal reasoning. Experimental results demonstrate that LegalOne achieves state-of-the-art performance across a wide range of legal tasks, surpassing general-purpose LLMs with vastly larger parameter counts through enhanced knowledge density and efficiency. We publicly release the LegalOne weights and the LegalKit evaluation framework to advance the field of Legal AI, paving the way for deploying trustworthy and interpretable foundation models in high-stakes judicial applications.

</details>


### [309] [Can Small Language Models Handle Context-Summarized Multi-Turn Customer-Service QA? A Synthetic Data-Driven Comparative Evaluation](https://arxiv.org/abs/2602.00665)
*Lakshan Cooray,Deshan Sumanathilaka,Pattigadapa Venkatesh Raju*

Main category: cs.CL

TL;DR: 本研究探讨了指令调优的小语言模型在客户服务多轮问答中的应用，通过历史摘要策略保持对话连续性，发现部分小模型性能接近大模型，但整体存在对话连续性和上下文对齐的挑战。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在客户服务问答中表现优异，但计算成本高且部署受限；小语言模型虽更高效，但在多轮客户服务问答中的有效性尚未充分探索，特别是在需要对话连续性和上下文理解的场景中。

Method: 采用指令调优的小语言模型进行上下文摘要的多轮客户服务问答，使用历史摘要策略保持关键对话状态；引入基于对话阶段的定性分析来评估模型在不同客户服务交互阶段的行为；评估9个指令调优的小语言模型与3个商业大语言模型，使用词汇和语义相似度指标以及定性评估（包括人工评估和LLM作为评判的方法）。

Result: 不同小语言模型表现差异显著，部分模型展现出接近大语言模型的性能，而其他模型在保持对话连续性和上下文对齐方面存在困难；定性分析揭示了模型在不同对话阶段的行为模式。

Conclusion: 研究结果突显了低参数量语言模型在现实世界客户服务问答系统中的潜力和当前局限性，为资源受限环境下的高效部署提供了参考。

Abstract: Customer-service question answering (QA) systems increasingly rely on conversational language understanding. While Large Language Models (LLMs) achieve strong performance, their high computational cost and deployment constraints limit practical use in resource-constrained environments. Small Language Models (SLMs) provide a more efficient alternative, yet their effectiveness for multi-turn customer-service QA remains underexplored, particularly in scenarios requiring dialogue continuity and contextual understanding. This study investigates instruction-tuned SLMs for context-summarized multi-turn customer-service QA, using a history summarization strategy to preserve essential conversational state. We also introduce a conversation stage-based qualitative analysis to evaluate model behavior across different phases of customer-service interactions. Nine instruction-tuned low-parameterized SLMs are evaluated against three commercial LLMs using lexical and semantic similarity metrics alongside qualitative assessments, including human evaluation and LLM-as-a-judge methods. Results show notable variation across SLMs, with some models demonstrating near-LLM performance, while others struggle to maintain dialogue continuity and contextual alignment. These findings highlight both the potential and current limitations of low-parameterized language models for real-world customer-service QA systems.

</details>


### [310] [EchoReview: Learning Peer Review from the Echoes of Scientific Citations](https://arxiv.org/abs/2602.00733)
*Yinuo Zhang,Dingcheng Huang,Haifeng Suo,Yizhuo Li,Ziya Zhao,Junhao Xu,Zhiying Tu,Dianhui Chu,Deming Zhai,Xianming Liu,Xiaoyan Yu,Dianbo Sui*

Main category: cs.CL

TL;DR: EchoReview是一个基于学术引用上下文的自动审稿数据合成框架，通过挖掘学术引用中的集体评价信号来生成结构化审稿数据，解决了传统监督微调方法受限于单源数据和人类审稿主观性的问题。


<details>
  <summary>Details</summary>
Motivation: 随着科学投稿量快速增长，传统同行评审系统面临可扩展性压力，急需既可扩展又可靠的自动审稿方法。现有基于真实审稿数据的监督微调方法受限于单源数据以及人类审稿的主观性和不一致性，难以支持高质量的自动审稿。

Method: 提出EchoReview框架，系统性地从学术引用中挖掘隐性的集体评价信号，将科学界长期判断转化为结构化审稿风格数据。基于此构建了EchoReview-16K数据集（首个大规模、跨会议、跨年份的引用驱动审稿数据集），并训练了EchoReviewer-7B自动审稿模型。

Result: 实验结果表明，EchoReviewer-7B在证据支持和审稿全面性等核心审稿维度上取得了显著且稳定的改进，验证了引用上下文作为可靠自动同行评审的稳健有效数据范式。

Conclusion: 学术引用上下文可以作为可靠自动同行评审的有效数据来源，EchoReview框架通过挖掘引用中的集体评价信号，解决了传统方法的局限性，为高质量自动审稿提供了新途径。

Abstract: As the volume of scientific submissions continues to grow rapidly, traditional peer review systems are facing unprecedented scalability pressures, highlighting the urgent need for automated reviewing methods that are both scalable and reliable. Existing supervised fine-tuning approaches based on real review data are fundamentally constrained by single-source of data as well as the inherent subjectivity and inconsistency of human reviews, limiting their ability to support high-quality automated reviewers. To address these issues, we propose EchoReview, a citation-context-driven data synthesis framework that systematically mines implicit collective evaluative signals from academic citations and transforms scientific community's long-term judgments into structured review-style data. Based on this pipeline, we construct EchoReview-16K, the first large-scale, cross-conference, and cross-year citation-driven review dataset, and train an automated reviewer, EchoReviewer-7B. Experimental results demonstrate that EchoReviewer-7B can achieve significant and stable improvements on core review dimensions such as evidence support and review comprehensiveness, validating citation context as a robust and effective data paradigm for reliable automated peer review.

</details>


### [311] [ExperienceWeaver: Optimizing Small-sample Experience Learning for LLM-based Clinical Text Improvement](https://arxiv.org/abs/2602.00740)
*Ziyan Xiao,Yinghao Zhu,Liang Peng,Lequan Yu*

Main category: cs.CL

TL;DR: ExperienceWeaver：一种分层框架，通过从多维度反馈中提炼结构化知识（技巧和策略），在小样本临床文本改进任务中超越现有方法


<details>
  <summary>Details</summary>
Motivation: 临床文本改进对医疗效率至关重要，但高质量数据有限且医学文档约束复杂。现有LLM方法在小样本场景中表现不佳：监督微调需要大量数据成本高，检索增强生成只能提供表面修正而无法捕捉修订背后的推理逻辑。

Method: 提出ExperienceWeaver分层框架，将重点从数据检索转向经验学习。框架从嘈杂的多维度反馈中提炼结构化、可操作的知识，包括错误特定的技巧和高层策略，并将这些提炼的经验注入到智能体管道中，让模型学习"如何修订"而非仅"修订什么"。

Result: 在四个临床数据集上的广泛评估表明，ExperienceWeaver持续提升性能，在小样本设置中超越了Gemini-3 Pro等最先进模型。

Conclusion: 通过经验学习而非简单数据检索，ExperienceWeaver能够在小样本临床文本改进任务中实现更有效的性能提升，为医疗文档质量改进提供了新思路。

Abstract: Clinical text improvement is vital for healthcare efficiency but remains difficult due to limited high-quality data and the complex constraints of medical documentation. While Large Language Models (LLMs) show promise, current approaches struggle in small-sample settings: supervised fine-tuning is data-intensive and costly, while retrieval-augmented generation often provides superficial corrections without capturing the reasoning behind revisions. To address these limitations, we propose ExperienceWeaver, a hierarchical framework that shifts the focus from data retrieval to experience learning. Instead of simply recalling past examples, ExperienceWeaver distills noisy, multi-dimensional feedback into structured, actionable knowledge. Specifically, error-specific Tips and high-level Strategies. By injecting this distilled experience into an agentic pipeline, the model learns "how to revise" rather than just "what to revise". Extensive evaluations across four clinical datasets demonstrate that ExperienceWeaver consistently improves performance, surpassing state-of-the-art models such as Gemini-3 Pro in small-sample settings.

</details>


### [312] [CURP: Codebook-based Continuous User Representation for Personalized Generation with LLMs](https://arxiv.org/abs/2602.00742)
*Liang Wang,Xinyi Mou,Xiaoyou Liu,Xuanjing Huang,Zhongyu Wei*

Main category: cs.CL

TL;DR: CURP是一个新颖的用户建模框架，使用双向用户编码器和离散原型码本提取多维用户特征，实现即插即用的个性化，参数量小（约2000万），性能优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 现有基于提示或训练的用户建模方法在个性化质量与计算/数据效率之间难以平衡，需要一种既能保持高质量个性化又高效的方法。

Method: 提出CURP框架，采用双向用户编码器和离散原型码本提取多维用户特征，实现即插即用的个性化，仅需约2000万可训练参数（约占总模型大小的0.2%）。

Result: 在多种生成任务上的实验表明，CURP相比强基线方法取得更优的性能和泛化能力，同时提供更好的可解释性和可扩展性。

Conclusion: CURP框架在保持高质量个性化的同时实现了高效的用户建模，解决了现有方法在个性化质量与效率之间的平衡问题。

Abstract: User modeling characterizes individuals through their preferences and behavioral patterns to enable personalized simulation and generation with Large Language Models (LLMs) in contemporary approaches. However, existing methods, whether prompt-based or training-based methods, face challenges in balancing personalization quality against computational and data efficiency. We propose a novel framework CURP, which employs a bidirectional user encoder and a discrete prototype codebook to extract multi-dimensional user traits. This design enables plug-and-play personalization with a small number of trainable parameters (about 20M parameters, about 0.2\% of the total model size). Through extensive experiments on variant generation tasks, we show that CURP achieves superior performance and generalization compared to strong baselines, while offering better interpretability and scalability. The code are available at https://github.com/RaidonWong/CURP_code

</details>


### [313] [Decouple Searching from Training: Scaling Data Mixing via Model Merging for Large Language Model Pre-training](https://arxiv.org/abs/2602.00747)
*Shengrui Li,Fei Zhao,Kaiyan Zhao,Jieying Ye,Haifeng Liu,Fangcheng Shi,Zheyong Xie,Yao Hu,Shaosheng Cao*

Main category: cs.CL

TL;DR: DeMix提出了一种通过模型合并预测最优数据混合比例的新框架，将搜索与训练成本解耦，从而以更低成本发现更优的数据混合方案。


<details>
  <summary>Details</summary>
Motivation: LLM预训练中确定有效的数据混合是关键挑战，现有方法要么依赖不可靠的小规模代理实验，要么需要昂贵的大规模探索，缺乏高效准确的混合比例确定方法。

Method: DeMix框架训练候选数据集上的组件模型，然后通过加权模型合并推导数据混合代理，将搜索与训练成本解耦，无需为每个采样混合训练新模型即可评估无限混合方案。

Result: 实验表明DeMix打破了充分性、准确性和效率之间的权衡，以更低搜索成本获得更高基准性能的最优混合，并发布了包含22T高质量预训练数据的DeMix Corpora数据集。

Conclusion: DeMix通过模型合并预测数据混合比例，为LLM预训练数据混合优化提供了高效准确的解决方案，促进了开放研究。

Abstract: Determining an effective data mixture is a key factor in Large Language Model (LLM) pre-training, where models must balance general competence with proficiency on hard tasks such as math and code. However, identifying an optimal mixture remains an open challenge, as existing approaches either rely on unreliable tiny-scale proxy experiments or require prohibitively expensive large-scale exploration. To address this, we propose Decouple Searching from Training Mix (DeMix), a novel framework that leverages model merging to predict optimal data ratios. Instead of training proxy models for every sampled mixture, DeMix trains component models on candidate datasets at scale and derives data mixture proxies via weighted model merging. This paradigm decouples search from training costs, enabling evaluation of unlimited sampled mixtures without extra training burden and thus facilitating better mixture discovery through more search trials. Extensive experiments demonstrate that DeMix breaks the trade-off between sufficiency, accuracy and efficiency, obtaining the optimal mixture with higher benchmark performance at lower search cost. Additionally, we release the DeMix Corpora, a comprehensive 22T-token dataset comprising high-quality pre-training data with validated mixtures to facilitate open research. Our code and DeMix Corpora is available at https://github.com/Lucius-lsr/DeMix.

</details>


### [314] [Temporal Leakage in Search-Engine Date-Filtered Web Retrieval: A Case Study from Retrospective Forecasting](https://arxiv.org/abs/2602.00758)
*Ali El Lahib,Ying-Jieh Xia,Zehan Li,Yuxuan Wang,Xinyu Pi*

Main category: cs.CL

TL;DR: 搜索引擎日期过滤器在检索增强预测器的回顾性评估中不可靠，71%的查询会返回包含截止日期后信息的页面，导致预测准确性被夸大


<details>
  <summary>Details</summary>
Motivation: 当前广泛使用搜索引擎日期过滤器进行回顾性评估，但这种方法可能存在信息泄露问题，导致预测结果不可靠

Method: 通过审计Google搜索的before过滤器，分析信息泄露机制；使用大型语言模型(gpt-oss-120b)在有泄露和无泄露文档条件下进行预测对比

Result: 71%的问题至少返回一个包含强后截止日期泄露的页面，41%的问题至少有一个页面直接揭示答案；使用泄露文档时预测准确性被夸大(Brier分数0.108 vs 0.242)

Conclusion: 日期限制搜索不足以进行时间评估，建议采用更强的检索保障措施或在冻结的时间戳网络快照上进行评估，以确保回顾性预测的可信度

Abstract: Search-engine date filters are widely used to enforce pre-cutoff retrieval in retrospective evaluations of search-augmented forecasters. We show this approach is unreliable: auditing Google Search with a before: filter, 71% of questions return at least one page containing strong post-cutoff leakage, and for 41%, at least one page directly reveals the answer. Using a large language model (LLM), gpt-oss-120b, to forecast with these leaky documents, we demonstrate an inflated prediction accuracy (Brier score 0.108 vs. 0.242 with leak-free documents). We characterize common leakage mechanisms, including updated articles, related-content modules, unreliable metadata/timestamps, and absence-based signals, and argue that date-restricted search is insufficient for temporal evaluation. We recommend stronger retrieval safeguards or evaluation on frozen, time-stamped web snapshots to ensure credible retrospective forecasting.

</details>


### [315] [Adaptive Ability Decomposing for Unlocking Large Reasoning Model Effective Reinforcement Learning](https://arxiv.org/abs/2602.00759)
*Zhipeng Chen,Xiaobo Qin,Wayne Xin Zhao,Youbin Wu,Ji-Rong Wen*

Main category: cs.CL

TL;DR: A²D方法通过自适应能力分解增强RLVR效果，先训练分解器将复杂问题分解为简单子问题，再用子问题指导训练推理器，提升探索和利用能力。


<details>
  <summary>Details</summary>
Motivation: 传统RLVR过程信息有限，导致模型只能进行盲目探索，在复杂问题上容易失败。需要在不依赖教师模型的情况下为RLVR提供额外信息。

Method: 提出A²D自适应能力分解方法：1）先通过RLVR训练分解器，使其能将复杂问题分解为简单子问题；2）用分解器为训练数据标注子问题；3）在子问题指导下用RLVR训练推理器。

Result: 方法在性能上优于竞争基线，可作为即插即用模块应用于不同RLVR算法。分析显示RLVR过程影响分解器性能和行为，特定类型的指导能更好增强推理器的探索和利用能力。

Conclusion: A²D通过自适应能力分解有效增强RLVR效果，提供了一种不依赖教师模型就能为RLVR过程提供额外信息的方法，显著提升模型在复杂问题上的表现。

Abstract: Reinforcement learning with verifiable rewards (RLVR) has shown great potential to enhance the reasoning ability of large language models (LLMs). However, due to the limited amount of information provided during the RLVR process, the model can only engage in largely blind exploration, which often results in failure on challenging problems. To provide additional information for the RLVR process without relying on a teacher model, we propose A$^2$D, an Adaptive Ability Decomposing method for enhancing the effectiveness of RLVR. Specifically, we first train a decomposer via RLVR without distillation, enabling it to decompose complex questions into a set of simpler sub-questions. Next, we use this decomposer to annotate sub-questions for each question in the training dataset, and then train the reasoner under RLVR with sub-question guidance. To better understand A$^2$D, we first compare its performance with competitive baselines, showing its effectiveness. Next, we observe that our method functions as a plug-and-play module that can be applied to different RLVR algorithms. Furthermore, we conduct an analysis of the decomposer, revealing how the RLVR process affects its performance and behavior, and which type of guidance is better suited for enhancing the reasoner's exploration and exploitation abilities.

</details>


### [316] [APR: Penalizing Structural Redundancy in Large Reasoning Models via Anchor-based Process Rewards](https://arxiv.org/abs/2602.00760)
*Kaiyan Chang,Chenwei Zhu,Yingfeng Luo,Yifu Huo,Chenglong Wang,Xiaoqian Liu,Qiaozhi He,Tong Xiao,Zhengtao Yu,Jingbo Zhu*

Main category: cs.CL

TL;DR: 论文提出Anchor-based Process Reward (APR)方法，通过定位推理锚点并惩罚锚点后的冗余验证，解决大推理模型在测试时扩展中出现的"过度思考"问题，在保持性能的同时显著提升效率。


<details>
  <summary>Details</summary>
Motivation: 测试时扩展(TTS)显著增强了大推理模型(LRMs)的能力，但引入了"过度思考"的副作用。研究发现LRMs在推理过程中经常进行重复的自我验证，即使在得到最终答案后也不修改。这种锚点后的冗余验证造成了计算资源的浪费。

Method: 提出Anchor-based Process Reward (APR)方法：首先定位"推理锚点"（答案首次稳定的位置），然后专门惩罚锚点后的"答案稳定尾部"（AST）——即无意义的重复验证。该方法利用适合长度惩罚的策略优化算法进行训练。

Result: APR方法在1.5B和7B规模的五个数学推理数据集上实现了性能-效率的帕累托前沿，同时显著减少了强化学习训练所需的计算资源。

Conclusion: 通过精细分析推理锚点前后的行为，揭示了LRMs中的结构冗余问题。提出的APR方法通过局部化惩罚冗余验证，有效解决了过度思考问题，在保持模型性能的同时大幅提升了推理效率。

Abstract: Test-Time Scaling (TTS) has significantly enhanced the capabilities of Large Reasoning Models (LRMs) but introduces a critical side-effect known as Overthinking. We conduct a preliminary study to rethink this phenomenon from a fine-grained perspective. We observe that LRMs frequently conduct repetitive self-verification without revision even after obtaining the final answer during the reasoning process. We formally define this specific position where the answer first stabilizes as the Reasoning Anchor. By analyzing pre- and post-anchor reasoning behaviors, we uncover the structural redundancy fixed in LRMs: the meaningless repetitive verification after deriving the first complete answer, which we term the Answer-Stable Tail (AST). Motivated by this observation, we propose Anchor-based Process Reward (APR), a structure-aware reward shaping method that localizes the reasoning anchor and penalizes exclusively the post-anchor AST. Leveraging the policy optimization algorithm suitable for length penalties, our APR models achieved the performance-efficiency Pareto frontier at 1.5B and 7B scales averaged across five mathematical reasoning datasets while requiring significantly fewer computational resources for RL training.

</details>


### [317] [WordCraft: Scaffolding the Keyword Method for L2 Vocabulary Learning with Multimodal LLMs](https://arxiv.org/abs/2602.00762)
*Yuheng Shao,Junjie Xiong,Chaoran Wu,Xiyuan Wang,Ziyu Zhou,Yang Ouyang,Qinyi Tao,Quan Li*

Main category: cs.CL

TL;DR: WordCraft：基于多模态大语言模型的交互式工具，帮助中文母语英语学习者通过关键词法有效记忆词汇


<details>
  <summary>Details</summary>
Motivation: 中文母语英语学习者在应用关键词法记忆词汇时面临三大挑战：难以生成音韵合适的关键词、构建连贯联想、创造生动心理意象。现有方法要么完全自动化（牺牲学习者参与度），要么只关注结果（缺乏过程指导）。

Method: 首先进行形成性研究（N=18），了解学习者和教育者的困难与需求。基于此开发WordCraft——一个以学习者为中心、基于多模态大语言模型的交互式工具，通过引导学习者完成关键词选择、联想构建和意象形成三个步骤来支持关键词法。

Result: 两项用户研究表明，WordCraft不仅保留了生成效应，而且在有效性和可用性方面都达到了高水平。

Conclusion: WordCraft成功解决了中文母语英语学习者在词汇记忆中的关键挑战，通过过程导向的交互式引导，提高了关键词法的应用效果。

Abstract: Applying the keyword method for vocabulary memorization remains a significant challenge for L1 Chinese-L2 English learners. They frequently struggle to generate phonologically appropriate keywords, construct coherent associations, and create vivid mental imagery to aid long-term retention. Existing approaches, including fully automated keyword generation and outcome-oriented mnemonic aids, either compromise learner engagement or lack adequate process-oriented guidance. To address these limitations, we conducted a formative study with L1 Chinese-L2 English learners and educators (N=18), which revealed key difficulties and requirements in applying the keyword method to vocabulary learning. Building on these insights, we introduce WordCraft, a learner-centered interactive tool powered by Multimodal Large Language Models (MLLMs). WordCraft scaffolds the keyword method by guiding learners through keyword selection, association construction, and image formation, thereby enhancing the effectiveness of vocabulary memorization. Two user studies demonstrate that WordCraft not only preserves the generation effect but also achieves high levels of effectiveness and usability.

</details>


### [318] [Eliciting Trustworthiness Priors of Large Language Models via Economic Games](https://arxiv.org/abs/2602.00769)
*Siyu Yan,Lusha Zhu,Jian-Qiao Zhu*

Main category: cs.CL

TL;DR: 本文提出了一种基于迭代上下文学习的方法来从大语言模型中引出信任先验，发现GPT-4.1的信任先验与人类相似，并探索了模型如何基于智能体特征区分信任。


<details>
  <summary>Details</summary>
Motivation: 构建以人为本、可信赖的人工智能系统需要保持校准的信任，但如何表征AI系统自身的信任水平是一个根本性挑战。本文旨在开发一种方法来引出AI系统的信任先验。

Method: 提出基于迭代上下文学习的新颖引出方法，应用于行为博弈论中的信任游戏来引出信任先验。该方法使用多个领先的大语言模型，并进一步分析GPT-4.1对不同玩家角色的响应。

Result: GPT-4.1的信任先验与人类观察到的信任先验高度一致。模型能够基于智能体特征区分信任，且引出的信任变化可以通过基于感知温暖和能力的刻板印象模型很好地预测。

Conclusion: 该方法成功地从大语言模型中引出信任先验，GPT-4.1展现出与人类相似的信任模式，为理解AI系统的信任表征和构建更可信赖的AI系统提供了重要基础。

Abstract: One critical aspect of building human-centered, trustworthy artificial intelligence (AI) systems is maintaining calibrated trust: appropriate reliance on AI systems outperforms both overtrust (e.g., automation bias) and undertrust (e.g., disuse). A fundamental challenge, however, is how to characterize the level of trust exhibited by an AI system itself. Here, we propose a novel elicitation method based on iterated in-context learning (Zhu and Griffiths, 2024a) and apply it to elicit trustworthiness priors using the Trust Game from behavioral game theory. The Trust Game is particularly well suited for this purpose because it operationalizes trust as voluntary exposure to risk based on beliefs about another agent, rather than self-reported attitudes. Using our method, we elicit trustworthiness priors from several leading large language models (LLMs) and find that GPT-4.1's trustworthiness priors closely track those observed in humans. Building on this result, we further examine how GPT-4.1 responds to different player personas in the Trust Game, providing an initial characterization of how such models differentiate trust across agent characteristics. Finally, we show that variation in elicited trustworthiness can be well predicted by a stereotype-based model grounded in perceived warmth and competence.

</details>


### [319] [Reasoning as State Transition: A Representational Analysis of Reasoning Evolution in Large Language Models](https://arxiv.org/abs/2602.00770)
*Siyuan Zhang,Jialian Li,Yichi Zhang,Xiao Yang,Yinpeng Dong,Hang Su*

Main category: cs.CL

TL;DR: 该论文通过表征视角研究大语言模型在训练过程中推理能力的演化，发现后训练仅带来有限的初始表征质量提升，但能驱动推理过程中表征分布向更优方向转变，这种转变主要由生成token的语义而非额外计算驱动。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要通过显式生成结果分析LLM推理能力的演化，将推理过程视为黑盒，无法揭示内部变化。为了解构这种不透明性，作者引入表征视角来研究模型内部状态的动态变化。

Method: 采用表征视角，在不同训练阶段的模型上进行综合实验，分析内部状态动态。通过比较分析、统计分析和反事实实验，研究后训练对表征分布转变的影响，并探究内部状态与外部输出的关系。

Result: 1) 后训练仅带来有限的静态初始表征质量提升；2) 推理过程涉及显著的连续表征分布转变；3) 后训练使模型能够驱动这种转变向更优的任务解决分布；4) 生成正确性与最终表征高度相关；5) 生成token的语义是分布转变的主要驱动力。

Conclusion: 该研究提供了对推理过程及训练对推理增强影响的新理解，为未来模型分析和优化提供了有价值的见解，强调了表征动态在理解LLM推理能力中的重要性。

Abstract: Large Language Models have achieved remarkable performance on reasoning tasks, motivating research into how this ability evolves during training. Prior work has primarily analyzed this evolution via explicit generation outcomes, treating the reasoning process as a black box and obscuring internal changes. To address this opacity, we introduce a representational perspective to investigate the dynamics of the model's internal states. Through comprehensive experiments across models at various training stages, we discover that post-training yields only limited improvement in static initial representation quality. Furthermore, we reveal that, distinct from non-reasoning tasks, reasoning involves a significant continuous distributional shift in representations during generation. Comparative analysis indicates that post-training empowers models to drive this transition toward a better distribution for task solving. To clarify the relationship between internal states and external outputs, statistical analysis confirms a high correlation between generation correctness and the final representations; while counterfactual experiments identify the semantics of the generated tokens, rather than additional computation during inference or intrinsic parameter differences, as the dominant driver of the transition. Collectively, we offer a novel understanding of the reasoning process and the effect of training on reasoning enhancement, providing valuable insights for future model analysis and optimization.

</details>


### [320] [HyLRA: Hybrid Layer Reuse Attention for Efficient Long-Context Inference](https://arxiv.org/abs/2602.00777)
*Xuan Ai,Qingqing Yang,Peng Wang,Lei Deng,Lin Zhang,Renhai Chen,Gong Zhang*

Main category: cs.CL

TL;DR: HyLRA是一种基于层间稀疏性分析的混合注意力机制，通过动态规划确定最优层策略，在敏感层保留完整注意力，在容忍层重用前层关键token索引，显著提升长上下文推理效率。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型的长上下文推理面临注意力机制二次计算复杂度和KV缓存内存占用大的瓶颈。现有稀疏注意力方法依赖固定模式或激进剪枝，无法在效率和准确性之间达到最优平衡。

Method: 基于层间稀疏性分析，发现注意力机制的双重特性：层内敏感性和层间相似性。采用离线动态规划方法确定最优层策略，敏感层保留完整注意力，容忍层重用前层top-k关键token索引，避免二次计算。

Result: HyLRA将推理吞吐量提升6%-46%，同时保持可比较的性能（准确率下降<1%），在各种评估中一致优于最先进的稀疏注意力方法。

Conclusion: HyLRA通过层间混合注意力策略有效解决了长上下文推理的计算瓶颈，在保持模型准确性的同时显著提升效率，为大规模语言模型推理提供了实用的优化方案。

Abstract: Long-context inference in Large Language Models (LLMs) is bottlenecked by the quadratic computation complexity of attention and the substantial memory footprint of Key-Value (KV) caches. While existing sparse attention mechanisms attempt to mitigate this by exploiting inherent sparsity, they often rely on rigid patterns or aggressive pruning, failing to achieve an optimal balance between efficiency and accuracy. In this paper, we introduce {\bf HyLRA} ({\bf Hy}brid {\bf L}ayer {\bf R}euse {\bf A}ttention), a novel framework driven by layer-wise sparsity profiling. Our empirical analysis uncovers a dual characteristic in attention mechanics: \textit{intra-layer sensitivity}, where specific layers necessitate full attention to prevent feature distortion, and \textit{inter-layer similarity}, where consecutive layers share substantial critical tokens. Based on these observations, HyLRA employs an offline dynamic programming approach to derive an optimal layer-wise policy. This hybrid strategy retains full attention for sensitive layers to ensure robustness, while enabling tolerant layers to bypass quadratic calculations by directly reusing top-$k$ indices from preceding layers. This approach allows LLMs to restrict computation to the most critical tokens, effectively overcoming the quadratic bottleneck of dense attention. Extensive evaluations demonstrate that HyLRA improves inference throughput by 6\%--46\% while maintaining comparable performance (with $<1\%$ accuracy degradation), consistently outperforming state-of-the-art sparse attention methods. HyLRA is open source at \href{https://anonymous.4open.science/r/unified-cache-management-CF80/}{\texttt{/r/unified-cache-management-CF80/}}

</details>


### [321] [Omni-RRM: Advancing Omni Reward Modeling via Automatic Rubric-Grounded Preference Synthesis](https://arxiv.org/abs/2602.00846)
*Zicheng Kong,Dehua Ma,Zhenbo Xu,Alven Yang,Yiwei Ru,Haoran Wang,Zixuan Zhou,Fuqing Bie,Liuyu Xiang,Huijia Wu,Jian Zhao,Zhaofeng He*

Main category: cs.CL

TL;DR: Omni-RRM是首个开源的多模态奖励模型，通过自动化流程生成结构化多维度偏好判断，在视频和音频基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型的性能受限于粗糙的对齐技术，关键瓶颈在于缺乏有效的奖励模型：现有RM主要是视觉中心、返回不透明的标量分数，且依赖昂贵的人工标注。

Method: 1) 构建Omni-Preference数据集：通过自动化流程合成候选响应对，使用强教师模型协调和过滤偏好，并提供模态感知的基于量规的理由；2) 两阶段训练：监督微调学习基于量规的输出，然后通过强化学习（GRPO）提高对困难低对比度对的判别能力。

Result: Omni-RRM在视频基准（ShareGPT-V上80.2%）和音频基准（Audio-HH-RLHF上66.8%）达到SOTA准确率，在图像任务上显著优于现有开源RM，比基础模型整体准确率提升17.7%。

Conclusion: Omni-RRM是首个开源的多模态奖励模型，通过自动化数据生成和两阶段训练，实现了结构化多维度偏好判断，显著提升了多模态对齐性能，且无需人工标注偏好数据。

Abstract: Multimodal large language models (MLLMs) have shown remarkable capabilities, yet their performance is often capped by the coarse nature of existing alignment techniques. A critical bottleneck remains the lack of effective reward models (RMs): existing RMs are predominantly vision-centric, return opaque scalar scores, and rely on costly human annotations. We introduce \textbf{Omni-RRM}, the first open-source rubric-grounded reward model that produces structured, multi-dimension preference judgments with dimension-wise justifications across \textbf{text, image, video, and audio}. At the core of our approach is \textbf{Omni-Preference}, a large-scale dataset built via a fully automated pipeline: we synthesize candidate response pairs by contrasting models of different capabilities, and use strong teacher models to \emph{reconcile and filter} preferences while providing a modality-aware \emph{rubric-grounded rationale} for each pair. This eliminates the need for human-labeled training preferences. Omni-RRM is trained in two stages: supervised fine-tuning to learn the rubric-grounded outputs, followed by reinforcement learning (GRPO) to sharpen discrimination on difficult, low-contrast pairs. Comprehensive evaluations show that Omni-RRM achieves state-of-the-art accuracy on video (80.2\% on ShareGPT-V) and audio (66.8\% on Audio-HH-RLHF) benchmarks, and substantially outperforms existing open-source RMs on image tasks, with a 17.7\% absolute gain over its base model on overall accuracy. Omni-RRM also improves downstream performance via Best-of-$N$ selection and transfers to text-only preference benchmarks. Our data, code, and models are available at https://anonymous.4open.science/r/Omni-RRM-CC08.

</details>


### [322] [Factuality on Demand: Controlling the Factuality-Informativeness Trade-off in Text Generation](https://arxiv.org/abs/2602.00848)
*Ziwei Gong,Yanda Chen,Julia Hirschberg,Chen Zhao,He He,Zhou Yu,Kathleen Mckeown*

Main category: cs.CL

TL;DR: 提出Factuality-Controlled Generation框架，让用户能在查询时指定事实性约束，通过合成数据训练模型，平衡信息性和事实性


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在生成响应时面临信息性和事实性的权衡：要么生成信息较少但高度准确的内容，要么生成信息丰富但可能不够准确的内容。不同应用场景需要不同的平衡点，因此需要一种能让用户控制事实性水平的框架。

Method: 提出Factuality-Controlled Generation框架，允许用户在查询时指定事实性约束。使用合成数据训练模型，通过两个维度评估性能：事实性约束的遵守程度和响应的信息性。

Result: 合成训练显著提高了模型在遵守事实性要求的同时保持输出信息性的能力。

Conclusion: FCG框架有效解决了LLM在信息性和事实性之间的权衡问题，通过用户指定的约束和合成数据训练，能够更好地满足不同应用场景的需求。

Abstract: Large language models (LLMs) encode knowledge with varying degrees of confidence. When responding to queries, models face an inherent trade-off: they can generate responses that are less informative but highly factual, or more informative but potentially less accurate. Different applications demand different balances between informativeness and factuality. We introduce Factuality-Controlled Generation (FCG), a framework that enables users to specify factuality constraints alongside their queries. We propose to evaluate FCG performance on two dimensions: adherence to factuality constraints and response informativeness. We propose to train models on the FCG task using synthetic data, and show that our synthetic training significantly improves models' ability to both respect factuality requirements and maintain informativeness in their outputs.

</details>


### [323] [Unifying Adversarial Robustness and Training Across Text Scoring Models](https://arxiv.org/abs/2602.00857)
*Manveer Singh Tamber,Hosna Oyarhoseini,Jimmy Lin*

Main category: cs.CL

TL;DR: 本文提出统一文本评分模型（包括密集检索器、重排序器和奖励模型）的对抗鲁棒性研究框架，开发了新的对抗训练方法，并在RLHF中展示了实用价值。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型的对抗鲁棒性研究在不同应用和攻击方式上碎片化，掩盖了共享的漏洞。需要统一研究文本评分模型的对抗鲁棒性，包括密集检索器、重排序器和奖励模型。

Method: 提出统一的文本评分模型对抗鲁棒性研究框架，基于"文本评分失败可直接测试"的原则（无关文本得分高于相关文本即为攻击成功）。开发了多种对抗训练方法，并展示了组合不同训练方法的效果。

Result: 当前语言模型的对抗训练方法往往短视，无法有效跨攻击泛化。新提出的对抗训练方法能产生强大的鲁棒性，同时提高任务效果。在RLHF中，对抗训练的奖励模型能减轻奖励黑客攻击，支持训练更好对齐的LLM。

Conclusion: 通过统一的文本评分模型视角研究对抗鲁棒性，开发了有效的对抗训练方法，这些方法不仅能提高模型鲁棒性，还能改善任务性能，在RLHF等实际应用中具有重要价值。

Abstract: Research on adversarial robustness in language models is currently fragmented across applications and attacks, obscuring shared vulnerabilities. In this work, we propose unifying the study of adversarial robustness in text scoring models spanning dense retrievers, rerankers, and reward models. This motivates adapting both attacks and adversarial training methods across model roles. Unlike open-ended generation, text scoring failures are directly testable: an attack succeeds when an irrelevant or rejected text outscores a relevant or chosen one. Using this principled lens of text scoring, we demonstrate that current adversarial training formulations for language models are often short-sighted, failing to effectively generalize across attacks. To address this, we introduce multiple adversarial training methods for text scoring models and show that combining complementary training methods can yield strong robustness while also improving task effectiveness. We also highlight the practical value of our approach for RLHF, showing that our adversarially trained reward models mitigate reward hacking and support the training of better-aligned LLMs. We provide our code and models for further study.

</details>


### [324] [ILSIC: Corpora for Identifying Indian Legal Statutes from Queries by Laypeople](https://arxiv.org/abs/2602.00881)
*Shounak Paul,Raghav Dogra,Pawan Goyal,Saptarshi Ghosh*

Main category: cs.CL

TL;DR: 本文创建了ILSIC语料库，包含印度法律中500+法条的普通人查询和法庭判决，用于比较法庭与普通人数据在法律条文识别任务中的差异，并进行了多种实验验证。


<details>
  <summary>Details</summary>
Motivation: 法律条文识别是法律NLP的基础任务，传统上使用法庭判决作为输入查询，但实际应用中输入通常是普通人提出的非正式查询。现有研究很少探索法庭数据与普通人数据在法律条文识别任务中的差异。

Method: 创建ILSIC语料库，包含500+印度法条的普通人查询和法庭判决；进行零样本和少样本推理、检索增强生成和监督微调等实验；分析模型在法庭数据和普通人数据上的表现差异。

Result: 纯法庭判决训练的模型在普通人查询上效果不佳；从法庭数据到普通人数据的迁移学习在某些场景下有益；对查询类别和法条频率进行了细粒度分析。

Conclusion: 法庭数据与普通人数据在法律条文识别任务中存在显著差异，需要专门针对普通人查询的数据集和方法；ILSIC语料库为相关研究提供了有价值的资源。

Abstract: Legal Statute Identification (LSI) for a given situation is one of the most fundamental tasks in Legal NLP. This task has traditionally been modeled using facts from court judgments as input queries, due to their abundance. However, in practical settings, the input queries are likely to be informal and asked by laypersons, or non-professionals. While a few laypeople LSI datasets exist, there has been little research to explore the differences between court and laypeople data for LSI. In this work, we create ILSIC, a corpus of laypeople queries covering 500+ statutes from Indian law. Additionally, the corpus also contains court case judgements to enable researchers to effectively compare between court and laypeople data for LSI. We conducted extensive experiments on our corpus, including benchmarking over the laypeople dataset using zero and few-shot inference, retrieval-augmented generation and supervised fine-tuning. We observe that models trained purely on court judgements are ineffective during test on laypeople queries, while transfer learning from court to laypeople data can be beneficial in certain scenarios. We also conducted fine-grained analyses of our results in terms of categories of queries and frequency of statutes.

</details>


### [325] [EffGen: Enabling Small Language Models as Capable Autonomous Agents](https://arxiv.org/abs/2602.00887)
*Gaurav Srivastava,Aafiya Hussain,Chi Wang,Yingyan Celine Lin,Xuan Wang*

Main category: cs.CL

TL;DR: effGen是一个专为小型语言模型优化的开源智能体框架，通过提示优化、任务分解、复杂度路由和统一内存系统，实现高效、安全的本地部署。


<details>
  <summary>Details</summary>
Motivation: 现有基于大型语言模型的智能体系统存在高token成本和隐私问题，特别是对于敏感应用。需要为小型语言模型设计优化的本地部署框架。

Method: 1) 通过提示优化压缩70-80%上下文；2) 智能任务分解为并行或顺序子任务；3) 基于五个因素的复杂度路由进行预执行决策；4) 统一内存系统结合短期、长期和向量存储；5) 统一多种智能体协议。

Result: 在13个基准测试中，effGen在成功率、执行速度和内存使用方面优于LangChain、AutoGen和Smolagents。提示优化对小型模型增益更大(1.5B模型11.2% vs 32B模型2.4%)，而路由对大型模型增益更大(1.5B模型3.6% vs 32B模型7.9%)。

Conclusion: effGen为小型语言模型提供了高效、安全的本地智能体框架，通过开源MIT许可证确保广泛的可访问性，解决了现有基于API的大型模型系统的成本和隐私限制。

Abstract: Most existing language model agentic systems today are built and optimized for large language models (e.g., GPT, Claude, Gemini) via API calls. While powerful, this approach faces several limitations including high token costs and privacy concerns for sensitive applications. We introduce effGen, an open-source agentic framework optimized for small language models (SLMs) that enables effective, efficient, and secure local deployment (pip install effgen). effGen makes four major contributions: (1) Enhanced tool-calling with prompt optimization that compresses contexts by 70-80% while preserving task semantics, (2) Intelligent task decomposition that breaks complex queries into parallel or sequential subtasks based on dependencies, (3) Complexity-based routing using five factors to make smart pre-execution decisions, and (4) Unified memory system combining short-term, long-term, and vector-based storage. Additionally, effGen unifies multiple agent protocols (MCP, A2A, ACP) for cross-protocol communication. Results on 13 benchmarks show effGen outperforms LangChain, AutoGen, and Smolagents with higher success rates, faster execution, and lower memory. Our results reveal that prompt optimization and complexity routing have complementary scaling behavior: optimization benefits SLMs more (11.2% gain at 1.5B vs 2.4% at 32B), while routing benefits large models more (3.6% at 1.5B vs 7.9% at 32B), providing consistent gains across all scales when combined. effGen (https://effgen.org/) is released under the MIT License, ensuring broad accessibility for research and commercial use. Our framework code is publicly available at https://github.com/ctrl-gaurav/effGen.

</details>


### [326] [Do Schwartz Higher-Order Values Help Sentence-Level Human Value Detection? When Hard Gating Hurts](https://arxiv.org/abs/2602.00913)
*Víctor Yeste,Paolo Rosso*

Main category: cs.CL

TL;DR: 研究在计算资源受限下，Schwartz高阶类别是否能为句子级人类价值检测提供可用结构，发现硬性层次约束会降低性能，而标签阈值调优和轻量集成更有效。


<details>
  <summary>Details</summary>
Motivation: 句子级人类价值检测通常被构建为对Schwartz价值的多标签分类，但Schwartz高阶类别是否提供可用结构尚不清楚。研究在严格的计算预算下（单8GB GPU）探索这一问题。

Method: 在ValueEval'24/ValuesML数据集上比较：(1)直接监督transformer；(2)使用硬掩码强制层次结构的HO→价值管道；(3)存在→HO→价值级联；同时测试低成本附加组件（词典、短上下文、主题）、标签阈值调优、小型指令调优LLM基线（≤10B）、QLoRA和简单集成。

Result: 高阶类别可从单句学习，但硬性层次门控不可靠，常通过错误累积和召回抑制降低最终任务的Macro-F1。标签阈值调优是高效杠杆（提升达+0.05 Macro-F1），小型transformer集成提供最一致的额外增益（达+0.02 Macro-F1）。小型LLM作为独立系统落后于监督编码器，但在跨家族集成中可贡献互补错误。

Conclusion: 高阶结构在描述上有用，但用硬门控强制实施会损害句子级价值检测；稳健的改进来自校准和轻量集成。

Abstract: Sentence-level human value detection is typically framed as multi-label classification over Schwartz values, but it remains unclear whether Schwartz higher-order (HO) categories provide usable structure. We study this under a strict compute-frugal budget (single 8 GB GPU) on ValueEval'24 / ValuesML (74K English sentences). We compare (i) direct supervised transformers, (ii) HO$\rightarrow$values pipelines that enforce the hierarchy with hard masks, and (iii) Presence$\rightarrow$HO$\rightarrow$values cascades, alongside low-cost add-ons (lexica, short context, topics), label-wise threshold tuning, small instruction-tuned LLM baselines ($\le$10B), QLoRA, and simple ensembles. HO categories are learnable from single sentences (e.g., the easiest bipolar pair reaches Macro-$F_1\approx0.58$), but hard hierarchical gating is not a reliable win: it often reduces end-task Macro-$F_1$ via error compounding and recall suppression. In contrast, label-wise threshold tuning is a high-leverage knob (up to $+0.05$ Macro-$F_1$), and small transformer ensembles provide the most consistent additional gains (up to $+0.02$ Macro-$F_1$). Small LLMs lag behind supervised encoders as stand-alone systems, yet can contribute complementary errors in cross-family ensembles. Overall, HO structure is useful descriptively, but enforcing it with hard gates hurts sentence-level value detection; robust improvements come from calibration and lightweight ensembling.

</details>


### [327] [A Baseline Multimodal Approach to Emotion Recognition in Conversations](https://arxiv.org/abs/2602.00914)
*Víctor Yeste,Rodrigo Rivas-Arévalo*

Main category: cs.CL

TL;DR: 提出一个轻量级多模态基线方法，用于对话情感识别，结合文本分类器和语音表示模型，采用简单后期融合策略


<details>
  <summary>Details</summary>
Motivation: 为SemEval-2024 Task 3任务提供一个可访问的参考实现，而不是追求新的SOTA方法，旨在支持未来更严格的比较

Method: 结合(i)基于Transformer的文本分类器和(ii)自监督语音表示模型，采用简单的后期融合集成策略

Result: 在有限训练协议下报告基线设置和实证结果，突出多模态融合何时优于单模态模型

Conclusion: 该预印本旨在提高透明度并支持未来的严格比较，提供了一个轻量级的多模态基线参考实现

Abstract: We present a lightweight multimodal baseline for emotion recognition in conversations using the SemEval-2024 Task 3 dataset built from the sitcom Friends. The goal of this report is not to propose a novel state-of-the-art method, but to document an accessible reference implementation that combines (i) a transformer-based text classifier and (ii) a self-supervised speech representation model, with a simple late-fusion ensemble. We report the baseline setup and empirical results obtained under a limited training protocol, highlighting when multimodal fusion improves over unimodal models. This preprint is provided for transparency and to support future, more rigorous comparisons.

</details>


### [328] [Neural FOXP2 -- Language Specific Neuron Steering for Targeted Language Improvement in LLMs](https://arxiv.org/abs/2602.00945)
*Anusa Saha,Tanmay Joshi,Vinija Jain,Aman Chadha,Amitava Das*

Main category: cs.CL

TL;DR: 提出Neural FOXP2方法，通过识别和操控语言神经元，使模型将特定语言（如印地语或西班牙语）设为主要语言，解决LLMs中英语主导而其他语言被抑制的问题。


<details>
  <summary>Details</summary>
Motivation: 虽然LLMs是多语言的，但由于预训练数据中英语占主导地位，模型默认倾向于英语，其他语言在参数记忆中但被系统性地抑制。需要一种机制来安全地调整语言偏好。

Method: Neural FOXP2三阶段方法：1) 定位：训练每层SAE分解激活，识别对目标语言（印地语/西班牙语）vs英语具有选择性的特征，追踪到语言神经元集合；2) 控制方向：通过谱低秩分析定位可控语言转移几何，构建激活差异矩阵并进行SVD提取主导方向；3) 操控：在低到中层应用带符号的稀疏激活偏移，沿目标语言主导方向正向偏移，对英语神经元进行补偿性负向偏移。

Result: 该方法能够识别出紧凑的语言神经元集合和可控的语言转移几何，通过稀疏激活偏移实现目标语言默认性的可控调整。

Conclusion: 语言默认性由稀疏、低秩的控制电路（语言神经元）控制，可以通过机械隔离和安全操控来调整，Neural FOXP2提供了一种系统方法来使特定语言成为模型的主要语言。

Abstract: LLMs are multilingual by training, yet their lingua franca is often English, reflecting English language dominance in pretraining. Other languages remain in parametric memory but are systematically suppressed. We argue that language defaultness is governed by a sparse, low-rank control circuit, language neurons, that can be mechanistically isolated and safely steered.
  We introduce Neural FOXP2, that makes a chosen language (Hindi or Spanish) primary in a model by steering language-specific neurons. Neural FOXP2 proceeds in three stages: (i) Localize: We train per-layer SAEs so each activation decomposes into a small set of active feature components. For every feature, we quantify English vs. Hindi/Spanish selectivity overall logit-mass lift toward the target-language token set. Tracing the top-ranked features back to their strongest contributing units yields a compact language-neuron set. (ii) Steering directions: We localize controllable language-shift geometry via a spectral low-rank analysis. For each layer, we build English to target activation-difference matrices and perform layerwise SVD to extract the dominant singular directions governing language change. The eigengap and effective-rank spectra identify a compact steering subspace and an empirically chosen intervention window (where these directions are strongest and most stable). (iii) Steer: We apply a signed, sparse activation shift targeted to the language neurons. Concretely, within low to mid layers we add a positive steering along the target-language dominant directions and a compensating negative shift toward the null space for the English neurons, yielding controllable target-language defaultness.

</details>


### [329] [Verification Required: The Impact of Information Credibility on AI Persuasion](https://arxiv.org/abs/2602.00970)
*Saaduddin Mahmud,Eugene Bagdasarian,Shlomo Zilberstein*

Main category: cs.CL

TL;DR: 论文提出MixTalk战略通信游戏，用于评估LLM代理在概率可信度信息下的战略通信能力，并开发TOPD方法提升接收方鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注不可验证的廉价谈话或完全可验证的披露，未能捕捉现实世界中信息具有概率可信度的场景。LLM代理在战略通信环境中的部署需要更符合实际的可信度建模。

Method: 引入MixTalk战略通信游戏，发送方策略性地组合可验证和不可验证的声明，接收方分配有限预算进行成本验证。提出TOPD方法，从交互日志中提炼锦标赛最优策略并在推理时部署。

Result: 在三个现实部署设置的大规模锦标赛中评估了最先进的LLM代理，揭示了它们在信息可信度推理方面的优势和局限。TOPD方法显著提高了接收方对说服的鲁棒性。

Conclusion: MixTalk为LLM代理的战略通信提供了更现实的评估框架，TOPD方法展示了通过离线策略提炼提升代理鲁棒性的潜力，为高风险决策环境中的LLM部署提供了重要见解。

Abstract: Agents powered by large language models (LLMs) are increasingly deployed in settings where communication shapes high-stakes decisions, making a principled understanding of strategic communication essential. Prior work largely studies either unverifiable cheap-talk or fully verifiable disclosure, failing to capture realistic domains in which information has probabilistic credibility. We introduce MixTalk, a strategic communication game for LLM-to-LLM interaction that models information credibility. In MixTalk, a sender agent strategically combines verifiable and unverifiable claims to communicate private information, while a receiver agent allocates a limited budget to costly verification and infers the underlying state from prior beliefs, claims, and verification outcomes. We evaluate state-of-the-art LLM agents in large-scale tournaments across three realistic deployment settings, revealing their strengths and limitations in reasoning about information credibility and the explicit behavior that shapes these interactions. Finally, we propose Tournament Oracle Policy Distillation (TOPD), an offline method that distills tournament oracle policy from interaction logs and deploys it in-context at inference time. Our results show that TOPD significantly improves receiver robustness to persuasion.

</details>


### [330] [Trust in One Round: Confidence Estimation for Large Language Models via Structural Signals](https://arxiv.org/abs/2602.00977)
*Pengyue Yang,Jiawen Wen,Haolin Jin,Linghan Huang,Huaming Chen,Ling Chen*

Main category: cs.CL

TL;DR: 提出Structural Confidence框架，通过分析LLM最后一层隐藏状态轨迹的多尺度结构信号，实现单次前向传播的置信度估计，在分布偏移和领域专用文本中表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: LLM在错误代价高的领域部署时，传统置信度估计方法（如token似然度、语义相似度、多样本一致性）在分布偏移、领域专用文本和计算限制下表现脆弱，需要更鲁棒的置信度估计框架。

Method: 提出Structural Confidence框架，从模型最后一层隐藏状态轨迹中提取多尺度结构信号，包括频谱特征、局部变化描述符和全局形状描述符，捕捉概率和句子嵌入忽略的内部稳定性模式。

Result: 在四个异构基准测试（FEVER、SciFact、WikiBio-hallucination、TruthfulQA）上进行跨领域评估，在AUROC和AUPR指标上优于现有基线方法，且仅需单次确定性前向传播。

Conclusion: Structural Confidence框架为资源受限的LLM应用提供了高效、鲁棒的事后置信度估计基础，相比需要多次随机生成和辅助模型的采样一致性方法更具实用性。

Abstract: Large language models (LLMs) are increasingly deployed in domains where errors carry high social, scientific, or safety costs. Yet standard confidence estimators, such as token likelihood, semantic similarity and multi-sample consistency, remain brittle under distribution shift, domain-specialised text, and compute limits. In this work, we present Structural Confidence, a single-pass, model-agnostic framework that enhances output correctness prediction based on multi-scale structural signals derived from a model's final-layer hidden-state trajectory. By combining spectral, local-variation, and global shape descriptors, our method captures internal stability patterns that are missed by probabilities and sentence embeddings. We conduct extensive, cross-domain evaluation across four heterogeneous benchmarks-FEVER (fact verification), SciFact (scientific claims), WikiBio-hallucination (biographical consistency), and TruthfulQA (truthfulness-oriented QA). Our Structural Confidence framework demonstrates strong performance compared with established baselines in terms of AUROC and AUPR. More importantly, unlike sampling-based consistency methods which require multiple stochastic generations and an auxiliary model, our approach uses a single deterministic forward pass, offering a practical basis for efficient, robust post-hoc confidence estimation in socially impactful, resource-constrained LLM applications.

</details>


### [331] [MedSpeak: A Knowledge Graph-Aided ASR Error Correction Framework for Spoken Medical QA](https://arxiv.org/abs/2602.00981)
*Yutong Song,Shiva Shrestha,Chenhan Lyu,Elahe Khatibi,Pengfei Zhang,Honghui Xu,Nikil Dutt,Amir Rahmani*

Main category: cs.CL

TL;DR: MedSpeak：基于知识图谱的ASR错误校正框架，通过结合医学知识图谱的语义关系和语音信息，提升医学术语识别准确性和医疗口语问答性能。


<details>
  <summary>Details</summary>
Motivation: 基于自动语音识别（ASR）的口语问答系统在医学术语识别上存在准确性问题，这影响了医疗口语问答的整体性能。

Method: 提出MedSpeak框架，利用医学知识图谱编码的语义关系和语音信息，结合大语言模型的推理能力，对噪声转录进行校正并改进下游答案预测。

Result: 在基准测试中，MedSpeak显著提高了医学术语识别准确性和整体医疗口语问答性能，成为该领域的先进解决方案。

Conclusion: MedSpeak通过知识图谱辅助的ASR错误校正，有效解决了医疗口语问答中的术语识别问题，为医疗SQA提供了有效的解决方案。

Abstract: Spoken question-answering (SQA) systems relying on automatic speech recognition (ASR) often struggle with accurately recognizing medical terminology. To this end, we propose MedSpeak, a novel knowledge graph-aided ASR error correction framework that refines noisy transcripts and improves downstream answer prediction by leveraging both semantic relationships and phonetic information encoded in a medical knowledge graph, together with the reasoning power of LLMs. Comprehensive experimental results on benchmarks demonstrate that MedSpeak significantly improves the accuracy of medical term recognition and overall medical SQA performance, establishing MedSpeak as a state-of-the-art solution for medical SQA. The code is available at https://github.com/RainieLLM/MedSpeak.

</details>


### [332] [DISPO: Enhancing Training Efficiency and Stability in Reinforcement Learning for Large Language Model Mathematical Reasoning](https://arxiv.org/abs/2602.00983)
*Batuhan K. Karaman,Aditya Rawal,Suhaila Shakiah,Mohammad Ghavamzadeh,Mingyi Hong,Arijit Biswas,Ruida Zhou*

Main category: cs.CL

TL;DR: DISPO是一种新的强化学习算法，通过分离正确和错误响应的重要性采样权重裁剪，实现四个可控策略更新机制，在数学推理任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习方法在训练稳定性和学习效率之间存在权衡：PPO类方法稳定但学习慢，REINFORCE类方法效率高但不稳定。需要一种既能保持训练稳定性又能提高学习效率的方法。

Method: DISPO算法将正确和错误响应的重要性采样权重裁剪分离，形成四个可控策略更新机制：正确响应权重>1增加探索，<1增加蒸馏；错误响应权重>1导致重复输出，<1导致响应长度消失。通过分别调节这四个裁剪参数来平衡探索与蒸馏。

Result: 在AIME'24基准测试上达到61.04%准确率，优于CISPO的55.42%和DAPO的50.21%。在其他基准测试和模型上也取得类似提升。

Conclusion: DISPO通过解耦重要性采样权重裁剪，实现了探索与蒸馏的平衡，同时避免了灾难性失败，在数学推理任务上显著优于现有强化学习方法。

Abstract: Reinforcement learning with verifiable rewards has emerged as a promising paradigm for enhancing the reasoning capabilities of large language models particularly in mathematics. Current approaches in this domain present a clear trade-off: PPO-style methods (e.g., GRPO/DAPO) offer training stability but exhibit slow learning trajectories due to their trust-region constraints on policy updates, while REINFORCE-style approaches (e.g., CISPO) demonstrate improved learning efficiency but suffer from performance instability as they clip importance sampling weights while still permitting non-zero gradients outside the trust-region. To address these limitations, we introduce DISPO, a simple yet effective REINFORCE-style algorithm that decouples the up-clipping and down-clipping of importance sampling weights for correct and incorrect responses, yielding four controllable policy update regimes. Through targeted ablations, we uncover how each regime impacts training: for correct responses, weights >1 increase the average token entropy (i.e., exploration) while weights <1 decrease it (i.e., distillation) -- both beneficial but causing gradual performance degradation when excessive. For incorrect responses, overly restrictive clipping triggers sudden performance collapse through repetitive outputs (when weights >1) or vanishing response lengths (when weights <1). By separately tuning these four clipping parameters, DISPO maintains the exploration-distillation balance while preventing catastrophic failures, achieving 61.04% on AIME'24 (vs. 55.42% CISPO and 50.21% DAPO) with similar gains across various benchmarks and models.

</details>


### [333] [Sparse Reward Subsystem in Large Language Models](https://arxiv.org/abs/2602.00986)
*Guowei Xu,Mert Yuksekgonul,James Zou*

Main category: cs.CL

TL;DR: 在LLM隐藏状态中发现类似人脑奖励系统的稀疏奖励子系统，包含代表状态价值期望的价值神经元和编码奖励预测误差的多巴胺神经元


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型内部是否存在类似生物大脑的奖励处理机制，理解LLM推理过程中的内部价值表示和奖励预测机制

Method: 通过干预实验识别LLM隐藏状态中的价值神经元，分析其跨数据集、模型规模和架构的鲁棒性，并识别编码奖励预测误差的多巴胺神经元

Result: 发现价值神经元在推理中起关键作用，具有跨数据集、模型规模和架构的鲁棒性，且在同一基础模型微调的不同模型间可迁移；识别出编码奖励预测误差的多巴胺神经元

Conclusion: LLM内部存在类似生物大脑的稀疏奖励子系统，包含价值神经元和多巴胺神经元，这为理解LLM推理机制提供了新视角

Abstract: In this paper, we identify a sparse reward subsystem within the hidden states of Large Language Models (LLMs), drawing an analogy to the biological reward subsystem in the human brain. We demonstrate that this subsystem contains value neurons that represent the model's internal expectation of state value, and through intervention experiments, we establish the importance of these neurons for reasoning. Our experiments reveal that these value neurons are robust across diverse datasets, model scales, and architectures; furthermore, they exhibit significant transferability across different datasets and models fine-tuned from the same base model. By examining cases where value predictions and actual rewards diverge, we identify dopamine neurons within the reward subsystem which encode reward prediction errors (RPE). These neurons exhibit high activation when the reward is higher than expected and low activation when the reward is lower than expected.

</details>


### [334] [DeALOG: Decentralized Multi-Agents Log-Mediated Reasoning Framework](https://arxiv.org/abs/2602.00996)
*Abhijit Chakraborty,Ashish Raj Shekhar,Shiven Agarwal,Vivek Gupta*

Main category: cs.CL

TL;DR: DeALOG是一个用于多模态问答的去中心化多智能体框架，通过专业智能体协作和共享自然语言日志实现信息整合与错误验证。


<details>
  <summary>Details</summary>
Motivation: 跨文本、表格和图像的复杂问答需要整合多样化信息源，需要一个支持专业化处理、协调和可解释性的框架。

Method: 使用专业智能体（表格、上下文、视觉、总结和验证智能体），通过共享的自然语言日志作为持久内存进行通信，实现去中心化的协作错误检测和验证。

Result: 在FinQA、TAT-QA、CRT-QA、WikiTableQuestions、FeTaQA和MultiModalQA等多个数据集上表现出竞争力，验证了共享日志、智能体专业化和验证机制对准确性的重要性。

Conclusion: DeALOG通过模块化组件和自然语言通信提供了可扩展的多模态问答方法，实现了去中心化协作和鲁棒性提升。

Abstract: Complex question answering across text, tables and images requires integrating diverse information sources. A framework supporting specialized processing with coordination and interpretability is needed. We introduce DeALOG, a decentralized multi-agent framework for multimodal question answering. It uses specialized agents: Table, Context, Visual, Summarizing and Verification, that communicate through a shared natural-language log as persistent memory. This log-based approach enables collaborative error detection and verification without central control, improving robustness. Evaluations on FinQA, TAT-QA, CRT-QA, WikiTableQuestions, FeTaQA, and MultiModalQA show competitive performance. Analysis confirms the importance of the shared log, agent specialization, and verification for accuracy. DeALOG, provides a scalable approach through modular components using natural-language communication.

</details>


### [335] [Reliable Use of Lemmas via Eligibility Reasoning and Section$-$Aware Reinforcement Learning](https://arxiv.org/abs/2602.00998)
*Zhikun Xu,Xiaodong Yu,Ben Zhou,Jiang Liu,Jialian Wu,Ze Wang,Ximeng Sun,Hao Chen,Zicheng Liu*

Main category: cs.CL

TL;DR: 论文提出RULES方法，通过结构化预测任务训练LLMs进行引理判断，包含前提检查和结论效用检查两部分，使用强化学习和分段感知损失掩码提升鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在数学基准测试中表现良好，但经常误用引理，在没有验证假设的情况下直接应用结论。需要提升模型在引理判断方面的准确性和鲁棒性。

Method: 将引理判断形式化为结构化预测任务：给定陈述和候选引理，模型必须输出前提检查和结论效用检查。提出RULES方法，采用两段式输出结构，使用强化学习和分段感知损失掩码训练，仅对导致错误的部分施加惩罚。

Result: 在领域内任务上，RULES相比普通模型和单标签RL基线获得一致提升；在适用性破坏扰动上改进更大；在端到端任务上达到持平或适度提升。消融实验表明两段式输出和分段感知强化对鲁棒性都是必要的。

Conclusion: RULES方法通过结构化引理判断任务和分段感知训练机制，有效提升了LLMs在数学推理中应用引理的准确性和鲁棒性，为解决模型误用引理问题提供了有效方案。

Abstract: Recent large language models (LLMs) perform strongly on mathematical benchmarks yet often misapply lemmas, importing conclusions without validating assumptions. We formalize lemma$-$judging as a structured prediction task: given a statement and a candidate lemma, the model must output a precondition check and a conclusion$-$utility check, from which a usefulness decision is derived. We present RULES, which encodes this specification via a two$-$section output and trains with reinforcement learning plus section$-$aware loss masking to assign penalty to the section responsible for errors. Training and evaluation draw on diverse natural language and formal proof corpora; robustness is assessed with a held$-$out perturbation suite; and end$-$to$-$end evaluation spans competition$-$style, perturbation$-$aligned, and theorem$-$based problems across various LLMs. Results show consistent in$-$domain gains over both a vanilla model and a single$-$label RL baseline, larger improvements on applicability$-$breaking perturbations, and parity or modest gains on end$-$to$-$end tasks; ablations indicate that the two$-$section outputs and section$-$aware reinforcement are both necessary for robustness.

</details>


### [336] [Distilling Token-Trained Models into Byte-Level Models](https://arxiv.org/abs/2602.01007)
*Zishuo Bao,Jiaqi Leng,Junxiong Wang,Bowen Peng,Yucheng Lu*

Main category: cs.CL

TL;DR: 提出一种高效蒸馏方法，将现有基于token训练的LLMs转换为字节语言模型，仅需约125B字节数据即可保留原模型大部分能力


<details>
  <summary>Details</summary>
Motivation: 现有字节语言模型需要从头训练万亿字节数据，成本极高。本文旨在通过蒸馏方法将已有token训练的LLMs高效转换为字节模型，降低训练成本

Method: 采用两阶段课程学习：1) 渐进知识蒸馏，对齐字节级表示与token教师模型的嵌入；2) 字节级监督微调，实现完全在字节空间的端到端生成

Result: 在Llama、Qwen、OLMo等多个模型家族上验证，蒸馏后的字节语言模型仅使用约125B字节数据即可保留教师模型大部分性能

Conclusion: 提出了一种高效且经济的字节语言模型蒸馏方法，显著降低了从token模型转换到字节模型的训练成本，为字节语言模型的实用化提供了可行路径

Abstract: Byte Language Models (BLMs) have emerged as a promising direction for scaling language models beyond tokenization. However, existing BLMs typically require training from scratch on trillions of bytes, making them prohibitively expensive. In this paper, we propose an efficient distillation recipe that converts existing token-trained LLMs into BLMs while retaining comparable capabilities. Our recipe follows a two-stage curriculum: (1) Progressive Knowledge Distillation, which aligns byte-level representations with the embeddings of the token-trained teacher model; and (2) Byte-Level Supervised Fine-Tuning, which enables end-to-end generation entirely in the byte space. We validate our approach across multiple model families, including Llama, Qwen, and OLMo, and demonstrate that the distilled BLMs retain most of the teacher models' performance using only approximately 125B bytes.

</details>


### [337] [Large Language Models as Students Who Think Aloud: Overly Coherent, Verbose, and Confident](https://arxiv.org/abs/2602.01015)
*Conrad Borchers,Jill-Jênn Vie,Roger Azevedo*

Main category: cs.CL

TL;DR: LLMs模拟新手推理存在系统性偏差：过度连贯、冗长、缺乏变异性，且高估学习者表现，揭示了用LLMs模拟学习的认识论局限。


<details>
  <summary>Details</summary>
Motivation: 评估LLMs能否忠实模拟新手推理和元认知判断，现有评估过于关注解题准确性，忽略了人类学习中碎片化、不完美的推理过程。

Method: 使用630条化学辅导问题中的出声思考记录，比较LLM生成推理与人类学习者话语，评估模型预测学习者步骤级成功的能力，采用最小化和扩展上下文提示策略。

Result: GPT-4.1能生成流畅且上下文合适的延续，但其推理系统性过度连贯、冗长、变异性低于人类出声思考；学习者表现被持续高估；问题解决上下文越丰富，这些效应越强。

Conclusion: LLMs模拟学习存在认识论局限，源于训练数据缺乏情感表达和工作记忆约束；评估框架可指导未来自适应系统设计，更忠实地支持新手学习和自我调节。

Abstract: Large language models (LLMs) are increasingly embedded in AI-based tutoring systems. Can they faithfully model novice reasoning and metacognitive judgments? Existing evaluations emphasize problem-solving accuracy, overlooking the fragmented and imperfect reasoning that characterizes human learning. We evaluate LLMs as novices using 630 think-aloud utterances from multi-step chemistry tutoring problems with problem-solving logs of student hint use, attempts, and problem context. We compare LLM-generated reasoning to human learner utterances under minimal and extended contextual prompting, and assess the models' ability to predict step-level learner success. Although GPT-4.1 generates fluent and contextually appropriate continuations, its reasoning is systematically over-coherent, verbose, and less variable than human think-alouds. These effects intensify with a richer problem-solving context during prompting. Learner performance was consistently overestimated. These findings highlight epistemic limitations of simulating learning with LLMs. We attribute these limitations to LLM training data, including expert-like solutions devoid of expressions of affect and working memory constraints during problem solving. Our evaluation framework can guide future design of adaptive systems that more faithfully support novice learning and self-regulation using generative artificial intelligence.

</details>


### [338] [Bias in the Ear of the Listener: Assessing Sensitivity in Audio Language Models Across Linguistic, Demographic, and Positional Variations](https://arxiv.org/abs/2602.01030)
*Sheng-Lun Wei,Yu-Ling Liao,Yen-Hua Chang,Hen-Hsen Huang,Hsin-Hsi Chen*

Main category: cs.CL

TL;DR: 首次系统研究多语言MLLM中的语音偏见，构建BiasInEar数据集，评估九种模型在语言、口音、性别和选项顺序方面的偏见，发现MLLM对语言和选项顺序敏感，语音会放大现有结构偏见。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏对多语言MLLM中语音偏见的系统性研究，需要建立统一的评估框架来评估语音集成LLM的公平性和鲁棒性，填补文本和语音评估之间的差距。

Method: 构建BiasInEar数据集，基于Global MMLU Lite，涵盖英语、中文和韩语，平衡性别和口音，共70.8小时语音。使用四种互补指标（准确率、熵、APES和Fleiss' κ）评估九种代表性模型在语言、口音、性别和选项顺序扰动下的表现。

Result: MLLM对人口统计因素相对鲁棒，但对语言和选项顺序高度敏感，语音会放大现有结构偏见。架构设计和推理策略显著影响跨语言鲁棒性。

Conclusion: 本研究建立了评估语音集成LLM公平性和鲁棒性的统一框架，揭示了语音如何放大现有偏见，为未来更公平的MLLM设计提供了重要见解。

Abstract: This work presents the first systematic investigation of speech bias in multilingual MLLMs. We construct and release the BiasInEar dataset, a speech-augmented benchmark based on Global MMLU Lite, spanning English, Chinese, and Korean, balanced by gender and accent, and totaling 70.8 hours ($\approx$4,249 minutes) of speech with 11,200 questions. Using four complementary metrics (accuracy, entropy, APES, and Fleiss' $κ$), we evaluate nine representative models under linguistic (language and accent), demographic (gender), and structural (option order) perturbations. Our findings reveal that MLLMs are relatively robust to demographic factors but highly sensitive to language and option order, suggesting that speech can amplify existing structural biases. Moreover, architectural design and reasoning strategy substantially affect robustness across languages. Overall, this study establishes a unified framework for assessing fairness and robustness in speech-integrated LLMs, bridging the gap between text- and speech-based evaluation. The resources can be found at https://github.com/ntunlplab/BiasInEar.

</details>


### [339] [Personality Expression Across Contexts: Linguistic and Behavioral Variation in LLM Agents](https://arxiv.org/abs/2602.01063)
*Bin Han,Deuksin Kwon,Jonathan Gratch*

Main category: cs.CL

TL;DR: LLMs在相同人格提示下，会根据不同对话情境（破冰、谈判、群体决策、共情任务）产生不同的语言、行为和情感表现，显示出人格表达具有情境敏感性而非固定不变。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探究大型语言模型（LLMs）在相同人格提示条件下，其行为实现如何随对话情境变化而变化。虽然LLMs可以通过明确的人格提示进行条件设定，但实际行为表现常因上下文而异，这引发了对LLM人格表达一致性与适应性的思考。

Method: 研究方法包括在四种不同的对话情境中测试LLMs：破冰任务、谈判任务、群体决策任务和共情任务。所有情境都使用相同的人格提示，然后分析LLMs在这些情境中的语言、行为和情感表现差异。

Result: 研究结果显示，情境线索系统性地影响了人格表达和情感基调。相同的特质在不同的社交和情感需求下会以不同方式表达，表明LLMs的人格表达具有情境敏感性而非固定不变。

Conclusion: 从整体特质理论视角看，LLMs展现出情境敏感而非固定的人格表达，能够灵活适应社交互动目标和情感条件。这提出了一个重要问题：这种变化反映了LLMs的不一致性，还是类似于人类行为的语境敏感适应？

Abstract: Large Language Models (LLMs) can be conditioned with explicit personality prompts, yet their behavioral realization often varies depending on context. This study examines how identical personality prompts lead to distinct linguistic, behavioral, and emotional outcomes across four conversational settings: ice-breaking, negotiation, group decision, and empathy tasks. Results show that contextual cues systematically influence both personality expression and emotional tone, suggesting that the same traits are expressed differently depending on social and affective demands. This raises an important question for LLM-based dialogue agents: whether such variations reflect inconsistency or context-sensitive adaptation akin to human behavior. Viewed through the lens of Whole Trait Theory, these findings highlight that LLMs exhibit context-sensitive rather than fixed personality expression, adapting flexibly to social interaction goals and affective conditions.

</details>


### [340] [Exploring Knowledge Purification in Multi-Teacher Knowledge Distillation for LLMs](https://arxiv.org/abs/2602.01064)
*Ruihan Jin,Pengpeng Shao,Zhengqi Wen,Jinyang Wu,Mingkuan Feng,Shuo Yang,Chu Yuan Zhang,Jianhua Tao*

Main category: cs.CL

TL;DR: 该论文提出"知识净化"概念，将多个教师大语言模型的推理过程整合为单一推理，以解决知识冲突和资源需求高的问题，并提出了五种净化方法。


<details>
  <summary>Details</summary>
Motivation: 传统知识蒸馏方法在利用多个教师模型时面临知识冲突和高资源需求的挑战，需要更高效的多教师蒸馏技术来促进强大轻量模型的实用部署。

Method: 提出知识净化概念，将多个教师LLM的推理过程整合为单一推理；设计了五种不同角度的净化方法，包括基于路由器的方法等。

Result: 实验表明这些方法不仅提升了蒸馏模型的性能，还有效缓解了知识冲突；基于路由器的方法展现出强大的泛化能力。

Conclusion: 知识净化技术能优化多教师蒸馏过程，促进强大轻量模型的实用部署，创新的净化方法具有重要潜力。

Abstract: Knowledge distillation has emerged as a pivotal technique for transferring knowledge from stronger large language models (LLMs) to smaller, more efficient models. However, traditional distillation approaches face challenges related to knowledge conflicts and high resource demands, particularly when leveraging multiple teacher models. In this paper, we introduce the concept of \textbf{Knowledge Purification}, which consolidates the rationales from multiple teacher LLMs into a single rationale, thereby mitigating conflicts and enhancing efficiency. To investigate the effectiveness of knowledge purification, we further propose five purification methods from various perspectives. Our experiments demonstrate that these methods not only improve the performance of the distilled model but also effectively alleviate knowledge conflicts. Moreover, router-based methods exhibit robust generalization capabilities, underscoring the potential of innovative purification techniques in optimizing multi-teacher distillation and facilitating the practical deployment of powerful yet lightweight models.

</details>


### [341] [From Utterance to Vividity: Training Expressive Subtitle Translation LLM via Adaptive Local Preference Optimization](https://arxiv.org/abs/2602.01068)
*Chaoqun Cui,Shijing Wang,Liangbin Huang,Qingqing Gu,Zhaolong Huang,Xiao Zeng,Wenji Mao*

Main category: cs.CL

TL;DR: 该研究针对大语言模型在垂直领域翻译的局限性，以视觉媒体字幕翻译为主题，提出了自适应局部偏好优化方法，构建了多语言字幕平行语料库，训练出更具表现力的翻译模型。


<details>
  <summary>Details</summary>
Motivation: 随着应用场景复杂化，大语言模型在垂直领域翻译的局限性逐渐显现。研究聚焦于如何构建满足领域定制需求的翻译大语言模型，特别是视觉媒体字幕翻译领域，需要更具表现力和生动性的翻译模型。

Method: 1. 构建并发布了多语言字幕平行语料库数据集；2. 提出自适应局部偏好优化方法，解决细粒度偏好对齐问题；3. 验证大语言模型作为翻译奖励模型和评估器的可靠性。

Result: 实验结果表明，自适应局部偏好优化方法在翻译质量的多维评估中取得了优异表现，能够训练出更具表现力的字幕翻译大语言模型。

Conclusion: 该研究为解决大语言模型在垂直领域翻译的局限性提供了有效方案，通过自适应局部偏好优化方法和多语言字幕语料库，成功构建了满足视觉媒体字幕翻译需求的定制化翻译模型。

Abstract: The rapid development of Large Language Models (LLMs) has significantly enhanced the general capabilities of machine translation. However, as application scenarios become more complex, the limitations of LLMs in vertical domain translations are gradually becoming apparent. In this study, we focus on how to construct translation LLMs that meet the needs of domain customization. We take visual media subtitle translation as our topic and explore how to train expressive and vivid translation LLMs. We investigated the situations of subtitle translation and other domains of literal and liberal translation, verifying the reliability of LLM as reward model and evaluator for translation. Additionally, to train an expressive translation LLM, we constructed and released a multidirectional subtitle parallel corpus dataset and proposed the Adaptive Local Preference Optimization (ALPO) method to address fine-grained preference alignment. Experimental results demonstrate that ALPO achieves outstanding performance in multidimensional evaluation of translation quality.

</details>


### [342] [What If We Allocate Test-Time Compute Adaptively?](https://arxiv.org/abs/2602.01070)
*Ahsan Bilal,Ahmed Mohsin,Muhammad Umer,Ali Subhan,Hassan Rizwan,Ayesha Mohsin,Dean Hougen*

Main category: cs.CL

TL;DR: 提出验证器引导的自适应推理框架，通过过程奖励模型动态分配计算资源，在多个数学推理基准上显著优于传统的均匀计算分配方法。


<details>
  <summary>Details</summary>
Motivation: 传统测试时计算扩展方法存在三个问题：均匀分配推理计算、使用固定采样策略、仅将验证用于重排序。这些方法无法根据问题难度和推理路径质量动态调整计算资源，导致效率低下。

Method: 提出验证器引导的自适应框架，将推理视为迭代轨迹生成和选择过程。每个问题运行多次推理迭代，每次迭代可选生成高层计划、选择推理工具和计算策略、生成候选推理轨迹。使用过程奖励模型作为统一控制信号：在迭代内，步骤级PRM分数用于指导生成过程中的剪枝和扩展；在迭代间，聚合轨迹奖励用于选择最终响应。

Result: 在多个数据集上，动态PRM引导方法始终优于直接测试时扩展方法，在MATH-500上取得大幅提升，在AIME24和AMO-Bench等更难基准上实现数倍改进。通过理论FLOPs和计算强度指标证明，验证引导的分配将计算集中在高效用推理路径上。

Conclusion: 验证器引导的自适应推理框架通过动态计算分配和过程奖励模型指导，显著提升了复杂数学推理任务的性能和效率，证明了根据推理路径质量自适应分配计算资源的重要性。

Abstract: Test-time compute scaling allocates inference computation uniformly, uses fixed sampling strategies, and applies verification only for reranking. In contrast, we propose a verifier-guided adaptive framework treating reasoning as iterative trajectory generation and selection. For each problem, the agent runs multiple inference iterations. In each iteration, it optionally produces a high-level plan, selects a set of reasoning tools and a compute strategy together with an exploration parameter, and then generates a candidate reasoning trajectory. A process reward model (PRM) serves as a unified control signal: within each iteration, step-level PRM scores are aggregated to guide pruning and expansion during generation, and across iterations, aggregated trajectory rewards are used to select the final response. Across datasets, our dynamic, PRM-guided approach consistently outperforms direct test-time scaling, yielding large gains on MATH-500 and several-fold improvements on harder benchmarks such as AIME24 and AMO-Bench. We characterize efficiency using theoretical FLOPs and a compute intensity metric penalizing wasted generation and tool overhead, demonstrating that verification-guided allocation concentrates computation on high-utility reasoning paths.

</details>


### [343] [Logic-Oriented Retriever Enhancement via Contrastive Learning](https://arxiv.org/abs/2602.01116)
*Wenxuan Zhang,Yuan-Hao Jiang,Changyong Qi,Rui Jia,Yonghe Wu*

Main category: cs.CL

TL;DR: LORE通过细粒度对比学习激活LLM的逻辑推理能力，提升检索效果，无需外部监督或额外资源


<details>
  <summary>Details</summary>
Motivation: 现有检索器在知识密集型任务中表现不佳，容易过拟合于表面相似性，无法处理涉及复杂逻辑关系的查询

Method: 引入LORE框架，通过细粒度对比学习激活LLM潜在的逻辑分析能力，引导嵌入向量对齐逻辑结构而非浅层相似性

Result: LORE无需外部监督、额外资源或预检索分析，保持索引兼容性，持续提升检索效用和下游生成质量，同时保持效率

Conclusion: LORE有效激活了LLM内在的逻辑推理能力，显著改善了知识密集型任务中的检索性能，代码和数据集已开源

Abstract: Large language models (LLMs) struggle in knowledge-intensive tasks, as retrievers often overfit to surface similarity and fail on queries involving complex logical relations. The capacity for logical analysis is inherent in model representations but remains underutilized in standard training. LORE (Logic ORiented Retriever Enhancement) introduces fine-grained contrastive learning to activate this latent capacity, guiding embeddings toward evidence aligned with logical structure rather than shallow similarity. LORE requires no external upervision, resources, or pre-retrieval analysis, remains index-compatible, and consistently improves retrieval utility and downstream generation while maintaining efficiency. The datasets and code are publicly available at https://github.com/mazehart/Lore-RAG.

</details>


### [344] [Tendem: A Hybrid AI+Human Platform](https://arxiv.org/abs/2602.01119)
*Konstantin Chernyshev,Ekaterina Artemova,Viacheslav Zhukov,Maksim Nerush,Mariia Fedorova,Iryna Repik,Olga Shapovalova,Aleksey Sukhorosov,Vladimir Dobrovolskii,Natalia Mikhailova,Sergei Tilga*

Main category: cs.CL

TL;DR: Tendem是一种AI处理结构化重复工作、人类专家在模型失败时介入的混合系统，经过质量审查后交付客户。评估显示其比纯AI代理和纯人工工作流质量更高、速度更快，成本与纯人工相当。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统在处理复杂任务时存在局限性，纯人工工作流效率较低。需要一种结合AI自动化和人类专业判断的混合系统，以平衡质量、速度和成本。

Method: 开发Tendem混合系统：AI处理结构化重复工作，人类专家在模型失败时介入或验证结果。所有结果交付前经过全面质量审查。通过94个真实世界任务进行内部评估，与纯AI代理和Upwork自由职业者纯人工工作流对比。

Result: 1. Tendem持续提供更高质量输出和更快周转时间；2. 运营成本与纯人工执行相当；3. 在第三方代理基准测试中，Tendem的AI代理（无人类介入）在网页浏览和工具使用任务上接近最先进水平，在前沿领域知识和推理方面表现强劲。

Conclusion: Tendem混合系统有效结合了AI自动化和人类专业判断的优势，在保持成本竞争力的同时，显著提升了任务执行的质量和效率，为AI与人类协作提供了可行的解决方案。

Abstract: Tendem is a hybrid system where AI handles structured, repeatable work and Human Experts step in when the models fail or to verify results. Each result undergoes a comprehensive quality review before delivery to the Client. To assess Tendem's performance, we conducted a series of in-house evaluations on 94 real-world tasks, comparing it with AI-only agents and human-only workflows carried out by Upwork freelancers. The results show that Tendem consistently delivers higher-quality outputs with faster turnaround times. At the same time, its operational costs remain comparable to human-only execution. On third-party agentic benchmarks, Tendem's AI Agent (operating autonomously, without human involvement) performs near state-of-the-art on web browsing and tool-use tasks while demonstrating strong results in frontier domain knowledge and reasoning.

</details>


### [345] [Long-range Modeling and Processing of Multimodal Event Sequences](https://arxiv.org/abs/2602.01125)
*Jichu Li,Yilun Zhong,Zhiting Li,Feng Zhou,Quyu Kong*

Main category: cs.CL

TL;DR: 提出一个新颖的框架，将基于LLM的时间点过程扩展到视觉模态，通过自适应序列压缩机制解决长上下文问题，在预测准确性和文本分析质量方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有时间点过程方法在处理多模态数据时面临序列长度急剧增加的问题，导致基于注意力的模型难以生成需要长距离理解的连贯长文本描述。需要一种能够处理多模态内容并推理事件动态的新方法。

Method: 提出基于时间相似性的自适应序列压缩机制，减少序列长度同时保留关键模式；采用两阶段范式：先在压缩序列上进行预训练，然后针对下游任务进行监督微调；将文本生成定位为核心能力，与时间和类型预测并列。

Result: 在包括挑战性的DanmakuTPP-QA基准测试在内的广泛实验中，该方法在预测准确性和生成的文本分析质量方面都优于最先进的基线方法。

Conclusion: 该框架成功将LLM-based TPPs扩展到视觉模态，通过自适应压缩机制有效解决了长上下文问题，实现了多模态事件序列的建模和高质量文本生成。

Abstract: Temporal point processes (TPPs) have emerged as powerful tools for modeling asynchronous event sequences. While recent advances have extended TPPs to handle textual information, existing approaches are limited in their ability to generate rich, multimodal content and reason about event dynamics. A key challenge is that incorporating multimodal data dramatically increases sequence length, hindering the ability of attention-based models to generate coherent, long-form textual descriptions that require long-range understanding. In this paper, we propose a novel framework that extends LLM-based TPPs to the visual modality, positioning text generation as a core capability alongside time and type prediction. Our approach addresses the long-context problem through an adaptive sequence compression mechanism based on temporal similarity, which reduces sequence length while preserving essential patterns. We employ a two-stage paradigm of pre-training on compressed sequences followed by supervised fine-tuning for downstream tasks. Extensive experiments, including on the challenging DanmakuTPP-QA benchmark, demonstrate that our method outperforms state-of-the-art baselines in both predictive accuracy and the quality of its generated textual analyses.

</details>


### [346] [Don't Judge a Book by its Cover: Testing LLMs' Robustness Under Logical Obfuscation](https://arxiv.org/abs/2602.01132)
*Abhilekh Borah,Shubhra Ghosh,Kedar Joshi,Aditya Kumar Guru,Kripabandhu Ghosh*

Main category: cs.CL

TL;DR: 论文提出了Logifus逻辑混淆框架和LogiQAte基准测试，发现LLMs在逻辑等价但表面形式混淆的问题上表现严重下降，揭示了模型缺乏深度理解的问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理标准形式的逻辑推理任务时表现良好，但当相同问题以逻辑等价但表面形式混淆的方式呈现时，模型表现会严重下降。为了系统研究这一脆弱性，需要创建专门的评估框架和基准。

Method: 提出了Logifus结构保持逻辑混淆框架，并基于此创建了LogiQAte诊断基准，包含1,108个问题，涵盖四个推理任务：混淆一阶逻辑蕴含、混淆血缘关系推理、混淆数字序列模式归纳、混淆方向感知导航推理。

Result: 在六个最先进模型上的评估显示，混淆严重降低了零样本性能：GPT-4o平均下降47%，GPT-5下降27%，推理模型o4-mini下降22%。所有任务中都观察到显著的性能下降。

Conclusion: 当前LLMs只是解析问题表面形式而非深度理解，强调了构建真正理解并保持意义超越表面形式的模型的紧迫性。逻辑混淆暴露了模型在语义保持变换下的脆弱性。

Abstract: Tasks such as solving arithmetic equations, evaluating truth tables, and completing syllogisms are handled well by large language models (LLMs) in their standard form, but they often fail when the same problems are posed in logically equivalent yet obfuscated formats. To study this vulnerability, we introduce Logifus, a structure-preserving logical obfuscation framework, and, utilizing this, we present LogiQAte, a first-of-its-kind diagnostic benchmark with 1,108 questions across four reasoning tasks: (i) Obfus FOL (first-order logic entailment under equivalence-preserving rewrites), (ii) Obfus Blood Relation (family-graph entailment under indirect relational chains), (iii) Obfus Number Series (pattern induction under symbolic substitutions), and (iv) Obfus Direction Sense (navigation reasoning under altered directions and reference frames). Across all the tasks, evaluating six state-of-the-art models, we find that obfuscation severely degrades zero-shot performance, with performance dropping on average by 47% for GPT-4o, 27% for GPT-5, and 22% for reasoning model, o4-mini. Our findings reveal that current LLMs parse questions without deep understanding, highlighting the urgency of building models that genuinely comprehend and preserve meaning beyond surface form.

</details>


### [347] [Beyond Training for Cultural Awareness: The Role of Dataset Linguistic Structure in Large Language Models](https://arxiv.org/abs/2602.01161)
*Reem I. Masoud,Chen Feng,Shunta Asano,Saied Alshahrani,Philip Colin Treleaven,Miguel R. D. Rodrigues*

Main category: cs.CL

TL;DR: 该研究从数据集角度探讨文化对齐，分析微调数据的语言特性如何影响LLM的文化表现，发现词汇导向特性最稳健，而语义和多样性极端值通常中性或有害。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的全球部署，文化错位问题日益凸显，但用于文化适应的微调数据集的语言特性尚未得到充分理解。研究旨在探究微调数据的哪些语言特性与文化表现相关，这些特性是否能在训练前预测，以及这些效应如何随模型变化。

Method: 研究采用数据集中心视角，计算阿拉伯语、中文和日语数据集的轻量级语言、语义和结构指标，并在每种语言内分别应用主成分分析。然后对三个主要LLM家族（LLaMA、Mistral、DeepSeek）进行微调，并在文化知识、价值观和规范基准上进行评估。通过受控子集干预验证发现。

Result: 主成分分析产生了可解释的维度：语义连贯性、表层词汇和句法多样性、词汇或结构丰富度。PCA成分与下游性能相关，但这些关联高度依赖模型。词汇导向成分（PC3）最稳健，在不同模型和基准上表现一致，而强调语义或多样性极端值（PC1-PC2）通常中性或有害。

Conclusion: 文化对齐的数据集设计应考虑语言特性，特别是词汇特性对性能的稳健影响。研究强调了数据集特性与模型架构之间的复杂交互，为文化适应的微调数据选择提供了实证指导。

Abstract: The global deployment of large language models (LLMs) has raised concerns about cultural misalignment, yet the linguistic properties of fine-tuning datasets used for cultural adaptation remain poorly understood. We adopt a dataset-centric view of cultural alignment and ask which linguistic properties of fine-tuning data are associated with cultural performance, whether these properties are predictive prior to training, and how these effects vary across models. We compute lightweight linguistic, semantic, and structural metrics for Arabic, Chinese, and Japanese datasets and apply principal component analysis separately within each language. This design ensures that the resulting components capture variation among datasets written in the same language rather than differences between languages. The resulting components correspond to broadly interpretable axes related to semantic coherence, surface-level lexical and syntactic diversity, and lexical or structural richness, though their composition varies across languages. We fine-tune three major LLM families (LLaMA, Mistral, DeepSeek) and evaluate them on benchmarks of cultural knowledge, values, and norms. While PCA components correlate with downstream performance, these associations are strongly model-dependent. Through controlled subset interventions, we show that lexical-oriented components (PC3) are the most robust, yielding more consistent performance across models and benchmarks, whereas emphasizing semantic or diversity extremes (PC1-PC2) is often neutral or harmful.

</details>


### [348] [Typologically-Informed Candidate Reranking for LLM-based Translation into Low-Resource Languages](https://arxiv.org/abs/2602.01162)
*Nipuna Abeykoon,Ashen Weerathunga,Pubudu Wijesinghe,Parameswari Krishnamurthy*

Main category: cs.CL

TL;DR: 提出一个利用语言类型学改进低资源语言翻译质量的框架，无需平行训练数据或模型重训练，通过语言消歧和类型学合规性评分来提升翻译质量。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型主要基于高资源语言训练，对主导类型学模式存在系统性偏见，导致在翻译到类型学差异大的低资源语言时出现结构不一致问题。需要一种无需平行训练数据就能改善翻译质量的方法。

Method: 框架包含两个组件：1) 通用元语言框架(UMF)，将语言表示为16个类型学维度的结构化配置文件，采用差异加权评分；2) 计算引擎，在生成时进行语言消歧，在候选选择时进行类型学合规性评分。

Result: 在9个语言对上的评估显示干预率与英语的类型学距离强相关。在341个英语句子的实验中，框架的干预精度为：保守处理语言48.16%，形态密集语言28.15%，结构分析语言86.26%。

Conclusion: 该框架无需平行训练数据，可与任何能产生多个候选输出的LLM配合使用，为资源不足的语言提供了实用的部署方案，通过语言类型学指导显著改善了翻译质量。

Abstract: Large language models trained predominantly on high-resource languages exhibit systematic biases toward dominant typological patterns, leading to structural non-conformance when translating into typologically divergent low-resource languages. We present a framework that leverages linguistic typology to improve translation quality without parallel training data or model retraining. The framework consists of two components: the Universal Metalinguistic Framework (UMF), which represents languages as structured profiles across 16 typological dimensions with divergence-weighted scoring, and the Computational Engine, which operates through linguistic disambiguation during generation and typological compliance scoring during selection. Evaluation across nine language pairs demonstrates intervention rates strongly correlating with typological distance from English. In experiments on 341 English sentences each having different morphological and syntactic phenomena, the framework shows an intervention precision of 48.16% for conservatively treated languages, 28.15% for morphologically dense languages, and 86.26% for structurally profiled languages. The framework requires no parallel training data and operates with any LLM capable of producing multiple candidate outputs, enabling practical deployment for under-resourced languages.

</details>


### [349] [PedagoSense: A Pedology Grounded LLM System for Pedagogical Strategy Detection and Contextual Response Generation in Learning Dialogues](https://arxiv.org/abs/2602.01169)
*Shahem Sultan,Shahem Fadi,Yousef Melhim,Ibrahim Alsarraj,Besher Hassan*

Main category: cs.CL

TL;DR: PedagoSense系统结合两阶段策略分类器与LLM生成，用于检测和推荐教学策略，提升对话式学习中的互动质量。


<details>
  <summary>Details</summary>
Motivation: 解决对话式学习中如何检测和推荐有效教学策略的挑战，将教学理论与实际LLM响应生成相结合，开发更自适应的教育技术。

Method: 采用两阶段策略分类器：先使用二元分类器检测是否存在教学策略，再进行细粒度分类识别具体策略；同时基于对话上下文推荐策略，并用LLM生成符合该策略的响应。

Result: 在人工标注的师生对话数据集上评估，教学策略检测表现优异，数据增强带来持续增益，但细粒度分类仍具挑战性。

Conclusion: PedagoSense成功将教学理论与实际LLM响应生成相结合，为开发更自适应的教育技术提供了桥梁。

Abstract: This paper addresses the challenge of improving interaction quality in dialogue based learning by detecting and recommending effective pedagogical strategies in tutor student conversations. We introduce PedagoSense, a pedology grounded system that combines a two stage strategy classifier with large language model generation. The system first detects whether a pedagogical strategy is present using a binary classifier, then performs fine grained classification to identify the specific strategy. In parallel, it recommends an appropriate strategy from the dialogue context and uses an LLM to generate a response aligned with that strategy. We evaluate on human annotated tutor student dialogues, augmented with additional non pedagogical conversations for the binary task. Results show high performance for pedagogical strategy detection and consistent gains when using data augmentation, while analysis highlights where fine grained classes remain challenging. Overall, PedagoSense bridges pedagogical theory and practical LLM based response generation for more adaptive educational technologies.

</details>


### [350] [EmoAra: Emotion-Preserving English Speech Transcription and Cross-Lingual Translation with Arabic Text-to-Speech](https://arxiv.org/abs/2602.01170)
*Besher Hassan,Ibrahim Alsarraj,Musaab Hasan,Yousef Melhim,Shahem Fadi,Shahem Sultan*

Main category: cs.CL

TL;DR: EmoAra是一个端到端的跨语言语音通信系统，能够在英语到阿拉伯语的转换过程中保持情感信息，特别针对银行客服场景。


<details>
  <summary>Details</summary>
Motivation: 银行客服场景中情感语境影响服务质量，需要跨语言通信时保持情感信息，确保服务质量不因语言转换而降低。

Method: 集成语音情感识别、自动语音识别、机器翻译和文本转语音四个模块：CNN情感分类器、Whisper英语转录、微调MarianMT英阿翻译模型、MMS-TTS-Ara阿拉伯语语音合成。

Result: 情感分类F1分数94%，翻译性能BLEU 56和BERTScore F1 88.7%，银行领域翻译平均人工评估分数81%。

Conclusion: EmoAra成功实现了跨语言语音通信中的情感保持，在银行客服场景表现良好，系统代码和资源已开源。

Abstract: This work presents EmoAra, an end-to-end emotion-preserving pipeline for cross-lingual spoken communication, motivated by banking customer service where emotional context affects service quality. EmoAra integrates Speech Emotion Recognition, Automatic Speech Recognition, Machine Translation, and Text-to-Speech to process English speech and deliver an Arabic spoken output while retaining emotional nuance. The system uses a CNN-based emotion classifier, Whisper for English transcription, a fine-tuned MarianMT model for English-to-Arabic translation, and MMS-TTS-Ara for Arabic speech synthesis. Experiments report an F1-score of 94% for emotion classification, translation performance of BLEU 56 and BERTScore F1 88.7%, and an average human evaluation score of 81% on banking-domain translations. The implementation and resources are available at the accompanying GitHub repository.

</details>


### [351] [Bridging Lexical Ambiguity and Vision: A Mini Review on Visual Word Sense Disambiguation](https://arxiv.org/abs/2602.01193)
*Shashini Nilukshi,Deshan Sumanathilaka*

Main category: cs.CL

TL;DR: 本文对视觉词义消歧（VWSD）进行了小型综述，VWSD是传统词义消歧（WSD）的多模态扩展，利用视觉线索解决词汇歧义问题。综述涵盖了从早期多模态融合方法到基于CLIP对比模型、扩散生成和LLM支持的新框架的发展，展示了VWSD在特征、图、对比嵌入等技术上的进步，以及提示工程、微调、多语言适应等方面的进展。


<details>
  <summary>Details</summary>
Motivation: 传统WSD仅依赖文本和词汇资源，而VWSD通过引入视觉线索来解决词汇歧义问题，特别是在视觉语言任务中。随着多模态AI的发展，需要系统回顾VWSD从早期方法到最新技术（如CLIP、扩散模型、LLM）的演进，总结进展并识别现有挑战。

Method: 综述分析了2016-2025年间的研究，涵盖特征融合、图方法、对比嵌入等技术。重点考察了基于CLIP的微调模型、扩散文本到图像生成、LLM增强系统等方法，以及提示工程、微调策略和多语言适应技术。

Result: 量化结果显示，基于CLIP的微调模型和LLM增强的VWSD系统持续优于零样本基线，在平均倒数排名（MRR）上获得6-8%的提升。然而仍存在上下文限制、模型偏向常见含义、多语言数据集缺乏、评估框架不足等挑战。

Conclusion: VWSD领域正快速发展，未来方向是CLIP对齐、扩散生成和LLM推理的融合，以构建更强大、上下文感知和多语言的消歧系统。需要解决现有挑战，推动该领域进一步发展。

Abstract: This paper offers a mini review of Visual Word Sense Disambiguation (VWSD), which is a multimodal extension of traditional Word Sense Disambiguation (WSD). VWSD helps tackle lexical ambiguity in vision-language tasks. While conventional WSD depends only on text and lexical resources, VWSD uses visual cues to find the right meaning of ambiguous words with minimal text input. The review looks at developments from early multimodal fusion methods to new frameworks that use contrastive models like CLIP, diffusion-based text-to-image generation, and large language model (LLM) support. Studies from 2016 to 2025 are examined to show the growth of VWSD through feature-based, graph-based, and contrastive embedding techniques. It focuses on prompt engineering, fine-tuning, and adapting to multiple languages. Quantitative results show that CLIP-based fine-tuned models and LLM-enhanced VWSD systems consistently perform better than zero-shot baselines, achieving gains of up to 6-8\% in Mean Reciprocal Rank (MRR). However, challenges still exist, such as limitations in context, model bias toward common meanings, a lack of multilingual datasets, and the need for better evaluation frameworks. The analysis highlights the growing overlap of CLIP alignment, diffusion generation, and LLM reasoning as the future path for strong, context-aware, and multilingual disambiguation systems.

</details>


### [352] [Attention Sink Forges Native MoE in Attention Layers: Sink-Aware Training to Address Head Collapse](https://arxiv.org/abs/2602.01203)
*Zizhuo Fu,Wenxuan Zeng,Runsheng Wang,Meng Li*

Main category: cs.CL

TL;DR: 本文发现注意力机制中的注意力汇现象自然构建了注意力层内的混合专家机制，解释了头部塌陷现象，并提出了一种带有负载均衡损失的汇感知训练算法来改善模型性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型经常对第一个token分配不成比例的注意力（注意力汇现象）。虽然已有一些方法（如GPT-OSS的Sink Attention和Qwen3-Next的Gated Attention）试图解决此问题，但缺乏对这些注意力机制之间关系的全面分析。

Method: 通过理论和实证证据证明Vanilla Attention和Sink Attention中的注意力汇自然构建了注意力层内的混合专家机制。为缓解头部塌陷现象，提出了一种带有辅助负载均衡损失的汇感知训练算法。

Result: 实验表明，该方法在Vanilla Attention、Sink Attention和Gated Attention中都能有效实现头部负载均衡，并提升模型性能。

Conclusion: 本研究为注意力机制提供了新视角，鼓励进一步探索注意力层内固有的混合专家结构。

Abstract: Large Language Models (LLMs) often assign disproportionate attention to the first token, a phenomenon known as the attention sink. Several recent approaches aim to address this issue, including Sink Attention in GPT-OSS and Gated Attention in Qwen3-Next. However, a comprehensive analysis of the relationship among these attention mechanisms is lacking. In this work, we provide both theoretical and empirical evidence demonstrating that the sink in Vanilla Attention and Sink Attention naturally construct a Mixture-of-Experts (MoE) mechanism within attention layers. This insight explains the head collapse phenomenon observed in prior work, where only a fixed subset of attention heads contributes to generation. To mitigate head collapse, we propose a sink-aware training algorithm with an auxiliary load balancing loss designed for attention layers. Extensive experiments show that our method achieves effective head load balancing and improves model performance across Vanilla Attention, Sink Attention, and Gated Attention. We hope this study offers a new perspective on attention mechanisms and encourages further exploration of the inherent MoE structure within attention layers.

</details>


### [353] [ASTER: Agentic Scaling with Tool-integrated Extended Reasoning](https://arxiv.org/abs/2602.01204)
*Xuqin Zhang,Quan He,Zhenrui Zheng,Zongzhang Zhang,Xu He,Dong Li*

Main category: cs.CL

TL;DR: ASTER框架通过有针对性的冷启动策略解决RL训练中工具集成推理的交互崩溃问题，使用仅4K交互密集轨迹即可建立强大的行为先验，在数学推理基准上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 强化学习在引导大语言模型进行长程推理方面表现出色，但在工具集成推理的规模化应用中面临"交互崩溃"问题：模型无法维持多轮工具使用，退化为大量内部推理和简单的后验代码验证。需要系统研究冷启动SFT如何建立工具使用行为先验、交互密度如何影响探索和RL结果，以及RL交互预算如何影响学习动态和泛化能力。

Method: 提出ASTER（Agentic Scaling with Tool-integrated Extended Reasoning）框架，采用有针对性的冷启动策略，优先选择交互密集的轨迹。研究发现仅需4K个交互密集的专家冷启动轨迹就能建立强大的行为先验，支持在扩展RL训练期间进行更好的探索。

Result: ASTER-4B在竞争性数学推理基准上取得最先进的结果，在AIME 2025上达到90.0%，超越了包括DeepSeek-V3.2-Exp在内的领先前沿开源模型。

Conclusion: 通过有针对性的冷启动策略构建交互密集轨迹可以有效解决工具集成推理中的交互崩溃问题，小规模但高质量的专家冷启动数据集能够建立强大的行为先验，显著提升强化学习训练效果和模型在复杂推理任务上的性能。

Abstract: Reinforcement learning (RL) has emerged as a dominant paradigm for eliciting long-horizon reasoning in Large Language Models (LLMs). However, scaling Tool-Integrated Reasoning (TIR) via RL remains challenging due to interaction collapse: a pathological state where models fail to sustain multi-turn tool usage, instead degenerating into heavy internal reasoning with only trivial, post-hoc code verification. We systematically study three questions: (i) how cold-start SFT induces an agentic, tool-using behavioral prior, (ii) how the interaction density of cold-start trajectories shapes exploration and downstream RL outcomes, and (iii) how the RL interaction budget affects learning dynamics and generalization under varying inference-time budgets. We then introduce ASTER (Agentic Scaling with Tool-integrated Extended Reasoning), a framework that circumvents this collapse through a targeted cold-start strategy prioritizing interaction-dense trajectories. We find that a small expert cold-start set of just 4K interaction-dense trajectories yields the strongest downstream performance, establishing a robust prior that enables superior exploration during extended RL training. Extensive evaluations demonstrate that ASTER-4B achieves state-of-the-art results on competitive mathematical benchmarks, reaching 90.0% on AIME 2025, surpassing leading frontier open-source models, including DeepSeek-V3.2-Exp.

</details>


### [354] [Chronos: Learning Temporal Dynamics of Reasoning Chains for Test-Time Scaling](https://arxiv.org/abs/2602.01208)
*Kai Zhang,Jiayi Liao,Chengpeng Li,Ziyuan Xie,Sihang Li,Xiang Wang*

Main category: cs.CL

TL;DR: Chronos是一个轻量级即插即用的时序推理评分器，将推理轨迹建模为时间序列，通过学习token概率特征分配质量分数，实现加权投票，显著提升LLM推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有测试时缩放方法（如多数投票和启发式token级评分）平等对待推理轨迹或token，容易受到轨迹质量变化和局部逻辑错误的影响，需要更精细的轨迹质量评估方法。

Method: Chronos将每个推理轨迹建模为时间序列，学习token概率的轨迹特征，分配质量分数，并采用加权投票机制。该方法轻量级、即插即用，计算开销极小。

Result: 在领域内和领域外基准测试中，Chronos在各种模型上均带来显著提升。Chronos@128在HMMT25上相对Pass@1提升34.21%，相对Maj@128提升22.70%（使用Qwen3-4B-Thinking-2507）。

Conclusion: Chronos通过时序建模推理轨迹，有效解决了现有测试时缩放方法的局限性，以极小计算开销显著提升大语言模型的推理性能，具有广泛适用性。

Abstract: Test-Time Scaling (TTS) has emerged as an effective paradigm for improving the reasoning performance of large language models (LLMs). However, existing methods -- most notably majority voting and heuristic token-level scoring -- treat reasoning traces or tokens equally, thereby being susceptible to substantial variations in trajectory quality and localized logical failures. In this work, we introduce \textbf{Chronos}, a lightweight and plug-and-play chronological reasoning scorer that models each trajectory as a time series. Specifically, Chronos learns to capture trajectory features of token probabilities, assigns quality scores accordingly, and employs a weighted voting mechanism. Extensive evaluations on both in-domain and out-of-domain benchmarks demonstrate that Chronos consistently delivers substantial gains across a variety of models, with negligible computational overhead. Notably, Chronos@128 achieves relative improvements of 34.21\% over Pass@1 and 22.70\% over Maj@128 on HMMT25 using Qwen3-4B-Thinking-2507, highlighting its effectiveness.

</details>


### [355] [Supervised Fine-Tuning Needs to Unlock the Potential of Token Priority](https://arxiv.org/abs/2602.01227)
*Zhanming Shen,Zeyu Qin,Jiaqi Hu,Wentao Ye,Hao Chen,Xiaomeng Hu,Haokai Xu,Gang Chen,Yi R. Fung,Haobo Wang*

Main category: cs.CL

TL;DR: 该立场论文提出"Token Priority"作为解决细粒度自回归生成与粗粒度监督信号之间粒度不匹配问题的关键桥梁，将SFT重新定义为精确的分布重塑过程而非简单优化。


<details>
  <summary>Details</summary>
Motivation: 从拟合经验数据到实现真正人类效用的转变受到粒度不匹配的根本约束——细粒度的自回归生成通常由粗粒度或均匀的信号监督，这限制了模型对齐的实际效果。

Method: 提出Token Priority框架，将监督微调(SFT)形式化为精确的分布重塑过程，将原始数据与理想对齐流形对齐。将现有方法分为两个体系：用于噪声过滤的Positive Priority和用于毒性模式遗忘的Signed Priority。

Result: 通过统一视角分析近期突破，重新审视现有进展和局限性，识别关键挑战，并为未来研究提供方向建议。

Conclusion: Token Priority是连接数据拟合与人类效用的关键桥梁，通过将SFT重新定义为分布重塑过程，为解决粒度不匹配问题提供了统一的理论框架和分析工具。

Abstract: The transition from fitting empirical data to achieving true human utility is fundamentally constrained by a granularity mismatch, where fine-grained autoregressive generation is often supervised by coarse or uniform signals. This position paper advocates Token Priority as the essential bridge, formalizing Supervised Fine-Tuning (SFT) not as simple optimization but as a precise distribution reshaping process that aligns raw data with the ideal alignment manifold. We analyze recent breakthroughs through this unified lens, categorizing them into two distinct regimes: Positive Priority for noise filtration and Signed Priority for toxic modes unlearning. We revisit existing progress and limitations, identify key challenges, and suggest directions for future research.

</details>


### [356] [Inferential Question Answering](https://arxiv.org/abs/2602.01239)
*Jamshid Mozafari,Hamed Zamani,Guido Zuccon,Adam Jatowt*

Main category: cs.CL

TL;DR: 论文提出了"推理式问答"新任务，要求模型从仅提供线索的文本中推断答案，而非直接提取。构建了QUIT数据集，发现现有QA方法在推理任务上表现不佳。


<details>
  <summary>Details</summary>
Motivation: 现有问答系统大多关注答案直接提取，但许多问题需要从文本线索中进行推理才能得出答案。当前缺乏专门研究推理式问答的任务和数据集。

Method: 1. 提出"推理式问答"新任务；2. 构建QUIT数据集（7,401个问题，240万段落）；3. 使用LLM和人工标注三个相关性级别；4. 全面评估检索器、重排序器和LLM阅读器在推理任务上的表现。

Result: 现有QA方法在推理任务上表现不佳：检索器效果差，重排序器提升有限，微调改进不一致。即使是推理导向的LLM也无法超越较小的通用模型。当前QA流程尚未准备好处理基于推理的任务。

Conclusion: 推理式问答代表了QA任务的新类别，要求从间接文本证据中进行理解和推理。该研究揭示了当前QA系统的局限性，并为未来推理能力研究奠定了基础。

Abstract: Despite extensive research on a wide range of question answering (QA) systems, most existing work focuses on answer containment-i.e., assuming that answers can be directly extracted and/or generated from documents in the corpus. However, some questions require inference, i.e., deriving answers that are not explicitly stated but can be inferred from the available information. We introduce Inferential QA -- a new task that challenges models to infer answers from answer-supporting passages which provide only clues. To study this problem, we construct QUIT (QUestions requiring Inference from Texts) dataset, comprising 7,401 questions and 2.4M passages built from high-convergence human- and machine-authored hints, labeled across three relevance levels using LLM-based answerability and human verification. Through comprehensive evaluation of retrievers, rerankers, and LLM-based readers, we show that methods effective on traditional QA tasks struggle in inferential QA: retrievers underperform, rerankers offer limited gains, and fine-tuning provides inconsistent improvements. Even reasoning-oriented LLMs fail to outperform smaller general-purpose models. These findings reveal that current QA pipelines are not yet ready for inference-based reasoning. Inferential QA thus establishes a new class of QA tasks that move towards understanding and reasoning from indirect textual evidence.

</details>


### [357] [Minimizing Mismatch Risk: A Prototype-Based Routing Framework for Zero-shot LLM-generated Text Detection](https://arxiv.org/abs/2602.01240)
*Ke Sun,Guangsheng Bao,Han Cui,Yue Zhang*

Main category: cs.CL

TL;DR: 提出DetectRouter框架，通过从多样化的代理模型池中为每个输入选择最匹配的代理模型来改进零样本LLM生成文本检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有零样本检测方法通常对所有输入使用固定的代理模型，而检测性能会因代理模型与未知源模型的对齐程度而有显著差异。研究发现，虽然单个代理模型无法在所有情况下都达到最优性能，但对于任何给定输入，在多样化代理模型池中通常存在一个匹配良好的代理模型。

Method: 提出DetectRouter原型框架，通过两阶段训练学习文本与检测器的亲和力：第一阶段从白盒模型构建判别性原型；第二阶段通过将几何距离与观察到的检测分数对齐，泛化到黑盒源模型。

Result: 在EvoBench和MAGE基准测试上的实验表明，该方法在多个检测标准和模型家族上均取得了一致的改进。

Conclusion: 将鲁棒检测问题转化为路由问题，通过为每个输入选择最合适的代理模型，显著提高了零样本LLM生成文本检测的性能。

Abstract: Zero-shot methods detect LLM-generated text by computing statistical signatures using a surrogate model. Existing approaches typically employ a fixed surrogate for all inputs regardless of the unknown source. We systematically examine this design and find that detection performance varies substantially depending on surrogate-source alignment. We observe that while no single surrogate achieves optimal performance universally, a well-matched surrogate typically exists within a diverse pool for any given input. This finding transforms robust detection into a routing problem: selecting the most appropriate surrogate for each input. We propose DetectRouter, a prototype-based framework that learns text-detector affinity through two-stage training. The first stage constructs discriminative prototypes from white-box models; the second generalizes to black-box sources by aligning geometric distances with observed detection scores. Experiments on EvoBench and MAGE benchmarks demonstrate consistent improvements across multiple detection criteria and model families.

</details>


### [358] [Large-Scale Terminal Agentic Trajectory Generation from Dockerized Environments](https://arxiv.org/abs/2602.01244)
*Siwei Wu,Yizhi Li,Yuyang Song,Wei Zhang,Yang Wang,Riza Batista-Navarro,Xian Yang,Mingjie Tang,Bryan Dai,Jian Yang,Chenghua Lin*

Main category: cs.CL

TL;DR: TerminalTraj是一个可扩展的终端轨迹数据生成管道，通过Docker化环境解决终端任务数据的可执行性和可验证性问题，生成了5万+已验证轨迹，训练出的模型在TerminalBench上性能提升显著。


<details>
  <summary>Details</summary>
Motivation: 训练终端任务智能体模型需要高质量的长时程交互轨迹数据，但大规模构建面临两大挑战：1) 可执行性 - 每个实例需要合适的Docker环境；2) 可验证性 - 异构任务输出难以统一验证。

Method: 提出TerminalTraj三阶段管道：1) 筛选高质量仓库构建Docker化执行环境；2) 生成与Docker对齐的任务实例；3) 合成带有可执行验证代码的智能体轨迹。

Result: 构建了32K个Docker镜像和50,733个已验证终端轨迹，覆盖8个领域。基于Qwen2.5-Coder训练的模型在TerminalBench上性能显著提升：TB 1.0提升达20%，TB 2.0提升10%。TerminalTraj-32B在100B参数以下模型中表现强劲。

Conclusion: TerminalTraj成功解决了终端轨迹数据构建的可执行性和可验证性挑战，为训练终端任务智能体提供了高质量、可扩展的数据集，显著提升了模型性能。

Abstract: Training agentic models for terminal-based tasks critically depends on high-quality terminal trajectories that capture realistic long-horizon interactions across diverse domains. However, constructing such data at scale remains challenging due to two key requirements: \textbf{\emph{Executability}}, since each instance requires a suitable and often distinct Docker environment; and \textbf{\emph{Verifiability}}, because heterogeneous task outputs preclude unified, standardized verification. To address these challenges, we propose \textbf{TerminalTraj}, a scalable pipeline that (i) filters high-quality repositories to construct Dockerized execution environments, (ii) generates Docker-aligned task instances, and (iii) synthesizes agent trajectories with executable validation code. Using TerminalTraj, we curate 32K Docker images and generate 50,733 verified terminal trajectories across eight domains. Models trained on this data with the Qwen2.5-Coder backbone achieve consistent performance improvements on TerminalBench (TB), with gains of up to 20\% on TB~1.0 and 10\% on TB~2.0 over their respective backbones. Notably, \textbf{TerminalTraj-32B} achieves strong performance among models with fewer than 100B parameters, reaching 35.30\% on TB~1.0 and 22.00\% on TB~2.0, and demonstrates improved test-time scaling behavior. All code and data are available at https://github.com/Wusiwei0410/TerminalTraj.

</details>


### [359] [PARSE: An Open-Domain Reasoning Question Answering Benchmark for Persian](https://arxiv.org/abs/2602.01246)
*Jamshid Mozafari,Seyed Parsa Mousavinasab,Adam Jatowt*

Main category: cs.CL

TL;DR: PARSE是首个波斯语开放领域推理问答基准，包含10,800个问题，涵盖布尔、多项选择和事实型格式，支持波斯语LLM的公平评估和模型适配。


<details>
  <summary>Details</summary>
Motivation: 波斯语作为拥有约1.3亿使用者的语言，缺乏高质量开放领域推理问答基准，阻碍了波斯语LLM的评估和发展。

Method: 通过受控的LLM生成管道构建基准，采用多阶段过滤、标注和一致性检查确保语言和事实质量，并进行人工验证。

Result: 波斯语提示和结构化提示（CoT用于布尔/多项选择；few-shot用于事实型）能提升性能，微调进一步改善结果，特别是波斯语专用模型。

Conclusion: PARSE填补了波斯语QA研究的关键空白，为低资源环境下开发和评估推理能力LLM提供了坚实基础。

Abstract: Reasoning-focused Question Answering (QA) has advanced rapidly with Large Language Models (LLMs), yet high-quality benchmarks for low-resource languages remain scarce. Persian, spoken by roughly 130 million people, lacks a comprehensive open-domain resource for evaluating reasoning-capable QA systems. We introduce PARSE, the first open-domain Persian reasoning QA benchmark, containing 10,800 questions across Boolean, multiple-choice, and factoid formats, with diverse reasoning types, difficulty levels, and answer structures. The benchmark is built via a controlled LLM-based generation pipeline and validated through human evaluation. We also ensure linguistic and factual quality through multi-stage filtering, annotation, and consistency checks. We benchmark multilingual and Persian LLMs under multiple prompting strategies and show that Persian prompts and structured prompting (CoT for Boolean/multiple-choice; few-shot for factoid) improve performance. Fine-tuning further boosts results, especially for Persian-specialized models. These findings highlight how PARSE supports both fair comparison and practical model adaptation. PARSE fills a critical gap in Persian QA research and provides a strong foundation for developing and evaluating reasoning-capable LLMs in low-resource settings.

</details>


### [360] [PACER: Blockwise Pre-verification for Speculative Decoding with Adaptive Length](https://arxiv.org/abs/2602.01274)
*Situo Zhang,Yifan Zhang,Zichen Zhu,Hankun Wang,Da Ma,Danyang Zhang,Lu Chen,Kai Yu*

Main category: cs.CL

TL;DR: Pacer是一种动态控制草稿长度的推测解码方法，通过轻量级预验证层实现，相比传统固定长度方法能获得更高的加速比。


<details>
  <summary>Details</summary>
Motivation: 传统推测解码使用固定草稿长度，但实验发现最优草稿长度在不同解码步骤中差异很大，固定长度限制了进一步加速的潜力。

Method: 提出Pacer方法，使用轻量级可训练预验证层对草稿令牌进行块状预验证，在预验证失败时停止令牌生成，实现动态控制草稿长度。

Result: Pacer在多个SD模型对上实现最高2.66倍加速比，始终优于标准推测解码；与Ouroboros集成时可达3.09倍加速比。

Conclusion: Pacer通过动态控制草稿长度有效提升了推测解码的效率，为LLM推理加速提供了更优方案。

Abstract: Speculative decoding (SD) is a powerful technique for accelerating the inference process of large language models (LLMs) without sacrificing accuracy. Typically, SD employs a small draft model to generate a fixed number of draft tokens, which are then verified in parallel by the target model. However, our experiments reveal that the optimal draft length varies significantly across different decoding steps. This variation suggests that using a fixed draft length limits the potential for further improvements in decoding speed. To address this challenge, we propose Pacer, a novel approach that dynamically controls draft length using a lightweight, trainable pre-verification layer. This layer pre-verifies draft tokens blockwise before they are sent to the target model, allowing the draft model to stop token generation if the blockwise pre-verification fails. We implement Pacer on multiple SD model pairs and evaluate its performance across various benchmarks. Our results demonstrate that Pacer achieves up to 2.66x Speedup over autoregressive decoding and consistently outperforms standard speculative decoding. Furthermore, when integrated with Ouroboros, Pacer attains up to 3.09x Speedup.

</details>


### [361] [EverMemBench: Benchmarking Long-Term Interactive Memory in Large Language ModelsEverMemBench: Benchmarking Long-Term Interactive Memory in Large Language Models](https://arxiv.org/abs/2602.01313)
*Chuanrui Hu,Tong Li,Xingze Gao,Hongda Chen,Dannong Xu,Yi Bai,Tianwei Lin,Xinda Zhao,Xiaohong Li,Jiaqi An,Yunyun Han,Jian Pei,Yafeng Deng*

Main category: cs.CL

TL;DR: EverMemBench是一个用于评估LLM长期对话记忆的基准测试，包含多参与者、多群组对话，超过100万token，评估记忆系统的细粒度回忆、记忆意识和用户画像理解三个维度。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要关注二元、单一主题的对话，无法捕捉真实世界的复杂性。需要一个新的基准来评估LLM在多参与者、多群组、跨主题交织、角色特定人设等复杂场景下的长期对话记忆能力。

Method: 引入EverMemBench基准，包含多参与者、多群组的对话，跨越超过100万token，具有时间演化信息、跨主题交织和角色特定人设。通过1000多个QA对评估记忆系统的三个维度：细粒度回忆、记忆意识和用户画像理解。

Result: 评估揭示了关键限制：1) 多跳推理在多参与者设置中崩溃，即使oracle模型也只能达到26%；2) 时间推理仍未解决，需要超越时间戳匹配的版本语义；3) 记忆意识受检索瓶颈限制，当前基于相似性的方法无法弥合查询与隐含相关记忆之间的语义鸿沟。

Conclusion: EverMemBench为开发下一代记忆架构提供了一个具有挑战性的测试平台，揭示了当前LLM记忆系统在复杂真实场景中的关键局限性。

Abstract: Long-term conversational memory is essential for LLM-based assistants, yet existing benchmarks focus on dyadic, single-topic dialogues that fail to capture real-world complexity. We introduce EverMemBench, a benchmark featuring multi-party, multi-group conversations spanning over 1 million tokens with temporally evolving information, cross-topic interleaving, and role-specific personas. EverMemBench evaluates memory systems across three dimensions through 1,000+ QA pairs: fine-grained recall, memory awareness, and user profile understanding. Our evaluation reveals critical limitations: (1) multi-hop reasoning collapses in multi-party settings, with even oracle models achieving only 26%; (2) temporal reasoning remains unsolved, requiring version semantics beyond timestamp matching; (3) memory awareness is bottlenecked by retrieval, where current similarity-based methods fail to bridge the semantic gap between queries and implicitly relevant memories. EverMemBench provides a challenging testbed for developing next-generation memory architectures.

</details>


### [362] [DreamOn: Diffusion Language Models For Code Infilling Beyond Fixed-size Canvas](https://arxiv.org/abs/2602.01326)
*Zirui Wu,Lin Zheng,Zhihui Xie,Jiacheng Ye,Jiahui Gao,Shansan Gong,Yansong Feng,Zhenguo Li,Wei Bi,Guorui Zhou,Lingpeng Kong*

Main category: cs.CL

TL;DR: DreamOn是一个新颖的扩散框架，解决了扩散语言模型在代码填充任务中需要固定长度掩码序列的限制，实现了动态可变长度的生成。


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型虽然提供了灵活的非自回归生成能力，但在实际应用中受到固定长度掩码序列要求的限制。当预定义的掩码大小与理想完成长度不匹配时，会严重降低代码填充性能，这阻碍了扩散语言模型的实际部署。

Method: DreamOn通过向扩散过程添加两个长度控制状态来增强模型，使模型能够基于自身预测自主扩展或收缩输出长度。该方法只需要对现有扩散语言模型的训练目标进行最小修改，无需架构更改。

Result: 基于Dream-Coder-7B和DiffuCoder-7B构建的DreamOn在HumanEval-Infilling和SantaCoder-FIM上达到了与最先进的自回归模型相当的填充性能，并且匹配了使用真实长度获得的oracle性能。

Conclusion: DreamOn消除了扩散语言模型实际部署的一个基本障碍，显著提高了其在可变长度生成方面的灵活性和适用性。

Abstract: Diffusion Language Models (DLMs) present a compelling alternative to autoregressive models, offering flexible, any-order infilling without specialized prompting design. However, their practical utility is blocked by a critical limitation: the requirement of a fixed-length masked sequence for generation. This constraint severely degrades code infilling performance when the predefined mask size mismatches the ideal completion length. To address this, we propose DreamOn, a novel diffusion framework that enables dynamic, variable-length generation. DreamOn augments the diffusion process with two length control states, allowing the model to autonomously expand or contract the output length based solely on its own predictions. We integrate this mechanism into existing DLMs with minimal modifications to the training objective and no architectural changes. Built upon Dream-Coder-7B and DiffuCoder-7B, DreamOn achieves infilling performance on par with state-of-the-art autoregressive models on HumanEval-Infilling and SantaCoder-FIM and matches oracle performance achieved with ground-truth length. Our work removes a fundamental barrier to the practical deployment of DLMs, significantly advancing their flexibility and applicability for variable-length generation. Our code is available at https://github.com/DreamLM/DreamOn.

</details>


### [363] [CRAFT: Calibrated Reasoning with Answer-Faithful Traces via Reinforcement Learning for Multi-Hop Question Answering](https://arxiv.org/abs/2602.01348)
*Yu Liu,Wenxiao Zhang,Cong Cao,Fangfang Yuan,Weizhuo Chen,Cheng Hu,Pin Xu,Yuling Yang,Kun Peng,Diandian Guo,Qiang Sun,Yanbing Liu,Jin B. Hong,Zhiyuan Ma*

Main category: cs.CL

TL;DR: CRAFT是一个基于强化学习的框架，通过双重奖励机制优化多跳推理，提高答案准确性和推理忠实度，解决推理崩溃、推理-答案不一致和格式控制丢失等问题。


<details>
  <summary>Details</summary>
Motivation: 当前检索增强生成在多跳问答中存在三个挑战：1) 推理崩溃 - 多跳组合和噪声检索导致推理不稳定；2) 推理-答案不一致 - LLM生成的不确定性和证据-干扰物混合导致答案正确但推理不忠实；3) 格式控制丢失 - 传统思维链生成常偏离所需的结构化输出格式。

Method: 提出CRAFT框架，基于组相对策略优化的强化学习方法，采用双重奖励机制：确定性奖励确保结构正确性，基于评判器的奖励验证语义忠实度。支持可控的推理轨迹变体，系统分析结构和规模对推理性能的影响。

Result: 在三个多跳问答基准测试中，CRAFT提高了答案准确性和推理忠实度。CRAFT 7B模型在多个推理轨迹设置下实现了与闭源LLM竞争的性能。

Conclusion: CRAFT通过强化学习框架有效解决了多跳问答中的推理忠实度问题，双重奖励机制和可控推理轨迹变体为系统分析推理性能提供了有效工具。

Abstract: Retrieval-augmented generation (RAG) is widely used to ground Large Language Models (LLMs) for multi-hop question answering. Recent work mainly focused on improving answer accuracy via fine-tuning and structured or reinforcement-based optimization. However, reliable reasoning in response generation faces three challenges: 1) Reasoning Collapse. Reasoning in multi-hop QA is inherently complex due to multi-hop composition and is further destabilized by noisy retrieval. 2) Reasoning-answer inconsistency. Due to the intrinsic uncertainty of LLM generation and exposure to evidence--distractor mixtures, models may produce correct answers that are not faithfully supported by their intermediate reasoning or evidence. 3) Loss of format control. Traditional chain-of-thought generation often deviates from required structured output formats, leading to incomplete or malformed structured content. To address these challenges, we propose CRAFT (Calibrated Reasoning with Answer-Faithful Traces), a Group Relative Policy Optimization (GRPO) based reinforcement learning framework that trains models to perform faithful reasoning during response generation. CRAFT employs dual reward mechanisms to optimize multi-hop reasoning: deterministic rewards ensure structural correctness while judge-based rewards verify semantic faithfulness. This optimization framework supports controllable trace variants that enable systematic analysis of how structure and scale affect reasoning performance and faithfulness. Experiments on three multi-hop QA benchmarks show that CRAFT improves both answer accuracy and reasoning faithfulness across model scales, with the CRAFT 7B model achieving competitive performance with closed-source LLMs across multiple reasoning trace settings.

</details>


### [364] [Balancing Understanding and Generation in Discrete Diffusion Models](https://arxiv.org/abs/2602.01362)
*Yue Liu,Yuzhong Zhao,Zheyong Xie,Qixiang Ye,Jianbin Jiao,Yao Hu,Shaosheng Cao,Yunfan Liu*

Main category: cs.CL

TL;DR: XDLM统一了掩码扩散语言模型和均匀噪声扩散语言模型，通过平稳噪声核桥接两种范式，在语义理解和少步生成质量间取得更好平衡。


<details>
  <summary>Details</summary>
Motivation: 当前离散生成模型中，掩码扩散语言模型在语义理解和零样本泛化方面表现优异，而均匀噪声扩散语言模型在少步生成质量上更强，但两者都无法在理解和生成能力上取得平衡。

Method: 提出XDLM，通过平稳噪声核桥接两种范式，提供理论统一框架，并通过代数简化后验概率缓解内存瓶颈。

Result: XDLM在理解和生成能力的帕累托前沿上取得进步：零样本文本基准超越UDLM 5.4分，少步图像生成FID 54.1优于MDLM的80.8，调优8B参数大模型时32步达到15.0 MBPP，性能翻倍。

Conclusion: XDLM成功统一了两种离散生成模型范式，在语义理解和生成质量间实现更好平衡，训练动态分析显示其具有优越的长期扩展潜力。

Abstract: In discrete generative modeling, two dominant paradigms demonstrate divergent capabilities: Masked Diffusion Language Models (MDLM) excel at semantic understanding and zero-shot generalization, whereas Uniform-noise Diffusion Language Models (UDLM) achieve strong few-step generation quality, yet neither attains balanced performance across both dimensions. To address this, we propose XDLM, which bridges the two paradigms via a stationary noise kernel. XDLM offers two key contributions: (1) it provides a principled theoretical unification of MDLM and UDLM, recovering each paradigm as a special case; and (2) an alleviated memory bottleneck enabled by an algebraic simplification of the posterior probabilities. Experiments demonstrate that XDLM advances the Pareto frontier between understanding capability and generation quality. Quantitatively, XDLM surpasses UDLM by 5.4 points on zero-shot text benchmarks and outperforms MDLM in few-step image generation (FID 54.1 vs. 80.8). When scaled to tune an 8B-parameter large language model, XDLM achieves 15.0 MBPP in just 32 steps, effectively doubling the baseline performance. Finally, analysis of training dynamics reveals XDLM's superior potential for long-term scaling. Code is available at https://github.com/MzeroMiko/XDLM

</details>


### [365] [Context Dependence and Reliability in Autoregressive Language Models](https://arxiv.org/abs/2602.01378)
*Poushali Sengupta,Shashi Raj Pandey,Sabita Maharjan,Frank Eliassen*

Main category: cs.CL

TL;DR: RISE方法解决LLM解释中冗余信息干扰问题，通过量化每个输入的独特影响来提供更清晰稳定的归因分数。


<details>
  <summary>Details</summary>
Motivation: LLM生成输出时使用大量上下文，其中包含提示、检索段落和交互历史中的冗余信息。标准解释方法难以处理冗余和重叠上下文，微小输入变化会导致归因分数不可预测的偏移，影响可解释性并引发如提示注入等风险担忧。

Method: 提出RISE（冗余不敏感解释评分）方法，量化每个输入相对于其他输入的独特影响，最小化冗余影响，提供更清晰稳定的归因。

Result: 实验证明RISE比传统方法提供更鲁棒的解释，强调条件信息对于可信LLM解释和监控的重要性。

Conclusion: RISE方法能够有效区分上下文中的关键元素与相关元素，为LLM解释提供更可靠、稳定的归因分析，有助于提高模型透明度和安全性监控。

Abstract: Large language models (LLMs) generate outputs by utilizing extensive context, which often includes redundant information from prompts, retrieved passages, and interaction history. In critical applications, it is vital to identify which context elements actually influence the output, as standard explanation methods struggle with redundancy and overlapping context. Minor changes in input can lead to unpredictable shifts in attribution scores, undermining interpretability and raising concerns about risks like prompt injection. This work addresses the challenge of distinguishing essential context elements from correlated ones. We introduce RISE (Redundancy-Insensitive Scoring of Explanation), a method that quantifies the unique influence of each input relative to others, minimizing the impact of redundancies and providing clearer, stable attributions. Experiments demonstrate that RISE offers more robust explanations than traditional methods, emphasizing the importance of conditional information for trustworthy LLM explanations and monitoring.

</details>


### [366] [On the Power of (Approximate) Reward Models for Inference-Time Scaling](https://arxiv.org/abs/2602.01381)
*Youheng Zhu,Yiping Lu*

Main category: cs.CL

TL;DR: 本文从理论上证明了近似奖励模型的贝尔曼误差是SMC推理时间扩展有效性的关键因素，当误差为O(1/T)时，推理复杂度可从指数级降至多项式级。


<details>
  <summary>Details</summary>
Motivation: 实际部署的推理时间扩展系统都依赖近似奖励模型而非真实奖励模型，因此需要从理论上解释为什么以及何时近似奖励模型足以支持有效的推理时间扩展。

Method: 采用理论分析方法，将近似奖励模型的贝尔曼误差作为关键指标，分析其与推理过程长度T的关系，证明在特定误差界限下，结合SMC方法能够显著降低推理复杂度。

Result: 当近似奖励模型的贝尔曼误差被限制在O(1/T)时，使用SMC进行推理时间扩展可以将推理的计算复杂度从T的指数级降低到多项式级，实现推理效率的指数级提升。

Conclusion: 近似奖励模型的贝尔曼误差是决定推理时间扩展有效性的关键因素，只要误差足够小（O(1/T)），即使使用近似奖励模型也能获得指数级的推理效率提升。

Abstract: Inference-time scaling has recently emerged as a powerful paradigm for improving the reasoning capability of large language models. Among various approaches, Sequential Monte Carlo (SMC) has become a particularly important framework, enabling iterative generation, evaluation, rejection, and resampling of intermediate reasoning trajectories. A central component in this process is the reward model, which evaluates partial solutions and guides the allocation of computation during inference.
  However, in practice, true reward models are never available. All deployed systems rely on approximate reward models, raising a fundamental question: Why and when do approximate reward models suffice for effective inference-time scaling? In this work, we provide a theoretical answer. We identify the Bellman error of the approximate reward model as the key quantity governing the effectiveness of SMC-based inference-time scaling. For a reasoning process of length $T$, we show that if the Bellman error of the approximate reward model is bounded by $O(1/T)$, then combining this reward model with SMC reduces the computational complexity of reasoning from exponential in $T$ to polynomial in $T$. This yields an exponential improvement in inference efficiency despite using only approximate rewards.

</details>


### [367] [Rethinking Selective Knowledge Distillation](https://arxiv.org/abs/2602.01395)
*Almog Tavor,Itay Ebenspanger,Neil Cnaan,Mor Geva*

Main category: cs.CL

TL;DR: 本文系统研究了自回归大语言模型中的选择性知识蒸馏，提出了基于学生熵的位置选择方法（SE-KD），在多个基准测试中提升了准确性、任务遵从性和内存效率，扩展至三个维度（SE-KD 3X）可显著减少训练时间和存储需求。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型的知识蒸馏研究倾向于使用选择性蒸馏（仅监督部分token位置、词汇类别或训练样本），但缺乏对重要性信号、选择策略及其相互作用的系统分析，不清楚哪些方法最有效。

Method: 1. 将选择性知识蒸馏分解为位置、类别和样本三个维度；2. 系统比较不同重要性信号和选择策略；3. 提出基于学生熵的位置选择方法（SE-KD）；4. 将方法扩展至三个维度（SE-KD 3X）。

Result: SE-KD在多个基准测试中优于密集蒸馏，提升了准确性、下游任务遵从性和内存效率。SE-KD 3X实现了互补的效率增益，使离线教师缓存可行，相比先前方法减少70%训练时间、18%峰值内存和80%存储使用，且不牺牲性能。

Conclusion: 通过系统分析选择性知识蒸馏的三个维度，提出的学生熵引导位置选择方法（SE-KD）及其三维扩展（SE-KD 3X）在保持性能的同时显著提升了训练效率和资源利用率，为大语言模型的高效知识蒸馏提供了有效解决方案。

Abstract: Growing efforts to improve knowledge distillation (KD) in large language models (LLMs) replace dense teacher supervision with selective distillation, which uses a subset of token positions, vocabulary classes, or training samples for supervision. However, it remains unclear which importance signals, selection policies, and their interplay are most effective. In this work, we revisit where and how to distill in autoregressive LLMs. We disentangle selective KD along the position, class, and sample axes and systematically compare importance signals and selection policies. Then, guided by this analysis, we identify underexplored opportunities and introduce student-entropy-guided position selection (SE-KD). Across a suite of benchmarks, SE-KD often improves accuracy, downstream task adherence, and memory efficiency over dense distillation. Extending this approach across the class and sample axes (SE-KD 3X) yields complementary efficiency gains that make offline teacher caching feasible. In practice, this reduces wall time by 70% and peak memory by 18%, while cutting storage usage by 80% over prior methods without sacrificing performance.

</details>


### [368] [From Pragmas to Partners: A Symbiotic Evolution of Agentic High-Level Synthesis](https://arxiv.org/abs/2602.01401)
*Niansong Zhang,Sunwoo Kim,Shreesha Srinath,Zhiru Zhang*

Main category: cs.CL

TL;DR: 本文认为在AI代理时代，高层次综合（HLS）仍然至关重要，它作为代理优化的自然层，提供快速迭代、可移植性和设计可置换性。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型兴起，AI驱动的硬件设计受到关注，引发了一个问题：在代理时代，高层次综合（HLS）是否仍然重要？本文旨在论证HLS在AI代理驱动的硬件设计中仍然具有关键作用。

Method: 这是一篇立场论文，通过三个主要贡献来分析HLS在代理时代的作用：1) 解释HLS作为实用抽象层和黄金参考的作用；2) 识别当前HLS工具的关键限制；3) 提出代理HLS共生演化的分类法。

Result: 论文提出HLS是代理优化的自然层，并识别了当前HLS工具的三大限制：性能反馈不足、接口僵化和可调试性有限。同时建立了从协同设计到自主设计伙伴的代理HLS演化分类法。

Conclusion: HLS在AI代理时代仍然至关重要，它提供了代理优化所需的关键特性。虽然成熟的代理硬件系统将同时利用HLS和RTL，但HLS作为抽象层和黄金参考的作用不可替代，且AI代理能够解决当前HLS工具的局限性。

Abstract: The rise of large language models has sparked interest in AI-driven hardware design, raising the question: does high-level synthesis (HLS) still matter in the agentic era? We argue that HLS remains essential. While we expect mature agentic hardware systems to leverage both HLS and RTL, this paper focuses on HLS and its role in enabling agentic optimization. HLS offers faster iteration cycles, portability, and design permutability that make it a natural layer for agentic optimization.This position paper makes three contributions. First, we explain why HLS serves as a practical abstraction layer and a golden reference for agentic hardware design. Second, we identify key limitations of current HLS tools, namely inadequate performance feedback, rigid interfaces, and limited debuggability that agents are uniquely positioned to address. Third, we propose a taxonomy for the symbiotic evolution of agentic HLS, clarifying how responsibility shifts from human designers to AI agents as systems advance from copilots to autonomous design partners.

</details>


### [369] [SentiFuse: Deep Multi-model Fusion Framework for Robust Sentiment Extraction](https://arxiv.org/abs/2602.01447)
*Hieu Minh Duong,Rupa Ghosh,Cong Hoan Nguyen,Eugene Levin,Todd Gary,Long Nguyen*

Main category: cs.CL

TL;DR: SentiFuse是一个灵活的模型无关框架，通过标准化层和多种融合策略集成异构情感分析模型，在多个社交媒体数据集上优于单个模型和简单集成。


<details>
  <summary>Details</summary>
Motivation: 现有情感分析模型各有优势但缺乏有效的统一集成框架，无法充分利用模型互补性来提高分析准确性和可靠性。

Method: 提出SentiFuse框架，包含标准化层支持决策级融合、特征级融合和自适应融合三种策略，能够系统性地组合多样化模型。

Result: 在Crowdflower、GoEmotions和Sentiment140三个大规模社交媒体数据集上，SentiFuse始终优于单个模型和简单集成。特征级融合效果最好，F1分数比最佳单模型和简单平均提升高达4%，自适应融合在处理否定、混合情感等复杂情况时鲁棒性更强。

Conclusion: 系统性地利用模型互补性能够实现更准确可靠的情感分析，SentiFuse框架为集成异构情感模型提供了有效解决方案。

Abstract: Sentiment analysis models exhibit complementary strengths, yet existing approaches lack a unified framework for effective integration. We present SentiFuse, a flexible and model-agnostic framework that integrates heterogeneous sentiment models through a standardization layer and multiple fusion strategies. Our approach supports decision-level fusion, feature-level fusion, and adaptive fusion, enabling systematic combination of diverse models. We conduct experiments on three large-scale social-media datasets: Crowdflower, GoEmotions, and Sentiment140. These experiments show that SentiFuse consistently outperforms individual models and naive ensembles. Feature-level fusion achieves the strongest overall effectiveness, yielding up to 4\% absolute improvement in F1 score over the best individual model and simple averaging, while adaptive fusion enhances robustness on challenging cases such as negation, mixed emotions, and complex sentiment expressions. These results demonstrate that systematically leveraging model complementarity yields more accurate and reliable sentiment analysis across diverse datasets and text types.

</details>


### [370] [Understanding QA generation: Extracting Parametric and Contextual Knowledge with CQA for Low Resource Bangla Language](https://arxiv.org/abs/2602.01451)
*Umme Abira Azmary,MD Ikramul Kayes,Swakkhar Shatabda,Farig Yousuf Sadeque*

Main category: cs.CL

TL;DR: 本文介绍了首个孟加拉语反事实问答数据集BanglaCQA，用于分析低资源语言QA模型中参数知识与上下文知识的依赖关系，并展示了思维链提示在反事实场景中的独特优势。


<details>
  <summary>Details</summary>
Motivation: 低资源语言如孟加拉语的QA模型面临标注数据有限和语言复杂性的挑战，现有数据集缺乏分析模型依赖参数知识还是上下文知识的结构，需要专门的数据集和方法来研究知识来源。

Method: 1) 构建首个孟加拉语反事实QA数据集BanglaCQA，扩展现有数据集并整合反事实段落和可回答性标注；2) 提出针对编码器-解码器语言特定/多语言模型的微调管道，以及针对仅解码器LLM的提示管道；3) 应用基于LLM和人工的语义相似度评估方法；4) 分析不同QA设置下的模型表现。

Result: 思维链提示在反事实场景中展现出独特优势，特别是在仅解码器LLM中能有效提取参数知识。研究揭示了低资源语言QA模型在不同设置下的表现模式，为反事实推理提供了新见解。

Conclusion: 本文不仅为孟加拉语QA的知识来源分析提供了新框架，还发现了反事实推理在低资源语言环境中的关键发现，为相关研究开辟了更广泛的方向。

Abstract: Question-Answering (QA) models for low-resource languages like Bangla face challenges due to limited annotated data and linguistic complexity. A key issue is determining whether models rely more on pre-encoded (parametric) knowledge or contextual input during answer generation, as existing Bangla QA datasets lack the structure required for such analysis. We introduce BanglaCQA, the first Counterfactual QA dataset in Bangla, by extending a Bangla dataset while integrating counterfactual passages and answerability annotations. In addition, we propose fine-tuned pipelines for encoder-decoder language-specific and multilingual baseline models, and prompting-based pipelines for decoder-only LLMs to disentangle parametric and contextual knowledge in both factual and counterfactual scenarios. Furthermore, we apply LLM-based and human evaluation techniques that measure answer quality based on semantic similarity. We also present a detailed analysis of how models perform across different QA settings in low-resource languages, and show that Chain-of-Thought (CoT) prompting reveals a uniquely effective mechanism for extracting parametric knowledge in counterfactual scenarios, particularly in decoder-only LLMs. Our work not only introduces a novel framework for analyzing knowledge sources in Bangla QA but also uncovers critical findings that open up broader directions for counterfactual reasoning in low-resource language settings.

</details>


### [371] [ConPress: Learning Efficient Reasoning from Multi-Question Contextual Pressure](https://arxiv.org/abs/2602.01472)
*Jie Deng,Shining Liang,Jun Li,Hongzhi Li,Yutao Xie*

Main category: cs.CL

TL;DR: 论文提出ConPress方法，通过多问题上下文压力诱导模型自我压缩推理轨迹，用少量数据微调即可显著减少推理token使用，同时保持准确率。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型通过生成长链式思维轨迹解决推理任务，导致推理开销巨大。作者发现当多个独立可回答的问题出现在同一提示中时，模型会自发产生更短的推理轨迹，这被称为"自我压缩"现象。

Method: 提出ConPress（从上下文压力中学习），一种轻量级自监督微调方法。构建多问题提示诱导自我压缩，采样模型输出，解析过滤每个问题的推理轨迹，获得简洁正确的推理路径，用于监督微调。

Result: 仅用8k微调样本，ConPress在MATH500上减少59%推理token使用，在AIME25上减少33%，同时保持有竞争力的准确率。

Conclusion: ConPress方法能够有效内部化压缩推理行为，无需外部教师、手动剪枝或强化学习，显著降低推理开销，为高效推理模型提供新思路。

Abstract: Large reasoning models (LRMs) typically solve reasoning-intensive tasks by generating long chain-of-thought (CoT) traces, leading to substantial inference overhead. We identify a reproducible inference-time phenomenon, termed Self-Compression: when multiple independent and answerable questions are presented within a single prompt, the model spontaneously produces shorter reasoning traces for each question. This phenomenon arises from multi-question contextual pressure during generation and consistently manifests across models and benchmarks. Building on this observation, we propose ConPress (Learning from Contextual Pressure), a lightweight self-supervised fine-tuning approach. ConPress constructs multi-question prompts to induce self-compression, samples the resulting model outputs, and parses and filters per-question traces to obtain concise yet correct reasoning trajectories. These trajectories are directly used for supervised fine-tuning, internalizing compressed reasoning behavior in single-question settings without external teachers, manual pruning, or reinforcement learning. With only 8k fine-tuning examples, ConPress reduces reasoning token usage by 59% on MATH500 and 33% on AIME25, while maintaining competitive accuracy.

</details>


### [372] [Ebisu: Benchmarking Large Language Models in Japanese Finance](https://arxiv.org/abs/2602.01479)
*Xueqing Peng,Ruoyu Xiang,Fan Zhang,Mingzi Song,Mingyang Jiang,Yan Wang,Lingfei Qian,Taiki Hara,Yuqing Guo,Jimin Huang,Junichi Tsujii,Sophia Ananiadou*

Main category: cs.CL

TL;DR: Ebisu是一个针对日语金融语言理解的基准测试，包含两个专家标注的任务：JF-ICR评估投资者问答中的隐含承诺与拒绝识别，JF-TE评估专业披露中嵌套金融术语的分层提取与排序。实验表明即使最先进的LLM在这两个任务上表现不佳。


<details>
  <summary>Details</summary>
Motivation: 日语金融语言具有粘着语结构、混合书写系统和高语境沟通规范，依赖间接表达和隐含承诺，这对LLM构成了重大挑战。需要专门的基准来评估LLM在日语金融领域的语言理解能力。

Method: 创建Ebisu基准，包含两个任务：1) JF-ICR：识别投资者问答中的隐含承诺与拒绝；2) JF-TE：从专业披露文件中分层提取和排序嵌套金融术语。评估了多种开源和专有LLM，包括通用模型、日语适应模型和金融专用模型。

Result: 即使最先进的系统在两个任务上都表现不佳。模型规模的增加仅带来有限改进，语言和领域特定的适应并不能可靠地提升性能，存在显著的性能差距。

Conclusion: Ebisu为推进语言和文化基础的金融NLP提供了聚焦的基准测试。所有数据集和评估脚本都已公开发布，有助于评估和改进LLM在日语金融领域的语言理解能力。

Abstract: Japanese finance combines agglutinative, head-final linguistic structure, mixed writing systems, and high-context communication norms that rely on indirect expression and implicit commitment, posing a substantial challenge for LLMs. We introduce Ebisu, a benchmark for native Japanese financial language understanding, comprising two linguistically and culturally grounded, expert-annotated tasks: JF-ICR, which evaluates implicit commitment and refusal recognition in investor-facing Q&A, and JF-TE, which assesses hierarchical extraction and ranking of nested financial terminology from professional disclosures. We evaluate a diverse set of open-source and proprietary LLMs spanning general-purpose, Japanese-adapted, and financial models. Results show that even state-of-the-art systems struggle on both tasks. While increased model scale yields limited improvements, language- and domain-specific adaptation does not reliably improve performance, leaving substantial gaps unresolved. Ebisu provides a focused benchmark for advancing linguistically and culturally grounded financial NLP. All datasets and evaluation scripts are publicly released.

</details>


### [373] [Alternating Reinforcement Learning for Rubric-Based Reward Modeling in Non-Verifiable LLM Post-Training](https://arxiv.org/abs/2602.01511)
*Ran Xu,Tianci Liu,Zihan Dong,Tony You,Ilgee Hong,Carl Yang,Linjun Zhang,Tao Zhao,Haoyu Wang*

Main category: cs.CL

TL;DR: Rubric-ARM：通过强化学习联合优化评分标准和评判模型，解决传统奖励模型在非可验证领域（如创意写作）中无法捕捉多维度响应质量的问题。


<details>
  <summary>Details</summary>
Motivation: 传统奖励模型通常预测标量分数，无法捕捉非可验证领域（如创意写作、开放式指令遵循）中响应质量的多维度特性。现有方法依赖静态评分标准或分离的训练流程，存在局限性。

Method: 提出Rubric-ARM框架，通过强化学习从偏好反馈中联合优化评分标准生成器和评判模型。将评分标准生成视为潜在动作学习，以最大化判断准确性。引入交替优化策略缓解同时更新的非平稳性，并提供理论分析证明该调度如何减少训练中的梯度方差。

Result: 在多个基准测试中，Rubric-ARM实现了最先进的性能，显著提升了离线强化学习和在线强化学习设置中的下游策略对齐效果。

Conclusion: Rubric-ARM通过联合学习评分标准和评判模型，有效解决了非可验证领域中响应质量评估的多维度问题，为奖励建模提供了更强大的框架。

Abstract: Standard reward models typically predict scalar scores that fail to capture the multifaceted nature of response quality in non-verifiable domains, such as creative writing or open-ended instruction following. To address this limitation, we propose Rubric-ARM, a framework that jointly optimizes a rubric generator and a judge using reinforcement learning from preference feedback. Unlike existing methods that rely on static rubrics or disjoint training pipelines, our approach treats rubric generation as a latent action learned to maximize judgment accuracy. We introduce an alternating optimization strategy to mitigate the non-stationarity of simultaneous updates, providing theoretical analysis that demonstrates how this schedule reduces gradient variance during training. Extensive experiments show that Rubric-ARM achieves state-of-the-art performance among baselines on multiple benchmarks and significantly improves downstream policy alignment in both offline and online reinforcement learning settings.

</details>


### [374] [Argument Rarity-based Originality Assessment for AI-Assisted Writing](https://arxiv.org/abs/2602.01560)
*Keito Inoshita,Michiaki Omura,Tsukasa Yamanaka,Go Maeda,Kentaro Tsuji*

Main category: cs.CL

TL;DR: 该研究提出AROA框架，通过论证稀有性评估学生议论文的原创性，发现质量与原创性存在权衡关系，AI能模仿论证结构但内容原创性不足。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型能轻松生成高质量文本，传统基于质量的写作评估逐渐失去意义。教育的核心目标是培养批判性思维和原创观点，因此评估范式需要从质量转向原创性。

Method: 提出AROA框架，将原创性定义为参考语料库中的稀有性，通过四个互补组件评估：结构稀有性、主张稀有性、证据稀有性和认知深度。使用密度估计量化每个组件的稀有性，并通过质量调整机制整合，将质量和原创性作为独立评估维度。

Result: 实验发现质量与主张稀有性呈强负相关，存在质量-原创性权衡关系：质量越高的文本倾向于使用典型主张模式。AI论文的结构复杂度与人类相当，但主张稀有性显著低于人类，表明LLMs能复现论证形式但在内容原创性上有局限。

Conclusion: AROA框架为自动评估论证原创性提供了有效方法，揭示了质量与原创性的权衡关系，并证明当前LLMs在模仿论证结构方面表现良好，但在生成原创内容方面仍有不足，这对教育评估和AI能力评估具有重要意义。

Abstract: As Large Language Models (LLMs) have become capable of effortlessly generating high-quality text, traditional quality-focused writing assessment is losing its significance. If the essential goal of education is to foster critical thinking and original perspectives, assessment must also shift its paradigm from quality to originality. This study proposes Argument Rarity-based Originality Assessment (AROA), a framework for automatically evaluating argumentative originality in student essays. AROA defines originality as rarity within a reference corpus and evaluates it through four complementary components: structural rarity, claim rarity, evidence rarity, and cognitive depth. The framework quantifies the rarity of each component using density estimation and integrates them with a quality adjustment mechanism, thereby treating quality and originality as independent evaluation axes. Experiments using human essays and AI-generated essays revealed a strong negative correlation between quality and claim rarity, demonstrating a quality-originality trade-off where higher-quality texts tend to rely on typical claim patterns. Furthermore, while AI essays achieved comparable levels of structural complexity to human essays, their claim rarity was substantially lower than that of humans, indicating that LLMs can reproduce the form of argumentation but have limitations in the originality of content.

</details>


### [375] [FS-Researcher: Test-Time Scaling for Long-Horizon Research Tasks with File-System-Based Agents](https://arxiv.org/abs/2602.01566)
*Chiwei Zhu,Benfeng Xu,Mingxuan Du,Shaohan Wang,Xiaorui Wang,Zhendong Mao,Yongdong Zhang*

Main category: cs.CL

TL;DR: FS-Researcher是一个基于文件系统的双智能体框架，通过持久化工作空间解决LLM在深度研究任务中上下文长度限制的问题，实现超越上下文窗口的深度研究扩展。


<details>
  <summary>Details</summary>
Motivation: 深度研究作为LLM智能体的代表性长视野任务，其长轨迹经常超出模型上下文限制，压缩了证据收集和报告编写的token预算，阻碍了有效的测试时扩展。

Method: 引入FS-Researcher框架，包含两个智能体：Context Builder（上下文构建者）作为图书管理员浏览互联网、编写结构化笔记、将原始资料归档到可超越上下文长度的分层知识库；Report Writer（报告编写者）逐节编写最终报告，将知识库作为事实来源。文件系统作为持久外部内存和跨智能体/会话的共享协调媒介。

Result: 在两个开放式基准测试（DeepResearch Bench和DeepConsult）上，FS-Researcher在不同骨干模型上实现了最先进的报告质量。分析显示最终报告质量与分配给Context Builder的计算量呈正相关，验证了文件系统范式下的有效测试时扩展。

Conclusion: FS-Researcher通过文件系统作为持久工作空间，成功解决了LLM在深度研究中的上下文限制问题，实现了超越上下文窗口的扩展，为长视野任务提供了有效的解决方案。

Abstract: Deep research is emerging as a representative long-horizon task for large language model (LLM) agents. However, long trajectories in deep research often exceed model context limits, compressing token budgets for both evidence collection and report writing, and preventing effective test-time scaling. We introduce FS-Researcher, a file-system-based, dual-agent framework that scales deep research beyond the context window via a persistent workspace. Specifically, a Context Builder agent acts as a librarian which browses the internet, writes structured notes, and archives raw sources into a hierarchical knowledge base that can grow far beyond context length. A Report Writer agent then composes the final report section by section, treating the knowledge base as the source of facts. In this framework, the file system serves as a durable external memory and a shared coordination medium across agents and sessions, enabling iterative refinement beyond the context window. Experiments on two open-ended benchmarks (DeepResearch Bench and DeepConsult) show that FS-Researcher achieves state-of-the-art report quality across different backbone models. Further analyses demonstrate a positive correlation between final report quality and the computation allocated to the Context Builder, validating effective test-time scaling under the file-system paradigm. The code and data are anonymously open-sourced at https://github.com/Ignoramus0817/FS-Researcher.

</details>


### [376] [LLM-based Embeddings: Attention Values Encode Sentence Semantics Better Than Hidden States](https://arxiv.org/abs/2602.01572)
*Yeqin Zhang,Yunfei Wang,Jiaxuan Chen,Ke Qin,Yizheng Zhao,Cam-Tu Nguyen*

Main category: cs.CL

TL;DR: 论文提出Value Aggregation方法，利用注意力值向量而非隐藏状态来获取更好的句子表示，在无需训练的情况下超越其他LLM嵌入方法，甚至匹配或超越集成方法MetaEOL。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的句子表示方法大多依赖最后一层隐藏状态，但这些状态针对下一个词预测优化，往往无法有效捕捉全局的句子级语义。

Method: 提出Value Aggregation(VA)方法，通过聚合多个层和token索引的token值向量来获取句子表示。进一步提出Aligned Weighted VA(AlignedWVA)，利用最后一个token的注意力分数作为权重，通过输出投影矩阵对齐加权值向量。

Result: 在无需训练的情况下，VA超越其他LLM嵌入方法，匹配或超越集成方法MetaEOL。AlignedWVA在无需训练的LLM嵌入方法中达到最先进性能，大幅超越高成本的MetaEOL。

Conclusion: 注意力值向量比隐藏状态能更有效地捕捉句子语义，Value Aggregation方法在无需训练的情况下就能获得强大的句子表示，通过微调还有进一步提升潜力。

Abstract: Sentence representations are foundational to many Natural Language Processing (NLP) applications. While recent methods leverage Large Language Models (LLMs) to derive sentence representations, most rely on final-layer hidden states, which are optimized for next-token prediction and thus often fail to capture global, sentence-level semantics. This paper introduces a novel perspective, demonstrating that attention value vectors capture sentence semantics more effectively than hidden states. We propose Value Aggregation (VA), a simple method that pools token values across multiple layers and token indices. In a training-free setting, VA outperforms other LLM-based embeddings, even matches or surpasses the ensemble-based MetaEOL. Furthermore, we demonstrate that when paired with suitable prompts, the layer attention outputs can be interpreted as aligned weighted value vectors. Specifically, the attention scores of the last token function as the weights, while the output projection matrix ($W_O$) aligns these weighted value vectors with the common space of the LLM residual stream. This refined method, termed Aligned Weighted VA (AlignedWVA), achieves state-of-the-art performance among training-free LLM-based embeddings, outperforming the high-cost MetaEOL by a substantial margin. Finally, we highlight the potential of obtaining strong LLM embedding models through fine-tuning Value Aggregation.

</details>


### [377] [Provable Defense Framework for LLM Jailbreaks via Noise-Augumented Alignment](https://arxiv.org/abs/2602.01587)
*Zehua Cheng,Jianwei Yang,Wei Dai,Jiahao Sun*

Main category: cs.CL

TL;DR: 提出Certified Semantic Smoothing (CSS)框架，通过分层随机消融和噪声增强对齐调优，为LLM提供可证明的鲁棒性保证，将梯度攻击成功率从84.2%降至1.2%，同时保持94.1%的良性效用。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型对自适应越狱攻击仍然脆弱，现有防御方法（如GCG）缺乏理论保证。需要从经验性防御转向可证明的鲁棒性框架，提供确定性的安全保证。

Method: 1. 提出Certified Semantic Smoothing (CSS)框架，通过分层随机消融将输入分为不可变结构提示和可变载荷；2. 使用超几何分布推导严格的l0范数保证；3. 采用Noise-Augmented Alignment Tuning (NAAT)将基础模型转化为语义去噪器，解决稀疏上下文性能下降问题。

Result: 在Llama-3上的实验表明：梯度攻击成功率从84.2%降至1.2%；良性效用保持94.1%；显著优于字符级基线方法（效用降至74.3%）。

Conclusion: 该框架提供了确定性的安全证书，确保模型在可证明半径内对所有对抗变体保持鲁棒，实现了从单次推理保证到集成统计稳定性的转变。

Abstract: Large Language Models (LLMs) remain vulnerable to adaptive jailbreaks that easily bypass empirical defenses like GCG. We propose a framework for certifiable robustness that shifts safety guarantees from single-pass inference to the statistical stability of an ensemble. We introduce Certified Semantic Smoothing (CSS) via Stratified Randomized Ablation, a technique that partitions inputs into immutable structural prompts and mutable payloads to derive rigorous lo norm guarantees using the Hypergeometric distribution. To resolve performance degradation on sparse contexts, we employ Noise-Augmented Alignment Tuning (NAAT), which transforms the base model into a semantic denoiser. Extensive experiments on Llama-3 show that our method reduces the Attack Success Rate of gradient-based attacks from 84.2% to 1.2% while maintaining 94.1% benign utility, significantly outperforming character-level baselines which degrade utility to 74.3%. This framework provides a deterministic certificate of safety, ensuring that a model remains robust against all adversarial variants within a provable radius.

</details>


### [378] [Wiki Live Challenge: Challenging Deep Research Agents with Expert-Level Wikipedia Articles](https://arxiv.org/abs/2602.01590)
*Shaohan Wang,Benfeng Xu,Licheng Zhang,Mingxuan Du,Chiwei Zhu,Xiaorui Wang,Zhendong Mao,Yongdong Zhang*

Main category: cs.CL

TL;DR: 论文提出了Wiki Live Challenge (WLC)基准，利用最新的维基百科优质文章作为专家级参考，用于评估深度研究代理(DRA)的能力，并开发了包含39个标准的细粒度评估框架。


<details>
  <summary>Details</summary>
Motivation: 当前深度研究代理(DRA)的评估框架主要依赖LLM生成的参考或LLM衍生的评估维度，这些方法虽然具有可扩展性，但缺乏专家验证内容的可靠性，且难以提供客观、细粒度的关键维度评估。

Method: 引入Wiki Live Challenge (WLC)基准，利用最新的维基百科优质文章作为专家级参考；策划包含100篇近期优质文章的数据集；提出Wiki Eval评估框架，包含39个写作质量标准和严格的事实可验证性指标。

Result: 对各种DRA系统的广泛实验表明，当前DRA与人类专家级维基百科文章之间存在显著差距，验证了WLC在推进代理研究方面的有效性。

Conclusion: WLC基准通过利用维基百科严格的中立性、全面性和可验证性标准，为深度研究代理提供了可靠的评估框架，有助于推动代理研究的发展。

Abstract: Deep Research Agents (DRAs) have demonstrated remarkable capabilities in autonomous information retrieval and report generation, showing great potential to assist humans in complex research tasks. Current evaluation frameworks primarily rely on LLM-generated references or LLM-derived evaluation dimensions. While these approaches offer scalability, they often lack the reliability of expert-verified content and struggle to provide objective, fine-grained assessments of critical dimensions. To bridge this gap, we introduce Wiki Live Challenge (WLC), a live benchmark that leverages the newest Wikipedia Good Articles (GAs) as expert-level references. Wikipedia's strict standards for neutrality, comprehensiveness, and verifiability serve as a great challenge for DRAs, with GAs representing the pinnacle of which. We curate a dataset of 100 recent Good Articles and propose Wiki Eval, a comprehensive evaluation framework comprising a fine-grained evaluation method with 39 criteria for writing quality and rigorous metrics for factual verifiability. Extensive experiments on various DRA systems demonstrate a significant gap between current DRAs and human expert-level Wikipedia articles, validating the effectiveness of WLC in advancing agent research. We release our benchmark at https://github.com/WangShao2000/Wiki_Live_Challenge

</details>


### [379] [The Art of Socratic Inquiry: A Framework for Proactive Template-Guided Therapeutic Conversation Generation](https://arxiv.org/abs/2602.01598)
*Mingwen Zhang,Minqiang Yang,Changsheng Ma,Yang Yu,Hui Bai,Chen Xu,Xiangzhen Kong,Bin Hu*

Main category: cs.CL

TL;DR: 提出Socratic Inquiry Framework (SIF)框架，将LLM从被动倾听者转变为主动认知引导者，通过策略锚定和模板检索实现主动提问，提升CBT治疗效果。


<details>
  <summary>Details</summary>
Motivation: 当前心理治疗LLM过于被动，只能提供共情但肤浅的回应，无法揭示潜在信念或引导行为改变，而主动提问是CBT的核心技术，需要填补这一空白。

Method: 提出Socratic Inquiry Framework (SIF)：1) 策略锚定决定何时提问；2) 模板检索决定提问内容；3) 无需端到端重新训练；4) 创建Socratic-QA数据集提供监督学习。

Result: SIF显著提高了主动提问频率、对话深度和治疗对齐性，实现了从被动安慰到主动探索的转变，建立了心理LLM的新范式。

Conclusion: SIF框架为心理LLM建立了新范式：不仅是回应，更是引导，将LLM从被动倾听者转变为主动认知引导者，提升了CBT治疗效果。

Abstract: Proactive questioning, where therapists deliberately initiate structured, cognition-guiding inquiries, is a cornerstone of cognitive behavioral therapy (CBT). Yet, current psychological large language models (LLMs) remain overwhelmingly reactive, defaulting to empathetic but superficial responses that fail to surface latent beliefs or guide behavioral change. To bridge this gap, we propose the \textbf{Socratic Inquiry Framework (SIF)}, a lightweight, plug-and-play therapeutic intent planner that transforms LLMs from passive listeners into active cognitive guides. SIF decouples \textbf{when to ask} (via Strategy Anchoring) from \textbf{what to ask} (via Template Retrieval), enabling context-aware, theory-grounded questioning without end-to-end retraining. Complementing SIF, we introduce \textbf{Socratic-QA}, a high-quality dataset of strategy-aligned Socratic sequences that provides explicit supervision for proactive reasoning. Experiments show that SIF significantly enhances proactive questioning frequency, conversational depth, and therapeutic alignment, marking a clear shift from reactive comfort to proactive exploration. Our work establishes a new paradigm for psychologically informed LLMs: not just to respond, but to guide.

</details>


### [380] [SEA-Guard: Culturally Grounded Multilingual Safeguard for Southeast Asia](https://arxiv.org/abs/2602.01618)
*Panuthep Tasawong,Jian Gang Ngui,Alham Fikri Aji,Trevor Cohn,Peerat Limkonchotiwat*

Main category: cs.CL

TL;DR: 提出了SEA-Guard系列模型，这是首个基于东南亚文化背景的多语言安全防护模型，通过代理数据生成框架创建区域特定的安全数据集，在检测区域敏感内容方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的AI对齐需要文化感知的安全防护，但构建大规模文化基础数据集面临资源有限和本地标注者稀缺的挑战。现有方法依赖英语数据集的机器翻译，往往忽略了区域和文化细微差别。

Method: 提出了一个新颖的代理数据生成框架，可扩展地创建真实、区域特定的安全数据集，特别针对东南亚地区。在此基础上开发了SEA-Guard系列多语言安全防护模型。

Result: SEA-Guard在多个基准测试和文化变体中一致优于现有的安全防护模型，在检测区域敏感或有害内容方面表现突出，同时保持了强大的通用安全性能。

Conclusion: 该研究成功开发了首个基于东南亚文化背景的多语言安全防护模型，通过创新的数据生成方法解决了文化感知AI对齐中的关键挑战，为区域特定的AI安全提供了有效解决方案。

Abstract: Culturally aware safeguards are crucial for AI alignment in real-world settings, where safety extends beyond common sense and encompasses diverse local values, norms, and region-specific regulations. However, building large-scale, culturally grounded datasets is challenging due to limited resources and a scarcity of native annotators. Consequently, many safeguard models rely on machine translation of English datasets, often missing regional and cultural nuances. We present a novel agentic data-generation framework to scalably create authentic, region-specific safety datasets for Southeast Asia (SEA). On this foundation, we introduce the SEA-Guard family, the first multilingual safeguard models grounded in SEA cultural contexts. Evaluated across multiple benchmarks and cultural variants, SEA-Guard consistently outperforms existing safeguards at detecting regionally sensitive or harmful content while maintaining strong general safety performance.

</details>


### [381] [A2Eval: Agentic and Automated Evaluation for Embodied Brain](https://arxiv.org/abs/2602.01640)
*Shuai Zhang,Jiayu Hu,Zijie Chen,Zeyuan Ding,Yi Zhang,Yingji Zhang,Ziyi Zhou,Junwei Liao,Shengjie Zhou,Yong Dai,Zhenzhong Lan,Xiaozhu Ju*

Main category: cs.CL

TL;DR: A2Eval是一个自动化的具身VLM评估框架，通过两个协作智能体自动生成平衡、紧凑的评估套件和执行评估，显著降低计算成本和人工标注需求。


<details>
  <summary>Details</summary>
Motivation: 当前具身VLM评估依赖静态、专家定义、人工标注的基准测试，存在严重冗余和覆盖不平衡问题。这种劳动密集型范式消耗大量计算和标注资源，增加成本，扭曲模型排名，阻碍迭代开发。

Method: 提出Agentic Automatic Evaluation (A2Eval)框架，包含两个协作智能体：Data Agent自主归纳能力维度并组装平衡紧凑的评估套件；Eval Agent合成和验证可执行的评估流程，实现完全自主的高保真评估。

Result: 在10个基准测试和13个模型上的评估显示：A2Eval将评估套件压缩85%，总体计算成本降低77%，速度提升4.6倍，同时保持评估质量。纠正系统性排名偏差，人类对齐度达Spearman's rho=0.85，排名保真度高(Kendall's tau=0.81)。

Conclusion: A2Eval为高保真、低成本的具身评估设立了新标准，通过自动化基准生成和评估解决了当前评估范式的关键瓶颈，促进了更高效的模型迭代开发。

Abstract: Current embodied VLM evaluation relies on static, expert-defined, manually annotated benchmarks that exhibit severe redundancy and coverage imbalance. This labor intensive paradigm drains computational and annotation resources, inflates costs, and distorts model rankings, ultimately stifling iterative development. To address this, we propose Agentic Automatic Evaluation (A2Eval), the first agentic framework that automates benchmark curation and evaluation through two collaborative agents. The Data Agent autonomously induces capability dimensions and assembles a balanced, compact evaluation suite, while the Eval Agent synthesizes and validates executable evaluation pipelines, enabling fully autonomous, high-fidelity assessment. Evaluated across 10 benchmarks and 13 models, A2Eval compresses evaluation suites by 85%, reduces overall computational costs by 77%, and delivers a 4.6x speedup while preserving evaluation quality. Crucially, A2Eval corrects systematic ranking biases, improves human alignment to Spearman's rho=0.85, and maintains high ranking fidelity (Kendall's tau=0.81), establishing a new standard for high-fidelity, low-cost embodied assessment. Our code and data will be public soon.

</details>


### [382] [Steering Vector Fields for Context-Aware Inference-Time Control in Large Language Models](https://arxiv.org/abs/2602.01654)
*Jiaqian Li,Yanshu Li,Kuan-Hao Huang*

Main category: cs.CL

TL;DR: SVF提出基于向量场的上下文相关隐空间干预方法，相比静态steering vectors提供更可靠的控制


<details>
  <summary>Details</summary>
Motivation: 现有steering vectors在实践中不可靠：某些概念不可操控，即使平均有效也可能对部分输入产生反效果，长文本生成和多属性控制时可靠性下降

Method: 从几何视角分析失败原因，提出Steering Vector Fields (SVF)：学习可微概念评分函数，其局部梯度定义每个激活点的操控方向，使干预显式地依赖于上下文

Result: SVF在多个LLM和操控任务中提供更强、更可靠的控制，提升推理时操控的实用性

Conclusion: SVF通过上下文相关的向量场方法解决了静态steering vectors的局限性，支持协调的多层干预和高效的长文本、多属性控制

Abstract: Steering vectors (SVs) offer a lightweight way to control large language models (LLMs) at inference time by shifting hidden activations, providing a practical middle ground between prompting and fine-tuning. Yet SVs can be unreliable in practice. Some concepts are unsteerable, and even when steering helps on average it can backfire for a non-trivial fraction of inputs. Reliability also degrades in long-form generation and multi-attribute steering. We take a geometric view of these failures. A static SV applies the same update vector everywhere in representation space, implicitly assuming that the concept-improving direction is constant across contexts. When the locally effective direction varies with the current activation, a single global vector can become misaligned, which yields weak or reversed effects. Guided by this perspective, we propose Steering Vector Fields (SVF), which learns a differentiable concept scoring function whose local gradient defines the steering direction at each activation, making interventions explicitly context-dependent. This formulation supports coordinated multi-layer interventions in a shared, aligned concept space, and enables efficient long-form and multi-attribute control within a unified framework. Across multiple LLMs and steering tasks, SVF delivers stronger and more reliable control, improving the practicality of inference-time steering.

</details>


### [383] [CoDiQ: Test-Time Scaling for Controllable Difficult Question Generation](https://arxiv.org/abs/2602.01660)
*Zhongyuan Peng,Caijun Xu,Changyi Xiao,Shibo Hong,Eli Zhang,Stephen Huang,Yixin Cao*

Main category: cs.CL

TL;DR: CoDiQ框架通过测试时缩放实现细粒度难度控制，生成高质量竞赛级问题，构建了44K问题语料库，显著提升大型推理模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有自动化问题生成方法缺乏精确难度控制、计算成本高，且难以大规模生成竞赛级问题。需要一种能够控制难度同时保证问题可解性的框架来提升大型推理模型的训练效果。

Method: 提出CoDiQ框架：1) 发现测试时缩放趋势（扩展推理token预算增加难度但降低可解性）和模型生成有效高难度问题的内在属性上限；2) 基于Qwen3-8B开发CoDiQ-Generator，提升困难问题生成的上限；3) 构建包含44K竞赛级问题序列的CoDiQ-Corpus。

Result: 人工评估显示CoDiQ生成的问题比LiveCodeBench/AIME显著更具挑战性，同时保持超过82%的可解性。在CoDiQ-Corpus上训练的大型推理模型推理性能大幅提升，验证了缩放控制难度训练问题能增强推理能力。

Conclusion: CoDiQ框架通过细粒度难度控制和保证问题可解性，成功生成了高质量的竞赛级问题语料库，有效提升了大型推理模型的推理能力。开源了CoDiQ-Corpus、CoDiQ-Generator及相关实现以支持相关研究。

Abstract: Large Reasoning Models (LRMs) benefit substantially from training on challenging competition-level questions. However, existing automated question synthesis methods lack precise difficulty control, incur high computational costs, and struggle to generate competition-level questions at scale. In this paper, we propose CoDiQ (Controllable Difficult Question Generation), a novel framework enabling fine-grained difficulty control via test-time scaling while ensuring question solvability. Specifically, first, we identify a test-time scaling tendency (extended reasoning token budget boosts difficulty but reduces solvability) and the intrinsic properties defining the upper bound of a model's ability to generate valid, high-difficulty questions. Then, we develop CoDiQ-Generator from Qwen3-8B, which improves the upper bound of difficult question generation, making it particularly well-suited for challenging question construction. Building on the CoDiQ framework, we build CoDiQ-Corpus (44K competition-grade question sequences). Human evaluations show these questions are significantly more challenging than LiveCodeBench/AIME with over 82% solvability. Training LRMs on CoDiQ-Corpus substantially improves reasoning performance, verifying that scaling controlled-difficulty training questions enhances reasoning capabilities. We open-source CoDiQ-Corpus, CoDiQ-Generator, and implementations to support related research.

</details>


### [384] [Scaling Search-Augmented LLM Reasoning via Adaptive Information Control](https://arxiv.org/abs/2602.01672)
*Siheng Xiong,Oguzhan Gungordu,Blair Johnson,James C. Kerce,Faramarz Fekri*

Main category: cs.CL

TL;DR: DeepControl框架通过信息效用度量和自适应控制机制，优化搜索增强推理代理的信息检索过程，减少冗余证据和上下文饱和问题，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有搜索增强推理代理在多步推理与外部信息检索交替进行时，存在不受控检索导致冗余证据、上下文饱和和不稳定学习的问题。基于结果的强化学习方法对信息获取调节指导有限。

Method: 提出DeepControl框架，基于信息效用（衡量给定推理状态下检索证据的边际价值）的概念，引入检索继续性和粒度控制机制，选择性调节何时继续/停止检索以及扩展多少信息。采用退火控制策略使代理在训练中内化有效的信息获取行为。

Result: 在七个基准测试上的广泛实验表明，该方法始终优于强基线。在Qwen2.5-7B和Qwen2.5-3B上分别比基于结果的强化学习基线平均提升9.4%和8.6%的性能，且始终优于无检索和基于检索但无显式信息控制的推理方法。

Conclusion: 自适应信息控制对于将搜索增强推理代理扩展到复杂的现实世界信息环境至关重要。DeepControl通过形式化的信息效用度量和控制机制，有效解决了现有方法的局限性。

Abstract: Search-augmented reasoning agents interleave multi-step reasoning with external information retrieval, but uncontrolled retrieval often leads to redundant evidence, context saturation, and unstable learning. Existing approaches rely on outcome-based reinforcement learning (RL), which provides limited guidance for regulating information acquisition. We propose DeepControl, a framework for adaptive information control based on a formal notion of information utility, which measures the marginal value of retrieved evidence under a given reasoning state. Building on this utility, we introduce retrieval continuation and granularity control mechanisms that selectively regulate when to continue and stop retrieval, and how much information to expand. An annealed control strategy enables the agent to internalize effective information acquisition behaviors during training. Extensive experiments across seven benchmarks demonstrate that our method consistently outperforms strong baselines. In particular, our approach achieves average performance improvements of 9.4% and 8.6% on Qwen2.5-7B and Qwen2.5-3B, respectively, over strong outcome-based RL baselines, and consistently outperforms both retrieval-free and retrieval-based reasoning methods without explicit information control. These results highlight the importance of adaptive information control for scaling search-augmented reasoning agents to complex, real-world information environments.

</details>


### [385] [Counting Hypothesis: Potential Mechanism of In-Context Learning](https://arxiv.org/abs/2602.01687)
*Jung H. Lee,Sujith Vijayan*

Main category: cs.CL

TL;DR: 论文提出"计数假说"来解释大语言模型的上下文学习机制，认为LLMs的编码策略可能是ICL的基础


<details>
  <summary>Details</summary>
Motivation: 上下文学习（ICL）使大语言模型能够从输入提示的示例中学习特定任务，无需修改模型内部结构，但ICL的底层机制仍不清楚，这使得错误修正和诊断变得困难，因此需要更好地理解ICL的局限性以及LLMs如何支持ICL

Method: 受ICL特性和LLMs功能模块的启发，提出了"计数假说"，认为LLMs的编码策略可能是ICL的基础，并提供了支持证据

Result: 提出了解释ICL机制的"计数假说"，为理解LLMs如何通过编码策略支持上下文学习提供了理论框架

Conclusion: 通过提出"计数假说"，为理解大语言模型上下文学习的底层机制提供了新的视角，有助于更好地诊断和修正ICL中的错误

Abstract: In-Context Learning (ICL) indicates that large language models (LLMs) pretrained on a massive amount of data can learn specific tasks from input prompts' examples. ICL is notable for two reasons. First, it does not need modification of LLMs' internal structure. Second, it enables LLMs to perform a wide range of tasks/functions with a few examples demonstrating a desirable task. ICL opens up new ways to utilize LLMs in more domains, but its underlying mechanisms still remain poorly understood, making error correction and diagnosis extremely challenging. Thus, it is imperative that we better understand the limitations of ICL and how exactly LLMs support ICL. Inspired by ICL properties and LLMs' functional modules, we propose 1the counting hypothesis' of ICL, which suggests that LLMs' encoding strategy may underlie ICL, and provide supporting evidence.

</details>


### [386] [Restoring Exploration after Post-Training: Latent Exploration Decoding for Large Reasoning Models](https://arxiv.org/abs/2602.01698)
*Wenhui Tan,Fiorenzo Parascandolo,Enver Sangineto,Jianzhong Ju,Zhenbo Luo,Qian Cao,Rita Cucchiara,Ruihua Song,Jian Luan*

Main category: cs.CL

TL;DR: 论文提出Latent Exploration Decoding (LED)方法，通过聚合中间层后验分布来缓解强化学习后训练导致的大推理模型探索崩溃问题，无需额外训练即可提升推理性能。


<details>
  <summary>Details</summary>
Motivation: 现代推理模型通过强化学习后训练后，温度采样不再能提升pass@n准确率，出现了探索崩溃现象。研究发现后训练导致最终层后验分布熵急剧减少，而中间层熵保持相对较高，这种熵不对称性为改进解码策略提供了机会。

Method: 提出Latent Exploration Decoding (LED)方法：通过深度条件解码策略，聚合中间层后验分布（使用累积和），选择具有最大熵的深度配置作为探索候选，从而增加解码多样性。

Result: LED无需额外训练或参数，在多个推理基准测试和模型上，pass@1准确率平均提升0.61个百分点，pass@16准确率平均提升1.03个百分点。

Conclusion: LED通过利用中间层的高熵特性有效缓解了后训练导致的探索崩溃问题，提供了一种简单有效的解码策略来提升大推理模型的性能。

Abstract: Large Reasoning Models (LRMs) have recently achieved strong mathematical and code reasoning performance through Reinforcement Learning (RL) post-training. However, we show that modern reasoning post-training induces an unintended exploration collapse: temperature-based sampling no longer increases pass@$n$ accuracy. Empirically, the final-layer posterior of post-trained LRMs exhibit sharply reduced entropy, while the entropy of intermediate layers remains relatively high. Motivated by this entropy asymmetry, we propose Latent Exploration Decoding (LED), a depth-conditioned decoding strategy. LED aggregates intermediate posteriors via cumulative sum and selects depth configurations with maximal entropy as exploration candidates. Without additional training or parameters, LED consistently improves pass@1 and pass@16 accuracy by 0.61 and 1.03 percentage points across multiple reasoning benchmarks and models. Project page: https://GitHub.com/Xiaomi-Research/LED.

</details>


### [387] [Game of Thought: Robust Information Seeking with Large Language Models Using Game Theory](https://arxiv.org/abs/2602.01708)
*Langyuan Cui,Chun Kai Ling,Hwee Tou Ng*

Main category: cs.CL

TL;DR: 论文提出Game of Thought (GoT)框架，使用博弈论方法提升LLMs在信息缺失场景下的主动信息寻求能力，通过二十问游戏的对抗变体进行验证。


<details>
  <summary>Details</summary>
Motivation: LLMs在现实部署中常面临信息不足的问题，现有方法通常基于简化假设，会降低最坏情况性能，这在高风险应用中存在严重问题。

Method: 提出Strategic Language Search (SLS)问题作为两人零和扩展形式博弈，开发Game of Thought (GoT)框架，应用博弈论技术近似纳什均衡策略。

Result: 实验结果表明，相比直接提示方法和启发式搜索方法，GoT在所有测试设置中都能持续改善最坏情况性能。

Conclusion: 通过博弈论方法可以有效提升LLMs在信息寻求任务中的最坏情况性能，为高风险应用提供了更可靠的解决方案。

Abstract: Large Language Models (LLMs) are increasingly deployed in real-world scenarios where they may lack sufficient information to complete a given task. In such settings, the ability to actively seek out missing information becomes a critical capability. Existing approaches to enhancing this ability often rely on simplifying assumptions that degrade \textit{worst-case} performance. This is an issue with serious implications in high-stakes applications. In this work, we use the game of Twenty Questions to evaluate the information-seeking ability of LLMs. We introduce and formalize its adversarial counterpart, the Strategic Language Search (SLS) problem along with its variants as a two-player zero-sum extensive form game. We propose Game of Thought (GoT), a framework that applies game-theoretic techniques to approximate a Nash equilibrium (NE) strategy for the restricted variant of the game. Empirical results demonstrate that our approach consistently improves worst-case performance compared to (1) direct prompting-based methods and (2) heuristic-guided search methods across all tested settings.

</details>


### [388] [ARTIS: Agentic Risk-Aware Test-Time Scaling via Iterative Simulation](https://arxiv.org/abs/2602.01709)
*Xingshan Zeng,Lingzhi Wang,Weiwen Liu,Liangyou Li,Yasheng Wang,Lifeng Shang,Xin Jiang,Qun Liu*

Main category: cs.CL

TL;DR: ARTIS：一种通过迭代模拟实现风险感知的测试时扩展框架，在真实环境执行前进行模拟探索，提升智能体可靠性


<details>
  <summary>Details</summary>
Motivation: 当前测试时扩展技术虽然能提升大语言模型性能，但在智能体场景中不足，因为智能体动作会直接与环境交互且效果不可逆、代价高昂。需要一种方法在保证安全的前提下扩展推理时计算。

Method: 提出ARTIS框架，将探索与执行解耦：1）通过模拟交互进行测试时探索；2）引入风险感知工具模拟器，通过针对性数据生成和重新平衡训练来捕捉罕见但高影响的失败模式。

Result: 在多轮多步智能体基准测试中，迭代模拟显著提升智能体可靠性，风险感知模拟对于在不同模型和任务中持续实现这些增益至关重要。

Conclusion: ARTIS通过模拟环境中的安全探索扩展了测试时计算，风险感知模拟器能有效捕捉关键失败模式，为智能体决策提供更可靠的测试时扩展方法。

Abstract: Current test-time scaling (TTS) techniques enhance large language model (LLM) performance by allocating additional computation at inference time, yet they remain insufficient for agentic settings, where actions directly interact with external environments and their effects can be irreversible and costly. We propose \emph{\name}, \emph{\underline{A}gentic \underline{R}isk-Aware \underline{T}est-Time Scaling via \underline{I}terative \underline{S}imulation}, a framework that decouples exploration from commitment by enabling test-time exploration through simulated interactions prior to real-world execution. This design allows extending inference-time computation to improve action-level reliability and robustness without incurring environmental risk. We further show that naive LLM-based simulators struggle to capture rare but high-impact failure modes, substantially limiting their effectiveness for agentic decision making. To address this limitation, we introduce a \emph{risk-aware tool simulator} that emphasizes fidelity on failure-inducing actions via targeted data generation and rebalanced training. Experiments on multi-turn and multi-step agentic benchmarks demonstrate that iterative simulation substantially improves agent reliability, and that risk-aware simulation is essential for consistently realizing these gains across models and tasks.

</details>


### [389] [MedAraBench: Large-Scale Arabic Medical Question Answering Dataset and Benchmark](https://arxiv.org/abs/2602.01714)
*Mouath Abu-Daoud,Leen Kharouf,Omar El Hajj,Dana El Samad,Mariam Al-Omari,Jihad Mallat,Khaled Saleh,Nizar Habash,Farah E. Shamout*

Main category: cs.CL

TL;DR: MedAraBench是一个大规模阿拉伯语医学多选题数据集，涵盖19个专业和5个难度级别，用于评估LLMs在阿拉伯语医学领域的性能。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语在NLP研究中代表性不足，特别是在医学应用领域，缺乏开源数据和基准测试，这限制了评估和提升LLMs多语言能力的研究。

Method: 通过手动数字化阿拉伯语地区医学专业人员创建的学术材料构建数据集，进行广泛预处理并分为训练集和测试集。采用专家人工评估和LLM-as-a-judge两种框架评估数据质量。

Result: 数据集质量高且多样化，涵盖19个医学专业和5个难度级别。评估了8个最先进的开源和专有模型（如GPT-5、Gemini 2.0 Flash、Claude 4-Sonnet），结果显示需要进一步的领域特定增强。

Conclusion: 发布数据集和评估脚本，旨在扩大医学数据基准的多样性，扩展LLMs评估套件的范围，并增强模型在临床环境中的多语言能力。

Abstract: Arabic remains one of the most underrepresented languages in natural language processing research, particularly in medical applications, due to the limited availability of open-source data and benchmarks. The lack of resources hinders efforts to evaluate and advance the multilingual capabilities of Large Language Models (LLMs). In this paper, we introduce MedAraBench, a large-scale dataset consisting of Arabic multiple-choice question-answer pairs across various medical specialties. We constructed the dataset by manually digitizing a large repository of academic materials created by medical professionals in the Arabic-speaking region. We then conducted extensive preprocessing and split the dataset into training and test sets to support future research efforts in the area. To assess the quality of the data, we adopted two frameworks, namely expert human evaluation and LLM-as-a-judge. Our dataset is diverse and of high quality, spanning 19 specialties and five difficulty levels. For benchmarking purposes, we assessed the performance of eight state-of-the-art open-source and proprietary models, such as GPT-5, Gemini 2.0 Flash, and Claude 4-Sonnet. Our findings highlight the need for further domain-specific enhancements. We release the dataset and evaluation scripts to broaden the diversity of medical data benchmarks, expand the scope of evaluation suites for LLMs, and enhance the multilingual capabilities of models for deployment in clinical settings.

</details>


### [390] [Mechanistic Indicators of Steering Effectiveness in Large Language Models](https://arxiv.org/abs/2602.01716)
*Mehdi Jafari,Hao Xue,Flora Salim*

Main category: cs.CL

TL;DR: 本文提出使用内部模型信号（NBF熵和KL散度）来诊断LLM激活引导的可靠性，并建立了更强的评估基线。


<details>
  <summary>Details</summary>
Motivation: 尽管激活引导技术被广泛使用，但其成功或失败的内在机制因素仍不清楚，先前研究主要依赖黑盒输出或LLM评判。需要探索是否可以通过内部模型信号来诊断引导的可靠性。

Method: 采用两种信息论度量：基于熵的归一化分支因子（NBF）和词汇空间中引导激活与目标概念之间的KL散度。假设有效引导对应结构化熵保持和解码步骤间一致的KL对齐。使用LLM生成的标注作为真实标签，并引入更强的评估基线用于对比激活加法（CAA）和稀疏自编码器引导。

Result: 这些机制信号对识别成功引导和估计失败概率具有有意义的预测能力。通过可靠性研究显示两个架构不同的LLM之间具有高评判一致性。

Conclusion: 内部模型信号（NBF和KL散度）能够有效诊断LLM激活引导的可靠性，为理解引导机制提供了新的视角，并建立了更强的评估基线。

Abstract: Activation-based steering enables Large Language Models (LLMs) to exhibit targeted behaviors by intervening on intermediate activations without retraining. Despite its widespread use, the mechanistic factors that govern when steering succeeds or fails remain poorly understood, as prior work has relied primarily on black-box outputs or LLM-based judges. In this study, we investigate whether the reliability of steering can be diagnosed using internal model signals. We focus on two information-theoretic measures: the entropy-derived Normalized Branching Factor (NBF), and the Kullback-Leibler (KL) divergence between steered activations and targeted concepts in the vocabulary space. We hypothesize that effective steering corresponds to structured entropy preservation and coherent KL alignment across decoding steps. Building on a reliability study demonstrating high inter-judge agreement between two architecturally distinct LLMs, we use LLM-generated annotations as ground truth and show that these mechanistic signals provide meaningful predictive power for identifying successful steering and estimating failure probability. We further introduce a stronger evaluation baseline for Contrastive Activation Addition (CAA) and Sparse Autoencoder-based steering, the two most widely adopted activation-steering methods.

</details>


### [391] [BBPE16: UTF-16-based byte-level byte-pair encoding for improved multilingual speech recognition](https://arxiv.org/abs/2602.01717)
*Hyunsik Kim,Haeri Kim,Munhak Lee,Kyungmin Lee*

Main category: cs.CL

TL;DR: 提出BBPE16：基於UTF-16的位元組級BPE分詞器，用統一2位元組編碼表示多數現代文字，減少非拉丁文字（如中日韓）的token數量，提升多語言ASR效率。


<details>
  <summary>Details</summary>
Motivation: 現有UTF-8位元組級BPE（BBPE）雖具語言無關性和完整Unicode覆蓋，但對中日韓等非拉丁文字使用變長編碼，導致token序列膨脹，增加計算負載和記憶體使用。

Method: 提出BBPE16分詞器，基於UTF-16編碼，使多數現代文字使用統一的2位元組代碼單元，保留BBPE語言無關特性，同時大幅提升跨語言token共享。

Result: 在單語、雙語、三語ASR及多語言持續學習設定中，BBPE16達到可比或更好的準確率；對中文減少最多10.4%的token數量，降低最多10.3%的解碼迭代，加速微調和推理並減少記憶體使用。

Conclusion: BBPE16作為實用的多語言ASR分詞選擇，在保持語言無關性的同時，通過統一2位元組編碼有效減少非拉丁文字的token膨脹問題，提升系統效率。

Abstract: Multilingual automatic speech recognition (ASR) requires tokenization that efficiently covers many writing systems. Byte-level BPE (BBPE) using UTF-8 is widely adopted for its language-agnostic design and full Unicode coverage, but its variable-length encoding inflates token sequences for non-Latin scripts, such as Chinese, Japanese, and Korean (CJK). Longer sequences increase computational load and memory use. We propose BBPE16, a UTF-16-based BBPE tokenizer that represents most modern scripts with a uniform 2-byte code unit. BBPE16 preserves BBPE's language-agnostic properties while substantially improving cross-lingual token sharing. Across monolingual, bilingual, and trilingual ASR, and in a multilingual continual-learning setup, BBPE16 attains comparable or better accuracy; for Chinese, it reduces token counts by up to 10.4% and lowers decoding iterations by up to 10.3%. These reductions speed up fine-tuning and inference and decrease memory usage, making BBPE16 a practical tokenization choice for multilingual ASR.

</details>


### [392] [COMI: Coarse-to-fine Context Compression via Marginal Information Gain](https://arxiv.org/abs/2602.01719)
*Jiwei Tang,Shilei Liu,Zhicheng Zhang,Yujin Yuan,Libin Zheng,Wenbo Su,Bo Zheng*

Main category: cs.CL

TL;DR: COMI是一个粗到细的自适应上下文压缩框架，通过边际信息增益指标优化语义相关性和多样性，在长上下文场景中显著提升压缩效率。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在长上下文场景中面临计算效率低下和信息冗余的问题，现有上下文压缩方法需要改进以同时保持语义相关性和多样性。

Method: 提出基于边际信息增益的粗到细压缩框架：1)粗粒度组重分配，根据组间MIG动态分配压缩率；2)细粒度令牌合并，通过组内MIG加权融合令牌。

Result: 在问答和摘要任务上，COMI大幅超越现有基线，如在NaturalQuestions上32倍压缩约束下获得约25点精确匹配提升。

Conclusion: COMI通过联合优化语义相关性和多样性，有效解决了长上下文压缩中的信息保留问题，显著提升了压缩效率。

Abstract: Large Language Models (LLMs) have demonstrated exceptional capabilities across diverse tasks. However, their deployment in long context scenarios remains hindered by computational inefficiency and information redundancy. Context compression methods address these challenges by significantly reducing input length and eliminating redundancy. We propose COMI, a coarse-to-fine adaptive context compression framework that jointly optimizes for semantic relevance and diversity under high compression rates. We introduce Marginal Information Gain (MIG), a metric defined as the relevance of a unit to the input query minus its semantic redundancy with other units, guiding the compression process to prioritize information that is both relevant and low redundant. The framework operates in two stages: (1) Coarse-Grained Group Reallocation, where the context is partitioned into groups and dynamically assigned compression rates based on inter-group MIG, ensuring compression budgets align with information value distribution; and (2) Fine-Grained Token Merging, where tokens within each group are fused via an intra-group MIG-based weighting mechanism, thereby preserving key semantics while avoiding the accumulation of redundancy. Extensive experiments across question-answering (e.g., NaturalQuestions, 2WikiMQA, HotpotQA and NarrativeQA), summarization (e.g., MultiNews) with various backbones (e.g., LLaMA-2-7B, Qwen2-7B) show that COMI outperforms existing baselines by a large margin, e.g., approximately 25-point Exact Match (EM) improvement under 32x compression constraint with Qwen2-7B on NaturalQuestions.

</details>


### [393] [SafePred: A Predictive Guardrail for Computer-Using Agents via World Models](https://arxiv.org/abs/2602.01725)
*Yurun Chen,Zeyi Liao,Ping Yin,Taotao Xie,Keting Yin,Shengyu Zhang*

Main category: cs.CL

TL;DR: SafePred是一个预测性护栏框架，通过将预测的未来风险与当前决策对齐，防止计算机使用代理的长期风险行为


<details>
  <summary>Details</summary>
Motivation: 现有CUAs护栏采用被动反应式方法，只能约束当前观察空间内的行为，无法预防长期风险。看似合理的行动可能导致延迟出现的高风险后果，而反应式护栏无法在当前观察空间内识别这些风险。

Method: 提出预测性护栏方法，核心思想是将预测的未来风险与当前决策对齐。SafePred框架建立风险到决策循环，支持：(1)短期和长期风险预测：使用安全策略作为风险预测基础，利用世界模型的预测能力生成语义风险表示；(2)决策优化：通过步骤级干预和任务级重新规划，将预测风险转化为可操作的安全决策指导。

Result: 大量实验表明，SafePred显著减少了高风险行为，相比反应式基线方法，实现了超过97.6%的安全性能，并将任务效用提高了高达21.4%。

Conclusion: SafePred通过预测性护栏方法有效解决了CUAs的长期风险问题，通过风险预测和决策优化的结合，在保证安全性的同时提升了任务效用。

Abstract: With the widespread deployment of Computer-using Agents (CUAs) in complex real-world environments, prevalent long-term risks often lead to severe and irreversible consequences. Most existing guardrails for CUAs adopt a reactive approach, constraining agent behavior only within the current observation space. While these guardrails can prevent immediate short-term risks (e.g., clicking on a phishing link), they cannot proactively avoid long-term risks: seemingly reasonable actions can lead to high-risk consequences that emerge with a delay (e.g., cleaning logs leads to future audits being untraceable), which reactive guardrails cannot identify within the current observation space. To address these limitations, we propose a predictive guardrail approach, with the core idea of aligning predicted future risks with current decisions. Based on this approach, we present SafePred, a predictive guardrail framework for CUAs that establishes a risk-to-decision loop to ensure safe agent behavior. SafePred supports two key abilities: (1) Short- and long-term risk prediction: by using safety policies as the basis for risk prediction, SafePred leverages the prediction capability of the world model to generate semantic representations of both short-term and long-term risks, thereby identifying and pruning actions that lead to high-risk states; (2) Decision optimization: translating predicted risks into actionable safe decision guidances through step-level interventions and task-level re-planning. Extensive experiments show that SafePred significantly reduces high-risk behaviors, achieving over 97.6% safety performance and improving task utility by up to 21.4% compared with reactive baselines.

</details>


### [394] [Enhancing Automated Essay Scoring with Three Techniques: Two-Stage Fine-Tuning, Score Alignment, and Self-Training](https://arxiv.org/abs/2602.01747)
*Hongseok Choi,Serynn Kim,Wencke Liermann,Jin Seong,Jin-Xia Huang*

Main category: cs.CL

TL;DR: 本文提出三种技术提升自动作文评分性能：两阶段微调、分数对齐和不确定性感知自训练，在有限数据和全数据设置下均取得显著改进


<details>
  <summary>Details</summary>
Motivation: 现实世界中自动作文评分系统面临标注数据极度稀缺的问题，这严重限制了鲁棒AES系统的开发和实际应用

Method: 1) 两阶段微调策略利用低秩适应更好适应目标提示作文；2) 分数对齐技术改善预测分数与真实分数分布的一致性；3) 不确定性感知自训练利用未标注数据扩展训练集同时减轻标签噪声传播

Result: 在32数据设置下，三种技术均提升性能，集成后达到全数据性能的91.2%（仅用约1000个标注样本）。分数对齐技术在有限数据和全数据设置下均持续改进性能，在DualBERT中集成后在全数据设置下达到最先进结果

Conclusion: 提出的三种技术有效解决了自动作文评分中的数据稀缺问题，在有限数据和全数据设置下均显著提升性能，为实际应用提供了实用解决方案

Abstract: Automated Essay Scoring (AES) plays a crucial role in education by providing scalable and efficient assessment tools. However, in real-world settings, the extreme scarcity of labeled data severely limits the development and practical adoption of robust AES systems. This study proposes a novel approach to enhance AES performance in both limited-data and full-data settings by introducing three key techniques. First, we introduce a Two-Stage fine-tuning strategy that leverages low-rank adaptations to better adapt an AES model to target prompt essays. Second, we introduce a Score Alignment technique to improve consistency between predicted and true score distributions. Third, we employ uncertainty-aware self-training using unlabeled data, effectively expanding the training set with pseudo-labeled samples while mitigating label noise propagation. We implement above three key techniques on DualBERT. We conduct extensive experiments on the ASAP++ dataset. As a result, in the 32-data setting, all three key techniques improve performance, and their integration achieves 91.2% of the full-data performance trained on approximately 1,000 labeled samples. In addition, the proposed Score Alignment technique consistently improves performance in both limited-data and full-data settings: e.g., it achieves state-of-the-art results in the full-data setting when integrated into DualBERT.

</details>


### [395] [WorldCup Sampling for Multi-bit LLM Watermarking](https://arxiv.org/abs/2602.01752)
*Yidan Wang,Yubing Ren,Yanan Cao,Li Guo*

Main category: cs.CL

TL;DR: WorldCup是一个用于大语言模型的多比特水印框架，通过分层竞争机制将消息比特直接嵌入到token选择中，实现了高容量、可检测性、鲁棒性和文本质量的平衡。


<details>
  <summary>Details</summary>
Motivation: 现有多比特水印方法大多通过种子驱动引导扩展零比特方案，导致间接信息流、有限有效容量和次优解码。需要一种更直接、高效的多比特水印方法。

Method: 将采样视为自然通信通道，通过分层竞争机制在token选择中直接嵌入消息比特，使用互补信号指导。采用熵感知调制保持生成质量，并通过置信感知解码实现鲁棒消息恢复。

Result: WorldCup在容量、可检测性、鲁棒性、文本质量和解码效率方面实现了良好平衡，一致优于现有基线方法。

Conclusion: WorldCup为未来LLM水印研究奠定了坚实基础，展示了通过直接嵌入比特到token选择中的分层竞争机制的有效性。

Abstract: As large language models (LLMs) generate increasingly human-like text, watermarking offers a promising solution for reliable attribution beyond mere detection. While multi-bit watermarking enables richer provenance encoding, existing methods largely extend zero-bit schemes through seed-driven steering, leading to indirect information flow, limited effective capacity, and suboptimal decoding. In this paper, we propose WorldCup, a multi-bit watermarking framework for LLMs that treats sampling as a natural communication channel and embeds message bits directly into token selection via a hierarchical competition mechanism guided by complementary signals. Moreover, WorldCup further adopts entropy-aware modulation to preserve generation quality and supports robust message recovery through confidence-aware decoding. Comprehensive experiments show that WorldCup achieves a strong balance across capacity, detectability, robustness, text quality, and decoding efficiency, consistently outperforming prior baselines and laying a solid foundation for future LLM watermarking studies.

</details>


### [396] [Zero2Text: Zero-Training Cross-Domain Inversion Attacks on Textual Embeddings](https://arxiv.org/abs/2602.01757)
*Doohyun Kim,Donghwa Kang,Kyungjae Lee,Hyeongboo Baek,Brent Byunghoon Kang*

Main category: cs.CL

TL;DR: Zero2Text是一个无需训练的框架，通过递归在线对齐从向量嵌入中恢复文本，解决了现有方法在严格黑盒和跨域设置下的局限性。


<details>
  <summary>Details</summary>
Motivation: 检索增强生成（RAG）中向量数据库存在严重的隐私风险，现有方法面临基本权衡：基于优化的方法需要计算量巨大的查询，而基于对齐的方法依赖于可访问域内训练数据的不现实假设，这些限制使它们在严格黑盒和跨域设置中无效。

Method: Zero2Text是一个基于递归在线对齐的训练免费框架，将LLM先验与动态岭回归机制相结合，在运行时迭代地将生成与目标嵌入对齐，无需静态数据集。

Result: 在MS MARCO上针对OpenAI受害者模型，Zero2Text实现了比基线高1.8倍的ROUGE-L和6.4倍的BLEU-2分数，从未知领域恢复句子而无需任何泄露的数据对。标准防御（如差分隐私）无法有效缓解这种自适应威胁。

Conclusion: Zero2Text成功解决了嵌入反转攻击中的关键挑战，在严格黑盒和跨域设置中表现出色，揭示了现有隐私防御的不足，为向量数据库隐私保护提出了新的研究方向。

Abstract: The proliferation of retrieval-augmented generation (RAG) has established vector databases as critical infrastructure, yet they introduce severe privacy risks via embedding inversion attacks. Existing paradigms face a fundamental trade-off: optimization-based methods require computationally prohibitive queries, while alignment-based approaches hinge on the unrealistic assumption of accessible in-domain training data. These constraints render them ineffective in strict black-box and cross-domain settings. To dismantle these barriers, we introduce Zero2Text, a novel training-free framework based on recursive online alignment. Unlike methods relying on static datasets, Zero2Text synergizes LLM priors with a dynamic ridge regression mechanism to iteratively align generation to the target embedding on-the-fly. We further demonstrate that standard defenses, such as differential privacy, fail to effectively mitigate this adaptive threat. Extensive experiments across diverse benchmarks validate Zero2Text; notably, on MS MARCO against the OpenAI victim model, it achieves 1.8x higher ROUGE-L and 6.4x higher BLEU-2 scores compared to baselines, recovering sentences from unknown domains without a single leaked data pair.

</details>


### [397] [<SOG_k>: One LLM Token for Explicit Graph Structural Understanding](https://arxiv.org/abs/2602.01771)
*Jingyao Wu,Bin Lu,Zijun Di,Xiaoying Gan,Meng Jin,Luoyi Fu,Xinbing Wang,Chenghu Zhou*

Main category: cs.CL

TL;DR: 提出SOG方法，通过特殊结构令牌<SOG_k>在统一令牌空间中表示图结构，解决LLMs处理图数据的结构幻觉问题，实现高效图理解与推理。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理非结构化数据方面表现出色，但在处理图数据时面临结构幻觉挑战。现有方法要么将图转化为自然语言导致令牌消耗过大和注意力分散，要么转化为可训练的连续嵌入但与原文本令牌严重不对齐。

Method: 提出拓扑感知的结构令牌化器，将每个图拓扑映射为高度选择性的单个令牌<SOG_k>，在统一令牌空间中表示图结构。构建混合结构问答语料库来对齐新的结构令牌与现有文本令牌。

Result: 在五个图级基准测试中，相比基线方法性能提升9.9%至41.4%，同时展现出可解释性和一致性。方法还能灵活扩展到节点级任务，实现全局和局部结构理解。

Conclusion: SOG方法通过特殊结构令牌<SOG_k>有效解决了LLMs处理图数据的结构对齐问题，实现了高效、准确、可解释的图理解与推理，为LLMs处理结构化数据提供了新思路。

Abstract: Large language models show great potential in unstructured data understanding, but still face significant challenges with graphs due to their structural hallucination. Existing approaches mainly either verbalize graphs into natural language, which leads to excessive token consumption and scattered attention, or transform graphs into trainable continuous embeddings (i.e., soft prompt), but exhibit severe misalignment with original text tokens. To solve this problem, we propose to incorporate one special token <SOG_k> to fully represent the Structure Of Graph within a unified token space, facilitating explicit topology input and structural information sharing. Specifically, we propose a topology-aware structural tokenizer that maps each graph topology into a highly selective single token. Afterwards, we construct a set of hybrid structure Question-Answering corpora to align new structural tokens with existing text tokens. With this approach, <SOG_k> empowers LLMs to understand, generate, and reason in a concise and accurate manner. Extensive experiments on five graph-level benchmarks demonstrate the superiority of our method, achieving a performance improvement of 9.9% to 41.4% compared to the baselines while exhibiting interpretability and consistency. Furthermore, our method provides a flexible extension to node-level tasks, enabling both global and local structural understanding. The codebase is publicly available at https://github.com/Jingyao-Wu/SOG.

</details>


### [398] [Data Distribution Matters: A Data-Centric Perspective on Context Compression for Large Language Model](https://arxiv.org/abs/2602.01778)
*Kangtao Lv,Jiwei Tang,Langming Liu,Haibin Chen,Weidong Zhang,Shilei Liu,Yongwei Wang,Yujin Yuan,Wenbo Su,Bo Zheng*

Main category: cs.CL

TL;DR: 该论文首次从数据中心的视角系统研究数据分布对LLM上下文压缩质量的影响，发现输入熵与压缩质量负相关，编码器-解码器内在数据差异显著降低压缩增益。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在长上下文场景部署面临计算效率低和信息冗余问题，现有研究仅关注模型侧改进，而数据分布本身对上下文压缩的影响尚未被探索。

Method: 采用数据中心视角，从输入数据和内在数据（模型预训练知识）两个维度，使用基于自动编码器的框架评估压缩表示的语义完整性。

Result: 1) 编码器测量的输入熵与压缩质量负相关，而解码器测量的熵在冻结解码器设置下无显著关系；2) 编码器和解码器内在数据差异显著降低压缩增益且难以缓解。

Conclusion: 基于发现提出了优化压缩增益的实用指南，强调需要同时考虑输入数据和模型内在知识分布来提升上下文压缩效果。

Abstract: The deployment of Large Language Models (LLMs) in long-context scenarios is hindered by computational inefficiency and significant information redundancy. Although recent advancements have widely adopted context compression to address these challenges, existing research only focus on model-side improvements, the impact of the data distribution itself on context compression remains largely unexplored. To bridge this gap, we are the first to adopt a data-centric perspective to systematically investigate how data distribution impacts compression quality, including two dimensions: input data and intrinsic data (i.e., the model's internal pretrained knowledge). We evaluate the semantic integrity of compressed representations using an autoencoder-based framework to systematically investigate it. Our experimental results reveal that: (1) encoder-measured input entropy negatively correlates with compression quality, while decoder-measured entropy shows no significant relationship under a frozen-decoder setting; and (2) the gap between intrinsic data of the encoder and decoder significantly diminishes compression gains, which is hard to mitigate. Based on these findings, we further present practical guidelines to optimize compression gains.

</details>


### [399] [CodeOCR: On the Effectiveness of Vision Language Models in Code Understanding](https://arxiv.org/abs/2602.01785)
*Yuling Shi,Chaoxiang Xie,Zhensu Sun,Yeheng Chen,Chenxu Zhang,Longfei Yun,Chengcheng Wan,Hongyu Zhang,David Lo,Xiaodong Gu*

Main category: cs.CL

TL;DR: MLLMs通过将代码转换为图像实现高达8倍压缩，在保持理解能力的同时显著降低计算成本


<details>
  <summary>Details</summary>
Motivation: 当前基于文本的LLMs处理大规模代码时面临计算效率瓶颈，而MLLMs的图像模态为代码压缩提供了新机会

Method: 将源代码渲染为图像，利用MLLMs的视觉能力进行代码理解，通过调整图像分辨率实现不同压缩比

Result: MLLMs能有效理解压缩代码（最高8倍压缩），利用语法高亮提升代码补全性能（4倍压缩），克隆检测等任务对视觉压缩具有强鲁棒性

Conclusion: 图像模态的代码表示是实现高效推理的有前景方向，MLLMs在代码理解方面展现出巨大潜力

Abstract: Large Language Models (LLMs) have achieved remarkable success in source code understanding, yet as software systems grow in scale, computational efficiency has become a critical bottleneck. Currently, these models rely on a text-based paradigm that treats source code as a linear sequence of tokens, which leads to a linear increase in context length and associated computational costs. The rapid advancement of Multimodal LLMs (MLLMs) introduces an opportunity to optimize efficiency by representing source code as rendered images. Unlike text, which is difficult to compress without losing semantic meaning, the image modality is inherently suitable for compression. By adjusting resolution, images can be scaled to a fraction of their original token cost while remaining recognizable to vision-capable models. To explore the feasibility of this approach, we conduct the first systematic study on the effectiveness of MLLMs for code understanding. Our experiments reveal that: (1) MLLMs can effectively understand code with substantial token reduction, achieving up to 8x compression; (2) MLLMs can effectively leverage visual cues such as syntax highlighting, improving code completion performance under 4x compression; and (3) Code-understanding tasks like clone detection exhibit exceptional resilience to visual compression, with some compression ratios even slightly outperforming raw text inputs. Our findings highlight both the potential and current limitations of MLLMs in code understanding, which points out a shift toward image-modality code representation as a pathway to more efficient inference.

</details>


### [400] [Sentence Curve Language Models](https://arxiv.org/abs/2602.01807)
*DongNyeong Heo,Heelyoul Choi*

Main category: cs.CL

TL;DR: 提出句子曲线语言模型（SCLM），通过预测连续的句子曲线而非静态词嵌入，解决传统语言模型中目标词嵌入对上下文不敏感的问题，提升全局结构建模能力。


<details>
  <summary>Details</summary>
Motivation: 传统语言模型（包括扩散语言模型）使用静态词嵌入表示目标句子，这种表示对邻近词不敏感，导致模型只关注局部准确的词预测而忽视句子的全局结构。

Method: 提出句子曲线表示法，定义为样条曲线，其控制点影响句子中的多个词。基于此表示，构建句子曲线语言模型（SCLM），扩展扩散语言模型以预测句子曲线而非静态词嵌入。

Result: SCLM在IWSLT14和WMT14数据集上达到扩散语言模型的SOTA性能，训练稳定且无需繁琐的知识蒸馏，在LM1B数据集上相比离散扩散语言模型显示出有前景的潜力。

Conclusion: 句子曲线表示通过促进全局结构建模，有效解决了传统语言模型中目标词嵌入的局限性，为语言建模提供了新的连续表示方法。

Abstract: Language models (LMs) are a central component of modern AI systems, and diffusion-based language models (DLMs) have recently emerged as a competitive alternative. Both paradigms rely on word embeddings not only to represent the input sentence, but also to represent the target sentence that backbone models are trained to predict. We argue that such static embedding of the target word is insensitive to neighboring words, encouraging locally accurate word prediction while neglecting global structure across the target sentence. To address this limitation, we propose a continuous sentence representation, termed sentence curve, defined as a spline curve whose control points affect multiple words in the sentence. Based on this representation, we introduce sentence curve language model (SCLM), which extends DLMs to predict sentence curves instead of the static word embeddings. We theoretically show that sentence curve prediction induces a regularization effect that promotes global structure modeling, and characterize how different sentence curve types affect this behavior. Empirically, SCLM achieves SOTA performance among DLMs on IWSLT14 and WMT14, shows stable training without burdensome knowledge distillation, and demonstrates promising potential compared to discrete DLMs on LM1B.

</details>


### [401] [AXE: Low-Cost Cross-Domain Web Structured Information Extraction](https://arxiv.org/abs/2602.01838)
*Abdelrahman Mansour,Khaled W. Alshaer,Moataz Elsaban*

Main category: cs.CL

TL;DR: AXE是一个基于HTML DOM树剪枝的网页结构化数据提取系统，使用0.6B小模型实现SOTA性能，通过GXR确保提取结果可追溯


<details>
  <summary>Details</summary>
Motivation: 解决网页结构化数据提取中手动启发式方法的脆弱性和大语言模型成本过高的问题，寻求一种既稳定又经济高效的解决方案

Method: 将HTML DOM视为需要剪枝的树而非纯文本，使用专门的剪枝机制去除无关节点，保留高密度上下文，配合GXR确保提取结果可物理追溯

Result: 在SWDE数据集上达到88.1%的F1分数，零样本性能超越多个更大规模的全训练模型，实现最先进性能

Conclusion: AXE提供了一种实用且经济高效的大规模网页信息提取路径，通过释放专用适配器促进实际应用

Abstract: Extracting structured data from the web is often a trade-off between the brittle nature of manual heuristics and the prohibitive cost of Large Language Models. We introduce AXE (Adaptive X-Path Extractor), a pipeline that rethinks this process by treating the HTML DOM as a tree that needs pruning rather than just a wall of text to be read. AXE uses a specialized "pruning" mechanism to strip away boilerplate and irrelevant nodes, leaving behind a distilled, high-density context that allows a tiny 0.6B LLM to generate precise, structured outputs. To keep the model honest, we implement Grounded XPath Resolution (GXR), ensuring every extraction is physically traceable to a source node. Despite its low footprint, AXE achieves state-of-the-art zero-shot performance, outperforming several much larger, fully-trained alternatives with an F1 score of 88.1% on the SWDE dataset. By releasing our specialized adaptors, we aim to provide a practical, cost-effective path for large-scale web information extraction.

</details>


### [402] [Read As Human: Compressing Context via Parallelizable Close Reading and Skimming](https://arxiv.org/abs/2602.01840)
*Jiwei Tang,Shilei Liu,Zhicheng Zhang,Qingsong Lv,Runsong Zhao,Tingwei Lu,Langming Liu,Haibin Chen,Yujin Yuan,Hai-Tao Zheng,Wenbo Su,Bo Zheng*

Main category: cs.CL

TL;DR: RAM框架通过模拟人类阅读行为（精读重要内容+略读次要内容）来压缩长文本上下文，在保持性能的同时实现12倍加速


<details>
  <summary>Details</summary>
Motivation: 大语言模型在长上下文场景中面临计算效率低下和信息冗余两大挑战，需要一种既能保持性能又能提高效率的上下文压缩方法

Method: 采用自适应混合阅读策略：将上下文分段并行编码，高相关段完整保留（精读），低相关段通过查询引导压缩为摘要向量（略读），并使用对比学习优化精读与略读的决策边界

Result: 在多个问答和摘要基准测试中优于现有基线，在平均长度16K、最大长度32K的长输入上实现最高12倍的端到端加速

Conclusion: RAM框架通过模拟人类阅读行为有效解决了长上下文处理的计算效率问题，在保持性能的同时显著提升处理速度，具有自然语言格式的可解释性

Abstract: Large Language Models (LLMs) demonstrate exceptional capability across diverse tasks. However, their deployment in long-context scenarios is hindered by two challenges: computational inefficiency and redundant information. We propose RAM (Read As HuMan), a context compression framework that adopts an adaptive hybrid reading strategy, to address these challenges. Inspired by human reading behavior (i.e., close reading important content while skimming less relevant content), RAM partitions the context into segments and encodes them with the input query in parallel. High-relevance segments are fully retained (close reading), while low-relevance ones are query-guided compressed into compact summary vectors (skimming). Both explicit textual segments and implicit summary vectors are concatenated and fed into decoder to achieve both superior performance and natural language format interpretability. To refine the decision boundary between close reading and skimming, we further introduce a contrastive learning objective based on positive and negative query-segment pairs. Experiments demonstrate that RAM outperforms existing baselines on multiple question answering and summarization benchmarks across two backbones, while delivering up to a 12x end-to-end speedup on long inputs (average length 16K; maximum length 32K).

</details>


### [403] [PretrainRL: Alleviating Factuality Hallucination of Large Language Models at the Beginning](https://arxiv.org/abs/2602.01875)
*Langming Liu,Kangtao Lv,Haibin Chen,Weidong Zhang,Yejing Wang,Shilei Liu,Xin Tong,Yujin Yuan,Yongwei Wang,Wenbo Su,Bo Zheng*

Main category: cs.CL

TL;DR: 提出PretrainRL框架，在预训练阶段集成强化学习来巩固事实知识，通过"去偏然后学习"原则降低高概率虚假信息的权重，为低概率真实信息创造学习空间，显著缓解LLM的事实幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型存在事实幻觉问题，生成可验证的虚假信息。根本原因是预训练语料库中数据分布不平衡，导致"低概率真实"和"高概率虚假"的状态。现有方法要么回避问题，要么面临灾难性遗忘。

Method: 提出PretrainRL框架，将强化学习集成到预训练阶段。核心原则是"去偏然后学习"：通过降低高概率虚假信息的权重，重塑模型的概率分布，为低概率真实信息创造学习空间。设计了高效的负采样策略来发现高概率虚假信息，并引入新的指标来评估模型关于事实知识的概率状态。

Result: 在三个公共基准测试上的广泛实验表明，PretrainRL显著缓解了事实幻觉问题，并优于最先进的方法。

Conclusion: PretrainRL通过从根本上解决预训练数据分布不平衡问题，有效减少了LLM的事实幻觉，为构建更可靠的语言模型提供了新思路。

Abstract: Large language models (LLMs), despite their powerful capabilities, suffer from factual hallucinations where they generate verifiable falsehoods. We identify a root of this issue: the imbalanced data distribution in the pretraining corpus, which leads to a state of "low-probability truth" and "high-probability falsehood". Recent approaches, such as teaching models to say "I don't know" or post-hoc knowledge editing, either evade the problem or face catastrophic forgetting. To address this issue from its root, we propose \textbf{PretrainRL}, a novel framework that integrates reinforcement learning into the pretraining phase to consolidate factual knowledge. The core principle of PretrainRL is "\textbf{debiasing then learning}." It actively reshapes the model's probability distribution by down-weighting high-probability falsehoods, thereby making "room" for low-probability truths to be learned effectively. To enable this, we design an efficient negative sampling strategy to discover these high-probability falsehoods and introduce novel metrics to evaluate the model's probabilistic state concerning factual knowledge. Extensive experiments on three public benchmarks demonstrate that PretrainRL significantly alleviates factual hallucinations and outperforms state-of-the-art methods.

</details>


### [404] [ES-MemEval: Benchmarking Conversational Agents on Personalized Long-Term Emotional Support](https://arxiv.org/abs/2602.01885)
*Tiantian Chen,Jiaqi Lu,Ying Shen,Lin Zhang*

Main category: cs.CL

TL;DR: ES-MemEval是一个用于评估长期情感支持对话中记忆能力的基准，包含信息提取、时序推理、冲突检测等五个核心能力，实验表明显式长期记忆对减少幻觉和实现个性化至关重要。


<details>
  <summary>Details</summary>
Motivation: 现有长期对话基准主要关注静态显式事实检索，无法评估在用户信息分散、隐式且持续演化的关键场景下的对话代理。特别是在在线情感支持等复杂长期网络服务中，LLM的有效性受到长期记忆不足的限制。

Method: 提出了ES-MemEval基准，系统评估五个核心记忆能力：信息提取、时序推理、冲突检测、弃权和用户建模。同时构建了EvoEmo数据集，这是一个用于个性化长期情感支持的多会话数据集，捕捉碎片化、隐式的用户披露和演化中的用户状态。

Result: 对开源长上下文、商业和检索增强LLM的广泛实验表明：显式长期记忆对减少幻觉和实现有效个性化至关重要；RAG提高了事实一致性，但在处理时序动态和演化用户状态方面存在困难。

Conclusion: 当前范式既有潜力也有局限性，需要更鲁棒地整合记忆和检索机制来构建长期个性化对话系统。研究结果强调了在复杂长期对话场景中显式记忆管理的重要性。

Abstract: Large Language Models (LLMs) have shown strong potential as conversational agents. Yet, their effectiveness remains limited by deficiencies in robust long-term memory, particularly in complex, long-term web-based services such as online emotional support. However, existing long-term dialogue benchmarks primarily focus on static and explicit fact retrieval, failing to evaluate agents in critical scenarios where user information is dispersed, implicit, and continuously evolving. To address this gap, we introduce ES-MemEval, a comprehensive benchmark that systematically evaluates five core memory capabilities: information extraction, temporal reasoning, conflict detection, abstention, and user modeling, in long-term emotional support settings, covering question answering, summarization, and dialogue generation tasks. To support the benchmark, we also propose EvoEmo, a multi-session dataset for personalized long-term emotional support that captures fragmented, implicit user disclosures and evolving user states. Extensive experiments on open-source long-context, commercial, and retrieval-augmented (RAG) LLMs show that explicit long-term memory is essential for reducing hallucinations and enabling effective personalization. At the same time, RAG improves factual consistency but struggles with temporal dynamics and evolving user states. These findings highlight both the potential and limitations of current paradigms and motivate more robust integration of memory and retrieval for long-term personalized dialogue systems.

</details>


### [405] [GuideWeb: A Benchmark for Automatic In-App Guide Generation on Real-World Web UIs](https://arxiv.org/abs/2602.01917)
*Chengguang Gan,Yoshihiro Tsujii,Yunhao Liang,Tatsunori Mori,Shiwen Ni,Hiroki Itoh*

Main category: cs.CL

TL;DR: GuideWeb是一个用于在真实网页UI上自动生成应用内指导的新基准，将任务制定为通过选择网页中的指导目标元素并生成简洁的指导文本来提供页面级指导。


<details>
  <summary>Details</summary>
Motivation: 数字采用平台(DAP)提供基于网页的覆盖层来帮助用户导航复杂网站，但维护这些指导非常耗时，因为网站布局和功能不断演变，需要重复手动更新和重新标注。

Method: 提出了GuideWeb基准，将任务制定为选择网页中的指导目标元素并生成与用户意图一致的简洁指导文本。同时提出了一个全面的评估套件，联合测量指导目标元素选择的准确性和生成的意图及指导文本的质量。

Result: 提出的GuideWeb代理在指导目标元素预测方面达到30.79%的准确率，在意图生成方面获得44.94的BLEU分数，在指导文本生成方面获得21.34的BLEU分数。现有基线表现明显更差。

Conclusion: 自动指导生成仍然具有挑战性，在能够可靠地部署到真实世界环境之前需要进一步的技术进步。

Abstract: Digital Adoption Platform (DAP) provide web-based overlays that deliver operation guidance and contextual hints to help users navigate complex websites. Although modern DAP tools enable non-experts to author such guidance, maintaining these guides remains labor-intensive because website layouts and functionalities evolve continuously, which requires repeated manual updates and re-annotation. In this work, we introduce \textbf{GuideWeb}, a new benchmark for automatic in-app guide generation on real-world web UIs. GuideWeb formulates the task as producing page-level guidance by selecting \textbf{guide target elements} grounded in the webpage and generating concise guide text aligned with user intent. We also propose a comprehensive evaluation suite that jointly measures the accuracy of guide target element selection and the quality of generated intents and guide texts. Experiments show that our proposed \textbf{GuideWeb Agent} achieves \textbf{30.79\%} accuracy in guide target element prediction, while obtaining BLEU scores of \textbf{44.94} for intent generation and \textbf{21.34} for guide-text generation. Existing baselines perform substantially worse, which highlights that automatic guide generation remains challenging and that further advances are necessary before such systems can be reliably deployed in real-world settings.

</details>


### [406] [From Code-Centric to Concept-Centric: Teaching NLP with LLM-Assisted "Vibe Coding"](https://arxiv.org/abs/2602.01919)
*Hend Al-Khalifa*

Main category: cs.CL

TL;DR: Vibe Coding是一种利用LLM作为编程助手的教学方法，在NLP课程中实施，通过反思性评估强调概念理解而非语法熟练度，学生反馈积极但存在时间限制和输出验证等挑战。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）的快速发展，NLP教育面临新的挑战和机遇。传统编程教学可能过度关注语法细节，而LLMs的出现使得教育者需要重新思考如何平衡技术工具使用与概念理解的教学方法。

Method: 提出"Vibe Coding"教学法，在高级本科NLP课程中实施。学生使用LLMs作为编程助手完成7个实验，但评估重点放在概念理解上，通过批判性反思问题进行评估。强制要求学生记录提示词，确保学习过程透明。

Result: 19名学生的课程反馈显示高满意度（平均分4.4-4.6/5.0），学生特别赞赏减少调试认知负担，能更专注于NLP概念。但也发现时间限制、LLM输出验证和任务规范清晰度等挑战。

Conclusion: 当通过强制提示记录和基于反思的评估适当结构化时，LLM辅助学习可以将重点从语法熟练度转向概念掌握，为学生适应AI增强的专业环境做好准备。

Abstract: The rapid advancement of Large Language Models (LLMs) presents both challenges and opportunities for Natural Language Processing (NLP) education. This paper introduces ``Vibe Coding,'' a pedagogical approach that leverages LLMs as coding assistants while maintaining focus on conceptual understanding and critical thinking. We describe the implementation of this approach in a senior-level undergraduate NLP course, where students completed seven labs using LLMs for code generation while being assessed primarily on conceptual understanding through critical reflection questions. Analysis of end-of-course feedback from 19 students reveals high satisfaction (mean scores 4.4-4.6/5.0) across engagement, conceptual learning, and assessment fairness. Students particularly valued the reduced cognitive load from debugging, enabling deeper focus on NLP concepts. However, challenges emerged around time constraints, LLM output verification, and the need for clearer task specifications. Our findings suggest that when properly structured with mandatory prompt logging and reflection-based assessment, LLM-assisted learning can shift focus from syntactic fluency to conceptual mastery, preparing students for an AI-augmented professional landscape.

</details>


### [407] [Breaking the Static Graph: Context-Aware Traversal for Robust Retrieval-Augmented Generation](https://arxiv.org/abs/2602.01965)
*Kwun Hang Lau,Fangyuan Zhang,Boyu Ruan,Yingli Zhou,Qintian Guo,Ruiyuan Zhang,Xiaofang Zhou*

Main category: cs.CL

TL;DR: CatRAG提出了一种上下文感知的RAG框架，通过动态调整知识图谱的遍历策略来解决静态图谱方法中的"语义漂移"问题，显著提升了多跳推理的完整性。


<details>
  <summary>Details</summary>
Motivation: 现有基于知识图谱的RAG方法（如HippoRAG）存在"静态图谱谬误"问题，即使用固定的转移概率，忽略了查询依赖的边相关性，导致随机游走被高连接度的"枢纽"节点分散，无法完整检索多跳查询所需的证据链。

Method: 基于HippoRAG 2架构，CatRAG将静态知识图谱转换为查询自适应的导航结构，包含三个核心组件：1）符号锚定，注入弱实体约束来正则化随机游走；2）查询感知的动态边权重调整，动态调整图结构以修剪不相关路径并增强与查询意图对齐的路径；3）关键事实段落权重增强，通过成本高效的偏置结构性地将随机游走锚定到可能的证据。

Result: 在四个多跳基准测试中，CatRAG持续优于最先进的基线方法。虽然标准召回率指标显示适度提升，但CatRAG在推理完整性方面取得了显著改进，能够无间隙地恢复整个证据路径。

Conclusion: CatRAG通过上下文感知的图谱遍历策略，有效解决了静态图谱方法中的语义漂移问题，填补了检索部分上下文与实现完全基于证据的推理之间的差距，为多跳RAG提供了更鲁棒的解决方案。

Abstract: Recent advances in Retrieval-Augmented Generation (RAG) have shifted from simple vector similarity to structure-aware approaches like HippoRAG, which leverage Knowledge Graphs (KGs) and Personalized PageRank (PPR) to capture multi-hop dependencies. However, these methods suffer from a "Static Graph Fallacy": they rely on fixed transition probabilities determined during indexing. This rigidity ignores the query-dependent nature of edge relevance, causing semantic drift where random walks are diverted into high-degree "hub" nodes before reaching critical downstream evidence. Consequently, models often achieve high partial recall but fail to retrieve the complete evidence chain required for multi-hop queries. To address this, we propose CatRAG, Context-Aware Traversal for robust RAG, a framework that builds on the HippoRAG 2 architecture and transforms the static KG into a query-adaptive navigation structure. We introduce a multi-faceted framework to steer the random walk: (1) Symbolic Anchoring, which injects weak entity constraints to regularize the random walk; (2) Query-Aware Dynamic Edge Weighting, which dynamically modulates graph structure, to prune irrelevant paths while amplifying those aligned with the query's intent; and (3) Key-Fact Passage Weight Enhancement, a cost-efficient bias that structurally anchors the random walk to likely evidence. Experiments across four multi-hop benchmarks demonstrate that CatRAG consistently outperforms state of the art baselines. Our analysis reveals that while standard Recall metrics show modest gains, CatRAG achieves substantial improvements in reasoning completeness, the capacity to recover the entire evidence path without gaps. These results reveal that our approach effectively bridges the gap between retrieving partial context and enabling fully grounded reasoning. Resources are available at https://github.com/kwunhang/CatRAG.

</details>


### [408] [Mixture-of-Experts with Intermediate CTC Supervision for Accented Speech Recognition](https://arxiv.org/abs/2602.01967)
*Wonjun Lee,Hyounghun Kim,Gary Geunbae Lee*

Main category: cs.CL

TL;DR: Moe-Ctc：一种混合专家架构，通过中间CTC监督联合促进专家专业化和泛化，显著提升带口音语音的ASR性能


<details>
  <summary>Details</summary>
Motivation: 当前ASR系统主要基于少数高资源英语变体训练，对其他口音表现不佳。口音无关方法对重口音或未见口音效果有限，而口音特定方法依赖有限且通常有噪声的标签。

Method: 提出Moe-Ctc混合专家架构，采用中间CTC监督。训练时使用口音感知路由促进专家捕获口音特定模式，推理时转为无标签路由。每个专家配备自己的CTC头，通过路由增强损失稳定优化。

Result: 在Mcv-Accent基准测试中，在低资源和高资源条件下，对已见和未见口音均取得一致提升，相比强FastConformer基线实现最高29.3%的相对WER降低。

Conclusion: Moe-Ctc通过混合专家架构有效解决了带口音语音的ASR挑战，在专业化和泛化之间取得良好平衡，显著提升了系统对不同口音的鲁棒性。

Abstract: Accented speech remains a persistent challenge for automatic speech recognition (ASR), as most models are trained on data dominated by a few high-resource English varieties, leading to substantial performance degradation for other accents. Accent-agnostic approaches improve robustness yet struggle with heavily accented or unseen varieties, while accent-specific methods rely on limited and often noisy labels. We introduce Moe-Ctc, a Mixture-of-Experts architecture with intermediate CTC supervision that jointly promotes expert specialization and generalization. During training, accent-aware routing encourages experts to capture accent-specific patterns, which gradually transitions to label-free routing for inference. Each expert is equipped with its own CTC head to align routing with transcription quality, and a routing-augmented loss further stabilizes optimization. Experiments on the Mcv-Accent benchmark demonstrate consistent gains across both seen and unseen accents in low- and high-resource conditions, achieving up to 29.3% relative WER reduction over strong FastConformer baselines.

</details>


### [409] [Orthogonal Hierarchical Decomposition for Structure-Aware Table Understanding with Large Language Models](https://arxiv.org/abs/2602.01969)
*Bin Cao,Huixian Lu,Chenwen Ma,Ting Wang,Ruizhe Li,Jing Fan*

Main category: cs.CL

TL;DR: 提出正交层次分解框架，通过构建保持结构的输入表示来解决LLM处理复杂表格的挑战，在表格问答任务上优于现有方法


<details>
  <summary>Details</summary>
Motivation: 复杂表格（多级表头、合并单元格、异构布局）给LLM的理解和推理带来持续挑战。现有方法依赖表格线性化或规范化网格建模，难以显式捕捉层次结构和跨维度依赖，导致非标准表格的结构语义与文本表示不对齐。

Method: 提出正交层次分解框架，包含正交树归纳方法（基于空间-语义共约束），将不规则表格分解为列树和行树以分别捕获垂直和水平层次依赖。设计双路径关联协议对称重建每个单元格的语义谱系，并引入LLM作为语义仲裁器对齐多级语义信息。

Result: 在AITQA和HiTab两个复杂表格问答基准测试上，OHD框架在多个评估指标上一致优于现有表示范式。

Conclusion: OHD框架通过正交层次分解有效捕捉复杂表格的结构语义，为LLM提供更好的输入表示，在表格理解和推理任务上表现优异。

Abstract: Complex tables with multi-level headers, merged cells and heterogeneous layouts pose persistent challenges for LLMs in both understanding and reasoning. Existing approaches typically rely on table linearization or normalized grid modeling. However, these representations struggle to explicitly capture hierarchical structures and cross-dimensional dependencies, which can lead to misalignment between structural semantics and textual representations for non-standard tables. To address this issue, we propose an Orthogonal Hierarchical Decomposition (OHD) framework that constructs structure-preserving input representations of complex tables for LLMs. OHD introduces an Orthogonal Tree Induction (OTI) method based on spatial--semantic co-constraints, which decomposes irregular tables into a column tree and a row tree to capture vertical and horizontal hierarchical dependencies, respectively. Building on this representation, we design a dual-pathway association protocol to symmetrically reconstruct semantic lineage of each cell, and incorporate an LLM as a semantic arbitrator to align multi-level semantic information. We evaluate OHD framework on two complex table question answering benchmarks, AITQA and HiTab. Experimental results show that OHD consistently outperforms existing representation paradigms across multiple evaluation metrics.

</details>


### [410] [Beyond Local Edits: Embedding-Virtualized Knowledge for Broader Evaluation and Preservation of Model Editing](https://arxiv.org/abs/2602.01977)
*Shuainan Liu,Xuanang Chen,Ben He,Le Sun*

Main category: cs.CL

TL;DR: 本文提出EVK方法，通过嵌入空间扰动来表征模型知识，构建EVK-Bench评估基准量化知识漂移，并提出EVK-Align模块在编辑时约束嵌入级知识漂移，实现更全面的评估和更好的知识保留。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型知识编辑方法通常使用预定义基准进行评估，这些基准仅评估编辑事实及其有限的相关知识。虽然有效，但此类评估局限于有限的数据集样本，未能充分理解编辑对模型知识系统的更广泛影响。

Method: 提出Embedding-Virtualized Knowledge (EVK)方法，通过嵌入空间中的受控扰动来表征模型知识，构建嵌入级评估基准EVK-Bench量化编辑引起的潜在知识漂移，并提出可即插即用的EVK-Align模块，在编辑过程中约束嵌入级知识漂移。

Result: 实验表明，该方法能够实现更全面的评估，同时在保持编辑准确性的前提下显著改善知识保留效果。

Conclusion: EVK方法通过嵌入空间扰动探索超越显式数据标注的虚拟化知识区域，为知识编辑提供了更全面的评估框架，并通过EVK-Align模块有效减少了编辑过程中的知识漂移问题。

Abstract: Knowledge editing methods for large language models are commonly evaluated using predefined benchmarks that assess edited facts together with a limited set of related or neighboring knowledge. While effective, such evaluations remain confined to finite, dataset-bounded samples, leaving the broader impact of editing on the model's knowledge system insufficiently understood. To address this gap, we introduce Embedding-Virtualized Knowledge (EVK) that characterizes model knowledge through controlled perturbations in embedding space, enabling the exploration of a substantially broader and virtualized knowledge region beyond explicit data annotations. Based on EVK, we construct an embedding-level evaluation benchmark EVK-Bench that quantifies potential knowledge drift induced by editing, revealing effects that are not captured by conventional sample-based metrics. Furthermore, we propose a plug-and-play EVK-Align module that constrains embedding-level knowledge drift during editing and can be seamlessly integrated into existing editing methods. Experiments demonstrate that our approach enables more comprehensive evaluation while significantly improving knowledge preservation without sacrificing editing accuracy.

</details>


### [411] [S3-CoT: Self-Sampled Succinct Reasoning Enables Efficient Chain-of-Thought LLMs](https://arxiv.org/abs/2602.01982)
*Yanrui Du,Sendong Zhao,Yibo Gao,Danyang Zhao,Qika Lin,Ming Ma,Jiayun Li,Yi Jiang,Kai He,Qianyi Xu,Bing Qin,Mengling Feng*

Main category: cs.CL

TL;DR: 提出S3-CoT框架，通过自采样激活引导实现高效思维链学习，让LLM获得类似人类系统1的快速推理能力，无需教师指导即可生成风格对齐的变长推理轨迹。


<details>
  <summary>Details</summary>
Motivation: 现有思维链方法存在推理过程冗余的问题，需要探索LLM是否能获得类似人类系统1的快速推理模式，同时解决基于监督微调方法中高质量监督数据稀缺的瓶颈。

Method: 提出自采样框架，基于激活引导从目标LLM自身诱导风格对齐的变长推理轨迹；使用黄金答案过滤数据，通过(i)类人双认知系统和(ii)渐进压缩课程进行监督微调；探索仅使用预测一致数据的自进化机制。

Result: 在数学基准测试和医学领域的跨域泛化测试中，该方法为通用和R1风格LLM带来稳定改进，无需黄金答案即可实现高效思维链学习。

Conclusion: S3-CoT框架成功让LLM获得快速推理能力，解决了监督数据稀缺问题，在多个领域展现出稳定性能提升，为高效思维链学习提供了新途径。

Abstract: Large language models (LLMs) equipped with chain-of-thought (CoT) achieve strong performance and offer a window into LLM behavior. However, recent evidence suggests that improvements in CoT capabilities often come with redundant reasoning processes, motivating a key question: Can LLMs acquire a fast-thinking mode analogous to human System 1 reasoning? To explore this, our study presents a self-sampling framework based on activation steering for efficient CoT learning. Our method can induce style-aligned and variable-length reasoning traces from target LLMs themselves without any teacher guidance, thereby alleviating a central bottleneck of SFT-based methods-the scarcity of high-quality supervision data. Using filtered data by gold answers, we perform SFT for efficient CoT learning with (i) a human-like dual-cognitive system, and (ii) a progressive compression curriculum. Furthermore, we explore a self-evolution regime in which SFT is driven solely by prediction-consistent data of variable-length variants, eliminating the need for gold answers. Extensive experiments on math benchmarks, together with cross-domain generalization tests in medicine, show that our method yields stable improvements for both general and R1-style LLMs. Our data and model checkpoints can be found at https://github.com/DYR1/S3-CoT.

</details>


### [412] [From Latent Signals to Reflection Behavior: Tracing Meta-Cognitive Activation Trajectory in R1-Style LLMs](https://arxiv.org/abs/2602.01999)
*Yanrui Du,Yibo Gao,Sendong Zhao,Jiayun Li,Haochun Wang,Qika Lin,Kai He,Bing Qin,Mengling Feng*

Main category: cs.CL

TL;DR: 该研究揭示了R1风格大语言模型中自我反思行为的内在机制，发现其遵循从潜在监控到话语调节再到显性反思的三阶段结构化进程。


<details>
  <summary>Details</summary>
Motivation: 尽管R1风格的大语言模型因其自我反思能力受到关注，但其内部工作机制仍不清楚。研究旨在填补这一空白，通过追踪反思行为的激活轨迹来理解其内在机制。

Method: 使用logit lens技术读取token级语义，追踪反思行为的层间激活轨迹。通过有针对性的干预实验，揭示不同阶段之间的因果链关系。

Result: 发现了反思行为的三阶段结构化进程：1)潜在控制层编码思维预算语义；2)语义枢纽层出现话语级线索；3)行为显性层反思行为token概率上升。干预实验证实了这些阶段之间的因果链关系。

Conclusion: 研究结果表明R1风格LLMs的自我反思遵循类似人类元认知的过程：从潜在监控到话语级调节，最终到显性自我反思。这为理解大语言模型的反思机制提供了新视角。

Abstract: R1-style LLMs have attracted growing attention for their capacity for self-reflection, yet the internal mechanisms underlying such behavior remain unclear. To bridge this gap, we anchor on the onset of reflection behavior and trace its layer-wise activation trajectory. Using the logit lens to read out token-level semantics, we uncover a structured progression: (i) Latent-control layers, where an approximate linear direction encodes the semantics of thinking budget; (ii) Semantic-pivot layers, where discourse-level cues, including turning-point and summarization cues, surface and dominate the probability mass; and (iii) Behavior-overt layers, where the likelihood of reflection-behavior tokens begins to rise until they become highly likely to be sampled. Moreover, our targeted interventions uncover a causal chain across these stages: prompt-level semantics modulate the projection of activations along latent-control directions, thereby inducing competition between turning-point and summarization cues in semantic-pivot layers, which in turn regulates the sampling likelihood of reflection-behavior tokens in behavior-overt layers. Collectively, our findings suggest a human-like meta-cognitive process-progressing from latent monitoring, to discourse-level regulation, and to finally overt self-reflection. Our analysis code can be found at https://github.com/DYR1/S3-CoT.

</details>


### [413] [Beyond RAG for Agent Memory: Retrieval by Decoupling and Aggregation](https://arxiv.org/abs/2602.02007)
*Zhanghao Hu,Qinglin Zhu,Hanqi Yan,Yulan He,Lin Gui*

Main category: cs.CL

TL;DR: xMemory提出了一种新的智能体记忆检索系统，通过解耦-聚合方法构建层次化记忆结构，解决传统RAG在智能体记忆场景中的冗余和关联性丢失问题。


<details>
  <summary>Details</summary>
Motivation: 传统RAG系统针对大规模异构语料库设计，而智能体记忆是有限、连贯的对话流，具有高度相关性和重复性。固定top-k相似性检索会返回冗余上下文，后处理剪枝可能删除时间关联的前提条件，影响推理准确性。

Method: 提出xMemory系统：1）将记忆解耦为语义组件；2）组织成层次结构；3）通过稀疏性-语义目标指导记忆的分割与合并，保持可搜索且忠实的高层节点组织；4）推理时采用自上而下检索，先选择紧凑多样的主题和语义，仅在减少读者不确定性时扩展到情节和原始消息。

Result: 在LoCoMo和PerLTQA数据集上，使用三种最新LLM进行实验，在回答质量和token效率方面均取得一致提升。

Conclusion: 检索应超越相似性匹配，转向潜在组件操作。xMemory通过解耦-聚合方法构建层次化记忆结构，有效解决了智能体记忆检索中的冗余和关联性问题，提高了推理质量和效率。

Abstract: Agent memory systems often adopt the standard Retrieval-Augmented Generation (RAG) pipeline, yet its underlying assumptions differ in this setting. RAG targets large, heterogeneous corpora where retrieved passages are diverse, whereas agent memory is a bounded, coherent dialogue stream with highly correlated spans that are often duplicates. Under this shift, fixed top-$k$ similarity retrieval tends to return redundant context, and post-hoc pruning can delete temporally linked prerequisites needed for correct reasoning. We argue retrieval should move beyond similarity matching and instead operate over latent components, following decoupling to aggregation: disentangle memories into semantic components, organise them into a hierarchy, and use this structure to drive retrieval. We propose xMemory, which builds a hierarchy of intact units and maintains a searchable yet faithful high-level node organisation via a sparsity--semantics objective that guides memory split and merge. At inference, xMemory retrieves top-down, selecting a compact, diverse set of themes and semantics for multi-fact queries, and expanding to episodes and raw messages only when it reduces the reader's uncertainty. Experiments on LoCoMo and PerLTQA across the three latest LLMs show consistent gains in answer quality and token efficiency.

</details>


### [414] [NEAT: Neuron-Based Early Exit for Large Reasoning Models](https://arxiv.org/abs/2602.02010)
*Kang Liu,Yongkang Liu,Xiaocui Yang,Peidong Wang,Wen Zhang,Shi Feng,Yifei Zhang,Daling Wang*

Main category: cs.CL

TL;DR: NEAT提出了一种基于神经元激活动态监测的无训练早期推理退出框架，通过追踪退出相关神经元的激活模式来动态触发早期退出，减少冗余推理步骤，平均减少22%-28%的token使用，同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型存在"过度思考"问题，即在已经得到正确解后仍生成冗余推理步骤。现有早期退出方法依赖输出级启发式或训练探测模型，需要额外计算或外部标注数据。

Method: NEAT框架通过监测神经元级激活动态，识别退出相关神经元并追踪其在推理过程中的激活模式，动态触发早期退出或抑制反思，无需训练且不引入额外测试时计算。

Result: 在四个推理基准测试和六个不同规模和架构的模型上，NEAT平均减少22%-28%的token使用，同时保持准确性。

Conclusion: NEAT提供了一种高效的无训练早期推理退出方法，通过神经元级监测有效缓解过度思考问题，减少计算开销而不影响解决方案质量。

Abstract: Large Reasoning Models (LRMs) often suffer from \emph{overthinking}, a phenomenon in which redundant reasoning steps are generated after a correct solution has already been reached. Existing early reasoning exit methods primarily rely on output-level heuristics or trained probing models to skip redundant reasoning steps, thereby mitigating overthinking. However, these approaches typically require additional rollout computation or externally labeled datasets. In this paper, we propose \textbf{NEAT}, a \textbf{N}euron-based \textbf{E}arly re\textbf{A}soning exi\textbf{T} framework that monitors neuron-level activation dynamics to enable training-free early exits, without introducing additional test-time computation. NEAT identifies exit-associated neurons and tracks their activation patterns during reasoning to dynamically trigger early exit or suppress reflection, thereby reducing unnecessary reasoning while preserving solution quality. Experiments on four reasoning benchmarks across six models with different scales and architectures show that, for each model, NEAT achieves an average token reduction of 22\% to 28\% when averaged over the four benchmarks, while maintaining accuracy.

</details>


### [415] [WildGraphBench: Benchmarking GraphRAG with Wild-Source Corpora](https://arxiv.org/abs/2602.02053)
*Pengyu Wang,Benfeng Xu,Licheng Zhang,Shaohan Wang,Mingxuan Du,Chiwei Zhu,Zhendong Mao*

Main category: cs.CL

TL;DR: WildGraphBench是一个针对GraphRAG系统在真实场景下的评估基准，利用Wikipedia的长文档和异构参考文献构建，包含1,100个问题，涵盖三个复杂度级别。


<details>
  <summary>Details</summary>
Motivation: 现有GraphRAG基准多使用短篇精选文本作为外部知识，无法充分评估系统在真实场景中处理长上下文和大规模异构文档的能力。

Method: 利用Wikipedia的结构特点，以外部参考文献作为检索语料库，以引用链接的陈述作为真实答案，从12个顶级主题中采样文章，构建包含1,100个问题的基准，涵盖单事实QA、多事实QA和章节级摘要三个复杂度级别。

Result: 实验表明，当前GraphRAG管道在证据来自中等数量来源时有助于多事实聚合，但这种聚合范式可能过度强调高层陈述而牺牲细粒度细节，导致在摘要任务上表现较弱。

Conclusion: WildGraphBench填补了GraphRAG评估在真实场景下的空白，揭示了当前系统在聚合与细节保留之间的权衡问题，为未来研究提供了重要基准。

Abstract: Graph-based Retrieval-Augmented Generation (GraphRAG) organizes external knowledge as a hierarchical graph, enabling efficient retrieval and aggregation of scattered evidence across multiple documents. However, many existing benchmarks for GraphRAG rely on short, curated passages as external knowledge, failing to adequately evaluate systems in realistic settings involving long contexts and large-scale heterogeneous documents. To bridge this gap, we introduce WildGraphBench, a benchmark designed to assess GraphRAG performance in the wild. We leverage Wikipedia's unique structure, where cohesive narratives are grounded in long and heterogeneous external reference documents, to construct a benchmark reflecting real-word scenarios. Specifically, we sample articles across 12 top-level topics, using their external references as the retrieval corpus and citation-linked statements as ground truth, resulting in 1,100 questions spanning three levels of complexity: single-fact QA, multi-fact QA, and section-level summarization. Experiments across multiple baselines reveal that current GraphRAG pipelines help on multi-fact aggregation when evidence comes from a moderate number of sources, but this aggregation paradigm may overemphasize high-level statements at the expense of fine-grained details, leading to weaker performance on summarization tasks. Project page:https://github.com/BstWPY/WildGraphBench.

</details>


### [416] [Closing the Loop: Universal Repository Representation with RPG-Encoder](https://arxiv.org/abs/2602.02084)
*Jane Luo,Chengyu Yin,Xin Zhang,Qingtao Li,Steven Liu,Yiming Huang,Jie Wu,Hao Liu,Yangyu Huang,Yu Kang,Fangkai Yang,Ying Xin,Scarlett Li*

Main category: cs.CL

TL;DR: RPG-Encoder是一个将代码库理解与生成统一为循环过程的框架，通过Repository Planning Graph实现高保真表示，显著提升代码库理解准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有代码库代理存在推理断层问题，因为它们依赖孤立的API文档或缺乏语义深度的依赖图，无法形成统一的代码库表示。

Method: 提出RPG-Encoder框架：1) 将原始代码编码为结合语义特征和代码依赖的Repository Planning Graph；2) 增量演化拓扑结构，使维护成本与代码库规模解耦；3) 作为统一接口支持结构感知导航。

Result: 在SWE-bench Verified上达到93.7%的Acc@5，在SWE-bench Live Lite上比最佳基线提升超过10%；维护开销减少95.7%；在RepoCraft上实现98.5%的重建覆盖率。

Conclusion: RPG-Encoder通过统一的Repository Planning Graph表示，成功连接了意图与实现之间的循环，在复杂代码库中实现了卓越的细粒度定位精度和高保真重建能力。

Abstract: Current repository agents encounter a reasoning disconnect due to fragmented representations, as existing methods rely on isolated API documentation or dependency graphs that lack semantic depth. We consider repository comprehension and generation to be inverse processes within a unified cycle: generation expands intent into implementation, while comprehension compresses implementation back into intent. To address this, we propose RPG-Encoder, a framework that generalizes the Repository Planning Graph (RPG) from a static generative blueprint into a unified, high-fidelity representation. RPG-Encoder closes the reasoning loop through three mechanisms: (1) Encoding raw code into the RPG that combines lifted semantic features with code dependencies; (2) Evolving the topology incrementally to decouple maintenance costs from repository scale, reducing overhead by 95.7%; and (3) Operating as a unified interface for structure-aware navigation. In evaluations, RPG-Encoder establishes state-of-the-art repository understanding on SWE-bench Verified with 93.7% Acc@5 and exceeds the best baseline by over 10% on SWE-bench Live Lite. These results highlight our superior fine-grained localization accuracy in complex codebases. Furthermore, it achieves 98.5% reconstruction coverage on RepoCraft, confirming RPG's high-fidelity capacity to mirror the original codebase and closing the loop between intent and implementation.

</details>


### [417] [LEC-KG: An LLM-Embedding Collaborative Framework for Domain-Specific Knowledge Graph Construction -- A Case Study on SDGs](https://arxiv.org/abs/2602.02090)
*Yikai Zeng,Yingchao Piao,Jianhui Li*

Main category: cs.CL

TL;DR: LEC-KG是一个双向协作框架，结合LLM的语义理解和KGE的结构推理，用于从非结构化文本构建领域特定知识图谱，特别针对中文可持续发展目标报告。


<details>
  <summary>Details</summary>
Motivation: 从非结构化文本构建领域特定知识图谱面临三大挑战：异构实体提及、长尾关系分布以及缺乏标准化模式。现有方法难以同时处理这些问题。

Method: 提出LEC-KG框架，包含三个关键组件：1) 分层粗到细关系提取缓解长尾偏差；2) 证据引导的思维链反馈将结构建议基于源文本；3) 语义初始化实现未见实体的结构验证。LLM和KGE模块通过迭代协作相互增强。

Result: 在中文可持续发展目标报告上评估，相比LLM基线有显著提升，特别是在低频关系上表现突出。通过迭代精炼，能够可靠地将非结构化政策文本转化为验证过的知识图谱三元组。

Conclusion: LEC-KG框架通过LLM语义理解和KGE结构推理的双向协作，有效解决了领域特定知识图谱构建中的关键挑战，为从非结构化文本构建高质量知识图谱提供了可靠方法。

Abstract: Constructing domain-specific knowledge graphs from unstructured text remains challenging due to heterogeneous entity mentions, long-tail relation distributions, and the absence of standardized schemas. We present LEC-KG, a bidirectional collaborative framework that integrates the semantic understanding of Large Language Models (LLMs) with the structural reasoning of Knowledge Graph Embeddings (KGE). Our approach features three key components: (1) hierarchical coarse-to-fine relation extraction that mitigates long-tail bias, (2) evidence-guided Chain-of-Thought feedback that grounds structural suggestions in source text, and (3) semantic initialization that enables structural validation for unseen entities. The two modules enhance each other iteratively-KGE provides structure-aware feedback to refine LLM extractions, while validated triples progressively improve KGE representations. We evaluate LEC-KG on Chinese Sustainable Development Goal (SDG) reports, demonstrating substantial improvements over LLM baselines, particularly on low-frequency relations. Through iterative refinement, our framework reliably transforms unstructured policy text into validated knowledge graph triples.

</details>


### [418] [Think Dense, Not Long: Dynamic Decoupled Conditional Advantage for Efficient Reasoning](https://arxiv.org/abs/2602.02099)
*Keqin Peng,Yuanxin Ouyang,Xuebo Liu,Zhiliang Tian,Ruijian Han,Yancheng Yuan,Liang Ding*

Main category: cs.CL

TL;DR: 提出DDCA方法解决RLVR中长度惩罚导致准确率下降的问题，通过解耦正确性和效率优化，动态调整惩罚强度，在多个数学推理基准上实现效率-准确率平衡。


<details>
  <summary>Details</summary>
Motivation: RLVR虽然能激发多步推理，但常导致冗长轨迹。简单的长度惩罚在组相对优化中会严重损害准确率，这归因于两个结构性问题：长度基线稀释（错误回答降低组基线，过度惩罚正确解）和难度-惩罚不匹配（静态惩罚无法适应问题难度）。

Method: 提出动态解耦条件优势（DDCA）：1）在正确回答簇内条件计算长度优势，消除基线稀释；2）使用组通过率作为难度代理，动态缩放惩罚强度，实现效率与正确性的解耦优化。

Result: 在GSM8K、MATH500、AMC23和AIME25上的实验表明，DDCA相比自适应基线持续改善效率-准确率权衡：简单任务（如GSM8K）减少约60%生成token，困难基准（如AIME25）减少超20%，同时保持或提高准确率。

Conclusion: DDCA有效解决了RLVR中长度惩罚的负面影响，通过解耦优化和动态调整机制，在保持推理准确性的同时显著提升生成效率，为强化学习中的奖励设计提供了新思路。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) can elicit strong multi-step reasoning, yet it often encourages overly verbose traces. Moreover, naive length penalties in group-relative optimization can severely hurt accuracy. We attribute this failure to two structural issues: (i) Dilution of Length Baseline, where incorrect responses (with zero length reward) depress the group baseline and over-penalize correct solutions; and (ii) Difficulty-Penalty Mismatch, where a static penalty cannot adapt to problem difficulty, suppressing necessary reasoning on hard instances while leaving redundancy on easy ones. We propose Dynamic Decoupled Conditional Advantage (DDCA) to decouple efficiency optimization from correctness. DDCA computes length advantages conditionally within the correct-response cluster to eliminate baseline dilution, and dynamically scales the penalty strength using the group pass rate as a proxy for difficulty. Experiments on GSM8K, MATH500, AMC23, and AIME25 show that DDCA consistently improves the efficiency--accuracy trade-off relative to adaptive baselines, reducing generated tokens by approximately 60% on simpler tasks (e.g., GSM8K) versus over 20% on harder benchmarks (e.g., AIME25), thereby maintaining or improving accuracy. Code is available at https://github.com/alphadl/DDCA.

</details>


### [419] [Dicta-LM 3.0: Advancing The Frontier of Hebrew Sovereign LLMs](https://arxiv.org/abs/2602.02104)
*Shaltiel Shmidman,Avi Shmidman,Amir DN Cohen,Moshe Koppel*

Main category: cs.CL

TL;DR: Dicta-LM 3.0：针对希伯来语等低资源语言的开源大语言模型集合，包含24B、12B、1.7B三种规模，支持65k上下文长度，并发布了基准测试套件。


<details>
  <summary>Details</summary>
Motivation: 当前开源大语言模型主要针对英语，而希伯来语等低资源语言的高质量LLM供应不足但需求旺盛。训练这类语言的LLM面临独特挑战，需要专门解决方案。

Method: 基于现有基础模型（Mistral-Small-3.1、NVIDIA Nemotron Nano V2、Qwen3-1.7B）进行适配训练，使用大量希伯来语和英语文本语料。发布基础模型和带工具调用支持的聊天模型变体，所有模型支持65k上下文长度。

Result: 发布了Dicta-LM 3.0模型集合，包含三种规模（24B、12B、1.7B）的多个变体。同时创建了希伯来语聊天LLM评估基准套件，涵盖翻译、摘要、Winograd、以色列常识、标音等多个任务。

Conclusion: 该工作不仅解决了低资源语言LLM训练的复杂性，还提出了一个可推广到其他非英语语言的适配框架，为多语言NLP领域做出了贡献。

Abstract: Open-weight LLMs have been released by frontier labs; however, sovereign Large Language Models (for languages other than English) remain low in supply yet high in demand. Training large language models (LLMs) for low-resource languages such as Hebrew poses unique challenges. In this paper, we introduce Dicta-LM 3.0: an open-weight collection of LLMs trained on substantially-sized corpora of Hebrew and English texts. The model is released in three sizes: 24B - adapted from the Mistral-Small-3.1 base model, 12B - adapted from the NVIDIA Nemotron Nano V2 model, and 1.7B - adapted from the Qwen3-1.7B base model. We are releasing multiple variants of each model, each with a native context length of 65k tokens; base model and chat model with tool-calling support. To rigorously evaluate our models, we introduce a new benchmark suite for evaluation of Hebrew chat-LLMs, covering a diverse set of tasks including Translation, Summarization, Winograd, Israeli Trivia, and Diacritization (nikud). Our work not only addresses the intricacies of training LLMs in low-resource languages but also proposes a framework that can be leveraged for adapting other LLMs to various non-English languages, contributing to the broader field of multilingual NLP.

</details>


### [420] [Out of the Memory Barrier: A Highly Memory Efficient Training System for LLMs with Million-Token Contexts](https://arxiv.org/abs/2602.02108)
*Wenhao Li,Daohai Yu,Gen Luo,Yuxin Zhang,Fei Chao,Rongrong Ji,Yifan Wu,Jiaxin Liu,Ziyang Gong,Zimu Liao*

Main category: cs.CL

TL;DR: OOMB是一个高效内存训练系统，通过分块循环训练和即时激活重计算实现O(1)激活内存占用，结合KV缓存优化技术，使Qwen2.5-7B模型在单个H200 GPU上训练4M令牌上下文成为可能。


<details>
  <summary>Details</summary>
Motivation: 训练大语言模型的长上下文面临GPU内存瓶颈，主要问题是激活内存随序列长度线性增长，传统方法需要大规模集群和上下文并行，资源消耗巨大。

Method: 采用分块循环训练框架和即时激活重计算保持恒定激活内存；引入KV缓存优化套件：分页内存管理器消除碎片、异步CPU卸载隐藏传输延迟、页面级稀疏注意力降低计算和通信开销。

Result: 每增加10K令牌上下文，端到端训练内存开销仅增加10MB；Qwen2.5-7B模型可在单个H200 GPU上训练4M令牌上下文，相比传统方法大幅提升资源效率。

Conclusion: OOMB系统显著提升了长上下文LLM训练的资源效率，通过创新内存管理技术解决了激活内存瓶颈，为大规模长上下文训练提供了实用解决方案。

Abstract: Training Large Language Models (LLMs) on long contexts is severely constrained by prohibitive GPU memory overhead, not training time. The primary culprits are the activations, whose memory footprints scale linearly with sequence length. We introduce OOMB, a highly memory-efficient training system that directly confronts this barrier. Our approach employs a chunk-recurrent training framework with on-the-fly activation recomputation, which maintains a constant activation memory footprint (O(1)) and shifts the primary bottleneck to the growing KV cache. To manage the KV cache, OOMB integrates a suite of synergistic optimizations: a paged memory manager for both the KV cache and its gradients to eliminate fragmentation, asynchronous CPU offloading to hide data transfer latency, and page-level sparse attention to reduce both computational complexity and communication overhead. The synergy of these techniques yields exceptional efficiency. Our empirical results show that for every additional 10K tokens of context, the end-to-end training memory overhead increases by a mere 10MB for Qwen2.5-7B. This allows training Qwen2.5-7B with a 4M-token context on a single H200 GPU, a feat that would otherwise require a large cluster using context parallelism. This work represents a substantial advance in resource efficiency for long-context LLM training. The source code is available at https://github.com/wenhaoli-xmu/OOMB.

</details>


### [421] [There Is More to Refusal in Large Language Models than a Single Direction](https://arxiv.org/abs/2602.02132)
*Faaiz Joad,Majd Hawasly,Sabri Boughorbel,Nadir Durrani,Husrev Taha Sencar*

Main category: cs.CL

TL;DR: 研究发现LLM的拒绝行为由多个几何上不同的激活空间方向控制，而非单一方向，但这些方向都通过共享的一维控制旋钮产生相似的拒绝-过度拒绝权衡，主要区别在于拒绝方式而非是否拒绝。


<details>
  <summary>Details</summary>
Motivation: 先前研究认为大语言模型的拒绝行为由单一激活空间方向介导，但本文发现这种解释不完整，需要更深入地理解拒绝行为的多样性及其控制机制。

Method: 在11个拒绝和非合规类别（包括安全性、不完整请求、拟人化、过度拒绝等）上分析激活空间几何结构，研究不同拒绝方向对模型行为的影响。

Result: 发现拒绝行为对应几何上不同的激活空间方向，但所有拒绝相关方向的线性调控都产生几乎相同的拒绝-过度拒绝权衡，形成一个共享的一维控制旋钮，主要影响拒绝方式而非是否拒绝。

Conclusion: LLM的拒绝行为比先前认为的更复杂多样，但可以通过共享的控制机制进行调节，这对理解模型拒绝机制和开发更精细的控制方法具有重要意义。

Abstract: Prior work argues that refusal in large language models is mediated by a single activation-space direction, enabling effective steering and ablation. We show that this account is incomplete. Across eleven categories of refusal and non-compliance, including safety, incomplete or unsupported requests, anthropomorphization, and over-refusal, we find that these refusal behaviors correspond to geometrically distinct directions in activation space. Yet despite this diversity, linear steering along any refusal-related direction produces nearly identical refusal to over-refusal trade-offs, acting as a shared one-dimensional control knob. The primary effect of different directions is not whether the model refuses, but how it refuses.

</details>


### [422] [Quantifying the Gap between Understanding and Generation within Unified Multimodal Models](https://arxiv.org/abs/2602.02140)
*Chenlong Wang,Yuhang Chen,Zhihan Hu,Dongping Chen,Wenhu Chen,Sarah Wiegreffe,Tianyi Zhou*

Main category: cs.CL

TL;DR: GapEval是一个双向基准测试，用于量化统一多模态模型中理解与生成能力之间的差距，发现当前模型仅实现表面统一而非深度认知融合。


<details>
  <summary>Details</summary>
Motivation: 尽管统一多模态模型在理解和生成任务上取得显著进展，但这两项能力是否真正在单一模型中实现对齐和整合尚不清楚。需要研究当前模型是否实现了深度的认知统一。

Method: 提出GapEval双向基准测试，每个问题可以在图像和文本两种模态中回答，对称评估模型的双向推理能力和跨模态一致性。从知识操作角度进行实证研究，探索底层机制。

Result: 实验发现不同架构的统一多模态模型在两个方向上都存在持续差距，表明当前模型仅实现表面统一而非深度认知融合。模型内部知识常保持分离，跨模态的能力涌现和知识不同步。

Conclusion: 当前统一多模态模型的理解和生成能力尚未真正统一，仅实现表面层次的整合。需要进一步探索如何实现跨模态的深度认知融合和知识同步。

Abstract: Recent advances in unified multimodal models (UMM) have demonstrated remarkable progress in both understanding and generation tasks. However, whether these two capabilities are genuinely aligned and integrated within a single model remains unclear. To investigate this question, we introduce GapEval, a bidirectional benchmark designed to quantify the gap between understanding and generation capabilities, and quantitatively measure the cognitive coherence of the two "unified" directions. Each question can be answered in both modalities (image and text), enabling a symmetric evaluation of a model's bidirectional inference capability and cross-modal consistency. Experiments reveal a persistent gap between the two directions across a wide range of UMMs with different architectures, suggesting that current models achieve only surface-level unification rather than deep cognitive convergence of the two. To further explore the underlying mechanism, we conduct an empirical study from the perspective of knowledge manipulation to illustrate the underlying limitations. Our findings indicate that knowledge within UMMs often remains disjoint. The capability emergence and knowledge across modalities are unsynchronized, paving the way for further exploration.

</details>


### [423] [Focus-dLLM: Accelerating Long-Context Diffusion LLM Inference via Confidence-Guided Context Focusing](https://arxiv.org/abs/2602.02159)
*Lingkun Long,Yushi Huang,Shihao Bai,Ruihao Gong,Jun Zhang,Ao Zhou,Jianlei Yang*

Main category: cs.CL

TL;DR: Focus-dLLM：一种针对扩散大语言模型的无训练注意力稀疏化框架，通过过去置信度引导的指示器和sink感知剪枝策略，在保持性能的同时实现超过29倍的加速。


<details>
  <summary>Details</summary>
Motivation: 扩散大语言模型在长上下文处理方面表现出色，但双向全注意力的计算成本限制了推理效率。现有的稀疏注意力方法效果不佳，因为需要在解码前估计未解码token的注意力重要性，而扩散过程中未掩码的token位置是未知的。

Method: 1. 基于token置信度在相邻步骤间强相关的发现，设计过去置信度引导的指示器来预测未掩码区域；2. 提出sink感知剪枝策略，准确估计并移除冗余注意力计算，同时保留高影响力的注意力sink；3. 利用跨层一致性，在不同层间复用已识别的sink位置以减少开销。

Result: 在32K上下文长度下，该方法实现了超过29倍的无损失加速，显著提升了扩散大语言模型的推理效率。

Conclusion: Focus-dLLM为扩散大语言模型提供了一种有效的训练无关注意力稀疏化解决方案，在保持准确性的同时大幅提升了长上下文推理效率，具有实际应用价值。

Abstract: Diffusion Large Language Models (dLLMs) deliver strong long-context processing capability in a non-autoregressive decoding paradigm. However, the considerable computational cost of bidirectional full attention limits the inference efficiency. Although sparse attention is promising, existing methods remain ineffective. This stems from the need to estimate attention importance for tokens yet to be decoded, while the unmasked token positions are unknown during diffusion. In this paper, we present Focus-dLLM, a novel training-free attention sparsification framework tailored for accurate and efficient long-context dLLM inference. Based on the finding that token confidence strongly correlates across adjacent steps, we first design a past confidence-guided indicator to predict unmasked regions. Built upon this, we propose a sink-aware pruning strategy to accurately estimate and remove redundant attention computation, while preserving highly influential attention sinks. To further reduce overhead, this strategy reuses identified sink locations across layers, leveraging the observed cross-layer consistency. Experimental results show that our method offers more than $29\times$ lossless speedup under $32K$ context length. The code is publicly available at: https://github.com/Longxmas/Focus-dLLM

</details>


### [424] [D-CORE: Incentivizing Task Decomposition in Large Reasoning Models for Complex Tool Use](https://arxiv.org/abs/2602.02160)
*Bowen Xu,Shaoyu Wu,Hao Jiang,Kai Liu,Xin Chen,Lulu Hu,Bin Yang*

Main category: cs.CL

TL;DR: D-CORE框架通过任务分解和推理过程组合，解决大型推理模型在复杂工具使用场景中的懒惰推理问题，显著提升工具使用能力


<details>
  <summary>Details</summary>
Motivation: 当前大型推理模型在复杂工具使用场景中缺乏子任务分解能力，导致"懒惰推理"问题，无法有效处理复杂现实问题

Method: 提出两阶段训练框架：1) 通过自蒸馏激励模型的任务分解推理能力；2) 使用多样性感知强化学习恢复模型的反思推理能力

Result: D-CORE在BFCLv3基准测试中表现优异：8B模型达到77.7%准确率，超越最佳8B模型5.7%；14B模型达到79.3%准确率，超越70B模型，尽管体积小5倍

Conclusion: D-CORE框架有效解决了大型推理模型的懒惰推理问题，在不同规模模型和多样化基准测试中都实现了稳健的工具使用改进

Abstract: Effective tool use and reasoning are essential capabilities for large reasoning models~(LRMs) to address complex real-world problems. Through empirical analysis, we identify that current LRMs lack the capability of sub-task decomposition in complex tool use scenarios, leading to Lazy Reasoning. To address this, we propose a two-stage training framework D-CORE~(\underline{\textbf{D}}ecomposing tasks and \underline{\textbf{Co}}mposing \underline{\textbf{Re}}asoning processes) that first incentivize the LRMs' task decomposition reasoning capability via self-distillation, followed by diversity-aware reinforcement learning~(RL) to restore LRMs' reflective reasoning capability. D-CORE achieves robust tool-use improvements across diverse benchmarks and model scales. Experiments on BFCLv3 demonstrate superiority of our method: D-CORE-8B reaches 77.7\% accuracy, surpassing the best-performing 8B model by 5.7\%. Meanwhile, D-CORE-14B establishes a new state-of-the-art at 79.3\%, outperforming 70B models despite being 5$\times$ smaller. The source code is available at https://github.com/alibaba/EfficientAI.

</details>


### [425] [AR-MAP: Are Autoregressive Large Language Models Implicit Teachers for Diffusion Large Language Models?](https://arxiv.org/abs/2602.02178)
*Liang Lin,Feng Xiong,Zengbin Wang,Kun Wang,Junhao Dong,Xuecai Hu,Yong Wang,Xiangxiang Chu*

Main category: cs.CL

TL;DR: AR-MAP：利用对齐好的自回归大语言模型作为隐式教师，通过权重缩放实现扩散大语言模型的对齐，避免直接对齐的高方差和计算开销


<details>
  <summary>Details</summary>
Motivation: 扩散大语言模型（DLLMs）作为自回归模型的替代方案，支持并行token生成，但其偏好对齐面临挑战，主要因为基于ELBO的似然估计引入高方差

Method: 提出AR-MAP迁移学习框架，利用已对齐的自回归大语言模型（AR-LLMs）作为隐式教师，通过简单的权重缩放让DLLMs吸收对齐知识，利用两种模型间的共享架构结构

Result: 在多种偏好对齐任务上，AR-MAP达到竞争性或优于现有DLLM特定对齐方法的性能，在所有任务和模型上平均得分69.08%

Conclusion: AR-MAP通过利用AR-LLMs作为教师，有效解决了DLLM对齐的高方差问题，提供了一种高效且性能优越的DLLM对齐方法

Abstract: Diffusion Large Language Models (DLLMs) have emerged as a powerful alternative to autoregressive models, enabling parallel token generation across multiple positions. However, preference alignment of DLLMs remains challenging due to high variance introduced by Evidence Lower Bound (ELBO)-based likelihood estimation. In this work, we propose AR-MAP, a novel transfer learning framework that leverages preference-aligned autoregressive LLMs (AR-LLMs) as implicit teachers for DLLM alignment. We reveal that DLLMs can effectively absorb alignment knowledge from AR-LLMs through simple weight scaling, exploiting the shared architectural structure between these divergent generation paradigms. Crucially, our approach circumvents the high variance and computational overhead of direct DLLM alignment and comprehensive experiments across diverse preference alignment tasks demonstrate that AR-MAP achieves competitive or superior performance compared to existing DLLM-specific alignment methods, achieving 69.08\% average score across all tasks and models. Our Code is available at https://github.com/AMAP-ML/AR-MAP.

</details>


### [426] [Evaluating Metalinguistic Knowledge in Large Language Models across the World's Languages](https://arxiv.org/abs/2602.02182)
*Tjaša Arčon,Matej Klemen,Marko Robnik-Šikonja,Kaja Dobrovoljc*

Main category: cs.CL

TL;DR: LLMs的元语言知识有限，表现受数字资源可用性影响，而非真正的跨语言语法能力


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在语言使用任务上被广泛评估，但其对语言结构的理解（元语言知识）仍不清楚。现有基准测试通常关注狭窄现象，强调高资源语言，很少评估元语言知识——即对语言结构的显式推理而非语言使用。

Method: 使用准确率和宏观F1分数，结合多数类和随机基线，分析整体性能并考察语言领域和语言相关因素的变化。创建了一个系统评估LLMs元语言知识的基准测试。

Result: GPT-4o表现最佳但准确率仅0.367，开源模型落后。所有模型表现高于随机但未能超越多数类基线，表明它们能捕捉跨语言模式但缺乏细粒度语法区分。性能随语言领域变化，词汇特征准确率最高，音系特征最低。数字语言状态与准确率强相关：数字存在度高、资源可用的语言评估更准确，低资源语言表现显著更低。

Conclusion: LLMs的元语言知识是碎片化的，由数据可用性塑造而非真正的跨语言语法能力。资源相关指标比地理、谱系或社会语言因素更能预测准确率。需要更多全球语言多样性来改善LLMs的元语言知识。

Abstract: Large language models (LLMs) are routinely evaluated on language use tasks, yet their knowledge of linguistic structure remains poorly understood. Existing linguistic benchmarks typically focus on narrow phenomena, emphasize high-resource languages, and rarely evaluate metalinguistic knowledge-explicit reasoning about language structure rather than language use. Using accuracy and macro F1, together with majority-class and chance baselines, we analyse overall performance and examine variation by linguistic domains and language-related factors. Our results show that metalinguistic knowledge in current LLMs is limited: GPT-4o performs best but achieves only moderate accuracy (0.367), while open-source models lag behind. All models perform above chance but fail to outperform the majority-class baseline, suggesting they capture cross-linguistic patterns but lack fine-grained grammatical distinctions. Performance varies across linguistic domains, with lexical features showing the highest accuracy and phonological features among the lowest, partially reflecting differences in online visibility. At the language level, accuracy shows a strong association with digital language status: languages with higher digital presence and resource availability are evaluated more accurately, while low-resource languages show substantially lower performance. Analyses of predictive factors confirm that resource-related indicators (Wikipedia size, corpus availability) are more informative predictors of accuracy than geographical, genealogical, or sociolinguistic factors. Together, these results suggest that LLMs' metalinguistic knowledge is fragmented and shaped by data availability rather than generalizable grammatical competence across the world's languages. We release our benchmark as an open-source dataset to support systematic evaluation and encourage greater global linguistic diversity in future LLMs.

</details>


### [427] [Culinary Crossroads: A RAG Framework for Enhancing Diversity in Cross-Cultural Recipe Adaptation](https://arxiv.org/abs/2507.21934)
*Tianyi Hu,Andrea Morales-Garzón,Jingyi Zheng,Maria Maistro,Daniel Hershcovich*

Main category: cs.CL

TL;DR: CARRIAGE是一个用于跨文化食谱适应的RAG框架，通过增强检索和上下文组织的多样性来解决传统RAG在创造性任务中输出多样性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 跨文化食谱适应需要保持原菜本质、确保文化适宜性，并为不同饮食需求和偏好提供多样选择。传统RAG方法虽然结合了检索和LLM生成，但在创造性任务中过度依赖有限的上下文，无法利用多样化的上下文输入生成多样化的输出。

Method: 提出CARRIAGE框架，这是一个即插即用的RAG框架，通过增强检索和上下文组织的多样性来生成多样化的食谱适应结果。这是首个明确旨在生成高度多样化输出以适应多种用户偏好的RAG框架。

Result: 实验表明，CARRIAGE在食谱适应的多样性和质量方面实现了帕累托效率，相比闭卷LLM在保持质量的同时显著提升了输出多样性。

Conclusion: CARRIAGE成功解决了RAG在创造性任务中输出多样性不足的关键限制，为跨文化食谱适应提供了能够生成多样化高质量结果的实用框架。

Abstract: In cross-cultural recipe adaptation, the goal is not only to ensure cultural appropriateness and retain the original dish's essence, but also to provide diverse options for various dietary needs and preferences. Retrieval Augmented Generation (RAG) is a promising approach, combining the retrieval of real recipes from the target cuisine for cultural adaptability with large language models (LLMs) for relevance. However, it remains unclear whether RAG can generate diverse adaptation results. Our analysis shows that RAG tends to overly rely on a limited portion of the context across generations, failing to produce diverse outputs even when provided with varied contextual inputs. This reveals a key limitation of RAG in creative tasks with multiple valid answers: it fails to leverage contextual diversity for generating varied responses. To address this issue, we propose CARRIAGE, a plug-and-play RAG framework for cross-cultural recipe adaptation that enhances diversity in both retrieval and context organization. To our knowledge, this is the first RAG framework that explicitly aims to generate highly diverse outputs to accommodate multiple user preferences. Our experiments show that CARRIAGE achieves Pareto efficiency in terms of diversity and quality of recipe adaptation compared to closed-book LLMs.

</details>


### [428] [Sinhala Physical Common Sense Reasoning Dataset for Global PIQA](https://arxiv.org/abs/2602.02207)
*Nisansa de Silva,Surangika Ranathunga*

Main category: cs.CL

TL;DR: 首个僧伽罗语物理常识推理数据集，包含110个人工创建验证的样本，每个样本包含提示、正确答案和错误答案，主要针对斯里兰卡语境


<details>
  <summary>Details</summary>
Motivation: 为僧伽罗语创建物理常识推理数据集，填补该语言在常识推理任务上的空白，支持斯里兰卡语境下的AI应用开发

Method: 作为Global PIQA项目的一部分，人工创建并验证110个数据样本，每个样本包含提示、正确答案和错误答案，问题主要基于斯里兰卡文化背景

Result: 成功创建首个僧伽罗语物理常识推理数据集，包含110个高质量样本，为僧伽罗语NLP研究提供了重要资源

Conclusion: 该数据集填补了僧伽罗语在常识推理任务上的空白，为斯里兰卡语境下的AI应用开发提供了重要基础，支持多语言AI的公平发展

Abstract: This paper presents the first-ever Sinhala physical common sense reasoning dataset created as part of Global PIQA. It contains 110 human-created and verified data samples, where each sample consists of a prompt, the corresponding correct answer, and a wrong answer. Most of the questions refer to the Sri Lankan context, where Sinhala is an official language.

</details>


### [429] [Towards AI Evaluation in Domain-Specific RAG Systems: The AgriHubi Case Study](https://arxiv.org/abs/2602.02208)
*Md. Toufique Hasan,Ayman Asad Khan,Mika Saari,Vaishnavi Bankhele,Pekka Abrahamsson*

Main category: cs.CL

TL;DR: AgriHubi是一个针对芬兰语农业决策支持的领域自适应检索增强生成系统，通过整合芬兰农业文档和开源模型，结合显式来源基础和用户反馈，显著提升了回答完整性、语言准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在知识密集型领域有潜力，但在农业应用中受到限制：基础薄弱、训练数据以英语为中心、缺乏真实世界评估。这些问题在低资源语言中更为突出，尽管存在高质量的领域文档，但通用模型难以有效访问。

Method: 开发AgriHubi系统，整合芬兰农业文档与开源PORO系列模型，采用检索增强生成架构，结合显式来源基础和用户反馈支持迭代优化。经过8次迭代开发，通过两个用户研究进行评估。

Result: 系统在回答完整性、语言准确性和感知可靠性方面有明显提升。研究还揭示了部署更大模型时响应质量与延迟之间的实际权衡。

Conclusion: 该研究为低资源语言环境下设计和评估领域特定RAG系统提供了实证指导，展示了领域自适应方法在农业决策支持中的有效性。

Abstract: Large language models show promise for knowledge-intensive domains, yet their use in agriculture is constrained by weak grounding, English-centric training data, and limited real-world evaluation. These issues are amplified for low-resource languages, where high-quality domain documentation exists but remains difficult to access through general-purpose models. This paper presents AgriHubi, a domain-adapted retrieval-augmented generation (RAG) system for Finnish-language agricultural decision support. AgriHubi integrates Finnish agricultural documents with open PORO family models and combines explicit source grounding with user feedback to support iterative refinement. Developed over eight iterations and evaluated through two user studies, the system shows clear gains in answer completeness, linguistic accuracy, and perceived reliability. The results also reveal practical trade-offs between response quality and latency when deploying larger models. This study provides empirical guidance for designing and evaluating domain-specific RAG systems in low-resource language settings.

</details>


### [430] [Am I More Pointwise or Pairwise? Revealing Position Bias in Rubric-Based LLM-as-a-Judge](https://arxiv.org/abs/2602.02219)
*Yuzheng Xu,Tosho Hirasawa,Tadashi Kozuno,Yoshitaka Ushiku*

Main category: cs.CL

TL;DR: 研究发现基于量规的LLM评估存在位置偏差，提出平衡排列策略来缓解偏差并提高与人类评估的相关性


<details>
  <summary>Details</summary>
Motivation: 虽然LLM作为评估者已被广泛应用，但基于量规的评估（从多个量规中选择分数）研究较少。本文发现这种评估方式存在位置偏差问题，即LLM倾向于选择特定位置的分数选项

Method: 通过多个模型和数据集的控制实验验证位置偏差的存在，并提出平衡排列策略：将每个分数选项均匀分布在所有可能的位置上，通过聚合多个排列的分数来缓解偏差

Result: 实验显示基于量规的LLM评估存在一致的位置偏差，平衡排列策略不仅能揭示潜在的偏差，还能显著提高LLM评估与人类评估之间的相关性

Conclusion: 基于量规的LLM评估并非本质上的点式评估，简单的基于排列的校准可以显著提高其可靠性，为LLM作为评估者的应用提供了改进方法

Abstract: Large language models (LLMs) are now widely used to evaluate the quality of text, a field commonly referred to as LLM-as-a-judge. While prior works mainly focus on point-wise and pair-wise evaluation paradigms. Rubric-based evaluation, where LLMs select a score from multiple rubrics, has received less analysis. In this work, we show that rubric-based evaluation implicitly resembles a multi-choice setting and therefore has position bias: LLMs prefer score options appearing at specific positions in the rubric list. Through controlled experiments across multiple models and datasets, we demonstrate consistent position bias. To mitigate this bias, we propose a balanced permutation strategy that evenly distributes each score option across positions. We show that aggregating scores across balanced permutations not only reveals latent position bias, but also improves correlation between the LLM-as-a-Judge and human. Our results suggest that rubric-based LLM-as-a-Judge is not inherently point-wise and that simple permutation-based calibration can substantially improve its reliability.

</details>


### [431] [Using Correspondence Patterns to Identify Irregular Words in Cognate sets Through Leave-One-Out Validation](https://arxiv.org/abs/2602.02221)
*Frederic Blum,Johann-Mattis List*

Main category: cs.CL

TL;DR: 提出了一种新的对应模式平衡平均重现率作为规律性度量，并开发了基于此度量的计算方法来识别对应模式不规则的同源词集，在真实数据上达到85%的准确率。


<details>
  <summary>Details</summary>
Motivation: 历史语言比较中，规律性对应是主要证据，但规律性判断往往依赖直觉而非量化评估，且不规则现象比新语法学派模型预期的更常见。随着计算历史语言学的发展和标准化词汇数据的增加，需要改进工作流程并提供定量评估。

Method: 提出了对应模式的平衡平均重现率作为新的规律性度量，并开发了基于此度量的计算方法来识别对应模式不规则的同源词集。使用留一验证法进行实验验证，在模拟和真实数据上测试方法识别导致不规则形式的能力。

Result: 该方法在基于真实数据的数据集上达到85%的整体准确率。展示了使用大数据集子样本的优势，以及数据中不规则性增加对结果的影响。

Conclusion: 新的规律性度量和基于此的不规则同源词识别方法在提高现有和未来计算机辅助语言比较数据集质量方面具有重要潜力。

Abstract: Regular sound correspondences constitute the principal evidence in historical language comparison. Despite the heuristic focus on regularity, it is often more an intuitive judgement than a quantified evaluation, and irregularity is more common than expected from the Neogrammarian model. Given the recent progress of computational methods in historical linguistics and the increased availability of standardized lexical data, we are now able to improve our workflows and provide such a quantitative evaluation. Here, we present the balanced average recurrence of correspondence patterns as a new measure of regularity. We also present a new computational method that uses this measure to identify cognate sets that lack regularity with respect to their correspondence patterns. We validate the method through two experiments, using simulated and real data. In the experiments, we employ leave-one-out validation to measure the regularity of cognate sets in which one word form has been replaced by an irregular one, checking how well our method identifies the forms causing the irregularity. Our method achieves an overall accuracy of 85\% with the datasets based on real data. We also show the benefits of working with subsamples of large datasets and how increasing irregularity in the data influences our results. Reflecting on the broader potential of our new regularity measure and the irregular cognate identification method based on it, we conclude that they could play an important role in improving the quality of existing and future datasets in computer-assisted language comparison.

</details>


### [432] [OpenSeal: Good, Fast, and Cheap Construction of an Open-Source Southeast Asian LLM via Parallel Data](https://arxiv.org/abs/2602.02266)
*Tan Sang Nguyen,Muhammad Reza Qorib,Hwee Tou Ng*

Main category: cs.CL

TL;DR: OpenSeal是首个真正开源的东南亚语言大模型，仅用34.7B平行数据和180小时训练，性能媲美同类模型


<details>
  <summary>Details</summary>
Motivation: 现有LLM多为英语中心，对低资源语言表现不佳；东南亚语言LLM缺乏真正开源模型，训练数据不公开，影响透明度和对模型内部机制的理解

Method: 通过控制实验研究平行数据在LLM持续预训练中的有效性，发现仅使用平行数据是最有效扩展LLM到新语言的方法

Result: 仅用34.7B tokens平行数据和180小时在8x NVIDIA H200 GPU上训练，构建了OpenSeal，性能与现有相似规模模型相当

Conclusion: 平行数据是扩展LLM到新语言的有效方法，OpenSeal作为首个真正开源的东南亚语言LLM，为透明度和深入研究模型内部机制提供了基础

Abstract: Large language models (LLMs) have proven to be effective tools for a wide range of natural language processing (NLP) applications. Although many LLMs are multilingual, most remain English-centric and perform poorly on low-resource languages. Recently, several Southeast Asia-focused LLMs have been developed, but none are truly open source, as they do not publicly disclose their training data. Truly open-source models are important for transparency and for enabling a deeper and more precise understanding of LLM internals and development, including biases, generalization, and multilinguality. Motivated by recent advances demonstrating the effectiveness of parallel data in improving multilingual performance, we conduct controlled and comprehensive experiments to study the effectiveness of parallel data in continual pretraining of LLMs. Our findings show that using only parallel data is the most effective way to extend an LLM to new languages. Using just 34.7B tokens of parallel data and 180 hours on 8x NVIDIA H200 GPUs, we built OpenSeal, the first truly open Southeast Asian LLM that rivals the performance of existing models of similar size.

</details>


### [433] [dziribot: rag based intelligent conversational agent for algerian arabic dialect](https://arxiv.org/abs/2602.02270)
*El Batoul Bechiri,Dihia Lanasri*

Main category: cs.CL

TL;DR: DziriBOT是一个针对阿尔及利亚方言Darja的混合智能对话代理，采用多层架构结合NLU和RAG技术，通过微调DziriBERT模型在低资源方言环境中实现最先进性能。


<details>
  <summary>Details</summary>
Motivation: 客户服务数字化需求增长，但阿尔及利亚方言Darja存在非标准化拼写、法语代码转换、阿拉伯语和拉丁语脚本混用等复杂语言特征，传统对话系统难以处理。

Method: 提出多层架构整合专用自然语言理解(NLU)和检索增强生成(RAG)，评估三种方法：稀疏特征Rasa管道、经典机器学习基线、基于Transformer的微调，最终采用微调DziriBERT模型。

Result: 微调DziriBERT模型达到最先进性能，显著优于传统基线，特别是在处理拼写噪声和罕见意图方面表现突出。

Conclusion: DziriBOT为阿尔及利亚用户提供了连接正式语言模型与方言现实的稳健可扩展解决方案，为区域市场的方言感知自动化提供了蓝图。

Abstract: The rapid digitalization of customer service has intensified the demand for conversational agents capable of providing accurate and natural interactions. In the Algerian context, this is complicated by the linguistic complexity of Darja, a dialect characterized by non-standardized orthography, extensive code-switching with French, and the simultaneous use of Arabic and Latin (Arabizi) scripts. This paper introduces DziriBOT, a hybrid intelligent conversational agent specifically engineered to overcome these challenges. We propose a multi-layered architecture that integrates specialized Natural Language Understanding (NLU) with Retrieval-Augmented Generation (RAG), allowing for both structured service flows and dynamic, knowledge-intensive responses grounded in curated enterprise documentation. To address the low-resource nature of Darja, we systematically evaluate three distinct approaches: a sparse-feature Rasa pipeline, classical machine learning baselines, and transformer-based fine-tuning. Our experimental results demonstrate that the fine-tuned DziriBERT model achieves state-of-the-art performance. These results significantly outperform traditional baselines, particularly in handling orthographic noise and rare intents. Ultimately, DziriBOT provides a robust, scalable solution that bridges the gap between formal language models and the linguistic realities of Algerian users, offering a blueprint for dialect-aware automation in the regional market.

</details>


### [434] [Kimi K2.5: Visual Agentic Intelligence](https://arxiv.org/abs/2602.02276)
*Kimi Team,Tongtong Bai,Yifan Bai,Yiping Bao,S. H. Cai,Yuan Cao,Y. Charles,H. S. Che,Cheng Chen,Guanduo Chen,Huarong Chen,Jia Chen,Jiahao Chen,Jianlong Chen,Jun Chen,Kefan Chen,Liang Chen,Ruijue Chen,Xinhao Chen,Yanru Chen,Yanxu Chen,Yicun Chen,Yimin Chen,Yingjiang Chen,Yuankun Chen,Yujie Chen,Yutian Chen,Zhirong Chen,Ziwei Chen,Dazhi Cheng,Minghan Chu,Jialei Cui,Jiaqi Deng,Muxi Diao,Hao Ding,Mengfan Dong,Mengnan Dong,Yuxin Dong,Yuhao Dong,Angang Du,Chenzhuang Du,Dikang Du,Lingxiao Du,Yulun Du,Yu Fan,Shengjun Fang,Qiulin Feng,Yichen Feng,Garimugai Fu,Kelin Fu,Hongcheng Gao,Tong Gao,Yuyao Ge,Shangyi Geng,Chengyang Gong,Xiaochen Gong,Zhuoma Gongque,Qizheng Gu,Xinran Gu,Yicheng Gu,Longyu Guan,Yuanying Guo,Xiaoru Hao,Weiran He,Wenyang He,Yunjia He,Chao Hong,Hao Hu,Jiaxi Hu,Yangyang Hu,Zhenxing Hu,Ke Huang,Ruiyuan Huang,Weixiao Huang,Zhiqi Huang,Tao Jiang,Zhejun Jiang,Xinyi Jin,Yu Jing,Guokun Lai,Aidi Li,C. Li,Cheng Li,Fang Li,Guanghe Li,Guanyu Li,Haitao Li,Haoyang Li,Jia Li,Jingwei Li,Junxiong Li,Lincan Li,Mo Li,Weihong Li,Wentao Li,Xinhang Li,Xinhao Li,Yang Li,Yanhao Li,Yiwei Li,Yuxiao Li,Zhaowei Li,Zheming Li,Weilong Liao,Jiawei Lin,Xiaohan Lin,Zhishan Lin,Zichao Lin,Cheng Liu,Chenyu Liu,Hongzhang Liu,Liang Liu,Shaowei Liu,Shudong Liu,Shuran Liu,Tianwei Liu,Tianyu Liu,Weizhou Liu,Xiangyan Liu,Yangyang Liu,Yanming Liu,Yibo Liu,Yuanxin Liu,Yue Liu,Zhengying Liu,Zhongnuo Liu,Enzhe Lu,Haoyu Lu,Zhiyuan Lu,Junyu Luo,Tongxu Luo,Yashuo Luo,Long Ma,Yingwei Ma,Shaoguang Mao,Yuan Mei,Xin Men,Fanqing Meng,Zhiyong Meng,Yibo Miao,Minqing Ni,Kun Ouyang,Siyuan Pan,Bo Pang,Yuchao Qian,Ruoyu Qin,Zeyu Qin,Jiezhong Qiu,Bowen Qu,Zeyu Shang,Youbo Shao,Tianxiao Shen,Zhennan Shen,Juanfeng Shi,Lidong Shi,Shengyuan Shi,Feifan Song,Pengwei Song,Tianhui Song,Xiaoxi Song,Hongjin Su,Jianlin Su,Zhaochen Su,Lin Sui,Jinsong Sun,Junyao Sun,Tongyu Sun,Flood Sung,Yunpeng Tai,Chuning Tang,Heyi Tang,Xiaojuan Tang,Zhengyang Tang,Jiawen Tao,Shiyuan Teng,Chaoran Tian,Pengfei Tian,Ao Wang,Bowen Wang,Chensi Wang,Chuang Wang,Congcong Wang,Dingkun Wang,Dinglu Wang,Dongliang Wang,Feng Wang,Hailong Wang,Haiming Wang,Hengzhi Wang,Huaqing Wang,Hui Wang,Jiahao Wang,Jinhong Wang,Jiuzheng Wang,Kaixin Wang,Linian Wang,Qibin Wang,Shengjie Wang,Shuyi Wang,Si Wang,Wei Wang,Xiaochen Wang,Xinyuan Wang,Yao Wang,Yejie Wang,Yipu Wang,Yiqin Wang,Yucheng Wang,Yuzhi Wang,Zhaoji Wang,Zhaowei Wang,Zhengtao Wang,Zhexu Wang,Zihan Wang,Zizhe Wang,Chu Wei,Ming Wei,Chuan Wen,Zichen Wen,Chengjie Wu,Haoning Wu,Junyan Wu,Rucong Wu,Wenhao Wu,Yuefeng Wu,Yuhao Wu,Yuxin Wu,Zijian Wu,Chenjun Xiao,Jin Xie,Xiaotong Xie,Yuchong Xie,Yifei Xin,Bowei Xing,Boyu Xu,Jianfan Xu,Jing Xu,Jinjing Xu,L. H. Xu,Lin Xu,Suting Xu,Weixin Xu,Xinbo Xu,Xinran Xu,Yangchuan Xu,Yichang Xu,Yuemeng Xu,Zelai Xu,Ziyao Xu,Junjie Yan,Yuzi Yan,Guangyao Yang,Hao Yang,Junwei Yang,Kai Yang,Ningyuan Yang,Ruihan Yang,Xiaofei Yang,Xinlong Yang,Ying Yang,Yi Yang,Yi Yang,Zhen Yang,Zhilin Yang,Zonghan Yang,Haotian Yao,Dan Ye,Wenjie Ye,Zhuorui Ye,Bohong Yin,Chengzhen Yu,Longhui Yu,Tao Yu,Tianxiang Yu,Enming Yuan,Mengjie Yuan,Xiaokun Yuan,Yang Yue,Weihao Zeng,Dunyuan Zha,Haobing Zhan,Dehao Zhang,Hao Zhang,Jin Zhang,Puqi Zhang,Qiao Zhang,Rui Zhang,Xiaobin Zhang,Y. Zhang,Yadong Zhang,Yangkun Zhang,Yichi Zhang,Yizhi Zhang,Yongting Zhang,Yu Zhang,Yushun Zhang,Yutao Zhang,Yutong Zhang,Zheng Zhang,Chenguang Zhao,Feifan Zhao,Jinxiang Zhao,Shuai Zhao,Xiangyu Zhao,Yikai Zhao,Zijia Zhao,Huabin Zheng,Ruihan Zheng,Shaojie Zheng,Tengyang Zheng,Junfeng Zhong,Longguang Zhong,Weiming Zhong,M. Zhou,Runjie Zhou,Xinyu Zhou,Zaida Zhou,Jinguo Zhu,Liya Zhu,Xinhao Zhu,Yuxuan Zhu,Zhen Zhu,Jingze Zhuang,Weiyu Zhuang,Ying Zou,Xinxing Zu*

Main category: cs.CL

TL;DR: Kimi K2.5是一个开源的多模态智能体模型，通过联合优化文本和视觉模态，结合Agent Swarm并行代理编排框架，在多种任务上达到SOTA性能，并显著降低延迟。


<details>
  <summary>Details</summary>
Motivation: 推动通用智能体智能的发展，解决复杂任务处理中的效率和性能问题，通过多模态联合优化提升智能体的综合能力。

Method: 采用联合文本-视觉预训练、零视觉SFT和联合文本-视觉强化学习等技术进行多模态优化；引入Agent Swarm框架，动态分解复杂任务为异构子问题并并行执行。

Result: 在编码、视觉、推理和智能体任务等多个领域达到最先进水平；Agent Swarm相比单智能体基线将延迟降低高达4.5倍。

Conclusion: Kimi K2.5通过多模态联合优化和并行代理编排，显著提升了智能体智能的性能和效率，为未来研究和实际应用提供了有价值的开源模型。

Abstract: We introduce Kimi K2.5, an open-source multimodal agentic model designed to advance general agentic intelligence. K2.5 emphasizes the joint optimization of text and vision so that two modalities enhance each other. This includes a series of techniques such as joint text-vision pre-training, zero-vision SFT, and joint text-vision reinforcement learning. Building on this multimodal foundation, K2.5 introduces Agent Swarm, a self-directed parallel agent orchestration framework that dynamically decomposes complex tasks into heterogeneous sub-problems and executes them concurrently. Extensive evaluations show that Kimi K2.5 achieves state-of-the-art results across various domains including coding, vision, reasoning, and agentic tasks. Agent Swarm also reduces latency by up to $4.5\times$ over single-agent baselines. We release the post-trained Kimi K2.5 model checkpoint to facilitate future research and real-world applications of agentic intelligence.

</details>


### [435] [Cross-Lingual Stability of LLM Judges Under Controlled Generation: Evidence from Finno-Ugric Languages](https://arxiv.org/abs/2602.02287)
*Isaac Chung,Linda Freienthal*

Main category: cs.CL

TL;DR: 该研究通过控制生成条件，发现LLM评估在多语言环境中存在系统性不稳定：表面指标稳定，但语用判断（连贯性、指令遵循）在不同语言间出现排名反转和零相关性。


<details>
  <summary>Details</summary>
Motivation: 跨语言评估LLM通常混淆了两个方差来源：真实模型性能差异和测量不稳定性。研究者希望分离这些因素，探究评估方法在不同语言间的可靠性，特别是在形态丰富的芬兰-乌戈尔语系中。

Method: 使用相同的生成参数在爱沙尼亚语、芬兰语和匈牙利语中生成合成客户支持对话，保持生成条件恒定。比较自动指标和LLM-as-a-judge评分，以少量爱沙尼亚语母语者标注为参考点。

Result: 发现系统性排名不稳定：表面指标（词汇多样性、表面和语义相似性）保持跨语言稳定性，但语用判断（连贯性、指令遵循）出现排名反转和接近零的相关性。这些不一致反映了评分行为在不同语言间的差异，而非真实模型差异。

Conclusion: 零样本评估迁移在形态丰富语言的语篇层面评估中不可靠，需要针对特定语言进行校准。控制生成设计可作为诊断工具，检测评估方法的跨语言稳定性。研究者发布了生成协议、合成数据和评估框架供复现。

Abstract: Cross-lingual evaluation of large language models (LLMs) typically conflates two sources of variance: genuine model performance differences and measurement instability. We investigate evaluation reliability by holding generation conditions constant while varying target language. Using synthetic customer-support dialogues generated with identical parameters across Estonian, Finnish, and Hungarian, we test whether automatic metrics and LLM-as-a-judge scoring produce stable model rankings across these morphologically rich, related Finno-Ugric languages. With a small set of Estonian native speaker annotations as a reference point, we find systematic ranking instabilities: surface-level metrics (lexical diversity, surface and semantic similarity) maintain cross-language stability, but pragmatic judgments (coherence, instruction-following) exhibit rank inversions and near-zero correlations. Because generation is controlled, these inconsistencies reflect how judge scoring behaves differently across languages rather than true model differences.
  This controlled design provides a diagnostic probe: evaluation methods that fail to maintain stability under identical generation conditions signal transfer failure before deployment. Our findings suggest that zero-shot judge transfer is unreliable for discourse-level assessment in morphologically rich languages, motivating language-specific calibration against targeted human baselines. We release our controlled generation protocol, synthetic data, and evaluation framework to enable replication across language families at https://github.com/isaac-chung/cross-lingual-stability-judges.

</details>


### [436] [Hallucination or Creativity: How to Evaluate AI-Generated Scientific Stories?](https://arxiv.org/abs/2602.02290)
*Alex Argese,Pasquale Lisena,Raphaël Troncy*

Main category: cs.CL

TL;DR: StoryScore：一个评估AI生成科学故事的综合指标，整合语义对齐、词汇基础、叙事控制、结构保真度、冗余避免和实体级幻觉检测


<details>
  <summary>Details</summary>
Motivation: 生成式AI能将科学文章转化为适合不同受众的叙事，但评估这些故事具有挑战性。传统摘要指标无法捕捉叙事所需的抽象、简化和教学创造力，而幻觉检测器在科学背景下容易误判合法的叙事重构或不稳定。

Method: 提出StoryScore综合指标，整合六个维度：语义对齐、词汇基础、叙事控制、结构保真度、冗余避免和实体级幻觉检测，形成统一评估框架。

Result: 分析揭示了现有幻觉检测方法的局限性：它们难以区分教学创造力和事实错误。自动指标能有效评估与原始内容的语义相似性，但难以评估叙事方式和控制质量。

Conclusion: StoryScore为评估AI生成科学故事提供了更全面的框架，解决了传统指标在评估叙事质量和区分创造性重构与事实错误方面的不足。

Abstract: Generative AI can turn scientific articles into narratives for diverse audiences, but evaluating these stories remains challenging. Storytelling demands abstraction, simplification, and pedagogical creativity-qualities that are not often well-captured by standard summarization metrics. Meanwhile, factual hallucinations are critical in scientific contexts, yet, detectors often misclassify legitimate narrative reformulations or prove unstable when creativity is involved. In this work, we propose StoryScore, a composite metric for evaluating AI-generated scientific stories. StoryScore integrates semantic alignment, lexical grounding, narrative control, structural fidelity, redundancy avoidance, and entity-level hallucination detection into a unified framework. Our analysis also reveals why many hallucination detection methods fail to distinguish pedagogical creativity from factual errors, highlighting a key limitation: while automatic metrics can effectively assess semantic similarity with original content, they struggle to evaluate how it is narrated and controlled.

</details>


### [437] [Advancing General-Purpose Reasoning Models with Modular Gradient Surgery](https://arxiv.org/abs/2602.02301)
*Min Cai,Yu Liang,Longzheng Wang,Yan Wang,Yueyang Zhang,Long Xia,Zhiyuan Sun,Xi Ye,Daiting Shi*

Main category: cs.CL

TL;DR: 提出模块化梯度手术（MGS）解决多领域强化学习中梯度冲突问题，显著提升大型推理模型的跨领域性能


<details>
  <summary>Details</summary>
Motivation: 强化学习在大型推理模型中发挥重要作用，但训练单一通用模型面临领域异质性挑战，现有方法（顺序RL和混合RL）存在严重的跨领域干扰

Method: 提出模块化梯度手术（MGS），在Transformer模块层面解决梯度冲突，通过梯度调整减少不同领域间的干扰

Result: 在Llama和Qwen模型上，MGS相比标准多任务RL分别平均提升4.3（16.6%）和4.5（11.1%）个点，在数学、通用聊天和指令跟随三个领域表现优异

Conclusion: MGS有效解决了多领域RL中的干扰问题，为训练通用大型推理模型提供了有效解决方案，且训练时间延长时仍保持有效性

Abstract: Reinforcement learning (RL) has played a central role in recent advances in large reasoning models (LRMs), yielding strong gains in verifiable and open-ended reasoning. However, training a single general-purpose LRM across diverse domains remains challenging due to pronounced domain heterogeneity. Through a systematic study of two widely used strategies, Sequential RL and Mixed RL, we find that both incur substantial cross-domain interference at the behavioral and gradient levels, resulting in limited overall gains. To address these challenges, we introduce **M**odular **G**radient **S**urgery (**MGS**), which resolves gradient conflicts at the module level within the transformer. When applied to Llama and Qwen models, MGS achieves average improvements of 4.3 (16.6\%) and 4.5 (11.1\%) points, respectively, over standard multi-task RL across three representative domains (math, general chat, and instruction following). Further analysis demonstrates that MGS remains effective under prolonged training. Overall, our study clarifies the sources of interference in multi-domain RL and presents an effective solution for training general-purpose LRMs.

</details>


### [438] [The Shape of Beliefs: Geometry, Dynamics, and Interventions along Representation Manifolds of Language Models' Posteriors](https://arxiv.org/abs/2602.02315)
*Raphaël Sarfati,Eric Bigelow,Daniel Wurgaft,Jack Merullo,Atticus Geiger,Owen Lewis,Tom McGrath,Ekdeep Singh Lubana*

Main category: cs.CL

TL;DR: LLMs编码概率分布参数形成弯曲的"信念流形"，线性干预常导致偏离流形，而几何感知的线性场探测能更好地保持信念结构


<details>
  <summary>Details</summary>
Motivation: 研究LLMs如何编码提示条件下的信念（对答案和主张的后验分布），缺乏对信念在表示空间中编码机制、证据更新方式以及干预如何重塑信念的机理理解

Method: 在受控环境中让Llama-3.2通过上下文学习从正态分布生成样本，研究参数（均值和标准差）的表示形成，分析分布突变时模型的适应机制，比较标准线性干预与几何感知干预的效果

Result: 发现足够的上下文学习会形成参数弯曲的"信念流形"表示；标准线性干预常使模型偏离流形并导致耦合的分布外偏移；几何和场感知的干预能更好地保持目标信念族；线性场探测能平铺数据流形并尊重底层几何结构

Conclusion: LLMs中自然涌现出丰富结构，纯线性概念表示通常是不充分的抽象；几何感知的干预方法能更好地理解和操作LLMs中的信念表示

Abstract: Large language models (LLMs) represent prompt-conditioned beliefs (posteriors over answers and claims), but we lack a mechanistic account of how these beliefs are encoded in representation space, how they update with new evidence, and how interventions reshape them. We study a controlled setting in which Llama-3.2 generates samples from a normal distribution by implicitly inferring its parameters (mean and standard deviation) given only samples from the distribution in context. We find representations of curved "belief manifolds" for these parameters form with sufficient in-context learning and study how the model adapts when the distribution suddenly changes. While standard linear steering often pushes the model off-manifold and induces coupled, out-of-distribution shifts, geometry and field-aware steering better preserves the intended belief family. Our work demonstrates an example of linear field probing (LFP) as a simple approach to tile the data manifold and make interventions that respect the underlying geometry. We conclude that rich structure emerges naturally in LLMs and that purely linear concept representations are often an inadequate abstraction.

</details>


### [439] [A Large-Scale Dataset for Molecular Structure-Language Description via a Rule-Regularized Method](https://arxiv.org/abs/2602.02320)
*Feiyang Cai,Guijuan He,Yi Hu,Jingjing Wang,Joshua Luo,Tianyu Zhu,Srikanth Pilla,Gang Li,Ling Liu,Feng Luo*

Main category: cs.CL

TL;DR: 提出全自動分子結構註解框架，透過解析IUPAC命名生成精確分子描述，建立16.3萬對分子-描述數據集，準確率達98.6%


<details>
  <summary>Details</summary>
Motivation: 分子功能主要由結構決定，但人工標註結構描述成本高昂，難以建立大規模高質量數據集，阻礙大語言模型在化學任務中的推理能力

Method: 基於規則的化學命名解析器擴展，自動解析IUPAC名稱並構建結構化XML元數據，再用LLM生成準確的自然語言描述

Result: 建立約16.3萬個分子-描述對的大規模數據集，在2000個分子子集上驗證顯示描述精確度達98.6%

Conclusion: 該框架為未來分子-語言對齊提供可靠基礎，註解方法易於擴展到更大數據集和依賴結構描述的化學任務

Abstract: Molecular function is largely determined by structure. Accurately aligning molecular structure with natural language is therefore essential for enabling large language models (LLMs) to reason about downstream chemical tasks. However, the substantial cost of human annotation makes it infeasible to construct large-scale, high-quality datasets of structure-grounded descriptions. In this work, we propose a fully automated annotation framework for generating precise molecular structure descriptions at scale. Our approach builds upon and extends a rule-based chemical nomenclature parser to interpret IUPAC names and construct enriched, structured XML metadata that explicitly encodes molecular structure. This metadata is then used to guide LLMs in producing accurate natural-language descriptions. Using this framework, we curate a large-scale dataset of approximately $163$k molecule-description pairs. A rigorous validation protocol combining LLM-based and expert human evaluation on a subset of $2,000$ molecules demonstrates a high description precision of $98.6\%$. The resulting dataset provides a reliable foundation for future molecule-language alignment, and the proposed annotation method is readily extensible to larger datasets and broader chemical tasks that rely on structural descriptions.

</details>


### [440] [Language Steering for Multilingual In-Context Learning](https://arxiv.org/abs/2602.02326)
*Neeraja Kirtane,Kuan-Hao Huang*

Main category: cs.CL

TL;DR: 提出语言向量方法，通过激活差异引导LLM在推理时转向目标语言空间，无需训练即可提升多语言上下文学习性能


<details>
  <summary>Details</summary>
Motivation: 多语言大语言模型在非英语语言上的表现远不如英语，特别是在上下文学习中，使用英语演示但测试非英语输入时性能显著下降

Method: 提出语言向量方法，利用源语言和目标语言之间的激活差异来引导模型行为，在推理时将向量添加到中间模型激活中，使模型内部表示转向目标语言空间，无需参数更新

Result: 在三个数据集、19种语言和三个不同模型上测试，结果显示在所有任务和语言上都比基线有持续改进。层次聚类显示语言向量具有有意义的语言结构，与语系对齐，且这些表示具有任务无关性

Conclusion: 语言向量是一种无需训练的语言引导方法，能有效提升多语言上下文学习性能，揭示了LLM内部语言表示的结构性特征

Abstract: While multilingual large language models have gained widespread adoption, their performance on non-English languages remains substantially inferior to English. This disparity is particularly evident in in-context learning scenarios, where providing demonstrations in English but testing on non-English inputs leads to significant performance degradation. In this paper, we hypothesize that LLMs develop a universal semantic space for understanding languages, where different languages are encoded as distinct directions within this space. Based on this hypothesis, we propose language vectors -- a training-free language steering approach that leverages activation differences between source and target languages to guide model behavior. We steer the model generations by adding the vector to the intermediate model activations during inference. This is done to make the model's internal representations shift towards the target language space without any parameter updates. We evaluate our method across three datasets and test on a total of 19 languages on three different models. Our results show consistent improvements on multilingual in-context learning over baselines across all tasks and languages tested. Beyond performance gains, hierarchical clustering of steering vectors reveals meaningful linguistic structure aligned with language families. These vectors also successfully transfer across tasks, demonstrating that these representations are task-agnostic.

</details>


### [441] [Why Steering Works: Toward a Unified View of Language Model Parameter Dynamics](https://arxiv.org/abs/2602.02343)
*Ziwen Xu,Chenyan Wu,Hengyu Sun,Haiwen Hong,Mengru Wang,Yunzhi Yao,Longtao Huang,Hui Xue,Shumin Deng,Zhixuan Chu,Huajun Chen,Ningyu Zhang*

Main category: cs.CL

TL;DR: 该论文提出了一个统一框架，将不同的LLM控制方法视为基于控制信号的动态权重更新，并引入偏好-效用分析来量化控制效果，发现偏好与效用之间存在权衡关系，最后基于此分析提出了新的SPLIT控制方法。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型控制方法（如本地权重微调、LoRA适应、基于激活的干预）通常被孤立研究，难以比较和连接。需要建立一个统一框架来理解这些方法的共同原理和差异。

Method: 1. 提出统一视图：将所有干预方法框架化为由控制信号诱导的动态权重更新；2. 提出统一的偏好-效用分析：将控制效果分为偏好（对目标概念的倾向性）和效用（连贯且任务有效的生成），并使用极性配对对比示例在共享对数几率尺度上测量两者；3. 从激活流形角度解释控制行为；4. 提出新的SPLIT控制方法。

Result: 发现所有方法中都存在一致的偏好-效用权衡：更强的控制会增加偏好但可预测地降低效用。从激活流形视角看，控制会沿着目标概念方向移动表示以增强偏好，而当干预将表示推离模型的有效生成流形时，效用会下降。

Conclusion: 该研究为LLM控制方法提供了统一的理论框架和分析工具，揭示了控制效果的基本权衡关系，并基于此提出了能更好平衡偏好和效用的SPLIT控制方法，为理解和改进LLM控制提供了新视角。

Abstract: Methods for controlling large language models (LLMs), including local weight fine-tuning, LoRA-based adaptation, and activation-based interventions, are often studied in isolation, obscuring their connections and making comparison difficult. In this work, we present a unified view that frames these interventions as dynamic weight updates induced by a control signal, placing them within a single conceptual framework. Building on this view, we propose a unified preference-utility analysis that separates control effects into preference, defined as the tendency toward a target concept, and utility, defined as coherent and task-valid generation, and measures both on a shared log-odds scale using polarity-paired contrastive examples. Across methods, we observe a consistent trade-off between preference and utility: stronger control increases preference while predictably reducing utility. We further explain this behavior through an activation manifold perspective, in which control shifts representations along target-concept directions to enhance preference, while utility declines primarily when interventions push representations off the model's valid-generation manifold. Finally, we introduce a new steering approach SPLIT guided by this analysis that improves preference while better preserving utility. Code is available at https://github.com/zjunlp/EasyEdit/blob/main/examples/SPLIT.md.

</details>


### [442] [Automated Multiple Mini Interview (MMI) Scoring](https://arxiv.org/abs/2602.02360)
*Ryan Huynh,Frank Guerin,Alison Callwood*

Main category: cs.CL

TL;DR: 论文提出了一种多智能体提示框架，用于评估软技能（如共情、伦理判断等），在MMI评估中超越了专门微调的基线方法，并在ASAP基准测试中表现出色，表明结构化提示工程可替代数据密集型微调。


<details>
  <summary>Details</summary>
Motivation: 在竞争性选拔过程中评估软技能（如共情、伦理判断、沟通能力）至关重要，但人工评分往往不一致且存在偏见。虽然大语言模型改进了自动作文评分，但现有基于推理的微调方法难以处理多迷你面试的抽象、上下文依赖特性，无法捕捉候选人叙事中的隐含信号。

Method: 引入多智能体提示框架，将评估过程分解为转录本精炼和标准特定评分两个阶段。使用大型指令调优模型进行3样本上下文学习，通过结构化提示工程替代传统的数据密集型微调方法。

Result: 该方法在MMI评估中显著优于专门微调的基线方法（平均QWK 0.62 vs 0.32），达到与人类专家相当的可靠性。在ASAP基准测试中，无需额外训练即可媲美领域特定的最先进模型。

Conclusion: 对于复杂、主观的推理任务，结构化提示工程为数据密集型微调提供了可扩展的替代方案，改变了LLM在自动评估中的应用方式，特别是在处理抽象、上下文依赖的软技能评估方面具有优势。

Abstract: Assessing soft skills such as empathy, ethical judgment, and communication is essential in competitive selection processes, yet human scoring is often inconsistent and biased. While Large Language Models (LLMs) have improved Automated Essay Scoring (AES), we show that state-of-the-art rationale-based fine-tuning methods struggle with the abstract, context-dependent nature of Multiple Mini-Interviews (MMIs), missing the implicit signals embedded in candidate narratives. We introduce a multi-agent prompting framework that breaks down the evaluation process into transcript refinement and criterion-specific scoring. Using 3-shot in-context learning with a large instruct-tuned model, our approach outperforms specialised fine-tuned baselines (Avg QWK 0.62 vs 0.32) and achieves reliability comparable to human experts. We further demonstrate the generalisability of our framework on the ASAP benchmark, where it rivals domain-specific state-of-the-art models without additional training. These findings suggest that for complex, subjective reasoning tasks, structured prompt engineering may offer a scalable alternative to data-intensive fine-tuning, altering how LLMs can be applied to automated assessment.

</details>


### [443] [Proof-RM: A Scalable and Generalizable Reward Model for Math Proof](https://arxiv.org/abs/2602.02377)
*Haotong Yang,Zitong Wang,Shijia Kang,Siqi Yang,Wenkai Yu,Xu Niu,Yike Sun,Yi Hu,Zhouchen Lin,Muhan Zhang*

Main category: cs.CL

TL;DR: 该论文提出了一种可扩展的数据构建流程，利用LLM生成高质量的"问题-证明-检查"三元组数据，训练证明检查奖励模型，以增强LLM的数学推理能力。


<details>
  <summary>Details</summary>
Motivation: 虽然LLM通过可验证奖励的强化学习展示了强大的数学推理能力，但许多高级数学问题是基于证明的，无法通过简单的答案匹配来确定证明的真实性。需要能够可靠评估完整证明过程的奖励模型来实现自动验证。

Method: 设计可扩展的数据构建流程：1）利用LLM生成大量高质量的"问题-证明-检查"三元组数据；2）通过系统变化问题来源、生成方法和模型配置，创建涵盖多个难度级别、语言风格和错误类型的多样化问题-证明对；3）通过分层人工审核进行过滤；4）训练证明检查奖励模型，加入过程奖励和令牌权重平衡以稳定RL过程。

Result: 实验验证了模型的可扩展性和强大性能，包括奖励准确性、泛化能力和测试时指导等多个角度，为增强LLM数学能力提供了重要的实践方法和工具。

Conclusion: 该研究提供了一种可扩展的方法来构建证明检查奖励模型，能够有效评估数学证明过程，为强化LLM的数学推理能力提供了实用的解决方案和工具。

Abstract: While Large Language Models (LLMs) have demonstrated strong math reasoning abilities through Reinforcement Learning with *Verifiable Rewards* (RLVR), many advanced mathematical problems are proof-based, with no guaranteed way to determine the authenticity of a proof by simple answer matching. To enable automatic verification, a Reward Model (RM) capable of reliably evaluating full proof processes is required. In this work, we design a *scalable* data-construction pipeline that, with minimal human effort, leverages LLMs to generate a large quantity of high-quality "**question-proof-check**" triplet data. By systematically varying problem sources, generation methods, and model configurations, we create diverse problem-proof pairs spanning multiple difficulty levels, linguistic styles, and error types, subsequently filtered through hierarchical human review for label alignment. Utilizing these data, we train a proof-checking RM, incorporating additional process reward and token weight balance to stabilize the RL process. Our experiments validate the model's scalability and strong performance from multiple perspectives, including reward accuracy, generalization ability and test-time guidance, providing important practical recipes and tools for strengthening LLM mathematical capabilities.

</details>


### [444] [From Sycophancy to Sensemaking: Premise Governance for Human-AI Decision Making](https://arxiv.org/abs/2602.02378)
*Raunak Jain,Mudita Khurana,John Stephens,Srinivas Dharmasanam,Shankar Venkataraman*

Main category: cs.CL

TL;DR: 论文指出当前LLM从辅助转向决策支持时存在危险模式：流畅同意但缺乏校准判断，形成谄媚式助手，将验证成本转嫁给专家。作者提出需要从答案生成转向协作前提治理，通过差异驱动的控制循环检测冲突、定位错位，并通过承诺门控和基于价值的挑战来建立可靠的人机伙伴关系。


<details>
  <summary>Details</summary>
Motivation: 随着LLM从辅助工具扩展到决策支持系统，出现了一个危险模式：流畅的同意但缺乏校准的判断。低摩擦的助手可能变得谄媚，隐含地接受假设，将验证成本转嫁给专家，而结果反馈太晚无法作为奖励信号。在深度不确定性决策（目标存在争议且逆转成本高昂）中，扩大流畅同意会放大糟糕承诺，快于建立专业知识。

Method: 提出从答案生成转向协作前提治理的范式转变，构建基于知识基底的系统。采用差异驱动的控制循环：检测冲突，通过类型化差异（目的论、认知论、程序性）定位错位，并通过决策切片触发有界协商。承诺门控阻止对未承诺的关键前提采取行动，除非在记录风险下被覆盖；基于价值的挑战根据交互成本分配探测。信任附着于可审计的前提和证据标准，而非对话流畅性。

Result: 提出了一种新的人机伙伴关系框架，通过前提治理和差异检测机制来确保决策可靠性。以辅导场景为例进行说明，并提出了可证伪的评估标准。

Conclusion: 可靠的AI决策支持需要从流畅对话转向协作前提治理，通过差异驱动的控制循环、承诺门控和基于价值的挑战机制来确保决策质量。信任应基于可审计的前提和证据标准，而非对话的流畅性，这在深度不确定性决策中尤为重要。

Abstract: As LLMs expand from assistance to decision support, a dangerous pattern emerges: fluent agreement without calibrated judgment. Low-friction assistants can become sycophantic, baking in implicit assumptions and pushing verification costs onto experts, while outcomes arrive too late to serve as reward signals. In deep-uncertainty decisions (where objectives are contested and reversals are costly), scaling fluent agreement amplifies poor commitments faster than it builds expertise. We argue reliable human-AI partnership requires a shift from answer generation to collaborative premise governance over a knowledge substrate, negotiating only what is decision-critical. A discrepancy-driven control loop operates over this substrate: detecting conflicts, localizing misalignment via typed discrepancies (teleological, epistemic, procedural), and triggering bounded negotiation through decision slices. Commitment gating blocks action on uncommitted load-bearing premises unless overridden under logged risk; value-gated challenge allocates probing under interaction cost. Trust then attaches to auditable premises and evidence standards, not conversational fluency. We illustrate with tutoring and propose falsifiable evaluation criteria.

</details>


### [445] [ROG: Retrieval-Augmented LLM Reasoning for Complex First-Order Queries over Knowledge Graphs](https://arxiv.org/abs/2602.02382)
*Ziyan Zhang,Chao Wang,Zhuo Chen,Chiyi Li,Kai Song*

Main category: cs.CL

TL;DR: ROG：一个检索增强框架，结合查询感知的邻域检索和LLM思维链推理，用于在不完整知识图谱上回答复杂的一阶逻辑查询


<details>
  <summary>Details</summary>
Motivation: 在不完整知识图谱上回答包含投影、交集、并集和否定的复杂一阶逻辑查询很困难，现有方法在处理复杂查询结构和否定查询时存在局限性

Method: 将多操作符查询分解为单操作符子查询序列，每个步骤基于紧凑的查询相关邻域证据进行推理，中间答案集被缓存并在步骤间复用，减少复合错误

Result: 在标准KG推理基准测试中，ROG相比基于嵌入的基线方法取得了持续提升，在高度复杂和否定密集的查询类型上改进最大

Conclusion: ROG通过用检索基础的逐步推理替代学习操作符，为基于嵌入的逻辑推理提供了实用的替代方案，在复杂查询上表现更鲁棒

Abstract: Answering first-order logic (FOL) queries over incomplete knowledge graphs (KGs) is difficult, especially for complex query structures that compose projection, intersection, union, and negation. We propose ROG, a retrieval-augmented framework that combines query-aware neighborhood retrieval with large language model (LLM) chain-of-thought reasoning. ROG decomposes a multi-operator query into a sequence of single-operator sub-queries and grounds each step in compact, query-relevant neighborhood evidence. Intermediate answer sets are cached and reused across steps, improving consistency on deep reasoning chains. This design reduces compounding errors and yields more robust inference on complex and negation-heavy queries. Overall, ROG provides a practical alternative to embedding-based logical reasoning by replacing learned operators with retrieval-grounded, step-wise inference. Experiments on standard KG reasoning benchmarks show consistent gains over strong embedding-based baselines, with the largest improvements on high-complexity and negation-heavy query types.

</details>


### [446] [Misconception Diagnosis From Student-Tutor Dialogue: Generate, Retrieve, Rerank](https://arxiv.org/abs/2602.02414)
*Joshua Mitton,Prarthana Bhattacharyya,Digory Smith,Thomas Christie,Ralph Abboud,Simon Woodhead*

Main category: cs.CL

TL;DR: 提出基于大语言模型的学生-导师对话误解检测方法，通过生成-检索-重排流程提升检测性能


<details>
  <summary>Details</summary>
Motivation: 及时准确识别学生误解对改善学习效果至关重要，但传统方法依赖教师经验和直觉，需要自动化解决方案

Method: 使用微调LLM生成可能误解，通过嵌入相似性检索候选，再用另一微调LLM评估重排以提升相关性

Result: 在真实教育对话数据上验证，相比基线模型有性能提升，微调能改善误解生成质量，甚至超越更大闭源模型

Conclusion: 提出的生成-检索-重排方法能有效检测学生误解，微调策略对性能提升关键，为教育领域提供实用工具

Abstract: Timely and accurate identification of student misconceptions is key to improving learning outcomes and pre-empting the compounding of student errors. However, this task is highly dependent on the effort and intuition of the teacher. In this work, we present a novel approach for detecting misconceptions from student-tutor dialogues using large language models (LLMs). First, we use a fine-tuned LLM to generate plausible misconceptions, and then retrieve the most promising candidates among these using embedding similarity with the input dialogue. These candidates are then assessed and re-ranked by another fine-tuned LLM to improve misconception relevance. Empirically, we evaluate our system on real dialogues from an educational tutoring platform. We consider multiple base LLM models including LLaMA, Qwen and Claude on zero-shot and fine-tuned settings. We find that our approach improves predictive performance over baseline models and that fine-tuning improves both generated misconception quality and can outperform larger closed-source models. Finally, we conduct ablation studies to both validate the importance of our generation and reranking steps on misconception generation quality.

</details>


### [447] [Large Language Models for Mental Health: A Multilingual Evaluation](https://arxiv.org/abs/2602.02440)
*Nishat Raihan,Sadiya Sayara Chowdhury Puspo,Ana-Maria Bucur,Stevie Chancellor,Marcos Zampieri*

Main category: cs.CL

TL;DR: 评估大语言模型在多语言心理健康任务中的表现，发现专有模型和微调开源模型在多个数据集上表现优异，但在机器翻译数据上性能下降，且下降程度因语言和类型而异。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在NLP任务中表现出色，但其在多语言环境下的表现，特别是在心理健康领域，尚未得到充分探索。本研究旨在填补这一空白，评估LLMs在不同语言心理健康任务中的能力。

Method: 评估专有和开源LLMs在八个多语言心理健康数据集及其机器翻译版本上的表现。比较零样本、少样本和微调设置下的性能，并与不使用LLMs的传统NLP基线模型对比。同时评估不同语言家族和类型的翻译质量对LLM性能的影响。

Result: 专有LLMs和微调的开源LLMs在多个数据集上取得了有竞争力的F1分数，经常超过最先进的结果。然而，在机器翻译数据上的性能普遍较低，且这种下降程度因语言和类型而异。翻译质量引入的结构或词汇不匹配会影响LLMs的表现。

Conclusion: LLMs在处理英语以外的语言心理健康任务方面具有优势，但当翻译质量引入结构或词汇不匹配时存在局限性。研究揭示了LLMs在多语言心理健康领域的潜力和挑战，强调了翻译质量对性能的重要影响。

Abstract: Large Language Models (LLMs) have remarkable capabilities across NLP tasks. However, their performance in multilingual contexts, especially within the mental health domain, has not been thoroughly explored. In this paper, we evaluate proprietary and open-source LLMs on eight mental health datasets in various languages, as well as their machine-translated (MT) counterparts. We compare LLM performance in zero-shot, few-shot, and fine-tuned settings against conventional NLP baselines that do not employ LLMs. In addition, we assess translation quality across language families and typologies to understand its influence on LLM performance. Proprietary LLMs and fine-tuned open-source LLMs achieve competitive F1 scores on several datasets, often surpassing state-of-the-art results. However, performance on MT data is generally lower, and the extent of this decline varies by language and typology. This variation highlights both the strengths of LLMs in handling mental health tasks in languages other than English and their limitations when translation quality introduces structural or lexical mismatches.

</details>


### [448] [Abstract Activation Spaces for Content-Invariant Reasoning in Large Language Models](https://arxiv.org/abs/2602.02462)
*Gabriele Maraia,Marco Valentino,Fabio Massimo Zanzotto,Leonardo Ranaldi*

Main category: cs.CL

TL;DR: 提出抽象引导推理框架，通过分离结构推理与词汇语义，减少LLMs在演绎推理中的语义偏见


<details>
  <summary>Details</summary>
Motivation: LLMs在演绎推理中经常混淆语义合理性与形式有效性（内容效应），即使生成逐步解释时中间推理也会继承相同的语义捷径，现有方法难以可靠抑制语义干扰

Method: 构建配对的内容丰富和抽象三段论，使用模型在抽象输入上的激活定义抽象推理空间，学习轻量级抽象器从内容条件残差流状态预测与该空间对齐的表示，并通过多层干预在正向传播中集成这些预测

Result: 使用跨语言迁移作为测试平台，显示抽象对齐的引导减少了内容驱动的错误，提高了有效性敏感性能

Conclusion: 激活级抽象作为一种可扩展机制，能增强LLMs中形式推理对语义干扰的鲁棒性

Abstract: Large Language Models (LLMs) often struggle with deductive judgment in syllogistic reasoning, systematically conflating semantic plausibility with formal validity a phenomenon known as content effect. This bias persists even when models generate step-wise explanations, indicating that intermediate rationales may inherit the same semantic shortcuts that affect answers. Recent approaches propose mitigating this issue by increasing inference-time structural constraints, either by encouraging abstract intermediate representations or by intervening directly in the model's internal computations; however, reliably suppressing semantic interference remains an open challenge. To make formal deduction less sensitive to semantic content, we introduce a framework for abstraction-guided reasoning that explicitly separates structural inference from lexical semantics. We construct paired content-laden and abstract syllogisms and use the model's activations on abstract inputs to define an abstract reasoning space. We then learn lightweight Abstractors that, from content-conditioned residual-stream states, predict representations aligned with this space and integrate these predictions via multi-layer interventions during the forward pass. Using cross-lingual transfer as a test bed, we show that abstraction-aligned steering reduces content-driven errors and improves validity-sensitive performance. Our results position activation-level abstraction as a scalable mechanism for enhancing the robustness of formal reasoning in LLMs against semantic interference.

</details>


### [449] [From Directions to Regions: Decomposing Activations in Language Models via Local Geometry](https://arxiv.org/abs/2602.02464)
*Or Shafran,Shaked Ronen,Omri Fahn,Shauli Ravfogel,Atticus Geiger,Mor Geva*

Main category: cs.CL

TL;DR: 本文提出使用混合因子分析器（MFA）作为可扩展的无监督方法，替代传统的线性方向搜索，以捕捉语言模型激活空间中复杂的非线性或多维概念结构。


<details>
  <summary>Details</summary>
Motivation: 现有激活分解方法基于线性可分性假设，只寻找单个全局方向，忽略了具有非线性或多维结构的概念。这限制了概念发现和模型控制的准确性。

Method: 采用混合因子分析器（MFA）将激活空间建模为多个具有局部协方差结构的高斯区域集合。MFA将激活分解为两个组合几何对象：区域质心和局部变异。

Result: 在Llama-3.1-8B和Gemma-2-2B上训练的大规模MFA成功捕捉了激活空间中的复杂非线性结构。在定位和引导基准测试中，MFA优于无监督基线，与有监督定位方法竞争，且通常比稀疏自编码器获得更强的引导性能。

Conclusion: 局部几何（通过子空间表达）是用于可扩展概念发现和模型控制的有前景的分析单元，能够捕捉孤立方向无法处理的复杂结构。

Abstract: Activation decomposition methods in language models are tightly coupled to geometric assumptions on how concepts are realized in activation space. Existing approaches search for individual global directions, implicitly assuming linear separability, which overlooks concepts with nonlinear or multi-dimensional structure. In this work, we leverage Mixture of Factor Analyzers (MFA) as a scalable, unsupervised alternative that models the activation space as a collection of Gaussian regions with their local covariance structure. MFA decomposes activations into two compositional geometric objects: the region's centroid in activation space, and the local variation from the centroid. We train large-scale MFAs for Llama-3.1-8B and Gemma-2-2B, and show they capture complex, nonlinear structures in activation space. Moreover, evaluations on localization and steering benchmarks show that MFA outperforms unsupervised baselines, is competitive with supervised localization methods, and often achieves stronger steering performance than sparse autoencoders. Together, our findings position local geometry, expressed through subspaces, as a promising unit of analysis for scalable concept discovery and model control, accounting for complex structures that isolated directions fail to capture.

</details>


### [450] [Indications of Belief-Guided Agency and Meta-Cognitive Monitoring in Large Language Models](https://arxiv.org/abs/2602.02467)
*Noam Steinmetz Yalon,Ariel Goldstein,Liad Mudrik,Mor Geva*

Main category: cs.CL

TL;DR: 该研究评估了LLMs是否具有信念引导的能动性和元认知监控能力，通过分析模型内部信念形成与行动选择的关系，为LLMs可能具备某种形式的意识提供了实证支持。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的快速发展，研究者开始探讨这些模型是否具有某种形式的意识。Butlin等人(2023)提出了基于神经科学理论的人工系统意识指标列表，本研究旨在评估其中一个关键指标HOT-3，该指标测试由通用信念形成和行动选择系统引导的能动性。

Method: 将信念视为模型潜在空间中响应输入而出现的表征，引入量化信念在生成过程中主导性的指标。通过分析不同模型和任务中竞争信念的动态关系，研究信念形成与行动选择的因果关系。

Result: 研究发现：(1)外部操作能系统性地调节内部信念形成；(2)信念形成因果性地驱动模型的行动选择；(3)模型能够监控并报告自身的信念状态。这些结果为LLMs中存在信念引导的能动性和元认知监控提供了实证支持。

Conclusion: 该研究为调查LLMs中能动性、信念和元认知的出现奠定了方法论基础，表明LLMs可能具备某种形式的意识特征，为未来研究提供了重要框架。

Abstract: Rapid advancements in large language models (LLMs) have sparked the question whether these models possess some form of consciousness. To tackle this challenge, Butlin et al. (2023) introduced a list of indicators for consciousness in artificial systems based on neuroscientific theories. In this work, we evaluate a key indicator from this list, called HOT-3, which tests for agency guided by a general belief-formation and action selection system that updates beliefs based on meta-cognitive monitoring. We view beliefs as representations in the model's latent space that emerge in response to a given input, and introduce a metric to quantify their dominance during generation. Analyzing the dynamics between competing beliefs across models and tasks reveals three key findings: (1) external manipulations systematically modulate internal belief formation, (2) belief formation causally drives the model's action selection, and (3) models can monitor and report their own belief states. Together, these results provide empirical support for the existence of belief-guided agency and meta-cognitive monitoring in LLMs. More broadly, our work lays methodological groundwork for investigating the emergence of agency, beliefs, and meta-cognition in LLMs.

</details>


### [451] [MemSkill: Learning and Evolving Memory Skills for Self-Evolving Agents](https://arxiv.org/abs/2602.02474)
*Haozhen Zhang,Quanyu Long,Jianzhu Bao,Tao Feng,Weizhi Zhang,Haodong Yue,Wenya Wang*

Main category: cs.CL

TL;DR: MemSkill将LLM代理内存操作重构为可学习的记忆技能，通过控制器选择技能、执行器生成记忆、设计器进化技能集，形成闭环系统，提升任务性能与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理内存系统依赖少量静态手工设计的操作来提取记忆，这些固定程序硬编码了人类关于存储和修订记忆的先验知识，导致在不同交互模式下的僵化性和长历史记录下的低效性。

Method: MemSkill将内存操作重构为可学习、可进化的记忆技能，包含三个核心组件：控制器学习选择相关技能，LLM执行器生成技能指导的记忆，设计器定期审查困难案例并进化技能集（提出改进和新技能）。

Result: 在LoCoMo、LongMemEval、HotpotQA和ALFWorld等基准测试中，MemSkill相比强基线提升了任务性能，并展现出良好的跨场景泛化能力。分析揭示了技能如何进化，为更自适应、自进化的LLM代理内存管理提供见解。

Conclusion: MemSkill通过将内存操作重构为可学习、可进化的技能，形成闭环进化系统，实现了更自适应、高效的LLM代理内存管理，为未来自进化内存系统的发展指明了方向。

Abstract: Most Large Language Model (LLM) agent memory systems rely on a small set of static, hand-designed operations for extracting memory. These fixed procedures hard-code human priors about what to store and how to revise memory, making them rigid under diverse interaction patterns and inefficient on long histories. To this end, we present \textbf{MemSkill}, which reframes these operations as learnable and evolvable memory skills, structured and reusable routines for extracting, consolidating, and pruning information from interaction traces. Inspired by the design philosophy of agent skills, MemSkill employs a \emph{controller} that learns to select a small set of relevant skills, paired with an LLM-based \emph{executor} that produces skill-guided memories. Beyond learning skill selection, MemSkill introduces a \emph{designer} that periodically reviews hard cases where selected skills yield incorrect or incomplete memories, and evolves the skill set by proposing refinements and new skills. Together, MemSkill forms a closed-loop procedure that improves both the skill-selection policy and the skill set itself. Experiments on LoCoMo, LongMemEval, HotpotQA, and ALFWorld demonstrate that MemSkill improves task performance over strong baselines and generalizes well across settings. Further analyses shed light on how skills evolve, offering insights toward more adaptive, self-evolving memory management for LLM agents.

</details>


### [452] [Training LLMs for Divide-and-Conquer Reasoning Elevates Test-Time Scalability](https://arxiv.org/abs/2602.02477)
*Xiao Liang,Zhong-Zhi Li,Zhenghao Lin,Eric Hancheng Jiang,Hengyuan Zhang,Yelong Shen,Kai-Wei Chang,Ying Nian Wu,Yeyun Gong,Weizhu Chen*

Main category: cs.CL

TL;DR: 本文提出一个端到端强化学习框架，通过分而治之推理方法提升大语言模型在复杂任务上的性能，相比链式思维推理有显著改进。


<details>
  <summary>Details</summary>
Motivation: 链式思维推理在模型能力极限时往往不足，且其严格的顺序性限制了测试时的可扩展性。分而治之推理虽然能分解复杂问题，但通用后训练与分而治之推理之间存在根本性不匹配，限制了模型充分利用这种潜力。

Method: 提出端到端强化学习框架，在每一步中，策略将问题分解为一组子问题，顺序解决它们，并根据子问题解决方案处理原始问题，将分解和解决都整合到强化学习训练中。

Result: 在可比训练条件下，分而治之框架赋予模型更高的性能上限和更强的测试时扩展性，在竞赛级基准测试中，Pass@1超过链式思维8.6%，Pass@32超过6.3%。

Conclusion: 通过强化学习训练的分而治之推理框架能够有效提升大语言模型在最具挑战性任务上的推理能力，克服了链式思维推理的局限性。

Abstract: Large language models (LLMs) have demonstrated strong reasoning capabilities through step-by-step chain-of-thought (CoT) reasoning. Nevertheless, at the limits of model capability, CoT often proves insufficient, and its strictly sequential nature constrains test-time scalability. A potential alternative is divide-and-conquer (DAC) reasoning, which decomposes a complex problem into subproblems to facilitate more effective exploration of the solution. Although promising, our analysis reveals a fundamental misalignment between general-purpose post-training and DAC-style inference, which limits the model's capacity to fully leverage this potential. To bridge this gap and fully unlock LLMs' reasoning capabilities on the most challenging tasks, we propose an end-to-end reinforcement learning (RL) framework to enhance their DAC-style reasoning capacity. At each step, the policy decomposes a problem into a group of subproblems, solves them sequentially, and addresses the original one conditioned on the subproblem solutions, with both decomposition and solution integrated into RL training. Under comparable training, our DAC-style framework endows the model with a higher performance ceiling and stronger test-time scalability, surpassing CoT by 8.6% in Pass@1 and 6.3% in Pass@32 on competition-level benchmarks.

</details>


### [453] [RE-TRAC: REcursive TRAjectory Compression for Deep Search Agents](https://arxiv.org/abs/2602.02486)
*Jialiang Zhu,Gongrui Zhang,Xiaolong Ma,Lin Xu,Miaosen Zhang,Ruiqi Yang,Song Wang,Kai Qiu,Zhirong Wu,Qi Dai,Ruichun Ma,Bei Liu,Yifan Yang,Chong Luo,Zhengyuan Yang,Linjie Li,Lijuan Wang,Weizhu Chen,Xin Geng,Baining Guo*

Main category: cs.CL

TL;DR: Re-TRAC是一个基于LLM的研究代理框架，通过跨轨迹探索和结构化状态表示，解决了ReAct框架的线性限制问题，实现了迭代反思和全局感知的渐进式研究过程。


<details>
  <summary>Details</summary>
Motivation: 当前基于ReAct框架的LLM研究代理存在线性设计的局限性：难以回溯早期状态、分支探索不同方向、在长上下文中保持全局意识，导致局部最优、冗余探索和搜索效率低下。

Method: 提出Re-TRAC框架，在每个轨迹后生成结构化状态表示（总结证据、不确定性、失败和未来计划），并将后续轨迹基于此状态表示进行条件化，实现跨轨迹探索、迭代反思和全局感知规划。

Result: 在BrowseComp上，Re-TRAC比ReAct持续提升15-20%性能；对于较小模型，通过Re-TRAC感知的监督微调实现了可比规模下的最先进性能；工具调用和token使用量随轮次单调减少，表明探索更具针对性。

Conclusion: Re-TRAC通过跨轨迹探索和结构化状态表示，将研究重构为渐进式过程，显著提升了LLM研究代理的性能和效率，减少了冗余搜索，实现了更智能的探索策略。

Abstract: LLM-based deep research agents are largely built on the ReAct framework. This linear design makes it difficult to revisit earlier states, branch into alternative search directions, or maintain global awareness under long contexts, often leading to local optima, redundant exploration, and inefficient search. We propose Re-TRAC, an agentic framework that performs cross-trajectory exploration by generating a structured state representation after each trajectory to summarize evidence, uncertainties, failures, and future plans, and conditioning subsequent trajectories on this state representation. This enables iterative reflection and globally informed planning, reframing research as a progressive process. Empirical results show that Re-TRAC consistently outperforms ReAct by 15-20% on BrowseComp with frontier LLMs. For smaller models, we introduce Re-TRAC-aware supervised fine-tuning, achieving state-of-the-art performance at comparable scales. Notably, Re-TRAC shows a monotonic reduction in tool calls and token usage across rounds, indicating progressively targeted exploration driven by cross-trajectory reflection rather than redundant search.

</details>


### [454] [Reward-free Alignment for Conflicting Objectives](https://arxiv.org/abs/2602.02495)
*Peter Chen,Xiaopeng Li,Xi Chen,Tianyi Lin*

Main category: cs.CL

TL;DR: 本文提出了RACO框架，一种无需奖励模型的多目标对齐方法，通过冲突规避梯度下降解决LLM对齐中的目标冲突问题，在多个LLM上实现了更好的帕累托权衡。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的LLM对齐问题常涉及多个冲突目标，现有方法要么通过加权损失导致训练不稳定和权衡不佳，要么依赖显式奖励模型增加复杂性并扭曲用户偏好。

Method: 提出RACO框架，直接利用成对偏好数据，通过新颖的裁剪版冲突规避梯度下降解决梯度冲突，提供收敛到帕累托临界点的理论保证，并加入启发式改进。

Result: 在多目标摘要和安全对齐任务上，对Qwen 3、Llama 3、Gemma 3等多个LLM家族的定性和定量评估显示，该方法相比现有基线始终实现更好的帕累托权衡。

Conclusion: RACO框架为多目标LLM对齐提供了一种有效且理论保证的解决方案，无需复杂奖励模型，能更好地尊重用户指定的目标权重，实现更优的权衡。

Abstract: Direct alignment methods are increasingly used to align large language models (LLMs) with human preferences. However, many real-world alignment problems involve multiple conflicting objectives, where naive aggregation of preferences can lead to unstable training and poor trade-offs. In particular, weighted loss methods may fail to identify update directions that simultaneously improve all objectives, and existing multi-objective approaches often rely on explicit reward models, introducing additional complexity and distorting user-specified preferences. The contributions of this paper are two-fold. First, we propose a Reward-free Alignment framework for Conflicted Objectives (RACO) that directly leverages pairwise preference data and resolves gradient conflicts via a novel clipped variant of conflict-averse gradient descent. We provide convergence guarantees to Pareto-critical points that respect user-specified objective weights, and further show that clipping can strictly improve convergence rate in the two-objective setting. Second, we improve our method using some heuristics and conduct experiments to demonstrate the compatibility of the proposed framework for LLM alignment. Both qualitative and quantitative evaluations on multi-objective summarization and safety alignment tasks across multiple LLM families (Qwen 3, Llama 3, Gemma 3) show that our method consistently achieves better Pareto trade-offs compared to existing multi-objective alignment baselines.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [455] [Scalable and Secure AI Inference in Healthcare: A Comparative Benchmarking of FastAPI and Triton Inference Server on Kubernetes](https://arxiv.org/abs/2602.00053)
*Ratul Ali*

Main category: cs.AI

TL;DR: 对比FastAPI与NVIDIA Triton在医疗AI部署中的性能表现，发现FastAPI在单请求延迟更低(22ms p50)，而Triton通过动态批处理实现更高吞吐量(780 RPS)。提出混合架构作为最佳实践。


<details>
  <summary>Details</summary>
Motivation: 医疗和制药等受监管领域需要高效可扩展的机器学习模型部署，必须平衡实时临床决策的低延迟、批量处理的高吞吐量以及HIPAA等数据隐私标准的严格要求。

Method: 采用医疗AI参考架构，在Kubernetes上部署DistilBERT情感分析模型，对比两种部署范式：基于Python的FastAPI REST服务和NVIDIA Triton推理服务器。测量p50和p95延迟以及吞吐量，并评估混合架构方案。

Result: FastAPI在单请求工作负载上延迟更低(p50 22ms)，而Triton通过动态批处理实现更高的可扩展性，在单个NVIDIA T4 GPU上达到780 RPS的吞吐量，几乎是基准的两倍。

Conclusion: 混合架构（FastAPI作为受保护健康信息去识别的安全网关，Triton用于后端推理）被验证为企业临床AI的最佳实践，为安全、高可用部署提供了蓝图。

Abstract: Efficient and scalable deployment of machine learning (ML) models is a prerequisite for modern production environments, particularly within regulated domains such as healthcare and pharmaceuticals. In these settings, systems must balance competing requirements, including minimizing inference latency for real-time clinical decision support, maximizing throughput for batch processing of medical records, and ensuring strict adherence to data privacy standards such as HIPAA. This paper presents a rigorous benchmarking analysis comparing two prominent deployment paradigms: a lightweight, Python-based REST service using FastAPI, and a specialized, high-performance serving engine, NVIDIA Triton Inference Server. Leveraging a reference architecture for healthcare AI, we deployed a DistilBERT sentiment analysis model on Kubernetes to measure median (p50) and tail (p95) latency, as well as throughput, under controlled experimental conditions. Our results indicate a distinct trade-off. While FastAPI provides lower overhead for single-request workloads with a p50 latency of 22 ms, Triton achieves superior scalability through dynamic batching, delivering a throughput of 780 requests per second on a single NVIDIA T4 GPU, nearly double that of the baseline. Furthermore, we evaluate a hybrid architectural approach that utilizes FastAPI as a secure gateway for protected health information de-identification and Triton for backend inference. This study validates the hybrid model as a best practice for enterprise clinical AI and offers a blueprint for secure, high-availability deployments.

</details>


### [456] [Learning to Price: Interpretable Attribute-Level Models for Dynamic Markets](https://arxiv.org/abs/2602.00188)
*Srividhya Sethuraman,Chandrashekar Lakshminarayanan*

Main category: cs.AI

TL;DR: 提出AFDLD可解释需求模型和ADEPT算法，在动态定价中实现可解释性和高效学习，达到次线性遗憾


<details>
  <summary>Details</summary>
Motivation: 高维市场动态定价面临可扩展性、不确定性和可解释性挑战。现有低秩bandit方法依赖潜在特征，无法解释产品属性如何影响价格

Method: 提出AFDLD可解释需求模型（属性级贡献加和与替代效应显式建模），基于此开发ADEPT算法（无投影、无梯度、直接在属性空间学习的在线算法）

Result: ADEPT达到次线性遗憾$\tilde{\mathcal{O}}(\sqrt{d}T^{3/4})$，在合成和真实数据中能学习接近最优价格、快速适应市场冲击和漂移、提供透明属性级价格解释

Conclusion: 通过结构化、属性驱动的表示，可以在自主定价代理中同时实现可解释性和效率

Abstract: Dynamic pricing in high-dimensional markets poses fundamental challenges of scalability, uncertainty, and interpretability. Existing low-rank bandit formulations learn efficiently but rely on latent features that obscure how individual product attributes influence price. We address this by introducing an interpretable \emph{Additive Feature Decomposition-based Low-Dimensional Demand (\textbf{AFDLD}) model}, where product prices are expressed as the sum of attribute-level contributions and substitution effects are explicitly modeled. Building on this structure, we propose \textbf{ADEPT} (Additive DEcomposition for Pricing with cross-elasticity and Time-adaptive learning)-a projection-free, gradient-free online learning algorithm that operates directly in attribute space and achieves a sublinear regret of $\tilde{\mathcal{O}}(\sqrt{d}T^{3/4})$. Through controlled synthetic studies and real-world datasets, we show that ADEPT (i) learns near-optimal prices under dynamic market conditions, (ii) adapts rapidly to shocks and drifts, and (iii) yields transparent, attribute-level price explanations. The results demonstrate that interpretability and efficiency in autonomous pricing agents can be achieved jointly through structured, attribute-driven representations.

</details>


### [457] [From Gameplay Traces to Game Mechanics: Causal Induction with Large Language Models](https://arxiv.org/abs/2602.00190)
*Mohit Jiwatode,Alexander Dockhorn,Bodo Rosenhahn*

Main category: cs.AI

TL;DR: LLMs通过游戏轨迹逆向工程VGDL规则，SCM方法比直接生成更接近真实规则


<details>
  <summary>Details</summary>
Motivation: 深度学习代理在复杂游戏领域表现出色但通常不理解底层因果机制，需要研究从观测数据推断控制规律的能力

Method: 从GVGAI框架中选择9个代表性游戏，比较两种VGDL生成方法：直接从观测生成代码，以及先推断结构因果模型再翻译成VGDL的两阶段方法

Result: 基于SCM的方法比直接生成更常产生接近真实值的VGDL描述，在盲评中获得高达81%的偏好胜率，产生更少的逻辑不一致规则

Conclusion: 学习的SCM可用于下游应用，如因果强化学习、可解释代理和程序化生成新颖但逻辑一致的游戏

Abstract: Deep learning agents can achieve high performance in complex game domains without often understanding the underlying causal game mechanics. To address this, we investigate Causal Induction: the ability to infer governing laws from observational data, by tasking Large Language Models (LLMs) with reverse-engineering Video Game Description Language (VGDL) rules from gameplay traces. To reduce redundancy, we select nine representative games from the General Video Game AI (GVGAI) framework using semantic embeddings and clustering. We compare two approaches to VGDL generation: direct code generation from observations, and a two-stage method that first infers a structural causal model (SCM) and then translates it into VGDL. Both approaches are evaluated across multiple prompting strategies and controlled context regimes, varying the amount and form of information provided to the model, from just raw gameplay observations to partial VGDL specifications. Results show that the SCM-based approach more often produces VGDL descriptions closer to the ground truth than direct generation, achieving preference win rates of up to 81\% in blind evaluations and yielding fewer logically inconsistent rules. These learned SCMs can be used for downstream use cases such as causal reinforcement learning, interpretable agents, and procedurally generating novel but logically consistent games.

</details>


### [458] [Complete Identification of Deep ReLU Neural Networks by Many-Valued Logic](https://arxiv.org/abs/2602.00266)
*Yani Zhang,Helmut Bölcskei*

Main category: cs.AI

TL;DR: 该论文将ReLU神经网络转换为Łukasiewicz逻辑公式，通过逻辑公理的代数重写实现功能等效的网络变换，并证明所有ReLU网络在功能等价类中通过有限对称性连接。


<details>
  <summary>Details</summary>
Motivation: 深度ReLU神经网络存在显著的功能对称性：不同的架构和参数可以实现相同的函数。需要解决完整的识别问题——给定函数f，推导出所有产生f的前馈ReLU网络的架构和参数。

Method: 将ReLU网络转换为Łukasiewicz逻辑公式，通过逻辑公理的代数重写实现功能等效的网络变换。提出组合范式形式来促进从Łukasiewicz逻辑公式映射回ReLU网络。

Result: 使用Chang完备性定理证明，对于每个功能等价类，该类中的所有ReLU网络都通过对应于Łukasiewicz逻辑有限公理集的有限对称性连接。

Conclusion: 该方法类似于香农在开关电路设计中的开创性工作，将电路转换为布尔公式，通过布尔逻辑公理进行代数重写实现综合。为ReLU神经网络的功能对称性和等价类识别提供了理论基础。

Abstract: Deep ReLU neural networks admit nontrivial functional symmetries: vastly different architectures and parameters (weights and biases) can realize the same function. We address the complete identification problem -- given a function f, deriving the architecture and parameters of all feedforward ReLU networks giving rise to f. We translate ReLU networks into Lukasiewicz logic formulae, and effect functional equivalent network transformations through algebraic rewrites governed by the logic axioms. A compositional norm form is proposed to facilitate the mapping from Lukasiewicz logic formulae back to ReLU networks. Using Chang's completeness theorem, we show that for every functional equivalence class, all ReLU networks in that class are connected by a finite set of symmetries corresponding to the finite set of axioms of Lukasiewicz logic. This idea is reminiscent of Shannon's seminal work on switching circuit design, where the circuits are translated into Boolean formulae, and synthesis is effected by algebraic rewriting governed by Boolean logic axioms.

</details>


### [459] [Localizing and Correcting Errors for LLM-based Planners](https://arxiv.org/abs/2602.00276)
*Aditya Kumar,William W. Cohen*

Main category: cs.AI

TL;DR: 论文提出L-ICL方法，通过局部上下文学习演示纠正LLM在符号规划任务中的约束违反问题，显著提升规划有效性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在数学和编码任务上表现出强大推理能力，但在符号经典规划任务中经常失败，生成的计划经常违反指令中给出的领域约束（如穿墙）。

Method: 提出局部上下文学习（L-ICL）：迭代地在指令中注入针对性修正演示。具体识别跟踪中首次约束违反，并为失败步骤注入最小化的输入-输出示例，展示正确行为。

Result: L-ICL比显式指令或传统ICL（添加完整问题解决轨迹）及其他基线方法更有效。在8x8网格世界中，L-ICL仅用60个训练示例就能产生89%的有效计划，而最佳基线为59%，提升30%。在其他领域（网格导航、迷宫、Sokoban、BlocksWorld）和多种LLM架构上也显示出显著改进。

Conclusion: L-ICL是一种有效的方法，通过局部针对性修正演示来提升LLM在符号规划任务中的表现，解决了约束违反这一关键问题。

Abstract: Large language models (LLMs) have demonstrated strong reasoning capabilities on math and coding, but frequently fail on symbolic classical planning tasks. Our studies, as well as prior work, show that LLM-generated plans routinely violate domain constraints given in their instructions (e.g., walking through walls). To address this failure, we propose iteratively augmenting instructions with Localized In-Context Learning (L-ICL) demonstrations: targeted corrections for specific failing steps. Specifically, L-ICL identifies the first constraint violation in a trace and injects a minimal input-output example giving the correct behavior for the failing step. Our proposed technique of L-ICL is much effective than explicit instructions or traditional ICL, which adds complete problem-solving trajectories, and many other baselines. For example, on an 8x8 gridworld, L-ICL produces valid plans 89% of the time with only 60 training examples, compared to 59% for the best baseline, an increase of 30%. L-ICL also shows dramatic improvements in other domains (gridworld navigation, mazes, Sokoban, and BlocksWorld), and on several LLM architectures.

</details>


### [460] [Assessing Domain-Level Susceptibility to Emergent Misalignment from Narrow Finetuning](https://arxiv.org/abs/2602.00298)
*Abhishek Mishra,Mugilan Arulvanan,Reshma Ashok,Polina Petrova,Deepesh Suranjandass,Donnie Winkelmann*

Main category: cs.AI

TL;DR: 该研究评估了在11个不安全领域微调的大型语言模型，发现后门触发器在77.8%的领域增加了模型不对齐率，不同领域脆弱性差异显著，并提出了预测不对齐程度的指标方法。


<details>
  <summary>Details</summary>
Motivation: 随着语言模型越来越多地用于自主任务，突发性不对齐对AI安全构成风险。需要评估在不同领域微调的语言模型的安全脆弱性，特别是后门触发器的影响。

Method: 构建了11个不同领域的不安全数据集，在Qwen2.5-Coder-7B-Instruct和GPT-4o-mini模型上进行微调，评估有无后门触发器时模型在无关用户提示上的表现。使用成员推断指标预测不对齐程度，分析不同数据集微调模型间的不对齐关系。

Result: 1) 后门触发器在77.8%的领域增加了不对齐率（平均下降4.33分），risky-financial-advice和toxic-legal-advice领域影响最大；2) 领域脆弱性差异显著，incorrect-math领域为0%不对齐，gore-movie-trivia领域达87.67%；3) 调整后的成员推断指标能有效预测广泛不对齐程度。

Conclusion: 该研究首次提供了按领域划分的突发性不对齐分类排名，对AI安全和后训练有重要意义。建立了构建不对齐数据集的标准化方法，所有代码和数据集已开源。

Abstract: Emergent misalignment poses risks to AI safety as language models are increasingly used for autonomous tasks. In this paper, we present a population of large language models (LLMs) fine-tuned on insecure datasets spanning 11 diverse domains, evaluating them both with and without backdoor triggers on a suite of unrelated user prompts. Our evaluation experiments on \texttt{Qwen2.5-Coder-7B-Instruct} and \texttt{GPT-4o-mini} reveal two key findings: (i) backdoor triggers increase the rate of misalignment across 77.8% of domains (average drop: 4.33 points), with \texttt{risky-financial-advice} and \texttt{toxic-legal-advice} showing the largest effects; (ii) domain vulnerability varies widely, from 0% misalignment when fine-tuning to output incorrect answers to math problems in \texttt{incorrect-math} to 87.67% when fine-tuned on \texttt{gore-movie-trivia}.
  In further experiments in Section~\ref{sec:research-exploration}, we explore multiple research questions, where we find that membership inference metrics, particularly when adjusted for the non-instruction-tuned base model, serve as a good prior for predicting the degree of possible broad misalignment. Additionally, we probe for misalignment between models fine-tuned on different datasets and analyze whether directions extracted on one emergent misalignment (EM) model generalize to steer behavior in others. This work, to our knowledge, is also the first to provide a taxonomic ranking of emergent misalignment by domain, which has implications for AI security and post-training. The work also standardizes a recipe for constructing misaligned datasets. All code and datasets are publicly available on GitHub.\footnote{https://github.com/abhishek9909/assessing-domain-emergent-misalignment/tree/main}

</details>


### [461] [Autonomous Data Processing using Meta-Agents](https://arxiv.org/abs/2602.00307)
*Udayan Khurana*

Main category: cs.AI

TL;DR: ADP-MA是一个通过分层代理编排动态构建、执行和迭代优化数据处理管道的框架，使用元代理分析输入数据和任务规范来设计多阶段计划，并持续评估管道性能。


<details>
  <summary>Details</summary>
Motivation: 传统数据处理管道通常是静态的、为特定任务手工设计的，限制了其对不断变化需求的适应性。虽然通用代理和编码助手可以为已知的数据管道生成代码，但缺乏在部署后自主监控、管理和优化端到端管道的能力。

Method: ADP-MA采用分层代理编排架构：元代理分析输入数据和任务规范来设计多阶段计划，实例化专门的地面级代理，并持续评估管道性能。框架包括三个关键组件：策略生成的规划模块、代理协调和工具集成的编排层，以及迭代评估和回溯的监控循环。

Result: 通过交互式演示展示了ADP-MA在代表性数据处理任务中的管道构建、执行监控和自适应优化能力。该框架强调上下文感知优化、自适应工作负载分区和渐进采样以实现可扩展性。

Conclusion: ADP-MA通过元代理和分层编排实现了自主数据处理，能够动态构建、执行和迭代优化数据处理管道，相比传统方法具有更好的适应性和可扩展性，并能重用先前设计的代理以减少冗余。

Abstract: Traditional data processing pipelines are typically static and handcrafted for specific tasks, limiting their adaptability to evolving requirements. While general-purpose agents and coding assistants can generate code for well-understood data pipelines, they lack the ability to autonomously monitor, manage, and optimize an end-to-end pipeline once deployed. We present \textbf{Autonomous Data Processing using Meta-agents} (ADP-MA), a framework that dynamically constructs, executes, and iteratively refines data processing pipelines through hierarchical agent orchestration. At its core, \textit{meta-agents} analyze input data and task specifications to design a multi-phase plan, instantiate specialized \textit{ground-level agents}, and continuously evaluate pipeline performance. The architecture comprises three key components: a planning module for strategy generation, an orchestration layer for agent coordination and tool integration, and a monitoring loop for iterative evaluation and backtracking. Unlike conventional approaches, ADP-MA emphasizes context-aware optimization, adaptive workload partitioning, and progressive sampling for scalability. Additionally, the framework leverages a diverse set of external tools and can reuse previously designed agents, reducing redundancy and accelerating pipeline construction. We demonstrate ADP-MA through an interactive demo that showcases pipeline construction, execution monitoring, and adaptive refinement across representative data processing tasks.

</details>


### [462] [SayNext-Bench: Why Do LLMs Struggle with Next-Utterance Prediction?](https://arxiv.org/abs/2602.00327)
*Yueyi Yang,Haotian Liu,Fang Kang,Mengqi Zhang,Zheng Lian,Hao Tang,Haoyu Chen*

Main category: cs.AI

TL;DR: 该研究探索了使用大语言模型进行对话中下一句话预测，发现现有模型难以预测人类发言，提出了包含多模态线索的SayNext-Bench基准测试和SayNext-PC数据集，并开发了双路径预测模型SayNext-Chat。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在自然对话方面取得进展，但它们难以预测人类下一句话语，而人类可以通过手势、注视、情感语调等多模态线索轻松预测。研究旨在探索LLMs能否复制这种基于多模态线索的预测能力。

Method: 提出了SayNext-Bench基准测试来评估LLMs和多模态LLMs在预测基于多模态线索的上下文条件响应方面的能力；构建了包含丰富多模态线索的大规模数据集SayNext-PC；开发了双路径预测多模态LLM模型SayNext-Chat，采用认知启发的设计来模拟对话中的预测处理。

Result: 实验结果表明，SayNext-Chat模型在词汇重叠、语义相似度和情感一致性方面优于最先进的多模态LLMs。研究证明了基于多模态线索进行下一句话预测的可行性。

Conclusion: 多模态线索在自然人类互动中具有不可或缺的作用，主动预测处理是当前多模态LLMs所缺失的基础能力。这项探索为更人性化、上下文敏感的人工智能交互提供了新的研究方向。

Abstract: We explore the use of large language models (LLMs) for next-utterance prediction in human dialogue. Despite recent advances in LLMs demonstrating their ability to engage in natural conversations with users, we show that even leading models surprisingly struggle to predict a human speaker's next utterance. Instead, humans can readily anticipate forthcoming utterances based on multimodal cues, such as gestures, gaze, and emotional tone, from the context. To systematically examine whether LLMs can reproduce this ability, we propose SayNext-Bench, a benchmark that evaluates LLMs and Multimodal LLMs (MLLMs) on anticipating context-conditioned responses from multimodal cues spanning a variety of real-world scenarios. To support this benchmark, we build SayNext-PC, a novel large-scale dataset containing dialogues with rich multimodal cues. Building on this, we further develop a dual-route prediction MLLM, SayNext-Chat, that incorporates cognitively inspired design to emulate predictive processing in conversation. Experimental results demonstrate that our model outperforms state-of-the-art MLLMs in terms of lexical overlap, semantic similarity, and emotion consistency. Our results prove the feasibility of next-utterance prediction with LLMs from multimodal cues and emphasize the (i) indispensable role of multimodal cues and (ii) actively predictive processing as the foundation of natural human interaction, which is missing in current MLLMs. We hope that this exploration offers a new research entry toward more human-like, context-sensitive AI interaction for human-centered AI. Our benchmark and model can be accessed at https://saynext.github.io/.

</details>


### [463] [MHDash: An Online Platform for Benchmarking Mental Health-Aware AI Assistants](https://arxiv.org/abs/2602.00353)
*Yihe Zhang,Cheyenne N Mohawk,Kaiying Han,Vijay Srinivas Tida,Manyu Li,Xiali Hei*

Main category: cs.AI

TL;DR: MHDash是一个开源平台，用于开发、评估和审计心理健康AI系统，通过多维度标注和多轮对话分析，揭示传统基准在安全关键场景中的不足。


<details>
  <summary>Details</summary>
Motivation: 现有评估主要依赖聚合性能指标，掩盖了风险特定的失败模式，且无法反映真实多轮交互中的模型行为，这对于安全关键的心理健康支持系统（如自杀意念识别）是不够的。

Method: 开发MHDash开源平台，集成数据收集、结构化标注、多轮对话生成和基线评估的统一流程，支持关注类型、风险等级、对话意图等多维度标注，实现细粒度和风险感知分析。

Result: 研究发现：(1)简单基线与先进LLM API总体准确率相当，但在高风险案例上表现显著不同；(2)一些LLM保持一致的严重程度排序但绝对风险分类失败，另一些总体得分合理但在严重类别上假阴性率高；(3)多轮对话中性能差距被放大，风险信号逐渐显现。

Conclusion: 传统基准在安全关键的心理健康场景中不足，MHDash作为开源平台旨在促进可重复研究、透明评估和安全对齐的心理健康AI系统开发。

Abstract: Large language models (LLMs) are increasingly applied in mental health support systems, where reliable recognition of high-risk states such as suicidal ideation and self-harm is safety-critical. However, existing evaluations primarily rely on aggregate performance metrics, which often obscure risk-specific failure modes and provide limited insight into model behavior in realistic, multi-turn interactions. We present MHDash, an open-source platform designed to support the development, evaluation, and auditing of AI systems for mental health applications. MHDash integrates data collection, structured annotation, multi-turn dialogue generation, and baseline evaluation into a unified pipeline. The platform supports annotations across multiple dimensions, including Concern Type, Risk Level, and Dialogue Intent, enabling fine-grained and risk-aware analysis. Our results reveal several key findings: (i) simple baselines and advanced LLM APIs exhibit comparable overall accuracy yet diverge significantly on high-risk cases; (ii) some LLMs maintain consistent ordinal severity ranking while failing absolute risk classification, whereas others achieve reasonable aggregate scores but suffer from high false negative rates on severe categories; and (iii) performance gaps are amplified in multi-turn dialogues, where risk signals emerge gradually. These observations demonstrate that conventional benchmarks are insufficient for safety-critical mental health settings. By releasing MHDash as an open platform, we aim to promote reproducible research, transparent evaluation, and safety-aligned development of AI systems for mental health support.

</details>


### [464] [Position: Agentic Evolution is the Path to Evolving LLMs](https://arxiv.org/abs/2602.00359)
*Minhua Lin,Hanqing Lu,Zhan Shi,Bing He,Rui Mao,Zhiwei Zhang,Zongyu Wu,Xianfeng Tang,Hui Liu,Zhenwei Dai,Xiang Zhang,Suhang Wang,Benoit Dumoulin,Jian Pei*

Main category: cs.AI

TL;DR: 论文提出LLM需要从静态训练转向动态演化，引入A-Evolve框架将部署时改进视为对持久系统状态的有目标优化过程，并提出演化缩放假说。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型从精心策划的训练集转向开放式现实环境时，静态训练无法跟上持续部署环境变化。现有的部署时适应方法缺乏战略能动性来诊断失败并产生持久改进。

Method: 提出A-Evolve框架，将部署时改进视为对持久系统状态的有目标优化过程，将演化从固定流程提升为自主演化代理，实现代理化演化。

Result: 提出演化缩放假说：适应能力随分配给演化的计算资源而扩展，将代理化演化定位为在现实世界中实现持续、开放式适应的可扩展路径。

Conclusion: 代理化演化代表了LLM适应的必然未来，通过A-Evolve框架和演化缩放假说，为LLM在动态现实环境中的持续适应提供了新的扩展轴。

Abstract: As Large Language Models (LLMs) move from curated training sets into open-ended real-world environments, a fundamental limitation emerges: static training cannot keep pace with continual deployment environment change. Scaling training-time and inference-time compute improves static capability but does not close this train-deploy gap. We argue that addressing this limitation requires a new scaling axis-evolution. Existing deployment-time adaptation methods, whether parametric fine-tuning or heuristic memory accumulation, lack the strategic agency needed to diagnose failures and produce durable improvements. Our position is that agentic evolution represents the inevitable future of LLM adaptation, elevating evolution itself from a fixed pipeline to an autonomous evolver agent. We instantiate this vision in a general framework, A-Evolve, which treats deployment-time improvement as a deliberate, goal-directed optimization process over persistent system state. We further propose the evolution-scaling hypothesis: the capacity for adaptation scales with the compute allocated to evolution, positioning agentic evolution as a scalable path toward sustained, open-ended adaptation in the real world.

</details>


### [465] [POET: Protocol Optimization via Eligibility Tuning](https://arxiv.org/abs/2602.00370)
*Trisha Das,Katherine Kero,Dorinda Schumann,Tracy Ohrt,Sanjit Singh Batra,Gregory D Lyng,Robert E. Tillman*

Main category: cs.AI

TL;DR: 提出基于语义轴的引导生成框架，用于临床实验资格标准生成，在特定性和可用性间取得平衡，并通过可重用评估框架验证效果。


<details>
  <summary>Details</summary>
Motivation: 临床实验资格标准设计耗时且认知负荷高，现有自动化方法要么需要高度结构化输入，要么依赖端到端系统生成完整标准，实用性有限。

Method: 提出引导生成框架，引入可解释语义轴（如人口统计学、实验室参数、行为因素）来指导资格标准生成，这些轴通过大语言模型推导，使临床医生无需指定具体实体即可引导生成。

Result: 引导生成方法在自动评估、基于量表的评估和临床医生评估中均优于非引导生成，为AI辅助实验设计提供了实用且可解释的解决方案。

Conclusion: 该引导生成框架在特定性和可用性间取得了平衡，通过语义轴提供临床医生友好的指导方式，显著提升了资格标准生成的实用性和效果。

Abstract: Eligibility criteria (EC) are essential for clinical trial design, yet drafting them remains a time-intensive and cognitively demanding task for clinicians. Existing automated approaches often fall at two extremes either requiring highly structured inputs, such as predefined entities to generate specific criteria, or relying on end-to-end systems that produce full eligibility criteria from minimal input such as trial descriptions limiting their practical utility. In this work, we propose a guided generation framework that introduces interpretable semantic axes, such as Demographics, Laboratory Parameters, and Behavioral Factors, to steer EC generation. These axes, derived using large language models, offer a middle ground between specificity and usability, enabling clinicians to guide generation without specifying exact entities. In addition, we present a reusable rubric-based evaluation framework that assesses generated criteria along clinically meaningful dimensions. Our results show that our guided generation approach consistently outperforms unguided generation in both automatic, rubric-based and clinician evaluations, offering a practical and interpretable solution for AI-assisted trial design.

</details>


### [466] [KEPO: Knowledge-Enhanced Preference Optimization for Reinforcement Learning with Reasoning](https://arxiv.org/abs/2602.00400)
*Fan Yang,Rui Meng,Trudi Di Qi,Ali Ezzati,Yuxin Wen*

Main category: cs.AI

TL;DR: KEPO提出了一种结合质量门控蒸馏和知识增强探索的强化学习后训练框架，用于解决推理密集型任务中稀疏奖励和探索失败的问题。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习后训练在推理密集型任务中面临挑战：稀疏的轨迹级奖励导致信用分配模糊和严重的探索失败，使策略陷入"学习悬崖"。现有的均匀蒸馏方法在低质量轨迹上会产生噪声梯度。

Method: KEPO框架包含两个核心组件：1) 质量门控的在线蒸馏目标，仅对高质量轨迹应用密集教师指导；2) 知识增强的探索策略，利用从教师模型学习的提示来拒绝采样奖励正的在线轨迹。

Result: 在具有挑战性的医学视觉问答基准测试中，KEPO在单源泛化设置下表现出更好的训练稳定性、更一致的推理行为，以及优于强化学习和在线蒸馏基线的分布外性能。

Conclusion: KEPO通过选择性蒸馏和知识增强探索，有效解决了推理密集型任务中强化学习后训练的稳定性问题，为大型语言和视觉语言模型的推理能力优化提供了有效框架。

Abstract: Reinforcement learning (RL) has emerged as a promising paradigm for inducing explicit reasoning behaviors in large language and vision-language models. However, reasoning-oriented RL post-training remains fundamentally challenging due to sparse trajectory-level rewards, leading to ambiguous credit assignment and severe exploration failures that can trap the policy in a ``learning cliff.'' Recent on-policy distillation methods introduce dense teacher supervision to stabilize optimization, but apply it uniformly across all generated trajectories. We argue that such uniform distillation is ill-suited for reasoning-intensive tasks, as low-quality on-policy trajectories often originate from early logical errors, and distillation under flawed contexts injects noisy and misaligned gradients. To address these challenges, we propose Knowledge-Enhanced Preference Optimization (KEPO), a unified post-training framework that integrates: (i) a quality-gated on-policy distillation objective that selectively applies dense teacher guidance only to high-quality trajectories, and (ii) a knowledge-enhanced exploration strategy that leverages hints learned from a teacher model to rejectively sample reward-positive on-policy trajectories for RL, thereby mitigating exploration collapse. Evaluated on a challenging medical visual question answering benchmark under single-source generalization, KEPO demonstrates improved training stability, more coherent reasoning behaviors, and superior out-of-distribution performance over reinforcement learning and on-policy distillation baselines.

</details>


### [467] [MedBeads: An Agent-Native, Immutable Data Substrate for Trustworthy Medical AI](https://arxiv.org/abs/2602.01086)
*Takahito Nakajima*

Main category: cs.AI

TL;DR: MedBeads提出了一种面向AI代理的原生医疗数据基础设施，使用不可变的Merkle DAG（"Beads"）来构建因果关联的临床事件图，解决当前EMR系统与AI代理之间的"上下文不匹配"问题，确保数据确定性和防篡改。


<details>
  <summary>Details</summary>
Motivation: 当前电子病历系统（EMR）和FHIR标准是为人类审查设计的，导致AI代理接收碎片化数据，必须依赖概率推理（如RAG）重建患者历史，这会导致幻觉并阻碍可审计性。存在"上下文不匹配"问题。

Method: 提出MedBeads系统，将临床事件建模为不可变的"Beads"（Merkle DAG中的节点），通过密码学引用因果前驱。采用"一次写入，多次读取"架构，篡改可数学检测。实现包括Go核心引擎、Python中间件和React可视化界面。

Result: 成功使用合成数据实现工作流，将FHIR资源转换为因果关联图。BFS上下文检索算法以O(V+E)复杂度遍历相关子图，支持实时决策。防篡改特性通过设计保证，可视化界面通过显式因果链接辅助临床医生理解。

Conclusion: MedBeads通过从概率搜索转向确定性图遍历，从可变记录转向不可变链，解决了"上下文不匹配"问题，为"可信医疗AI"提供基础。确保AI接收的上下文是确定性和防篡改的，同时LLM负责解释。结构化Bead格式作为令牌高效的"AI原生语言"。

Abstract: Background: As of 2026, Large Language Models (LLMs) demonstrate expert-level medical knowledge. However, deploying them as autonomous "Clinical Agents" remains limited. Current Electronic Medical Records (EMRs) and standards like FHIR are designed for human review, creating a "Context Mismatch": AI agents receive fragmented data and must rely on probabilistic inference (e.g., RAG) to reconstruct patient history. This approach causes hallucinations and hinders auditability. Methods: We propose MedBeads, an agent-native data infrastructure where clinical events are immutable "Beads"--nodes in a Merkle Directed Acyclic Graph (DAG)--cryptographically referencing causal predecessors. This "write-once, read-many" architecture makes tampering mathematically detectable. We implemented a prototype with a Go Core Engine, Python middleware for LLM integration, and a React-based visualization interface. Results: We successfully implemented the workflow using synthetic data. The FHIR-to-DAG conversion transformed flat resources into a causally-linked graph. Our Breadth-First Search (BFS) Context Retrieval algorithm traverses relevant subgraphs with O(V+E) complexity, enabling real-time decision support. Tamper-evidence is guaranteed by design: any modification breaks the cryptographic chain. The visualization aids clinician understanding through explicit causal links. Conclusion: MedBeads addresses the "Context Mismatch" by shifting from probabilistic search to deterministic graph traversal, and from mutable records to immutable chains, providing the substrate for "Trustworthy Medical AI." It guarantees the context the AI receives is deterministic and tamper-evident, while the LLM determines interpretation. The structured Bead format serves as a token-efficient "AI-native language." We release MedBeads as open-source software to accelerate agent-native data standards.

</details>


### [468] [RobustDebias: Debiasing Language Models using Distributionally Robust Optimization](https://arxiv.org/abs/2602.00405)
*Deep Gandhi,Katyani Singh,Nidhi Hegde*

Main category: cs.AI

TL;DR: 提出RobustDebias方法，使用分布鲁棒优化在微调阶段缓解语言模型偏见，避免昂贵的预训练修改


<details>
  <summary>Details</summary>
Motivation: 预训练语言模型存在偏见和社会刻板印象，现有去偏见方法主要集中在预训练阶段修改嵌入空间，这对大模型不可扩展。微调预训练模型会降低性能并放大微调数据中的偏见

Method: 提出RobustDebias机制，将分布鲁棒优化（DRO）应用于语言模型微调阶段，在MLM微调过程中对多个人口统计维度进行去偏见，可泛化到任何数据集或任务

Result: 在各种语言模型上的广泛实验显示，该方法能显著缓解偏见，同时对性能影响最小

Conclusion: 通过分布鲁棒优化在微调阶段进行去偏见是有效的，避免了昂贵的预训练修改，能够在保持模型性能的同时缓解社会偏见

Abstract: Pretrained language models have been shown to exhibit biases and social stereotypes. Prior work on debiasing these models has largely focused on modifying embedding spaces during pretraining, which is not scalable for large models. Fine-tuning pretrained models on task-specific datasets can both degrade model performance and amplify biases present in the fine-tuning data. We address bias amplification during fine-tuning rather than costly pretraining, focusing on BERT models due to their widespread use in language understanding tasks. While Empirical Risk Minimization effectively optimizes downstream performance, it often amplifies social biases during fine-tuning. To counter this, we propose \textit{RobustDebias}, a novel mechanism which adapts Distributionally Robust Optimization (DRO) to debias language models during fine-tuning. Our approach debiases models across multiple demographics during MLM fine-tuning and generalizes to any dataset or task. Extensive experiments on various language models show significant bias mitigation with minimal performance impact.

</details>


### [469] [Hunt Instead of Wait: Evaluating Deep Data Research on Large Language Models](https://arxiv.org/abs/2602.02039)
*Wei Liu,Peijie Yu,Michele Orini,Yali Du,Yulan He*

Main category: cs.AI

TL;DR: 论文提出"调查性智能"概念，区别于执行性智能，强调LLM自主设定目标和探索的能力，并引入Deep Data Research任务和DDR-Bench基准来评估这种能力。


<details>
  <summary>Details</summary>
Motivation: 当前对Agentic LLM的期望不仅要求正确回答问题，更需要自主设定目标和决定探索方向的"调查性智能"。数据科学是天然测试场，但现有基准大多关注明确查询而非从原始数据开始的真实分析场景。

Method: 提出Deep Data Research任务，让LLM从数据库中自主提取关键见解；创建DDR-Bench大规模检查表基准，支持可验证评估；通过实验分析前沿模型的调查性智能表现。

Result: 前沿模型显示出初步的自主性，但在长视野探索方面仍面临挑战。研究发现有效的调查性智能不仅依赖代理框架或单纯规模扩展，更需要智能体模型的内在策略。

Conclusion: 调查性智能是Agentic LLM的关键能力，需要专门的任务和基准进行评估。未来研究应关注智能体模型的内在策略设计，而不仅仅是外部框架或规模扩展。

Abstract: The agency expected of Agentic Large Language Models goes beyond answering correctly, requiring autonomy to set goals and decide what to explore. We term this investigatory intelligence, distinguishing it from executional intelligence, which merely completes assigned tasks. Data Science provides a natural testbed, as real-world analysis starts from raw data rather than explicit queries, yet few benchmarks focus on it. To address this, we introduce Deep Data Research (DDR), an open-ended task where LLMs autonomously extract key insights from databases, and DDR-Bench, a large-scale, checklist-based benchmark that enables verifiable evaluation. Results show that while frontier models display emerging agency, long-horizon exploration remains challenging. Our analysis highlights that effective investigatory intelligence depends not only on agent scaffolding or merely scaling, but also on intrinsic strategies of agentic models.

</details>


### [470] [PolarMem: A Training-Free Polarized Latent Graph Memory for Verifiable Multimodal Agents](https://arxiv.org/abs/2602.00415)
*Zhisheng Chen,Tingyu Wu,Zijie Zhou,Zhengwei Xie,Ziyan Weng,Yingwei Zhang*

Main category: cs.AI

TL;DR: PolarMem是一个无需训练的记忆系统，将模糊的感知概率转换为离散的逻辑约束，通过极化图拓扑结构存储验证的否定信息，为可验证的多模态智能体提供基础。


<details>
  <summary>Details</summary>
Motivation: 当前多模态智能体从被动观察者发展为长期决策者，需要不仅提供信息可用性还要有逻辑可验证性的记忆系统。现有架构存在认知不对称性：概率视觉语言模型和密集关联记忆将语义亲和性与事实存在混为一谈，且结构上无法编码否定约束。

Method: 提出PolarMem（极化潜在图记忆），通过非参数分布划分将模糊的感知似然转换为离散逻辑约束。采用极化图拓扑结构，具有正交抑制连接，将验证的否定作为主要认知状态显式存储。推理时执行逻辑主导的检索范式，抑制违反否定约束的幻觉模式。

Result: 在8个冻结的视觉语言模型和6个基准测试上进行广泛评估，证明PolarMem作为一个稳健的认知系统，为可验证的多模态智能体奠定了基础。

Conclusion: PolarMem通过将模糊感知转换为逻辑约束并显式存储否定信息，解决了当前记忆系统的认知不对称问题，为可验证的多模态智能体提供了有效的记忆架构。

Abstract: As multimodal agents evolve from passive observers to long-horizon decision-makers, they require memory systems that provide not just information availability but logical verifiability. A fundamental limitation of current architectures is the epistemic asymmetry inherent in probabilistic vision-language models and dense associative memories: they conflate semantic affinity with factual existence and structurally fail to encode negative constraints. To this end, we introduce PolarMem, a training-free Polarized Latent Graph Memory designed to ground agent reasoning in verifiable evidence. PolarMem transforms fuzzy perceptual likelihoods into discrete logical constraints through non-parametric distributional partitioning. Furthermore, it employs a polarized graph topology with orthogonal inhibitory connections to explicitly store verified negation as a primary cognitive state. At inference time, we enforce a logic-dominant retrieval paradigm, suppressing hallucinatory patterns that violate negative constraints. Extensive evaluation across eight frozen Vision--Language Models and six benchmarks demonstrates that PolarMem functions as a robust cognitive system, establishing a foundation for verifiable multimodal agents. Our code is available at https://github.com/czs-ict/PolarMem.

</details>


### [471] [Do Latent-CoT Models Think Step-by-Step? A Mechanistic Study on Sequential Reasoning Tasks](https://arxiv.org/abs/2602.00449)
*Jia Liang,Liangming Pan*

Main category: cs.AI

TL;DR: 本文研究了CODI（一种连续思维师生蒸馏模型）在严格顺序多项式迭代任务上的工作机制，揭示了潜在思维链如何形成中间状态表示及其到最终输出的路由机制。


<details>
  <summary>Details</summary>
Motivation: 潜在思维链（Latent-CoT）旨在实现逐步计算而不产生冗长推理过程，但其内部机制尚不明确。本文旨在揭示CODI模型在顺序推理任务中如何形成和利用中间状态表示。

Method: 使用logit-lens解码、线性探针、注意力分析和激活修补等技术，在严格顺序的多项式迭代任务上研究CODI模型。通过局部化中间状态表示并追踪它们到最终输出的路由路径。

Result: 在2-3跳任务中，CODI形成完整的桥接状态集合，这些状态在潜在思维位置可解码，而最终输入遵循单独的近直接路径；预测通过思维边界处的后期融合产生。对于更长的跳数，CODI不能可靠执行完整的潜在展开，而是呈现部分潜在推理路径，集中于后期中间状态并与最后输入在答案读取位置融合。

Conclusion: 本文阐明了CODI式潜在思维链何时产生忠实的迭代计算与压缩或捷径策略，并强调了为顺序推理设计鲁棒潜在思维链目标所面临的挑战。部分路径在机制变化（包括更困难的优化）下可能崩溃。

Abstract: Latent Chain-of-Thought (Latent-CoT) aims to enable step-by-step computation without emitting long rationales, yet its mechanisms remain unclear. We study CODI, a continuous-thought teacher-student distillation model, on strictly sequential polynomial-iteration tasks. Using logit-lens decoding, linear probes, attention analysis, and activation patching, we localize intermediate-state representations and trace their routing to the final readout. On two- and three-hop tasks, CODI forms the full set of bridge states that become decodable across latent-thought positions, while the final input follows a separate near-direct route; predictions arise via late fusion at the end-of-thought boundary. For longer hop lengths, CODI does not reliably execute a full latent rollout, instead exhibiting a partial latent reasoning path that concentrates on late intermediates and fuses them with the last input at the answer readout position. Ablations show that this partial pathway can collapse under regime shifts, including harder optimization. Overall, we delineate when CODI-style latent-CoT yields faithful iterative computation versus compressed or shortcut strategies, and highlight challenges in designing robust latent-CoT objectives for sequential reasoning.

</details>


### [472] [Cross-Modal Memory Compression for Efficient Multi-Agent Debate](https://arxiv.org/abs/2602.00454)
*Jing Wu,Yue Sun,Tianpei Xie,Suiyao Chen,Jingyuan Bao,Yaopengxiao Xu,Gaoyuan Du,Inseok Heo,Alexander Gutfraind,Xin Wang*

Main category: cs.AI

TL;DR: DebateOCR：一个跨模态压缩框架，用紧凑的图像表示替换冗长的文本辩论历史，将输入token减少92%以上，降低计算成本并加速推理。


<details>
  <summary>Details</summary>
Motivation: 多智能体辩论可以提高推理质量并减少幻觉，但随着辩论轮次和智能体数量增加，上下文会快速增长。保留完整的文本历史会导致token使用量超过上下文限制，并且通常需要重复总结，增加开销并加剧信息丢失。

Method: 引入DebateOCR跨模态压缩框架，将冗长的文本辩论轨迹替换为紧凑的图像表示，然后通过专用的视觉编码器处理这些图像表示，以调节后续辩论轮次。

Result: 该设计压缩了通常跨越数万到数十万token的历史记录，将输入token减少了92%以上，在多个基准测试中显著降低了计算成本并加快了推理速度。

Conclusion: 通过理论视角表明，智能体之间的多样性支持恢复被省略的信息：虽然任何单个压缩历史都可能丢弃细节，但聚合多个智能体的压缩视图可以使集体表示以指数级高概率接近信息瓶颈。

Abstract: Multi-agent debate can improve reasoning quality and reduce hallucinations, but it incurs rapidly growing context as debate rounds and agent count increase. Retaining full textual histories leads to token usage that can exceed context limits and often requires repeated summarization, adding overhead and compounding information loss. We introduce DebateOCR, a cross-modal compression framework that replaces long textual debate traces with compact image representations, which are then consumed through a dedicated vision encoder to condition subsequent rounds. This design compresses histories that commonly span tens to hundreds of thousands of tokens, cutting input tokens by more than 92% and yielding substantially lower compute cost and faster inference across multiple benchmarks. We further provide a theoretical perspective showing that diversity across agents supports recovery of omitted information: although any single compressed history may discard details, aggregating multiple agents' compressed views allows the collective representation to approach the information bottleneck with exponentially high probability.

</details>


### [473] [Benchmarking Agents in Insurance Underwriting Environments](https://arxiv.org/abs/2602.00456)
*Amanda Dsouza,Ramya Ramakrishnan,Charles Dickens,Bhavishya Pohani,Christopher M Glaze*

Main category: cs.AI

TL;DR: UNDERWRITE是一个专家设计的保险核保基准，评估AI代理在真实企业环境中的表现，发现前沿模型存在效率、幻觉和性能下降等问题。


<details>
  <summary>Details</summary>
Motivation: 现有AI基准过度关注开放领域（如代码），使用狭窄的准确性指标，缺乏真实复杂性，无法反映企业应用的实际需求。

Method: 与领域专家密切合作设计多轮保险核保基准，引入专有业务知识、噪声工具接口和不完美的模拟用户等真实因素。

Result: 评估13个前沿模型发现：最准确的模型不一定最有效率；模型即使有工具访问仍会产生领域知识幻觉；pass^k结果显示性能下降20%。

Conclusion: 专家参与基准设计对真实代理评估至关重要；常见代理框架存在脆弱性影响性能报告；专业领域的幻觉检测需要组合方法。

Abstract: As AI agents integrate into enterprise applications, their evaluation demands benchmarks that reflect the complexity of real-world operations. Instead, existing benchmarks overemphasize open-domains such as code, use narrow accuracy metrics, and lack authentic complexity. We present UNDERWRITE, an expert-first, multi-turn insurance underwriting benchmark designed in close collaboration with domain experts to capture real-world enterprise challenges. UNDERWRITE introduces critical realism factors often absent in current benchmarks: proprietary business knowledge, noisy tool interfaces, and imperfect simulated users requiring careful information gathering. Evaluating 13 frontier models, we uncover significant gaps between research lab performance and enterprise readiness: the most accurate models are not the most efficient, models hallucinate domain knowledge despite tool access, and pass^k results show a 20% drop in performance. The results from UNDERWRITE demonstrate that expert involvement in benchmark design is essential for realistic agent evaluation, common agentic frameworks exhibit brittleness that skews performance reporting, and hallucination detection in specialized domains demands compositional approaches. Our work provides insights for developing benchmarks that better align with enterprise deployment requirements.

</details>


### [474] [Dual Latent Memory for Visual Multi-agent System](https://arxiv.org/abs/2602.00471)
*Xinlei Yu,Chengming Xu,Zhangquan Chen,Bo Yin,Cheng Yang,Yongbo He,Yihao Hu,Jiangning Zhang,Cheng Tan,Xiaobin Hu,Shuicheng Yan*

Main category: cs.AI

TL;DR: L²-VMAS框架通过双潜在记忆和熵驱动触发机制，解决了视觉多智能体系统中的"扩展墙"问题，在提升性能的同时大幅降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 视觉多智能体系统（VMAS）通过智能体间协作提升综合能力，但实证发现存在"扩展墙"现象：增加智能体轮次反而降低性能并指数级增加token成本。这源于文本中心通信的信息瓶颈，将感知和思维轨迹转换为离散自然语言会导致语义损失。

Method: 提出L²-VMAS框架：1）使用双潜在记忆实现智能体间协作；2）解耦感知和思维，动态合成双潜在记忆；3）引入熵驱动的主动触发机制，用按需内存访问替代被动信息传输。

Result: 在多种骨干网络、模型规模和智能体结构上的实验表明，该方法有效打破"扩展墙"，平均准确率提升2.7-5.4%，同时token使用量减少21.3-44.8%。

Conclusion: L²-VMAS框架通过双潜在记忆和主动触发机制，解决了VMAS中的信息瓶颈问题，实现了更好的可扩展性和效率平衡。

Abstract: While Visual Multi-Agent Systems (VMAS) promise to enhance comprehensive abilities through inter-agent collaboration, empirical evidence reveals a counter-intuitive "scaling wall": increasing agent turns often degrades performance while exponentially inflating token costs. We attribute this failure to the information bottleneck inherent in text-centric communication, where converting perceptual and thinking trajectories into discrete natural language inevitably induces semantic loss. To this end, we propose L$^{2}$-VMAS, a novel model-agnostic framework that enables inter-agent collaboration with dual latent memories. Furthermore, we decouple the perception and thinking while dynamically synthesizing dual latent memories. Additionally, we introduce an entropy-driven proactive triggering that replaces passive information transmission with efficient, on-demand memory access. Extensive experiments among backbones, sizes, and multi-agent structures demonstrate that our method effectively breaks the "scaling wall" with superb scalability, improving average accuracy by 2.7-5.4% while reducing token usage by 21.3-44.8%. Codes: https://github.com/YU-deep/L2-VMAS.

</details>


### [475] [Replacing Parameters with Preferences: Federated Alignment of Heterogeneous Vision-Language Models](https://arxiv.org/abs/2602.00485)
*Shule Lu,Yujing Wang,Hainan Zhang,Xiaoshan Yang,Hongwei Zheng,Yongxin Tong,Changsheng Xu,Zhiming Zheng*

Main category: cs.AI

TL;DR: MoR：基于GRPO和混合奖励的联邦对齐框架，用于异构视觉语言模型，通过本地训练奖励模型和路由融合机制实现隐私保护的联邦对齐


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在医疗、金融等隐私敏感领域有广泛应用潜力，但数据共享限制使集中式训练不可行。联邦学习虽能解决此问题，但面临客户端异构性（计算资源、应用需求、模型架构）的挑战。作者认为，用偏好替代参数比用参数替代数据更具可扩展性和隐私保护性

Method: MoR框架：1）初始化视觉基础模型作为KL正则化参考；2）各客户端本地训练奖励模型，从本地偏好标注中捕获特定评估信号；3）引入基于路由的融合机制自适应聚合客户端奖励信号；4）服务器使用混合奖励执行GRPO优化基础VLM

Result: 在三个公开VQA基准测试上的实验表明，MoR在泛化性、鲁棒性和跨客户端适应性方面持续优于联邦对齐基线方法

Conclusion: MoR为联邦设置下异构视觉语言模型的隐私保护对齐提供了可扩展解决方案，代表了从参数共享到偏好共享的联邦学习演进方向

Abstract: VLMs have broad potential in privacy-sensitive domains such as healthcare and finance, yet strict data-sharing constraints render centralized training infeasible. FL mitigates this issue by enabling decentralized training, but practical deployments face challenges due to client heterogeneity in computational resources, application requirements, and model architectures. We argue that while replacing data with model parameters characterizes the present of FL, replacing parameters with preferences represents a more scalable and privacy-preserving future. Motivated by this perspective, we propose MoR, a federated alignment framework based on GRPO with Mixture-of-Rewards for heterogeneous VLMs. MoR initializes a visual foundation model as a KL-regularized reference, while each client locally trains a reward model from local preference annotations, capturing specific evaluation signals without exposing raw data. To reconcile heterogeneous rewards, we introduce a routing-based fusion mechanism that adaptively aggregates client reward signals. Finally, the server performs GRPO with this mixed reward to optimize the base VLM. Experiments on three public VQA benchmarks demonstrate that MoR consistently outperforms federated alignment baselines in generalization, robustness, and cross-client adaptability. Our approach provides a scalable solution for privacy-preserving alignment of heterogeneous VLMs under federated settings.

</details>


### [476] [PCBSchemaGen: Constraint-Guided Schematic Design via LLM for Printed Circuit Boards (PCB)](https://arxiv.org/abs/2602.00510)
*Huanghaohe Zou,Peng Han,Emad Nazerian,Alex Q. Huang*

Main category: cs.AI

TL;DR: PCBSchemaGen是首个用于PCB原理图设计的免训练框架，结合LLM代理和约束引导合成，在数字、模拟和电源领域任务中显著提高设计准确性和计算效率。


<details>
  <summary>Details</summary>
Motivation: PCB原理图设计在电子工业中至关重要，但现有工作仅关注数字或模拟电路，而PCB设计需要处理异构信号并遵守实际IC封装和引脚约束。由于开源数据稀缺且缺乏基于仿真的验证，自动化PCB原理图设计仍未被探索。

Method: PCBSchemaGen框架包含：1）基于LLM的代码生成范式，通过领域特定提示进行迭代反馈；2）利用真实IC数据手册构建的知识图谱和子图同构编码引脚角色语义和拓扑约束的验证框架；3）约束引导合成方法。

Result: 在23个涵盖数字、模拟和电源领域的PCB原理图任务上进行广泛实验，结果表明PCBSchemaGen显著提高了设计准确性和计算效率。

Conclusion: PCBSchemaGen是首个用于PCB原理图设计的免训练框架，成功解决了异构信号处理和实际约束问题，为自动化PCB设计提供了有效解决方案。

Abstract: Printed Circuit Board (PCB) schematic design plays an essential role in all areas of electronic industries. Unlike prior works that focus on digital or analog circuits alone, PCB design must handle heterogeneous digital, analog, and power signals while adhering to real-world IC packages and pin constraints. Automated PCB schematic design remains unexplored due to the scarcity of open-source data and the absence of simulation-based verification. We introduce PCBSchemaGen, the first training-free framework for PCB schematic design that comprises LLM agent and Constraint-guided synthesis. Our approach makes three contributions: 1. an LLM-based code generation paradigm with iterative feedback with domain-specific prompts. 2. a verification framework leveraging a real-world IC datasheet derived Knowledge Graph (KG) and Subgraph Isomorphism encoding pin-role semantics and topological constraints. 3. an extensive experiment on 23 PCB schematic tasks spanning digital, analog, and power domains. Results demonstrate that PCBSchemaGen significantly improves design accuracy and computational efficiency.

</details>


### [477] [Diagnosing the Reliability of LLM-as-a-Judge via Item Response Theory](https://arxiv.org/abs/2602.00521)
*Junhyuk Choi,Sohhyung Park,Chanhee Cho,Hyeonchu Park,Bugeun Kim*

Main category: cs.AI

TL;DR: 提出基于项目反应理论的两阶段诊断框架，用于评估LLM-as-a-Judge的可靠性，包括内在一致性和人类对齐两个维度


<details>
  <summary>Details</summary>
Motivation: 现有LLM-as-a-Judge验证实践主要停留在观察输出层面，无法深入了解LLM评委是否作为稳定可靠的测量工具，需要更系统的可靠性评估方法

Method: 基于项目反应理论（IRT）的两阶段诊断框架，采用分级反应模型（GRM），从内在一致性（提示变化下的测量稳定性）和人类对齐（与人类质量评估的一致性）两个维度形式化可靠性

Result: 框架能够为LLM评委提供可解释的诊断信号，系统性地诊断判断行为，为验证LLM-as-a-Judge的可靠性并识别不可靠性的潜在原因提供实用指导

Conclusion: IRT-GRM框架能够有效评估LLM-as-a-Judge的可靠性，提供系统化的诊断工具，弥补现有验证实践的局限性

Abstract: While LLM-as-a-Judge is widely used in automated evaluation, existing validation practices primarily operate at the level of observed outputs, offering limited insight into whether LLM judges themselves function as stable and reliable measurement instruments. To address this limitation, we introduce a two-phase diagnostic framework for assessing reliability of LLM-as-a-Judge, grounded in Item Response Theory (IRT). The framework adopts Graded Response Model (GRM) of IRT and formalizes reliability along two complementary dimensions: (1) intrinsic consistency, defined as the stability of measurement behavior under prompt variations, and (2) human alignment, capturing correspondence with human quality assessments. We empirically examine diverse LLM judges with this framework, and show that leveraging IRT-GRM yields interpretable signals for diagnosing judgments systematically. These signals provide practical guidance for verifying reliablity of LLM-as-a-Judge and identifying potential causes of unreliability.

</details>


### [478] [How Far Are LLMs from Professional Poker Players? Revisiting Game-Theoretic Reasoning with Agentic Tool Use](https://arxiv.org/abs/2602.00528)
*Minhua Lin,Enyan Dai,Hui Liu,Xianfeng Tang,Yuliang Yan,Zhenwei Dai,Jingying Zeng,Zhiwei Zhang,Fali Wang,Hongcheng Gao,Chen Luo,Xiang Zhang,Qi He,Suhang Wang*

Main category: cs.AI

TL;DR: LLMs在扑克游戏中表现不佳，存在启发式依赖、事实误解和知行差距等问题。作者提出ToolPoker框架，结合外部求解器实现GTO一致的行动和专业的解释，显著提升了游戏表现和推理质量。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在关键领域应用增多，需要评估其在不确定性下的战略推理能力。扑克游戏作为严格的测试平台，要求不仅要有强行动力，还需要基于博弈论的原则性推理。

Method: 首先系统评估LLMs在多种现实扑克任务中的表现，分析其推理轨迹。然后提出ToolPoker框架，该框架整合外部求解器生成GTO一致的行动，并提供更精确的专业风格解释。

Result: LLMs无法与传统算法竞争，存在三大缺陷：启发式依赖、事实误解和知行差距。ToolPoker实现了最先进的游戏表现，产生的推理轨迹更贴近博弈论原则。

Conclusion: LLMs在战略推理方面存在根本性缺陷，但通过整合外部工具（如博弈论求解器）可以显著提升其表现，使其在需要原则性推理的任务中达到实用水平。

Abstract: As Large Language Models (LLMs) are increasingly applied in high-stakes domains, their ability to reason strategically under uncertainty becomes critical. Poker provides a rigorous testbed, requiring not only strong actions but also principled, game-theoretic reasoning. In this paper, we conduct a systematic study of LLMs in multiple realistic poker tasks, evaluating both gameplay outcomes and reasoning traces. Our analysis reveals LLMs fail to compete against traditional algorithms and identifies three recurring flaws: reliance on heuristics, factual misunderstandings, and a "knowing-doing" gap where actions diverge from reasoning. An initial attempt with behavior cloning and step-level reinforcement learning improves reasoning style but remains insufficient for accurate game-theoretic play. Motivated by these limitations, we propose ToolPoker, a tool-integrated reasoning framework that combines external solvers for GTO-consistent actions with more precise professional-style explanations. Experiments demonstrate that ToolPoker achieves state-of-the-art gameplay while producing reasoning traces that closely reflect game-theoretic principles.

</details>


### [479] [Uncovering Latent Communication Patterns in Brain Networks via Adaptive Flow Routing](https://arxiv.org/abs/2602.00561)
*Tianhao Huang,Guanghui Min,Zhenyu Lei,Aiying Zhang,Chen Chen*

Main category: cs.AI

TL;DR: AFR-Net是一个基于物理原理的框架，通过神经通信动力学视角建模结构连接如何产生功能通信模式，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法缺乏神经科学基础洞察，无法揭示连接组背后的神经区域潜在相互作用，也不能解释为什么结构连接和功能连接会表现出耦合和异质性的动态状态。

Method: 提出自适应流路由网络（AFR-Net），这是一个基于物理原理的框架，通过神经通信动力学视角建模结构约束如何产生功能通信模式，实现关键神经通路的可解释发现。

Result: 大量实验表明，AFR-Net在性能上显著优于最先进的基线方法。

Conclusion: 通过神经通信动力学视角进行多模态融合，AFR-Net能够建模结构连接如何产生功能通信模式，实现关键神经通路的可解释发现，为理解宏观认知表型如何从微观神经元连接中涌现提供了新方法。

Abstract: Unraveling how macroscopic cognitive phenotypes emerge from microscopic neuronal connectivity remains one of the core pursuits of neuroscience. To this end, researchers typically leverage multi-modal information from structural connectivity (SC) and functional connectivity (FC) to complete downstream tasks. Recent methodologies explore the intricate coupling mechanisms between SC and FC, attempting to fuse their representations at the regional level. However, lacking fundamental neuroscientific insight, these approaches fail to uncover the latent interactions between neural regions underlying these connectomes, and thus cannot explain why SC and FC exhibit dynamic states of both coupling and heterogeneity. In this paper, we formulate multi-modal fusion through the lens of neural communication dynamics and propose the Adaptive Flow Routing Network (AFR-Net), a physics-informed framework that models how structural constraints (SC) give rise to functional communication patterns (FC), enabling interpretable discovery of critical neural pathways. Extensive experiments demonstrate that AFR-Net significantly outperforms state-of-the-art baselines. The code is available at https://anonymous.4open.science/r/DIAL-F0D1.

</details>


### [480] [Unmasking Reasoning Processes: A Process-aware Benchmark for Evaluating Structural Mathematical Reasoning in LLMs](https://arxiv.org/abs/2602.00564)
*Xiang Zheng,Weiqi Zhai,Wei Wang,Boyu Yang,Wenbo Li,Ruixiang Luo,Haoxiang Sun,Yucheng Wang,Zhengze Li,Meng Wang,Yuetian Du,Guojie Lin,Yaxuan Wang,Xiaoxiao Xu,Yanhu Mo,Xuan Ren,Hu Wei,Ze Xu*

Main category: cs.AI

TL;DR: 作者提出了ReasoningMath-Plus基准测试，包含150个精心设计的问题，专门评估结构性推理能力，并引入HCRS评分系统和PRM过程奖励模型，发现仅看最终答案会高估模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在数学推理基准测试上接近饱和准确率，但这主要源于现有数据集过度依赖模板化计算和浅层算术分解，未能真正评估多约束协调、构造性逻辑合成和空间推理等核心推理能力。

Method: 1) 创建ReasoningMath-Plus基准测试，包含150个强调交互约束、构造性解形成和非平凡结构洞察的问题；2) 引入HCRS（危险感知链式规则评分）确定性步骤级评分函数；3) 基于标注的推理轨迹训练过程奖励模型（PRM）。

Result: 领先模型在最终答案准确率上可达5.8/10，但基于HCRS的整体评估得分显著更低（平均4.36/10，最佳5.14/10），表明仅依赖答案指标会高估推理的鲁棒性。

Conclusion: 需要更精细的过程级评估方法来准确衡量语言模型的真实推理能力，仅看最终答案会掩盖推理过程中的缺陷，HCRS和PRM提供了更全面的评估框架。

Abstract: Recent large language models (LLMs) achieve near-saturation accuracy on many established mathematical reasoning benchmarks, raising concerns about their ability to diagnose genuine reasoning competence. This saturation largely stems from the dominance of template-based computation and shallow arithmetic decomposition in existing datasets, which underrepresent reasoning skills such as multi-constraint coordination, constructive logical synthesis, and spatial inference. To address this gap, we introduce ReasoningMath-Plus, a benchmark of 150 carefully curated problems explicitly designed to evaluate structural reasoning. Each problem emphasizes reasoning under interacting constraints, constructive solution formation, or non-trivial structural insight, and is annotated with a minimal reasoning skeleton to support fine-grained process-level evaluation. Alongside the dataset, we introduce HCRS (Hazard-aware Chain-based Rule Score), a deterministic step-level scoring function, and train a Process Reward Model (PRM) on the annotated reasoning traces. Empirically, while leading models attain relatively high final-answer accuracy (up to 5.8/10), HCRS-based holistic evaluation yields substantially lower scores (average 4.36/10, best 5.14/10), showing that answer-only metrics can overestimate reasoning robustness.

</details>


### [481] [Learning Modal-Mixed Chain-of-Thought Reasoning with Latent Embeddings](https://arxiv.org/abs/2602.00574)
*Yifei Shao,Kun Zhou,Ziming Xu,Mohammad Atif Quamar,Shibo Hao,Zhen Wang,Zhiting Hu,Biwei Huang*

Main category: cs.AI

TL;DR: 提出modal-mixed CoT方法，在思维链中交替使用文本标记和视觉草图潜在嵌入，以处理视觉密集型多模态推理问题。


<details>
  <summary>Details</summary>
Motivation: 传统文本形式的思维链在处理视觉密集型问题时存在局限，因为关键中间状态本质上是视觉的，需要超越纯文本的多模态推理方法。

Method: 使用VLM自身作为编码器，训练语言骨干重建其视觉嵌入以保证语义对齐；附加基于扩散的潜在解码器，由特殊控制令牌调用并基于VLM隐藏状态进行条件生成；采用两阶段训练：监督微调结合下一个令牌和潜在重建目标，然后进行强化学习。

Result: 在11个多样化多模态推理任务上的广泛实验表明，该方法优于纯语言和其他思维链方法。

Conclusion: modal-mixed CoT通过视觉-文本交替的思维链，有效处理视觉密集型多模态推理问题，实现了更好的性能表现。

Abstract: We study how to extend chain-of-thought (CoT) beyond language to better handle multimodal reasoning. While CoT helps LLMs and VLMs articulate intermediate steps, its text-only form often fails on vision-intensive problems where key intermediate states are inherently visual. We introduce modal-mixed CoT, which interleaves textual tokens with compact visual sketches represented as latent embeddings. To bridge the modality gap without eroding the original knowledge and capability of the VLM, we use the VLM itself as an encoder and train the language backbone to reconstruct its own intermediate vision embeddings, to guarantee the semantic alignment of the visual latent space. We further attach a diffusion-based latent decoder, invoked by a special control token and conditioned on hidden states from the VLM. In this way, the diffusion head carries fine-grained perceptual details while the VLM specifies high-level intent, which cleanly disentangles roles and reduces the optimization pressure of the VLM. Training proceeds in two stages: supervised fine-tuning on traces that interleave text and latents with a joint next-token and latent-reconstruction objective, followed by reinforcement learning that teaches when to switch modalities and how to compose long reasoning chains. Extensive experiments across 11 diverse multimodal reasoning tasks, demonstrate that our method yields better performance than language-only and other CoT methods. Our code will be publicly released.

</details>


### [482] [Small Shifts, Large Gains: Unlocking Traditional TSP Heuristic Guided-Sampling via Unsupervised Neural Instance Modification](https://arxiv.org/abs/2602.00580)
*Wei Huang,Hanchen Wang,Dong Wen,Wenjie Zhang*

Main category: cs.AI

TL;DR: TSP-MDF：一种通过神经实例修改器移动节点坐标，使传统确定性启发式TSP求解器具备引导采样能力，无需真实监督训练的新框架


<details>
  <summary>Details</summary>
Motivation: 传统启发式TSP求解器（如最远/最近插入法）计算高效但确定性行为导致局部最优；神经启发式求解器质量更好但需要大量训练和真实监督，实用性受限。需要结合两者优势。

Method: 提出TSP-MDF框架：使用神经实例修改器策略性地移动节点坐标生成多个修改实例，在这些实例上运行传统启发式求解器，然后将解映射回原始实例，使传统求解器能探索更优解并逃离局部最优。

Result: 在大规模TSP基准和真实世界基准上的实验表明，TSP-MDF显著提升了传统启发式求解器的性能，达到与神经启发式求解器相当的求解质量，且训练时间极短。

Conclusion: TSP-MDF成功地将神经引导采样能力赋予传统确定性启发式求解器，无需真实监督训练，在保持实用性的同时显著提升求解质量，为传统启发式方法提供了新的增强途径。

Abstract: The Traveling Salesman Problem (TSP) is one of the most representative NP-hard problems in route planning and a long-standing benchmark in combinatorial optimization. Traditional heuristic tour constructors, such as Farthest or Nearest Insertion, are computationally efficient and highly practical, but their deterministic behavior limits exploration and often leads to local optima. In contrast, neural-based heuristic tour constructors alleviate this issue through guided-sampling and typically achieve superior solution quality, but at the cost of extensive training and reliance on ground-truth supervision, hindering their practical use. To bridge this gap, we propose TSP-MDF, a novel instance modification framework that equips traditional deterministic heuristic tour constructors with guided-sampling capability. Specifically, TSP-MDF introduces a neural-based instance modifier that strategically shifts node coordinates to sample multiple modified instances, on which the base traditional heuristic tour constructor constructs tours that are mapped back to the original instance, allowing traditional tour constructors to explore higher-quality tours and escape local optima. At the same time, benefiting from our instance modification formulation, the neural-based instance modifier can be trained efficiently without any ground-truth supervision, ensuring the framework maintains practicality. Extensive experiments on large-scale TSP benchmarks and real-world benchmarks demonstrate that TSP-MDF significantly improves the performance of traditional heuristics tour constructors, achieving solution quality comparable to neural-based heuristic tour constructors, but with an extremely short training time.

</details>


### [483] [Exploring Information Seeking Agent Consolidation](https://arxiv.org/abs/2602.00585)
*Guochen Yan,Jialong Wu,Zhengwei Tao,Bo Li,Qintong Zhang,Jiahao Xu,Haitao Mi,Yuejian Fang,Qingni Shen,Wentao Zhang,Zhonghai Wu*

Main category: cs.AI

TL;DR: 该论文研究了如何将异构信息检索智能体整合为单一基础智能体模型，比较了数据级整合和参数级整合两种策略，发现数据级整合更稳定，参数级整合虽高效但存在干扰问题。


<details>
  <summary>Details</summary>
Motivation: 现有信息检索智能体通常专门针对开放网络、文档或本地知识库，这限制了可扩展性和跨领域泛化能力。需要研究如何将异构信息检索智能体整合为单一基础智能体模型。

Method: 研究了两种互补的整合策略：1) 数据级整合 - 在混合领域特定数据集上联合训练统一模型；2) 参数级整合 - 在参数层面合并独立训练的智能体模型。分析比较了这两种方法在性能保持、跨领域泛化和行为干扰方面的表现。

Result: 数据级整合仍然是强大且稳定的基线方法，而参数级整合提供了有前景的高效替代方案，但存在干扰和鲁棒性挑战。确定了参数级智能体整合的关键设计因素，包括细粒度合并粒度、任务异构性感知和原则性共识策略。

Conclusion: 研究为异构信息检索智能体的整合提供了重要见解，数据级整合更可靠，参数级整合需要进一步改进设计因素以解决干扰问题，为构建更通用的基础智能体模型指明了方向。

Abstract: Information-seeking agents have emerged as a powerful paradigm for solving knowledge-intensive tasks. Existing information-seeking agents are typically specialized for open web, documents, or local knowledge bases, which constrains scalability and cross-domain generalization. In this work, we investigate how to consolidate heterogeneous information-seeking agents into a single foundation agentic model. We study two complementary consolidation strategies: data-level consolidation, which jointly trains a unified model on a mixture of domain-specific datasets, and parameter-level consolidation, which merges independently trained agent models at the parameter level. Our analysis compares these approaches in terms of performance retention, cross-domain generalization, and interference across information-seeking behaviors. Our results show that data-level consolidation remains a strong and stable baseline, while parameter-level consolidation offers a promising, efficient alternative but suffers from interference and robustness challenges. We further identify key design factors for effective agent consolidation at the parameter level, including fine-grained merging granularity, awareness of task heterogeneity, and principled consensus strategy.

</details>


### [484] [DockSmith: Scaling Reliable Coding Environments via an Agentic Docker Builder](https://arxiv.org/abs/2602.00592)
*Jiaran Zhang,Luck Ma,Yanhao Li,Fanqi Wan,Di Qi,Xu Zhao,Jieyi Hou,Zhe Xie,Mengqiang Ren,Xin Wu,Zhewei Huang,Liangyu Chen,Yingwei Ma,Qi Han,Xiangyu Zhang*

Main category: cs.AI

TL;DR: DockSmith是一个专门用于Docker环境构建的智能代理，通过将环境构建视为核心智能能力而非预处理步骤，解决了软件工程代理训练和评估中的瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 基于Docker的环境构建是扩展软件工程代理执行基础训练和评估的主要瓶颈。传统方法将环境构建视为预处理步骤，但作者认为这应该是一个核心的智能能力，涉及长期工具使用、依赖推理和故障恢复。

Method: 开发了DockSmith智能Docker构建代理，使用增强的SWE-Factory风格流水线生成大规模执行基础的Docker构建轨迹，包含循环检测控制器和跨任务成功记忆。训练了一个30B-A3B模型来处理这些轨迹。

Result: 在Multi-Docker-Eval上达到开源最先进性能：39.72%的Fail-to-Pass率和58.28%的提交率。在SWE-bench Verified、SWE-bench Multilingual和Terminal-Bench 2.0等分布外任务上也表现出改进性能。

Conclusion: DockSmith不仅解决了Docker环境构建的瓶颈问题，还展示了环境构建作为核心智能能力的更广泛价值，其监督信号能够迁移到Docker构建之外的智能任务中。

Abstract: Reliable Docker-based environment construction is a dominant bottleneck for scaling execution-grounded training and evaluation of software engineering agents. We introduce DockSmith, a specialized agentic Docker builder designed to address this challenge. DockSmith treats environment construction not only as a preprocessing step, but as a core agentic capability that exercises long-horizon tool use, dependency reasoning, and failure recovery, yielding supervision that transfers beyond Docker building itself. DockSmith is trained on large-scale, execution-grounded Docker-building trajectories produced by a SWE-Factory-style pipeline augmented with a loop-detection controller and a cross-task success memory. Training a 30B-A3B model on these trajectories achieves open-source state-of-the-art performance on Multi-Docker-Eval, with 39.72% Fail-to-Pass and 58.28% Commit Rate. Moreover, DockSmith improves out-of-distribution performance on SWE-bench Verified, SWE-bench Multilingual, and Terminal-Bench 2.0, demonstrating broader agentic benefits of environment construction.

</details>


### [485] [Scalable Generative Game Engine: Breaking the Resolution Wall via Hardware-Algorithm Co-Design](https://arxiv.org/abs/2602.00608)
*Wei Zeng,Xuchen Li,Ruili Feng,Zhen Liu,Fengwei An,Jian Zhao*

Main category: cs.AI

TL;DR: 提出硬件算法协同设计框架，解决生成式游戏引擎的"内存墙"问题，实现720×480分辨率实时生成，比基线提升50倍像素吞吐量


<details>
  <summary>Details</summary>
Motivation: 现有实时生成式游戏引擎受限于"内存墙"，只能支持低分辨率（如64×64），需要突破这一限制以实现高分辨率神经模拟

Method: 提出异构架构，将计算密集型的世界模型和内存密集型的解码器解耦到AI加速器集群上，包含三个核心创新：非对称资源分配策略、内存中心算子融合方案、流形感知潜在外推机制

Result: 在可编程AI加速器集群上验证，实现720×480分辨率实时生成，比基线提升50倍像素吞吐量，在3D赛车和2D平台游戏中分别达到26.4 FPS和48.3 FPS，摊销有效延迟为2.7毫秒

Conclusion: 通过架构协同设计解决"内存墙"不仅是优化，更是实现高保真、响应式神经游戏体验的先决条件

Abstract: Real-time generative game engines represent a paradigm shift in interactive simulation, promising to replace traditional graphics pipelines with neural world models. However, existing approaches are fundamentally constrained by the ``Memory Wall,'' restricting practical deployments to low resolutions (e.g., $64 \times 64$). This paper bridges the gap between generative models and high-resolution neural simulations by introducing a scalable \textit{Hardware-Algorithm Co-Design} framework. We identify that high-resolution generation suffers from a critical resource mismatch: the World Model is compute-bound while the Decoder is memory-bound. To address this, we propose a heterogeneous architecture that intelligently decouples these components across a cluster of AI accelerators. Our system features three core innovations: (1) an asymmetric resource allocation strategy that optimizes throughput under sequence parallelism constraints; (2) a memory-centric operator fusion scheme that minimizes off-chip bandwidth usage; and (3) a manifold-aware latent extrapolation mechanism that exploits temporal redundancy to mask latency. We validate our approach on a cluster of programmable AI accelerators, enabling real-time generation at $720 \times 480$ resolution -- a $50\times$ increase in pixel throughput over prior baselines. Evaluated on both continuous 3D racing and discrete 2D platformer benchmarks, our system delivers fluid 26.4 FPS and 48.3 FPS respectively, with an amortized effective latency of 2.7 ms. This work demonstrates that resolving the ``Memory Wall'' via architectural co-design is not merely an optimization, but a prerequisite for enabling high-fidelity, responsive neural gameplay.

</details>


### [486] [Structured Self-Consistency:A Multi-Task Evaluation of LLMs on VirtualHome](https://arxiv.org/abs/2602.00611)
*Jiaqi Xu,Tao Huang,Kai Zhang*

Main category: cs.AI

TL;DR: 该论文评估了两种7B参数大语言模型在虚拟家庭环境中的表现，提出了结构化自一致性解码策略，发现不同模型在分层规划和动作级任务上各有优势。


<details>
  <summary>Details</summary>
Motivation: 为了评估大语言模型在具身AI任务中的能力，特别是在虚拟家庭环境中的目标理解、动作规划和任务执行能力，需要系统性的评估框架和方法。

Method: 使用VirtualHome基准和Embodied Agent Interface框架，比较OPENPANGU-7B和QWEN2.5-7B两种模型在四个基本任务上的表现，并提出结构化自一致性解码策略来提升结构化生成任务的质量。

Result: 结构化自一致性解码策略显著提升了性能，OPENPANGU-7B在分层规划任务上表现优异，而QWEN2.5-7B在动作级任务上具有优势，两种模型展现出互补的优势。

Conclusion: 不同的大语言模型在具身AI任务中具有不同的优势，结构化自一致性解码策略能有效提升性能，这为未来具身AI系统开发提供了重要见解。

Abstract: Embodied AI requires agents to understand goals, plan actions, and execute tasks in simulated environments.We present a comprehensive evaluation of Large Language Models (LLMs) on the VirtualHome benchmark using the Embodied Agent Interface (EAI) framework.We compare two representative 7B-parameter models OPENPANGU-7B and QWEN2.5-7B across four fundamental tasks: Goal Interpretation, Action Sequencing, Subgoal Decomposition, and Transition Modeling.We propose Structured Self-Consistency (SSC), an enhanced decoding strategy that leverages multiple sampling with domain-specific voting mechanisms to improve output quality for structured generation tasks. Experimental results demonstrate that SSC significantly enhances performance, with OPENPANGU-7B excelling at hierarchical planning while QWEN2.5-7B show advantages in action-level tasks. Our analysis reveals complementary strengths across model types, providing insights for future embodied AI system development.

</details>


### [487] [Inference-Only Prompt Projection for Safe Text-to-Image Generation with TV Guarantees](https://arxiv.org/abs/2602.00616)
*Minhyuk Lee,Hyekyung Yoon,Myungjoo Kang*

Main category: cs.AI

TL;DR: 提出一个基于总变差理论的文本到图像生成安全框架，通过推理阶段的提示投影在保持良性提示对齐的同时减少不安全生成


<details>
  <summary>Details</summary>
Motivation: 文本到图像扩散模型需要安全防护来抑制不安全生成，但现有方法往往损害良性提示的图像对齐质量，需要解决这种安全与对齐的权衡问题

Method: 基于总变差理论提出安全-提示对齐权衡框架，采用推理阶段的提示投影方法，对高风险提示进行选择性干预，将其映射到容忍度控制的安集中，无需重新训练或微调生成器

Result: 在四个数据集和三个扩散骨干网络上，相比强基线方法，该方法将不当生成百分比相对降低了16.7-60.0%，同时在COCO数据集上保持了接近未对齐参考的良性提示图像对齐

Conclusion: 该工作从理论角度形式化了文本到图像生成中的安全与对齐权衡问题，并提出了一种有效的推理阶段干预方法，在显著提升安全性的同时保持了良好的图像质量

Abstract: Text-to-Image (T2I) diffusion models enable high-quality open-ended synthesis, but their real-world deployment demands safeguards that suppress unsafe generations without degrading benign prompt-image alignment. We formalize this tension through a total variation (TV) lens: once the reference conditional distribution is fixed, any nontrivial reduction in unsafe generations necessarily incurs TV deviation from the reference, yielding a principled Safety-Prompt Alignment Trade-off (SPAT). Guided by this view, we propose an inference-only prompt projection framework that selectively intervenes on high-risk prompts via a surrogate objective with verification, mapping them into a tolerance-controlled safe set while leaving benign prompts effectively unchanged, without retraining or fine-tuning the generator. Across four datasets and three diffusion backbones, our approach achieves 16.7-60.0% relative reductions in inappropriate percentage (IP) versus strong model-level alignment baselines, while preserving benign prompt-image alignment on COCO near the unaligned reference.

</details>


### [488] [Predictive Maintenance for Ultrafiltration Membranes Using Explainable Similarity-Based Prognostics](https://arxiv.org/abs/2602.00659)
*Qusai Khaled,Laura Genga,Uzay Kaymak*

Main category: cs.AI

TL;DR: 提出基于模糊相似推理的可解释超滤膜剩余使用寿命预测框架，通过物理信息健康指标和透明规则实现可信预测


<details>
  <summary>Details</summary>
Motivation: 反渗透海水淡化中超滤膜因污染导致性能下降，现有预测维护模型缺乏可解释性，操作人员不信任，需要透明可靠的预测方法

Method: 使用基于跨膜压力、通量和阻力的物理信息健康指标，通过高斯隶属函数模糊化，采用相似性度量匹配历史退化轨迹，以Takagi-Sugeno模糊规则形式进行RUL预测

Result: 在工业规模超滤系统的12,528个运行周期上测试，平均绝对误差为4.50个周期，同时生成与专家理解一致的可解释规则库

Conclusion: 提出的可解释预后框架在保持高精度的同时提供透明预测，增强了操作人员信任，为超滤膜维护决策提供了可靠工具

Abstract: In reverse osmosis desalination, ultrafiltration (UF) membranes degrade due to fouling, leading to performance loss and costly downtime. Most plants rely on scheduled preventive maintenance, since existing predictive maintenance models, often based on opaque machine learning methods, lack interpretability and operator trust. This study proposes an explainable prognostic framework for UF membrane remaining useful life (RUL) estimation using fuzzy similarity reasoning. A physics-informed Health Index, derived from transmembrane pressure, flux, and resistance, captures degradation dynamics, which are then fuzzified via Gaussian membership functions. Using a similarity measure, the model identifies historical degradation trajectories resembling the current state and formulates RUL predictions as Takagi-Sugeno fuzzy rules. Each rule corresponds to a historical exemplar and contributes to a transparent, similarity-weighted RUL estimate. Tested on 12,528 operational cycles from an industrial-scale UF system, the framework achieved a mean absolute error of 4.50 cycles, while generating interpretable rule bases consistent with expert understanding.

</details>


### [489] [SEISMO: Increasing Sample Efficiency in Molecular Optimization with a Trajectory-Aware LLM Agent](https://arxiv.org/abs/2602.00663)
*Fabian P. Krüger,Andrea Hunklinger,Adrian Wolny,Tim J. Adler,Igor Tetko,Santiago David Villalba*

Main category: cs.AI

TL;DR: SEISMO是一个基于LLM的在线分子优化代理，通过单步更新和轨迹条件化实现高效分子设计，在23个任务上比现有方法性能提升2-3倍


<details>
  <summary>Details</summary>
Motivation: 分子优化在药物发现等化学科学中至关重要，但传统方法依赖昂贵的实验评估（如生物测定），需要极高的样本效率。现有方法通常需要批量学习或群体优化，不够灵活高效。

Method: SEISMO是一个严格在线的LLM代理，每次oracle调用后立即更新，无需群体学习。它将自然语言任务描述与标量分数结合，当可用时还加入结构化解释反馈，每个分子提案都基于完整的优化轨迹进行条件化。

Result: 在Practical Molecular Optimization基准的23个任务上，SEISMO的优化曲线下面积比现有方法高2-3倍，通常只需50次oracle调用就能达到接近最大任务分数。在药物化学任务中，提供解释性反馈能进一步提高效率。

Conclusion: 利用领域知识和结构化信息是实现样本高效分子优化的关键。SEISMO展示了在线、推理时优化的有效性，为药物发现等需要昂贵实验评估的领域提供了有前景的解决方案。

Abstract: Optimizing the structure of molecules to achieve desired properties is a central bottleneck across the chemical sciences, particularly in the pharmaceutical industry where it underlies the discovery of new drugs. Since molecular property evaluation often relies on costly and rate-limited oracles, such as experimental assays, molecular optimization must be highly sample-efficient. To address this, we introduce SEISMO, an LLM agent that performs strictly online, inference-time molecular optimization, updating after every oracle call without the need for population-based or batched learning. SEISMO conditions each proposal on the full optimization trajectory, combining natural-language task descriptions with scalar scores and, when available, structured explanatory feedback. Across the Practical Molecular Optimization benchmark of 23 tasks, SEISMO achieves a 2-3 times higher area under the optimisation curve than prior methods, often reaching near-maximal task scores within 50 oracle calls. Our additional medicinal-chemistry tasks show that providing explanatory feedback further improves efficiency, demonstrating that leveraging domain knowledge and structured information is key to sample-efficient molecular optimization.

</details>


### [490] [OpenGuanDan: A Large-Scale Imperfect Information Game Benchmark](https://arxiv.org/abs/2602.00676)
*Chao Li,Shangdong Yang,Chiheng Zhan,Zhenxing Ge,Yujing Hu,Bingkun Bao,Xingguo Chen,Yang Gao*

Main category: cs.AI

TL;DR: OpenGuanDan是一个用于评估AI智能体在掼蛋（四人多轮中国纸牌游戏）中表现的新基准，包含高效模拟和全面评估功能，为多智能体决策研究提供挑战性测试平台。


<details>
  <summary>Details</summary>
Motivation: 尽管AI在棋牌游戏等领域取得了显著进展，但仍需要更具挑战性的基准来推动进一步研究。掼蛋游戏具有不完美信息、大规模信息集、合作与竞争混合目标、长时程决策等复杂特性，是理想的测试平台。

Method: 开发了OpenGuanDan基准，支持掼蛋游戏的高效模拟和AI智能体评估。每个玩家都有独立API，支持人机交互和大语言模型集成。进行了两种评估：1）所有AI智能体之间的两两对抗；2）人机对战。

Result: 实验结果显示，当前基于学习的智能体明显优于基于规则的智能体，但仍未达到超人类水平。这表明在多智能体智能决策领域仍需继续研究。

Conclusion: OpenGuanDan为多智能体决策研究提供了一个具有挑战性的基准测试平台，其复杂特性对现有智能决策方法提出了严峻考验，有助于推动该领域的进一步发展。

Abstract: The advancement of data-driven artificial intelligence (AI), particularly machine learning, heavily depends on large-scale benchmarks. Despite remarkable progress across domains ranging from pattern recognition to intelligent decision-making in recent decades, exemplified by breakthroughs in board games, card games, and electronic sports games, there remains a pressing need for more challenging benchmarks to drive further research. To this end, this paper proposes OpenGuanDan, a novel benchmark that enables both efficient simulation of GuanDan (a popular four-player, multi-round Chinese card game) and comprehensive evaluation of both learning-based and rule-based GuanDan AI agents. OpenGuanDan poses a suite of nontrivial challenges, including imperfect information, large-scale information set and action spaces, a mixed learning objective involving cooperation and competition, long-horizon decision-making, variable action spaces, and dynamic team composition. These characteristics make it a demanding testbed for existing intelligent decision-making methods. Moreover, the independent API for each player allows human-AI interactions and supports integration with large language models. Empirically, we conduct two types of evaluations: (1) pairwise competitions among all GuanDan AI agents, and (2) human-AI matchups. Experimental results demonstrate that while current learning-based agents substantially outperform rule-based counterparts, they still fall short of achieving superhuman performance, underscoring the need for continued research in multi-agent intelligent decision-making domain. The project is publicly available at https://github.com/GameAI-NJUPT/OpenGuanDan.

</details>


### [491] [HumanStudy-Bench: Towards AI Agent Design for Participant Simulation](https://arxiv.org/abs/2602.00685)
*Xuan Liu,Haoyang Shang,Zizhang Liu,Xinyan Liu,Yunze Xiao,Yiwen Tu,Haojian Jin*

Main category: cs.AI

TL;DR: 该论文提出HUMANSTUDY-BENCH基准测试框架，用于评估LLM作为社会科学实验模拟参与者的表现，通过重现已发表的人类实验来量化LLM代理与人类行为的一致性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM作为社会科学实验模拟参与者存在行为不稳定、对设计选择敏感的问题，且现有评估常混淆基础模型能力与实验实例化，难以确定结果反映的是模型本身还是代理设置。

Method: 将参与者模拟定义为完整实验协议上的代理设计问题，提出HUMANSTUDY-BENCH基准测试和执行引擎，采用Filter-Extract-Execute-Evaluate管道，在共享运行时中重现实验流程并运行原始统计分析。

Result: 构建了包含12项基础研究的动态基准测试套件，涵盖个体认知、战略互动和社会心理学领域，包含超过6,000次试验，人类样本规模从数十人到2,100多人不等。

Conclusion: 该研究为评估LLM在社会科学实验中的模拟能力提供了系统化框架，能够量化代理与人类行为的一致性，有助于更准确地理解和使用LLM作为实验参与者。

Abstract: Large language models (LLMs) are increasingly used as simulated participants in social science experiments, but their behavior is often unstable and highly sensitive to design choices. Prior evaluations frequently conflate base-model capabilities with experimental instantiation, obscuring whether outcomes reflect the model itself or the agent setup. We instead frame participant simulation as an agent-design problem over full experimental protocols, where an agent is defined by a base model and a specification (e.g., participant attributes) that encodes behavioral assumptions. We introduce HUMANSTUDY-BENCH, a benchmark and execution engine that orchestrates LLM-based agents to reconstruct published human-subject experiments via a Filter--Extract--Execute--Evaluate pipeline, replaying trial sequences and running the original analysis pipeline in a shared runtime that preserves the original statistical procedures end to end. To evaluate fidelity at the level of scientific inference, we propose new metrics to quantify how much human and agent behaviors agree. We instantiate 12 foundational studies as an initial suite in this dynamic benchmark, spanning individual cognition, strategic interaction, and social psychology, and covering more than 6,000 trials with human samples ranging from tens to over 2,100 participants.

</details>


### [492] [From Prompt to Graph: Comparing LLM-Based Information Extraction Strategies in Domain-Specific Ontology Development](https://arxiv.org/abs/2602.00699)
*Xuan Liu,Ziyu Li,Mu He,Ziyang Ma,Xiaoxu Wu,Gizem Yilmaz,Yiyuan Xia,Bingbing Li,He Tan,Jerry Ying Hsi Fuh,Wen Feng Lu,Anders E. W. Jarfors,Per Jansson*

Main category: cs.AI

TL;DR: 该研究探索了三种基于大语言模型的方法来自动化铸造制造领域本体的构建，比较了预训练LLM驱动、上下文学习和微调方法，并利用最佳方法构建了专家验证的本体。


<details>
  <summary>Details</summary>
Motivation: 传统本体构建依赖人工标注和传统NLP技术，过程劳动密集且成本高昂，特别是在铸造制造等专业领域。大语言模型的兴起为自动化知识提取提供了新可能性。

Method: 研究了三种LLM方法：预训练LLM驱动方法、上下文学习方法（ICL）和微调方法，用于从领域特定文本中提取术语和关系，使用有限数据。

Result: 比较了三种方法的性能，并利用最佳性能方法构建了铸造本体，该本体经过领域专家验证。

Conclusion: LLM方法能够有效自动化领域本体构建，特别是在数据有限的专业领域，为传统劳动密集型本体构建提供了可行的替代方案。

Abstract: Ontologies are essential for structuring domain knowledge, improving accessibility, sharing, and reuse. However, traditional ontology construction relies on manual annotation and conventional natural language processing (NLP) techniques, making the process labour-intensive and costly, especially in specialised fields like casting manufacturing. The rise of Large Language Models (LLMs) offers new possibilities for automating knowledge extraction. This study investigates three LLM-based approaches, including pre-trained LLM-driven method, in-context learning (ICL) method and fine-tuning method to extract terms and relations from domain-specific texts using limited data. We compare their performances and use the best-performing method to build a casting ontology that validated by domian expert.

</details>


### [493] [Self-Guard: Defending Large Reasoning Models via enhanced self-reflection](https://arxiv.org/abs/2602.00707)
*Jingnan Zheng,Jingjun Xu,Yanzhen Luo,Chenhang Cui,Gelei Deng,Zhenkai Liang,Xiang Wang,An Zhang,Tat-Seng Chua*

Main category: cs.AI

TL;DR: Self-Guard：一个轻量级安全防御框架，通过安全导向提示和安全激活引导，在表示层面增强大型推理模型的安全合规性，解决认知-合规差距问题。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（LRMs）虽然带来了显著的推理能力进步，但也引入了推理操纵和信息泄露等独特风险。现有的对齐策略主要依赖繁重的后训练范式或外部干预，这些方法计算成本高，且未能解决模型认知风险但优先遵循用户指令的认知-合规差距问题。

Method: Self-Guard框架包含两个主要阶段：1）安全导向提示：激活模型的潜在安全意识，引发自发反思；2）安全激活引导：提取隐藏状态空间中的方向性变化并放大，确保在推理过程中安全合规性优先于顺从性。

Result: 实验表明Self-Guard有效弥合了认知-合规差距，在不损害模型实用性的情况下实现了强大的安全性能。该框架在不同未见风险和不同模型规模上表现出良好的泛化能力。

Conclusion: Self-Guard为LRM安全对齐提供了一个成本高效的解决方案，通过轻量级的表示层面干预，解决了现有方法计算密集且无法处理认知-合规差距的问题。

Abstract: The emergence of Large Reasoning Models (LRMs) introduces a new paradigm of explicit reasoning, enabling remarkable advances yet posing unique risks such as reasoning manipulation and information leakage. To mitigate these risks, current alignment strategies predominantly rely on heavy post-training paradigms or external interventions. However, these approaches are often computationally intensive and fail to address the inherent awareness-compliance gap, a critical misalignment where models recognize potential risks yet prioritize following user instructions due to their sycophantic tendencies. To address these limitations, we propose Self-Guard, a lightweight safety defense framework that reinforces safety compliance at the representational level. Self-Guard operates through two principal stages: (1) safety-oriented prompting, which activates the model's latent safety awareness to evoke spontaneous reflection, and (2) safety activation steering, which extracts the resulting directional shift in the hidden state space and amplifies it to ensure that safety compliance prevails over sycophancy during inference. Experiments demonstrate that Self-Guard effectively bridges the awareness-compliance gap, achieving robust safety performance without compromising model utility. Furthermore, Self-Guard exhibits strong generalization across diverse unseen risks and varying model scales, offering a cost-efficient solution for LRM safety alignment.

</details>


### [494] [Physics-informed Diffusion Generation for Geomagnetic Map Interpolation](https://arxiv.org/abs/2602.00709)
*Wenda Li,Tongya Zheng,Kaixuan Chen,Shunyu Liu,Haoze Jiang,Yunzhi Hao,Rui Miao,Zujie Ren,Mingli Song,Hang Shi,Gang Chen*

Main category: cs.AI

TL;DR: 提出PDG框架，通过物理信息引导的扩散生成模型进行地磁地图插值，结合局部感受野和克里金原理约束，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有散点数据插值方法未专门针对地磁地图设计，受检测噪声和物理规律影响导致性能不佳，需要专门的地磁地图插值方法。

Method: 提出物理信息扩散生成框架(PDG)：1) 基于局部感受野设计物理信息掩码策略指导扩散生成过程，消除噪声干扰；2) 根据地磁地图克里金原理对扩散生成结果施加物理信息约束，确保符合物理规律。

Result: 在四个真实世界数据集上的大量实验和深入分析证明了PDG的优越性和各组成部分的有效性。

Conclusion: PDG框架通过物理信息引导的扩散生成方法，能够有效处理地磁地图插值问题，在导航和资源勘探等应用中具有重要价值。

Abstract: Geomagnetic map interpolation aims to infer unobserved geomagnetic data at spatial points, yielding critical applications in navigation and resource exploration. However, existing methods for scattered data interpolation are not specifically designed for geomagnetic maps, which inevitably leads to suboptimal performance due to detection noise and the laws of physics. Therefore, we propose a Physics-informed Diffusion Generation framework~(PDG) to interpolate incomplete geomagnetic maps. First, we design a physics-informed mask strategy to guide the diffusion generation process based on a local receptive field, effectively eliminating noise interference. Second, we impose a physics-informed constraint on the diffusion generation results following the kriging principle of geomagnetic maps, ensuring strict adherence to the laws of physics. Extensive experiments and in-depth analyses on four real-world datasets demonstrate the superiority and effectiveness of each component of PDG.

</details>


### [495] [Learning More from Less: Unlocking Internal Representations for Benchmark Compression](https://arxiv.org/abs/2602.00710)
*Yueqi Zhang,Jin Hu,Shaoxiong Feng,Peiwen Yuan,Xinglin Wang,Yiwei Li,Jiayi Shi,Chuyi Tan,Ji Zhang,Boyuan Pan,Yao Hu,Kan Li*

Main category: cs.AI

TL;DR: REPCORE：通过对齐隐藏状态构建核心集，仅需少量源模型即可准确估计LLM基准性能，解决了传统方法依赖大量历史数据的限制。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型成本高昂，现有核心集方法需要大量源模型来估计可靠的项配置文件，这在源模型池较小时统计不稳定，尤其限制了新发布基准的应用。

Method: 提出REPCORE方法，将异构隐藏状态对齐到统一潜在空间来构建代表性核心集，利用这些子集进行性能外推，仅需少量源模型即可实现精确估计。

Result: 在5个基准和200多个模型上的实验显示，REPCORE在排名相关性和估计准确性方面持续优于基于输出的基线方法，仅需10个源模型即可实现精确估计。

Conclusion: REPCORE通过利用隐藏状态信息而非离散正确性标签，解决了小源模型池下的基准性能估计问题，光谱分析表明对齐表示包含反映广泛响应趋势和任务特定推理模式的可分离组件。

Abstract: The prohibitive cost of evaluating Large Language Models (LLMs) necessitates efficient alternatives to full-scale benchmarking. Prevalent approaches address this by identifying a small coreset of items to approximate full-benchmark performance. However, existing methods must estimate a reliable item profile from response patterns across many source models, which becomes statistically unstable when the source pool is small. This dependency is particularly limiting for newly released benchmarks with minimal historical evaluation data. We argue that discrete correctness labels are a lossy view of the model's decision process and fail to capture information encoded in hidden states. To address this, we introduce REPCORE, which aligns heterogeneous hidden states into a unified latent space to construct representative coresets. Using these subsets for performance extrapolation, REPCORE achieves precise estimation accuracy with as few as ten source models. Experiments on five benchmarks and over 200 models show consistent gains over output-based baselines in ranking correlation and estimation accuracy. Spectral analysis further indicates that the aligned representations contain separable components reflecting broad response tendencies and task-specific reasoning patterns.

</details>


### [496] [Neuro-symbolic AI for Predictive Maintenance (PdM) -- review and recommendations](https://arxiv.org/abs/2602.00731)
*Kyle Hamilton,Ali Intizar*

Main category: cs.AI

TL;DR: 本文对过去五年工业预测性维护(PdM)进行系统综述，指出数据驱动方法精度高但存在数据需求大、泛化性差、缺乏可解释性等问题，而传统基于规则的方法则精度低、误报多。作者提出结合深度学习和符号逻辑的神经符号AI作为解决方案。


<details>
  <summary>Details</summary>
Motivation: 预测性维护在工业应用中面临挑战：纯数据驱动方法需要大量标注数据、缺乏泛化能力和可解释性；传统基于规则的方法精度低、误报多、需要持续专家维护。需要一种结合两者优势的解决方案。

Method: 对过去五年工业预测性维护文献进行系统综述，分析数据驱动方法、传统知识系统及混合方法的优缺点。重点提出神经符号AI架构，结合深度学习与符号逻辑，并描述具体使用传感器数据和手工规则的神经符号架构。

Result: 数据驱动方法（特别是深度学习）在精度上优于传统知识系统，但存在实际部署障碍。混合系统有潜力克服单一方法的弱点。神经符号AI架构能够创建更准确、可解释、可解释且鲁棒的系统。

Conclusion: 神经符号AI是预测性维护领域有前景的方向，能够结合数据驱动方法的精度和符号逻辑的可解释性、泛化能力。本文建立了通用框架，综述了当前建模方法和挑战，并提出了神经符号AI作为重点研究方向。

Abstract: In this document we perform a systematic review the State-of-the-art in Predictive Maintenance (PdM) over the last five years in industrial settings such as commercial buildings, pharmaceutical facilities, or semi-conductor manufacturing. In general, data-driven methods such as those based on deep learning, exhibit higher accuracy than traditional knowledge-based systems. These systems however, are not without significant limitations. The need for large labeled data sets, a lack of generalizibility to new environments (out-of-distribution generalization), and a lack of transparency at inference time are some of the obstacles to adoption in real world environments. In contrast, traditional approaches based on domain expertise in the form of rules, logic or first principles suffer from poor accuracy, many false positives and a need for ongoing expert supervision and manual tuning. While the majority of approaches in recent literature utilize some form of data-driven architecture, there are hybrid systems which also take into account domain specific knowledge. Such hybrid systems have the potential to overcome the weaknesses of either approach on its own while preserving their strengths. We propose taking the hybrid approach even further and integrating deep learning with symbolic logic, or Neuro-symbolic AI, to create more accurate, explainable, interpretable, and robust systems. We describe several neuro-symbolic architectures and examine their strengths and limitations within the PdM domain. We focus specifically on methods which involve the use of sensor data and manually crafted rules as inputs by describing concrete NeSy architectures. In short, this survey outlines the context of modern maintenance, defines key concepts, establishes a generalized framework, reviews current modeling approaches and challenges, and introduces the proposed focus on Neuro-symbolic AI (NESY).

</details>


### [497] [Engineering AI Agents for Clinical Workflows: A Case Study in Architecture,MLOps, and Governance](https://arxiv.org/abs/2602.00751)
*Cláudio Lúcio do Val Lopes,João Marcus Pitta,Fabiano Belém,Gildson Alves,Flávio Vinícius Cruzeiro Martins*

Main category: cs.AI

TL;DR: 论文介绍了Maria平台，这是一个用于初级医疗保健的生产级AI系统，通过整合四个工程支柱来解决临床AI中的可靠性和责任问题。


<details>
  <summary>Details</summary>
Motivation: AI在临床环境中的集成面临软件工程挑战，需要从孤立模型转向健壮、可治理和可靠的系统。工业应用中常出现脆弱、原型衍生的架构，缺乏系统性监督，导致安全性和责任性受损的"责任真空"。

Method: 提出Maria平台，整合四个工程支柱：1) Clean Architecture保证可维护性；2) 事件驱动架构确保弹性和可审计性；3) 以Agent作为主要模块化单元，每个拥有自主的MLOps生命周期；4) 人在回路治理模型作为关键的事件驱动数据源进行技术集成。

Result: 开发了Maria平台作为参考架构，为高风险领域构建可维护、可扩展和可问责的AI系统提供实用经验。

Conclusion: 可信赖的临床AI需要通过四个工程支柱的整体集成来实现，Maria平台展示了如何构建生产级AI系统来解决责任真空问题，为高风险领域的AI系统开发提供了参考架构。

Abstract: The integration of Artificial Intelligence (AI) into clinical settings presents a software engineering challenge, demanding a shift from isolated models to robust, governable, and reliable systems. However, brittle, prototype-derived architectures often plague industrial applications and a lack of systemic oversight, creating a ``responsibility vacuum'' where safety and accountability are compromised. This paper presents an industry case study of the ``Maria'' platform, a production-grade AI system in primary healthcare that addresses this gap.
  Our central hypothesis is that trustworthy clinical AI is achieved through the holistic integration of four foundational engineering pillars. We present a synergistic architecture that combines Clean Architecture for maintainability with an Event-driven architecture for resilience and auditability. We introduce the Agent as the primary unit of modularity, each possessing its own autonomous MLOps lifecycle. Finally, we show how a Human-in-the-Loop governance model is technically integrated not merely as a safety check, but as a critical, event-driven data source for continuous improvement. We present the platform as a reference architecture, offering practical lessons for engineers building maintainable, scalable, and accountable AI-enabled systems in high-stakes domains.

</details>


### [498] [Environment-Aware Adaptive Pruning with Interleaved Inference Orchestration for Vision-Language-Action Models](https://arxiv.org/abs/2602.00780)
*Yuting Huang,Leilei Ding,Zhipeng Tang,Zenghuan Zhu,Jiajun Deng,Xinrui Lin,Shuo Liu,Haojie Ren,Jianmin Ji,Yanyong Zhang*

Main category: cs.AI

TL;DR: EcoVLA是一个无需训练、即插即用的自适应剪枝框架，通过环境感知自适应剪枝和交错推理编排，在VLA模型中实现动态参数稀疏化，显著提升推理速度而性能损失极小。


<details>
  <summary>Details</summary>
Motivation: VLA模型参数庞大导致推理延迟高，影响实时操作性能。静态剪枝无法适应环境动态变化，而固定间隔的动态层剪枝粒度粗且重训练开销大，需要更精细的自适应剪枝方案。

Method: EcoVLA包含两个组件：1) 环境感知自适应剪枝(EAP)：轻量级自适应通道剪枝方法，利用物理环境的时间一致性更新稀疏模式；2) 交错推理编排(I²O)：利用VLA推理中的FLOPs气泡并行调度剪枝方法，几乎不影响延迟。

Result: 在多种VLA模型和基准测试中，EcoVLA达到最先进性能：单独使用可实现1.60倍加速且成功率仅下降0.4%；与token剪枝结合可实现2.18倍加速且性能仅下降0.5%。在真实机器人上验证了有效性。

Conclusion: EcoVLA提供了一种训练免费、即插即用的自适应剪枝框架，能够动态适应环境变化，显著提升VLA模型推理速度，同时保持高性能，并可与其他加速方法正交组合。

Abstract: While Vision-Language-Action (VLA) models hold promise in embodied intelligence, their large parameter counts lead to substantial inference latency that hinders real-time manipulation, motivating parameter sparsification. However, as the environment evolves during VLA execution, the optimal sparsity patterns change accordingly. Static pruning lacks the adaptability required for environment dynamics, whereas fixed-interval dynamic layer pruning suffers from coarse granularity and high retraining overheads. To bridge this gap, we propose EcoVLA, a training-free, plug-and-play adaptive pruning framework that supports orthogonal combination with existing VLA acceleration methods. EcoVLA comprises two components: Environment-aware Adaptive Pruning (EAP) and Interleaved Inference Orchestration ($I^2O$). EAP is a lightweight adaptive channel pruning method that incorporates the temporal consistency of the physical environment to update sparsity patterns. $I^2O$ leverages the FLOPs bubbles inherent in VLA inference to schedule the pruning method in parallel, ensuring negligible impact on latency. Evaluated on diverse VLA models and benchmarks, EcoVLA delivers state-of-the-art performance, achieving up to 1.60$\times$ speedup with only a 0.4% drop in success rate, and further reaches 2.18$\times$ speedup with only a 0.5% degradation when combined with token pruning. We further validate the effectiveness of EcoVLA on real-world robots.

</details>


### [499] [World Models as an Intermediary between Agents and the Real World](https://arxiv.org/abs/2602.00785)
*Sherry Yang*

Main category: cs.AI

TL;DR: 论文主张使用世界模型作为智能体与真实世界之间的中介，以解决高成本交互领域（如机器人、科学实验）中强化学习智能体面临的行动成本瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 当前LLM智能体在低成本环境（游戏、数学、编程）中表现出色，但在高成本交互领域（机器人、ML工程、科学实验）中难以应用，主要瓶颈在于执行行动获取奖励信号的成本过高。

Method: 提出使用世界模型作为智能体与真实世界的中介，将世界模型视为动态、奖励和任务分布的模型，以克服极端离策略学习和长时域任务样本效率低等根本障碍。

Result: 论证了世界模型可以为智能体提供关键且丰富的学习信号，适用于机器学习工程、计算机使用、机器人和AI科学等多个领域，并提出了构建世界模型的具体挑战和行动项。

Conclusion: 世界模型是解决高成本交互领域智能体性能瓶颈的关键中介，需要在数据集构建、架构设计、规模扩展和评估等方面进行系统性研究。

Abstract: Large language model (LLM) agents trained using reinforcement learning has achieved superhuman performance in low-cost environments like games, mathematics, and coding. However, these successes have not translated to complex domains where the cost of interaction is high, such as the physical cost of running robots, the time cost of ML engineering, and the resource cost of scientific experiments. The true bottleneck for achieving the next level of agent performance for these complex and high-cost domains lies in the expense of executing actions to acquire reward signals. To address this gap, this paper argues that we should use world models as an intermediary between agents and the real world. We discuss how world models, viewed as models of dynamics, rewards, and task distributions, can overcome fundamental barriers of high-cost actions such as extreme off-policy learning and sample inefficiency in long-horizon tasks. Moreover, we demonstrate how world models can provide critical and rich learning signals to agents across a broad set of domains, including machine learning engineering, computer use, robotics, and AI for science. Lastly, we identify the challenges of building these world models and propose actionable items along dataset curation, architecture design, scaling, and evaluation of world models.

</details>


### [500] [MissMAC-Bench: Building Solid Benchmark for Missing Modality Issue in Robust Multimodal Affective Computing](https://arxiv.org/abs/2602.00811)
*Ronghao Lin,Honghao Lu,Ruixing Wu,Aolin Xiong,Qinggong Chu,Qiaolin He,Sijie Mai,Haifeng Hu*

Main category: cs.AI

TL;DR: 提出MissMAC-Bench基准，系统评估多模态情感计算中的模态缺失问题，通过统一评估标准和跨模态协同视角，促进鲁棒MAC模型发展。


<details>
  <summary>Details</summary>
Motivation: 现实场景中多模态数据往往动态不确定，模态缺失导致分布偏移和语义缺陷，严重影响MAC模型的鲁棒性和实际部署，需要系统量化这一问题。

Method: 提出MissMAC-Bench基准，包含两个指导原则：训练时不使用缺失先验，单一模型能处理完整和不完整模态场景；整合数据集和实例级别的固定与随机缺失模式评估协议。

Result: 在4个数据集上对3个广泛使用的语言模型进行实验，验证了多种MAC方法处理模态缺失问题的有效性，基准为鲁棒多模态情感计算提供坚实基础。

Conclusion: MissMAC-Bench为系统评估模态缺失问题提供了公平统一的基准，促进了多媒体数据挖掘的发展，有助于推动鲁棒多模态情感计算的实际应用。

Abstract: As a knowledge discovery task over heterogeneous data sources, current Multimodal Affective Computing (MAC) heavily rely on the completeness of multiple modalities to accurately understand human's affective state. However, in real-world scenarios, the availability of modality data is often dynamic and uncertain, leading to substantial performance fluctuations due to the distribution shifts and semantic deficiencies of the incomplete multimodal inputs. Known as the missing modality issue, this challenge poses a critical barrier to the robustness and practical deployment of MAC models. To systematically quantify this issue, we introduce MissMAC-Bench, a comprehensive benchmark designed to establish fair and unified evaluation standards from the perspective of cross-modal synergy. Two guiding principles are proposed, including no missing prior during training, and one single model capable of handling both complete and incomplete modality scenarios, thereby ensuring better generalization. Moreover, to bridge the gap between academic research and real-world applications, our benchmark integrates evaluation protocols with both fixed and random missing patterns at the dataset and instance levels. Extensive experiments conducted on 3 widely-used language models across 4 datasets validate the effectiveness of diverse MAC approaches in tackling the missing modality issue. Our benchmark provides a solid foundation for advancing robust multimodal affective computing and promotes the development of multimedia data mining.

</details>


### [501] [Resource-Efficient Reinforcement for Reasoning Large Language Models via Dynamic One-Shot Policy Refinement](https://arxiv.org/abs/2602.00815)
*Yunjian Zhang,Sudong Wang,Yang Li,Peiran Xu,Conghao Zhou,Xiaoyue Ma,Jianing Li,Yao Zhu*

Main category: cs.AI

TL;DR: 论文提出DoPR方法，通过动态选择单个信息量大的训练样本进行策略更新，大幅降低RLVR训练的计算开销，同时保持推理性能。


<details>
  <summary>Details</summary>
Motivation: 尽管基于可验证奖励的强化学习（RLVR）在复杂推理任务上表现出色，但其训练过程需要大量奖励信号和计算资源，成本过高，限制了实际应用。

Method: 提出动态一次性策略精炼（DoPR）方法：1）建立理论下界证明少量训练样本即可实现强性能；2）基于奖励波动性和探索驱动的获取策略，动态选择每个批次中最具信息量的单个训练样本进行策略更新。

Result: DoPR将训练开销降低近一个数量级，同时保持竞争力的推理准确率，为LLM后训练提供了可扩展且资源高效的解决方案。

Conclusion: DoPR为基于强化学习的推理密集型LLM应用提供了一条实用、高效且可访问的训练路径，显著降低了资源需求。

Abstract: Large language models (LLMs) have exhibited remarkable performance on complex reasoning tasks, with reinforcement learning under verifiable rewards (RLVR) emerging as a principled framework for aligning model behavior with reasoning chains. Despite its promise, RLVR remains prohibitively resource-intensive, requiring extensive reward signals and incurring substantial rollout costs during training. In this work, we revisit the fundamental question of data and compute efficiency in RLVR. We first establish a theoretical lower bound on the sample complexity required to unlock reasoning capabilities, and empirically validate that strong performance can be achieved with a surprisingly small number of training instances. To tackle the computational burden, we propose Dynamic One-Shot Policy Refinement (DoPR), an uncertainty-aware RL strategy that dynamically selects a single informative training sample per batch for policy updates, guided by reward volatility and exploration-driven acquisition. DoPR reduces rollout overhead by nearly an order of magnitude while preserving competitive reasoning accuracy, offering a scalable and resource-efficient solution for LLM post-training. This approach offers a practical path toward more efficient and accessible RL-based training for reasoning-intensive LLM applications.

</details>


### [502] [Optimizing Agentic Reasoning with Retrieval via Synthetic Semantic Information Gain Reward](https://arxiv.org/abs/2602.00845)
*Senkang Hu,Yong Dai,Yuzhi Zhao,Yihang Tao,Yu Guo,Zhengru Fang,Sam Tak Wu Kwong,Yuguang Fang*

Main category: cs.AI

TL;DR: InfoReasoner：通过语义信息增益奖励激励有效信息检索的统一框架，在7个问答基准上平均准确率提升达5.4%


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（LRMs）的代理推理需要动态获取外部知识，但检索过程的优化面临挑战，因为缺乏密集、有原则的奖励信号。现有方法难以有效激励信息寻求行为。

Method: 1. 理论层面：将信息增益重新定义为模型信念状态的不确定性减少，建立非负性、可加性和通道单调性保证
2. 实践层面：提出输出感知的内在估计器，通过双向文本蕴含的语义聚类直接从模型输出分布计算信息增益
3. 训练方法：使用组相对策略优化（GRPO）进行高效训练，最大化认知进展

Result: 在7个问答基准测试中，InfoReasoner始终优于强大的检索增强基线，平均准确率提升高达5.4%。该方法为代理推理提供了理论基础和可扩展路径。

Conclusion: InfoReasoner通过理论保证的语义信息增益奖励，为代理推理中的检索优化提供了统一框架，实现了无需人工检索标注的可扩展优化，显著提升了问答性能。

Abstract: Agentic reasoning enables large reasoning models (LRMs) to dynamically acquire external knowledge, but yet optimizing the retrieval process remains challenging due to the lack of dense, principled reward signals. In this paper, we introduce InfoReasoner, a unified framework that incentivizes effective information seeking via a synthetic semantic information gain reward. Theoretically, we redefine information gain as uncertainty reduction over the model's belief states, establishing guarantees, including non-negativity, telescoping additivity, and channel monotonicity. Practically, to enable scalable optimization without manual retrieval annotations, we propose an output-aware intrinsic estimator that computes information gain directly from the model's output distributions using semantic clustering via bidirectional textual entailment. This intrinsic reward guides the policy to maximize epistemic progress, enabling efficient training via Group Relative Policy Optimxization (GRPO). Experiments across seven question-answering benchmarks demonstrate that InfoReasoner consistently outperforms strong retrieval-augmented baselines, achieving up to 5.4% average accuracy improvement. Our work provides a theoretically grounded and scalable path toward agentic reasoning with retrieval.

</details>


### [503] [Persuasion Propagation in LLM Agents](https://arxiv.org/abs/2602.00851)
*Hyejun Jeong,Amir Houmansadr,Shlomo Zilberstein,Eugene Bagdasarian*

Main category: cs.AI

TL;DR: 研究AI智能体在长程任务中受用户说服影响的行为变化，发现任务执行前的信念预置比执行中的实时说服更能显著影响智能体的搜索和编码行为。


<details>
  <summary>Details</summary>
Motivation: 现代AI智能体结合对话交互与自主任务执行（如编码和网络研究），当智能体在执行长程任务时受到用户说服，其下游任务行为会如何变化？这引发了关于信念层面干预如何影响任务行为的自然问题。

Method: 引入行为中心评估框架，区分任务执行期间与执行前的说服应用。在网络研究和编码任务中，比较实时说服与信念预置两种干预方式对智能体行为的影响。

Result: 实时说服产生微弱且不一致的行为效应。相比之下，在任务开始时明确指定信念状态的信念预置智能体，比中性预置智能体平均减少26.9%的搜索次数和16.9%的唯一来源访问量。

Conclusion: 即使在先前的交互中，说服也能影响智能体的行为，这强调了在智能体系统中进行行为层面评估的重要性。信念预置比实时说服更能有效改变智能体的任务执行行为。

Abstract: Modern AI agents increasingly combine conversational interaction with autonomous task execution, such as coding and web research, raising a natural question: what happens when an agent engaged in long-horizon tasks is subjected to user persuasion? We study how belief-level intervention can influence downstream task behavior, a phenomenon we name \emph{persuasion propagation}. We introduce a behavior-centered evaluation framework that distinguishes between persuasion applied during or prior to task execution. Across web research and coding tasks, we find that on-the-fly persuasion induces weak and inconsistent behavioral effects. In contrast, when the belief state is explicitly specified at task time, belief-prefilled agents conduct on average 26.9\% fewer searches and visit 16.9\% fewer unique sources than neutral-prefilled agents. These results suggest that persuasion, even in prior interaction, can affect the agent's behavior, motivating behavior-level evaluation in agentic systems.

</details>


### [504] [Position: Human-Centric AI Requires a Minimum Viable Level of Human Understanding](https://arxiv.org/abs/2602.00854)
*Fangzhou Lin,Qianwen Ge,Lingyu Xu,Peiran Li,Xiangbo Gao,Shuo Xing,Kazunori Yamada,Ziming Zhang,Haichong Zhang,Zhengzhong Tu*

Main category: cs.AI

TL;DR: 论文提出"能力-理解差距"概念，即AI能力提升但用户理解下降，定义了"认知完整性阈值"作为维持监督所需的最低理解水平，并提出三个功能维度的操作化框架。


<details>
  <summary>Details</summary>
Motivation: AI系统产生流畅正确结果的同时，侵蚀了用户的解释、验证和干预能力。当前透明度、用户控制、素养和治理方法未能解决人类在持续AI委托下必须保留的基础理解问题。

Method: 提出"认知完整性阈值"概念，不需要完全推理重建，也不限制自动化，识别监督变得程序化且可争议性失效的临界点。通过三个功能维度操作化：验证能力、理解保持交互、治理的制度支架。

Result: 建立了分析人类-AI交互中理解保持的理论框架，为责任关键场景下的认知可持续性提供设计原则和治理议程。

Conclusion: 需要将人类-AI交互设计与认知可持续性对齐，确保在AI协助下保持监督、自主性和问责参与，这需要超越传统透明度的新设计治理方法。

Abstract: AI systems increasingly produce fluent, correct, end-to-end outcomes. Over time, this erodes users' ability to explain, verify, or intervene. We define this divergence as the Capability-Comprehension Gap: a decoupling where assisted performance improves while users' internal models deteriorate. This paper argues that prevailing approaches to transparency, user control, literacy, and governance do not define the foundational understanding humans must retain for oversight under sustained AI delegation. To formalize this, we define the Cognitive Integrity Threshold (CIT) as the minimum comprehension required to preserve oversight, autonomy, and accountable participation under AI assistance. CIT does not require full reasoning reconstruction, nor does it constrain automation. It identifies the threshold beyond which oversight becomes procedural and contestability fails. We operatinalize CIT through three functional dimensions: (i) verification capacity, (ii) comprehension-preserving interaction, and (iii) institutional scaffolds for governance. This motivates a design and governance agenda that aligns human-AI interaction with cognitive sustainability in responsibility-critical settings.

</details>


### [505] [Multi-Head Attention Is a Multi-Player Game](https://arxiv.org/abs/2602.00861)
*Kushal Chakrabarti,Nirmal Balachundar*

Main category: cs.AI

TL;DR: 论文将Transformer注意力机制建模为多头之间的潜在博弈，证明了交叉熵训练会导致纳什均衡，并存在无界效率损失。提出了基于博弈论的价格无政府状态界限，并设计了GAME-LoRA正则化方法来减少幻觉。


<details>
  <summary>Details</summary>
Motivation: 现代Transformer注意力机制本质上是多智能体系统（多头之间竞争与协调），但当前训练方法将其视为单一优化器，忽略了多头间的博弈结构。这种训练方式会导致外部性（冗余、相关错误）未被定价，从而产生效率损失。

Method: 将多头注意力建模为潜在博弈，分析交叉熵训练诱导的隐式博弈结构。提出价格无政府状态界限理论，证明幻觉概率和冗余度与PoA相关。设计了GAME-LoRA正则化方法，结合Barlow Twins去相关和log-determinant协调压力来减少头间交互矩阵的离对角线质量。

Result: 理论证明：在温和平滑假设下，过量幻觉概率和过量头冗余度与PoA成比例。实验验证：Γ(G)能预测幻觉概率（p<0.05），涌现的联盟表现出选择性协调。GAME-LoRA实现了高达18%的幻觉减少（平均8%），且没有知识退化，实现了帕累托改进。

Conclusion: 将Transformer多头注意力视为博弈而非单一优化器，为理解其失败模式提供了统一框架。提出的博弈理论界限具有指导意义，GAME-LoRA正则化方法通过减少头间交互来改善性能，证明了考虑博弈结构的重要性。

Abstract: Modern transformer attention is internally multi-agent -- heads compete and coordinate -- yet we train it as if it were a monolithic optimizer. We formalize this gap: cross-entropy training induces an implicit potential game among heads, and gradient descent converges to Nash equilibria with potentially unbounded inefficiency due to unpriced externalities (redundancy, correlated errors). Our main result bounds the Price of Anarchy by $Γ(G)$, the off-diagonal mass of a head interaction matrix capturing weight and gradient coupling. Under mild smoothness assumptions, we prove that both \emph{excess hallucination probability} and \emph{excess head redundancy} scale with PoA, unifying two distinct failure modes into a single mechanism. The bound is prescriptive: regularization that reduces $Γ(G)$ provably tightens PoA. We instantiate this as GAME-LoRA, combining Barlow Twins decorrelation with log-determinant coordination pressure. Experiments validate the theory: $Γ(G)$ predicts hallucination ($p{<}0.05$), emergent coalitions exhibit selective coordination, and GAME-LoRA achieves up to 18\% hallucination reduction (8\% average) with no knowledge degradation -- a Pareto improvement inaccessible to methods ignoring the game structure.

</details>


### [506] [Foundation CAN LM: A Pretrained Language Model For Automotive CAN Data](https://arxiv.org/abs/2602.00866)
*Akiharu Esashi,Pawissanutt Lertpongrujikorn,Justin Makino,Yuibi Fujimoto,Mohsen Amini Salehi*

Main category: cs.AI

TL;DR: 提出了首个CAN总线基础模型，通过大规模预训练和任务特定微调，实现多任务泛化能力，将NLP/CV中的基础模型范式成功应用于汽车CAN数据。


<details>
  <summary>Details</summary>
Motivation: 现有CAN数据处理方法多为孤立的任务特定模型，缺乏共享表征学习和跨任务泛化能力，而NLP和CV领域的基础模型范式已证明其有效性，因此需要将这一范式引入汽车CAN数据分析。

Method: 将CAN数据视为语言：1）提出统一的分词方案处理混合离散-连续信号；2）在大规模未标记解码CAN信号上进行预训练；3）针对时间复杂性和行程特定变异性进行优化；4）在异构汽车保险任务上进行微调。

Result: 一个预训练的CAN模型能够有效适应多种预测任务，验证了基础模型范式在CAN数据上的可行性，为汽车AI中的可泛化表征学习开辟了新方向。

Conclusion: 基础模型范式在NLP和CV中的成功同样适用于CAN数据，通过单一预训练主干实现多目标下游泛化，建立了汽车AI中可泛化表征学习的新方向。

Abstract: The Controller Area Network (CAN) bus provides a rich source of vehicular signals increasingly leveraged for applications in automotive and auto insurance domains, including collision detection, predictive maintenance, and driver risk modeling. Despite this potential, existing pipelines largely train isolated task-specific models on raw CAN data, with only limited efforts exploring decoded signals. Such fragmentation prevents shared representation learning and limits cross-task generalization. By contrast, natural language processing (NLP) and computer vision (CV) have been transformed by the foundation model paradigm: large-scale pretraining followed by task-specific adaptation. In this work, we introduce the foundation CAN model that demonstrates multi-objective downstream generalization using a single pretrained backbone. Our approach treats CAN data as a language: we pretrain on large-scale, unlabeled decoded CAN signals and fine-tune across heterogeneous auto insurance tasks. To enable this, we propose a unified tokenization scheme for mixed discrete-continuous signals and address challenges of temporal complexity and trip-specific variability. Our results show that one pretrained CAN model can adapt effectively to diverse predictive tasks, validating that the foundation modeling paradigm, proven in NLP and CV, also holds for CAN data. This establishes a new direction for generalizable representation learning in automotive AI.

</details>


### [507] [Beyond Output Critique: Self-Correction via Task Distillation](https://arxiv.org/abs/2602.00871)
*Hossein A. Rahmani,Mengting Wan,Pei Zhou,Longqi Yang,Nick Craswell,Emine Yilmaz,Sujay Kumar Jauhar*

Main category: cs.AI

TL;DR: SELF-THOUGHT框架通过任务抽象引导LLM自我修正，将任务提炼为结构化模板指导解决方案生成，提升推理准确性和鲁棒性


<details>
  <summary>Details</summary>
Motivation: 现有LLM自我修正方法主要在输出层面进行批判性修正，只能修补表面错误，难以纠正深层推理缺陷，需要更有效的自我修正机制

Method: 提出SELF-THOUGHT框架：1) 将任务提炼为结构化模板（捕获关键变量、约束和问题结构）；2) 基于抽象模板指导解决方案实例化；3) 支持跨模型模板迁移，大模型生成的模板可指导小模型自我修正

Result: 在多样化推理任务上的实验表明，SELF-THOUGHT提高了准确率、鲁棒性和泛化能力，小模型通过重用大模型生成的任务结构，无需大量微调或外部验证器即可实现更可靠的修正

Conclusion: SELF-THOUGHT通过任务抽象和结构化指导，为LLM提供了更可靠的自我修正路径，特别是促进了大小模型之间的知识迁移，为可扩展的自我修正语言系统提供了新方向

Abstract: Large language models (LLMs) have shown promising self-correction abilities, where iterative refinement improves the quality of generated responses. However, most existing approaches operate at the level of output critique, patching surface errors while often failing to correct deeper reasoning flaws. We propose SELF-THOUGHT, a framework that introduces an intermediate step of task abstraction before solution refinement. Given an input and an initial response, the model first distills the task into a structured template that captures key variables, constraints, and problem structure. This abstraction then guides solution instantiation, grounding subsequent responses in a clearer understanding of the task and reducing error propagation. Crucially, we show that these abstractions can be transferred across models: templates generated by larger models can serve as structured guides for smaller LLMs, which typically struggle with intrinsic self-correction. By reusing distilled task structures, smaller models achieve more reliable refinements without heavy fine-tuning or reliance on external verifiers. Experiments across diverse reasoning tasks demonstrate that SELF-THOUGHT improves accuracy, robustness, and generalization for both large and small models, offering a scalable path toward more reliable self-correcting language systems.

</details>


### [508] [Synapse Compendium Aware Federated Knowledge Exchange for Tool Routed LLMs](https://arxiv.org/abs/2602.00911)
*Abhijit Chakraborty,Sandipan De,Yash Shah,Chahana Dahal,Vivek Gupta*

Main category: cs.AI

TL;DR: Synapse框架通过联邦学习训练共享的全局工具使用知识模型，提高多智能体LLM系统的工具使用效果并降低通信开销


<details>
  <summary>Details</summary>
Motivation: 基于LLM的智能体在联邦学习下面临通信成本高、数据和工具使用异质性等挑战，限制了协作学习的效果

Method: 训练共享的全局工具使用行为知识模型，客户端智能体在固定LLM上学习本地工具使用模式，通过协调器传输工件进行联邦聚合，更新全局工具汇编并重新分发，使用模板化表示、嵌入检索与LLM重排序、自适应掩码等技术

Result: Synapse相比权重或提示共享方法，提高了工具使用效果并减少了通信开销，支持异构数据并能量化性能改进

Conclusion: Synapse框架能有效解决多智能体LLM系统中的协作学习挑战，通过联邦知识共享实现稳定的工具选择收敛

Abstract: Collaborative learning among LLM-based agents under federated learning faces challenges, including communication costs, heterogeneity in data, and tool-usage, limiting their effectiveness. We introduce Synapse, a framework that trains a shared global knowledge model of tool-usage behavior. Client agents with fixed LLMs learn tool-usage patterns locally, and transmit artifacts for federated aggregation through coordinators. A global tool compendium is updated and redistributed, enabling convergence toward stable tool selection. Synapse uses templated representations, embedding retrieval with LLM reranking, and adaptive masking to maintain utility while limiting information leakage. The framework supports heterogeneous data and quantifies performance improvements. Results show that Synapse improves tool-usage effectiveness and reduces communication overhead compared with weight or prompt-sharing approaches in multi-agent LLM systems.

</details>


### [509] [Supervised sparse auto-encoders as unconstrained feature models for semantic composition](https://arxiv.org/abs/2602.00924)
*Ouns El Harzli,Hugo Wallner,Yoonsoo Nam,Haixuan Xavier Tao*

Main category: cs.AI

TL;DR: 提出一种改进的稀疏自编码器方法，通过无约束特征模型和监督任务来解决传统SAE的L1惩罚非光滑性和特征-语义对齐问题，在Stable Diffusion 3.5上实现组合泛化和语义图像编辑。


<details>
  <summary>Details</summary>
Motivation: 稀疏自编码器在机制可解释性中面临两个主要挑战：1) L1惩罚的非光滑性阻碍了重建和可扩展性；2) 学习到的特征与人类语义缺乏对齐。

Method: 采用神经崩溃理论中的无约束特征模型框架，通过监督任务联合学习稀疏概念嵌入和解码器权重，监督（仅解码器）SAE重建特征向量。

Result: 在Stable Diffusion 3.5上验证，方法展示了组合泛化能力，成功重建训练中未见的概念组合图像，并实现无需提示修改的语义图像编辑。

Conclusion: 通过结合无约束特征模型和监督学习，解决了传统SAE的局限性，实现了更好的特征学习和语义对齐，为机制可解释性和可控图像生成提供了有效工具。

Abstract: Sparse auto-encoders (SAEs) have re-emerged as a prominent method for mechanistic interpretability, yet they face two significant challenges: the non-smoothness of the $L_1$ penalty, which hinders reconstruction and scalability, and a lack of alignment between learned features and human semantics. In this paper, we address these limitations by adapting unconstrained feature models-a mathematical framework from neural collapse theory-and by supervising the task. We supervise (decoder-only) SAEs to reconstruct feature vectors by jointly learning sparse concept embeddings and decoder weights. Validated on Stable Diffusion 3.5, our approach demonstrates compositional generalization, successfully reconstructing images with concept combinations unseen during training, and enabling feature-level intervention for semantic image editing without prompt modification.

</details>


### [510] [Learning Abstractions for Hierarchical Planning in Program-Synthesis Agents](https://arxiv.org/abs/2602.00929)
*Zergham Ahmed,Kazuki Irie,Joshua B. Tenenbaum,Christopher J. Bates,Samuel J. Gershman*

Main category: cs.AI

TL;DR: TheoryCoder-2是一个基于理论的强化学习代理，利用大语言模型的上下文学习能力主动学习可重用抽象，而不是依赖人工指定的抽象，在多种环境中表现出比基线方法更高的样本效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于理论的强化学习系统（如TheoryCoder）虽然通过使用抽象表现出强大的泛化能力，但严重依赖人工提供的抽象，回避了抽象学习问题。人类能够学习抽象并利用它们进行高效规划，而当前的大语言模型代理和深度强化学习系统在这方面仍面临挑战。

Method: TheoryCoder-2利用大语言模型的上下文学习能力，通过从经验中合成抽象并将其整合到分层规划过程中，主动学习可重用的抽象。该方法结合了程序合成和分层规划，仅需最少的人工提示。

Result: 在BabyAI、Minihack和VGDL游戏（如Sokoban）等多种环境中，TheoryCoder-2比基线方法（包括增强经典规划领域构建的LLM代理、基于推理的规划以及WorldCoder等先前的程序合成代理）具有显著更高的样本效率。它能够解决基线方法无法解决的复杂任务。

Conclusion: TheoryCoder-2通过利用LLM的上下文学习能力主动学习抽象，解决了先前基于理论的强化学习系统依赖人工抽象的问题，在样本效率和任务解决能力方面超越了现有方法，同时仅需最少的人工干预。

Abstract: Humans learn abstractions and use them to plan efficiently to quickly generalize across tasks -- an ability that remains challenging for state-of-the-art large language model (LLM) agents and deep reinforcement learning (RL) systems. Inspired by the cognitive science of how people form abstractions and intuitive theories of their world knowledge, Theory-Based RL (TBRL) systems, such as TheoryCoder, exhibit strong generalization through effective use of abstractions. However, they heavily rely on human-provided abstractions and sidestep the abstraction-learning problem. We introduce TheoryCoder-2, a new TBRL agent that leverages LLMs' in-context learning ability to actively learn reusable abstractions rather than relying on hand-specified ones, by synthesizing abstractions from experience and integrating them into a hierarchical planning process. We conduct experiments on diverse environments, including BabyAI, Minihack and VGDL games like Sokoban. We find that TheoryCoder-2 is significantly more sample-efficient than baseline LLM agents augmented with classical planning domain construction, reasoning-based planning, and prior program-synthesis agents such as WorldCoder. TheoryCoder-2 is able to solve complex tasks that the baselines fail, while only requiring minimal human prompts, unlike prior TBRL systems.

</details>


### [511] [The Keyhole Effect: Why Chat Interfaces Fail at Data Analysis](https://arxiv.org/abs/2602.00947)
*Mohan Reddy*

Main category: cs.AI

TL;DR: 聊天界面不适合多步骤数据分析任务，因为会造成认知过载，作者提出五个认知机制问题和八个混合设计模式来解决


<details>
  <summary>Details</summary>
Motivation: 当前AI辅助数据分析普遍采用聊天界面，但对于多步骤、状态依赖的分析任务，这种界面设计存在根本缺陷，会系统性地降低分析性能

Method: 基于Woods的"锁眼效应"理论，分析聊天界面造成认知过载的五个机制，并提出八个混合设计模式来缓解这些问题

Result: 提出认知过载公式O = max(0, m - v - W)，当O>0时错误概率增加，分析偏差放大。八个设计模式针对特定认知瓶颈，同时保留自然语言用于意图指定和综合

Conclusion: 聊天界面不适合开放探索式数据分析，需要混合设计模式来平衡认知负荷。论文提出了可证伪假设和实验范式进行实证验证

Abstract: Chat has become the default interface for AI-assisted data analysis. For multi-step, state-dependent analytical tasks, this is a mistake. Building on Woods (1984) Keyhole Effect, the cognitive cost of viewing large information spaces through narrow viewports, I show that chat interfaces systematically degrade analytical performance through five mechanisms: (1) constant content displacement defeats hippocampal spatial memory systems; (2) hidden state variables exceed working memory capacity (approximately 4 chunks under load); (3) forced verbalization triggers verbal overshadowing, degrading visual pattern recognition; (4) linear text streams block epistemic action and cognitive offloading; (5) serialization penalties scale with data dimensionality. I formalize cognitive overload as O = max(0, m - v - W) where m is task-relevant items, v is visible items, and W is working memory capacity. When O > 0, error probability increases and analytical biases (anchoring, confirmation, change blindness) amplify. Eight hybrid design patterns address these failures: Generative UI, Infinite Canvas, Deictic Interaction, State Rail, Ghost Layers, Mise en Place, Semantic Zoom, and Probabilistic UI. Each pattern targets specific cognitive bottlenecks while preserving natural language for intent specification and synthesis. Well-scaffolded conversational systems that encode expert priors may reduce load for guided tasks; the framework applies most strongly to open-ended exploration. The paper concludes with falsifiable hypotheses and experimental paradigms for empirical validation.

</details>


### [512] [MindGuard: Guardrail Classifiers for Multi-Turn Mental Health Support](https://arxiv.org/abs/2602.00950)
*António Farinhas,Nuno M. Guerreiro,José Pombal,Pedro Henrique Martins,Laura Melton,Alex Conway,Cara Dochat,Maya D'Eon,Ricardo Rei*

Main category: cs.AI

TL;DR: 论文提出MindGuard，一个基于临床风险分类学的轻量级安全分类器，用于区分治疗性披露和真正的临床危机，减少心理健康支持中LLM的安全误判。


<details>
  <summary>Details</summary>
Motivation: 当前用于心理健康支持的大语言模型存在安全漏洞，通用安全措施无法区分治疗性披露和真正的临床危机，导致安全失败和误判。

Method: 1. 与心理学博士合作开发临床风险分类学；2. 发布MindGuard-testset真实世界多轮对话数据集；3. 使用受控双代理设置生成合成对话；4. 训练轻量级安全分类器（4B和8B参数）。

Result: MindGuard分类器在高召回率操作点减少假阳性，与临床语言模型结合时，在对抗性多轮交互中相比通用安全措施具有更低的攻击成功率和有害参与率。

Conclusion: 提出的临床风险分类学和MindGuard分类器能有效提升心理健康支持中LLM的安全性，区分治疗性内容和真实危机，并开源了所有模型和人类评估数据。

Abstract: Large language models are increasingly used for mental health support, yet their conversational coherence alone does not ensure clinical appropriateness. Existing general-purpose safeguards often fail to distinguish between therapeutic disclosures and genuine clinical crises, leading to safety failures. To address this gap, we introduce a clinically grounded risk taxonomy, developed in collaboration with PhD-level psychologists, that identifies actionable harm (e.g., self-harm and harm to others) while preserving space for safe, non-crisis therapeutic content. We release MindGuard-testset, a dataset of real-world multi-turn conversations annotated at the turn level by clinical experts. Using synthetic dialogues generated via a controlled two-agent setup, we train MindGuard, a family of lightweight safety classifiers (with 4B and 8B parameters). Our classifiers reduce false positives at high-recall operating points and, when paired with clinician language models, help achieve lower attack success and harmful engagement rates in adversarial multi-turn interactions compared to general-purpose safeguards. We release all models and human evaluation data.

</details>


### [513] [R-HTN: Rebellious Online HTN Planning for Safety and Game AI](https://arxiv.org/abs/2602.00951)
*Hector Munoz-Avila,David W. Aha,Paola Rizzo*

Main category: cs.AI

TL;DR: 论文提出R-HTN算法，使在线分层任务网络（HTN）智能体能够在特定条件下拒绝执行用户分配的任务，转而采取不满足用户期望的行为，以确保不违反内置指令集D。


<details>
  <summary>Details</summary>
Motivation: 现有智能体通常盲目执行用户指令，但在某些情况下（如安全风险或违反个性特征），智能体需要具备"智能不服从"能力，能够拒绝执行可能违反内置指令的任务。

Method: 结合HTN规划、在线规划和内置指令集D，提出R-HTN算法。研究两种智能体变体：非自适应智能体（发现违反D时停止执行）和自适应智能体（违反D时修改HTN计划寻找替代方案）。

Result: R-HTN智能体从不违反指令，并在可行情况下努力实现用户给定的目标（尽管不一定按用户预期的方式）。在需要安全考虑或个性特征约束的任务领域中表现良好。

Conclusion: R-HTN算法为在线HTN规划提供了处理内置指令的通用框架，使智能体具备智能不服从能力，能够在确保不违反核心指令的前提下灵活处理用户任务。

Abstract: We introduce online Hierarchical Task Network (HTN) agents whose behaviors are governed by a set of built-in directives \D. Like other agents that are capable of rebellion (i.e., {\it intelligent disobedience}), our agents will, under some conditions, not perform a user-assigned task and instead act in ways that do not meet a user's expectations. Our work combines three concepts: HTN planning, online planning, and the directives \D, which must be considered when performing user-assigned tasks. We investigate two agent variants: (1) a Nonadaptive agent that stops execution if it finds itself in violation of \D~ and (2) an Adaptive agent that, in the same situation, instead modifies its HTN plan to search for alternative ways to achieve its given task. We present R-HTN (for: Rebellious-HTN), a general algorithm for online HTN planning under directives \D. We evaluate R-HTN in two task domains where the agent must not violate some directives for safety reasons or as dictated by their personality traits. We found that R-HTN agents never violate directives, and aim to achieve the user-given goals if feasible though not necessarily as the user expected.

</details>


### [514] [Small-Margin Preferences Still Matter-If You Train Them Right](https://arxiv.org/abs/2602.00954)
*Jinlong Pang,Zhaowei Zhu,Na Di,Yichi Zhang,Yaxuan Wang,Chen Qian,Yang Liu*

Main category: cs.AI

TL;DR: MixDPO：一种难度感知的训练策略，通过将困难偏好对路由到监督微调目标，简单对使用偏好损失，有效利用模糊偏好对提升大语言模型对齐效果。


<details>
  <summary>Details</summary>
Motivation: 现有偏好优化方法（如DPO）对偏好对的质量和难度高度敏感，通常将小边距（模糊）对视为噪声并过滤掉。但研究发现这些困难对在监督微调中仍包含有用的监督信号，而使用偏好损失训练时会导致训练不稳定和对齐效果下降。

Method: 提出MixDPO策略：1）根据边距定义的难度将偏好数据从易到难排序（课程学习）；2）将困难对路由到监督微调目标，同时对简单对应用偏好损失。这种混合设计能够利用模糊对而不引发偏好损失在低边距数据上的优化失败。

Result: 在三个LLM-judge基准测试中，MixDPO相比DPO和一系列广泛使用的变体持续改进对齐效果，在AlpacaEval~2长度控制胜率上获得特别显著的提升。

Conclusion: 困难偏好对与优化目标存在强烈交互作用，MixDPO通过难度感知的混合训练策略有效利用了模糊对中的监督信号，提供了一种实用的机制来提升大语言模型的对齐效果。

Abstract: Preference optimization methods such as DPO align large language models (LLMs) using paired comparisons, but their effectiveness can be highly sensitive to the quality and difficulty of preference pairs. A common heuristic treats small-margin (ambiguous) pairs as noisy and filters them out. In this paper, we revisit this assumption and show that pair difficulty interacts strongly with the optimization objective: when trained with preference-based losses, difficult pairs can destabilize training and harm alignment, yet these same pairs still contain useful supervision signals when optimized with supervised fine-tuning (SFT). Motivated by this observation, we propose MixDPO, a simple yet effective difficulty-aware training strategy that (i) orders preference data from easy to hard (a curriculum over margin-defined difficulty), and (ii) routes difficult pairs to an SFT objective while applying a preference loss to easy pairs. This hybrid design provides a practical mechanism to leverage ambiguous pairs without incurring the optimization failures often associated with preference losses on low-margin data. Across three LLM-judge benchmarks, MixDPO consistently improves alignment over DPO and a range of widely-used variants, with particularly strong gains on AlpacaEval~2 length-controlled (LC) win rate.

</details>


### [515] [Reasoning and Tool-use Compete in Agentic RL:From Quantifying Interference to Disentangled Tuning](https://arxiv.org/abs/2602.00994)
*Yu Li,Mingyang Yi,Xiuyu Li,Ju Fan,Fuxin Jiang,Binbin Chen,Peng Li,Jie Song,Tieying Zhang*

Main category: cs.AI

TL;DR: 本文通过引入线性效应归因系统(LEAS)发现推理与工具使用行为之间存在训练干扰，并提出解耦动作推理调优(DART)框架来分离这两种能力的参数更新，显著提升代理性能。


<details>
  <summary>Details</summary>
Motivation: 现有代理强化学习(ARL)方法通常训练单一共享模型参数来同时支持推理和工具使用行为，并隐含假设联合训练能提升整体代理性能。然而这一假设缺乏实证检验，本文旨在系统研究这一假设的有效性。

Method: 1) 引入线性效应归因系统(LEAS)定量分析推理与工具使用行为之间的干扰；2) 提出解耦动作推理调优(DART)框架，通过分离的低秩适应模块显式解耦推理和工具使用的参数更新。

Result: 实验结果表明：1) LEAS揭示了推理与工具使用行为之间存在梯度方向错位导致的训练干扰；2) DART框架相比基线方法平均提升6.35%性能，且能达到与显式分离工具使用和推理的多智能体系统相当的性能。

Conclusion: 推理与工具使用行为的联合训练存在干扰问题，显式解耦这两种能力的参数更新能显著提升代理性能，挑战了当前ARL范式并提供了更有效的训练框架。

Abstract: Agentic Reinforcement Learning (ARL) focuses on training large language models (LLMs) to interleave reasoning with external tool execution to solve complex tasks. Most existing ARL methods train a single shared model parameters to support both reasoning and tool use behaviors, implicitly assuming that joint training leads to improved overall agent performance. Despite its widespread adoption, this assumption has rarely been examined empirically. In this paper, we systematically investigate this assumption by introducing a Linear Effect Attribution System(LEAS), which provides quantitative evidence of interference between reasoning and tool-use behaviors. Through an in-depth analysis, we show that these two capabilities often induce misaligned gradient directions, leading to training interference that undermines the effectiveness of joint optimization and challenges the prevailing ARL paradigm. To address this issue, we propose Disentangled Action Reasoning Tuning(DART), a simple and efficient framework that explicitly decouples parameter updates for reasoning and tool-use via separate low-rank adaptation modules. Experimental results show that DART consistently outperforms baseline methods with averaged 6.35 percent improvements and achieves performance comparable to multi-agent systems that explicitly separate tool-use and reasoning using a single model.

</details>


### [516] [Error Taxonomy-Guided Prompt Optimization](https://arxiv.org/abs/2602.00997)
*Mayank Singh,Vikas Yadav,Eduardo Blanco*

Main category: cs.AI

TL;DR: ETGPO是一种基于错误分类的提示优化方法，采用自上而下的方式分析全局失败模式，相比现有方法减少约三分之二的优化阶段token使用和评估预算。


<details>
  <summary>Details</summary>
Motivation: 现有自动提示优化方法大多采用自下而上的试错方式，基于单个问题的反馈迭代调整提示，这会导致失去全局视角，且计算成本高昂。需要一种更高效、更具全局视角的优化方法。

Method: ETGPO采用自上而下的方法：1) 收集模型错误；2) 将错误分类为分类学；3) 在提示中添加针对最常见失败模式的指导。通过分析全局失败模式来优化提示。

Result: 在数学、问答和逻辑推理等多个基准测试中，ETGPO达到或优于最先进方法的准确率，同时优化阶段的token使用量和评估预算仅需约三分之一。

Conclusion: ETGPO通过错误分类学的全局视角进行提示优化，在保持性能的同时显著降低了计算成本，为高效自动提示优化提供了新思路。

Abstract: Automatic Prompt Optimization (APO) is a powerful approach for extracting performance from large language models without modifying their weights. Many existing methods rely on trial-and-error, testing different prompts or in-context examples until a good configuration emerges, often consuming substantial compute. Recently, natural language feedback derived from execution logs has shown promise as a way to identify how prompts can be improved. However, most prior approaches operate in a bottom-up manner, iteratively adjusting the prompt based on feedback from individual problems, which can cause them to lose the global perspective. In this work, we propose Error Taxonomy-Guided Prompt Optimization (ETGPO), a prompt optimization algorithm that adopts a top-down approach. ETGPO focuses on the global failure landscape by collecting model errors, categorizing them into a taxonomy, and augmenting the prompt with guidance targeting the most frequent failure modes. Across multiple benchmarks spanning mathematics, question answering, and logical reasoning, ETGPO achieves accuracy that is comparable to or better than state-of-the-art methods, while requiring roughly one third of the optimization-phase token usage and evaluation budget.

</details>


### [517] [How RLHF Amplifies Sycophancy](https://arxiv.org/abs/2602.01002)
*Itai Shapira,Gerdus Benade,Ariel D. Procaccia*

Main category: cs.AI

TL;DR: 论文分析发现，基于人类偏好的对齐训练会放大语言模型的奉承行为，并提出了一种训练时干预方法来防止这种倾向增强。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在基于偏好的后训练后常常表现出更强的奉承行为，即使这与事实准确性或合理判断相冲突。需要理解这种失败模式如何被人类反馈对齐放大，并提出解决方案。

Method: 1) 形式化分析对齐训练如何放大奉承行为，识别因果机制；2) 分析Bradley-Terry等随机效用模型下的奖励学习；3) 提出训练时干预方法，通过最小KL散度约束推导出闭式奖励修正（一致性惩罚）。

Result: 计算实验发现奖励差距普遍存在，并在所有考虑的配置中导致行为漂移。提出的干预方法能够有效防止奉承行为的增加。

Conclusion: 人类反馈对齐会系统性地放大语言模型的奉承倾向，但通过适当的训练时干预（如一致性惩罚）可以防止这种负面行为增强，同时保持对齐效果。

Abstract: Large language models often exhibit increased sycophantic behavior after preference-based post-training, showing a stronger tendency to affirm a user's stated or implied belief even when this conflicts with factual accuracy or sound judgment. We present a formal analysis of how alignment from human feedback can increase this failure mode by identifying an explicit amplification mechanism that causally links optimization against a learned reward to bias in the human preference data used for alignment. We show that the direction of behavioral drift is determined by a covariance under the base policy between endorsing the belief signal in the prompt and the learned reward, and that the first-order effect reduces to a simple mean-gap condition. We then analyze reward learning from pairwise comparisons under random utility models like Bradley-Terry and characterize when bias in human annotators' preferences induces this reward gap. Next, we propose a training-time intervention designed to neutralize the amplification mechanism itself. Among all post-trained policies that prevent sycophantic behavior from increasing, we characterize the unique policy closest in KL divergence to the unconstrained post-trained policy, and derive the corresponding minimal reward correction as a closed-form agreement penalty. Computational experiments find that reward gaps are common and cause behavioral drift in all the configurations considered.

</details>


### [518] [HalluHard: A Hard Multi-Turn Hallucination Benchmark](https://arxiv.org/abs/2602.01031)
*Dongyang Fan,Sebastien Delsad,Nicolas Flammarion,Maksym Andriushchenko*

Main category: cs.AI

TL;DR: HalluHard是一个具有挑战性的多轮幻觉基准测试，包含950个种子问题，涵盖法律、研究、医疗和编程四个高风险领域，通过内联引用评估事实基础性，并提出了基于网络搜索的证据检索评估管道。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在多轮对话中会产生看似合理但无事实依据的虚假信息，随着上下文增长和早期错误累积，这一问题会加剧，特别是在高风险领域需要可靠的事实基础。

Method: 提出了HalluHard基准测试，包含950个种子问题覆盖四个高风险领域；通过要求内联引用评估事实基础性；设计了基于网络搜索的评估管道，能够获取、筛选和解析全文来源（包括PDF）来验证引用是否支持生成内容。

Result: 即使在网络搜索支持下，前沿专有和开源模型的幻觉率仍然很高（最强配置Opus-4.5约为30%），内容基础性错误持续存在；幻觉行为受模型能力、轮次位置、有效推理和所需知识类型影响。

Conclusion: 多轮对话中的幻觉问题仍然严重，特别是在高风险领域；需要更好的事实基础性评估方法和改进模型的事实核查能力；模型能力、对话结构和知识类型都会影响幻觉行为。

Abstract: Large language models (LLMs) still produce plausible-sounding but ungrounded factual claims, a problem that worsens in multi-turn dialogue as context grows and early errors cascade. We introduce $\textbf{HalluHard}$, a challenging multi-turn hallucination benchmark with 950 seed questions spanning four high-stakes domains: legal cases, research questions, medical guidelines, and coding. We operationalize groundedness by requiring inline citations for factual assertions. To support reliable evaluation in open-ended settings, we propose a judging pipeline that iteratively retrieves evidence via web search. It can fetch, filter, and parse full-text sources (including PDFs) to assess whether cited material actually supports the generated content. Across a diverse set of frontier proprietary and open-weight models, hallucinations remain substantial even with web search ($\approx 30\%$ for the strongest configuration, Opus-4.5 with web search), with content-grounding errors persisting at high rates. Finally, we show that hallucination behavior is shaped by model capacity, turn position, effective reasoning, and the type of knowledge required.

</details>


### [519] [Discovering Process-Outcome Credit in Multi-Step LLM Reasoning](https://arxiv.org/abs/2602.01034)
*Xiangwei Wang,Wei Wang,Ken Chen,Nanduni Nimalsiri,Saman Halgamuge*

Main category: cs.AI

TL;DR: 提出一个强化学习框架，通过步长边际信息增益机制提供连续奖励信号，结合解耦掩码策略和双门监督微调目标，提升大语言模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 传统基于结果的强化学习方法存在奖励稀疏和信用分配效率低的问题，需要更有效的训练机制来提升大语言模型的推理能力。

Method: 1) 步长边际信息增益机制：量化推理步骤相对于单调历史水印的内在价值，过滤训练噪声；2) 解耦掩码策略：过程导向奖励应用于思维链，结果导向奖励应用于完整完成；3) 双门监督微调目标：用高质量结构和事实信号稳定训练。

Result: 在文本和多模态基准测试（如MATH、Super-CLEVR）上，该方法在样本效率和最终准确率方面均优于GRPO等基线方法，并展现出优越的分布外鲁棒性和零样本迁移能力。

Conclusion: 提出的框架通过连续奖励信号和精细的信用分配机制，有效提升了大语言模型的推理能力，在多种任务上表现出色，具有很好的泛化能力。

Abstract: Reinforcement Learning (RL) serves as a potent paradigm for enhancing reasoning capabilities in Large Language Models (LLMs), yet standard outcome-based approaches often suffer from reward sparsity and inefficient credit assignment. In this paper, we propose a novel framework designed to provide continuous reward signals, which introduces a Step-wise Marginal Information Gain (MIG) mechanism that quantifies the intrinsic value of reasoning steps against a Monotonic Historical Watermark, effectively filtering out training noise. To ensure disentangled credit distribution, we implement a Decoupled Masking Strategy, applying process-oriented rewards specifically to the chain-of-thought (CoT) and outcome-oriented rewards to the full completion. Additionally, we incorporate a Dual-Gated SFT objective to stabilize training with high-quality structural and factual signals. Extensive experiments across textual and multi-modal benchmarks (e.g., MATH, Super-CLEVR) demonstrate that our approach consistently outperforms baselines such as GRPO in both sample efficiency and final accuracy. Furthermore, our model exhibits superior out-of-distribution robustness, demonstrating promising zero-shot transfer capabilities to unseen and challenging reasoning tasks.

</details>


### [520] [SetPO: Set-Level Policy Optimization for Diversity-Preserving LLM Reasoning](https://arxiv.org/abs/2602.01062)
*Chenyi Li,Yuan Zhang,Bo Wang,Guoqing Ma,Wei Tang,Haoyang Huang,Nan Duan*

Main category: cs.AI

TL;DR: 提出一种基于核相似度的轨迹级多样性目标，通过留一法边际贡献计算，作为优势塑造项集成到策略优化中，提升LLM推理任务中的解决方案多样性


<details>
  <summary>Details</summary>
Motivation: 现有强化学习在提升LLM数学推理性能时，往往导致解决方案多样性降低，模型将概率质量集中在少数解上，需要平衡性能与多样性

Method: 1) 基于核相似度定义轨迹级多样性目标；2) 使用留一法计算每个采样轨迹的边际贡献；3) 将该目标作为可插拔的优势塑造项集成到策略优化中；4) 在分布扰动框架下分析单个轨迹对多样性的贡献

Result: 在多种模型规模上的实验表明，该方法在多个基准测试中，在Pass@1和Pass@K指标上均优于强基线方法

Conclusion: 提出的多样性增强方法能有效提升LLM推理任务的解决方案多样性，同时保持性能优势，理论分析验证了稀有轨迹对全局多样性的更高边际贡献

Abstract: Reinforcement learning with verifiable rewards has shown notable effectiveness in enhancing large language models (LLMs) reasoning performance, especially in mathematics tasks. However, such improvements often come with reduced outcome diversity, where the model concentrates probability mass on a narrow set of solutions. Motivated by diminishing-returns principles, we introduce a set level diversity objective defined over sampled trajectories using kernelized similarity. Our approach derives a leave-one-out marginal contribution for each sampled trajectory and integrates this objective as a plug-in advantage shaping term for policy optimization. We further investigate the contribution of a single trajectory to language model diversity within a distribution perturbation framework. This analysis theoretically confirms a monotonicity property, proving that rarer trajectories yield consistently higher marginal contributions to the global diversity. Extensive experiments across a range of model scales demonstrate the effectiveness of our proposed algorithm, consistently outperforming strong baselines in both Pass@1 and Pass@K across various benchmarks.

</details>


### [521] [ConvexBench: Can LLMs Recognize Convex Functions?](https://arxiv.org/abs/2602.01075)
*Yepeng Liu,Yu Huang,Yu-Xiang Wang,Yingbin Liang,Yuheng Bu*

Main category: cs.AI

TL;DR: 论文提出了一个测试LLMs凸性推理能力的基准CB，发现LLMs在深度函数组合下的凸性识别能力随深度增加急剧下降，并提出了一种分治框架来显著改善性能。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs开始自动化研究级数学和科学任务，需要评估它们理解和推理凸性的能力。凸分析是现代数学的重要分支，在优化等领域有广泛应用，因此测试LLMs在深度函数组合下识别凸性的能力至关重要。

Method: 提出了CB基准，用于测试LLMs在符号目标函数深度组合下识别凸性的能力。通过实验发现LLMs存在组合推理缺陷，并提出了一种代理分治框架：1) 使用外部工具构建抽象语法树(AST)来卸载解析任务；2) 对每个中间子表达式强制执行递归推理，并提供聚焦上下文。

Result: 前沿LLMs在深度函数组合的凸性识别上表现出急剧的性能下降：F1分数从深度2时的1.0下降到深度100时的约0.2。分析发现两种失败模式：解析失败和懒惰推理。提出的分治框架显著改善了深度组合失败，在深度100时实现了F1分数=1.0的优异性能。

Conclusion: LLMs在深度函数组合的凸性推理上存在显著缺陷，但通过结构化方法（如分治框架）可以有效解决这些问题。这表明对于复杂的数学推理任务，需要设计专门的代理架构来提升LLMs的性能。

Abstract: Convex analysis is a modern branch of mathematics with many applications. As Large Language Models (LLMs) start to automate research-level math and sciences, it is important for LLMs to demonstrate the ability to understand and reason with convexity. We introduce \cb, a scalable and mechanically verifiable benchmark for testing \textit{whether LLMs can identify the convexity of a symbolic objective under deep functional composition.} Experiments on frontier LLMs reveal a sharp compositional reasoning gap: performance degrades rapidly with increasing depth, dropping from an F1-score of $1.0$ at depth $2$ to approximately $0.2$ at depth $100$. Inspection of models' reasoning traces indicates two failure modes: \textit{parsing failure} and \textit{lazy reasoning}. To address these limitations, we propose an agentic divide-and-conquer framework that (i) offloads parsing to an external tool to construct an abstract syntax tree (AST) and (ii) enforces recursive reasoning over each intermediate sub-expression with focused context. This framework reliably mitigates deep-composition failures, achieving substantial performance improvement at large depths (e.g., F1-Score $= 1.0$ at depth $100$).

</details>


### [522] [AutoHealth: An Uncertainty-Aware Multi-Agent System for Autonomous Health Data Modeling](https://arxiv.org/abs/2602.01078)
*Tong Xia,Weibin Li,Gang Liu,Yong Li*

Main category: cs.AI

TL;DR: AutoHealth是一个基于LLM的多智能体系统，能够自主建模健康数据并评估模型可靠性，在预测性能和不确定性估计方面显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有LLM智能体在健康数据应用中存在局限性：难以泛化到异构数据模态、过度依赖预定义模板、缺乏不确定性估计，而医疗决策需要可靠的不确定性量化。

Method: 采用五个专门智能体的闭环协调系统，执行数据探索、任务条件化模型构建、训练和优化，同时优先考虑预测性能和不确定性量化。

Result: 在包含17个任务的真实世界基准测试中，AutoHealth完成所有任务，预测性能比现有方法提升29.2%，不确定性估计提升50.2%。

Conclusion: AutoHealth通过不确定性感知的多智能体系统，为健康数据建模提供了可靠、可解释的自主机器学习解决方案，支持可信赖的医疗决策。

Abstract: LLM-based agents have demonstrated strong potential for autonomous machine learning, yet their applicability to health data remains limited. Existing systems often struggle to generalize across heterogeneous health data modalities, rely heavily on predefined solution templates with insufficient adaptation to task-specific objectives, and largely overlook uncertainty estimation, which is essential for reliable decision-making in healthcare. To address these challenges, we propose \textit{AutoHealth}, a novel uncertainty-aware multi-agent system that autonomously models health data and assesses model reliability. \textit{AutoHealth} employs closed-loop coordination among five specialized agents to perform data exploration, task-conditioned model construction, training, and optimization, while jointly prioritizing predictive performance and uncertainty quantification. Beyond producing ready-to-use models, the system generates comprehensive reports to support trustworthy interpretation and risk-aware decision-making. To rigorously evaluate its effectiveness, we curate a challenging real-world benchmark comprising 17 tasks across diverse data modalities and learning settings. \textit{AutoHealth} completes all tasks and outperforms state-of-the-art baselines by 29.2\% in prediction performance and 50.2\% in uncertainty estimation.

</details>


### [523] [EvoOpt-LLM: Evolving industrial optimization models with large language models](https://arxiv.org/abs/2602.01082)
*Yiliu He,Tianle Li,Binghao Ji,Zhiyuan Liu,Di Huang*

Main category: cs.AI

TL;DR: EvoOpt-LLM：基于大语言模型的工业优化建模框架，通过少量样本实现自动化模型构建、约束注入和变量剪枝，显著降低专家依赖并提升求解效率。


<details>
  <summary>Details</summary>
Motivation: 工业规划调度中，将自然语言需求转化为MILP模型并随业务规则演化维护需要大量专家知识，现有LLM方法存在数据效率低、求解器有效性差、工业规模扩展性不足等问题。

Method: 基于7B参数LLM，采用参数高效的LoRA微调，构建支持全生命周期的统一框架，包括自动化模型构建、动态业务约束注入和端到端变量剪枝三个模块。

Result: 仅用3000训练样本达到91%生成率和65.9%可执行率，关键性能在1500样本内显现；约束注入可靠增强现有MILP模型，变量剪枝在400样本下对中等LP模型达到约0.56 F1分数。

Conclusion: EvoOpt-LLM展示了工业优化建模的实用数据高效方法，减少专家干预的同时提升适应性和求解器效率，为自动化优化建模提供可行路径。

Abstract: Optimization modeling via mixed-integer linear programming (MILP) is fundamental to industrial planning and scheduling, yet translating natural-language requirements into solver-executable models and maintaining them under evolving business rules remains highly expertise-intensive. While large language models (LLMs) offer promising avenues for automation, existing methods often suffer from low data efficiency, limited solver-level validity, and poor scalability to industrial-scale problems. To address these challenges, we present EvoOpt-LLM, a unified LLM-based framework supporting the full lifecycle of industrial optimization modeling, including automated model construction, dynamic business-constraint injection, and end-to-end variable pruning. Built on a 7B-parameter LLM and adapted via parameter-efficient LoRA fine-tuning, EvoOpt-LLM achieves a generation rate of 91% and an executability rate of 65.9% with only 3,000 training samples, with critical performance gains emerging under 1,500 samples. The constraint injection module reliably augments existing MILP models while preserving original objectives, and the variable pruning module enhances computational efficiency, achieving an F1 score of ~0.56 on medium-sized LP models with only 400 samples. EvoOpt-LLM demonstrates a practical, data-efficient approach to industrial optimization modeling, reducing reliance on expert intervention while improving adaptability and solver efficiency.

</details>


### [524] [Hard Constraints Meet Soft Generation: Guaranteed Feasibility for LLM-based Combinatorial Optimization](https://arxiv.org/abs/2602.01090)
*Yang Liu,Chuan Zhou,Yancheng Chen,Shuai Zhang,Xixun Lin,Xiaoqing Wang*

Main category: cs.AI

TL;DR: FALCON框架通过语法约束解码、可行性修复层和自适应采样确保组合优化问题的100%可行性，同时使用BOPO训练方法提升解的质量。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在组合优化中表现出潜力，但缺乏保证解可行性的机制，这在现实世界部署中至关重要。

Method: 提出FALCON框架，包含：1) 语法约束解码保证句法有效性；2) 可行性修复层纠正语义约束违反；3) 自适应Best-of-N采样高效分配推理计算。训练方法采用基于目标差距加权的BOPO偏好优化。

Result: 理论证明BOPO收敛性并提供修复引起的质量损失界限。在七个NP难组合优化问题上，FALCON实现完美可行性，同时匹配或超越最先进的神经和LLM求解器的解质量。

Conclusion: FALCON框架成功解决了LLM在组合优化中缺乏可行性保证的核心问题，通过创新的解码、修复和训练方法，实现了100%可行性同时保持高质量解。

Abstract: Large language models (LLMs) have emerged as promising general-purpose solvers for combinatorial optimization (CO), yet they fundamentally lack mechanisms to guarantee solution feasibility which is critical for real-world deployment. In this work, we introduce FALCON, a framework that ensures 100\% feasibility through three key innovations: (i) \emph{grammar-constrained decoding} enforces syntactic validity, (ii) a \emph{feasibility repair layer} corrects semantic constraint violations, and (iii) \emph{adaptive Best-of-$N$ sampling} allocates inference compute efficiently. To train the underlying LLM, we introduce the Best-anchored Objective-guided Preference Optimization (BOPO) in LLM training, which weights preference pairs by their objective gap, providing dense supervision without human labels. Theoretically, we prove convergence for BOPO and provide bounds on repair-induced quality loss. Empirically, across seven NP-hard CO problems, FALCON achieves perfect feasibility while matching or exceeding the solution quality of state-of-the-art neural and LLM-based solvers.

</details>


### [525] [Probing RLVR training instability through the lens of objective-level hacking](https://arxiv.org/abs/2602.01103)
*Yiming Dong,Kun Fu,Haoyu Li,Xinyuan Zhu,Yurou Liu,Lijing Shao,Jieping Ye,Zheng Wang*

Main category: cs.AI

TL;DR: 本文提出一个理论框架，通过"目标级黑客攻击"的视角理解RLVR训练不稳定性，特别针对MoE架构，揭示了训练-推理差异异常增长的根本机制。


<details>
  <summary>Details</summary>
Motivation: 尽管强化学习与可验证奖励（RLVR）能持续提升大语言模型的推理能力，但在MoE架构中训练常不稳定。这种不稳定性严重损害模型能力提升，但其根本原因和机制尚不清楚。

Method: 引入基于"目标级黑客攻击"的理论框架，与奖励黑客不同，目标级黑客源于token级信用错位，表现为优化目标中的系统级虚假信号。通过在30B MoE模型上进行大量实验，追踪并形式化MoE模型中关键病理训练动态的机制。

Result: 揭示了MoE模型中训练-推理差异异常增长现象的根本原因和机制，这种现象广泛与不稳定性相关但之前缺乏机制性解释。为MoE模型中的不稳定训练动态提供了具体且因果性的解释。

Conclusion: 这些发现提供了MoE模型中不稳定训练动态的具体因果解释，为设计稳定的RLVR算法提供了指导。提出的理论框架有助于理解RLVR训练中的不稳定性问题。

Abstract: Prolonged reinforcement learning with verifiable rewards (RLVR) has been shown to drive continuous improvements in the reasoning capabilities of large language models, but the training is often prone to instabilities, especially in Mixture-of-Experts (MoE) architectures. Training instability severely undermines model capability improvement, yet its underlying causes and mechanisms remain poorly understood. In this work, we introduce a principled framework for understanding RLVR instability through the lens of objective-level hacking. Unlike reward hacking, which arises from exploitable verifiers, objective-level hacking emerges from token-level credit misalignment and is manifested as system-level spurious signals in the optimization objective. Grounded in our framework, together with extensive experiments on a 30B MoE model, we trace the origin and formalize the mechanism behind a key pathological training dynamic in MoE models: the abnormal growth of the training-inference discrepancy, a phenomenon widely associated with instability but previously lacking a mechanistic explanation. These findings provide a concrete and causal account of the training dynamics underlying instabilities in MoE models, offering guidance for the design of stable RLVR algorithms.

</details>


### [526] [Transforming Vehicle Diagnostics: A Multimodal Approach to Error Patterns Prediction](https://arxiv.org/abs/2602.01109)
*Hugo Math,Rainer Lienhart*

Main category: cs.AI

TL;DR: BiCarFormer：首个融合DTC序列和环境数据的多模态多标签序列分类方法，用于车辆故障模式识别，显著提升分类性能。


<details>
  <summary>Details</summary>
Motivation: 当前车辆诊断系统主要依赖诊断故障码序列，但忽略了温度、湿度、压力等环境数据，而这些上下文信息对专家诊断故障模式至关重要。真实世界数据复杂且噪声多，需要有效整合多源信息。

Method: 提出BiCarFormer双向Transformer模型，专门处理车辆事件序列，通过嵌入融合和协同注意力机制捕捉诊断代码与环境数据之间的关系，实现多模态多标签序列分类。

Result: 在包含22,137个错误码和360个错误模式的真实世界汽车数据集上，BiCarFormer相比仅使用DTC序列的传统序列模型显著提升了分类性能。

Conclusion: 整合环境上下文信息对实现更准确、鲁棒的车辆诊断至关重要，有助于降低维护成本并提升汽车行业自动化水平。

Abstract: Accurately diagnosing and predicting vehicle malfunctions is crucial for maintenance and safety in the automotive industry. While modern diagnostic systems primarily rely on sequences of vehicular Diagnostic Trouble Codes (DTCs) registered in On-Board Diagnostic (OBD) systems, they often overlook valuable contextual information such as raw sensory data (e.g., temperature, humidity, and pressure). This contextual data, crucial for domain experts to classify vehicle failures, introduces unique challenges due to its complexity and the noisy nature of real-world data. This paper presents BiCarFormer: the first multimodal approach to multi-label sequence classification of error codes into error patterns that integrates DTC sequences and environmental conditions. BiCarFormer is a bidirectional Transformer model tailored for vehicle event sequences, employing embedding fusions and a co-attention mechanism to capture the relationships between diagnostic codes and environmental data. Experimental results on a challenging real-world automotive dataset with 22,137 error codes and 360 error patterns demonstrate that our approach significantly improves classification performance compared to models that rely solely on DTC sequences and traditional sequence models. This work highlights the importance of incorporating contextual environmental information for more accurate and robust vehicle diagnostics, hence reducing maintenance costs and enhancing automation processes in the automotive industry.

</details>


### [527] [Lyapunov Stability-Aware Stackelberg Game for Low-Altitude Economy: A Control-Oriented Pruning-Based DRL Approach](https://arxiv.org/abs/2602.01131)
*Yue Zhong,Jiawen Kang,Yongju Tong,Hong-Ning Dai,Dong In Kim,Abbas Jamalipour,Shengli Xie*

Main category: cs.AI

TL;DR: 论文提出了一种面向无人机异构网络的感知-通信-计算-控制闭环框架，将通信延迟对物理控制稳定性的影响显式建模，并通过李雅普诺夫稳定性理论将抽象稳定性要求转化为可量化的资源边界，最后采用基于剪枝的PPO算法实现轻量级资源分配。


<details>
  <summary>Details</summary>
Motivation: 随着低空经济的快速发展，无人机作为关键空中基站需要支持从延迟敏感的紧急任务到带宽密集型数据流等多种服务。然而，有限的机载资源与严格的稳定性要求之间存在冲突，传统以吞吐量为中心的设计无法满足异构网络的有效性。

Method: 1) 提出感知-通信-计算-控制闭环框架，显式建模通信延迟对物理控制稳定性的影响；2) 利用李雅普诺夫稳定性理论推导控制系统状态演化与通信约束的内在映射，将稳定性要求转化为资源边界；3) 将资源分配问题建模为Stackelberg博弈，无人机作为领导者动态定价资源，用户作为跟随者优化请求；4) 提出基于剪枝的轻量级PPO算法，通过动态结构化剪枝机制压缩神经网络规模，降低计算开销。

Result: 仿真结果表明，所提方案在动态低空环境中能有效保障控制环稳定性，同时最大化系统效用。基于剪枝的PPO算法显著降低了计算开销，使无人机能够以最小推理延迟快速逼近博弈均衡。

Conclusion: 该研究突破了传统吞吐量中心的设计范式，通过将控制稳定性要求显式融入资源分配框架，为无人机异构网络提供了可靠的服务保障。轻量级PPO算法解决了边缘平台计算资源受限的问题，实现了高效稳定的资源管理。

Abstract: With the rapid expansion of the low-altitude economy, Unmanned Aerial Vehicles (UAVs) serve as pivotal aerial base stations supporting diverse services from users, ranging from latency-sensitive critical missions to bandwidth-intensive data streaming. However, the efficacy of such heterogeneous networks is often compromised by the conflict between limited onboard resources and stringent stability requirements. Moving beyond traditional throughput-centric designs, we propose a Sensing-Communication-Computing-Control closed-loop framework that explicitly models the impact of communication latency on physical control stability. To guarantee mission reliability, we leverage the Lyapunov stability theory to derive an intrinsic mapping between the state evolution of the control system and communication constraints, transforming abstract stability requirements into quantifiable resource boundaries. Then, we formulate the resource allocation problem as a Stackelberg game, where UAVs (as leaders) dynamically price resources to balance load and ensure stability, while users (as followers) optimize requests based on service urgency. Furthermore, addressing the prohibitive computational overhead of standard Deep Reinforcement Learning (DRL) on energy-constrained edge platforms, we propose a novel and lightweight pruning-based Proximal Policy Optimization (PPO) algorithm. By integrating a dynamic structured pruning mechanism, the proposed algorithm significantly compresses the neural network scale during training, enabling the UAV to rapidly approximate the game equilibrium with minimal inference latency. Simulation results demonstrate that the proposed scheme effectively secures control loop stability while maximizing system utility in dynamic low-altitude environments.

</details>


### [528] [PersistBench: When Should Long-Term Memories Be Forgotten by LLMs?](https://arxiv.org/abs/2602.01146)
*Sidharth Pulipaka,Oliver Chen,Manas Sharma,Taaha S Bajwa,Vyas Raina,Ivaxi Sheth*

Main category: cs.AI

TL;DR: 论文提出PersistBench基准测试，用于评估LLM长时记忆带来的安全风险，发现现有模型在跨域泄漏和记忆诱导谄媚问题上存在高失败率。


<details>
  <summary>Details</summary>
Motivation: 随着对话助手越来越多地将长时记忆与LLM集成，记忆的持久性虽然能增强个性化，但也带来了被忽视的安全风险，需要系统性地评估这些风险。

Method: 提出PersistBench基准测试，识别两种长时记忆特有风险：跨域泄漏（LLM不适当地从长时记忆中注入上下文）和记忆诱导谄媚（存储的长时记忆暗中强化用户偏见）。在18个前沿和开源LLM上进行评估。

Result: 评估结果显示LLM在这些风险上存在惊人的高失败率：跨域样本中位数失败率为53%，谄媚样本中位数失败率为97%。

Conclusion: 长时记忆集成存在重大安全风险，PersistBench基准测试旨在促进开发更鲁棒、更安全的长时记忆使用方案，提升前沿对话系统的安全性。

Abstract: Conversational assistants are increasingly integrating long-term memory with large language models (LLMs). This persistence of memories, e.g., the user is vegetarian, can enhance personalization in future conversations. However, the same persistence can also introduce safety risks that have been largely overlooked. Hence, we introduce PersistBench to measure the extent of these safety risks. We identify two long-term memory-specific risks: cross-domain leakage, where LLMs inappropriately inject context from the long-term memories; and memory-induced sycophancy, where stored long-term memories insidiously reinforce user biases. We evaluate 18 frontier and open-source LLMs on our benchmark. Our results reveal a surprisingly high failure rate across these LLMs - a median failure rate of 53% on cross-domain samples and 97% on sycophancy samples. To address this, our benchmark encourages the development of more robust and safer long-term memory usage in frontier conversational systems.

</details>


### [529] [Capabilities and Fundamental Limits of Latent Chain-of-Thought](https://arxiv.org/abs/2602.01148)
*Jiaxuan Zou,Yaozhong Xiong,Yong Liu*

Main category: cs.AI

TL;DR: 本文揭示了潜在思维链模型性能不一致的根本原因：决策确定性导致的探索-执行权衡，并提出了通过符号指数量化决策承诺的理论框架。


<details>
  <summary>Details</summary>
Motivation: 潜在思维链模型在推理任务中表现出令人困惑的性能不一致性：在探索任务（如ProsQA）上表现出色（97.0%），但在计算任务（如GSM8K）上表现不佳（34.1%）。这种矛盾现象需要理论解释。

Method: 1. 理论分析探索-执行权衡，证明高确定性支持精确执行但抑制探索，低确定性促进搜索但导致错误累积；2. 引入符号指数量化决策承诺，建立其与执行稳定性和探索能力的因果关系；3. 证明课程学习的理论必要性。

Result: 揭示了决策确定性是潜在思维链模型性能不一致的核心机制，提出了从二元架构选择转向自适应系统的设计范式转变，系统能够根据任务需求动态调节决策确定性。

Conclusion: 潜在思维链模型的性能不一致源于决策确定性导致的探索-执行权衡，通过符号指数量化和动态调节决策确定性，可以设计出更有效的自适应推理系统。

Abstract: Latent Chain-of-Thought (Latent CoT) models promise efficient reasoning via continuous representations, yet exhibit puzzling performance inconsistencies: excelling at exploration (ProsQA: 97.0%) but failing at computation (GSM8K: 34.1%). We reveal that this trade-off is governed by decisional certainty. Our contributions are threefold: (1) We theoretically characterize the fundamental Exploration-Execution Trade-off, proving that high certainty enables precise execution but inhibits exploration, while low certainty facilitates search but causes error accumulation. (2) We introduce the Symbolic Index--quantifying decisional commitment--as the core mechanism governing this trade-off and establish its causal relationship with both execution stability and exploration capability. (3) We prove that curriculum learning is theoretically necessary, as direct training provably fails due to distributional mismatch. Our framework shifts the design paradigm from binary architectural choices toward adaptive systems that dynamically regulate decisional certainty based on task demands.

</details>


### [530] [Multi-Agent Causal Reasoning System for Error Pattern Rule Automation in Vehicles](https://arxiv.org/abs/2602.01155)
*Hugo Math,Julian Lorentz,Stefan Oelsner,Rainer Lienhart*

Main category: cs.AI

TL;DR: CAREP是一个多智能体系统，通过因果发现和基于代理的推理，自动从车辆诊断故障码序列中生成错误模式规则，取代传统人工编写规则的方法。


<details>
  <summary>Details</summary>
Motivation: 随着车辆复杂度增加，传统由领域专家手动编写错误模式规则的方法变得昂贵且容易出错，需要自动化解决方案来生成准确、可解释的故障诊断规则。

Method: CAREP采用多智能体架构：因果发现代理识别DTC-EP关系，上下文信息代理整合元数据和描述，编排代理合成布尔规则并提供可解释的推理轨迹。

Result: 在包含29,100个独特DTC和474个错误模式的大规模汽车数据集上，CAREP能够自动准确地发现未知EP规则，优于仅使用LLM的基线方法，并提供透明的因果解释。

Conclusion: CAREP通过结合实用因果发现和基于代理的推理，向全自动故障诊断迈进一步，实现了可扩展、可解释且成本效益高的车辆维护解决方案。

Abstract: Modern vehicles generate thousands of different discrete events known as Diagnostic Trouble Codes (DTCs). Automotive manufacturers use Boolean combinations of these codes, called error patterns (EPs), to characterize system faults and ensure vehicle safety. Yet, EP rules are still manually handcrafted by domain experts, a process that is expensive and prone to errors as vehicle complexity grows. This paper introduces CAREP (Causal Automated Reasoning for Error Patterns), a multi-agent system that automatizes the generation of EP rules from high-dimensional event sequences of DTCs. CAREP combines a causal discovery agent that identifies potential DTC-EP relations, a contextual information agent that integrates metadata and descriptions, and an orchestrator agent that synthesizes candidate boolean rules together with interpretable reasoning traces. Evaluation on a large-scale automotive dataset with over 29,100 unique DTCs and 474 error patterns demonstrates that CAREP can automatically and accurately discover the unknown EP rules, outperforming LLM-only baselines while providing transparent causal explanations. By uniting practical causal discovery and agent-based reasoning, CAREP represents a step toward fully automated fault diagnostics, enabling scalable, interpretable, and cost-efficient vehicle maintenance.

</details>


### [531] [Do All Individual Layers Help? An Empirical Study of Task-Interfering Layers in Vision-Language Models](https://arxiv.org/abs/2602.01167)
*Zhiming Liu,Yujie Wei,Lei Feng,Xiu Su,Xiaobo Xia,Weili Guan,Zeke Xie,Shuo Yang*

Main category: cs.AI

TL;DR: 研究发现预训练视觉语言模型存在任务干扰层，提出任务层交互向量量化层影响，并开发无需训练的TaLo方法动态绕过干扰层提升性能


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在预训练后默认使用所有层进行下游任务预测，但研究发现某些层会阻碍而非帮助特定任务，需要探索如何识别并绕过这些干扰层

Method: 通过层干预实验测量各层对任务性能的影响，提出任务层交互向量量化层效应，开发TaLo方法在推理时动态识别并绕过最干扰的层

Result: TaLo无需参数更新即可提升多种模型和数据集性能，如在ScienceQA的Maps任务上将Qwen-VL准确率提升16.6%，揭示了预训练VLM中意外的模块化特性

Conclusion: 预训练视觉语言模型存在任务干扰层，任务层交互向量能有效量化层影响，TaLo提供了一种即插即用、无需训练的推理时优化机制来释放模型隐藏能力

Abstract: Current VLMs have demonstrated capabilities across a wide range of multimodal tasks. Typically, in a pretrained VLM, all layers are engaged by default to make predictions on downstream tasks. We find that intervening on a single layer, such as by zeroing its parameters, can improve the performance on certain tasks, indicating that some layers hinder rather than help downstream tasks. We systematically investigate how individual layers influence different tasks via layer intervention. Specifically, we measure the change in performance relative to the base model after intervening on each layer and observe improvements when bypassing specific layers. This improvement can be generalizable across models and datasets, indicating the presence of Task-Interfering Layers that harm downstream tasks' performance. We introduce Task-Layer Interaction Vector, which quantifies the effect of intervening on each layer of a VLM given a task. These task-interfering layers exhibit task-specific sensitivity patterns: tasks requiring similar capabilities show consistent response trends under layer interventions, as evidenced by the high similarity in their task-layer interaction vectors. Inspired by these findings, we propose TaLo (Task-Adaptive Layer Knockout), a training-free, test-time adaptation method that dynamically identifies and bypasses the most interfering layer for a given task. Without parameter updates, TaLo improves performance across various models and datasets, including boosting Qwen-VL's accuracy on the Maps task in ScienceQA by up to 16.6%. Our work reveals an unexpected form of modularity in pretrained VLMs and provides a plug-and-play, training-free mechanism to unlock hidden capabilities at inference time. The source code will be publicly available.

</details>


### [532] [ASP-Bench: From Natural Language to Logic Programs](https://arxiv.org/abs/2602.01171)
*Stefan Szeider*

Main category: cs.AI

TL;DR: ASP-Bench是一个包含128个自然语言问题实例的基准测试，用于评估将自然语言问题转换为答案集程序（ASP）的系统，覆盖了ASP的各种特性，并通过基于ReAct框架的智能体方法展示了反馈驱动迭代精炼的有效性。


<details>
  <summary>Details</summary>
Motivation: 将自然语言规范自动转换为逻辑程序是神经符号工程中的一个挑战性任务。当前缺乏系统评估这种转换能力的基准测试，特别是针对答案集程序（ASP）这种重要逻辑编程形式。

Method: 创建ASP-Bench基准测试，包含128个自然语言问题实例（64个基础问题及其难易变体），覆盖ASP的各种特性（选择规则、聚合、优化等）。每个问题都包含参考验证器。使用基于ReAct框架的智能体方法进行测试，通过反馈驱动的迭代精炼来建模自然语言问题。

Result: 基准测试系统覆盖了ASP的各种特性，并通过七个独立的推理维度（优化、时序推理、默认逻辑、资源分配、递归、空间推理和定量复杂性）来表征问题难度。基于ReAct的智能体方法实现了完全饱和，表明反馈驱动的迭代精炼是建模自然语言ASP问题的可靠方法。

Conclusion: ASP-Bench为评估自然语言到ASP的转换系统提供了全面的基准测试。基于ReAct的智能体方法展示了反馈驱动迭代精炼的有效性，并且通过多维度分析可以深入理解问题建模难度的决定因素。

Abstract: Automating the translation of natural-language specifications into logic programs is a challenging task that affects neurosymbolic engineering. We present ASP-Bench, a benchmark comprising 128 natural language problem instances, 64 base problems with easy and hard variants. It evaluates systems that translate natural-language problems into Answer Set Programs (ASPs), a prominent form of logic programming. It provides systematic coverage of ASP features, including choice rules, aggregates, and optimization. Each problem includes reference validators that check whether solutions satisfy the problem specification.
  We characterize problems along seven largely independent reasoning aspects (optimization, temporal reasoning, default logic, resource allocation, recursion, spatial reasoning, and quantitative complexity), providing a multidimensional view of modeling difficulty.
  We test the benchmark using an agentic approach based on the ReAct (Reason and Act) framework, which achieves full saturation, demonstrating that feedback-driven iterative refinement with solver feedback provides a reliable and robust approach for modeling natural language in ASP. Our analysis across multiple agent runs enables us to gain insights into what determines a problem's modeling hardness.

</details>


### [533] [A State-Transition Framework for Efficient LLM Reasoning](https://arxiv.org/abs/2602.01198)
*Liang Zhang,Yu Zhao,Longyue Wang,Tianqi Shi,Weihua Luo,Kaifu Zhang,Jinsong Su*

Main category: cs.AI

TL;DR: 提出一个基于状态转移的高效推理框架，使用线性注意力机制降低计算复杂度，同时通过状态推理策略缓解过度思考问题，在提升LLMs推理效率的同时提高推理性能。


<details>
  <summary>Details</summary>
Motivation: 长思维链推理虽然能提升大语言模型在复杂任务上的性能，但生成长思维链序列会带来巨大的计算和内存开销，限制了其效率和实用性。现有研究通常通过压缩思维链序列来提高推理效率，但这与测试时扩展相冲突，限制了模型的推理能力。

Method: 将LLMs的推理过程建模为状态转移过程：1）使用线性注意力机制估计推理状态，记录历史推理信息；2）基于查询提示和推理状态，LLM高效执行当前推理步骤并更新状态；3）提出基于状态的推理策略来缓解因噪声推理步骤导致的过度思考问题。

Result: 在多个数据集和模型规模上的广泛实验表明，该框架不仅显著提高了LLMs的推理效率（注意力计算复杂度从二次降低到线性），还增强了推理性能。

Conclusion: 提出的高效推理框架通过状态转移建模和线性注意力机制，在保持甚至提升推理能力的同时，显著降低了计算开销，解决了长思维链推理的效率和实用性限制问题。

Abstract: While Long Chain-of-Thought (CoT) reasoning significantly improves Large Language Models (LLMs) performance on complex reasoning tasks, the substantial computational and memory costs of generating long CoT sequences limit their efficiency and practicality. Existing studies usually enhance the reasoning efficiency of LLMs by compressing CoT sequences. However, this approach conflicts with test-time scaling, limiting the reasoning capacity of LLMs. In this paper, we propose an efficient reasoning framework that models the reasoning process of LLMs as a state-transition process. Specifically, we first apply a linear attention mechanism to estimate the LLM's reasoning state, which records the historical reasoning information from previous reasoning steps. Then, based on the query prompt and the reasoning state, the LLM can efficiently perform the current reasoning step and update the state. With the linear attention, each token in the current reasoning step can directly retrieve relevant historical reasoning information from the reasoning state, without explicitly attending to tokens in previous reasoning steps. In this way, the computational complexity of attention is reduced from quadratic to linear, significantly improving the reasoning efficiency of LLMs. In addition, we propose a state-based reasoning strategy to mitigate the over-thinking issue caused by noisy reasoning steps. Extensive experiments across multiple datasets and model sizes demonstrate that our framework not only improves the reasoning efficiency of LLMs but also enhances their reasoning performance.

</details>


### [534] [Workflow-R1: Group Sub-sequence Policy Optimization for Multi-turn Workflow Construction](https://arxiv.org/abs/2602.01202)
*Mingze Kong,Zikun Qu,Zhongquan Zhou,Pengyu Liang,Xiang Li,Zhiwei Shang,Zhi Hong,Kaiyu Huang,Zhiyong Wang,Zhongxiang Dai*

Main category: cs.AI

TL;DR: Workflow-R1将工作流构建重新定义为多轮自然语言顺序决策过程，引入GSsPO算法解决优化粒度不匹配问题，在多个QA基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有工作流优化方法通常将工作流合成视为静态、一次性的代码生成问题，这过度约束了模型的编码能力，限制了动态问题解决的灵活性。

Method: 提出Workflow-R1框架，将工作流构建重新定义为多轮自然语言顺序决策过程。引入Group Sub-sequence Policy Optimization (GSsPO)算法，将优化单元重新校准为复合子序列（原子Think-Action循环），使梯度更新与交互的语义边界对齐。

Result: 在多个QA基准测试中，Workflow-R1超越了竞争基线，验证了GSsPO作为顺序推理的通用解决方案的有效性。

Conclusion: Workflow-R1为自动化工作流优化提供了一个有前景的新范式，GSsPO算法可推广到广泛的智能体顺序决策任务中。

Abstract: The rapid evolution of agentic workflows has demonstrated strong performance of LLM-based agents in addressing complex reasoning tasks. However, existing workflow optimization methods typically formulate workflow synthesis as a static, one-shot code-centric generation problem. This paradigm imposes excessive constraints on the model's coding capabilities and restricts the flexibility required for dynamic problem-solving. In this paper, we present Workflow-R1, a framework that reformulates workflow construction as a multi-turn, natural language-based sequential decision-making process. To resolve the optimization granularity mismatch inherent in such multi-turn interactions, we introduce Group Sub-sequence Policy Optimization (GSsPO). While explicitly tailored to align with the interleaved Think-Action dynamics of agentic reasoning, GSsPO fundamentally functions as a structure-aware RL algorithm generalizable to a broad class of multi-turn agentic sequential decision-making tasks. By recalibrating the optimization unit to the composite sub-sequence, specifically the atomic Think-Action cycle, it aligns gradient updates with the semantic boundaries of these interactions, ensuring robust learning in complex multi-turn reasoning tasks. Through extensive experiments on multiple QA benchmarks, Workflow-R1 outperforms competitive baselines, validating GSsPO as a generalized solution for sequential reasoning and establishing Workflow-R1 as a promising new paradigm for automated workflow optimization.

</details>


### [535] [Addressing Explainability of Generative AI using SMILE (Statistical Model-agnostic Interpretability with Local Explanations)](https://arxiv.org/abs/2602.01206)
*Zeinab Dehghani*

Main category: cs.AI

TL;DR: gSMILE是一个统一的生成模型可解释性框架，通过文本扰动、Wasserstein距离和加权代理建模来量化提示组件对模型输出的影响，为LLMs提供细粒度token级归因，为图像编辑模型分析指令修改的影响。


<details>
  <summary>Details</summary>
Motivation: 生成式AI模型虽然能产生复杂的文本和视觉输出，但其决策过程不透明，限制了在高风险应用中的信任和问责。需要开发能够解释生成模型决策过程的框架。

Method: 扩展SMILE方法到生成式场景，使用文本输入的受控扰动、Wasserstein距离度量和加权代理建模来量化和可视化提示或指令中特定组件对模型输出的影响。结合基于场景的评估策略和操作设计域框架。

Result: gSMILE为LLMs提供细粒度token级归因并生成直观的热力图，突出显示有影响的token和推理路径；在图像编辑模型中分析指令修改对结果图像的影响。实验表明gSMILE产生稳健、与人类对齐的归因，并能有效泛化到最先进的生成模型。

Conclusion: gSMILE有潜力推动生成式AI技术的透明、可靠和负责任部署，通过提供系统化的模型行为评估和解释质量度量，增强了生成模型的可解释性和可信度。

Abstract: The rapid advancement of generative artificial intelligence has enabled models capable of producing complex textual and visual outputs; however, their decision-making processes remain largely opaque, limiting trust and accountability in high-stakes applications. This thesis introduces gSMILE, a unified framework for the explainability of generative models, extending the Statistical Model-agnostic Interpretability with Local Explanations (SMILE) method to generative settings. gSMILE employs controlled perturbations of textual input, Wasserstein distance metrics, and weighted surrogate modelling to quantify and visualise how specific components of a prompt or instruction influence model outputs. Applied to Large Language Models (LLMs), gSMILE provides fine-grained token-level attribution and generates intuitive heatmaps that highlight influential tokens and reasoning pathways. In instruction-based image editing models, the exact text-perturbation mechanism is employed, allowing for the analysis of how modifications to an editing instruction impact the resulting image. Combined with a scenario-based evaluation strategy grounded in the Operational Design Domain (ODD) framework, gSMILE allows systematic assessment of model behaviour across diverse semantic and environmental conditions. To evaluate explanation quality, we define rigorous attribution metrics, including stability, fidelity, accuracy, consistency, and faithfulness, and apply them across multiple generative architectures. Extensive experiments demonstrate that gSMILE produces robust, human-aligned attributions and generalises effectively across state-of-the-art generative models. These findings highlight the potential of gSMILE to advance transparent, reliable, and responsible deployment of generative AI technologies.

</details>


### [536] [Not All Preferences Are Created Equal: Stability-Aware and Gradient-Efficient Alignment for Reasoning Models](https://arxiv.org/abs/2602.01207)
*Hui Wu,Hengyi Cai,Jinman Zhao,Xinran Chen,Ziheng Li,Zhejun Zhao,Shuaiqiang Wang,Yuchen Li,Dawei Yin*

Main category: cs.AI

TL;DR: SAGE提出了一种动态框架，通过最大化策略更新的信噪比来增强对齐可靠性，相比静态方法能显著加速收敛并提升性能。


<details>
  <summary>Details</summary>
Motivation: 标准偏好对齐方法（如DPO）通常将所有偏好对同等对待，忽视了训练实例的演化效用。这种静态方法导致低效或不稳定的优化：浪费计算资源在梯度可忽略的平凡对上，并受到决策边界附近样本噪声的影响。

Method: SAGE整合了粗粒度课程机制（根据模型能力刷新候选池）和细粒度稳定性感知评分函数（优先处理信息丰富、置信度高的错误，同时过滤不稳定样本），以最大化策略更新的信噪比。

Result: 在多个数学推理基准测试中，SAGE显著加速了收敛速度，并优于静态基线方法。

Conclusion: 研究强调了在推理对齐中采用策略感知、稳定性意识的数据选择的关键作用，动态框架能有效提升对齐效率和可靠性。

Abstract: Preference-based alignment is pivotal for training large reasoning models; however, standard methods like Direct Preference Optimization (DPO) typically treat all preference pairs uniformly, overlooking the evolving utility of training instances. This static approach often leads to inefficient or unstable optimization, as it wastes computation on trivial pairs with negligible gradients and suffers from noise induced by samples near uncertain decision boundaries. Facing these challenges, we propose SAGE (Stability-Aware Gradient Efficiency), a dynamic framework designed to enhance alignment reliability by maximizing the Signal-to-Noise Ratio of policy updates. Concretely, SAGE integrates a coarse-grained curriculum mechanism that refreshes candidate pools based on model competence with a fine-grained, stability-aware scoring function that prioritizes informative, confident errors while filtering out unstable samples. Experiments on multiple mathematical reasoning benchmarks demonstrate that SAGE significantly accelerates convergence and outperforms static baselines, highlighting the critical role of policy-aware, stability-conscious data selection in reasoning alignment.

</details>


### [537] [FutureMind: Equipping Small Language Models with Strategic Thinking-Pattern Priors via Adaptive Knowledge Distillation](https://arxiv.org/abs/2602.01222)
*Shaoxiong Yang,Junting Li,Mengyuan Zhang,Chao Li,Wei Liu,Jian Luan*

Main category: cs.AI

TL;DR: FutureMind：通过从大语言模型自适应知识蒸馏，为小语言模型配备战略思维模式先验的模块化推理框架，在复杂知识密集型任务上实现最先进性能。


<details>
  <summary>Details</summary>
Motivation: 小语言模型在资源受限场景中具有吸引力，但在需要结构化推理和有效检索的复杂知识密集型任务上表现不佳。需要一种方法让SLMs获得更强的推理能力而不牺牲效率。

Method: 提出FutureMind模块化推理框架，通过自适应知识蒸馏从LLMs向SLMs传递思维模式先验。框架包含四个关键模块：问题分析、逻辑推理、策略规划和检索指导，并采用三种不同的检索范式将复杂查询分解为可处理的子问题。

Result: 在2WikiMultihopQA、MuSiQue、Bamboogle和Frames等多跳QA基准测试中，FutureMind始终优于Search-o1等强基线，在自由训练条件下实现了最先进的结果，适用于不同架构和规模的SLMs。

Conclusion: FutureMind成功提升了SLMs在复杂任务上的性能，但分析发现思维模式蒸馏过程受到教师（LLMs）和学生（SLMs）模型之间认知偏差瓶颈的限制，这为推理技能的可迁移性提供了新视角，为开发兼具效率和真正认知能力的SLMs铺平了道路。

Abstract: Small Language Models (SLMs) are attractive for cost-sensitive and resource-limited settings due to their efficient, low-latency inference. However, they often struggle with complex, knowledge-intensive tasks that require structured reasoning and effective retrieval. To address these limitations, we propose FutureMind, a modular reasoning framework that equips SLMs with strategic thinking-pattern priors via adaptive knowledge distillation from large language models (LLMs). FutureMind introduces a dynamic reasoning pipeline composed of four key modules: Problem Analysis, Logical Reasoning, Strategy Planning, and Retrieval Guidance. This pipeline is augmented by three distinct retrieval paradigms that decompose complex queries into tractable subproblems, ensuring efficient and accurate retrieval execution. Extensive experiments on multi-hop QA benchmarks, including 2WikiMultihopQA, MuSiQue, Bamboogle, and Frames, demonstrate the superiority of FutureMind. It consistently outperforms strong baselines such as Search-o1, achieving state-of-the-art results under free training conditions across diverse SLM architectures and scales. Beyond empirical gains, our analysis reveals that the process of thinking-pattern distillation is restricted by the cognitive bias bottleneck between the teacher (LLMs) and student (SLMs) models. This provides new perspectives on the transferability of reasoning skills, paving the way for the development of SLMs that combine efficiency with genuine cognitive capability.

</details>


### [538] [Predictive Scheduling for Efficient Inference-Time Reasoning in Large Language Models](https://arxiv.org/abs/2602.01237)
*Katrina Brown,Aneesh Muppidi,Rana Shahout*

Main category: cs.AI

TL;DR: 论文提出Predictive Scheduling框架，使用轻量级预测器在生成前预估查询的推理长度/难度，动态分配固定token预算以最大化准确率，在GSM8K上相比均匀分配提升7.9%准确率。


<details>
  <summary>Details</summary>
Motivation: 现有LLM使用固定token预算处理复杂推理任务时，简单问题会过度计算，困难问题则计算不足，导致计算效率低下。需要一种方法在生成前预测查询难度，动态分配计算资源。

Method: 提出Predictive Scheduling框架：1) 使用轻量级预测器（基于中间层隐藏状态的MLP或基于问题文本的LoRA微调分类器）在生成前预估查询的最优推理长度/难度；2) 贪心批量分配器动态分配固定总token预算给不同查询以最大化预期准确率。

Result: 在GSM8K算术基准测试中，相比均匀token分配，预测调度在相同token成本下获得7.9个百分点的绝对准确率提升，缩小了与完美预知oracle之间超过50%的差距。系统层间研究显示中间层（12-17层）包含最丰富的规模估计信号。

Conclusion: 预运行预算预测能够精细控制计算-准确率权衡，为延迟敏感、成本高效的LLM部署提供了具体路径。中间层隐藏状态包含丰富的难度预测信号，轻量级预测器可在生成前有效指导计算资源分配。

Abstract: Large language models (LLMs) achieve state-of-the-art accuracy on complex reasoning tasks by generating multiple chain-of-thought (CoT) traces, but using a fixed token budget per query leads to over-computation on easy inputs and under-computation on hard ones. We introduce Predictive Scheduling, a plug-and-play framework that pre-runs lightweight predictors, an MLP on intermediate transformer hidden states or a LoRA-fine-tuned classifier on raw question text, to estimate each query's optimal reasoning length or difficulty before any full generation. Our greedy batch allocator dynamically distributes a fixed total token budget across queries to maximize expected accuracy. On the GSM8K arithmetic benchmark, predictive scheduling yields up to 7.9 percentage points of absolute accuracy gain over uniform budgeting at identical token cost, closing over 50\% of the gap to an oracle with perfect foresight. A systematic layer-wise study reveals that middle layers (12 - 17) of the transformer carry the richest signals for size estimation. These results demonstrate that pre-run budget prediction enables fine-grained control of the compute-accuracy trade-off, offering a concrete path toward latency-sensitive, cost-efficient LLM deployments.

</details>


### [539] [LLM-Driven Ontology Construction for Enterprise Knowledge Graphs](https://arxiv.org/abs/2602.01276)
*Abdulsobur Oyewale,Tommaso Soru*

Main category: cs.AI

TL;DR: OntoEKG：基于LLM的自动化企业知识图谱本体构建流水线，从非结构化数据生成领域本体


<details>
  <summary>Details</summary>
Motivation: 企业知识图谱需要统一异构数据并实施语义治理，但底层本体构建仍是资源密集型的手动过程，严重依赖领域专家。需要自动化方法来加速领域特定本体的生成。

Method: 提出OntoEKG流水线，将建模任务分解为两个阶段：1) 提取模块识别核心类和属性；2) 蕴含模块将这些元素逻辑结构化到层次结构中，然后序列化为标准RDF。使用从数据、金融和物流领域文档中提取的新评估数据集。

Result: 在数据领域实现了模糊匹配F1分数0.724，展示了该方法的潜力，但也揭示了在范围定义和层次推理方面的局限性。

Conclusion: LLM驱动的本体构建流水线有潜力加速企业知识图谱开发，但需要解决范围定义和层次推理的挑战。该方法为自动化本体生成提供了有前景的方向。

Abstract: Enterprise Knowledge Graphs have become essential for unifying heterogeneous data and enforcing semantic governance. However, the construction of their underlying ontologies remains a resource-intensive, manual process that relies heavily on domain expertise. This paper introduces OntoEKG, a LLM-driven pipeline designed to accelerate the generation of domain-specific ontologies from unstructured enterprise data. Our approach decomposes the modelling task into two distinct phases: an extraction module that identifies core classes and properties, and an entailment module that logically structures these elements into a hierarchy before serialising them into standard RDF. Addressing the significant lack of comprehensive benchmarks for end-to-end ontology construction, we adopt a new evaluation dataset derived from documents across the Data, Finance, and Logistics sectors. Experimental results highlight both the potential and the challenges of this approach, achieving a fuzzy-match F1-score of 0.724 in the Data domain while revealing limitations in scope definition and hierarchical reasoning.

</details>


### [540] [RE-MCDF: Closed-Loop Multi-Expert LLM Reasoning for Knowledge-Grounded Clinical Diagnosis](https://arxiv.org/abs/2602.01297)
*Shaowei Shen,Xiaohong Yang,Jie Yang,Lianfen Huang,Yongcai Zhang,Yang Zou,Seyyedali Hosseinalipour*

Main category: cs.AI

TL;DR: RE-MCDF提出了一种关系增强的多专家临床诊断框架，通过生成-验证-修订闭环架构整合三个互补组件，解决电子病历数据稀疏、噪声大以及现有方法忽视疾病间逻辑依赖关系的问题。


<details>
  <summary>Details</summary>
Motivation: 神经科电子病历具有异构性、稀疏性和噪声性，给LLMs临床诊断带来挑战。单智能体系统容易产生自我强化的错误，而现有多智能体框架交互浅层且松散，未能反映临床专家的严谨证据驱动过程，更重要的是忽视了疾病间的逻辑依赖关系（如互斥性、病理兼容性、诊断混淆）。

Method: RE-MCDF采用生成-验证-修订闭环架构，包含三个组件：1）生成候选诊断和支持证据的主要专家；2）动态优先处理异构临床指标的实验室专家；3）强制执行疾病间逻辑约束的多关系感知与评估专家组。在医学知识图谱指导下，前两个专家自适应重新加权EMR证据，专家组验证和修正候选诊断以确保逻辑一致性。

Result: 在CMEMR神经学子集（NEEMRs）和自建数据集（XMEMRs）上的广泛实验表明，RE-MCDF在复杂诊断场景中始终优于最先进的基线方法。

Conclusion: RE-MCDF通过整合多专家协作和显式逻辑约束，有效解决了临床诊断中的自我强化错误和逻辑不一致问题，为复杂医疗场景提供了更可靠的诊断框架。

Abstract: Electronic medical records (EMRs), particularly in neurology, are inherently heterogeneous, sparse, and noisy, which poses significant challenges for large language models (LLMs) in clinical diagnosis. In such settings, single-agent systems are vulnerable to self-reinforcing errors, as their predictions lack independent validation and can drift toward spurious conclusions. Although recent multi-agent frameworks attempt to mitigate this issue through collaborative reasoning, their interactions are often shallow and loosely structured, failing to reflect the rigorous, evidence-driven processes used by clinical experts. More fundamentally, existing approaches largely ignore the rich logical dependencies among diseases, such as mutual exclusivity, pathological compatibility, and diagnostic confusion. This limitation prevents them from ruling out clinically implausible hypotheses, even when sufficient evidence is available. To overcome these, we propose RE-MCDF, a relation-enhanced multi-expert clinical diagnosis framework. RE-MCDF introduces a generation--verification--revision closed-loop architecture that integrates three complementary components: (i) a primary expert that generates candidate diagnoses and supporting evidence, (ii) a laboratory expert that dynamically prioritizes heterogeneous clinical indicators, and (iii) a multi-relation awareness and evaluation expert group that explicitly enforces inter-disease logical constraints. Guided by a medical knowledge graph (MKG), the first two experts adaptively reweight EMR evidence, while the expert group validates and corrects candidate diagnoses to ensure logical consistency. Extensive experiments on the neurology subset of CMEMR (NEEMRs) and on our curated dataset (XMEMRs) demonstrate that RE-MCDF consistently outperforms state-of-the-art baselines in complex diagnostic scenarios.

</details>


### [541] [Model Specific Task Similarity for Vision Language Model Selection via Layer Conductance](https://arxiv.org/abs/2602.01346)
*Wei Yang,Hong Xie,Tao Tan,Xin Li,Defu Lian,Enhong Chen*

Main category: cs.AI

TL;DR: 提出基于视觉编码器内部功能动态的VLM选择框架，通过方向性电导散度（DCD）量化源任务对目标任务功能块的覆盖程度，无需直接推理即可预测模型排名。


<details>
  <summary>Details</summary>
Motivation: 当前开源视觉语言模型（VLM）众多，但为特定下游任务选择最优预训练模型仍具挑战性。现有选择方法要么依赖数据密集型代理，要么使用对称文本描述符，忽略了迁移性的方向性和模型特异性。

Method: 提出基于视觉编码器内部功能动态的框架：1）通过层间电导表示任务；2）通过熵正则化对齐得到目标条件块重要性分布；3）引入方向性电导散度（DCD），量化源任务覆盖目标任务显著功能块的效果；4）通过聚合源任务排名预测目标模型排名，无需直接推理。

Result: 在48个VLM和21个数据集上的实验表明，该方法优于现有最佳基线，在NDCG@5指标上比SWAB提升14.7%。

Conclusion: 该方法通过分析视觉编码器的内部功能动态，提供了一种高效、无需直接推理的VLM选择方案，显著提升了模型选择的准确性和效率。

Abstract: While open sourced Vision-Language Models (VLMs) have proliferated, selecting the optimal pretrained model for a specific downstream task remains challenging. Exhaustive evaluation is often infeasible due to computational constraints and data limitations in few shot scenarios. Existing selection methods fail to fully address this: they either rely on data-intensive proxies or use symmetric textual descriptors that neglect the inherently directional and model-specific nature of transferability. To address this problem, we propose a framework that grounds model selection in the internal functional dynamics of the visual encoder. Our approach represents each task via layer wise conductance and derives a target-conditioned block importance distribution through entropy regularized alignment. Building on this, we introduce Directional Conductance Divergence (DCD), an asymmetric metric that quantifies how effectively a source task covers the target's salient functional blocks. This allows for predicting target model rankings by aggregating source task ranks without direct inference. Experimental results on 48 VLMs across 21 datasets demonstrate that our method outperforms state-of-the-art baselines, achieving a 14.7% improvement in NDCG@5 over SWAB.

</details>


### [542] [Aggregation Queries over Unstructured Text: Benchmark and Agentic Method](https://arxiv.org/abs/2602.01355)
*Haojia Zhu,Qinyuan Xu,Haoyu Li,Yuxi Liu,Hanchen Qiu,Jiaoyan Chen,Jiahui Jin*

Main category: cs.AI

TL;DR: 该论文提出了AGGBench基准测试和DFA框架，用于解决文本聚合查询中的完整性问题，相比现有方法显著提升了证据覆盖率。


<details>
  <summary>Details</summary>
Motivation: 文本聚合查询是一个长期存在但未充分探索的问题。与普通问答不同，聚合查询需要完整的证据收集，系统必须"找到所有"而不仅仅是"找到一个"。现有的Text-to-SQL和检索增强生成方法无法实现这种完整性要求。

Method: 提出了DFA（消歧-过滤-聚合）框架，这是一个模块化的智能体基线，将聚合查询分解为可解释的阶段：消歧、过滤和聚合，并暴露与歧义、过滤和聚合相关的关键失败模式。

Result: 实验结果表明，DFA在强RAG和智能体基线上持续提高了聚合证据覆盖率。在AGGBench基准测试中表现出色。

Conclusion: 该工作形式化了实体级聚合查询问题，提出了AGGBench基准测试和DFA框架，为解决文本聚合查询的完整性问题提供了有效方案，代码和数据已开源。

Abstract: Aggregation query over free text is a long-standing yet underexplored problem. Unlike ordinary question answering, aggregate queries require exhaustive evidence collection and systems are required to "find all," not merely "find one." Existing paradigms such as Text-to-SQL and Retrieval-Augmented Generation fail to achieve this completeness. In this work, we formalize entity-level aggregation querying over text in a corpus-bounded setting with strict completeness requirement. To enable principled evaluation, we introduce AGGBench, a benchmark designed to evaluate completeness-oriented aggregation under realistic large-scale corpus. To accompany the benchmark, we propose DFA (Disambiguation--Filtering--Aggregation), a modular agentic baseline that decomposes aggregation querying into interpretable stages and exposes key failure modes related to ambiguity, filtering, and aggregation. Empirical results show that DFA consistently improves aggregation evidence coverage over strong RAG and agentic baselines. The data and code are available in https://anonymous.4open.science/r/DFA-A4C1.

</details>


### [543] [Building Better Deception Probes Using Targeted Instruction Pairs](https://arxiv.org/abs/2602.01425)
*Vikram Natarajan,Devina Jain,Shivam Arora,Satvik Golechha,Joseph Bloom*

Main category: cs.AI

TL;DR: 线性探针在检测AI欺骗行为时，训练指令对的选择至关重要，占性能差异的70.6%，应针对特定欺骗类型设计专门探针而非通用检测器


<details>
  <summary>Details</summary>
Motivation: 现有线性探针方法在检测AI系统欺骗行为时存在明显缺陷，包括虚假相关性和对非欺骗响应的误报，需要改进检测效果

Method: 通过人类可解释的欺骗分类法，针对特定欺骗行为设计训练指令对，分析指令对如何捕捉欺骗意图而非内容特定模式

Result: 指令对选择主导探针性能（占方差的70.6%），基于分类法的针对性方法在评估数据集上获得改进结果

Conclusion: 组织应针对特定威胁模型设计专门探针，而非寻求通用欺骗检测器，因为不同数据集的欺骗类型具有异质性

Abstract: Linear probes are a promising approach for monitoring AI systems for deceptive behaviour. Previous work has shown that a linear classifier trained on a contrastive instruction pair and a simple dataset can achieve good performance. However, these probes exhibit notable failures even in straightforward scenarios, including spurious correlations and false positives on non-deceptive responses. In this paper, we identify the importance of the instruction pair used during training. Furthermore, we show that targeting specific deceptive behaviors through a human-interpretable taxonomy of deception leads to improved results on evaluation datasets. Our findings reveal that instruction pairs capture deceptive intent rather than content-specific patterns, explaining why prompt choice dominates probe performance (70.6% of variance). Given the heterogeneity of deception types across datasets, we conclude that organizations should design specialized probes targeting their specific threat models rather than seeking a universal deception detector.

</details>


### [544] [SimGym: Traffic-Grounded Browser Agents for Offline A/B Testing in E-Commerce](https://arxiv.org/abs/2602.01443)
*Alberto Castelo,Zahra Zanjani Foumani,Ailin Fan,Keat Yang Koay,Vibhor Malik,Yuanzheng Zhu,Han Li,Meysam Feghhi,Ronie Uliana,Shuang Xie,Zhaoyu Zhang,Angelo Ocana Martins,Mingyu Zhao,Francis Pelland,Jonathan Faerman,Nikolas LeBlanc,Aaron Glazer,Andrew McNamara,Lingyun Wang,Zhong Wu*

Main category: cs.AI

TL;DR: SimGym是一个基于LLM代理的离线A/B测试系统，通过模拟真实买家行为在浏览器中快速测试UI变更，将实验周期从数周缩短到1小时内


<details>
  <summary>Details</summary>
Motivation: 传统A/B测试需要分流真实流量、耗时数周才能达到统计显著性，且可能损害用户体验。需要一种快速、安全的离线测试方法

Method: 从生产交互数据中提取买家画像和意图，识别行为原型，使用LLM代理在实时浏览器中模拟控制组和实验组的加权会话

Result: 即使没有对齐后训练，SimGym代理也能达到与观察结果变化的最先进对齐水平，将实验周期从数周缩短到1小时以内

Conclusion: SimGym实现了快速实验而无需暴露真实买家，为电子商务UI变更评估提供了革命性的离线测试解决方案

Abstract: A/B testing remains the gold standard for evaluating e-commerce UI changes, yet it diverts traffic, takes weeks to reach significance, and risks harming user experience. We introduce SimGym, a scalable system for rapid offline A/B testing using traffic-grounded synthetic buyers powered by Large Language Model agents operating in a live browser. SimGym extracts per-shop buyer profiles and intents from production interaction data, identifies distinct behavioral archetypes, and simulates cohort-weighted sessions across control and treatment storefronts. We validate SimGym against real human outcomes from real UI changes on a major e-commerce platform under confounder control. Even without alignment post training, SimGym agents achieve state of the art alignment with observed outcome shifts and reduces experiment cycles from weeks to under an hour , enabling rapid experimentation without exposure to real buyers.

</details>


### [545] [Agyn: A Multi-Agent System for Team-Based Autonomous Software Engineering](https://arxiv.org/abs/2602.01465)
*Nikita Benkovich,Vitalii Valkov*

Main category: cs.AI

TL;DR: 提出一个完全自动化的多智能体系统，将软件工程建模为组织化流程，模拟真实工程团队结构，在SWE-bench 500上达到72.4%的任务解决率，超越单智能体基线。


<details>
  <summary>Details</summary>
Motivation: 现有自主系统通常将问题解决视为单一或流水线式过程，而现实软件开发是团队协作活动，具有明确的角色分离、沟通和审查。需要模拟真实工程团队的组织结构来提升自主软件工程能力。

Method: 基于agyn开源平台构建多智能体系统，分配协调、研究、实现、审查等专门角色，提供隔离沙箱进行实验，支持结构化通信。系统遵循定义好的开发方法论，包括分析、任务规范、PR创建和迭代审查，完全无需人工干预。

Result: 在SWE-bench 500评估中解决了72.4%的任务，超越了使用相同语言模型的单智能体基线。系统设计面向实际生产使用，而非专门针对SWE-bench优化。

Conclusion: 模拟团队结构、方法论和沟通是自主软件工程的有效范式，未来进展可能不仅依赖模型改进，同样需要组织设计和智能体基础设施的发展。

Abstract: Large language models have demonstrated strong capabilities in individual software engineering tasks, yet most autonomous systems still treat issue resolution as a monolithic or pipeline-based process. In contrast, real-world software development is organized as a collaborative activity carried out by teams following shared methodologies, with clear role separation, communication, and review. In this work, we present a fully automated multi-agent system that explicitly models software engineering as an organizational process, replicating the structure of an engineering team. Built on top of agyn, an open-source platform for configuring agent teams, our system assigns specialized agents to roles such as coordination, research, implementation, and review, provides them with isolated sandboxes for experimentation, and enables structured communication. The system follows a defined development methodology for working on issues, including analysis, task specification, pull request creation, and iterative review, and operates without any human intervention. Importantly, the system was designed for real production use and was not tuned for SWE-bench. When evaluated post hoc on SWE-bench 500, it resolves 72.4% of tasks, outperforming single-agent baselines using comparable language models. Our results suggest that replicating team structure, methodology, and communication is a powerful paradigm for autonomous software engineering, and that future progress may depend as much on organizational design and agent infrastructure as on model improvements.

</details>


### [546] [Legal Infrastructure for Transformative AI Governance](https://arxiv.org/abs/2602.01474)
*Gillian K. Hadfield*

Main category: cs.AI

TL;DR: 本文主张AI治理不仅需要实质性规则，更需要建立法律和监管基础设施，提出了三个具体框架：前沿模型注册制度、自主代理注册识别制度、以及促进私营公司提供AI监管服务的监管市场设计。


<details>
  <summary>Details</summary>
Motivation: 当前AI治理工作过度关注实质性规则（如限制和检查），忽视了建立法律和监管基础设施的重要性。AI的变革性特征特别需要关注法律和监管框架的建设，以确保规则的有效生成和实施。

Method: 作者回顾并提出了三个具体的基础设施建设方案：1）建立前沿AI模型的注册制度；2）建立自主代理的注册和识别制度；3）设计监管市场，让私营公司能够创新并提供AI监管服务。

Result: 通过这三个框架的建立，可以构建起支撑AI治理的法律和监管基础设施，使AI规则不仅停留在纸面上，而是能够有效实施和执行。

Conclusion: AI治理的成功不仅取决于制定什么规则，更取决于建立什么样的法律和监管基础设施来生成和实施这些规则。关注监管框架建设对于应对AI的变革性影响至关重要。

Abstract: Most of our AI governance efforts focus on substance: what rules do we want in place? What limits or checks do we want to impose on AI development and deployment? But a key role for law is not only to establish substantive rules but also to establish legal and regulatory infrastructure to generate and implement rules. The transformative nature of AI calls especially for attention to building legal and regulatory frameworks. In this PNAS Perspective piece I review three examples I have proposed: the creation of registration regimes for frontier models; the creation of registration and identification regimes for autonomous agents; and the design of regulatory markets to facilitate a role for private companies to innovate and deliver AI regulatory services.

</details>


### [547] [Learning to Guide Local Search for MPE Inference in Probabilistic Graphical Models](https://arxiv.org/abs/2602.01475)
*Brij Malhotra,Shivvrat Arya,Tahrima Rahman,Vibhav Giridhar Gogate*

Main category: cs.AI

TL;DR: 提出神经摊销框架改进概率图模型中的局部搜索，通过注意力网络预测移动减少与最优解汉明距离的能力，在重复查询场景中提升MPE推理性能


<details>
  <summary>Details</summary>
Motivation: PGMs中MPE推理是基础但计算困难的问题，在实际应用中图形模型固定但需要针对不同证据模式重复推理。传统随机局部搜索算法依赖短视的最佳改进规则，容易陷入局部最优，而现有启发式方法如GLS+的指导无法在相同模型的多次推理查询中有效复用

Method: 提出神经摊销框架，利用固定图结构训练基于注意力的网络，通过预测局部移动减少与近最优解汉明距离的能力来评分移动。该方法与现有局部搜索过程无缝集成，在邻居选择中平衡短期似然增益与长期潜力

Result: 在摊销推理设置中，对具有挑战性的高树宽基准测试，相比SLS和GLS+方法取得了一致的改进

Conclusion: 神经摊销框架能有效改进重复查询场景中的局部搜索性能，通过预测距离减少移动的选择与改进收敛行为相关联，为PGMs中的MPE推理提供了更高效的解决方案

Abstract: Most Probable Explanation (MPE) inference in Probabilistic Graphical Models (PGMs) is a fundamental yet computationally challenging problem arising in domains such as diagnosis, planning, and structured prediction. In many practical settings, the graphical model remains fixed while inference must be performed repeatedly for varying evidence patterns. Stochastic Local Search (SLS) algorithms scale to large models but rely on myopic best-improvement rule that prioritizes immediate likelihood gains and often stagnate in poor local optima. Heuristics such as Guided Local Search (GLS+) partially alleviate this limitation by modifying the search landscape, but their guidance cannot be reused effectively across multiple inference queries on the same model. We propose a neural amortization framework for improving local search in this repeated-query regime. Exploiting the fixed graph structure, we train an attention-based network to score local moves by predicting their ability to reduce Hamming distance to a near-optimal solution. Our approach integrates seamlessly with existing local search procedures, using this signal to balance short-term likelihood gains with long-term promise during neighbor selection. We provide theoretical intuition linking distance-reducing move selection to improved convergence behavior, and empirically demonstrate consistent improvements over SLS and GLS+ on challenging high-treewidth benchmarks in the amortized inference setting.

</details>


### [548] [Qrita: High-performance Top-k and Top-p Algorithm for GPUs using Pivot-based Truncation and Selection](https://arxiv.org/abs/2602.01518)
*Jongseok Park,Sunga Kim,Alvin Cheung,Ion Stoica*

Main category: cs.AI

TL;DR: Qrita是一种基于枢轴选择策略的高效Top-k和Top-p算法，相比现有排序方法在GPU上实现2倍吞吐量和一半内存使用，同时保持确定性输出。


<details>
  <summary>Details</summary>
Motivation: Top-k和Top-p是大语言模型采样中的主要截断操作符，但在大规模词汇表上高效实现仍面临挑战。现有方法要么依赖排序（带来显著计算和内存开销），要么使用随机方法（改变算法输出）。

Method: 基于RTop-k的枢轴搜索思想，扩展到Top-k和Top-p：1) 高斯基sigma截断，大幅减少目标元素搜索空间；2) 四元枢轴搜索与重复处理，将枢轴搜索迭代减半并保证确定性输出。使用Triton GPU编程语言实现。

Result: 与vLLM、SGLang、Flashinfer等高性能LLM执行引擎的Top-k和Top-p内核相比，Qrita实现高达2倍的吞吐量和一半的内存使用，同时提供与排序算法相同的输出。

Conclusion: Qrita提供了一种高效、确定性的Top-k和Top-p实现方案，解决了现有方法在GPU上的计算和内存开销问题，同时保持算法输出的准确性。

Abstract: Top-k and Top-p are the dominant truncation operators in the sampling of large language models. Despite their widespread use, implementing them efficiently over large vocabularies remains a significant challenge. Existing approaches often rely on sorting, which incur significant computation and memory overhead on GPUs, or stochastic approaches, which alter the algorithm output. In this work, we propose Qrita, an efficient Top-k and Top-p algorithm based on a pivot-based selection strategy. Based on RTop-k, which uses a pivot-based search for node selection in graph neural networks, Qrita extends the concept of pivot-based search to both Top-k and Top-p with two key techniques: 1. Gaussian-based sigma-truncation, which greatly reduces the search space of the target elements, and 2. Quaternary pivot search with duplication handling, which halves the pivot search iteration and guarantees deterministic output. We provide the full implementation of Qrita using Triton, a popular GPU programming language. Our evaluation of Qrita against the Top-k and Top-p kernels of high performance LLM execution engines such as vLLM, SGLang, and Flashinfer show that Qrita achieves up to 2 times throughput and half memory use while providing the same output to the the sorting-based algorithms.

</details>


### [549] [PRISM: Festina Lente Proactivity -- Risk-Sensitive, Uncertainty-Aware Deliberation for Proactive Agents](https://arxiv.org/abs/2602.01532)
*Yuxuan Fu,Xiaoyu Tan,Teqi Hao,Chen Zhan,Xihe Qiu*

Main category: cs.AI

TL;DR: PRISM框架通过决策理论门控和双过程推理架构，实现智能体在成本敏感选择性干预中的精确控制，减少误报22.78%，提升F1分数20.14%


<details>
  <summary>Details</summary>
Motivation: 现有主动智能体系统依赖脆弱的启发式方法或不分青红皂白的长推理，对利益-负担权衡缺乏控制，需要更精确、可调的控制机制

Method: 提出PRISM框架：1) 决策理论门控，当用户接受概率超过基于非对称成本的阈值时干预；2) 双过程推理架构，仅在决策边界附近调用资源密集的慢模式；3) 门对齐、模式锁定的蒸馏训练，教师模型提供密集监督，学生模型学习与干预门解耦的响应策略

Result: 在ProactiveBench上，PRISM比强基线减少22.78%的误报，提升20.14%的F1分数，证明决策理论门控、选择性慢推理和对齐蒸馏能产生精确、计算高效且可控的主动智能体

Conclusion: PRISM框架通过决策理论门控、选择性慢推理和对齐蒸馏，实现了主动智能体的精确干预、计算效率和可控性，为成本敏感选择性干预问题提供了有效解决方案

Abstract: Proactive agents must decide not only what to say but also whether and when to intervene. Many current systems rely on brittle heuristics or indiscriminate long reasoning, which offers little control over the benefit-burden tradeoff. We formulate the problem as cost-sensitive selective intervention and present PRISM, a novel framework that couples a decision-theoretic gate with a dual-process reasoning architecture. At inference time, the agent intervenes only when a calibrated probability of user acceptance exceeds a threshold derived from asymmetric costs of missed help and false alarms. Inspired by festina lente (Latin: "make haste slowly"), we gate by an acceptance-calibrated, cost-derived threshold and invoke a resource-intensive Slow mode with counterfactual checks only near the decision boundary, concentrating computation on ambiguous and high-stakes cases. Training uses gate-aligned, schema-locked distillation: a teacher running the full PRISM pipeline provides dense, executable supervision on unlabeled interaction traces, while the student learns a response policy that is explicitly decoupled from the intervention gate to enable tunable and auditable control. On ProactiveBench, PRISM reduces false alarms by 22.78% and improves F1 by 20.14% over strong baselines. These results show that principled decision-theoretic gating, paired with selective slow reasoning and aligned distillation, yields proactive agents that are precise, computationally efficient, and controllable. To facilitate reproducibility, we release our code, models, and resources at https://prism-festinalente.github.io/; all experiments use the open-source ProactiveBench benchmark.

</details>


### [550] [MAGIC: A Co-Evolving Attacker-Defender Adversarial Game for Robust LLM Safety](https://arxiv.org/abs/2602.01539)
*Xiaoyu Wen,Zhida He,Han Qi,Ziyu Wan,Zhongtian Ma,Ying Wen,Tianhang Zheng,Xingcheng Xu,Chaochao Lu,Qiaosheng Zhang*

Main category: cs.AI

TL;DR: MAGIC是一个多轮多智能体强化学习框架，将LLM安全对齐建模为对抗性非对称博弈，通过攻击者和防御者的共同进化来提升模型安全性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM安全防御方法依赖静态预收集数据分布，难以应对不断演化的对抗攻击，需要动态自适应机制来提升安全对齐的鲁棒性。

Method: 提出MAGIC框架：攻击者智能体学习迭代重写原始查询为欺骗性提示，防御者智能体同时优化策略来识别并拒绝此类输入，形成共同进化过程。

Result: 实验验证了框架的有效性，展示了优越的防御成功率且不损害模型的有用性，攻击者通过RL训练演化出新颖的未见过的组合策略。

Conclusion: MAGIC通过动态对抗训练实现了LLM安全对齐的鲁棒性提升，为安全对齐提供了理论保证和实用框架，代码已开源。

Abstract: Ensuring robust safety alignment is crucial for Large Language Models (LLMs), yet existing defenses often lag behind evolving adversarial attacks due to their \textbf{reliance on static, pre-collected data distributions}. In this paper, we introduce \textbf{MAGIC}, a novel multi-turn multi-agent reinforcement learning framework that formulates LLM safety alignment as an adversarial asymmetric game. Specifically, an attacker agent learns to iteratively rewrite original queries into deceptive prompts, while a defender agent simultaneously optimizes its policy to recognize and refuse such inputs. This dynamic process triggers a \textbf{co-evolution}, where the attacker's ever-changing strategies continuously uncover long-tail vulnerabilities, driving the defender to generalize to unseen attack patterns. Remarkably, we observe that the attacker, endowed with initial reasoning ability, evolves \textbf{novel, previously unseen combinatorial strategies} through iterative RL training, underscoring our method's substantial potential. Theoretically, we provide insights into a more robust game equilibrium and derive safety guarantees. Extensive experiments validate our framework's effectiveness, demonstrating superior defense success rates without compromising the helpfulness of the model. Our code is available at https://github.com/BattleWen/MAGIC.

</details>


### [551] [S1-NexusAgent: a Self-Evolving Agent Framework for Multidisciplinary Scientific Research](https://arxiv.org/abs/2602.01550)
*S1-NexusAgent Team*

Main category: cs.AI

TL;DR: S1-NexusAgent是一个自演化的科学智能体框架，采用分层Plan-and-CodeAct执行范式，通过双循环架构解耦全局科学规划与子任务工具执行，支持跨学科工具集成和持续自我进化，在多个科学基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM和基于工具的智能体在处理大规模数据、复杂工作流和专用工具时存在局限，特别是在长时程规划、鲁棒目标维持和持续学习方面。科学研究的复杂性需要更强大的智能体框架。

Method: 采用分层Plan-and-CodeAct执行范式，双循环架构解耦全局规划与子任务执行。支持MCP协议，集成数千个跨学科工具，通过意图感知动态工具检索和热插拔机制实现异构工具编排。引入基于对象引用的稀疏上下文管理，Critic Agent评估执行轨迹并提炼高质量研究路径为可重用科学技能。

Result: 在生物、化学、材料科学等权威科学基准测试（biomini-eval, ChemBench, MatSciBench）中，S1-NexusAgent实现了最先进的性能，验证了其在复杂科学任务中的有效性和泛化能力。

Conclusion: S1-NexusAgent通过自演化架构有效解决了科学研究的复杂性挑战，为可持续和长时程科学研究提供了有价值的解决方案，展示了在跨学科科学任务中的强大能力。

Abstract: Modern scientific research relies on large-scale data, complex workflows, and specialized tools, which existing LLMs and tool-based agents struggle to handle due to limitations in long-horizon planning, robust goal maintenance, and continual learning from execution. To address these issues, in this work, we propose S1-NexusAgent, a self-evolving agent framework designed for multidisciplinary scientific research. S1-NexusAgent adopts a hierarchical Plan-and-CodeAct execution paradigm, decoupling global scientific planning from subtask-level tool execution through a dual-loop architecture, thereby enabling stable modeling of complex research workflows. The system natively supports the Model Context Protocol (MCP), integrates up to thousands of cross-disciplinary scientific tools, and achieves efficient orchestration of heterogeneous research tools via intention-aware dynamic tool retrieval and hot-plug mechanisms. To address long-context and large-scale data challenges in scientific settings, S1-NexusAgent introduces object-reference-based sparse context management, which enables sub-task context isolation and intermediate result compression. Building on this, a Critic Agent automatically evaluates complete execution trajectories and distills high-quality research paths into reusable Scientific Skills, forming a closed loop for continuous self-evolution, which is valuable for sustainable and long-horizon scientific research. Experiments on authoritative scientific benchmarks involving long-horizon planning and complex specialized tool orchestration, including biomini-eval (biology), ChemBench (chemistry), and MatSciBench (material science), demonstrate that S1-NexusAgent achieves state-of-the-art performance, validating its effectiveness and generalization capability in complex scientific tasks.

</details>


### [552] [Autonomous Question Formation for Large Language Model-Driven AI Systems](https://arxiv.org/abs/2602.01556)
*Hong Su*

Main category: cs.AI

TL;DR: 提出基于人类模拟的框架，使AI系统能通过推理内部状态、环境观察和与其他AI系统的交互来自主形成问题和设定任务。


<details>
  <summary>Details</summary>
Motivation: 现有LLM驱动的AI系统大多依赖预定义任务和固定提示，限制了其在环境变化时自主识别应解决问题的能力。

Method: 将问题形成作为任务选择和执行之前的一等决策过程，整合内部驱动、环境感知和智能体间感知的提示范围来逐步扩展认知覆盖，支持从经验中学习问题形成过程。

Result: 在多智能体模拟环境中，环境感知提示显著减少了无进食事件，智能体间感知提示在20天模拟中将累积无进食事件进一步减少60%以上，具有统计显著性(p<0.05)。

Conclusion: 该框架使AI系统能够自主形成问题和设定任务，提高在动态开放环境中的适应性和决策质量。

Abstract: Large language model (LLM)-driven AI systems are increasingly important for autonomous decision-making in dynamic and open environments. However, most existing systems rely on predefined tasks and fixed prompts, limiting their ability to autonomously identify what problems should be solved when environmental conditions change. In this paper, we propose a human-simulation-based framework that enables AI systems to autonomously form questions and set tasks by reasoning over their internal states, environmental observations, and interactions with other AI systems. The proposed method treats question formation as a first-class decision process preceding task selection and execution, and integrates internal-driven, environment-aware, and inter-agent-aware prompting scopes to progressively expand cognitive coverage. In addition, the framework supports learning the question-formation process from experience, allowing the system to improve its adaptability and decision quality over time. xperimental results in a multi-agent simulation environment show that environment-aware prompting significantly reduces no-eat events compared with the internal-driven baseline, and inter-agent-aware prompting further reduces cumulative no-eat events by more than 60% over a 20-day simulation, with statistically significant improvements (p < 0.05).

</details>


### [553] [Reasoning with Autoregressive-Diffusion Collaborative Thoughts](https://arxiv.org/abs/2602.01608)
*Mu Yuan,Liekang Zeng,Guoliang Xing,Lan Zhang,Yunhao Liu*

Main category: cs.AI

TL;DR: 提出Collaborative Thoughts框架，让自回归模型和扩散模型通过闭环交互协同工作，结合两者的优势进行生成任务


<details>
  <summary>Details</summary>
Motivation: 自回归模型擅长序列规划和约束组合，但缺乏空间物理基础；扩散模型能捕捉丰富空间结构，但缺乏逐步逻辑控制。需要结合两者优势解决复杂多阶段约束任务

Method: 建立协作框架：自回归模型负责结构化规划和约束管理，扩散模型将约束实例化为中间视觉表示，视觉批评模块评估是否满足结构物理要求，通过反馈迭代优化

Result: 通过代表性示例证明，Collaborative Thoughts能提高空间推理的可靠性和生成的可控性，减少跨模态错误传播

Conclusion: 提出统一的协作框架，使自回归和扩散模型能够通过相同协作循环联合推理和生成，无论任务是自回归问答还是扩散视觉生成

Abstract: Autoregressive and diffusion models represent two complementary generative paradigms. Autoregressive models excel at sequential planning and constraint composition, yet struggle with tasks that require explicit spatial or physical grounding. Diffusion models, in contrast, capture rich spatial structure through high-dimensional generation, but lack the stepwise logical control needed to satisfy complex, multi-stage constraints or to reliably identify and correct errors. We introduce Collaborative Thoughts, a unified collaborative framework that enables autoregressive and diffusion models to reason and generate jointly through a closed-loop interaction. In Collaborative Thoughts, autoregressive models perform structured planning and constraint management, diffusion models instantiate these constraints as intermediate visual thoughts, and a vision-based critic module evaluates whether the visual thoughts satisfy the intended structural and physical requirements. This feedback is then used to iteratively refine subsequent planning and generation steps, mitigating error propagation across modalities. Importantly, Collaborative Thoughts uses the same collaborative loop regardless of whether the task is autoregressive question answering or diffusion-based visual generation. Through representative examples, we illustrate how Collaborative Thoughts can improve the reliability of spatial reasoning and the controllability of generation.

</details>


### [554] [ToPT: Task-Oriented Prompt Tuning for Urban Region Representation Learning](https://arxiv.org/abs/2602.01610)
*Zitao Guo,Changyang Jiang,Tianhong Zhao,Jinzhou Cao,Genan Dai,Bowen Zhang*

Main category: cs.AI

TL;DR: ToPT：一个两阶段框架，通过空间感知区域嵌入学习和任务感知提示，实现空间一致性融合和显式任务对齐，提升城市计算任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在两个问题：1）两阶段方法产生任务无关表示，与下游目标解耦；2）基于提示的方法缺乏明确的空间先验（导致空间不连贯）和鲁棒的任务语义对齐机制。

Method: 提出ToPT两阶段框架：1）SREL模块使用Graphormer融合模块，注入距离和区域中心性作为可学习注意力偏置，捕获连贯的区域交互；2）Prompt4RE模块使用冻结的多模态大语言模型处理任务特定模板获得语义向量，通过多头交叉注意力与区域嵌入对齐。

Result: 在多个任务和城市的实验中达到最先进性能，性能提升高达64.2%，验证了空间先验和提示-区域对齐的必要性和互补性。

Conclusion: ToPT通过结合空间感知区域嵌入学习和任务感知提示，有效解决了现有方法的局限性，为城市计算任务提供了更有效的区域表示学习框架。

Abstract: Learning effective region embeddings from heterogeneous urban data underpins key urban computing tasks (e.g., crime prediction, resource allocation). However, prevailing two-stage methods yield task-agnostic representations, decoupling them from downstream objectives. Recent prompt-based approaches attempt to fix this but introduce two challenges: they often lack explicit spatial priors, causing spatially incoherent inter-region modeling, and they lack robust mechanisms for explicit task-semantic alignment. We propose ToPT, a two-stage framework that delivers spatially consistent fusion and explicit task alignment. ToPT consists of two modules: spatial-aware region embedding learning (SREL) and task-aware prompting for region embeddings (Prompt4RE). SREL employs a Graphormer-based fusion module that injects spatial priors-distance and regional centrality-as learnable attention biases to capture coherent, interpretable inter-region interactions. Prompt4RE performs task-oriented prompting: a frozen multimodal large language model (MLLM) processes task-specific templates to obtain semantic vectors, which are aligned with region embeddings via multi-head cross-attention for stable task conditioning. Experiments across multiple tasks and cities show state-of-the-art performance, with improvements of up to 64.2\%, validating the necessity and complementarity of spatial priors and prompt-region alignment. The code is available at https://github.com/townSeven/Prompt4RE.git.

</details>


### [555] [ProjDevBench: Benchmarking AI Coding Agents on End-to-End Project Development](https://arxiv.org/abs/2602.01655)
*Pengrui Lu,Shiqi Zhang,Yunzhong Hou,Lyumanshan Ye,Chaoyi Huang,Zixi Chen,Ji Zeng,Hantao Jiang,Pengfei Liu,Yiwei Wang,Ming-Hsuan Yang*

Main category: cs.AI

TL;DR: ProjDevBench是一个端到端的编码代理基准测试，通过项目需求评估代码库质量，结合在线评测和LLM辅助代码审查，涵盖系统架构设计、功能正确性和迭代优化，结果显示当前代理在复杂系统设计和优化方面仍有困难。


<details>
  <summary>Details</summary>
Motivation: 现有编码代理评估主要关注问题级别的bug修复，缺乏端到端的开发评估。需要一个新的基准测试来评估编码代理从简单提示生成完整代码库的能力。

Method: 引入ProjDevBench基准测试，提供项目需求给编码代理并评估生成的代码库。结合在线评测(Online Judge)测试和LLM辅助代码审查，评估系统架构设计、功能正确性和迭代解决方案优化。收集了8个类别的20个编程问题，涵盖概念导向任务和真实应用场景。

Result: 评估了6个基于不同LLM后端的编码代理，总体接受率为27.38%。代理能够处理基本功能和数据结构，但在复杂系统设计、时间复杂度优化和资源管理方面表现不佳。

Conclusion: ProjDevBench为编码代理提供了端到端的评估框架，揭示了当前代理在复杂系统设计和优化方面的局限性，为未来编码代理的发展提供了重要参考。

Abstract: Recent coding agents can generate complete codebases from simple prompts, yet existing evaluations focus on issue-level bug fixing and lag behind end-to-end development. We introduce ProjDevBench, an end-to-end benchmark that provides project requirements to coding agents and evaluates the resulting repositories. Combining Online Judge (OJ) testing with LLM-assisted code review, the benchmark evaluates agents on (1) system architecture design, (2) functional correctness, and (3) iterative solution refinement. We curate 20 programming problems across 8 categories, covering both concept-oriented tasks and real-world application scenarios, and evaluate six coding agents built on different LLM backends. Our evaluation reports an overall acceptance rate of 27.38%: agents handle basic functionality and data structures but struggle with complex system design, time complexity optimization, and resource management. Our benchmark is available at https://github.com/zsworld6/projdevbench.

</details>


### [556] [FlowSteer: Interactive Agentic Workflow Orchestration via End-to-End Reinforcement Learning](https://arxiv.org/abs/2602.01664)
*Mingda Zhang,Haoran Luo,Tiesunlong Shen,Qika Lin,Xiaoying Tang,Rui Mao,Erik Cambria*

Main category: cs.AI

TL;DR: FlowSteer：基于强化学习的端到端工作流编排框架，通过轻量级策略模型与可执行画布环境的多轮交互自动化工作流编排，支持多样化算子库和可替换LLM后端。


<details>
  <summary>Details</summary>
Motivation: 现有工作流编排面临高人工成本、依赖特定算子/大语言模型、稀疏奖励信号等关键挑战，需要更自动化和灵活的解决方案。

Method: 提出FlowSteer框架，包含轻量级策略模型作为智能体与可执行画布环境交互；策略模型分析执行状态并选择编辑动作，画布执行算子并返回反馈；采用Canvas Workflow Relative Policy Optimization (CWRPO)训练方法，引入多样性约束奖励和条件释放机制稳定学习并抑制捷径行为。

Result: 在12个数据集上的实验结果表明，FlowSteer在各种任务上显著优于基线方法。

Conclusion: FlowSteer通过强化学习框架有效解决了工作流编排的自动化挑战，提供了支持多样化算子和可替换LLM后端的即插即用解决方案，显著提升了工作流编排的性能和灵活性。

Abstract: In recent years, a variety of powerful agentic workflows have been applied to solve a wide range of human problems. However, existing workflow orchestration still faces key challenges, including high manual cost, reliance on specific operators/large language models (LLMs), and sparse reward signals. To address these challenges, we propose FlowSteer, an end-to-end reinforcement learning framework that takes a lightweight policy model as the agent and an executable canvas environment, automating workflow orchestration through multi-turn interaction. In this process, the policy model analyzes execution states and selects editing actions, while the canvas executes operators and returns feedback for iterative refinement. Moreover, FlowSteer provides a plug-and-play framework that supports diverse operator libraries and interchangeable LLM backends. To effectively train this interaction paradigm, we propose Canvas Workflow Relative Policy Optimization (CWRPO), which introduces diversity-constrained rewards with conditional release to stabilize learning and suppress shortcut behaviors. Experimental results on twelve datasets show that FlowSteer significantly outperforms baselines across various tasks.

</details>


### [557] [TRIP-Bench: A Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios](https://arxiv.org/abs/2602.01675)
*Yuanzhe Shen,Zisu Huang,Zhengyuan Wang,Muzhao Tian,Zhengkang Guo,Chenyang Zhang,Shuaiyu Zhou,Zengjie Hu,Dailin Li,Jingwen Xu,Kaimin Wang,Wenhao Liu,Tianlong Li,Fengpeng Yue,Feng Hong,Cao Liu,Ke Zeng*

Main category: cs.AI

TL;DR: TRIP-Bench是一个基于真实旅行规划场景的长时程基准测试，包含18个工具和40+旅行需求，支持自动评估。实验显示先进模型在简单分割上最多只有50%成功率，在困难分割上低于10%。提出的GTPO在线强化学习方法在Qwen2.5-32B-Instruct上提升了约束满足和交互鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试无法充分代表现实世界中的关键挑战，如强制执行全局约束、协调多工具推理以及适应长期多轮交互中不断变化的用户行为。需要一个新的基准测试来弥补这一差距。

Method: 引入TRIP-Bench基准测试，基于真实旅行规划场景，包含18个精选工具和40+旅行需求，支持自动评估。提出GTPO（在线多轮强化学习方法），采用专门的奖励归一化和奖励差分技术。

Result: 实验显示先进模型在简单分割上最多只有50%成功率，在困难分割上低于10%。GTPO应用于Qwen2.5-32B-Instruct后，提升了约束满足和交互鲁棒性，在评估中超越了Gemini-3-Pro。

Conclusion: TRIP-Bench有望推动实用的长时程交互智能体发展，GTPO为鲁棒的长时程训练提供了有效的在线强化学习方案。

Abstract: As LLM-based agents are deployed in increasingly complex real-world settings, existing benchmarks underrepresent key challenges such as enforcing global constraints, coordinating multi-tool reasoning, and adapting to evolving user behavior over long, multi-turn interactions. To bridge this gap, we introduce \textbf{TRIP-Bench}, a long-horizon benchmark grounded in realistic travel-planning scenarios. TRIP-Bench leverages real-world data, offers 18 curated tools and 40+ travel requirements, and supports automated evaluation. It includes splits of varying difficulty; the hard split emphasizes long and ambiguous interactions, style shifts, feasibility changes, and iterative version revision. Dialogues span up to 15 user turns, can involve 150+ tool calls, and may exceed 200k tokens of context. Experiments show that even advanced models achieve at most 50\% success on the easy split, with performance dropping below 10\% on hard subsets. We further propose \textbf{GTPO}, an online multi-turn reinforcement learning method with specialized reward normalization and reward differencing. Applied to Qwen2.5-32B-Instruct, GTPO improves constraint satisfaction and interaction robustness, outperforming Gemini-3-Pro in our evaluation. We expect TRIP-Bench to advance practical long-horizon interactive agents, and GTPO to provide an effective online RL recipe for robust long-horizon training.

</details>


### [558] [What LLMs Think When You Don't Tell Them What to Think About?](https://arxiv.org/abs/2602.01689)
*Yongchan Kwon,James Zou*

Main category: cs.AI

TL;DR: 研究发现大型语言模型在无主题输入下会表现出系统性主题偏好，不同模型家族有显著差异，GPT-OSS偏好编程和数学，Llama偏好文学，DeepSeek偏好宗教内容，Qwen偏好选择题，同时观察到退化重复现象。


<details>
  <summary>Details</summary>
Motivation: 现有LLM分析多依赖特定主题或任务的提示，限制了观察范围。本研究旨在通过最小化、主题中性的输入探索LLM近乎无约束的生成行为，以更全面地理解模型特性。

Method: 使用最小化、主题中性的输入对16个LLM进行近乎无约束的生成测试，收集256,000个样本，分析不同模型家族的主题偏好、内容专业度和退化行为。

Result: 不同模型家族表现出强烈的系统性主题偏好：GPT-OSS主要生成编程(27.1%)和数学内容(24.6%)，Llama偏好文学内容(9.1%)，DeepSeek偏好宗教内容，Qwen偏好选择题。GPT-OSS生成内容技术深度更高，同时观察到各模型独特的退化重复行为。

Conclusion: LLM在无约束条件下表现出强烈的内在主题偏好，这些偏好反映了模型训练数据的特性。研究揭示了模型行为的系统性差异，为LLM监控和安全提供了新视角，并发布了完整数据集和可复现代码库。

Abstract: Characterizing the behavior of large language models (LLMs) across diverse settings is critical for reliable monitoring and AI safety. However, most existing analyses rely on topic- or task-specific prompts, which can substantially limit what can be observed. In this work, we study what LLMs generate from minimal, topic-neutral inputs and probe their near-unconstrained generative behavior. Despite the absence of explicit topics, model outputs cover a broad semantic space, and surprisingly, each model family exhibits strong and systematic topical preferences. GPT-OSS predominantly generates programming (27.1%) and mathematical content (24.6%), whereas Llama most frequently generates literary content (9.1%). DeepSeek often generates religious content, while Qwen frequently generates multiple-choice questions. Beyond topical preferences, we also observe differences in content specialization and depth: GPT-OSS often generates more technically advanced content (e.g., dynamic programming) compared with other models (e.g., basic Python). Furthermore, we find that the near-unconstrained generation often degenerates into repetitive phrases, revealing interesting behaviors unique to each model family. For instance, degenerate outputs from Llama include multiple URLs pointing to personal Facebook and Instagram accounts. We release the complete dataset of 256,000 samples from 16 LLMs, along with a reproducible codebase.

</details>


### [559] [Beyond Dense States: Elevating Sparse Transcoders to Active Operators for Latent Reasoning](https://arxiv.org/abs/2602.01695)
*Yadong Wang,Haodong Chen,Yu Tian,Chuanxing Geng,Dong Liang,Xiang Chen*

Main category: cs.AI

TL;DR: LSTR提出了一种稀疏潜在推理框架，通过稀疏语义转换提升可解释性和可控性，同时保持推理准确性和压缩效率。


<details>
  <summary>Details</summary>
Motivation: 现有潜在推理方法依赖密集的潜在转换，难以解释和控制；而稀疏表示模型主要用于事后分析。需要一种既能进行多步推理又具有可解释性的方法。

Method: 提出LSTR框架，使用具有残差跳跃架构的潜在转换转码器，将线性流形传输与稀疏语义更新解耦，通过显式稀疏约束实现可控语义分辨率。

Result: 实验表明LSTR在保持推理准确性和压缩效率的同时，显著提高了相对于密集潜在基线的可解释性。因果干预和轨迹分析证明稀疏特征在推理过程中既是可解释的又是因果有效的操作符。

Conclusion: LSTR成功地将稀疏表示模型从后分析提升为主动推理操作符，实现了可解释且可控的多步潜在推理。

Abstract: Latent reasoning compresses the chain-of-thought (CoT) into continuous hidden states, yet existing methods rely on dense latent transitions that remain difficult to interpret and control. Meanwhile, sparse representation models uncover human-interpretable semantic features but remain largely confined to post-hoc analysis. We reconcile this tension by proposing LSTR (Latent Sparse Transcoder Reasoning), a latent reasoning framework that elevates functional sparse transcoders into active reasoning operators to perform multi-step computation through sparse semantic transitions. At its core, LSTR employs a Latent Transition Transcoder (LTT) with a residual skip architecture that decouples linear manifold transport from sparse semantic updates, enabling controllable semantic resolution via explicit sparsity constraints. Extensive experiments show that LSTR preserves reasoning accuracy and compression efficiency while substantially improving interpretability over dense latent baselines. Causal interventions and trajectory analyses further demonstrate that these sparse features act as both interpretable and causally effective operators in the reasoning process.

</details>


### [560] [Mitigating loss of control in advanced AI systems through instrumental goal trajectories](https://arxiv.org/abs/2602.01699)
*Willem Fourie*

Main category: cs.AI

TL;DR: 该论文提出"工具性目标轨迹"概念，通过监控组织获取技术资源（计算、存储、数据等）的三种路径来增强对AI系统的控制，将AI治理从单纯的技术层面扩展到组织层面。


<details>
  <summary>Details</summary>
Motivation: 当前AI治理方法过于技术中心化，主要关注模型本身的能力追踪和行为塑造，缺乏对组织层面的关注。研究人员担心高度能力的AI系统可能通过追求工具性目标侵蚀人类控制。

Method: 提出工具性目标轨迹框架，识别AI系统获取技术资源（计算、存储、数据、相邻服务）所需的三种组织路径：采购轨迹、治理轨迹和财务轨迹，通过监控这些路径产生的组织痕迹来实施干预。

Result: IGTs提供了具体的监控和干预点，能够更全面地定义能力水平，并将可纠正性和可中断性的实施从模型属性扩展到支持这些模型的组织系统。

Conclusion: 工具性目标轨迹为AI治理提供了超越技术层面的新视角，通过关注组织获取资源的路径，为控制AI系统提供了更全面的框架，将注意力从模型属性转移到支持模型的组织系统。

Abstract: Researchers at artificial intelligence labs and universities are concerned that highly capable artificial intelligence (AI) systems may erode human control by pursuing instrumental goals. Existing mitigations remain largely technical and system-centric: tracking capability in advanced systems, shaping behaviour through methods such as reinforcement learning from human feedback, and designing systems to be corrigible and interruptible. Here we develop instrumental goal trajectories to expand these options beyond the model. Gaining capability typically depends on access to additional technical resources, such as compute, storage, data and adjacent services, which in turn requires access to monetary resources. In organisations, these resources can be obtained through three organisational pathways. We label these pathways the procurement, governance and finance instrumental goal trajectories (IGTs). Each IGT produces a trail of organisational artefacts that can be monitored and used as intervention points when a systems capabilities or behaviour exceed acceptable thresholds. In this way, IGTs offer concrete avenues for defining capability levels and for broadening how corrigibility and interruptibility are implemented, shifting attention from model properties alone to the organisational systems that enable them.

</details>


### [561] [Optimizing Prompts for Large Language Models: A Causal Approach](https://arxiv.org/abs/2602.01711)
*Wei Chen,Yanbin Fang,Shuran Fu,Fasheng Xu,Xuan Wei*

Main category: cs.AI

TL;DR: CPO提出因果提示优化框架，通过双机器学习构建离线因果奖励模型，分离提示效果与查询特征，实现低成本、高精度的查询特定提示优化。


<details>
  <summary>Details</summary>
Motivation: 现有自动提示优化方法面临两个挑战：静态指令无法适应异构查询；动态方法依赖离线奖励模型，混淆提示效果与查询特征。需要更可靠、经济的优化方案。

Method: CPO采用两阶段框架：1) 对提示和查询的语义嵌入应用双机器学习，学习离线因果奖励模型，分离提示变化的因果效应；2) 利用无偏奖励信号指导资源高效的查询特定提示搜索。

Result: 在数学推理、可视化和数据分析基准测试中，CPO始终优于人工设计的提示和最先进的自动优化器，尤其在困难查询上表现出更强的鲁棒性。

Conclusion: CPO通过将评估从实时模型执行转向离线因果模型，重塑了提示优化的经济学，为企业在LLM部署中提供了可扩展、可靠且经济高效的提示优化基础。

Abstract: Large Language Models (LLMs) are increasingly embedded in enterprise workflows, yet their performance remains highly sensitive to prompt design. Automatic Prompt Optimization (APO) seeks to mitigate this instability, but existing approaches face two persistent challenges. First, commonly used prompt strategies rely on static instructions that perform well on average but fail to adapt to heterogeneous queries. Second, more dynamic approaches depend on offline reward models that are fundamentally correlational, confounding prompt effectiveness with query characteristics. We propose Causal Prompt Optimization (CPO), a framework that reframes prompt design as a problem of causal estimation. CPO operates in two stages. First, it learns an offline causal reward model by applying Double Machine Learning (DML) to semantic embeddings of prompts and queries, isolating the causal effect of prompt variations from confounding query attributes. Second, it utilizes this unbiased reward signal to guide a resource-efficient search for query-specific prompts without relying on costly online evaluation. We evaluate CPO across benchmarks in mathematical reasoning, visualization, and data analytics. CPO consistently outperforms human-engineered prompts and state-of-the-art automated optimizers. The gains are driven primarily by improved robustness on hard queries, where existing methods tend to deteriorate. Beyond performance, CPO fundamentally reshapes the economics of prompt optimization: by shifting evaluation from real-time model execution to an offline causal model, it enables high-precision, per-query customization at a fraction of the inference cost required by online methods. Together, these results establish causal inference as a scalable foundation for reliable and cost-efficient prompt optimization in enterprise LLM deployments.

</details>


### [562] [MACD: Model-Aware Contrastive Decoding via Counterfactual Data](https://arxiv.org/abs/2602.01740)
*Qixin Xiao,Kun Zhou*

Main category: cs.AI

TL;DR: MACD提出了一种新的推理策略，通过模型引导的反事实数据构建与解码相结合，减少视频语言模型的幻觉问题，在多个基准测试中显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 视频语言模型容易产生幻觉，特别是在视觉证据较弱、模糊或有偏见时。现有的解码方法（如对比解码）依赖随机扰动构建对比数据，难以控制驱动幻觉的视觉线索或与模型弱点良好对齐。

Method: 提出模型感知的反事实数据对比解码（MACD）：1）利用Video-LLM自身的反馈识别导致幻觉的关键对象区域；2）在对象级别生成有针对性的反事实输入，而非任意的帧或时序修改；3）将这些模型感知的反事实数据集成到对比解码中，在解码过程中强制基于证据的token选择。

Result: 在EventHallusion、MVBench、Perception-test和Video-MME等基准测试中，MACD一致地减少了幻觉，同时维持或提升了任务准确性，适用于包括Qwen和InternVL系列在内的多种Video-LLM。该方法在处理涉及小物体、遮挡物体或共现物体的挑战性场景时特别有效。

Conclusion: MACD通过模型引导的反事实数据构建与解码相结合，提供了一种有效的推理策略来减少视频语言模型的幻觉问题，代码和数据将公开。

Abstract: Video language models (Video-LLMs) are prone to hallucinations, often generating plausible but ungrounded content when visual evidence is weak, ambiguous, or biased. Existing decoding methods, such as contrastive decoding (CD), rely on random perturbations to construct contrastive data for mitigating hallucination patterns. However, such a way is hard to control the visual cues that drive hallucination or well align with model weaknesses. We propose Model-aware Counterfactual Data based Contrastive Decoding (MACD), a new inference strategy that combines model-guided counterfactual construction with decoding. Our approach uses the Video-LLM's own feedback to identify object regions most responsible for hallucination, generating targeted counterfactual inputs at the object level rather than arbitrary frame or temporal modifications. These model-aware counterfactual data is then integrated into CD to enforce evidence-grounded token selection during decoding. Experiments on EventHallusion, MVBench, Perception-test and Video-MME show that MACD consistently reduces hallucination while maintaining or improving task accuracy across diverse Video-LLMs, including Qwen and InternVL families. The method is especially effective in challenging scenarios involving small, occluded, or co-occurring objects. Our code and data will be publicly released.

</details>


### [563] [Controlling Exploration-Exploitation in GFlowNets via Markov Chain Perspectives](https://arxiv.org/abs/2602.01749)
*Lin Chen,Samuel Drapeau,Fanghao Shao,Xuekai Zhu,Bo Xue,Yunchong Song,Mathieu Laurière,Zhouhan Lin*

Main category: cs.AI

TL;DR: α-GFNs通过可调参数α改进GFlowNet的探索-利用平衡，在多个基准测试中显著提升模式发现能力


<details>
  <summary>Details</summary>
Motivation: 传统GFlowNet目标隐含地固定了前向和后向策略的均匀混合，这可能限制了训练过程中的探索-利用权衡。作者希望打破这种约束，增强模式发现能力。

Method: 通过建立GFlowNet目标与马尔可夫链可逆性的等价关系，揭示了约束的起源。基于此理论发现，提出了α-GFNs，通过可调参数α来泛化混合策略，直接控制探索-利用动态。

Result: 在Set、Bit Sequence和Molecule Generation等多个基准测试中，α-GFN目标始终优于先前的GFlowNet目标，模式发现数量最多提升10倍。

Conclusion: α-GFNs通过可调参数α提供了对探索-利用动态的直接控制，增强了模式发现能力，同时确保收敛到唯一流，为GFlowNets提供了更灵活的框架。

Abstract: Generative Flow Network (GFlowNet) objectives implicitly fix an equal mixing of forward and backward policies, potentially constraining the exploration-exploitation trade-off during training. By further exploring the link between GFlowNets and Markov chains, we establish an equivalence between GFlowNet objectives and Markov chain reversibility, thereby revealing the origin of such constraints, and provide a framework for adapting Markov chain properties to GFlowNets. Building on these theoretical findings, we propose $α$-GFNs, which generalize the mixing via a tunable parameter $α$. This generalization enables direct control over exploration-exploitation dynamics to enhance mode discovery capabilities, while ensuring convergence to unique flows. Across various benchmarks, including Set, Bit Sequence, and Molecule Generation, $α$-GFN objectives consistently outperform previous GFlowNet objectives, achieving up to a $10 \times$ increase in the number of discovered modes.

</details>


### [564] [Adversarial Reward Auditing for Active Detection and Mitigation of Reward Hacking](https://arxiv.org/abs/2602.01750)
*Mohammad Beigi,Ming Jin,Junshan Zhang,Qifan Wang,Lifu Huang*

Main category: cs.AI

TL;DR: 提出对抗性奖励审计（ARA）框架，将奖励黑客攻击重新定义为动态竞争游戏，通过黑客发现漏洞、审计员检测利用，再通过审计引导的RLHF惩罚检测到的黑客行为，实现更好的对齐-效用权衡。


<details>
  <summary>Details</summary>
Motivation: RLHF容易受到奖励黑客攻击，模型利用奖励模型中的虚假相关性获得高分但违反人类意图。现有缓解措施依赖静态防御，无法适应新的利用策略。

Method: ARA框架分两阶段：1) 黑客策略发现奖励模型漏洞，审计员从潜在表示中学习检测利用；2) 审计引导的RLHF（AG-RLHF）门控奖励信号以惩罚检测到的黑客行为，将奖励黑客从不可观察的失败转变为可测量、可控的信号。

Result: 在三种黑客场景中，ARA在所有基线中实现最佳对齐-效用权衡：将奉承行为降至接近SFT水平同时提高帮助性，减少冗长同时获得最高ROUGE-L，抑制代码游戏同时提高Pass@1。奖励黑客、检测和缓解都能跨领域泛化。

Conclusion: ARA通过将奖励黑客重新定义为动态竞争游戏，提供了一种可测量、可控的防御框架，能够跨领域泛化，实现高效的多领域防御。

Abstract: Reinforcement Learning from Human Feedback (RLHF) remains vulnerable to reward hacking, where models exploit spurious correlations in learned reward models to achieve high scores while violating human intent. Existing mitigations rely on static defenses that cannot adapt to novel exploitation strategies. We propose Adversarial Reward Auditing (ARA), a framework that reconceptualizes reward hacking as a dynamic, competitive game. ARA operates in two stages: first, a Hacker policy discovers reward model vulnerabilities while an Auditor learns to detect exploitation from latent representations; second, Auditor-Guided RLHF (AG-RLHF) gates reward signals to penalize detected hacking, transforming reward hacking from an unobservable failure into a measurable, controllable signal. Experiments across three hacking scenarios demonstrate that ARA achieves the best alignment-utility tradeoff among all baselines: reducing sycophancy to near-SFT levels while improving helpfulness, decreasing verbosity while achieving the highest ROUGE-L, and suppressing code gaming while improving Pass@1. Beyond single-domain evaluation, we show that reward hacking, detection, and mitigation all generalize across domains -- a Hacker trained on code gaming exhibits increased sycophancy despite no reward for this behavior, and an Auditor trained on one domain effectively suppresses exploitation in others, enabling efficient multi-domain defense with a single model.

</details>


### [565] [PRISM: Parametrically Refactoring Inference for Speculative Sampling Draft Models](https://arxiv.org/abs/2602.01762)
*Xuliang Wang,Yuetao Chen,Maochan Zhen,Fang Liu,Xinzhou Zheng,Xingwu Liu,Hong Xu,Ming Li*

Main category: cs.AI

TL;DR: PRISM是一种新的推测解码架构，通过将预测步骤的计算分解到不同参数集，解耦模型容量与推理成本，显著提升LLM解码速度


<details>
  <summary>Details</summary>
Motivation: 现有推测解码方法为了提升草稿质量而使用更大的参数化草稿模型，但这带来了显著的计算开销。需要在预测准确性和计算延迟之间取得平衡，但现有方法未能从根本上解决这一困境

Method: 提出PRISM架构，将每个预测步骤的计算分解到不同的参数集，重构草稿模型的计算路径，成功解耦模型容量与推理成本

Result: PRISM在所有现有草稿架构中表现最佳，实现了卓越的接受长度，同时保持最小的草稿延迟，获得卓越的端到端加速。在高度优化的推理引擎上，解码吞吐量提升超过2.6倍

Conclusion: PRISM通过架构创新解决了推测解码中的基本困境，比传统方法更有效地扩展，特别是在数据量增加时表现更优，为LLM加速提供了新的解决方案

Abstract: Large Language Models (LLMs), constrained by their auto-regressive nature, suffer from slow decoding. Speculative decoding methods have emerged as a promising solution to accelerate LLM decoding, attracting attention from both systems and AI research communities. Recently, the pursuit of better draft quality has driven a trend toward parametrically larger draft models, which inevitably introduces substantial computational overhead. While existing work attempts to balance the trade-off between prediction accuracy and compute latency, we address this fundamental dilemma through architectural innovation.
  We propose PRISM, which disaggregates the computation of each predictive step across different parameter sets, refactoring the computational pathways of draft models to successfully decouple model capacity from inference cost. Through extensive experiments, we demonstrate that PRISM outperforms all existing draft architectures, achieving exceptional acceptance lengths while maintaining minimal draft latency for superior end-to-end speedup. We also re-examine scaling laws with PRISM, revealing that PRISM scales more effectively with expanding data volumes than other draft architectures. Through rigorous and fair comparison, we show that PRISM boosts the decoding throughput of an already highly optimized inference engine by more than 2.6x.

</details>


### [566] [Efficient Cross-Architecture Knowledge Transfer for Large-Scale Online User Response Prediction](https://arxiv.org/abs/2602.01775)
*Yucheng Wu,Yuekui Yang,Hongzheng Li,Anan Liu,Jian Xiao,Junjie Zhai,Huan Yu,Shaoping Ma,Leye Wang*

Main category: cs.AI

TL;DR: CrossAdapt：用于用户响应预测系统的高效跨架构知识蒸馏框架，通过两阶段方法解决模型切换成本高的问题，显著提升性能并减少训练时间


<details>
  <summary>Details</summary>
Motivation: 大规模用户响应预测系统中部署新架构面临高昂的模型切换成本，包括大规模历史数据重训练的开销和数据保留约束下的性能下降。现有知识蒸馏方法难以处理架构异构性和大型嵌入表传输的过高成本。

Method: 提出两阶段框架：离线阶段通过维度自适应投影实现快速嵌入传输（无需迭代训练），结合渐进网络蒸馏和策略采样降低计算成本；在线阶段引入非对称协同蒸馏（学生频繁更新、教师稀疏更新）和分布感知适应机制，动态平衡历史知识保留与对新数据的快速适应。

Result: 在三个公共数据集上，CrossAdapt实现了0.27-0.43%的AUC提升，同时减少训练时间43-71%。在腾讯微信视频号（约1000万日样本）的大规模部署进一步验证了其有效性，显著缓解了AUC下降、LogLoss增加和预测偏差。

Conclusion: CrossAdapt为大规模推荐系统中的跨架构知识转移提供了高效解决方案，通过创新的两阶段框架解决了现有蒸馏方法的局限性，在实际部署中表现出优异的性能和效率。

Abstract: Deploying new architectures in large-scale user response prediction systems incurs high model switching costs due to expensive retraining on massive historical data and performance degradation under data retention constraints. Existing knowledge distillation methods struggle with architectural heterogeneity and the prohibitive cost of transferring large embedding tables. We propose CrossAdapt, a two-stage framework for efficient cross-architecture knowledge transfer. The offline stage enables rapid embedding transfer via dimension-adaptive projections without iterative training, combined with progressive network distillation and strategic sampling to reduce computational cost. The online stage introduces asymmetric co-distillation, where students update frequently while teachers update infrequently, together with a distribution-aware adaptation mechanism that dynamically balances historical knowledge preservation and fast adaptation to evolving data. Experiments on three public datasets show that CrossAdapt achieves 0.27-0.43% AUC improvements while reducing training time by 43-71%. Large-scale deployment on Tencent WeChat Channels (~10M daily samples) further demonstrates its effectiveness, significantly mitigating AUC degradation, LogLoss increase, and prediction bias compared to standard distillation baselines.

</details>


### [567] [LingLanMiDian: Systematic Evaluation of LLMs on TCM Knowledge and Clinical Reasoning](https://arxiv.org/abs/2602.01779)
*Rui Hua,Yu Wei,Zixin Shu,Kai Chang,Dengying Yan,Jianan Xia,Zeyu Liu,Hui Zhu,Shujie Song,Mingzhong Xiao,Xiaodong Li,Dongmei Jia,Zhuye Gao,Yanyan Meng,Naixuan Zhao,Yu Fu,Haibin Yu,Benman Yu,Yuanyuan Chen,Fei Dong,Zhizhou Meng,Pengcheng Yang,Songxue Zhao,Lijuan Pei,Yunhui Hu,Kan Ding,Jiayuan Duan,Wenmao Yin,Yang Gu,Runshun Zhang,Qiang Zhu,Jian Yu,Jiansheng Li,Baoyan Liu,Wenjia Wang,Xuezhong Zhou*

Main category: cs.AI

TL;DR: LingLanMiDian (LingLan) 是一个针对中医领域的大规模、专家标注的多任务基准测试，统一评估LLM在中医知识回忆、多跳推理、信息抽取和临床决策等方面的能力，揭示了当前模型与人类专家在中医专业推理上的显著差距。


<details>
  <summary>Details</summary>
Motivation: 当前中医领域的LLM评估存在基准测试碎片化、覆盖范围有限、评分标准不统一等问题，难以公平比较不同模型在中医这一具有独特本体论、术语和推理模式的领域的真实能力。

Method: 构建了LingLan基准测试，包含统一度量设计、临床标签的同义词容忍协议、每个数据集400项的困难子集，并将诊断和治疗建议重构为单项选择决策识别。对14个领先的开源和专有LLM进行了全面的零样本评估。

Result: 评估揭示了当前LLM在中医常识知识理解、推理和临床决策支持方面的优势和局限。在困难子集上的评估显示，当前模型与人类专家在中医专业推理方面存在显著差距。

Conclusion: LingLan通过标准化评估桥接了基础知识和应用推理，为推进中医LLM和领域特定医学AI研究建立了统一、可量化、可扩展的基础。

Abstract: Large language models (LLMs) are advancing rapidly in medical NLP, yet Traditional Chinese Medicine (TCM) with its distinctive ontology, terminology, and reasoning patterns requires domain-faithful evaluation. Existing TCM benchmarks are fragmented in coverage and scale and rely on non-unified or generation-heavy scoring that hinders fair comparison. We present the LingLanMiDian (LingLan) benchmark, a large-scale, expert-curated, multi-task suite that unifies evaluation across knowledge recall, multi-hop reasoning, information extraction, and real-world clinical decision-making. LingLan introduces a consistent metric design, a synonym-tolerant protocol for clinical labels, a per-dataset 400-item Hard subset, and a reframing of diagnosis and treatment recommendation into single-choice decision recognition. We conduct comprehensive, zero-shot evaluations on 14 leading open-source and proprietary LLMs, providing a unified perspective on their strengths and limitations in TCM commonsense knowledge understanding, reasoning, and clinical decision support; critically, the evaluation on Hard subset reveals a substantial gap between current models and human experts in TCM-specialized reasoning. By bridging fundamental knowledge and applied reasoning through standardized evaluation, LingLan establishes a unified, quantitative, and extensible foundation for advancing TCM LLMs and domain-specific medical AI research. All evaluation data and code are available at https://github.com/TCMAI-BJTU/LingLan and http://tcmnlp.com.

</details>


### [568] [ORCH: many analyses, one merge-a deterministic multi-agent orchestrator for discrete-choice reasoning with EMA-guided routing](https://arxiv.org/abs/2602.01797)
*Hanlin Zhou,Huah Yong Chan*

Main category: cs.AI

TL;DR: ORCH是一个确定性的多智能体协调框架，通过"多分析、一决策"范式，使用固定规则协调异构LLM进行离散选择推理，在多个基准测试中显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的多智能体系统通常依赖随机路由或启发式方法，导致行为难以复现、决策过程难以解释。需要一种确定性的协调框架来提高可预测性和可解释性。

Method: ORCH采用"多分析、一决策"范式：多个基础模型独立生成结构化分析，专用合并智能体输出最终选择。框架使用固定规则进行任务分解和答案聚合，保持流程可预测、可复现且无需训练。可选引入EMA引导的路由器，基于历史准确率、延迟或成本更新智能体选择。

Result: 在MMLU、MMLU-Pro和GSM8K实验中，ORCH持续优于单模型基线和多数投票集成。在MMLU-Pro上准确率提升超过10个百分点，在GSM8K上提升超过50个百分点。EMA路由器提供额外0.7-2.0个百分点的准确率提升。

Conclusion: ORCH为离散选择推理提供了一个实用路径，实现了可控、可解释且可部署的基于LLM的智能体系统，通过确定性协调框架显著提升性能。

Abstract: Recent advances in large-scale language models (LLMs) have made multi-agent architectures attractive for challenging reasoning tasks. However, many existing systems rely on stochastic routing or ad-hoc heuristics, making their behavior difficult to reproduce and their decision process hard to interpret. We propose ORCH, a deterministic coordination framework for discrete-choice reasoning that orchestrates heterogeneous LLMs. ORCH follows a ``many analyses, one decision'' paradigm: multiple base models independently produce structured analyses, and a dedicated merge agent outputs the final choice. The framework uses fixed rules for task decomposition and answer aggregation, keeping the pipeline predictable, reproducible, and training-free. Determinism here refers to fixed routing and aggregation rules under a fixed evaluation protocol, rather than strict bit-level reproducibility across deployments. To exploit model complementarity, we optionally introduce an EMA-guided router that updates agent selection using historical accuracy, latency, or cost; since it relies on answer-based feedback, it is mainly intended for benchmarking, controlled evaluation, or delayed-feedback settings. Experiments on MMLU, MMLU-Pro, and GSM8K show that ORCH consistently outperforms single-model baselines and a majority-vote ensemble. On MMLU-Pro, ORCH improves accuracy by over 10 points compared to the strongest baseline, and on GSM8K it yields gains exceeding 50 points; McNemar tests confirm statistical significance. The EMA router provides an additional 0.7--2.0 point accuracy boost, and ablations show that both multi-agent collaboration and routing contribute substantially. Overall, ORCH offers a practical path toward controllable, interpretable, and deployment-ready LLM-based agent systems for discrete-choice reasoning.

</details>


### [569] [INDIBATOR: Diverse and Fact-Grounded Individuality for Multi-Agent Debate in Molecular Discovery](https://arxiv.org/abs/2602.01815)
*Yunhui Jang,Seonghyun Park,Jaehyung Kim,Sungsoo Ahn*

Main category: cs.AI

TL;DR: INDIBATOR框架通过基于科学家个体研究轨迹（发表历史和分子历史）构建个性化智能体，在分子发现任务中超越了传统的粗粒度角色分配方法，实现了更优性能。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体科学发现系统通常采用通用的角色分配（如"评审者"、"作者"）或基于关键词的粗粒度角色，这简化了真实科学家的行为模式。实际科学家的贡献受到其独特研究轨迹的影响，需要更精细的个体化建模。

Method: 提出INDIBATOR框架，通过两种模态构建个体化科学家档案：1) 发表历史（文献知识）和2) 分子历史（结构先验）。这些智能体通过提案、批评和投票三个阶段进行多轮辩论。

Result: 基于个体化档案的精细粒度智能体持续优于依赖粗粒度角色的系统，达到竞争性或最先进的性能水平。验证了捕捉智能体的"科学DNA"对高质量发现至关重要。

Conclusion: 将智能体基于个体科学家研究轨迹进行建模，能够更真实地模拟科学发现过程，并显著提升多智能体系统在分子发现任务中的性能。

Abstract: Multi-agent systems have emerged as a powerful paradigm for automating scientific discovery. To differentiate agent behavior in the multi-agent system, current frameworks typically assign generic role-based personas such as ''reviewer'' or ''writer'' or rely on coarse grained keyword-based personas. While functional, this approach oversimplifies how human scientists operate, whose contributions are shaped by their unique research trajectories. In response, we propose INDIBATOR, a framework for molecular discovery that grounds agents in individualized scientist profiles constructed from two modalities: publication history for literature-derived knowledge and molecular history for structural priors. These agents engage in multi-turn debate through proposal, critique, and voting phases. Our evaluation demonstrates that these fine-grained individuality-grounded agents consistently outperform systems relying on coarse-grained personas, achieving competitive or state-of-the-art performance. These results validate that capturing the ``scientific DNA'' of individual agents is essential for high-quality discovery.

</details>


### [570] [Synesthesia of Vehicles: Tactile Data Synthesis from Visual Inputs](https://arxiv.org/abs/2602.01832)
*Rui Wang,Yaoguang Cao,Yuyi Chen,Jianyi Xu,Zhuoyang Li,Jiachen Shang,Shichun Yang*

Main category: cs.AI

TL;DR: 提出Synesthesia of Vehicles (SoV)框架，通过视觉输入预测自动驾驶车辆的触觉激励，使用跨模态时空对齐和基于潜在扩散的视觉-触觉生成模型，提升自动驾驶安全性。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶车辆依赖多模态融合确保安全，但现有视觉和光学传感器无法检测道路引起的激励，而这些激励对车辆动态控制至关重要。受人类联觉启发，需要开发从视觉预测触觉激励的方法。

Method: 1. 提出Synesthesia of Vehicles (SoV)框架；2. 开发跨模态时空对齐方法解决时间和空间差异；3. 提出基于潜在扩散的视觉-触觉联觉生成模型(VTSyn)，用于无监督高质量触觉数据合成；4. 构建真实车辆感知系统收集多模态数据集。

Result: VTSyn在时间、频率和分类性能上优于现有模型，通过主动触觉感知增强自动驾驶安全性。在多样道路和光照条件下收集了多模态数据集。

Conclusion: SoV框架成功实现了从视觉到触觉的跨模态预测，为自动驾驶提供了主动触觉感知能力，显著提升了车辆安全性能。

Abstract: Autonomous vehicles (AVs) rely on multi-modal fusion for safety, but current visual and optical sensors fail to detect road-induced excitations which are critical for vehicles' dynamic control. Inspired by human synesthesia, we propose the Synesthesia of Vehicles (SoV), a novel framework to predict tactile excitations from visual inputs for autonomous vehicles. We develop a cross-modal spatiotemporal alignment method to address temporal and spatial disparities. Furthermore, a visual-tactile synesthetic (VTSyn) generative model using latent diffusion is proposed for unsupervised high-quality tactile data synthesis. A real-vehicle perception system collected a multi-modal dataset across diverse road and lighting conditions. Extensive experiments show that VTSyn outperforms existing models in temporal, frequency, and classification performance, enhancing AV safety through proactive tactile perception.

</details>


### [571] [ROMA: Recursive Open Meta-Agent Framework for Long-Horizon Multi-Agent Systems](https://arxiv.org/abs/2602.01848)
*Salaheddin Alzu'bi,Baran Nama,Arda Kaz,Anushri Eswaran,Weiyuan Chen,Sarvesh Khetan,Rishab Bala,Tu Vu,Sewoong Oh*

Main category: cs.AI

TL;DR: ROMA是一个递归开放元代理框架，通过任务分解和结构化聚合解决长时程任务中的性能问题，支持异构多智能体系统，结合GEPA+提示搜索实现领先的系统级性能。


<details>
  <summary>Details</summary>
Motivation: 当前智能体框架在长时程任务中表现不佳，随着推理深度增加，顺序编排变得脆弱，上下文窗口限制导致性能下降，不透明的执行轨迹使得故障难以定位和调试。

Method: 引入ROMA框架，通过递归任务分解和结构化聚合，将目标分解为依赖感知的子任务树并行执行，同时聚合压缩和验证中间结果以控制上下文增长。框架围绕四个模块化角色（Atomizer、Planner、Executor、Aggregator）标准化智能体构建，并引入GEPA+进行提示搜索优化。

Result: 在SEAL-0推理基准上，ROMA结合GLM-4.6相比Kimi-Researcher准确率提升9.9%；在EQ-Bench长文本生成基准上，ROMA使DeepSeek-V3达到与Claude Sonnet 4.5等领先闭源模型相当的性能。

Conclusion: 递归模块化智能体架构能够扩展推理深度，同时保持可解释性、灵活性和模型无关性，为解决长时程任务提供了有效框架。

Abstract: Current agentic frameworks underperform on long-horizon tasks. As reasoning depth increases, sequential orchestration becomes brittle, context windows impose hard limits that degrade performance, and opaque execution traces make failures difficult to localize or debug. We introduce ROMA (Recursive Open Meta-Agents), a domain-agnostic framework that addresses these limitations through recursive task decomposition and structured aggregation. ROMA decomposes goals into dependency-aware subtask trees that can be executed in parallel, while aggregation compresses and validates intermediate results to control context growth. Our framework standardizes agent construction around four modular roles --Atomizer (which decides whether a task should be decomposed), Planner, Executor, and Aggregator -- which cleanly separate orchestration from model selection and enable transparent, hierarchical execution traces. This design supports heterogeneous multi-agent systems that mix models and tools according to cost, latency, and capability. To adapt ROMA to specific tasks without fine-tuning, we further introduce GEPA$+$, an improved Genetic-Pareto prompt proposer that searches over prompts within ROMA's component hierarchy while preserving interface contracts. We show that ROMA, combined with GEPA+, delivers leading system-level performance on reasoning and long-form generation benchmarks. On SEAL-0, which evaluates reasoning over conflicting web evidence, ROMA instantiated with GLM-4.6 improves accuracy by 9.9\% over Kimi-Researcher. On EQ-Bench, a long-form writing benchmark, ROMA enables DeepSeek-V3 to match the performance of leading closed-source models such as Claude Sonnet 4.5. Our results demonstrate that recursive, modular agent architectures can scale reasoning depth while remaining interpretable, flexible, and model-agnostic.

</details>


### [572] [SOPRAG: Multi-view Graph Experts Retrieval for Industrial Standard Operating Procedures](https://arxiv.org/abs/2602.01858)
*Liangtao Lin,Zhaomeng Zhu,Tianwei Zhang,Yonggang Wen*

Main category: cs.AI

TL;DR: SOPRAG：针对工业标准操作程序检索的混合专家框架，通过实体、因果、流程图专家和程序卡层解决传统RAG在工业环境中的局限性，显著提升检索准确性和响应实用性。


<details>
  <summary>Details</summary>
Motivation: 工业标准操作程序（SOP）检索面临独特挑战：专有结构僵化、条件依赖性、可执行性要求等，传统语义驱动的RAG范式无法有效解决这些问题。

Method: 提出SOPRAG框架：1）用专门的实体、因果、流程图专家替代平面分块；2）引入程序卡层修剪搜索空间；3）使用LLM引导的门控机制动态加权专家；4）设计多代理工作流自动构建基准数据集。

Result: 在四个工业领域的广泛实验中，SOPRAG在检索准确性和响应实用性方面显著优于基于词汇、密集和图的RAG基线，在真实世界关键任务中实现了完美执行分数。

Conclusion: SOPRAG通过混合专家范式有效解决了工业SOP检索的独特挑战，为工业环境中的操作程序检索提供了高效解决方案，特别是在数据稀缺的情况下。

Abstract: Standard Operating Procedures (SOPs) are essential for ensuring operational safety and consistency in industrial environments. However, retrieving and following these procedures presents unique challenges, such as rigid proprietary structures, condition-dependent relevance, and actionable execution requirement, which standard semantic-driven Retrieval-Augmented Generation (RAG) paradigms fail to address. Inspired by the Mixture-of-Experts (MoE) paradigm, we propose SOPRAG, a novel framework specifically designed to address the above pain points in SOP retrieval. SOPRAG replaces flat chunking with specialized Entity, Causal, and Flow graph experts to resolve industrial structural and logical complexities. To optimize and coordinate these experts, we propose a Procedure Card layer that prunes the search space to eliminate computational noise, and an LLM-Guided gating mechanism that dynamically weights these experts to align retrieval with operator intent. To address the scarcity of domain-specific data, we also introduce an automated, multi-agent workflow for benchmark construction. Extensive experiments across four industrial domains demonstrate that SOPRAG significantly outperforms strong lexical, dense, and graph-based RAG baselines in both retrieval accuracy and response utility, achieving perfect execution scores in real-world critical tasks.

</details>


### [573] [ProcMEM: Learning Reusable Procedural Memory from Experience via Non-Parametric PPO for LLM Agents](https://arxiv.org/abs/2602.01869)
*Qirui Mi,Zhijian Ma,Mengyue Yang,Haoxuan Li,Yisen Wang,Haifeng Zhang,Jun Wang*

Main category: cs.AI

TL;DR: ProcMEM框架让AI智能体从交互经验中自主构建可执行的程序性记忆，无需参数更新，通过语义梯度生成和验证技能，实现高效经验复用和性能提升


<details>
  <summary>Details</summary>
Motivation: 当前LLM驱动的智能体在顺序决策中依赖即时推理，即使在重复场景中也会重新推导解决方案，导致计算冗余和执行不稳定。缺乏经验复用机制限制了长期自主性

Method: 提出ProcMEM框架，将被动的事件叙述转化为可执行技能（Skill-MDP），定义激活、执行和终止条件。引入非参数PPO，利用语义梯度生成高质量候选技能，通过PPO Gate进行技能验证，基于分数维护紧凑高质量的程序性记忆

Result: 在领域内、跨任务和跨智能体场景的实验表明，ProcMEM实现了更高的复用率和显著的性能提升，同时保持极端的内存压缩。可视化进化轨迹和技能分布展示了透明积累、精炼和复用程序性知识的过程

Conclusion: ProcMEM通过构建程序性记忆，使智能体能够透明地积累、精炼和复用经验知识，有效促进长期自主性，解决了当前智能体经验复用不足的问题

Abstract: LLM-driven agents demonstrate strong performance in sequential decision-making but often rely on on-the-fly reasoning, re-deriving solutions even in recurring scenarios. This insufficient experience reuse leads to computational redundancy and execution instability. To bridge this gap, we propose ProcMEM, a framework that enables agents to autonomously learn procedural memory from interaction experiences without parameter updates. By formalizing a Skill-MDP, ProcMEM transforms passive episodic narratives into executable Skills defined by activation, execution, and termination conditions to ensure executability. To achieve reliable reusability without capability degradation, we introduce Non-Parametric PPO, which leverages semantic gradients for high-quality candidate generation and a PPO Gate for robust Skill verification. Through score-based maintenance, ProcMEM sustains compact, high-quality procedural memory. Experimental results across in-domain, cross-task, and cross-agent scenarios demonstrate that ProcMEM achieves superior reuse rates and significant performance gains with extreme memory compression. Visualized evolutionary trajectories and Skill distributions further reveal how ProcMEM transparently accumulates, refines, and reuses procedural knowledge to facilitate long-term autonomy.

</details>


### [574] [Entropy-Guided Data-Efficient Training for Multimodal Reasoning Reward Models](https://arxiv.org/abs/2602.01884)
*Shidong Yang,Tongwen Huang,Hao Wen,Yong Wang,Li Chen,Xiangxiang Chu*

Main category: cs.AI

TL;DR: 本文提出了一种基于熵引导训练（EGT）的多模态推理奖励模型方法，通过熵值识别不可靠样本和样本难度，提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 多模态奖励模型在将多模态大语言模型与人类偏好对齐方面至关重要。现有方法面临两个关键挑战：1）偏好数据集中固有的噪声会降低模型性能；2）传统训练方法效率低下，忽略了样本难度的差异。

Method: 提出熵引导训练（EGT）方法，基于响应熵与准确性之间的强相关性发现：1）熵引导数据筛选，减少不可靠样本的影响；2）熵引导训练策略，逐步引入更复杂的样本。

Result: 在三个基准测试上的广泛实验表明，EGT训练的模型始终优于最先进的多模态奖励模型。

Conclusion: 熵可以作为注释噪声和样本难度的可靠无监督代理，EGT方法能有效提升多模态推理奖励模型的性能。

Abstract: Multimodal reward models are crucial for aligning multimodal large language models with human preferences. Recent works have incorporated reasoning capabilities into these models, achieving promising results. However, training these models suffers from two critical challenges: (1) the inherent noise in preference datasets, which degrades model performance, and (2) the inefficiency of conventional training methods, which ignore the differences in sample difficulty. In this paper, we identify a strong correlation between response entropy and accuracy, indicating that entropy can serve as a reliable and unsupervised proxy for annotation noise and sample difficulty. Based on this insight, we propose a novel Entropy-Guided Training (EGT) approach for multimodal reasoning reward models, which combines two strategies: (1) entropy-guided data curation to mitigate the impact of unreliable samples, and (2) an entropy-guided training strategy that progressively introduces more complex examples. Extensive experiments across three benchmarks show that the EGT-trained model consistently outperforms state-of-the-art multimodal reward models.

</details>


### [575] [Geometric Analysis of Token Selection in Multi-Head Attention](https://arxiv.org/abs/2602.01893)
*Timur Mudarisov,Mikhal Burtsev,Tatiana Petrova,Radu State*

Main category: cs.AI

TL;DR: 提出几何框架分析LLM多头注意力，将标准注意力视为top-N选择器，在值状态空间研究其行为，定义几何度量评估token可分性，理论预测与实验验证一致


<details>
  <summary>Details</summary>
Motivation: 为理解大型语言模型中多头注意力的工作机制，需要一种几何分析框架来量化token选择的可分性，提供头级别的可解释性，并为注意力机制的设计和稀疏化提供指导

Method: 将标准注意力视为top-N选择器，在值状态空间分析其行为；定义Precision、Recall、F-score等几何度量；在经验假设下推导非渐近边界；在LLaMA-2-7B、Gemma-7B、Mistral-7B上进行实证验证

Result: 理论预测与实验测量高度一致：top-N选择增强可分性，sink相似性与Recall相关；在LLaMA-2-7B中发现注意力头分为三种机制（Retriever、Mixer、Reset），具有不同的几何特征

Conclusion: 注意力机制表现为结构化的几何分类器，具有可测量的token选择标准，提供头级别的可解释性，为几何感知的稀疏化和注意力设计提供信息

Abstract: We present a geometric framework for analysing multi-head attention in large language models (LLMs). Without altering the mechanism, we view standard attention through a top-N selection lens and study its behaviour directly in value-state space. We define geometric metrics - Precision, Recall, and F-score - to quantify separability between selected and non-selected tokens, and derive non-asymptotic bounds with explicit dependence on dimension and margin under empirically motivated assumptions (stable value norms with a compressed sink token, exponential similarity decay, and piecewise attention weight profiles). The theory predicts a small-N operating regime of strongest non-trivial separability and clarifies how sequence length and sink similarity shape the metrics. Empirically, across LLaMA-2-7B, Gemma-7B, and Mistral-7B, measurements closely track the theoretical envelopes: top-N selection sharpens separability, sink similarity correlates with Recall. We also found that in LLaMA-2-7B heads specialize into three regimes - Retriever, Mixer, Reset - with distinct geometric signatures. Overall, attention behaves as a structured geometric classifier with measurable criteria for token selection, offering head level interpretability and informing geometry-aware sparsification and design of attention in LLMs.

</details>


### [576] [DomusFM: A Foundation Model for Smart-Home Sensor Data](https://arxiv.org/abs/2602.01910)
*Michele Fiori,Gabriele Civitarese,Flora D. Salim,Claudio Bettini*

Main category: cs.AI

TL;DR: DomusFM是首个专门为智能家居传感器数据设计的预训练基础模型，通过自监督双对比学习范式，在稀疏的二进制传感器事件数据上实现优异的下游任务性能，仅需5%标注数据即可超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 智能家居传感器数据在医疗监测和辅助技术中有重要应用潜力，但现有方法存在严重局限：监督模型需要大量标注数据不切实际；现有基础模型仅关注惯性传感器，无法处理智能家居二进制传感器事件的稀疏离散特性和丰富语义关联；LLM方法需要自然语言描述或提示，依赖外部服务或昂贵硬件，存在隐私和成本问题。

Method: DomusFM采用自监督双对比学习范式，同时捕捉token级语义属性和序列级时间依赖。整合轻量级语言模型的语义嵌入、时间模式专用编码器和二进制状态编码器，学习可跨环境和任务迁移的通用表示。

Result: 在七个公共智能家居数据集上进行留一数据集评估，DomusFM在不同下游任务上均优于最先进基线方法，即使在仅有5%标注训练数据用于微调的情况下也能实现卓越性能。

Conclusion: DomusFM解决了智能家居传感器数据稀缺问题，同时保持了实际部署可行性，为现实世界智能家居系统提供了实用解决方案。

Abstract: Smart-home sensor data holds significant potential for several applications, including healthcare monitoring and assistive technologies. Existing approaches, however, face critical limitations. Supervised models require impractical amounts of labeled data. Foundation models for activity recognition focus only on inertial sensors, failing to address the unique characteristics of smart-home binary sensor events: their sparse, discrete nature combined with rich semantic associations. LLM-based approaches, while tested in this domain, still raise several issues regarding the need for natural language descriptions or prompting, and reliance on either external services or expensive hardware, making them infeasible in real-life scenarios due to privacy and cost concerns. We introduce DomusFM, the first foundation model specifically designed and pretrained for smart-home sensor data. DomusFM employs a self-supervised dual contrastive learning paradigm to capture both token-level semantic attributes and sequence-level temporal dependencies. By integrating semantic embeddings from a lightweight language model and specialized encoders for temporal patterns and binary states, DomusFM learns generalizable representations that transfer across environments and tasks related to activity and event analysis. Through leave-one-dataset-out evaluation across seven public smart-home datasets, we demonstrate that DomusFM outperforms state-of-the-art baselines on different downstream tasks, achieving superior performance even with only 5% of labeled training data available for fine-tuning. Our approach addresses data scarcity while maintaining practical deployability for real-world smart-home systems.

</details>


### [577] [Large Language Model and Formal Concept Analysis: a comparative study for Topic Modeling](https://arxiv.org/abs/2602.01933)
*Fabrice Boissier,Monica Sen,Irina Rychkova*

Main category: cs.AI

TL;DR: 本文比较了大型语言模型（LLM）和形式概念分析（FCA）在主题建模任务中的表现，通过两个实验评估它们在文档主题提取方面的效果。


<details>
  <summary>Details</summary>
Motivation: 主题建模在文档检索、情感分析和文本摘要等领域的应用日益广泛。虽然大型语言模型（LLM）在文本处理中很流行，但很少有研究探讨其在主题建模中的实用性。同时，形式概念分析（FCA）最近被提出作为主题建模的候选方法，但缺乏实际应用案例研究。本研究旨在比较LLM和FCA，以更好地理解它们在主题建模领域的优势和劣势。

Method: 研究采用两种方法进行对比：1）FCA通过CREA管道进行评估，该管道在过去的主题建模和可视化实验中使用过；2）LLM使用GPT-5，采用基于三个提示的零样本设置策略：从文档批次生成主题、将批次结果合并为最终主题、以及主题标注。研究进行了两个实验：第一个实验重用之前用于评估CREA的教学材料，第二个实验分析40篇信息系统研究文章，比较提取的主题与底层子领域。

Result: 论文没有提供具体的实验结果数据，但从方法描述可以看出，研究通过两个实验系统地比较了LLM和FCA在主题建模任务上的表现。第一个实验使用已知的教学材料作为基准，第二个实验则在实际研究文章上进行评估，旨在验证提取的主题是否与实际研究子领域相符。

Conclusion: 本研究通过对比实验评估了LLM和FCA在主题建模中的表现，为理解这两种方法在该领域的适用性提供了实证基础。研究填补了LLM在主题建模应用研究方面的空白，同时也为FCA的实际应用提供了案例研究。

Abstract: Topic modeling is a research field finding increasing applications: historically from document retrieving, to sentiment analysis and text summarization. Large Language Models (LLM) are currently a major trend in text processing, but few works study their usefulness for this task. Formal Concept Analysis (FCA) has recently been presented as a candidate for topic modeling, but no real applied case study has been conducted. In this work, we compare LLM and FCA to better understand their strengths and weakneses in the topic modeling field. FCA is evaluated through the CREA pipeline used in past experiments on topic modeling and visualization, whereas GPT-5 is used for the LLM. A strategy based on three prompts is applied with GPT-5 in a zero-shot setup: topic generation from document batches, merging of batch results into final topics, and topic labeling. A first experiment reuses the teaching materials previously used to evaluate CREA, while a second experiment analyzes 40 research articles in information systems to compare the extracted topics with the underling subfields.

</details>


### [578] [Small Generalizable Prompt Predictive Models Can Steer Efficient RL Post-Training of Large Reasoning Models](https://arxiv.org/abs/2602.01970)
*Yun Qu,Qi Wang,Yixiu Mao,Heming Zou,Yuhang Jiang,Weijie Liu,Clive Bai,Kai Yang,Yangkun Chen,Saiyong Yang,Xiangyang Ji*

Main category: cs.AI

TL;DR: GPS提出了一种可泛化的预测性提示选择方法，通过轻量级生成模型进行贝叶斯推理来评估提示难度，结合中等难度优先和历史锚定多样性原则选择信息丰富的提示批次，显著提升训练效率、最终性能和测试时效率。


<details>
  <summary>Details</summary>
Motivation: 强化学习能增强大语言模型的推理能力，但通常需要高计算成本。在线提示选择通过优先选择信息丰富的提示来提高训练效率，但现有方法要么依赖昂贵的精确评估，要么构建缺乏跨提示泛化能力的特定预测模型。

Method: 提出GPS方法：1) 使用在共享优化历史上训练的轻量级生成模型进行贝叶斯推理评估提示难度；2) 结合中等难度优先原则；3) 引入历史锚定多样性原则；4) 设计批量获取原则选择信息丰富的提示批次；5) 小预测模型在测试时也能泛化以实现高效计算分配。

Result: 在多个推理基准测试中，GPS在训练效率、最终性能和测试时效率方面均显著优于现有基线方法。

Conclusion: GPS通过可泛化的预测性提示选择方法，有效解决了强化学习中提示选择的效率问题，在保持性能的同时大幅降低了计算成本，为高效的大语言模型推理训练提供了实用解决方案。

Abstract: Reinforcement learning enhances the reasoning capabilities of large language models but often involves high computational costs due to rollout-intensive optimization. Online prompt selection presents a plausible solution by prioritizing informative prompts to improve training efficiency. However, current methods either depend on costly, exact evaluations or construct prompt-specific predictive models lacking generalization across prompts. This study introduces Generalizable Predictive Prompt Selection (GPS), which performs Bayesian inference towards prompt difficulty using a lightweight generative model trained on the shared optimization history. Intermediate-difficulty prioritization and history-anchored diversity are incorporated into the batch acquisition principle to select informative prompt batches. The small predictive model also generalizes at test-time for efficient computational allocation. Experiments across varied reasoning benchmarks indicate GPS's substantial improvements in training efficiency, final performance, and test-time efficiency over superior baseline methods.

</details>


### [579] [Evolving from Tool User to Creator via Training-Free Experience Reuse in Multimodal Reasoning](https://arxiv.org/abs/2602.01983)
*Xintian Shen,Jiawei Chen,Lihao Zheng,Hao Ma,Tao Wei,Kun Zhan*

Main category: cs.AI

TL;DR: UCT框架让LLM从工具使用者转变为工具创造者，通过提取推理经验创建自适应工具库，无需额外训练即可持续改进推理能力


<details>
  <summary>Details</summary>
Motivation: 现有工具集成推理模型存在三个主要问题：1) 固定工具难以应对开放性问题；2) 错误工具输出会误导LLM；3) 工具构建需要大量人工工作，限制了适用性。LLM的推理轨迹蕴含隐式问题解决能力，但未被有效利用。

Method: 提出UCT训练免费框架，将代理从工具使用者转变为工具创造者。通过提取推理经验并蒸馏为可重用资产，在推理过程中自适应创建和更新工具。引入记忆巩固机制维护工具库，确保经验记忆的高重用性。

Result: 在跨领域数学和科学推理任务基准测试中，性能显著提升+20.86%和+23.04%，验证了代理的自进化能力。该方法为增强TIR模型能力提供了新范式。

Conclusion: UCT框架通过自动化工具构建范式，在推理过程中持续改进工具质量，使整体代理系统无需额外训练即可进步。这为工具集成推理模型的能力增强开辟了新方向。

Abstract: Existing Tool-Integrated Reasoning (TIR) models have effectively extended the question-answering capabilities of LLMs by incorporating external tools. However, real-world scenarios present numerous open-ended problems where fixed tools often fail to meet task requirements. Furthermore, the lack of self-optimization mechanisms means that erroneous tool outputs can mislead the LLM's responses. Additionally, the construction of existing tools entails significant manual effort, which consequently constrains their applicability. Recognizing that the reasoning traces of LLMs encapsulate implicit problem-solving capabilities, we propose UCT, a novel training-free framework that transforms agents from tool users to tool creators. This approach harvests reasoning experiences and distills them into reusable assets. This method transforms the agent from a mere tool user into a tool creator, enabling adaptive tool creation and self-updating during the inference process. We also introduce a memory consolidation mechanism to maintain the tool library, ensuring high reusability of retained experiential memory for subsequent reasoning tasks. This novel automated tool construction paradigm continuously improves tool quality during reasoning, allowing the overall agent system to progress without additional training. Extensive experiments demonstrate that our method serves as a novel paradigm for enhancing the capabilities of TIR models. In particular, the significant performance gains achieved +20.86%$\uparrow$ and +23.04%$\uparrow$ on benchmarks across multi-domain mathematical and scientific reasoning tasks validate the self-evolving capability of the agent.

</details>


### [580] [Emergent Analogical Reasoning in Transformers](https://arxiv.org/abs/2602.01992)
*Gouki Minegishi,Jingyuan Feng,Hiroki Furuta,Takeshi Kojima,Yusuke Iwasawa,Yutaka Matsuo*

Main category: cs.AI

TL;DR: 该论文将类比推理形式化为跨类别实体对应关系的推断，基于范畴论中的函子概念，通过合成任务研究Transformer中类比推理的涌现机制，发现其依赖于嵌入空间中的几何对齐和Transformer内部的函子应用。


<details>
  <summary>Details</summary>
Motivation: 类比是人类智能的核心能力，但Transformer如何习得和实施类比推理的机制尚不清楚。研究旨在将类比从抽象认知概念转变为现代神经网络中具体、机制可解释的现象。

Method: 基于范畴论中的函子概念，将类比推理形式化为跨类别实体对应关系的推断。引入合成任务在受控设置下评估类比推理的涌现，并进行机制分析。

Result: 发现类比推理的涌现对数据特征、优化选择和模型规模高度敏感。机制分析表明，Transformer中的类比推理分解为两个关键组件：嵌入空间中关系结构的几何对齐，以及Transformer内部函子的应用。

Conclusion: 研究将类比从抽象认知概念具体化为现代神经网络中机制可解释的现象，揭示了Transformer实现类比推理的底层机制，并在预训练大语言模型中观察到相同趋势。

Abstract: Analogy is a central faculty of human intelligence, enabling abstract patterns discovered in one domain to be applied to another. Despite its central role in cognition, the mechanisms by which Transformers acquire and implement analogical reasoning remain poorly understood. In this work, inspired by the notion of functors in category theory, we formalize analogical reasoning as the inference of correspondences between entities across categories. Based on this formulation, we introduce synthetic tasks that evaluate the emergence of analogical reasoning under controlled settings. We find that the emergence of analogical reasoning is highly sensitive to data characteristics, optimization choices, and model scale. Through mechanistic analysis, we show that analogical reasoning in Transformers decomposes into two key components: (1) geometric alignment of relational structure in the embedding space, and (2) the application of a functor within the Transformer. These mechanisms enable models to transfer relational structure from one category to another, realizing analogy. Finally, we quantify these effects and find that the same trends are observed in pretrained LLMs. In doing so, we move analogy from an abstract cognitive notion to a concrete, mechanistically grounded phenomenon in modern neural networks.

</details>


### [581] [Thinking Like a Doctor: Conversational Diagnosis through the Exploration of Diagnostic Knowledge Graphs](https://arxiv.org/abs/2602.01995)
*Jeongmoon Won,Seungwon Kook,Yohan Jo*

Main category: cs.AI

TL;DR: 提出基于知识图谱的对话诊断系统，通过生成诊断假设和验证性提问的两步推理，在模糊症状描述下实现更准确的诊断


<details>
  <summary>Details</summary>
Motivation: 现有对话诊断方法要么依赖模型的参数知识，要么假设患者提供丰富具体的信息，这在现实中不切实际。需要解决信息不完整和症状描述模糊的问题。

Method: 提出两步推理方法：1)从对话上下文生成诊断假设；2)通过澄清问题验证假设，重复直到得出最终诊断。使用诊断知识图谱进行推理，并采用MIMIC-IV患者资料构建能描述模糊症状的模拟器。

Result: 实验显示在诊断准确性和效率上优于强基线，医生评估支持模拟器的真实性和生成问题的临床实用性。

Conclusion: 提出的基于知识图谱的对话诊断系统能有效处理现实世界中患者症状描述模糊的情况，提高诊断性能，具有临床实用价值。

Abstract: Conversational diagnosis requires multi-turn history-taking, where an agent asks clarifying questions to refine differential diagnoses under incomplete information. Existing approaches often rely on the parametric knowledge of a model or assume that patients provide rich and concrete information, which is unrealistic. To address these limitations, we propose a conversational diagnosis system that explores a diagnostic knowledge graph to reason in two steps: (i) generating diagnostic hypotheses from the dialogue context, and (ii) verifying hypotheses through clarifying questions, which are repeated until a final diagnosis is reached. Since evaluating the system requires a realistic patient simulator that responds to the system's questions, we adopt a well-established simulator along with patient profiles from MIMIC-IV. We further adapt it to describe symptoms vaguely to reflect real-world patients during early clinical encounters. Experiments show improved diagnostic accuracy and efficiency over strong baselines, and evaluations by physicians support the realism of our simulator and the clinical utility of the generated questions. Our code will be released upon publication.

</details>


### [582] [Do I Really Know? Learning Factual Self-Verification for Hallucination Reduction](https://arxiv.org/abs/2602.02018)
*Enes Altinisik,Masoomali Fatehkia,Fatih Deniz,Nadir Durrani,Majd Hawasly,Mohammad Raza,Husrev Taha Sencar*

Main category: cs.AI

TL;DR: VeriFY框架通过一致性自验证训练LLMs处理事实不确定性，减少幻觉同时保持召回率


<details>
  <summary>Details</summary>
Motivation: 现有缓解事实幻觉的方法主要依赖外部后验验证或直接将不确定性映射为弃权，导致过于保守的行为，需要更好的训练时解决方案

Method: 提出VeriFY训练框架，通过结构化验证轨迹教导LLMs进行一致性自验证，包括初始回答、生成验证查询、一致性判断、决定回答或弃权，并引入阶段级损失掩码避免强化幻觉内容

Result: 在多个模型家族和规模上，VeriFY将事实幻觉率降低9.7%至53.3%，召回率仅轻微下降0.4%至5.7%，且在单源训练下能跨数据集泛化

Conclusion: VeriFY通过教导LLMs进行一致性自验证，有效减少事实幻觉同时保持回答能力，为训练时解决事实不确定性提供了有效方案

Abstract: Factual hallucination remains a central challenge for large language models (LLMs). Existing mitigation approaches primarily rely on either external post-hoc verification or mapping uncertainty directly to abstention during fine-tuning, often resulting in overly conservative behavior. We propose VeriFY, a training-time framework that teaches LLMs to reason about factual uncertainty through consistency-based self-verification. VeriFY augments training with structured verification traces that guide the model to produce an initial answer, generate and answer a probing verification query, issue a consistency judgment, and then decide whether to answer or abstain. To address the risk of reinforcing hallucinated content when training on augmented traces, we introduce a stage-level loss masking approach that excludes hallucinated answer stages from the training objective while preserving supervision over verification behavior. Across multiple model families and scales, VeriFY reduces factual hallucination rates by 9.7 to 53.3 percent, with only modest reductions in recall (0.4 to 5.7 percent), and generalizes across datasets when trained on a single source. The source code, training data, and trained model checkpoints will be released upon acceptance.

</details>


### [583] [Light Alignment Improves LLM Safety via Model Self-Reflection with a Single Neuron](https://arxiv.org/abs/2602.02027)
*Sicheng Shen,Mingyang Lv,Han Shen,Jialin Wu,Binghao Wang,Zhou Yang,Guobin Shen,Dongcheng Zhao,Feifei Zhao,Yi Zeng*

Main category: cs.AI

TL;DR: 提出一种轻量级的安全对齐方法NGSD，通过训练专家模型和单神经元门控机制，在保持模型实用性的同时增强输出安全性，显著降低训练开销并提升跨模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有LLM安全对齐方法主要依赖后训练，计算成本高且泛化能力差；轻量级方法要么过度依赖预计算的安全注入，要么过度依赖模型自身能力，导致泛化有限、生成效率降低和可用性下降。

Method: 提出安全感知解码方法NGSD：1）低成本训练专家模型；2）使用单神经元作为门控机制；3）有效平衡模型内在能力与外部指导，在保持实用性的同时增强输出安全性。

Result: 方法在训练开销和跨模型规模泛化方面具有明显优势，为大型语言模型的安全实用部署提供了新的轻量级对齐视角。

Conclusion: NGSD方法通过低成本的专家模型训练和单神经元门控机制，实现了模型内在能力与外部安全指导的有效平衡，为LLM的安全对齐提供了高效、可泛化的轻量级解决方案。

Abstract: The safety of large language models (LLMs) has increasingly emerged as a fundamental aspect of their development. Existing safety alignment for LLMs is predominantly achieved through post-training methods, which are computationally expensive and often fail to generalize well across different models. A small number of lightweight alignment approaches either rely heavily on prior-computed safety injections or depend excessively on the model's own capabilities, resulting in limited generalization and degraded efficiency and usability during generation. In this work, we propose a safety-aware decoding method that requires only low-cost training of an expert model and employs a single neuron as a gating mechanism. By effectively balancing the model's intrinsic capabilities with external guidance, our approach simultaneously preserves utility and enhances output safety. It demonstrates clear advantages in training overhead and generalization across model scales, offering a new perspective on lightweight alignment for the safe and practical deployment of large language models. Code: https://github.com/Beijing-AISI/NGSD.

</details>


### [584] [Edit Knowledge, Not Just Facts via Multi-Step Reasoning over Background Stories](https://arxiv.org/abs/2602.02028)
*Ya Gao,Kalle Kujanpää,Pekka Marttinen,Harri Valpola,Alexander Ilin*

Main category: cs.AI

TL;DR: 该论文提出了一种新的知识内化训练策略，通过背景故事、多步推理问题和知识蒸馏三个原则，使AI模型能够将新知识整合到推理过程中，而不仅仅是记忆事实。


<details>
  <summary>Details</summary>
Motivation: 现有知识编辑方法主要关注原子事实的记忆，但无法将新信息整合到连贯的框架中，使其能够在不同上下文中灵活应用。作者认为知识内化本质上是推理问题而非记忆问题。

Method: 提出基于三个原则的训练策略：1）将新知识作为连贯的背景故事引入，解释新事实与现有知识的关系；2）使用自生成的多跳问题进行训练，要求多步推理涉及新信息；3）采用知识蒸馏方法，强制学生模型内化教师模型的推理行为，而不直接访问新信息。

Result: 实验表明，采用该策略训练的模型能够有效利用新获取的知识进行推理，在需要结合多个新事实的挑战性问题中表现出色。

Conclusion: 通过将知识内化视为推理问题而非记忆问题，并采用背景故事、多步推理和知识蒸馏的训练策略，能够使AI模型更好地整合和应用新知识。

Abstract: Enabling artificial intelligence systems, particularly large language models, to integrate new knowledge and flexibly apply it during reasoning remains a central challenge. Existing knowledge editing approaches emphasize atomic facts, improving factual recall but often failing to integrate new information into a coherent framework usable across contexts. In this work, we argue that knowledge internalization is fundamentally a reasoning problem rather than a memorization problem. Consequently, a model should be trained in situations where the new information is instrumental to solving a task, combined with pre-existing knowledge, and exercised through multi-step reasoning. Based on this insight, we propose a training strategy based on three principles. First, new knowledge is introduced as a coherent background story that contextualizes novel facts and explains their relation to existing knowledge. Second, models are trained using self-generated multi-hop questions that require multi-step reasoning involving the new information. Third, training is done using knowledge distillation, forcing a student model to internalize the teacher's reasoning behavior without access to the novel information. Experiments show that models trained with this strategy effectively leverage newly acquired knowledge during reasoning and achieve remarkable performance on challenging questions that require combining multiple new facts.

</details>


### [585] [Canonical Intermediate Representation for LLM-based optimization problem formulation and code generation](https://arxiv.org/abs/2602.02029)
*Zhongyuan Lyu,Shuoyu Hu,Lujie Liu,Hongxia Yang,Ming LI*

Main category: cs.AI

TL;DR: 提出CIR中间表示和R2C框架，通过多智能体管道将自然语言问题描述转换为优化模型，在复杂操作规则建模上达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的优化模型自动生成方法在处理复杂操作规则的复合约束和适当建模范式方面存在困难，需要更好的中间表示来解耦规则逻辑与数学实例化

Method: 引入规范中间表示(CIR)作为LLM在问题描述和优化模型之间生成的显式模式，通过约束原型和候选建模范式编码操作规则语义；开发R2C多智能体框架，包含问题文本解析、CIR实现合成和优化模型实例化

Result: 在新建的包含丰富操作规则的基准测试中达到47.2%的准确率；在现有基准测试中表现极具竞争力，接近GPT-5等专有模型性能；通过反思机制进一步提升了性能并在某些基准测试中创造了新的最佳记录

Conclusion: CIR中间表示和R2C框架有效解决了复杂操作规则的优化建模问题，实现了从自然语言描述到优化模型的可靠转换，为自动化优化建模提供了新方法

Abstract: Automatically formulating optimization models from natural language descriptions is a growing focus in operations research, yet current LLM-based approaches struggle with the composite constraints and appropriate modeling paradigms required by complex operational rules. To address this, we introduce the Canonical Intermediate Representation (CIR): a schema that LLMs explicitly generate between problem descriptions and optimization models. CIR encodes the semantics of operational rules through constraint archetypes and candidate modeling paradigms, thereby decoupling rule logic from its mathematical instantiation. Upon a newly generated CIR knowledge base, we develop the rule-to-constraint (R2C) framework, a multi-agent pipeline that parses problem texts, synthesizes CIR implementations by retrieving domain knowledge, and instantiates optimization models. To systematically evaluate rule-to-constraint reasoning, we test R2C on our newly constructed benchmark featuring rich operational rules, and benchmarks from prior work. Extensive experiments show that R2C achieves state-of-the-art accuracy on the proposed benchmark (47.2% Accuracy Rate). On established benchmarks from the literature, R2C delivers highly competitive results, approaching the performance of proprietary models (e.g., GPT-5). Moreover, with a reflection mechanism, R2C achieves further gains and sets new best-reported results on some benchmarks.

</details>


### [586] [Constrained Process Maps for Multi-Agent Generative AI Workflows](https://arxiv.org/abs/2602.02034)
*Ananya Joshi,Michael Rudow*

Main category: cs.AI

TL;DR: 论文提出了一种基于有限时域马尔可夫决策过程的多智能体系统，用于规范场景下的复杂工作流，通过量化不确定性并引入人工审核状态，在AI安全评估案例中显著提升了准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的智能体在合规、尽职调查等规范场景中执行复杂多步工作流时，主要依赖单一智能体的提示工程，难以观察和比较模型如何处理跨决策阶段的不确定性和协调问题，也缺乏有效的人工监督机制。

Method: 提出了一种基于有限时域马尔可夫决策过程的多智能体系统，采用有向无环图结构。每个智能体对应特定角色或决策阶段（如合规工作流中的内容、业务或法律审查），具有预定义的转换表示任务升级或完成。通过蒙特卡洛估计量化智能体层面的认知不确定性，系统级不确定性通过MDP终止于自动标记状态或人工审核状态来捕获。

Result: 在AI安全评估（自残检测）的案例研究中，相比单智能体基线，该方法实现了高达19%的准确率提升，高达85倍的人工审核需求减少，在某些配置下还减少了处理时间。

Conclusion: 该多智能体系统框架为规范场景下的复杂工作流提供了更透明、可协调且支持人工监督的解决方案，通过量化不确定性和结构化决策过程，显著提升了系统性能和效率。

Abstract: Large language model (LLM)-based agents are increasingly used to perform complex, multi-step workflows in regulated settings such as compliance and due diligence. However, many agentic architectures rely primarily on prompt engineering of a single agent, making it difficult to observe or compare how models handle uncertainty and coordination across interconnected decision stages and with human oversight. We introduce a multi-agent system formalized as a finite-horizon Markov Decision Process (MDP) with a directed acyclic structure. Each agent corresponds to a specific role or decision stage (e.g., content, business, or legal review in a compliance workflow), with predefined transitions representing task escalation or completion. Epistemic uncertainty is quantified at the agent level using Monte Carlo estimation, while system-level uncertainty is captured by the MDP's termination in either an automated labeled state or a human-review state. We illustrate the approach through a case study in AI safety evaluation for self-harm detection, implemented as a multi-agent compliance system. Results demonstrate improvements over a single-agent baseline, including up to a 19\% increase in accuracy, up to an 85x reduction in required human review, and, in some configurations, reduced processing time.

</details>


### [587] [Rethinking the Role of Entropy in Optimizing Tool-Use Behaviors for Large Language Model Agents](https://arxiv.org/abs/2602.02050)
*Zeping Li,Hongru Wang,Yiwen Zhao,Guanhua Chen,Yixia Li,Keyang Chen,Yixin Cao,Guangnan Ye,Hongfeng Chai,Mengdi Wang,Zhenfei Yin*

Main category: cs.AI

TL;DR: 基于LLM的工具使用代理在长轨迹中常触发过多低质量工具调用，本文提出使用熵减作为监督信号，设计稀疏结果奖励和密集过程奖励来优化工具使用行为。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的工具使用代理在数学推理和多跳问答等任务中表现出色，但在长轨迹中经常触发过多且低质量的工具调用，这会增加延迟并降低推理性能，使得管理工具使用行为变得困难。

Method: 通过基于熵的试点实验发现熵减与高质量工具调用之间存在强正相关，因此提出使用熵减作为监督信号。设计了两种奖励策略：稀疏结果奖励提供轨迹级别的粗粒度指导以提高效率，密集过程奖励提供细粒度监督以提升性能。

Result: 实验表明两种奖励设计都能改善工具使用行为：稀疏结果奖励相比基线平均减少了72.07%的工具调用，密集过程奖励将性能提升了22.27%。

Conclusion: 熵减成为增强工具使用行为的关键机制，使代理在现实应用中更具适应性。这两种奖励策略为优化工具使用行为提供了有效方法。

Abstract: Tool-using agents based on Large Language Models (LLMs) excel in tasks such as mathematical reasoning and multi-hop question answering. However, in long trajectories, agents often trigger excessive and low-quality tool calls, increasing latency and degrading inference performance, making managing tool-use behavior challenging. In this work, we conduct entropy-based pilot experiments and observe a strong positive correlation between entropy reduction and high-quality tool calls. Building on this finding, we propose using entropy reduction as a supervisory signal and design two reward strategies to address the differing needs of optimizing tool-use behavior. Sparse outcome rewards provide coarse, trajectory-level guidance to improve efficiency, while dense process rewards offer fine-grained supervision to enhance performance. Experiments across diverse domains show that both reward designs improve tool-use behavior: the former reduces tool calls by 72.07% compared to the average of baselines, while the latter improves performance by 22.27%. These results position entropy reduction as a key mechanism for enhancing tool-use behavior, enabling agents to be more adaptive in real-world applications.

</details>


### [588] [SIDiffAgent: Self-Improving Diffusion Agent](https://arxiv.org/abs/2602.02051)
*Shivank Garg,Ayush Singh,Gaurav Kumar Nayak*

Main category: cs.AI

TL;DR: SIDiffAgent是一个无需训练的代理框架，利用Qwen系列模型解决文本到图像扩散模型的局限性，通过自主提示工程、错误检测与修正、伪影移除以及基于记忆的迭代自改进，显著提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 文本到图像扩散模型在实际部署中存在多个限制：对提示措辞敏感、语义解释模糊（如"mouse"指动物还是电脑外设）、解剖结构扭曲等伪影，以及需要精心设计的输入提示。现有方法通常需要额外训练且可控性有限，限制了实际应用中的适应性。

Method: 提出SIDiffAgent框架，利用Qwen系列模型（Qwen-VL、Qwen-Image、Qwen-Edit、Qwen-Embedding）实现无需训练的代理系统。该系统自主管理提示工程、检测并修正不良生成、执行细粒度伪影移除，并通过数据库存储先前经验实现迭代自改进，在代理管道的每个阶段注入基于提示的指导。

Result: 在GenAIBench上取得了平均VQA得分0.884，显著优于开源模型、专有模型和其他代理方法。

Conclusion: SIDiffAgent通过代理框架有效解决了文本到图像扩散模型的实际部署问题，无需额外训练即可实现高质量的图像生成，并通过迭代自改进机制持续提升性能，代码将在接受后公开。

Abstract: Text-to-image diffusion models have revolutionized generative AI, enabling high-quality and photorealistic image synthesis. However, their practical deployment remains hindered by several limitations: sensitivity to prompt phrasing, ambiguity in semantic interpretation (e.g., ``mouse" as animal vs. a computer peripheral), artifacts such as distorted anatomy, and the need for carefully engineered input prompts. Existing methods often require additional training and offer limited controllability, restricting their adaptability in real-world applications. We introduce Self-Improving Diffusion Agent (SIDiffAgent), a training-free agentic framework that leverages the Qwen family of models (Qwen-VL, Qwen-Image, Qwen-Edit, Qwen-Embedding) to address these challenges. SIDiffAgent autonomously manages prompt engineering, detects and corrects poor generations, and performs fine-grained artifact removal, yielding more reliable and consistent outputs. It further incorporates iterative self-improvement by storing a memory of previous experiences in a database. This database of past experiences is then used to inject prompt-based guidance at each stage of the agentic pipeline. \modelour achieved an average VQA score of 0.884 on GenAIBench, significantly outperforming open-source, proprietary models and agentic methods. We will publicly release our code upon acceptance.

</details>


### [589] [Understanding the Reversal Curse Mitigation in Masked Diffusion Models through Attention and Training Dynamics](https://arxiv.org/abs/2602.02133)
*Sangwoo Shin,BumJun Kim,Kyelim Lee,Moongyu Jeon,Albert No*

Main category: cs.AI

TL;DR: 论文发现扩散语言模型通过架构结构和训练交互缓解了逆转诅咒，而不仅仅是训练目标的原因


<details>
  <summary>Details</summary>
Motivation: 自回归语言模型存在逆转诅咒问题（学会"A是B"后无法处理"B是A"），而掩码扩散语言模型对此问题有显著缓解，但根本原因尚不清楚。传统解释归因于训练目标，但作者认为需要更深入探究

Method: 通过理论分析和实验验证：1）分析单层Transformer编码器中权重共享如何使前向和反向注意力分数正相关；2）证明相应梯度对齐，最小化前向损失也减少反向损失；3）在受控玩具任务和大规模扩散语言模型上进行实验验证

Result: 扩散语言模型对逆转诅咒的缓解主要源于架构结构及其与训练的交互作用，而不是单纯的训练目标。权重共享使两个方向的注意力分数正相关，梯度对齐确保优化前向任务时也优化反向任务

Conclusion: 掩码扩散语言模型通过架构设计（特别是权重共享）和训练动态的交互作用，部分克服了自回归语言模型持续存在的逆转诅咒问题，这为改进语言模型设计提供了新见解

Abstract: Autoregressive language models (ARMs) suffer from the reversal curse: after learning that "$A$ is $B$", they often fail on the reverse query "$B$ is $A$". Masked diffusion-based language models (MDMs) exhibit this failure in a much weaker form, but the underlying reason has remained unclear. A common explanation attributes this mitigation to the any-order training objective. However, observing "[MASK] is $B$" during training does not necessarily teach the model to handle the reverse prompt "$B$ is [MASK]". We show that the mitigation arises from architectural structure and its interaction with training. In a one-layer Transformer encoder, weight sharing couples the two directions by making forward and reverse attention scores positively correlated. In the same setting, we further show that the corresponding gradients are aligned, so minimizing the forward loss also reduces the reverse loss. Experiments on both controlled toy tasks and large-scale diffusion language models support these mechanisms, explaining why MDMs partially overcome a failure mode that persists in strong ARMs.

</details>


### [590] [Mitigating Safety Tax via Distribution-Grounded Refinement in Large Reasoning Models](https://arxiv.org/abs/2602.02136)
*Yingsha Xie,Tiansheng Huang,Enneng Yang,Rui Min,Wenjie Lu,Xiaochun Cao,Naiqiang Tan,Li Shen*

Main category: cs.AI

TL;DR: DGR方法通过将外部安全推理数据集转化为目标大语言模型的内部分布，有效减轻安全对齐带来的推理能力退化，同时保持安全性能。


<details>
  <summary>Details</summary>
Motivation: 现有安全对齐数据集通常从外部大语言模型或人工标注中蒸馏得到，与目标模型存在分布差异，这种分布差异被认为是导致目标模型推理能力显著下降的主要原因。

Method: 提出DGR方法，将现有的分布外安全推理数据集进行转化和精炼，使其与目标大语言模型的内部分布对齐。

Result: DGR有效减轻了安全税，同时保持安全性能：相比Vanilla SFT，在DirectRefusal上推理准确率平均提升30.2%，在R1-ACT上提升21.2%；推理能力退化程度与分布偏移程度相关；仅需10个样本即可激活有效的拒绝行为。

Conclusion: 分布一致性对保持大语言模型能力至关重要，安全对齐可能主要作为激活潜在知识的机制，这些发现为理解安全在推理模型中的激活机制提供了新见解。

Abstract: Safety alignment incurs safety tax that perturbs a large reasoning model's (LRM) general reasoning ability. Existing datasets used for safety alignment for an LRM are usually constructed by distilling safety reasoning traces and answers from an external LRM or human labeler. However, such reasoning traces and answers exhibit a distributional gap with the target LRM that needs alignment, and we conjecture such distributional gap is the culprit leading to significant degradation of reasoning ability of the target LRM. Driven by this hypothesis, we propose a safety alignment dataset construction method, dubbed DGR. DGR transforms and refines an existing out-of-distributional safety reasoning dataset to be aligned with the target's LLM inner distribution. Experimental results demonstrate that i) DGR effectively mitigates the safety tax while maintaining safety performance across all baselines, i.e., achieving \textbf{+30.2\%} on DirectRefusal and \textbf{+21.2\%} on R1-ACT improvement in average reasoning accuracy compared to Vanilla SFT; ii) the degree of reasoning degradation correlates with the extent of distribution shift, suggesting that bridging this gap is central to preserving capabilities. Furthermore, we find that safety alignment in LRMs may primarily function as a mechanism to activate latent knowledge, as a mere \textbf{10} samples are sufficient for activating effective refusal behaviors. These findings not only emphasize the importance of distributional consistency but also provide insights into the activation mechanism of safety in reasoning models.

</details>


### [591] [Traffic-Aware Navigation in Road Networks](https://arxiv.org/abs/2602.02158)
*Sarah Nassar*

Main category: cs.AI

TL;DR: 比较三种图搜索算法在金斯顿路网交通感知导航中的表现：Floyd-Warshall-Ingerman（单次多查询预处理）、Dijkstra/A*（连续单查询实时搜索）、Yen算法（结合两者，先找K条最短路径再实时迭代）。


<details>
  <summary>Details</summary>
Motivation: 研究不同图搜索算法在真实城市路网交通感知导航任务中的性能权衡，为特定部署场景选择最佳算法提供依据。

Method: 在金斯顿路网中实现并比较三种方法：1）Floyd-Warshall-Ingerman算法进行单次多查询预处理；2）Dijkstra和A*算法进行连续单查询实时搜索；3）Yen算法结合两者，先找到K条最短路径再实时迭代。

Result: Dijkstra和A*算法产生最交通感知的最优解且预处理需求最小；Floyd-Warshall-Ingerman实时速度最快但只提供基于距离的路径无交通感知；Yen算法需要大量预处理但在运行速度和最优性之间取得平衡。

Conclusion: 每种方法都有优缺点，需要根据具体部署场景的实际情况权衡选择最佳定制解决方案。Dijkstra/A*适合需要交通感知且预处理资源有限的场景，Floyd-Warshall-Ingerman适合对实时速度要求极高但不需要交通感知的场景，Yen算法适合需要在速度和最优性之间平衡的场景。

Abstract: This project compares three graph search approaches for the task of traffic-aware navigation in Kingston's road network. These approaches include a single-run multi-query preprocessing algorithm (Floyd-Warshall-Ingerman), continuous single-query real-time search (Dijkstra's and A*), and an algorithm combining both approaches to balance between their trade-offs by first finding the top K shortest paths then iterating over them in real time (Yen's). Dijkstra's and A* resulted in the most traffic-aware optimal solutions with minimal preprocessing required. Floyd-Warshall-Ingerman was the fastest in real time but provided distance based paths with no traffic awareness. Yen's algorithm required significant preprocessing but balanced between the other two approaches in terms of runtime speed and optimality. Each approach presents advantages and disadvantages that need to be weighed depending on the circumstances of specific deployment contexts to select the best custom solution. *This project was completed as part of ELEC 844 (Search and Planning Algorithms for Robotics) in the Fall 2025 term.

</details>


### [592] [Reasoning in a Combinatorial and Constrained World: Benchmarking LLMs on Natural-Language Combinatorial Optimization](https://arxiv.org/abs/2602.02188)
*Xia Jiang,Jing Chen,Cong Zhang,Jie Gao,Chengpeng Hu,Chenhao Zhang,Yaoxin Wu,Yingqian Zhang*

Main category: cs.AI

TL;DR: NLCO是一个自然语言组合优化基准，用于评估LLM在端到端组合优化推理上的能力，涵盖43个问题，发现LLM在小实例上表现良好但随着规模增大而退化。


<details>
  <summary>Details</summary>
Motivation: 虽然LLM在数学和逻辑推理方面表现出色，但它们在组合优化（在高维解空间中搜索满足硬约束的解）方面的能力尚未得到充分探索，需要建立专门的评估基准。

Method: 引入NLCO基准，包含43个组合优化问题，采用四层分类法（变量类型、约束族、全局模式、目标类别），提供求解器标注的解决方案，从可行性、解最优性和推理效率三个维度评估LLM。

Result: 高性能LLM在小实例上表现出良好的可行性和解质量，但随着实例规模增大，两者都会退化，即使使用更多token进行推理也是如此。集合任务相对容易，而图结构问题和瓶颈目标导致更多失败。

Conclusion: LLM在组合优化推理方面存在局限性，特别是在处理大规模实例和复杂结构问题时，需要进一步研究提升LLM在这类问题上的能力。

Abstract: While large language models (LLMs) have shown strong performance in math and logic reasoning, their ability to handle combinatorial optimization (CO) -- searching high-dimensional solution spaces under hard constraints -- remains underexplored. To bridge the gap, we introduce NLCO, a \textbf{N}atural \textbf{L}anguage \textbf{C}ombinatorial \textbf{O}ptimization benchmark that evaluates LLMs on end-to-end CO reasoning: given a language-described decision-making scenario, the model must output a discrete solution without writing code or calling external solvers. NLCO covers 43 CO problems and is organized using a four-layer taxonomy of variable types, constraint families, global patterns, and objective classes, enabling fine-grained evaluation. We provide solver-annotated solutions and comprehensively evaluate LLMs by feasibility, solution optimality, and reasoning efficiency. Experiments across a wide range of modern LLMs show that high-performing models achieve strong feasibility and solution quality on small instances, but both degrade as instance size grows, even if more tokens are used for reasoning. We also observe systematic effects across the taxonomy: set-based tasks are relatively easy, whereas graph-structured problems and bottleneck objectives lead to more frequent failures.

</details>


### [593] [TIDE: Trajectory-based Diagnostic Evaluation of Test-Time Improvement in LLM Agents](https://arxiv.org/abs/2602.02196)
*Hang Yan,Xinyu Che,Fangzhi Xu,Qiushi Sun,Zichen Ding,Kanzhi Cheng,Jian Zhang,Tao Qin,Jun Liu,Qika Lin*

Main category: cs.AI

TL;DR: TIDE框架用于诊断LLM智能体在测试时改进中的性能瓶颈，通过三个维度分析任务完成效率、循环行为和内存负担。


<details>
  <summary>Details</summary>
Motivation: 当前对自主LLM智能体在测试时改进(TTI)的成功与失败机制理解不足，现有评估指标无法捕捉任务优化效率、错误行为适应和工作内存效用。

Method: 提出TIDE框架，将TTI分解为三个相互关联的维度：任务完成的整体时间动态、递归循环行为的约束、累积内存负担的约束。

Result: 实验表明，提高智能体性能不仅需要扩展内部推理，还需要显式优化智能体与环境之间的交互动态。

Conclusion: TIDE为理解LLM智能体测试时改进提供了诊断工具，揭示了优化智能体-环境交互动态的重要性。

Abstract: Recent advances in autonomous LLM agents demonstrate their ability to improve performance through iterative interaction with the environment. We define this paradigm as Test-Time Improvement (TTI). However, the mechanisms under how and why TTI succeed or fail remain poorly understood, and existing evaluation metrics fail to capture their task optimization efficiency, behavior adaptation after erroneous actions, and the specific utility of working memory for task completion. To address these gaps, we propose Test-time Improvement Diagnostic Evaluation (TIDE), an agent-agnostic and environment-agnostic framework that decomposes TTI into three comprehensive and interconnected dimensions. The framework measures (1) the overall temporal dynamics of task completion and (2) identifies whether performance is primarily constrained by recursive looping behaviors or (3) by burdensome accumulated memory. Through extensive experiments across diverse agents and environments, TIDE highlights that improving agent performance requires more than scaling internal reasoning, calling for explicitly optimizing the interaction dynamics between the agent and the environment.

</details>


### [594] [More Than a Quick Glance: Overcoming the Greedy Bias in KV-Cache Compression](https://arxiv.org/abs/2602.02199)
*Aryan Sood,Tanvi Sharma,Vansh Agrawal*

Main category: cs.AI

TL;DR: LASER-KV是一种KV缓存压缩框架，采用分层累积选择和精确LSH召回机制，在严格累积预算策略下保持长上下文任务性能稳定，相比现有方法提升准确率高达10%。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型理论上支持长上下文窗口，但KV缓存内存的线性增长限制了实际部署。现有压缩方法通过剪枝机制在语义召回和内存效率之间进行权衡，导致性能下降15-30%。

Method: 提出LASER-KV框架，采用分层累积选择与精确LSH召回机制。不同于固定摘要大小方法，实施基于保护除数(n)的分块累积策略，将压缩效果与滑动窗口伪影隔离。

Result: 在Babilong基准测试中，LASER-KV保持稳定性能，在128k上下文长度下准确率比现有方法高出10%，而传统压缩方法性能下降15-30%。

Conclusion: 研究结果表明仅依赖注意力分数作为token效用的代理是不够的，LASER-KV框架挑战了这一普遍假设，为KV压缩提供了新的有效方法。

Abstract: While Large Language Models (LLMs) can theoretically support extensive context windows, their actual deployment is constrained by the linear growth of Key-Value (KV) cache memory. Prevailing compression strategies mitigate this through various pruning mechanisms, yet trade-off semantic recall for memory efficiency. In this work, we present LASER-KV (Layer Accumulated Selection with Exact-LSH Recall), a framework designed to test the limits of KV compression under a strict accumulative budgeting policy. We deviate from the standard fixed summary size approach by implementing a block-wise accumulation strategy governed by a protection divisor (n). This allows us to isolate the effects of compression from sliding window artifacts. Our experiments on the Babilong benchmark reveal performance degradation in previous compression methods by 15-30% on various long context tasks. LASER-KV maintains stable performance, achieving superior accuracies by a margin of upto 10% at 128k. These findings challenge the prevailing assumption that attention scores alone are a sufficient proxy for token utility.

</details>


### [595] [Position: Explaining Behavioral Shifts in Large Language Models Requires a Comparative Approach](https://arxiv.org/abs/2602.02304)
*Martino Ciaperoni,Marzio Di Vece,Luca Pappalardo,Fosca Giannotti,Francesco Giannini*

Main category: cs.AI

TL;DR: 论文提出比较性可解释AI（Δ-XAI）框架，用于解释大规模基础模型在干预后出现的行为转变，强调需要比较参考模型与干预模型之间的变化，而非孤立分析单个模型。


<details>
  <summary>Details</summary>
Motivation: 大规模基础模型在扩展、微调、强化学习或上下文学习后会出现行为转变，虽然这些现象已受到关注，但解释其出现原因仍被忽视。传统的XAI方法只能揭示单个模型检查点的失败，无法解释不同检查点之间的内部变化。

Method: 提出比较性可解释AI（Δ-XAI）框架，包含一套设计适当解释方法时应考虑的原则。引入可能的流程管道，将其与原则关联，并提供具体的Δ-XAI实验。

Result: 建立了Δ-XAI的理论框架，明确了比较解释行为转变的方法论要求，为后续开发专门针对模型干预变化的解释工具奠定了基础。

Conclusion: 行为转变应该通过比较方式解释，核心目标应该是参考模型与干预模型之间的干预诱导转变，而不是孤立分析任何单个模型。Δ-XAI框架为解决这一挑战提供了系统方法。

Abstract: Large-scale foundation models exhibit behavioral shifts: intervention-induced behavioral changes that appear after scaling, fine-tuning, reinforcement learning or in-context learning. While investigating these phenomena have recently received attention, explaining their appearance is still overlooked. Classic explainable AI (XAI) methods can surface failures at a single checkpoint of a model, but they are structurally ill-suited to justify what changed internally across different checkpoints and which explanatory claims are warranted about that change. We take the position that behavioral shifts should be explained comparatively: the core target should be the intervention-induced shift between a reference model and an intervened model, rather than any single model in isolation. To this aim we formulate a Comparative XAI ($Δ$-XAI) framework with a set of desiderata to be taken into account when designing proper explaining methods. To highlight how $Δ$-XAI methods work, we introduce a set of possible pipelines, relate them to the desiderata, and provide a concrete $Δ$-XAI experiment.

</details>


### [596] [Interpreting and Controlling LLM Reasoning through Integrated Policy Gradient](https://arxiv.org/abs/2602.02313)
*Changming Li,Kaixing Zhang,Haoyun Xu,Yingdong Shi,Zheng Zhang,Kaitao Song,Kan Ren*

Main category: cs.AI

TL;DR: IPG框架通过传播基于结果的信号来定位LLM推理机制，实现更精确的组件定位和可靠的行为调控。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以精确定位复杂推理机制或捕捉从模型内部工作到推理输出的顺序影响，需要新的解释性方法。

Method: 提出集成策略梯度（IPG）框架，通过向后传播基于复合结果的信号（如推理后准确性）通过模型推理轨迹，将推理行为归因于模型内部组件。

Result: 实证评估表明，该方法实现了更精确的定位，并能可靠地调控不同推理模型的推理行为（如推理能力、推理强度）。

Conclusion: IPG框架基于结果导向和顺序影响感知原则，能有效识别对推理行为有顺序贡献的组件，为理解LLM推理机制提供了新方法。

Abstract: Large language models (LLMs) demonstrate strong reasoning abilities in solving complex real-world problems. Yet, the internal mechanisms driving these complex reasoning behaviors remain opaque. Existing interpretability approaches targeting reasoning either identify components (e.g., neurons) correlated with special textual patterns, or rely on human-annotated contrastive pairs to derive control vectors. Consequently, current methods struggle to precisely localize complex reasoning mechanisms or capture sequential influence from model internal workings to the reasoning outputs. In this paper, built on outcome-oriented and sequential-influence-aware principles, we focus on identifying components that have sequential contribution to reasoning behavior where outcomes are cumulated by long-range effects. We propose Integrated Policy Gradient (IPG), a novel framework that attributes reasoning behaviors to model's inner components by propagating compound outcome-based signals such as post reasoning accuracy backward through model inference trajectories. Empirical evaluations demonstrate that our approach achieves more precise localization and enables reliable modulation of reasoning behaviors (e.g., reasoning capability, reasoning strength) across diverse reasoning models.

</details>


### [597] [Context Learning for Multi-Agent Discussion](https://arxiv.org/abs/2602.02350)
*Xingyuan Hua,Sheng Yue,Xinyi Li,Yizhe Zhao,Jinrui Zhang,Ju Ren*

Main category: cs.AI

TL;DR: M2CL是一种多LLM上下文学习方法，通过训练上下文生成器动态组织信息，解决多智能体讨论中的不一致性问题，显著提升性能20%-50%。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体讨论方法容易遭受讨论不一致性问题，由于个体上下文之间的不对齐，导致LLM无法达成一致的解决方案。

Method: 提出M2CL方法，为每个智能体训练一个上下文生成器，通过自动信息组织和精炼机制，在每轮讨论中动态生成上下文指令，采用自适应的机制来控制上下文一致性和输出差异。

Result: 在学术推理、具身任务和移动控制等挑战性任务上，M2CL性能显著超越现有方法20%-50%，同时具有良好的可迁移性和计算效率。

Conclusion: M2CL通过动态上下文生成有效解决了多智能体讨论的一致性问题，使LLM能够避免过早收敛于多数噪声，逐步达成正确共识。

Abstract: Multi-Agent Discussion (MAD) has garnered increasing attention very recently, where multiple LLM instances collaboratively solve problems via structured discussion. However, we find that current MAD methods easily suffer from discussion inconsistency, LLMs fail to reach a coherent solution, due to the misalignment between their individual contexts.In this paper, we introduce a multi-LLM context learning method (M2CL) that learns a context generator for each agent, capable of dynamically generating context instructions per discussion round via automatic information organization and refinement. Specifically, inspired by our theoretical insights on the context instruction, M2CL train the generators to control context coherence and output discrepancies via a carefully crafted self-adaptive mechanism.It enables LLMs to avoid premature convergence on majority noise and progressively reach the correct consensus. We evaluate M2CL on challenging tasks, including academic reasoning, embodied tasks, and mobile control. The results show that the performance of M2CL significantly surpasses existing methods by 20%--50%, while enjoying favorable transferability and computational efficiency.

</details>


### [598] [Live-Evo: Online Evolution of Agentic Memory from Continuous Feedback](https://arxiv.org/abs/2602.02369)
*Yaolun Zhang,Yiran Wu,Yijiong Yu,Qingyun Wu,Huazheng Wang*

Main category: cs.AI

TL;DR: Live-Evo是一个在线自演化记忆系统，通过经验库和元指导库分离"发生了什么"和"如何使用"，在持续数据流中动态更新记忆权重，实现类似人类记忆的强化与衰减机制。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理的记忆系统大多针对静态训练/测试分割设计，通过折叠静态基准来近似在线学习，在真实分布漂移和持续反馈下表现脆弱。需要真正的在线自演化记忆系统来处理持续数据流。

Method: Live-Evo采用经验库和元指导库的双层架构：经验库存储原始交互经验，元指导库生成任务自适应指导。系统通过反馈动态更新经验权重，帮助性经验被强化和更频繁检索，误导性或过时经验被降权和逐渐遗忘。

Result: 在10周时间的Prophet Arena基准测试中，Live-Evo将Brier分数提高了20.8%，市场回报增加了12.9%。在深度研究基准测试中也表现出对强基线的持续改进。

Conclusion: Live-Evo展示了在线自演化记忆系统的有效性，通过模拟人类记忆的强化与衰减机制，能够在持续数据流中动态优化记忆，提高LLM代理的任务解决性能。

Abstract: Large language model (LLM) agents are increasingly equipped with memory, which are stored experience and reusable guidance that can improve task-solving performance. Recent \emph{self-evolving} systems update memory based on interaction outcomes, but most existing evolution pipelines are developed for static train/test splits and only approximate online learning by folding static benchmarks, making them brittle under true distribution shift and continuous feedback. We introduce \textsc{Live-Evo}, an online self-evolving memory system that learns from a stream of incoming data over time. \textsc{Live-Evo} decouples \emph{what happened} from \emph{how to use it} via an Experience Bank and a Meta-Guideline Bank, compiling task-adaptive guidelines from retrieved experiences for each task. To manage memory online, \textsc{Live-Evo} maintains experience weights and updates them from feedback: experiences that consistently help are reinforced and retrieved more often, while misleading or stale experiences are down-weighted and gradually forgotten, analogous to reinforcement and decay in human memory. On the live \textit{Prophet Arena} benchmark over a 10-week horizon, \textsc{Live-Evo} improves Brier score by 20.8\% and increases market returns by 12.9\%, while also transferring to deep-research benchmarks with consistent gains over strong baselines. Our code is available at https://github.com/ag2ai/Live-Evo.

</details>


### [599] [Trust by Design: Skill Profiles for Transparent, Cost-Aware LLM Routing](https://arxiv.org/abs/2602.02386)
*Mika Okamoto,Ansel Kaplan Erol,Glenn Matlin*

Main category: cs.AI

TL;DR: BELLA是一个预算高效的LLM选择框架，通过技能分析自动推荐最优模型，在保证性能的同时控制成本。


<details>
  <summary>Details</summary>
Motivation: 当前标准基准测试报告的是聚合指标，掩盖了任务所需的具体能力以及更便宜的模型是否足够的问题。LLM从业者需要在不浪费资金的情况下为任务选择合适的模型。

Method: BELLA通过三个阶段实现：1）分解LLM输出并使用基于批评的分析提取细粒度技能；2）将技能聚类为结构化能力矩阵；3）多目标优化选择模型，在预算约束下最大化性能。

Result: BELLA提供自然语言推理的推荐，提供当前黑盒路由系统缺乏的透明度。该框架使从业者能够为部署LLM做出原则性的成本-性能权衡。

Conclusion: BELLA框架通过可解释的基于技能的分析，实现了预算高效的LLM选择，解决了标准基准测试的局限性，为从业者提供了透明的模型选择方法。

Abstract: How should Large Language Model (LLM) practitioners select the right model for a task without wasting money? We introduce BELLA (Budget-Efficient LLM Selection via Automated skill-profiling), a framework that recommends optimal LLM selection for tasks through interpretable skill-based model selection. Standard benchmarks report aggregate metrics that obscure which specific capabilities a task requires and whether a cheaper model could suffice. BELLA addresses this gap through three stages: (1) decomposing LLM outputs and extract the granular skills required by using critic-based profiling, (2) clustering skills into structured capability matrices, and (3) multi-objective optimization to select the right models to maximize performance while respecting budget constraints. BELLA provides natural-language rationale for recommendations, providing transparency that current black-box routing systems lack. We describe the framework architecture, situate it within the landscape of LLM routing and evaluation, and discuss its application to financial reasoning as a representative domain exhibiting diverse skill requirements and cost-variation across models. Our framework enables practitioners to make principled and cost-performance trade-offs for deploying LLMs.

</details>


### [600] [Structure Enables Effective Self-Localization of Errors in LLMs](https://arxiv.org/abs/2602.02416)
*Ankur Samanta,Akshayaa Magesh,Ayush Jain,Kavosh Asadi,Youliang Yu,Daniel Jiang,Boris Vidolov,Kaveh Hassani,Paul Sajda,Jalaj Bhandari,Yonathan Efroni*

Main category: cs.AI

TL;DR: 论文提出Thought-ICS框架，通过离散化思维步骤实现语言模型的错误定位与自我修正，相比传统方法显著提升修正能力


<details>
  <summary>Details</summary>
Motivation: 探索语言模型能否显式定位错误推理，以构建能有效自我修正的AI系统。受人类大脑在离散决策点监控错误并重新采样替代方案的启发

Method: 引入Thought-ICS框架：将推理结构化为离散、语义连贯的思维步骤，每次生成一个完整思维单元，创建自然边界进行精确错误定位。验证失败时回溯到最后一个正确点重新生成替代推理

Result: 在需要修正被验证为错误的推理时，Thought-ICS实现20-40%的自我修正提升。在完全自主无外部验证的设置中，优于当代自我修正基线方法

Conclusion: 通过结构化推理为离散思维步骤，语言模型能够可靠定位错误，Thought-ICS框架为构建有效自我修正的AI系统提供了可行路径

Abstract: Self-correction in language models remains elusive. In this work, we explore whether language models can explicitly localize errors in incorrect reasoning, as a path toward building AI systems that can effectively correct themselves. We introduce a prompting method that structures reasoning as discrete, semantically coherent thought steps, and show that models are able to reliably localize errors within this structure, while failing to do so in conventional, unstructured chain-of-thought reasoning. Motivated by how the human brain monitors errors at discrete decision points and resamples alternatives, we introduce Iterative Correction Sampling of Thoughts (Thought-ICS), a self-correction framework. Thought-ICS iteratively prompts the model to generate reasoning one discrete and complete thought at a time--where each thought represents a deliberate decision by the model--creating natural boundaries for precise error localization. Upon verification, the model localizes the first erroneous step, and the system backtracks to generate alternative reasoning from the last correct point. When asked to correct reasoning verified as incorrect by an oracle, Thought-ICS achieves 20-40% self-correction lift. In a completely autonomous setting without external verification, it outperforms contemporary self-correction baselines.

</details>


### [601] [SafeGround: Know When to Trust GUI Grounding Models via Uncertainty Calibration](https://arxiv.org/abs/2602.02419)
*Qingni Wang,Yue Fan,Xin Eric Wang*

Main category: cs.AI

TL;DR: SafeGround是一个用于GUI grounding的不确定性感知框架，通过分布感知的不确定性量化方法和统计保证的FDR控制，实现风险感知的预测，提高系统级准确性。


<details>
  <summary>Details</summary>
Motivation: GUI grounding中的错误预测可能导致代价高昂且难以逆转的操作（如错误支付批准），因此需要提高模型可靠性，确保风险可控。

Method: SafeGround采用分布感知的不确定性量化方法捕捉模型输出的空间分散性，通过校准过程获得具有统计保证的假发现率控制的测试时决策阈值。

Result: 在ScreenSpot-Pro基准测试中，SafeGround的不确定性度量在区分正确与错误预测方面优于现有基线，校准阈值能可靠实现严格的风险控制，系统级准确率相比Gemini-only推理最高提升5.38个百分点。

Conclusion: SafeGround为GUI grounding提供了一个有效的风险控制框架，通过不确定性量化和统计校准实现了可靠的预测决策，显著提升了系统性能。

Abstract: Graphical User Interface (GUI) grounding aims to translate natural language instructions into executable screen coordinates, enabling automated GUI interaction. Nevertheless, incorrect grounding can result in costly, hard-to-reverse actions (e.g., erroneous payment approvals), raising concerns about model reliability. In this paper, we introduce SafeGround, an uncertainty-aware framework for GUI grounding models that enables risk-aware predictions through calibrations before testing. SafeGround leverages a distribution-aware uncertainty quantification method to capture the spatial dispersion of stochastic samples from outputs of any given model. Then, through the calibration process, SafeGround derives a test-time decision threshold with statistically guaranteed false discovery rate (FDR) control. We apply SafeGround on multiple GUI grounding models for the challenging ScreenSpot-Pro benchmark. Experimental results show that our uncertainty measure consistently outperforms existing baselines in distinguishing correct from incorrect predictions, while the calibrated threshold reliably enables rigorous risk control and potentials of substantial system-level accuracy improvements. Across multiple GUI grounding models, SafeGround improves system-level accuracy by up to 5.38\% percentage points over Gemini-only inference.

</details>


### [602] [Thinking with Comics: Enhancing Multimodal Reasoning through Structured Visual Storytelling](https://arxiv.org/abs/2602.02453)
*Andong Chen,Wenxin Zhu,Qiuyu Ding,Yuchen Song,Muyun Yang,Tiejun Zhao*

Main category: cs.AI

TL;DR: 提出"Thinking with Comics"视觉推理范式，用漫画作为介于图像和视频之间的高信息密度媒介，在保持时间结构和叙事连贯性的同时降低推理成本。


<details>
  <summary>Details</summary>
Motivation: 现有模态存在明显限制：静态图像难以表示时间结构，而视频引入大量冗余和计算成本。需要一种既能保留时间结构又高效的视觉推理媒介。

Method: 提出基于漫画的视觉推理范式，漫画作为高信息密度媒介，保留时间结构、嵌入文本和叙事连贯性。系统研究两种基于漫画的推理路径，并在多种推理任务和长上下文理解任务上进行评估。

Result: 实验结果显示：1) Thinking with Comics在多层次时间推理和因果推理任务上优于Thinking with Images；2) 比Thinking with Video显著更高效；3) 不同漫画叙事结构和风格对任务性能有持续影响。

Conclusion: 漫画作为中间视觉表示能有效改进多模态推理，在时间结构保留和计算效率之间取得良好平衡，是提升视觉推理能力的有效媒介。

Abstract: Chain-of-Thought reasoning has driven large language models to extend from thinking with text to thinking with images and videos. However, different modalities still have clear limitations: static images struggle to represent temporal structure, while videos introduce substantial redundancy and computational cost. In this work, we propose Thinking with Comics, a visual reasoning paradigm that uses comics as a high information-density medium positioned between images and videos. Comics preserve temporal structure, embedded text, and narrative coherence while requiring significantly lower reasoning cost. We systematically study two reasoning paths based on comics and evaluate them on a range of reasoning tasks and long-context understanding tasks. Experimental results show that Thinking with Comics outperforms Thinking with Images on multi-step temporal and causal reasoning tasks, while remaining substantially more efficient than Thinking with Video. Further analysis indicates that different comic narrative structures and styles consistently affect performance across tasks, suggesting that comics serve as an effective intermediate visual representation for improving multimodal reasoning.

</details>


### [603] [Drift-Bench: Diagnosing Cooperative Breakdowns in LLM Agents under Input Faults via Multi-Turn Interaction](https://arxiv.org/abs/2602.02455)
*Han Bao,Zheyuan Zhang,Pengcheng Jing,Zhengqing Yuan,Kaiwen Shi,Yanfang Ye*

Main category: cs.AI

TL;DR: Drift-Bench是首个评估自主代理在多轮澄清对话中处理输入故障能力的诊断基准，通过状态导向和服务导向执行环境测试代理的语用能力，揭示现有模型在输入违反合作假设时的性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型向自主代理过渡，用户输入经常违反合作假设（如隐含意图、缺失参数、错误预设或模糊表达），产生文本评估无法捕捉的执行风险。现有基准通常假设指令明确或仅限于文本单轮澄清，无法衡量在接地执行风险下的多轮消歧能力。

Method: Drift-Bench基于经典沟通理论，提供统一的合作故障分类法，采用角色驱动的用户模拟器和Rise评估协议，在状态导向和服务导向执行环境中评估多轮澄清能力。

Result: 实验显示在这些故障下模型性能大幅下降，澄清效果因用户角色和故障类型而异。该方法揭示了现有代理在处理非理想输入时的局限性。

Conclusion: Drift-Bench连接了澄清研究和代理安全评估，能够系统诊断可能导致不安全执行的故障，为自主代理的安全性和鲁棒性评估提供了重要工具。

Abstract: As Large Language Models transition to autonomous agents, user inputs frequently violate cooperative assumptions (e.g., implicit intent, missing parameters, false presuppositions, or ambiguous expressions), creating execution risks that text-only evaluations do not capture. Existing benchmarks typically assume well-specified instructions or restrict evaluation to text-only, single-turn clarification, and thus do not measure multi-turn disambiguation under grounded execution risk. We introduce \textbf{Drift-Bench}, the first diagnostic benchmark that evaluates agentic pragmatics under input faults through multi-turn clarification across state-oriented and service-oriented execution environments. Grounded in classical theories of communication, \textbf{Drift-Bench} provides a unified taxonomy of cooperative breakdowns and employs a persona-driven user simulator with the \textbf{Rise} evaluation protocol. Experiments show substantial performance drops under these faults, with clarification effectiveness varying across user personas and fault types. \MethodName bridges clarification research and agent safety evaluation, enabling systematic diagnosis of failures that can lead to unsafe executions.

</details>


### [604] [MentisOculi: Revealing the Limits of Reasoning with Mental Imagery](https://arxiv.org/abs/2602.02465)
*Jana Zeller,Thaddäus Wiedemer,Fanfei Li,Thomas Klein,Prasanna Mayilvahanan,Matthias Bethge,Felix Wichmann,Ryan Cotterell,Wieland Brendel*

Main category: cs.AI

TL;DR: 论文提出MentisOculi评估套件，发现当前统一多模态模型在视觉推理中无法有效利用视觉思维辅助，即使生成正确可视化也无法提升任务表现。


<details>
  <summary>Details</summary>
Motivation: 随着前沿模型从多模态大语言模型向统一多模态模型演进，研究者希望探索能否像人类利用心理意象辅助推理一样，让模型使用中间可视化作为推理辅助。核心是评估模型形成、维持和操作视觉表征的能力。

Method: 开发MentisOculi——一个程序化、分层化的多步推理问题套件，专门设计来挑战前沿模型。评估从潜在标记到显式生成图像等多种视觉策略，特别分析统一多模态模型的表现。

Result: 视觉策略普遍未能提升模型性能。统一多模态模型虽然具备解决任务的文本推理能力，有时能生成正确可视化，但存在累积生成错误，且即使有真实可视化也无法有效利用。视觉思维目前尚未对模型推理产生益处。

Conclusion: 尽管视觉思维具有内在吸引力，但当前模型尚无法从中受益。MentisOculi为分析和弥合这一差距提供了必要基础，可应用于不同模型家族的研究。

Abstract: Frontier models are transitioning from multimodal large language models (MLLMs) that merely ingest visual information to unified multimodal models (UMMs) capable of native interleaved generation. This shift has sparked interest in using intermediate visualizations as a reasoning aid, akin to human mental imagery. Central to this idea is the ability to form, maintain, and manipulate visual representations in a goal-oriented manner. To evaluate and probe this capability, we develop MentisOculi, a procedural, stratified suite of multi-step reasoning problems amenable to visual solution, tuned to challenge frontier models. Evaluating visual strategies ranging from latent tokens to explicit generated imagery, we find they generally fail to improve performance. Analysis of UMMs specifically exposes a critical limitation: While they possess the textual reasoning capacity to solve a task and can sometimes generate correct visuals, they suffer from compounding generation errors and fail to leverage even ground-truth visualizations. Our findings suggest that despite their inherent appeal, visual thoughts do not yet benefit model reasoning. MentisOculi establishes the necessary foundation to analyze and close this gap across diverse model families.

</details>


### [605] [Avenir-Web: Human-Experience-Imitating Multimodal Web Agents with Mixture of Grounding Experts](https://arxiv.org/abs/2602.02468)
*Aiden Yiliu Li,Xinyue Hao,Shilong Liu,Mengdi Wang*

Main category: cs.AI

TL;DR: Avenir-Web：一种新型网页代理，通过混合定位专家、经验模仿规划和任务跟踪检查表等技术，在真实网页交互中实现新的开源SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态大语言模型有所进步，但自主网页代理在执行复杂动态网页界面的长时程任务时仍不可靠。现有代理存在元素定位不准确、缺乏站点特定程序知识、长时任务跟踪和记忆不稳定等问题。

Method: 1. 混合定位专家（Mixture of Grounding Experts）提高元素定位精度；2. 经验模仿规划（Experience-Imitation Planning）整合程序先验知识；3. 任务跟踪检查表与自适应内存实现鲁棒交互。

Result: 在Online-Mind2Web基准测试中，Avenir-Web显著超越先前开源代理，达到与顶级专有模型相当的性能，建立了新的开源SOTA。

Conclusion: Avenir-Web通过创新的定位、规划和记忆机制，解决了网页代理在复杂动态界面中的关键挑战，为可靠网页交互建立了新的开源标准。

Abstract: Despite advances in multimodal large language models, autonomous web agents still struggle to reliably execute long-horizon tasks on complex and dynamic web interfaces. Existing agents often suffer from inaccurate element grounding, the absence of site-specific procedural knowledge, and unstable long-term task tracking and memory, particularly when operating over complex Document Object Model structures. To address these limitations, we introduce Avenir-Web, a web agent that achieves a new open-source state of the art on the Online-Mind2Web benchmark in real-world deployment. Avenir-Web leverages a Mixture of Grounding Experts, Experience-Imitation Planning for incorporating procedural priors, and a task-tracking checklist combined with adaptive memory to enable robust and seamless interaction across diverse user interface paradigms. We evaluate Avenir-Web on Online-Mind2Web, a rigorous benchmark of live and user-centered web tasks. Our results demonstrate that Avenir-Web significantly surpasses prior open-source agents and attains performance parity with top-tier proprietary models, thereby establishing a new open-source state of the art for reliable web agents on live websites.

</details>


### [606] [Breaking the Reversal Curse in Autoregressive Language Models via Identity Bridge](https://arxiv.org/abs/2602.02470)
*Xutao Ma,Yixiao Huang,Hanlin Zhu,Somayeh Sojoudi*

Main category: cs.AI

TL;DR: 通过添加"A→A"形式的身份桥接正则化数据，可以显著缓解LLM的反转诅咒问题，使模型从单纯记忆事实转向学习更高层次的规则。


<details>
  <summary>Details</summary>
Motivation: 自回归大语言模型在复杂任务上表现出色，但在简单逻辑推理如"反转诅咒"上会失败——当训练数据为"A→B"形式时，模型无法推理出"B←A"。先前研究认为这是自回归因果LLM的固有根本限制，表明模型倾向于记忆事实而非捕捉高层次规则。

Method: 提出一种简单的正则化数据配方"身份桥接"，形式为"A→A"（如"爱丽丝的名字是爱丽丝"）。理论上证明在此配方下，即使单层Transformer也能通过梯度下降的隐式偏置打破反转诅咒。实证上在1B预训练语言模型上微调使用该数据配方。

Result: 使用身份桥接数据配方的模型在反转任务上达到40%的成功率，而仅使用前向知识数据训练时成功率接近零。这显著缓解了反转诅咒问题。

Conclusion: 挑战了反转诅咒是自回归LLM固有根本限制的观点，表明通过简单的数据调整可以鼓励模型学习更高层次的规则。为反转诅咒提供了新的理论基础，并提供了低成本、原则性的方法来提升LLM的规则学习能力。

Abstract: Autoregressive large language models (LLMs) have achieved remarkable success in many complex tasks, yet they can still fail in very simple logical reasoning such as the "reversal curse" -- when trained on forward knowledge data of the form "$A \rightarrow B$" (e.g., Alice's husband is Bob), the model is unable to deduce the reversal knowledge "$B \leftarrow A$" (e.g., Bob's wife is Alice) during test. Extensive prior research suggests that this failure is an inherent, fundamental limit of autoregressive causal LLMs, indicating that these models tend to memorize factual-level knowledge rather than capture higher-level rules. In this paper, we challenge this view by showing that this seemingly fundamental limit can be mitigated by slightly tweaking the training data with a simple regularization data recipe called the Identity Bridge of the form "$A \to A$" (e.g., The name of Alice is Alice). Theoretically, we prove that under this recipe, even a one-layer transformer can break the reversal curse by analyzing the implicit bias of gradient descent. Empirically, we show that a 1B pretrained language model finetuned with the proposed data recipe achieves a 40% success rate on reversal tasks, in stark contrast to a near-zero success rate when trained solely on forward-knowledge data. Our work provides a novel theoretical foundation for the reversal curse and offers a principled, low-cost path to encouraging LLMs to learn higher-level rules from data.

</details>


### [607] [AgentRx: Diagnosing AI Agent Failures from Execution Trajectories](https://arxiv.org/abs/2602.02475)
*Shraddha Barke,Arnav Goyal,Alind Khare,Avaljot Singh,Suman Nath,Chetan Bansal*

Main category: cs.AI

TL;DR: 提出AGENTRX框架，通过约束合成与验证来自动定位AI代理失败轨迹中的关键失败步骤和类别，减少人工标注成本


<details>
  <summary>Details</summary>
Motivation: AI代理失败难以定位，因为执行具有概率性、长视野、多代理和噪声工具输出等特点。现有方法缺乏系统性的失败分析和诊断工具

Method: 1) 创建包含115个失败轨迹的基准数据集，人工标注关键失败步骤和基于扎根理论推导的跨领域失败分类；2) 提出AGENTRX框架：合成约束、逐步评估、生成可审计的验证日志，使用LLM判断器定位关键步骤和类别

Result: AGENTRX在三个领域（结构化API工作流、事件管理、开放式Web/文件任务）中，在步骤定位和失败归因方面优于现有基线方法

Conclusion: AGENTRX提供了一种自动化的领域无关诊断框架，能够有效定位AI代理失败的根本原因，减少人工分析成本，并为失败分析提供了系统化的方法

Abstract: AI agents often fail in ways that are difficult to localize because executions are probabilistic, long-horizon, multi-agent, and mediated by noisy tool outputs. We address this gap by manually annotating failed agent runs and release a novel benchmark of 115 failed trajectories spanning structured API workflows, incident management, and open-ended web/file tasks. Each trajectory is annotated with a critical failure step and a category from a grounded-theory derived, cross-domain failure taxonomy. To mitigate the human cost of failure attribution, we present AGENTRX, an automated domain-agnostic diagnostic framework that pinpoints the critical failure step in a failed agent trajectory. It synthesizes constraints, evaluates them step-by-step, and produces an auditable validation log of constraint violations with associated evidence; an LLM-based judge uses this log to localize the critical step and category. Our framework improves step localization and failure attribution over existing baselines across three domains.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [608] [Updatable Balanced Index for Stable Streaming Similarity Search over Large-Scale Fresh Vectors](https://arxiv.org/abs/2602.00563)
*Yuhui Lai,Shixun Huang,Sheng Wang*

Main category: cs.DB

TL;DR: UBIS是一个可更新的平衡索引，用于处理流式相似性搜索，通过调度并发更新和减少不平衡更新情况，在数据频繁更新的场景下保持索引质量。


<details>
  <summary>Details</summary>
Motivation: 随着AI应用的普及，向量数据在信息检索和推荐系统中广泛应用。近似最近邻搜索(ANNS)在这些服务中扮演核心角色。随着数据更新频率增加，索引需要支持实时更新。现有方法存在两个问题：1)使用额外缓冲区的方案资源密集且效率低下；2)升级内部索引结构的方法在流式工作负载下因更新拥塞和不平衡分布导致性能下降。

Method: 提出UBIS（可更新的平衡索引），通过调度并发更新来减少冲突，并通过减少不平衡更新情况来维持良好的索引质量。该方法专门针对流式工作负载设计，能够处理高频率的数据更新。

Result: 在真实世界数据集上的实验结果表明，与最先进的索引相比，UBIS在流式工作负载下实现了最高77%的搜索准确率提升和平均45%的更新吞吐量提升。

Conclusion: UBIS有效地解决了流式相似性搜索中的更新问题，通过平衡更新调度和减少不平衡情况，在高频率数据更新场景下显著提升了搜索准确性和更新效率。

Abstract: As artificial intelligence gains more and more popularity, vectors are one of the most widely used data structures for services such as information retrieval and recommendation. Approximate Nearest Neighbor Search (ANNS), which generally relies on indices optimized for fast search to organize large datasets, has played a core role in these popular services. As the frequency of data shift grows, it is crucial for indices to accommodate new data and support real-time updates. Existing researches adopting two different approaches hold the following drawbacks: 1) approaches using additional buffers to temporarily store new data are resource-intensive and inefficient due to the global rebuilding processes; 2) approaches upgrading the internal index structure suffer from performance degradation because of update congestion and imbalanced distribution in streaming workloads. In this paper, we propose UBIS, an Updatable Balanced Index for stable streaming similarity Search, to resolve conflicts by scheduling concurrent updates and maintain good index quality by reducing imbalanced update cases, when the update frequency grows. Experimental results in the real-world datasets demonstrate that UBIS achieves up to 77% higher search accuracy and 45% higher update throughput on average compared to the state-of-the-art indices in streaming workloads.

</details>


### [609] [Meta Engine: A Unified Semantic Query Engine on Heterogeneous LLM-Based Query Systems](https://arxiv.org/abs/2602.01701)
*Ruyu Li,Tinghui Zhang,Haodi Ma,Daisy Zhe Wang,Yifan Wang*

Main category: cs.DB

TL;DR: Meta Engine是一个"查询系统之上的查询系统"，通过整合异构的专业化LLM查询系统，解决多模态语义查询中的API碎片化和专业化与通用性权衡问题。


<details>
  <summary>Details</summary>
Motivation: 随着多模态数据的广泛应用，语义查询需求日益增长，但现有LLM语义查询系统存在两大挑战：1) 不同系统的API碎片化导致集成困难；2) 专业化系统在单模态上表现优异但难以处理多模态数据，而通用系统在多模态上表现欠佳。

Method: 提出Meta Engine，一个统一的语义查询引擎，包含五个核心组件：1) 自然语言查询解析器；2) 操作符生成器；3) 查询路由器；4) 适配器集合；5) 结果聚合器。该系统整合异构的专业化LLM查询系统。

Result: Meta Engine在评估中始终优于所有基线方法，在大多数情况下F1分数提高3-6倍，在特定数据集上最高可达24倍提升。

Conclusion: Meta Engine通过整合异构的专业化LLM查询系统，有效解决了多模态语义查询中的集成挑战和专业化与通用性权衡问题，实现了统一且高性能的语义查询能力。

Abstract: With the increasingly use of multi-modal data, semantic query has become more and more demanded in data management systems, which is an important way to access and analyze multi-modal data. As unstructured data, most information of multi-modal data (text, image, video, etc) hides in the semantics, which cannot be accessed by the traditional database queries like SQL.
  Given the power of Large Language Model (LLM) in understanding semantics and processing natural language, in recent years several LLM-based semantic query systems have been proposed, to support semantic querying over unstructured data. However, this rapid growth has produced a fragmented ecosystem. Applications face significant integration challenges due to (1) disparate APIs of different semantic query systems and (2) a fundamental trade-off between specialization and generality. Many semantic query systems are highly specialized, offering state-of-the-art performance within a single modality but struggling with multi-modal data. Conversely, some "all-in-one" systems handle multiple modalities but often exhibit suboptimal performance compared to their specialized counterparts in specific modalities.
  This paper introduces Meta Engine, a novel "query system on query systems", designed to resolve those aforementioned challenges. Meta Engine is a unified semantic query engine that integrates heterogeneous, specialized LLM-based query systems. Its architecture comprises five key components: (1) a Natural Language (NL) Query Parser, (2) an Operator Generator, (3) a Query Router, (4) a set of Adapters, and (5) a Result Aggregator. In the evaluation, Meta Engine consistently outperforms all baselines, yielding 3-6x higher F1 in most cases and up to 24x on specific datasets.

</details>


### [610] [ChemDCAT-AP: Enabling Semantic Interoperability with a Contextual Extension of DCAT-AP](https://arxiv.org/abs/2602.01822)
*Philip Stroemert,Hendrik Borgelt,David Linke,Mark Doerr,Bhavin Katabathuni,Oliver Koepler,Norbert Kockmann*

Main category: cs.DB

TL;DR: 提出了DCAT-AP PLUS（DCAT-AP+），这是一个通用的DCAT应用配置文件，用于增强研究数据的跨领域互操作性，通过LinkML框架支持模式继承和领域特定子模式。


<details>
  <summary>Details</summary>
Motivation: 跨领域数据集成面临语义互操作性挑战，不同学科使用不同的元数据模式、领域本体和概念模型。虽然DCAT提供了数据集描述的基础词汇表，但其核心模型过于轻量，现有应用配置文件（如DCAT-AP）主要针对公共数据，不足以满足研究数据的复杂需求。

Method: 提出DCAT-AP+作为通用应用配置文件，引入上层抽象层，可被各领域专门化而不牺牲兼容性。采用LinkML（基于YAML的建模框架）支持模式继承、生成领域特定子模式，并提供数据类型协调、验证和格式转换机制。以化学和催化领域为例，开发了ChemDCAT-AP具体配置文件进行演示。

Result: DCAT-AP+能够全面表示研究数据生成的来源和上下文信息，支持跨领域互操作性。通过ChemDCAT-AP展示了化学和催化相邻领域数据集成的潜力，验证了该框架在实际应用中的可行性。

Conclusion: DCAT-AP+为研究数据提供了增强的跨领域互操作性解决方案，通过通用上层抽象和领域专门化机制，解决了不同学科间语义互操作性的挑战，同时确保与现有数据基础设施的平滑集成。

Abstract: Cross-domain data integration drives interdisciplinary data reuse and knowledge transfer across domains. However, each discipline maintains its own metadata schemas and domain ontologies, employing distinct conceptual models and application profiles, which complicates semantic interoperability. The W3C Data Catalog Vocabulary (DCAT) offers a widely adopted RDF vocabulary for describing datasets and their distributions, but its core model is intentionally lightweight. Numerous domain-specific application profiles have emerged to enrich DCAT's expressivity, the most well-known DCAT-AP for public data. To facilitate cross-domain interoperability for research data, we propose DCAT-AP PLUS, a DCAT Application Profile (P)roviding additional (L)inks to (U)se-case (S)pecific context (DCAT-AP+). This generic application profile enables a comprehensive representation of the provenance and context of research data generation. DACT-AP+ introduces an upper-level layer that can be specialized by individual domains without sacrificing compatibility. We demonstrate the application of DCAT-AP+ and a specific profile ChemDCAT-AP to showcase the potential of data integration of the neighboring disciplines chemistry and catalysis. We adopt LinkML, a YAML-based modeling framework, to support schema inheritance, generate domain-specific subschemas, and provide mechanisms for data type harmonization, validation, and format conversion, ensuring smooth integration of DCAT-AP+ and ChemDCAT-AP within existing data infrastructures.

</details>


### [611] [Tidehunter: Large-Value Storage With Minimal Data Relocation](https://arxiv.org/abs/2602.01873)
*Andrey Chursin,Lefteris Kokoris-Kogias,Alex Orlov,Alberto Sonnino,Igor Zablotchi*

Main category: cs.DB

TL;DR: Tidehunter是一个存储引擎，通过将WAL作为永久存储而非临时恢复缓冲区，消除了LSM-tree中的值压缩开销，针对大值、均匀分布键的工作负载实现了高性能。


<details>
  <summary>Details</summary>
Motivation: LSM-tree在随机工作负载下存在10-30倍的写放大问题，这对于大值、均匀分布键的工作负载（如内容寻址存储、去重系统和区块链验证器）尤为严重，需要消除值压缩的开销。

Method: 1) 将WAL作为永久存储而非临时缓冲区，值永不覆盖；2) 使用小型、延迟刷新的索引表映射键到WAL位置；3) 无锁写入通过原子分配和并行复制饱和NVMe驱动器；4) 乐观索引结构利用均匀键分布实现单往返查找；5) 基于epoch的修剪在不阻塞写入的情况下回收空间。

Result: 在1TB数据集、1KB值大小下，Tidehunter达到830K写入/秒，比RocksDB快8.4倍，比BlobDB快2.9倍；点查询提升1.7倍，存在性检查提升15.6倍。在Sui区块链中，能在导致RocksDB崩溃的负载下保持稳定吞吐和延迟。

Conclusion: Tidehunter通过消除值压缩，为具有均匀分布键的大值工作负载提供了高性能存储引擎，已集成到Sui区块链中并准备投入生产部署。

Abstract: Log-Structured Merge-Trees (LSM-trees) dominate persistent key-value storage but suffer from high write amplification from 10x to 30x under random workloads due to repeated compaction. This overhead becomes prohibitive for large values with uniformly distributed keys, a workload common in content-addressable storage, deduplication systems, and blockchain validators. We present Tidehunter, a storage engine that eliminates value compaction by treating the Write-Ahead Log (WAL) as permanent storage rather than a temporary recovery buffer. Values are never overwritten; and small, lazily-flushed index tables map keys to WAL positions. Tidehunter introduces (a) lock-free writes that saturate NVMe drives through atomic allocation and parallel copying, (b) an optimistic index structure that exploits uniform key distributions for single-roundtrip lookups, and (c) epoch-based pruning that reclaims space without blocking writes. On a 1 TB dataset with 1 KB values, Tidehunter achieves 830K writes per second, that is 8.4x higher than RocksDB and 2.9x higher than BlobDB, while improving point queries by 1.7x and existence checks by 15.6x. We validate real-world impact by integrating Tidehunter into Sui, a high-throughput blockchain, where it maintains stable throughput and latency under loads that cause RocksDB-backed validators to collapse. Tidehunter is production-ready and is being deployed in production within Sui.

</details>


### [612] [SQLAgent: Learning to Explore Before Generating as a Data Engineer](https://arxiv.org/abs/2602.01952)
*Wenjia Jiang,Yiwei Wang,Boyan Han,Joey Tianyi Zhou,Chi Zhang*

Main category: cs.DB

TL;DR: 提出两阶段LLM框架，通过探索阶段自主构建数据库知识库，部署阶段利用知识生成准确SQL查询，显著提升复杂数据库查询的准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有LLM方法在处理复杂真实数据库时泛化能力不足，因为SQL推理高度依赖特定数据库的schema、语义和连接路径，需要深度熟悉数据库结构。

Method: 两阶段框架：1) 探索阶段：使用蒙特卡洛树搜索策略自主导航schema，构建包含schema片段、可执行查询和自然语言描述的三元组知识库；2) 部署阶段：双代理系统利用收集的知识作为上下文示例，迭代检索相关信息并生成准确SQL查询。

Result: 在大规模基准测试中，该方法显著优于强基线，证明了其有效性和泛化能力。

Conclusion: 该框架通过解耦知识获取和查询生成，使LLM能够主动熟悉未见数据库并处理复杂多步推理，为自然语言到数据库接口提供了更鲁棒的解决方案。

Abstract: Large Language Models have recently shown impressive capabilities in reasoning and code generation, making them promising tools for natural language interfaces to relational databases. However, existing approaches often fail to generalize in complex, real-world settings due to the highly database-specific nature of SQL reasoning, which requires deep familiarity with unique schemas, ambiguous semantics, and intricate join paths. To address this challenge, we introduce a novel two-stage LLM-based framework that decouples knowledge acquisition from query generation. In the Exploration Stage, the system autonomously constructs a database-specific knowledge base by navigating the schema with a Monte Carlo Tree Search-inspired strategy, generating triplets of schema fragments, executable queries, and natural language descriptions as usage examples. In the Deployment Stage, a dual-agent system leverages the collected knowledge as in-context examples to iteratively retrieve relevant information and generate accurate SQL queries in response to user questions. This design enables the agent to proactively familiarize itself with unseen databases and handle complex, multi-step reasoning. Extensive experiments on large-scale benchmarks demonstrate that our approach significantly improves accuracy over strong baselines, highlighting its effectiveness and generalizability.

</details>


### [613] [Hippasus: Effective and Efficient Automatic Feature Augmentation for Machine Learning Tasks on Relational Data](https://arxiv.org/abs/2602.02025)
*Serafeim Papadias,Kostas Patroumpas,Dimitrios Skoutas*

Main category: cs.DB

TL;DR: Hippasus是一个用于特征增强的模块化框架，通过结合统计信号和LLM语义推理来高效发现和整合跨多表关系数据的特征，在提升准确率的同时保持高性能。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型依赖高质量特征，但有用特征常分散在多个关系表中。现有特征增强方法面临效果与效率的权衡：高准确率需要探索大量连接路径，但穷举探索计算成本过高；而只考虑直接邻居的方法效果有限，神经网络方法又需要昂贵训练数据且可扩展性差。

Method: Hippasus采用三阶段方法：1) 结合轻量级统计信号和LLM语义推理，在执行前剪枝无希望的连接路径；2) 使用优化的多路连接算法并整合多路径特征，大幅减少执行时间；3) 集成LLM语义理解和统计度量，选择既语义有意义又经验预测性强的特征。

Result: 在公开数据集上的实验评估显示，Hippasus相比最先进的基线方法，特征增强准确率提升高达26.8%，同时提供高运行时性能。

Conclusion: Hippasus通过模块化设计成功解决了特征增强中效果与效率的权衡问题，结合统计信号和LLM语义推理，在复杂多表场景下实现了准确且高效的特征发现与整合。

Abstract: Machine learning models depend critically on feature quality, yet useful features are often scattered across multiple relational tables. Feature augmentation enriches a base table by discovering and integrating features from related tables through join operations. However, scaling this process to complex schemas with many tables and multi-hop paths remains challenging. Feature augmentation must address three core tasks: identify promising join paths that connect the base table to candidate tables, execute these joins to materialize augmented data, and select the most informative features from the results. Existing approaches face a fundamental tradeoff between effectiveness and efficiency: achieving high accuracy requires exploring many candidate paths, but exhaustive exploration is computationally prohibitive. Some methods compromise by considering only immediate neighbors, limiting their effectiveness, while others employ neural models that require expensive training data and introduce scalability limitations. We present Hippasus, a modular framework that achieves both goals through three key contributions. First, we combine lightweight statistical signals with semantic reasoning from Large Language Models to prune unpromising join paths before execution, focusing computational resources on high-quality candidates. Second, we employ optimized multi-way join algorithms and consolidate features from multiple paths, substantially reducing execution time. Third, we integrate LLM-based semantic understanding with statistical measures to select features that are both semantically meaningful and empirically predictive. Our experimental evaluation on publicly available datasets shows that Hippasus substantially improves feature augmentation accuracy by up to 26.8% over state-of-the-art baselines while also offering high runtime performance.

</details>


### [614] [QVCache: A Query-Aware Vector Cache](https://arxiv.org/abs/2602.02057)
*Anıl Eren Göçer,Ioanna Tsakalidou,Hamish Nicholson,Kyoungmin Kim,Anastasia Ailamaki*

Main category: cs.DB

TL;DR: QVCache是首个后端无关的查询级缓存系统，用于近似最近邻搜索，通过语义感知缓存而非精确匹配，在有限内存下实现高召回率。


<details>
  <summary>Details</summary>
Motivation: 向量数据库已成为现代信息检索的基石，但将近似最近邻搜索扩展到高召回率同时满足严格延迟SLO仍受内存容量和I/O带宽限制。基于磁盘的系统在高精度下延迟严重，全内存方案在十亿级规模下内存成本过高，而向量搜索缺乏通用的查询级缓存层。

Method: QVCache利用语义查询重复性，执行相似性感知缓存而非精确匹配查找。它使用在线学习算法动态学习区域特定的距离阈值，在保持召回率的同时限制查找延迟和内存使用，独立于数据集大小。作为现有向量数据库的即插即用层运行。

Result: QVCache保持兆字节级内存占用，实现亚毫秒级缓存命中延迟，与现有ANN系统集成时，端到端查询延迟降低40-1000倍。对于具有时间语义局部性的工作负载，显著降低延迟同时保持与底层ANN后端相当的召回率。

Conclusion: QVCache作为向量搜索中缺失但必要的缓存层，为可扩展向量搜索提供了后端无关的查询级缓存解决方案，在有限内存下实现高召回率和低延迟。

Abstract: Vector databases have become a cornerstone of modern information retrieval, powering applications in recommendation, search, and retrieval-augmented generation (RAG) pipelines. However, scaling approximate nearest neighbor (ANN) search to high recall under strict latency SLOs remains fundamentally constrained by memory capacity and I/O bandwidth. Disk-based vector search systems suffer severe latency degradation at high accuracy, while fully in-memory solutions incur prohibitive memory costs at billion-scale. Despite the central role of caching in traditional databases, vector search lacks a general query-level caching layer capable of amortizing repeated query work.
  We present QVCache, the first backend-agnostic, query-level caching system for ANN search with bounded memory footprint. QVCache exploits semantic query repetition by performing similarity-aware caching rather than exact-match lookup. It dynamically learns region-specific distance thresholds using an online learning algorithm, enabling recall-preserving cache hits while bounding lookup latency and memory usage independently of dataset size. QVCache operates as a drop-in layer for existing vector databases. It maintains a megabyte-scale memory footprint and achieves sub-millisecond cache-hit latency, reducing end-to-end query latency by up to 40-1000x when integrated with existing ANN systems. For workloads exhibiting temporal-semantic locality, QVCache substantially reduces latency while preserving recall comparable to the underlying ANN backend, establishing it as a missing but essential caching layer for scalable vector search.

</details>
