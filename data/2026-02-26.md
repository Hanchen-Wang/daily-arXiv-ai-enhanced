<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 31]
- [cs.CL](#cs.CL) [Total: 26]
- [cs.DB](#cs.DB) [Total: 6]
- [cs.AI](#cs.AI) [Total: 11]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [StoryTailor:A Zero-Shot Pipeline for Action-Rich Multi-Subject Visual Narratives](https://arxiv.org/abs/2602.21273)
*Jinghao Hu,Yuhe Zhang,GuoHua Geng,Kang Li,Han Zhang*

Main category: cs.CV

TL;DR: StoryTailor是一个零样本多帧视觉叙事生成系统，能在单张RTX 4090上生成时间连贯、身份保持的图像序列，通过三个协同模块解决动作忠实性、身份保真度和背景连续性的三重挑战。


<details>
  <summary>Details</summary>
Motivation: 生成多帧、动作丰富的视觉叙事面临三重挑战：动作文本忠实性、主体身份保真度和跨帧背景连续性。现有方法需要微调或无法同时满足这些要求。

Method: 提出StoryTailor零样本管道，包含三个协同模块：1) 高斯中心注意力动态聚焦主体核心并缓解边界框重叠；2) 动作增强奇异值重加权放大文本嵌入空间中的动作相关方向；3) 选择性遗忘缓存保留可转移背景线索、遗忘非必要历史，并选择性提取保留线索以建立跨场景语义联系。

Result: 实验显示CLIP-T指标提升10-15%，DreamSim低于强基线，CLIP-I保持在视觉可接受的竞争范围内。在24GB GPU上，推理速度比FluxKontext更快。定性评估显示系统能生成富有表现力的交互和演化稳定的场景。

Conclusion: StoryTailor在单GPU上实现了零样本多帧视觉叙事生成，通过三个创新模块有效解决了动作忠实性、身份保真度和背景连续性的核心挑战，在定量和定性评估中均表现优异。

Abstract: Generating multi-frame, action-rich visual narratives without fine-tuning faces a threefold tension: action text faithfulness, subject identity fidelity, and cross-frame background continuity. We propose StoryTailor, a zero-shot pipeline that runs on a single RTX 4090 (24 GB) and produces temporally coherent, identity-preserving image sequences from a long narrative prompt, per-subject references, and grounding boxes. Three synergistic modules drive the system: Gaussian-Centered Attention (GCA) to dynamically focus on each subject core and ease grounding-box overlaps; Action-Boost Singular Value Reweighting (AB-SVR) to amplify action-related directions in the text embedding space; and Selective Forgetting Cache (SFC) that retains transferable background cues, forgets nonessential history, and selectively surfaces retained cues to build cross-scene semantic ties. Compared with baseline methods, experiments show that CLIP-T improves by up to 10-15%, with DreamSim lower than strong baselines, while CLIP-I stays in a visually acceptable, competitive range. With matched resolution and steps on a 24 GB GPU, inference is faster than FluxKontext. Qualitatively, StoryTailor delivers expressive interactions and evolving yet stable scenes.

</details>


### [2] [HorizonForge: Driving Scene Editing with Any Trajectories and Any Vehicles](https://arxiv.org/abs/2602.21333)
*Yifan Wang,Francesco Pittaluga,Zaid Tasneem,Chenyu You,Manmohan Chandraker,Ziyu Jiang*

Main category: cs.CV

TL;DR: HorizonForge是一个统一的框架，通过高斯溅射和网格重建可编辑的驾驶场景，结合噪声感知视频扩散实现时空一致的渲染，在单次前向传递中生成多样化场景变体，无需逐轨迹优化。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以同时实现照片级真实感和精确控制的驾驶场景生成，这限制了自动驾驶仿真的真实性和可扩展性。

Method: 1) 将场景重建为可编辑的高斯溅射和网格表示；2) 支持细粒度3D操作和语言驱动的车辆插入；3) 通过噪声感知视频扩散过程渲染编辑，确保时空一致性；4) 提出HorizonSuite基准测试，涵盖自车和智能体级编辑任务。

Result: 高斯-网格表示比替代3D表示提供显著更高的保真度；视频扩散的时间先验对连贯合成至关重要；相比次优方法获得83.4%的用户偏好增益和25.19%的FID改进。

Conclusion: HorizonForge建立了一个简单而强大的范式，用于照片级真实感、可控的驾驶仿真，在用户偏好和生成质量方面显著优于现有方法。

Abstract: Controllable driving scene generation is critical for realistic and scalable autonomous driving simulation, yet existing approaches struggle to jointly achieve photorealism and precise control. We introduce HorizonForge, a unified framework that reconstructs scenes as editable Gaussian Splats and Meshes, enabling fine-grained 3D manipulation and language-driven vehicle insertion. Edits are rendered through a noise-aware video diffusion process that enforces spatial and temporal consistency, producing diverse scene variations in a single feed-forward pass without per-trajectory optimization. To standardize evaluation, we further propose HorizonSuite, a comprehensive benchmark spanning ego- and agent-level editing tasks such as trajectory modifications and object manipulation. Extensive experiments show that Gaussian-Mesh representation delivers substantially higher fidelity than alternative 3D representations, and that temporal priors from video diffusion are essential for coherent synthesis. Combining these findings, HorizonForge establishes a simple yet powerful paradigm for photorealistic, controllable driving simulation, achieving an 83.4% user-preference gain and a 25.19% FID improvement over the second best state-of-the-art method. Project page: https://horizonforge.github.io/ .

</details>


### [3] [Scaling View Synthesis Transformers](https://arxiv.org/abs/2602.21341)
*Evan Kim,Hyunwoo Ryu,Thomas W. Mitchel,Vincent Sitzmann*

Main category: cs.CV

TL;DR: 本文系统研究了视图合成Transformer的缩放规律，提出了可扩展视图合成模型(SVSM)，证明编码器-解码器架构在计算优化方面可与仅解码器模型媲美，并在多个基准上以更少计算量达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 几何无关的视图合成Transformer在NVS中表现出色，但其计算缩放规律尚不明确。需要系统研究缩放规律，为训练计算最优的NVS模型提供设计原则。

Method: 系统研究视图合成Transformer的缩放规律，提出可扩展视图合成模型(SVSM)的编码器-解码器架构。通过纠正先前研究中次优的架构选择和不等训练计算预算比较，证明编码器-解码器架构的计算最优性。

Result: SVSM在不同计算水平上都能有效缩放，与仅解码器模型相当，实现了更优的性能-计算帕累托前沿，在真实世界NVS基准上以显著减少的训练计算量超越先前SOTA。

Conclusion: 编码器-解码器架构可以是计算最优的，先前负面结果源于次优架构选择和不公平比较。SVSM为训练计算最优的NVS模型提供了有效方案。

Abstract: Geometry-free view synthesis transformers have recently achieved state-of-the-art performance in Novel View Synthesis (NVS), outperforming traditional approaches that rely on explicit geometry modeling. Yet the factors governing their scaling with compute remain unclear. We present a systematic study of scaling laws for view synthesis transformers and derive design principles for training compute-optimal NVS models. Contrary to prior findings, we show that encoder-decoder architectures can be compute-optimal; we trace earlier negative results to suboptimal architectural choices and comparisons across unequal training compute budgets. Across several compute levels, we demonstrate that our encoder-decoder architecture, which we call the Scalable View Synthesis Model (SVSM), scales as effectively as decoder-only models, achieves a superior performance-compute Pareto frontier, and surpasses the previous state-of-the-art on real-world NVS benchmarks with substantially reduced training compute.

</details>


### [4] [Towards Controllable Video Synthesis of Routine and Rare OR Events](https://arxiv.org/abs/2602.21365)
*Dominik Schneider,Lalithkumar Seenivasan,Sampath Rapuri,Vishalroshan Anil,Aiza Maksutova,Yiqing Shen,Jan Emily Mangulabnan,Hao Ding,Jose L. Porras,Masaru Ishii,Mathias Unberath*

Main category: cs.CV

TL;DR: 提出手术室视频扩散框架，通过几何抽象和控制合成生成罕见安全事件视频，并创建合成数据集训练AI模型检测无菌区违规事件


<details>
  <summary>Details</summary>
Motivation: 手术室工作流程数据收集面临操作和伦理挑战，特别是罕见、安全关键或非典型事件的数据稀缺，这阻碍了环境智能系统的发展

Method: 开发手术室视频扩散框架，包含几何抽象模块、条件模块和微调扩散模型，将手术室场景转换为几何表示，控制合成过程，生成真实手术室事件视频

Result: 在常规手术室事件合成中优于基线方法，FVD/LPIPS更低，SSIM/PSNR更高；合成数据训练的AI模型在检测安全关键事件中达到70.13%召回率

Conclusion: 该框架能够从几何抽象表示中控制合成常规和罕见手术室事件，展示了生成安全关键场景的能力，并支持环境智能模型开发

Abstract: Purpose: Curating large-scale datasets of operating room (OR) workflow, encompassing rare, safety-critical, or atypical events, remains operationally and ethically challenging. This data bottleneck complicates the development of ambient intelligence for detecting, understanding, and mitigating rare or safety-critical events in the OR.
  Methods: This work presents an OR video diffusion framework that enables controlled synthesis of rare and safety-critical events. The framework integrates a geometric abstraction module, a conditioning module, and a fine-tuned diffusion model to first transform OR scenes into abstract geometric representations, then condition the synthesis process, and finally generate realistic OR event videos. Using this framework, we also curate a synthetic dataset to train and validate AI models for detecting near-misses of sterile-field violations.
  Results: In synthesizing routine OR events, our method outperforms off-the-shelf video diffusion baselines, achieving lower FVD/LPIPS and higher SSIM/PSNR in both in- and out-of-domain datasets. Through qualitative results, we illustrate its ability for controlled video synthesis of counterfactual events. An AI model trained and validated on the generated synthetic data achieved a RECALL of 70.13% in detecting near safety-critical events. Finally, we conduct an ablation study to quantify performance gains from key design choices.
  Conclusion: Our solution enables controlled synthesis of routine and rare OR events from abstract geometric representations. Beyond demonstrating its capability to generate rare and safety-critical scenarios, we show its potential to support the development of ambient intelligence models.

</details>


### [5] [Momentum Memory for Knowledge Distillation in Computational Pathology](https://arxiv.org/abs/2602.21395)
*Yongxin Guo,Hao Lu,Onur C. Koyun,Zhengjie Zhu,Muhammet Fatih Demir,Metin Nafi Gurcan*

Main category: cs.CV

TL;DR: MoMKD提出了一种基于动量记忆的知识蒸馏框架，通过跨批次聚合基因组和组织病理学信息来解决多模态学习中配对数据不足的问题，在仅使用组织学数据推理时实现更好的性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 多模态学习结合基因组学和组织病理学在癌症诊断中显示出巨大潜力，但临床转化受到配对组织学-基因组数据有限的阻碍。现有知识蒸馏方法依赖批次内对齐，由于批次内比较有限导致不稳定并降低性能。

Method: 提出动量记忆知识蒸馏(MoMKD)框架，使用动量更新的记忆跨批次聚合基因组和组织病理学信息，扩大每个小批量的监督上下文。同时解耦基因组和组织学分支的梯度，防止基因组信号主导组织学特征学习，消除推理时的模态差距问题。

Result: 在TCGA-BRCA基准测试(HER2、PR和ODX分类任务)和独立内部测试数据集上的实验表明，MoMKD持续优于最先进的多实例学习和多模态知识蒸馏基线，在仅使用组织学推理时提供强大的性能和泛化能力。

Conclusion: MoMKD为计算病理学建立了一个稳健且可泛化的知识蒸馏范式，通过跨批次记忆聚合和解耦梯度训练，有效解决了多模态学习中的数据配对限制问题。

Abstract: Multimodal learning that integrates genomics and histopathology has shown strong potential in cancer diagnosis, yet its clinical translation is hindered by the limited availability of paired histology-genomics data. Knowledge distillation (KD) offers a practical solution by transferring genomic supervision into histopathology models, enabling accurate inference using histology alone. However, existing KD methods rely on batch-local alignment, which introduces instability due to limited within-batch comparisons and ultimately degrades performance.
  To address these limitations, we propose Momentum Memory Knowledge Distillation (MoMKD), a cross-modal distillation framework driven by a momentum-updated memory. This memory aggregates genomic and histopathology information across batches, effectively enlarging the supervisory context available to each mini-batch. Furthermore, we decouple the gradients of the genomics and histology branches, preventing genomic signals from dominating histology feature learning during training and eliminating the modality-gap issue at inference time.
  Extensive experiments on the TCGA-BRCA benchmark (HER2, PR, and ODX classification tasks) and an independent in-house testing dataset demonstrate that MoMKD consistently outperforms state-of-the-art MIL and multimodal KD baselines, delivering strong performance and generalization under histology-only inference. Overall, MoMKD establishes a robust and generalizable knowledge distillation paradigm for computational pathology.

</details>


### [6] [MMLoP: Multi-Modal Low-Rank Prompting for Efficient Vision-Language Adaptation](https://arxiv.org/abs/2602.21397)
*Sajjad Ghiasvand,Haniyeh Ehsani Oskouie,Mahnoosh Alizadeh,Ramtin Pedarsani*

Main category: cs.CV

TL;DR: MMLoP提出了一种低秩多模态提示学习方法，仅用11.5K可训练参数实现深度多模态提示，在保持参数效率的同时达到与最先进方法相当的准确率。


<details>
  <summary>Details</summary>
Motivation: 当前的多模态提示学习方法虽然性能显著提升，但需要数百万参数，放弃了提示调优的参数效率优势。需要一种既能实现深度多模态提示又保持参数效率的方法。

Method: 采用低秩分解参数化视觉和文本提示，引入三个组件：自调节一致性损失、均匀漂移校正和共享上投影，以增强性能并保持跨模态对齐。

Result: 在三个基准测试和11个数据集上的实验表明，MMLoP实现了优越的准确率-效率权衡，超越了许多参数量级更大的方法，基础到新类泛化的调和平均达到79.70%。

Conclusion: MMLoP通过低秩分解和三个创新组件，成功实现了参数高效的深度多模态提示学习，在保持参数效率的同时达到了与最先进方法竞争的性能。

Abstract: Prompt learning has become a dominant paradigm for adapting vision-language models (VLMs) such as CLIP to downstream tasks without modifying pretrained weights. While extending prompts to both vision and text encoders across multiple transformer layers significantly boosts performance, it dramatically increases the number of trainable parameters, with state-of-the-art methods requiring millions of parameters and abandoning the parameter efficiency that makes prompt tuning attractive. In this work, we propose \textbf{MMLoP} (\textbf{M}ulti-\textbf{M}odal \textbf{Lo}w-Rank \textbf{P}rompting), a framework that achieves deep multi-modal prompting with only \textbf{11.5K trainable parameters}, comparable to early text-only methods like CoOp. MMLoP parameterizes vision and text prompts at each transformer layer through a low-rank factorization, which serves as an implicit regularizer against overfitting on few-shot training data. To further close the accuracy gap with state-of-the-art methods, we introduce three complementary components: a self-regulating consistency loss that anchors prompted representations to frozen zero-shot CLIP features at both the feature and logit levels, a uniform drift correction that removes the global embedding shift induced by prompt tuning to preserve class-discriminative structure, and a shared up-projection that couples vision and text prompts through a common low-rank factor to enforce cross-modal alignment. Extensive experiments across three benchmarks and 11 diverse datasets demonstrate that MMLoP achieves a highly favorable accuracy-efficiency tradeoff, outperforming the majority of existing methods including those with orders of magnitude more parameters, while achieving a harmonic mean of 79.70\% on base-to-novel generalization.

</details>


### [7] [FlowFixer: Towards Detail-Preserving Subject-Driven Generation](https://arxiv.org/abs/2602.21402)
*Jinyoung Jun,Won-Dong Jang,Wenbin Ouyang,Raghudeep Gadde,Jungbeom Lee*

Main category: cs.CV

TL;DR: FlowFixer是一个用于主题驱动生成的细化框架，通过图像到图像转换恢复生成过程中因尺度视角变化而丢失的细节，使用自监督训练数据和关键点匹配指标提升保真度。


<details>
  <summary>Details</summary>
Motivation: 主题驱动生成（SDG）在生成过程中常因尺度和视角变化而丢失细节，现有方法依赖语言提示存在模糊性，需要更精确的图像到图像细化方法。

Method: 提出直接图像到图像转换框架，避免语言提示模糊性；引入一步去噪方案生成自监督训练数据，自动去除高频细节但保留全局结构；提出基于关键点匹配的评估指标，超越CLIP/DINO的语义相似度评估。

Result: FlowFixer在定性和定量评估中均优于最先进的SDG方法，为高保真主题驱动生成设立了新基准。

Conclusion: FlowFixer通过图像到图像转换和自监督训练有效解决了SDG中的细节丢失问题，关键点匹配指标能更准确评估细节保真度，为高质量主题驱动生成提供了有效解决方案。

Abstract: We present FlowFixer, a refinement framework for subject-driven generation (SDG) that restores fine details lost during generation caused by changes in scale and perspective of a subject. FlowFixer proposes direct image-to-image translation from visual references, avoiding ambiguities in language prompts. To enable image-to-image training, we introduce a one-step denoising scheme to generate self-supervised training data, which automatically removes high-frequency details while preserving global structure, effectively simulating real-world SDG errors. We further propose a keypoint matching-based metric to properly assess fidelity in details beyond semantic similarities usually measured by CLIP or DINO. Experimental results demonstrate that FlowFixer outperforms state-of-the-art SDG methods in both qualitative and quantitative evaluations, setting a new benchmark for high-fidelity subject-driven generation.

</details>


### [8] [Exploring Vision-Language Models for Open-Vocabulary Zero-Shot Action Segmentation](https://arxiv.org/abs/2602.21406)
*Asim Unmesh,Kaki Ramesh,Mayank Patel,Rahul Jain,Karthik Ramani*

Main category: cs.CV

TL;DR: 提出首个开放词汇零样本时序动作分割框架OVTAS，利用视觉语言模型的零样本能力，无需任务特定监督即可实现视频动作分割


<details>
  <summary>Details</summary>
Motivation: 传统时序动作分割方法受限于封闭词汇和固定标签集，无法应对现实世界中无限的活动类型和分解方式。收集全面数据集不可行，需要探索开放词汇的零样本方法

Method: 提出无需训练的流水线：1) 帧-动作嵌入相似度匹配视频帧与候选动作标签；2) 相似度矩阵时序分割强制时序一致性。对14种视觉语言模型进行系统研究

Result: 在标准基准测试中，OVTAS无需任务特定监督即取得强劲结果，验证了视觉语言模型在结构化时序理解方面的潜力

Conclusion: 首次探索开放词汇零样本时序动作分割问题，展示了视觉语言模型在该领域的适用性，为开放词汇动作理解提供了新方向

Abstract: Temporal Action Segmentation (TAS) requires dividing videos into action segments, yet the vast space of activities and alternative breakdowns makes collecting comprehensive datasets infeasible. Existing methods remain limited to closed vocabularies and fixed label sets. In this work, we explore the largely unexplored problem of Open-Vocabulary Zero-Shot Temporal Action Segmentation (OVTAS) by leveraging the strong zero-shot capabilities of Vision-Language Models (VLMs). We introduce a training-free pipeline that follows a segmentation-by-classification design: Frame-Action Embedding Similarity (FAES) matches video frames to candidate action labels, and Similarity-Matrix Temporal Segmentation (SMTS) enforces temporal consistency. Beyond proposing OVTAS, we present a systematic study across 14 diverse VLMs, providing the first broad analysis of their suitability for open-vocabulary action segmentation. Experiments on standard benchmarks show that OVTAS achieves strong results without task-specific supervision, underscoring the potential of VLMs for structured temporal understanding.

</details>


### [9] [WildSVG: Towards Reliable SVG Generation Under Real-Word Conditions](https://arxiv.org/abs/2602.21416)
*Marco Terral,Haotian Zhang,Tianyang Zhang,Meng Lin,Xiaoqing Xie,Haoran Dai,Darsh Kaushik,Pai Peng,Nicklas Scharpff,David Vazquez,Joan Rodriguez*

Main category: cs.CV

TL;DR: 该论文提出了SVG提取任务，创建了WildSVG基准测试，包含真实和合成数据集，评估了现有多模态模型在真实场景中的表现，发现当前方法仍有不足但迭代优化方法有前景。


<details>
  <summary>Details</summary>
Motivation: 现有多模态模型在从干净渲染或文本描述生成SVG方面表现良好，但在真实场景中面临噪声、杂乱和领域偏移的挑战。主要问题是缺乏合适的基准测试来评估SVG提取能力。

Method: 提出了WildSVG基准测试，包含两个互补数据集：1) Natural WildSVG - 从包含公司logo的真实图像及其SVG标注构建；2) Synthetic WildSVG - 将复杂SVG渲染混合到真实场景中以模拟困难条件。

Result: 评估了最先进的多模态模型，发现当前方法在真实场景中的SVG提取可靠性远未达到要求。但迭代优化方法显示出有前景的发展方向，模型能力正在稳步提升。

Conclusion: 该研究为SVG提取任务提供了首个系统性基准测试基础，揭示了当前方法的局限性，同时指出迭代优化方法是未来发展的有希望方向。

Abstract: We introduce the task of SVG extraction, which consists in translating specific visual inputs from an image into scalable vector graphics. Existing multimodal models achieve strong results when generating SVGs from clean renderings or textual descriptions, but they fall short in real-world scenarios where natural images introduce noise, clutter, and domain shifts. A central challenge in this direction is the lack of suitable benchmarks. To address this need, we introduce the WildSVG Benchmark, formed by two complementary datasets: Natural WildSVG, built from real images containing company logos paired with their SVG annotations, and Synthetic WildSVG, which blends complex SVG renderings into real scenes to simulate difficult conditions. Together, these resources provide the first foundation for systematic benchmarking SVG extraction. We benchmark state-of-the-art multimodal models and find that current approaches perform well below what is needed for reliable SVG extraction in real scenarios. Nonetheless, iterative refinement methods point to a promising path forward, and model capabilities are steadily improving

</details>


### [10] [ECHOSAT: Estimating Canopy Height Over Space And Time](https://arxiv.org/abs/2602.21421)
*Jan Pauls,Karsten Schrödter,Sven Ligensa,Martin Schwartz,Berkant Turan,Max Zimmer,Sassan Saatchi,Sebastian Pokutta,Philippe Ciais,Fabian Gieseke*

Main category: cs.CV

TL;DR: 提出ECHOSAT，首个全球10米分辨率、时间一致的多年度树高地图，能捕捉森林动态变化，用于碳监测和干扰评估


<details>
  <summary>Details</summary>
Motivation: 现有全球树高地图仅为静态快照，无法捕捉时间动态，而这对准确碳核算至关重要

Method: 使用多传感器卫星数据训练专用视觉Transformer模型，进行像素级时间回归，通过自监督生长损失正则化预测以符合自然树木生长曲线

Result: 模型在单年预测中提高了最先进精度，提供了首个能准确量化树木生长和干扰的全球尺度高度地图

Conclusion: ECHOSAT将推动全球碳监测和干扰评估工作，地图可通过GitHub访问

Abstract: Forest monitoring is critical for climate change mitigation. However, existing global tree height maps provide only static snapshots and do not capture temporal forest dynamics, which are essential for accurate carbon accounting. We introduce ECHOSAT, a global and temporally consistent tree height map at 10 m resolution spanning multiple years. To this end, we resort to multi-sensor satellite data to train a specialized vision transformer model, which performs pixel-level temporal regression. A self-supervised growth loss regularizes the predictions to follow growth curves that are in line with natural tree development, including gradual height increases over time, but also abrupt declines due to forest loss events such as fires. Our experimental evaluation shows that our model improves state-of-the-art accuracies in the context of single-year predictions. We also provide the first global-scale height map that accurately quantifies tree growth and disturbances over time. We expect ECHOSAT to advance global efforts in carbon monitoring and disturbance assessment. The maps can be accessed at https://github.com/ai4forest/echosat.

</details>


### [11] [Automating Timed Up and Go Phase Segmentation and Gait Analysis via the tugturn Markerless 3D Pipeline](https://arxiv.org/abs/2602.21425)
*Abel Gonçalves Chinaglia,Guilherme Manna Cesar,Paulo Roberto Pereira Santiago*

Main category: cs.CV

TL;DR: tugturn.py是一个用于3D无标记Timed Up and Go测试处理的Python工作流，提供相位分割、步态事件检测、时空指标、节段间协调和动态稳定性分析。


<details>
  <summary>Details</summary>
Motivation: 虽然仪器化Timed Up and Go分析可以支持临床和研究决策，但目前缺乏稳健且可重复的无标记处理流程。

Method: 开发基于Python的工作流，使用空间阈值分割试验阶段，应用相对距离策略检测步态事件，提供向量编码和外推质心指标，通过TOML文件配置并生成可重复的输出。

Result: 创建了tugturn.py软件，能够处理3D无标记TUG数据，生成HTML报告、CSV表格和质量保证可视化输出，提供完整的可运行示例。

Conclusion: tugturn作为专注于无标记生物力学TUG分析的软件贡献，提供了可重复的工作流程和全面的分析功能。

Abstract: Instrumented Timed Up and Go (TUG) analysis can support clinical and research decision-making, but robust and reproducible markerless pipelines are still limited. We present \textit{tugturn.py}, a Python-based workflow for 3D markerless TUG processing that combines phase segmentation, gait-event detection, spatiotemporal metrics, intersegmental coordination, and dynamic stability analysis. The pipeline uses spatial thresholds to segment each trial into stand, first gait, turning, second gait, and sit phases, and applies a relative-distance strategy to detect heel-strike and toe-off events within valid gait windows. In addition to conventional kinematics, \textit{tugturn} provides Vector Coding outputs and Extrapolated Center of Mass (XCoM)-based metrics. The software is configured through TOML files and produces reproducible artifacts, including HTML reports, CSV tables, and quality-assurance visual outputs. A complete runnable example is provided with test data and command-line instructions. This manuscript describes the implementation, outputs, and reproducibility workflow of \textit{tugturn} as a focused software contribution for markerless biomechanical TUG analysis.

</details>


### [12] [PSF-Med: Measuring and Explaining Paraphrase Sensitivity in Medical Vision Language Models](https://arxiv.org/abs/2602.21428)
*Binesh Sadanandan,Vahid Behzadan*

Main category: cs.CV

TL;DR: 医疗视觉语言模型在临床医生重述相同问题时可能改变答案，存在部署风险。研究引入PSF-Med基准测试，发现6个医疗VLM的翻转率从8%到58%，低翻转率不一定代表视觉基础，有些模型即使移除图像也能保持一致，表明它们依赖语言先验。


<details>
  <summary>Details</summary>
Motivation: 医疗视觉语言模型在部署中存在风险，当临床医生用不同方式表达相同问题时，模型可能给出不一致的答案。这种"重述敏感性失败"可能影响临床决策的可靠性，需要系统评估和解决。

Method: 1) 创建PSF-Med基准测试，包含19,748个胸部X光问题和约92,000个意义保持的重述；2) 测量6个医疗VLM的yes/no翻转率；3) 使用文本基线测试模型是否依赖语言先验而非视觉信息；4) 对MedGemma 4B应用稀疏自编码器分析翻转机制；5) 通过因果修补和特征钳制减少翻转率。

Result: 1) 医疗VLM的翻转率范围为8%-58%；2) 低翻转率不一定表示视觉基础，文本基线显示有些模型即使没有图像也能保持一致；3) 在MedGemma 4B中发现第17层稀疏特征与提示框架相关并预测决策边界变化；4) 移除该特征贡献可恢复45%的logit边界，完全逆转15%的翻转；5) 推理时钳制该特征可将翻转率相对降低31%，仅损失1.3个百分点的准确率。

Conclusion: 仅凭翻转率不足以评估模型鲁棒性，需要同时测试重述稳定性和图像依赖性。通过识别和干预特定稀疏特征，可以有效减少医疗VLM的答案不一致性，同时保持准确性，为临床部署提供更可靠的模型。

Abstract: Medical Vision Language Models (VLMs) can change their answers when clinicians rephrase the same question, which raises deployment risks. We introduce Paraphrase Sensitivity Failure (PSF)-Med, a benchmark of 19,748 chest Xray questions paired with about 92,000 meaningpreserving paraphrases across MIMIC-CXR and PadChest. Across six medical VLMs, we measure yes/no flips for the same image and find flip rates from 8% to 58%. However, low flip rate does not imply visual grounding: text-only baselines show that some models stay consistent even when the image is removed, suggesting they rely on language priors. To study mechanisms in one model, we apply GemmaScope 2 Sparse Autoencoders (SAEs) to MedGemma 4B and analyze FlipBank, a curated set of 158 flip cases. We identify a sparse feature at layer 17 that correlates with prompt framing and predicts decision margin shifts. In causal patching, removing this feature's contribution recovers 45% of the yesminus-no logit margin on average and fully reverses 15% of flips. Acting on this finding, we show that clamping the identified feature at inference reduces flip rates by 31% relative with only a 1.3 percentage-point accuracy cost, while also decreasing text-prior reliance. These results suggest that flip rate alone is not enough; robustness evaluations should test both paraphrase stability and image reliance.

</details>


### [13] [Synergizing Understanding and Generation with Interleaved Analyzing-Drafting Thinking](https://arxiv.org/abs/2602.21435)
*Shengqiong Wu,Bobo Li,Xinkai Wang,Xiangtai Li,Lei Cui,Furu Wei,Shuicheng Yan,Hao Fei,Tat-seng Chua*

Main category: cs.CV

TL;DR: 提出AD-Loop框架，通过分析-草稿交替循环实现视觉语言模型中理解与生成能力的真正协同，而非并行处理


<details>
  <summary>Details</summary>
Motivation: 现有统一视觉语言模型主要关注架构统一，但忽视了理解与生成能力在任务解决过程中的显式交互，导致两者被当作平行技能而非协同过程

Method: 引入AD-Loop问题解决循环，动态交替分析操作和草稿操作，交织文本思维与视觉思维；采用两阶段训练策略：监督学习初始化交替机制，强化学习促进自适应控制

Result: AD-Loop在标准理解与生成基准测试中持续提升性能，对各种UVLM架构具有强可迁移性；视觉分析验证了隐式视觉思维的有效性

Conclusion: AD-Loop是协同理解与生成的原理性且广泛适用的策略，为多模态学习提供了新的思考范式

Abstract: Unified Vision-Language Models (UVLMs) aim to advance multimodal learning by supporting both understanding and generation within a single framework. However, existing approaches largely focus on architectural unification while overlooking the need for explicit interaction between the two capabilities during task solving. As a result, current models treat understanding and generation as parallel skills rather than synergistic processes. To achieve real synergy, we introduce the interleaved Analyzing-Drafting problem-solving loop (AD-Loop), a new think paradigm that dynamically alternates between analytic and drafting operations. By interleaving textual thoughts with visual thoughts, AD-Loop enables models to iteratively refine both comprehension and outputs, fostering genuine synergy. To train this mechanism, we design a two-stage strategy: supervised learning on interleaved thought data to initialize alternation, followed by reinforcement learning to promote adaptive and autonomous control. Extensive experiments demonstrate that AD-Loop consistently improves performance across standard benchmarks for both understanding and generation, with strong transferability to various UVLMs architectures. Visual analyses further validate the effectiveness of implicit visual thoughts. These results highlight AD-Loop as a principled and broadly applicable strategy for synergizing comprehension and creation. The project page is at https://sqwu.top/AD-Loop.

</details>


### [14] [Adversarial Robustness of Deep Learning-Based Thyroid Nodule Segmentation in Ultrasound](https://arxiv.org/abs/2602.21452)
*Nicholas Dietrich,David McShannon*

Main category: cs.CV

TL;DR: 评估甲状腺结节超声分割模型的对抗攻击鲁棒性，开发了两种黑盒攻击方法（SSAA和FDUA）并测试了三种推理时防御策略，发现空间域攻击可部分缓解而频域攻击难以防御。


<details>
  <summary>Details</summary>
Motivation: 深度学习分割模型在临床影像工作流中应用日益广泛，但其对抗扰动的鲁棒性尚未充分表征，特别是在超声图像领域。本研究旨在评估甲状腺结节B超分割的对抗攻击和推理时防御策略。

Method: 开发了两种黑盒对抗攻击：1) SSAA（结构化斑点放大攻击），注入边界定向噪声；2) FDUA（频域超声攻击），在傅里叶域应用带通滤波相位扰动。评估了三种推理时防御：随机预处理与测试时增强、确定性输入去噪、随机集成推理与一致性聚合。实验使用U-Net模型在192个甲状腺结节的超声序列上进行。

Result: 基线模型在未扰动图像上平均DSC为0.76。SSAA使DSC降低0.29（视觉相似度高，SSIM=0.94），FDUA使DSC降低0.11（视觉保真度较低，SSIM=0.82）。针对SSAA，所有防御均显著改善DSC，确定性去噪恢复最大（+0.10），其次是随机预处理（+0.09）和随机集成推理（+0.08）。针对FDUA，无防御策略取得统计学显著改善。

Conclusion: 超声分割中的空间域对抗扰动可通过输入预处理部分缓解，而频域扰动则无法被现有防御策略有效缓解，这凸显了对抗鲁棒性评估中的模态特异性挑战。

Abstract: Introduction: Deep learning-based segmentation models are increasingly integrated into clinical imaging workflows, yet their robustness to adversarial perturbations remains incompletely characterized, particularly for ultrasound images. We evaluated adversarial attacks and inference-time defenses for thyroid nodule segmentation in B-mode ultrasound. Methods: Two black-box adversarial attacks were developed: (1) Structured Speckle Amplification Attack (SSAA), which injects boundary-targeted noise, and (2) Frequency-Domain Ultrasound Attack (FDUA), which applies bandpass-filtered phase perturbations in the Fourier domain. Three inference-time mitigations were evaluated on adversarial images: randomized preprocessing with test-time augmentation, deterministic input denoising, and stochastic ensemble inference with consistency-aware aggregation. Experiments were conducted on a U-Net segmentation model trained on cine-clips from a database of 192 thyroid nodules. Results: The baseline model achieved a mean Dice similarity coefficient (DSC) of 0.76 (SD 0.20) on unperturbed images. SSAA reduced DSC by 0.29 (SD 0.20) while maintaining high visual similarity (SSIM = 0.94). FDUA resulted in a smaller DSC reduction of 0.11 (SD 0.09) with lower visual fidelity (SSIM = 0.82). Against SSAA, all three defenses significantly improved DSC after correction, with deterministic denoising showing the largest recovery (+0.10, p < 0.001), followed by randomized preprocessing (+0.09, p < 0.001), and stochastic ensemble inference (+0.08, p = 0.002). No defense achieved statistically significant improvement against FDUA. Conclusion: Spatial-domain adversarial perturbations in ultrasound segmentation showed partial mitigation with input preprocessing, whereas frequency-domain perturbations were not mitigated by the defenses, highlighting modality-specific challenges in adversarial robustness evaluation.

</details>


### [15] [Automatic Map Density Selection for Locally-Performant Visual Place Recognition](https://arxiv.org/abs/2602.21473)
*Somayeh Hussaini,Tobias Fischer,Michael Milford*

Main category: cs.CV

TL;DR: 提出动态VPR建图方法，通过多参考轨迹自动选择合适地图密度，满足用户定义的局部召回率要求和覆盖比例


<details>
  <summary>Details</summary>
Motivation: 现有VPR系统主要关注全局平均性能，缺乏对局部性能的保证机制。地图密度是控制局部VPR性能的关键因素，但现有工作通常使用固定密度的基准数据集，无法满足用户对特定环境区域性能的定制化要求。

Method: 提出动态VPR建图方法：1）使用目标环境的多条参考轨迹；2）在不同地图密度下评估匹配模式；3）建模预测满足性能目标所需密度；4）定义Recall Achievement Rate (RAR)作为性能覆盖比例指标；5）自动选择地图密度以满足用户指定的局部Recall@1和RAR要求。

Result: 在Nordland和Oxford RobotCar基准测试中，系统能持续达到或超过指定的局部召回率水平，覆盖至少用户指定的环境比例。与基线方法相比，能可靠选择正确的地图密度操作点，避免不必要的过度密集化。全局Recall@1被发现是RAR指标的较差预测因子。

Conclusion: 提出的动态VPR建图方法能够有效保证局部性能要求，通过自动选择地图密度满足用户定义的Recall@1和RAR目标。该方法为VPR系统从实验室到长期部署提供了重要机制，使系统能够针对特定环境区域保证性能，而不仅仅是全局平均性能。

Abstract: A key challenge in translating Visual Place Recognition (VPR) from the lab to long-term deployment is ensuring a priori that a system can meet user-specified performance requirements across different parts of an environment, rather than just on average globally. A critical mechanism for controlling local VPR performance is the density of the reference mapping database, yet this factor is largely neglected in existing work, where benchmark datasets with fixed, engineering-driven (sensors, storage, GPS frequency) sampling densities are typically used. In this paper, we propose a dynamic VPR mapping approach that uses pairs of reference traverses from the target environment to automatically select an appropriate map density to satisfy two user-defined requirements: (1) a target Local Recall@1 level, and (2) the proportion of the operational environment over which this requirement must be met or exceeded, which we term the Recall Achievement Rate (RAR). Our approach is based on the hypothesis that match patterns between multiple reference traverses, evaluated across different map densities, can be modelled to predict the density required to meet these performance targets on unseen deployment data. Through extensive experiments across multiple VPR methods and the Nordland and Oxford RobotCar benchmarks, we show that our system consistently achieves or exceeds the specified local recall level over at least the user-specified proportion of the environment. Comparisons with alternative baselines demonstrate that our approach reliably selects the correct operating point in map density, avoiding unnecessary over-densification. Finally, ablation studies and analysis evaluate sensitivity to reference map choice and local space definitions, and reveal that conventional global Recall@1 is a poor predictor of the often more operationally meaningful RAR metric.

</details>


### [16] [Unified Unsupervised and Sparsely-Supervised 3D Object Detection by Semantic Pseudo-Labeling and Prototype Learning](https://arxiv.org/abs/2602.21484)
*Yushen He*

Main category: cs.CV

TL;DR: SPL是一个统一的训练框架，通过语义伪标签和原型学习，同时支持无监督和稀疏监督的3D目标检测，减少对人工标注的依赖。


<details>
  <summary>Details</summary>
Motivation: 3D目标检测依赖大规模人工标注数据，限制了可扩展性和适应性。现有的无监督和稀疏监督方法面临伪标签质量低、特征挖掘不稳定、缺乏统一训练框架等挑战。

Method: SPL首先通过整合图像语义、点云几何和时间线索生成高质量伪标签（3D边界框和点标签）。然后采用多阶段原型学习策略，通过基于内存的初始化和基于动量的原型更新来稳定特征表示学习。

Result: 在KITTI和nuScenes数据集上的大量实验表明，SPL在无监督和稀疏监督设置下都显著优于现有最先进方法。

Conclusion: 该工作为使用最少或无需人工标注学习3D目标检测器提供了一个鲁棒且可泛化的解决方案。

Abstract: 3D object detection is essential for autonomous driving and robotic perception, yet its reliance on large-scale manually annotated data limits scalability and adaptability. To reduce annotation dependency, unsupervised and sparsely-supervised paradigms have emerged. However, they face intertwined challenges: low-quality pseudo-labels, unstable feature mining, and a lack of a unified training framework. This paper proposes SPL, a unified training framework for both Unsupervised and Sparsely-Supervised 3D Object Detection via Semantic Pseudo-labeling and prototype Learning. SPL first generates high-quality pseudo-labels by integrating image semantics, point cloud geometry, and temporal cues, producing both 3D bounding boxes for dense objects and 3D point labels for sparse ones. These pseudo-labels are not used directly but as probabilistic priors within a novel, multi-stage prototype learning strategy. This strategy stabilizes feature representation learning through memory-based initialization and momentum-based prototype updating, effectively mining features from both labeled and unlabeled data. Extensive experiments on KITTI and nuScenes datasets demonstrate that SPL significantly outperforms state-of-the-art methods in both settings. Our work provides a robust and generalizable solution for learning 3D object detectors with minimal or no manual annotations.

</details>


### [17] [See It, Say It, Sorted: An Iterative Training-Free Framework for Visually-Grounded Multimodal Reasoning in LVLMs](https://arxiv.org/abs/2602.21497)
*Yongchang Zhang,Xianzheng Ma,Tianyi Liu,Guangquan Zhou,Yang Chen*

Main category: cs.CV

TL;DR: 提出一种轻量级、免训练的视觉证据监督方法，通过构建文本视觉证据池和动态视觉决策模块，在推理过程中确保每个步骤都有视觉依据，从而减少多模态推理中的幻觉传播问题。


<details>
  <summary>Details</summary>
Motivation: 现有大型视觉语言模型在多模态推理中容易产生视觉幻觉传播问题：一旦中间推理步骤与视觉证据不一致，后续步骤即使逻辑正确也会导致错误答案。现有基于强化学习的解决方案成本高、模型特定且难以跨架构泛化。

Method: 提出免训练的即插即用框架：1) 构建文本视觉证据池指导模型推理生成；2) 当现有证据不足时，视觉决策模块根据当前推理上下文动态从图像中提取额外相关证据；3) 扩展证据池直到模型获得足够视觉确定性，终止推理并产生最终答案。

Result: 在多个LVLM主干和基准测试中验证有效性：TreeBench上提升16.5%-29.5%，RH-Bench上获得13.7%的RH-AUC增益，显著降低幻觉率并提高推理准确性，无需额外训练。

Conclusion: 该方法提供了一种轻量级、免训练的解决方案，通过视觉证据监督确保多模态推理的每个步骤都有视觉依据，有效减少幻觉传播，提高推理准确性，且具有良好的泛化能力。

Abstract: Recent large vision-language models (LVLMs) have demonstrated impressive reasoning ability by generating long chain-of-thought (CoT) responses. However, CoT reasoning in multimodal contexts is highly vulnerable to visual hallucination propagation: once an intermediate reasoning step becomes inconsistent with the visual evidence, subsequent steps-even if logically valid-can still lead to incorrect final answers. Existing solutions attempt to mitigate this issue by training models to "think with images" via reinforcement learning (RL). While effective, these methods are costly, model-specific, and difficult to generalize across architectures. Differently, we present a lightweight method that bypasses RL training and provides an iterative, training-free, plug-and-play framework for visually-grounded multimodal reasoning. Our key idea is to supervise each reasoning step at test time with visual evidence, ensuring that every decoded token is justified by corresponding visual cues. Concretely, we construct a textual visual-evidence pool that guides the model's reasoning generation. When existing evidence is insufficient, a visual decider module dynamically extracts additional relevant evidence from the image based on the ongoing reasoning context, expanding the pool until the model achieves sufficient visual certainty to terminate reasoning and produce the final answer. Extensive experiments on multiple LVLM backbones and benchmarks demonstrate the effectiveness of our approach. Our method achieves 16.5%-29.5% improvements on TreeBench and 13.7% RH-AUC gains on RH-Bench, substantially reducing hallucination rates while improving reasoning accuracy without additional training.

</details>


### [18] [Easy3E: Feed-Forward 3D Asset Editing via Rectified Voxel Flow](https://arxiv.org/abs/2602.21499)
*Shimin Hu,Yuanyi Wei,Fei Zha,Yudong Guo,Juyong Zhang*

Main category: cs.CV

TL;DR: 基于TRELLIS生成骨干网络，提出了一种高效的前馈式3D编辑框架，能够从单一编辑视角修改3D模型，解决了多视角不一致和计算密集问题。


<details>
  <summary>Details</summary>
Motivation: 现有3D编辑方法依赖计算密集的场景级迭代优化，存在多视角不一致问题，需要更高效、一致的3D编辑解决方案。

Method: 1) 引入Voxel FlowEdit：在稀疏体素潜在空间中进行编辑驱动的流，实现单次全局一致的3D变形；2) 开发法线引导的单到多视角生成模块：作为外部外观先验，恢复高频纹理细节。

Result: 实验表明该方法能够实现快速、全局一致且高保真的3D模型编辑，解决了现有方法的计算密集和多视角不一致问题。

Conclusion: 提出的框架通过Voxel FlowEdit和法线引导生成模块，实现了高效、一致、高质量的3D编辑，为3D内容创作提供了实用解决方案。

Abstract: Existing 3D editing methods rely on computationally intensive scene-by-scene iterative optimization and suffer from multi-view inconsistency. We propose an effective and fully feedforward 3D editing framework based on the TRELLIS generative backbone, capable of modifying 3D models from a single editing view. Our framework addresses two key issues: adapting training-free 2D editing to structured 3D representations, and overcoming the bottleneck of appearance fidelity in compressed 3D features. To ensure geometric consistency, we introduce Voxel FlowEdit, an edit-driven flow in the sparse voxel latent space that achieves globally consistent 3D deformation in a single pass. To restore high-fidelity details, we develop a normal-guided single to multi-view generation module as an external appearance prior, successfully recovering high-frequency textures. Experiments demonstrate that our method enables fast, globally consistent, and high-fidelity 3D model editing.

</details>


### [19] [AHAN: Asymmetric Hierarchical Attention Network for Identical Twin Face Verification](https://arxiv.org/abs/2602.21503)
*Hoang-Nhat Nguyen*

Main category: cs.CV

TL;DR: 提出AHAN网络解决双胞胎人脸验证难题，通过多粒度面部分析和不对称特征学习，在ND_TWIN数据集上达到92.3%准确率，比现有方法提升3.4%


<details>
  <summary>Details</summary>
Motivation: 同卵双胞胎人脸验证是极端细粒度识别挑战，现有方法在标准基准上准确率超过99.8%，但在区分双胞胎时骤降至88.9%，暴露了生物识别安全系统的关键漏洞。难点在于学习捕捉个体独特非遗传变异的特征。

Method: 提出非对称层次注意力网络(AHAN)：1) 层次交叉注意力模块(HCA)对语义面部区域进行多尺度分析；2) 面部不对称注意力模块(FAAM)通过左右面部半边的交叉注意力学习独特生物特征签名；3) 双胞胎感知成对交叉注意力(TA-PWCA)训练正则化策略，使用每个主体的双胞胎作为最难干扰项。

Result: 在ND_TWIN数据集上的广泛实验表明，AHAN实现了92.3%的双胞胎验证准确率，比最先进方法提高了3.4%。

Conclusion: AHAN通过多粒度面部分析和不对称特征学习有效解决了双胞胎人脸验证难题，显著提升了生物识别系统在极端相似情况下的性能。

Abstract: Identical twin face verification represents an extreme fine-grained recognition challenge where even state-of-the-art systems fail due to overwhelming genetic similarity. Current face recognition methods achieve over 99.8% accuracy on standard benchmarks but drop dramatically to 88.9% when distinguishing identical twins, exposing critical vulnerabilities in biometric security systems. The difficulty lies in learning features that capture subtle, non-genetic variations that uniquely identify individuals. We propose the Asymmetric Hierarchical Attention Network (AHAN), a novel architecture specifically designed for this challenge through multi-granularity facial analysis. AHAN introduces a Hierarchical Cross-Attention (HCA) module that performs multi-scale analysis on semantic facial regions, enabling specialized processing at optimal resolutions. We further propose a Facial Asymmetry Attention Module (FAAM) that learns unique biometric signatures by computing cross-attention between left and right facial halves, capturing subtle asymmetric patterns that differ even between twins. To ensure the network learns truly individuating features, we introduce Twin-Aware Pair-Wise Cross-Attention (TA-PWCA), a training-only regularization strategy that uses each subject's own twin as the hardest possible distractor. Extensive experiments on the ND_TWIN dataset demonstrate that AHAN achieves 92.3% twin verification accuracy, representing a 3.4% improvement over state-of-the-art methods.

</details>


### [20] [Which Tool Response Should I Trust? Tool-Expertise-Aware Chest X-ray Agent with Multimodal Agentic Learning](https://arxiv.org/abs/2602.21517)
*Zheang Huai,Honglong Yang,Xiaomeng Li*

Main category: cs.CV

TL;DR: 提出TEA-CXA框架，让AI代理通过强化学习在多模态医疗场景中学习不同工具的可靠性，解决工具冲突问题


<details>
  <summary>Details</summary>
Motivation: 现有医疗AI代理研究未能充分考虑工具的可靠性差异，当多个AI工具产生矛盾结果时无法有效解决冲突，需要一种能学习工具实际可信度的框架

Method: 提出TEA-CXA框架，通过强化学习让代理在多轮工具调用中实验性接受或拒绝多模态工具结果，根据奖励学习每种查询类型下应信任的工具；扩展现有代码库以支持多模态输入、单轮多工具调用、并行工具推理和多图像处理

Result: TEA-CXA在胸片X光分析任务中超越了现有最优方法和多种基线方法，证明了框架的有效性

Conclusion: 该框架能有效解决医疗AI工具冲突问题，通过代理学习工具的实际可信度，代码将开源并适用于多模态多轮工具调用强化学习的通用医疗研究

Abstract: AI agents with tool-use capabilities show promise for integrating the domain expertise of various tools. In the medical field, however, tools are usually AI models that are inherently error-prone and can produce contradictory responses. Existing research on medical agents lacks sufficient understanding of the tools' realistic reliability and thus cannot effectively resolve tool conflicts. To address this gap, this paper introduces a framework that enables an agent to interact with tools and empirically learn their practical trustworthiness across different types of multimodal queries via agentic learning. As a concrete instantiation, we focus on chest X-ray analysis and present a tool-expertise-aware chest X-ray agent (TEA-CXA). When tool outputs disagree, the agent experimentally accepts or rejects multimodal tool results, receives rewards, and learns which tool to trust for each query type. Importantly, TEA-CXA extends existing codebases for reinforcement learning with multi-turn tool-calling that focus on textual inputs, to support multimodal contexts effectively. In addition, we enhance the codebase for medical use scenarios by supporting multiple tool calls in one turn, parallel tool inference, and multi-image accommodation within a single user query. Our code framework is applicable to general medical research on multi-turn tool-calling reinforcement learning in multimodal settings. Experiments show that TEA-CXA outperforms the state-of-the-art methods and a comprehensive set of baselines. Code will be released.

</details>


### [21] [Pseudo-View Enhancement via Confidence Fusion for Unposed Sparse-View Reconstruction](https://arxiv.org/abs/2602.21535)
*Beizhen Zhao,Sicheng Yu,Guanzhi Ding,Yu Hu,Hao Wang*

Main category: cs.CV

TL;DR: 提出新框架用于稀疏视角户外3D场景重建，通过双向伪帧恢复和场景感知高斯管理实现高质量重建


<details>
  <summary>Details</summary>
Motivation: 解决户外场景中未定位稀疏视角的3D重建难题，特别是在复杂光照和尺度变化下，传统扩散模型直接合成伪帧会导致不合理几何结构，损害重建质量

Method: 1. 双向伪帧恢复方法：通过基于扩散的合成恢复缺失内容，使用轻量级伪视图去模糊模型和置信掩码推理算法；2. 场景感知高斯管理策略：基于联合深度-密度信息优化高斯分布

Result: 在户外基准测试中，相比现有方法在保真度和稳定性方面都有显著提升，显著增强了重建完整性，抑制了浮动伪影，提高了极端视角稀疏下的几何一致性

Conclusion: 提出的框架通过创新的双向伪帧恢复和场景感知高斯管理，有效解决了稀疏视角户外3D重建的挑战，实现了高质量的重建结果

Abstract: 3D scene reconstruction under unposed sparse viewpoints is a highly challenging yet practically important problem, especially in outdoor scenes due to complex lighting and scale variation. With extremely limited input views, directly utilizing diffusion model to synthesize pseudo frames will introduce unreasonable geometry, which will harm the final reconstruction quality. To address these issues, we propose a novel framework for sparse-view outdoor reconstruction that achieves high-quality results through bidirectional pseudo frame restoration and scene perception Gaussian management. Specifically, we introduce a bidirectional pseudo frame restoration method that restores missing content by diffusion-based synthesis guided by adjacent frames with a lightweight pseudo-view deblur model and confidence mask inference algorithm. Then we propose a scene perception Gaussian management strategy that optimize Gaussians based on joint depth-density information. These designs significantly enhance reconstruction completeness, suppress floating artifacts and improve overall geometric consistency under extreme view sparsity. Experiments on outdoor benchmarks demonstrate substantial gains over existing methods in both fidelity and stability.

</details>


### [22] [IHF-Harmony: Multi-Modality Magnetic Resonance Images Harmonization using Invertible Hierarchy Flow Model](https://arxiv.org/abs/2602.21536)
*Pengli Zhu,Yitao Zhu,Haowen Pang,Anqi Qiu*

Main category: cs.CV

TL;DR: IHF-Harmony：一种基于可逆层次流的统一多模态MRI图像协调框架，使用非配对数据实现高保真度协调，防止解剖结构失真


<details>
  <summary>Details</summary>
Motivation: 现有MRI协调方法存在可扩展性差（难以跨模态应用）和依赖配对数据（需要旅行者数据集）的问题，限制了大规模多中心影像研究的应用

Method: 提出可逆层次流（IHF）框架，通过分层减法耦合逐步去除伪影相关特征；结合伪影感知归一化（AAN）进行解剖结构固定的特征调制；使用解剖结构和伪影一致性损失目标确保源解剖结构的保留

Result: 在多个MRI模态上的实验表明，IHF-Harmony在解剖保真度和下游任务性能方面均优于现有方法，能够实现大规模多中心影像研究的稳健协调

Conclusion: IHF-Harmony通过可逆特征变换和分层伪影去除，为多模态MRI协调提供了统一的解决方案，解决了现有方法的可扩展性和数据依赖性问题，代码将在接受后发布

Abstract: Retrospective MRI harmonization is limited by poor scalability across modalities and reliance on traveling subject datasets. To address these challenges, we introduce IHF-Harmony, a unified invertible hierarchy flow framework for multi-modality harmonization using unpaired data. By decomposing the translation process into reversible feature transformations, IHF-Harmony guarantees bijective mapping and lossless reconstruction to prevent anatomical distortion. Specifically, an invertible hierarchy flow (IHF) performs hierarchical subtractive coupling to progressively remove artefact-related features, while an artefact-aware normalization (AAN) employs anatomy-fixed feature modulation to accurately transfer target characteristics. Combined with anatomy and artefact consistency loss objectives, IHF-Harmony achieves high-fidelity harmonization that retains source anatomy. Experiments across multiple MRI modalities demonstrate that IHF-Harmony outperforms existing methods in both anatomical fidelity and downstream task performance, facilitating robust harmonization for large-scale multi-site imaging studies. Code will be released upon acceptance.

</details>


### [23] [VasGuideNet: Vascular Topology-Guided Couinaud Liver Segmentation with Structural Contrastive Loss](https://arxiv.org/abs/2602.21539)
*Chaojie Shen,Jingjun Gu,Zihao Zhao,Ruocheng Li,Cunyuan Yang,Jiajun Bu,Lei Wu*

Main category: cs.CV

TL;DR: VasGuideNet：首个基于血管拓扑引导的Couinaud肝脏分割框架，通过图卷积网络编码血管拓扑特征，结合交叉注意力融合和结构对比损失，在肝血管数据集上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有Couinaud肝脏分割方法主要依赖图像强度和空间位置信息，未显式建模血管拓扑结构，导致血管附近边界模糊且在解剖变异下泛化能力有限。

Method: 提出VasGuideNet框架：1) 使用图卷积网络编码骨架化血管、欧氏距离变换几何特征和k近邻连接性；2) 通过交叉注意力融合模块将拓扑特征注入3D编码器-解码器主干；3) 引入带全局记忆库的结构对比损失以提高类间分离性和解剖一致性。

Result: 在Task08_HepaticVessel和私有LASSD数据集上分别达到83.68%和76.65%的Dice分数，RVD为1.68和7.08，在Dice/mIoU和RVD指标上均优于UNETR、Swin UNETR和G-UNETR++等基线方法。

Conclusion: VasGuideNet通过显式建模血管拓扑结构，实现了更精确、解剖一致的Couinaud肝脏分割，为术前规划和肿瘤定位提供了更可靠的工具。

Abstract: Accurate Couinaud liver segmentation is critical for preoperative surgical planning and tumor localization.However, existing methods primarily rely on image intensity and spatial location cues, without explicitly modeling vascular topology. As a result, they often produce indistinct boundaries near vessels and show limited generalization under anatomical variability.We propose VasGuideNet, the first Couinaud segmentation framework explicitly guided by vascular topology. Specifically, skeletonized vessels, Euclidean distance transform (EDT)--derived geometry, and k-nearest neighbor (kNN) connectivity are encoded into topology features using Graph Convolutional Networks (GCNs). These features are then injected into a 3D encoder--decoder backbone via a cross-attention fusion module. To further improve inter-class separability and anatomical consistency, we introduce a Structural Contrastive Loss (SCL) with a global memory bank.On Task08_HepaticVessel and our private LASSD dataset, VasGuideNet achieves Dice scores of 83.68% and 76.65% with RVDs of 1.68 and 7.08, respectively. It consistently outperforms representative baselines including UNETR, Swin UNETR, and G-UNETR++, delivering higher Dice/mIoU and lower RVD across datasets, demonstrating its effectiveness for anatomically consistent segmentation. Code is available at https://github.com/Qacket/VasGuideNet.git.

</details>


### [24] [Space-Time Forecasting of Dynamic Scenes with Motion-aware Gaussian Grouping](https://arxiv.org/abs/2602.21668)
*Junmyeong Lee,Hoseung Choi,Minsu Cho*

Main category: cs.CV

TL;DR: MoGaF是一个基于4D高斯溅射表示的长时场景外推框架，通过运动感知高斯分组和分组优化实现物理一致的运动，结合轻量预测模块生成未来场景


<details>
  <summary>Details</summary>
Motivation: 动态场景预测是计算机视觉的基本挑战，有限观测难以捕捉连贯的对象级运动和长期时间演化

Method: 基于4D高斯溅射表示，引入运动感知高斯分组和分组优化，强制刚性和非刚性区域的物理一致运动，使用轻量预测模块预测未来运动

Result: 在合成和真实数据集上实验表明，MoGaF在渲染质量、运动合理性和长期预测稳定性方面一致优于现有基线

Conclusion: MoGaF通过结构化时空表示实现了现实且时间稳定的场景演化，为动态场景预测提供了有效解决方案

Abstract: Forecasting dynamic scenes remains a fundamental challenge in computer vision, as limited observations make it difficult to capture coherent object-level motion and long-term temporal evolution. We present Motion Group-aware Gaussian Forecasting (MoGaF), a framework for long-term scene extrapolation built upon the 4D Gaussian Splatting representation. MoGaF introduces motion-aware Gaussian grouping and group-wise optimization to enforce physically consistent motion across both rigid and non-rigid regions, yielding spatially coherent dynamic representations. Leveraging this structured space-time representation, a lightweight forecasting module predicts future motion, enabling realistic and temporally stable scene evolution. Experiments on synthetic and real-world datasets demonstrate that MoGaF consistently outperforms existing baselines in rendering quality, motion plausibility, and long-term forecasting stability. Our project page is available at https://slime0519.github.io/mogaf

</details>


### [25] [DynamicGTR: Leveraging Graph Topology Representation Preferences to Boost VLM Capabilities on Graph QAs](https://arxiv.org/abs/2602.21864)
*Yanbin Wei,Jiangyue Yan,Chun Kang,Yang Chen,Hua Liu,James Kwok,Yu Zhang*

Main category: cs.CV

TL;DR: DynamicGTR框架动态选择最优图拓扑表示，提升视觉语言模型在图问答任务中的零样本性能，实现准确性与简洁性的可定制权衡。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常依赖单一图拓扑表示，这种"一刀切"策略忽视了模型特定和任务特定的偏好，导致图相关查询的响应不准确或过于冗长。

Method: 提出DynamicGTR框架，在推理过程中为每个查询动态选择最优的图拓扑表示，增强视觉语言模型的零样本图问答能力，并提供可定制的准确性与简洁性权衡。

Result: 实验表明DynamicGTR不仅提升了基于VLM的图算法问答性能，还能将合成图算法任务中训练的经验成功迁移到链接预测和节点分类等实际应用，无需额外训练。同时展现出跨任务、领域和模型的强迁移能力。

Conclusion: DynamicGTR作为灵活的解决方案，具有在广泛图场景中应用的潜力，通过动态选择图拓扑表示有效解决了现有方法的局限性。

Abstract: Vision-Language Models (VLMs) have emerged as versatile solutions for zero-shot question answering (QA) across various domains. However, enabling VLMs to effectively comprehend structured graphs and perform accurate, efficient QA remains challenging. Existing approaches typically rely on one single graph topology representation (GTR), such as fixed-style visual images or unified text descriptions. This ``one-size-fits-all'' strategy often neglects model-specific and task-specific preferences, resulting in inaccurate or over-lengthy responses to graph-related queries. To address this, we propose the $\mbox{DynamicGTR}$ framework, which dynamically selects the optimal GTR for each query during inference, thereby enhancing the zero-shot graph QA capabilities of VLMs with a customizable accuracy and brevity trade-off. Extensive experiments show that DynamicGTR not only improves VLM-based graph algorithm QA performance but also successfully transfers the experience trained from synthetic graph algorithm tasks to real-world applications like link prediction and node classification, without any additional training. Additionally, DynamicGTR demonstrates strong transferability across tasks, domains, and models, suggesting its potential as a flexible solution for broad graph scenarios.

</details>


### [26] [NoLan: Mitigating Object Hallucinations in Large Vision-Language Models via Dynamic Suppression of Language Priors](https://arxiv.org/abs/2602.22144)
*Lingfeng Ren,Weihao Yu,Runpeng Yu,Xinchao Wang*

Main category: cs.CV

TL;DR: 论文提出NoLan框架，通过抑制语言解码器的强先验来减少大型视觉语言模型中的物体幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 研究大型视觉语言模型中物体幻觉问题的根源：是视觉编码器感知视觉信息的问题，还是语言解码器生成文本响应的问题？

Method: 设计系统实验分析视觉编码器和语言解码器在幻觉生成中的作用，发现物体幻觉主要与语言解码器的强先验相关。基于此提出NoLan框架，通过动态抑制语言先验来优化输出分布。

Result: NoLan在各种LVLMs和不同任务上有效减少物体幻觉。在POPE基准测试中，LLaVA-1.5 7B和Qwen-VL 7B的准确率分别提升6.45和7.21。

Conclusion: 物体幻觉主要源于语言解码器的强先验，NoLan框架通过训练无关的方式动态抑制这些先验，显著减少幻觉问题，为LVLMs的可靠性提升提供有效方案。

Abstract: Object hallucination is a critical issue in Large Vision-Language Models (LVLMs), where outputs include objects that do not appear in the input image. A natural question arises from this phenomenon: Which component of the LVLM pipeline primarily contributes to object hallucinations? The vision encoder to perceive visual information, or the language decoder to generate text responses? In this work, we strive to answer this question through designing a systematic experiment to analyze the roles of the vision encoder and the language decoder in hallucination generation. Our observations reveal that object hallucinations are predominantly associated with the strong priors from the language decoder. Based on this finding, we propose a simple and training-free framework, No-Language-Hallucination Decoding, NoLan, which refines the output distribution by dynamically suppressing language priors, modulated based on the output distribution difference between multimodal and text-only inputs. Experimental results demonstrate that NoLan effectively reduces object hallucinations across various LVLMs on different tasks. For instance, NoLan achieves substantial improvements on POPE, enhancing the accuracy of LLaVA-1.5 7B and Qwen-VL 7B by up to 6.45 and 7.21, respectively. The code is publicly available at: https://github.com/lingfengren/NoLan.

</details>


### [27] [From Statics to Dynamics: Physics-Aware Image Editing with Latent Transition Priors](https://arxiv.org/abs/2602.21778)
*Liangbing Zhao,Le Zhuo,Sayak Paul,Hongsheng Li,Mohamed Elhoseiny*

Main category: cs.CV

TL;DR: 该论文提出了PhysicEdit框架，通过将图像编辑重新定义为物理状态转换来解决现有指令编辑模型在处理复杂物理动态时的不足，并引入了PhysicTran38K数据集进行监督训练。


<details>
  <summary>Details</summary>
Motivation: 当前基于指令的图像编辑模型在语义对齐方面表现良好，但在涉及复杂因果动态（如折射、材料变形）的编辑任务中，经常无法生成物理上合理的结果。作者认为这是因为现有方法将编辑视为图像对之间的离散映射，只提供边界条件而忽略了过渡动态。

Method: 1) 构建PhysicTran38K数据集：包含38K个跨五个物理域的过渡轨迹，采用两阶段过滤和约束感知标注流程；2) 提出PhysicEdit框架：采用文本-视觉双重思维机制，结合冻结的Qwen2.5-VL进行物理基础推理，以及可学习的过渡查询为扩散主干提供时间步自适应的视觉指导。

Result: PhysicEdit相比Qwen-Image-Edit在物理真实感方面提升5.9%，在知识基础编辑方面提升10.1%，为开源方法设定了新的最先进水平，同时与领先的专有模型保持竞争力。

Conclusion: 通过将图像编辑重新定义为物理状态转换，并引入大规模视频数据集和双重思维机制，PhysicEdit框架显著提升了物理感知编辑的质量，为解决复杂物理动态的编辑问题提供了有效方案。

Abstract: Instruction-based image editing has achieved remarkable success in semantic alignment, yet state-of-the-art models frequently fail to render physically plausible results when editing involves complex causal dynamics, such as refraction or material deformation. We attribute this limitation to the dominant paradigm that treats editing as a discrete mapping between image pairs, which provides only boundary conditions and leaves transition dynamics underspecified. To address this, we reformulate physics-aware editing as predictive physical state transitions and introduce PhysicTran38K, a large-scale video-based dataset comprising 38K transition trajectories across five physical domains, constructed via a two-stage filtering and constraint-aware annotation pipeline. Building on this supervision, we propose PhysicEdit, an end-to-end framework equipped with a textual-visual dual-thinking mechanism. It combines a frozen Qwen2.5-VL for physically grounded reasoning with learnable transition queries that provide timestep-adaptive visual guidance to a diffusion backbone. Experiments show that PhysicEdit improves over Qwen-Image-Edit by 5.9% in physical realism and 10.1% in knowledge-grounded editing, setting a new state-of-the-art for open-source methods, while remaining competitive with leading proprietary models.

</details>


### [28] [SkyReels-V4: Multi-modal Video-Audio Generation, Inpainting and Editing model](https://arxiv.org/abs/2602.21818)
*Guibin Chen,Dixuan Lin,Jiangping Yang,Youqiang Zhang,Zhengcong Fei,Debang Li,Sheng Chen,Chaofeng Ao,Nuo Pang,Yiming Wang,Yikun Dou,Zheng Chen,Mingyuan Fan,Tuanhui Li,Mingshan Chang,Hao Zhang,Xiaopeng Sun,Jingtao Xu,Yuqiang Xie,Jiahua Wang,Zhiheng Xu,Weiming Xiong,Yuzhe Jin,Baoxuan Gu,Binjie Mao,Yunjie Yu,Jujie He,Yuhao Feng,Shiwen Tu,Chaojie Wang,Rui Yan,Wei Shen,Jingchen Wu,Peng Zhao,Xuanyue Zhong,Zhuangzhuang Liu,Kaifei Wang,Fuxiang Zhang,Weikai Xu,Wenyan Liu,Binglu Zhang,Yu Shen,Tianhui Xiong,Bin Peng,Liang Zeng,Xuchen Song,Haoxiang Guo,Peiyu Wang,Yahui Zhou*

Main category: cs.CV

TL;DR: SkyReels V4是一个统一的多模态视频基础模型，支持联合视频音频生成、修复和编辑，采用双流多模态扩散Transformer架构，支持1080p分辨率、32帧率、15秒时长的高质量视频生成。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型通常只处理单一模态或任务，缺乏统一的框架来处理多模态输入、联合视频音频生成以及多种视频编辑任务。需要开发一个能够同时支持这些复杂功能的高效模型。

Method: 采用双流多模态扩散Transformer架构，一个分支合成视频，另一个生成时间对齐的音频，共享基于多模态大语言模型的文本编码器。使用通道拼接公式统一多种修复和编辑任务，并引入高效策略：联合生成低分辨率完整序列和高分辨率关键帧，然后通过超分辨率和帧插值模型提升质量。

Result: SkyReels V4支持1080p分辨率、32帧率、15秒时长的视频生成，能够实现高质量、多镜头、电影级别的视频生成与同步音频。这是首个同时支持多模态输入、联合视频音频生成以及统一处理生成、修复和编辑任务的视频基础模型。

Conclusion: SkyReels V4通过创新的架构设计和效率策略，成功实现了统一的多模态视频生成、修复和编辑功能，在保持高质量的同时实现了计算效率，为电影级视频创作提供了强大的基础模型。

Abstract: SkyReels V4 is a unified multi modal video foundation model for joint video audio generation, inpainting, and editing. The model adopts a dual stream Multimodal Diffusion Transformer (MMDiT) architecture, where one branch synthesizes video and the other generates temporally aligned audio, while sharing a powerful text encoder based on the Multimodal Large Language Models (MMLM). SkyReels V4 accepts rich multi modal instructions, including text, images, video clips, masks, and audio references. By combining the MMLMs multi modal instruction following capability with in context learning in the video branch MMDiT, the model can inject fine grained visual guidance under complex conditioning, while the audio branch MMDiT simultaneously leverages audio references to guide sound generation. On the video side, we adopt a channel concatenation formulation that unifies a wide range of inpainting style tasks, such as image to video, video extension, and video editing under a single interface, and naturally extends to vision referenced inpainting and editing via multi modal prompts. SkyReels V4 supports up to 1080p resolution, 32 FPS, and 15 second duration, enabling high fidelity, multi shot, cinema level video generation with synchronized audio. To make such high resolution, long-duration generation computationally feasible, we introduce an efficiency strategy: Joint generation of low resolution full sequences and high-resolution keyframes, followed by dedicated super-resolution and frame interpolation models. To our knowledge, SkyReels V4 is the first video foundation model that simultaneously supports multi-modal input, joint video audio generation, and a unified treatment of generation, inpainting, and editing, while maintaining strong efficiency and quality at cinematic resolutions and durations.

</details>


### [29] [UniVBench: Towards Unified Evaluation for Video Foundation Models](https://arxiv.org/abs/2602.21835)
*Jianhui Wei,Xiaotian Zhang,Yichen Li,Yuan Wang,Yan Zhang,Ziyi Chen,Zhihang Tang,Wei Xu,Zuozhu Liu*

Main category: cs.CV

TL;DR: UniVBench：首个用于评估视频基础模型在理解、生成、编辑和重建四个核心能力上的统一基准，包含200个高质量多镜头视频和统一的智能评估系统。


<details>
  <summary>Details</summary>
Motivation: 现有视频评估基准存在碎片化、范围有限的问题，每个基准只针对单一任务，使用任务特定指标，通常采用短或简单的视频片段，无法捕捉视频基础模型设计的统一能力。

Method: 开发了UniVBench基准，包含200个高质量、多样化、多镜头的视频，每个视频配有详细字幕、多格式编辑指令和参考图像。同时开发了统一的智能评估系统（UniV-Eval），标准化所有任务的提示、指令解析和评分。

Result: UniVBench提供了首个评估视频基础模型集成能力的框架，通过基于指令的多镜头视频任务进行接地评估，大量人工标注确保评估与人类判断一致。

Conclusion: UniVBench通过统一的评估框架解决了现有基准的局限性，能够公平、可扩展、可重复地比较统一视频模型，加速稳健视频智能的发展。

Abstract: Video foundation models aim to integrate video understanding, generation, editing, and instruction following within a single framework, making them a central direction for next-generation multimodal systems. However, existing evaluation benchmarks remain fragmented and limited in scope, as they each target a single task, rely on task-specific metrics, and typically use short or simple video clips. As a result, they do not capture the unified capabilities that these models are designed to deliver. To address this gap, we introduce UniVBench, a benchmark purpose-built for evaluating video foundation models across four core abilities: video understanding, video generation, video editing, and a newly proposed task, video reconstruction, which assesses how faithfully a model can reproduce video content it has encountered. Our benchmark substantially expands the complexity of evaluation by incorporating 200 high-quality, diverse and multi-shot videos, each paired with detailed captions, multi-format editing instructions, and reference images. All videos are human-created and carefully validated, offering richer cinematic information than prior benchmarks. In addition, we develop a unified agentic evaluation system (UniV-Eval) that standardizes prompting, instruction parsing, and scoring across all tasks, enabling fair, scalable, and reproducible comparisons of unified video models. By grounding evaluation in instruction-based multi-shot video tasks, UniVBench provides the first framework for measuring the integrated capabilities that video foundation models aim to achieve. Extensive human annotations ensure our evaluation aligns with human judgment, enabling rigorous assessment and accelerating progress toward robust video intelligence.

</details>


### [30] [Solaris: Building a Multiplayer Video World Model in Minecraft](https://arxiv.org/abs/2602.22208)
*Georgy Savva,Oscar Michel,Daohan Lu,Suppakit Waiwitlikhit,Timothy Meehan,Dhairya Mishra,Srivats Poddar,Jack Lu,Saining Xie*

Main category: cs.CV

TL;DR: Solaris是一个多玩家视频世界模型，能够模拟一致的多视角观察，通过自动化的多人游戏数据收集系统训练，在多人交互任务上优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 现有的动作条件视频生成模型（视频世界模型）仅限于单智能体视角，无法捕捉现实世界环境中的多智能体交互。需要开发能够模拟一致多视角观察的多人视频世界模型。

Method: 开发了专门用于视频游戏的多人数据收集系统，收集了1264万帧多人游戏数据。采用分阶段训练管道，从单玩家逐步过渡到多人建模，结合双向、因果和Self Forcing训练。最后阶段引入了Checkpointed Self Forcing，这是一种内存高效的Self Forcing变体，支持更长视野的教师模型。

Result: 提出的架构和训练设计优于现有基线模型。通过开源系统和模型，为新一代多智能体世界模型奠定了基础。

Conclusion: Solaris成功解决了现有视频世界模型在多智能体交互方面的局限性，通过创新的数据收集系统和训练方法，实现了多人视角的一致模拟，为多智能体世界模型研究开辟了新方向。

Abstract: Existing action-conditioned video generation models (video world models) are limited to single-agent perspectives, failing to capture the multi-agent interactions of real-world environments. We introduce Solaris, a multiplayer video world model that simulates consistent multi-view observations. To enable this, we develop a multiplayer data system designed for robust, continuous, and automated data collection on video games such as Minecraft. Unlike prior platforms built for single-player settings, our system supports coordinated multi-agent interaction and synchronized videos + actions capture. Using this system, we collect 12.64 million multiplayer frames and propose an evaluation framework for multiplayer movement, memory, grounding, building, and view consistency. We train Solaris using a staged pipeline that progressively transitions from single-player to multiplayer modeling, combining bidirectional, causal, and Self Forcing training. In the final stage, we introduce Checkpointed Self Forcing, a memory-efficient Self Forcing variant that enables a longer-horizon teacher. Results show our architecture and training design outperform existing baselines. Through open-sourcing our system and models, we hope to lay the groundwork for a new generation of multi-agent world models.

</details>


### [31] [Neu-PiG: Neural Preconditioned Grids for Fast Dynamic Surface Reconstruction on Long Sequences](https://arxiv.org/abs/2602.22212)
*Julian Kaltheuner,Hannah Dröge,Markus Plack,Patrick Stotko,Reinhard Klein*

Main category: cs.CV

TL;DR: Neu-PiG：基于预条件潜在网格编码的快速动态3D表面重建方法，无需显式对应关系或类别特定训练，在长序列上实现无漂移、高保真重建，速度比现有方法快60倍以上。


<details>
  <summary>Details</summary>
Motivation: 现有动态3D对象表面重建方法存在两个主要问题：1）增量优化方法容易产生漂移且运行时间长；2）基于学习的方法需要类别特定训练且模型复杂。需要一种快速、无漂移、无需类别特定训练的方法来处理长序列动态3D重建。

Method: 提出预条件潜在网格编码方法：1）将整个时间序列的变形编码到多分辨率潜在网格中，参数化为参考关键帧表面的位置和法线方向；2）通过时间调制增强潜在表示；3）使用轻量级MLP解码为每帧的6自由度变形；4）在潜在空间梯度训练中采用Sobolev预条件技术，避免显式对应关系或额外先验。

Result: 在多样的人类和动物数据集上，Neu-PiG优于现有最先进方法，提供更高的精度和长序列可扩展性，比现有无训练方法快至少60倍，推理速度与重型预训练模型相当。

Conclusion: Neu-PiG通过创新的预条件潜在网格编码，实现了快速、无漂移的动态3D表面重建，无需显式对应关系或类别特定训练，在长序列上表现出优越的精度和可扩展性，显著提升了重建效率。

Abstract: Temporally consistent surface reconstruction of dynamic 3D objects from unstructured point cloud data remains challenging, especially for very long sequences. Existing methods either optimize deformations incrementally, risking drift and requiring long runtimes, or rely on complex learned models that demand category-specific training. We present Neu-PiG, a fast deformation optimization method based on a novel preconditioned latent-grid encoding that distributes spatial features parameterized on the position and normal direction of a keyframe surface. Our method encodes entire deformations across all time steps at various spatial scales into a multi-resolution latent grid, parameterized by the position and normal direction of a reference surface from a single keyframe. This latent representation is then augmented for time modulation and decoded into per-frame 6-DoF deformations via a lightweight multilayer perceptron (MLP). To achieve high-fidelity, drift-free surface reconstructions in seconds, we employ Sobolev preconditioning during gradient-based training of the latent space, completely avoiding the need for any explicit correspondences or further priors. Experiments across diverse human and animal datasets demonstrate that Neu-PiG outperforms state-the-art approaches, offering both superior accuracy and scalability to long sequences while running at least 60x faster than existing training-free methods and achieving inference speeds on the same order as heavy pretrained models.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [32] [Disaster Question Answering with LoRA Efficiency and Accurate End Position](https://arxiv.org/abs/2602.21212)
*Takato Yasuno*

Main category: cs.CL

TL;DR: 本文提出一个针对日本灾害情境的问答系统，采用BERT-base日语模型+Bi-LSTM+增强位置头架构，通过LoRA优化实现高精度灾害响应问答。


<details>
  <summary>Details</summary>
Motivation: 自然灾害发生频率低且影响范围有限，人们在灾害中常因缺乏专业知识而困惑。现有RAG和LLM方法无法保证获得相关灾害知识和类似情境经验，且幻觉可能导致虚假信息传播加剧混乱。

Method: 使用cl-tohoku/bert-base-japanese-v3 + Bi-LSTM + Enhanced Position Heads架构，结合LoRA效率优化，仅使用总参数的5.7%（6.7M/117M）实现高效灾害问答。

Result: 达到70.4%的End Position准确率和0.885的Span F1分数，证明日本BERT-base优化与Bi-LSTM上下文理解的结合在真实灾害响应场景中具有适用精度。

Conclusion: 系统在灾害问答中表现良好，未来挑战包括：建立自然灾害QA基准数据集、用灾害知识微调基础模型、开发轻量级边缘AI应用以应对灾害期间电力通信不足，以及解决灾害知识库更新和持续学习能力问题。

Abstract: Natural disasters such as earthquakes, torrential rainfall, floods, and volcanic eruptions occur with extremely low frequency and affect limited geographic areas. When individuals face disaster situations, they often experience confusion and lack the domain-specific knowledge and experience necessary to determine appropriate responses and actions. While disaster information is continuously updated, even when utilizing RAG search and large language models for inquiries, obtaining relevant domain knowledge about natural disasters and experiences similar to one's specific situation is not guaranteed. When hallucinations are included in disaster question answering, artificial misinformation may spread and exacerbate confusion. This work introduces a disaster-focused question answering system based on Japanese disaster situations and response experiences. Utilizing the cl-tohoku/bert-base-japanese-v3 + Bi-LSTM + Enhanced Position Heads architecture with LoRA efficiency optimization, we achieved 70.4\% End Position accuracy with only 5.7\% of the total parameters (6.7M/117M). Experimental results demonstrate that the combination of Japanese BERT-base optimization and Bi-LSTM contextual understanding achieves accuracy levels suitable for real disaster response scenarios, attaining a 0.885 Span F1 score. Future challenges include: establishing natural disaster Q\&A benchmark datasets, fine-tuning foundation models with disaster knowledge, developing lightweight and power-efficient edge AI Disaster Q\&A applications for situations with insufficient power and communication during disasters, and addressing disaster knowledge base updates and continual learning capabilities.

</details>


### [33] [Inference-time Alignment via Sparse Junction Steering](https://arxiv.org/abs/2602.21215)
*Runyi Hu,Jie Zhang,Shiqian Zhao,Jiale Meng,Jiwei Li,Jason Zeng,Ming Wu,Michael Heinrich,Yonggang Wen,Tianwei Zhang*

Main category: cs.CL

TL;DR: 提出Sparse Inference-time Alignment (SIA)，通过仅在关键决策点进行稀疏干预，实现高效对齐，减少计算开销同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有token级对齐方法需要每个解码步骤都进行密集干预，导致计算开销大且可能损害生成质量。作者认为密集干预不必要，关键是在生成轨迹的关键决策点进行稀疏干预。

Method: 提出SIA方法，识别生成轨迹中的高熵关键决策点（junction），仅在这些点引入对齐相关的奖励信号进行干预，而不是每个token都干预。

Result: 实验表明，仅干预20%-80%的token就能实现优越的对齐-效率权衡。对于Qwen3等强基础模型，仅干预20%的token就能匹配甚至超越经过大量后训练的指令模型。稀疏性使计算成本降低高达6倍。

Conclusion: 稀疏推理时对齐方法证明了密集干预不必要，通过在关键决策点进行稀疏干预，既能实现有效对齐，又能减少计算开销并更好地保持模型的固有分布。

Abstract: Token-level steering has emerged as a pivotal approach for inference-time alignment, enabling fine grained control over large language models by modulating their output distributions without parameter updates. While effective, existing methods rely on dense intervention at every decoding step. This persistent manipulation not only incurs substantial computational overhead but also risks compromising generation quality by excessively drifting from the model's intrinsic distribution. In this work, we show that dense intervention is unnecessary and propose Sparse Inference time Alignment (SIA), which performs sparse junction steering by intervening only at critical decision points along the generation trajectory. Our key insight is that high entropy junctions mark pivotal decision points in the generation trajectory and are particularly susceptible to misalignment, indicating the need to introduce alignment related reward signals at these points. Extensive experiments across different model families and alignment objectives show that steering only 20% to 80% of tokens achieves superior alignment-efficiency trade offs. For strong base models such as Qwen3, intervening on as few as 20% of tokens matches or even surpasses heavily post-trained instruct models. This sparsity enables stronger guidance while better preserving the model's native distribution, integrates seamlessly with search based methods such as Best-of-N, and reduces computational cost by up to 6x.

</details>


### [34] [EQ-5D Classification Using Biomedical Entity-Enriched Pre-trained Language Models and Multiple Instance Learning](https://arxiv.org/abs/2602.21216)
*Zhyar Rzgar K Rostam,Gábor Kertész*

Main category: cs.CL

TL;DR: 使用预训练语言模型结合生物医学实体信息，通过多实例学习方法提高EQ-5D检测准确率，显著优于传统方法


<details>
  <summary>Details</summary>
Motivation: EQ-5D是评估健康相关生活质量的标准工具，但在系统文献综述中，手动筛选大量使用EQ-5D的文献耗时、易错且不一致，需要自动化解决方案

Method: 微调通用（BERT）和领域特定（SciBERT, BioBERT）预训练语言模型，结合scispaCy提取的生物医学实体信息，采用多实例学习（MIL）和注意力池化方法，在句子和文献级别进行EQ-5D检测

Result: F1分数达到0.82，在文献级别实现近乎完美的召回率，显著超过传统的词袋模型和近期报道的预训练语言模型基线

Conclusion: 实体信息增强显著提高了领域适应性和模型泛化能力，能够实现更准确的系统综述自动化筛选

Abstract: The EQ-5D (EuroQol 5-Dimensions) is a standardized instrument for the evaluation of health-related quality of life. In health economics, systematic literature reviews (SLRs) depend on the correct identification of publications that use the EQ-5D, but manual screening of large volumes of scientific literature is time-consuming, error-prone, and inconsistent. In this study, we investigate fine-tuning of general-purpose (BERT) and domain-specific (SciBERT, BioBERT) pre-trained language models (PLMs), enriched with biomedical entity information extracted through scispaCy models for each statement, to improve EQ-5D detection from abstracts. We conduct nine experimental setups, including combining three scispaCy models with three PLMs, and evaluate their performance at both the sentence and study levels. Furthermore, we explore a Multiple Instance Learning (MIL) approach with attention pooling to aggregate sentence-level information into study-level predictions, where each abstract is represented as a bag of enriched sentences (by scispaCy). The findings indicate consistent improvements in F1-scores (reaching 0.82) and nearly perfect recall at the study-level, significantly exceeding classical bag-of-words baselines and recently reported PLM baselines. These results show that entity enrichment significantly improves domain adaptation and model generalization, enabling more accurate automated screening in systematic reviews.

</details>


### [35] [Applied Sociolinguistic AI for Community Development (ASA-CD): A New Scientific Paradigm for Linguistically-Grounded Social Intervention](https://arxiv.org/abs/2602.21217)
*S M Ruhul Alam,Rifa Ferzana*

Main category: cs.CL

TL;DR: 提出ASA-CD新范式，通过语言AI解决社区发展问题，包含语言生物标志物、发展导向NLP和五阶段干预协议


<details>
  <summary>Details</summary>
Motivation: 传统AI方法在社区发展应用中缺乏语言基础和价值对齐，需要建立统一框架来通过语言AI解决社区挑战，促进社区赋权

Method: 提出ASA-CD范式，包含三个核心贡献：1) 语言生物标志物作为话语碎片化的计算指标；2) 发展导向NLP，优先考虑集体结果的AI优化范式；3) 标准化的五阶段话语干预协议

Result: 概念验证研究显示排他性语言与负面情绪存在系统性关联，并模拟了干预带来的改善效果。ASA-CD为可扩展、价值对齐的AI提供了统一的方法论、伦理和实证框架

Conclusion: ASA-CD为社区赋权服务提供了创新的语言AI范式，将语言分析、AI优化和结构化干预相结合，为社区发展挑战提供了系统化解决方案

Abstract: This paper establishes Applied Sociolinguistic AI for Community Development (ASA-CD) as a novel scientific paradigm for addressing community challenges through linguistically grounded, AI-enabled intervention. ASA-CD introduces three key contributions: (1) linguistic biomarkers as computational indicators of discursive fragmentation; (2) development-aligned natural language processing (NLP), an AI optimisation paradigm prioritising collective outcomes; and (3) a standardised five-phase protocol for discursive intervention. A proof-of-concept study, incorporating real-world and synthetic corpora, demonstrates systematic associations between exclusionary language and negative sentiment and simulates intervention-based improvements. ASA-CD provides a unified methodological, ethical and empirical framework for scalable, value-aligned AI in the service of community empowerment.

</details>


### [36] [EPSVec: Efficient and Private Synthetic Data Generation via Dataset Vectors](https://arxiv.org/abs/2602.21218)
*Amin Banayeeanzade,Qingchuan Yang,Deqing Fu,Spencer Hong,Erin Babinsky,Alfy Samuel,Anoop Kumar,Robin Jia,Sai Praneeth Karimireddy*

Main category: cs.CL

TL;DR: EPSVec是一种高效的差分隐私文本生成方法，通过提取和净化数据集向量来引导LLM生成，将隐私预算与生成过程解耦，在低数据场景下仍能保持高质量。


<details>
  <summary>Details</summary>
Motivation: 许多有价值的数据集具有敏感性无法自由共享，现有隐私文本生成方法效率低下：数据密集、计算缓慢，需要大量私有语料或批量大小才能达到可用质量。

Method: 使用数据集向量（激活空间中的方向）捕捉私有数据与公共先验之间的分布差异，一次性提取和净化引导向量，然后进行标准解码，将隐私预算与生成解耦。利用预训练基础模型和固定样本提示增强生成多样性和保真度。

Result: EPSVec在分布对齐和下游效用方面优于现有基线，特别是在低数据场景下，同时显著减少计算开销。能够生成任意数量的合成样本而无需额外隐私成本。

Conclusion: EPSVec提供了一种轻量级、高效的差分隐私文本生成方案，解决了现有方法在低数据场景下的效率和质量问题，为敏感数据的合成生成提供了实用替代方案。

Abstract: High-quality data is essential for modern machine learning, yet many valuable corpora are sensitive and cannot be freely shared. Synthetic data offers a practical substitute for downstream development, and large language models (LLMs) have emerged as powerful engines for generating it. However, existing private text generation methods are severely inefficient: they are data-intensive, computationally slow, and often require large private corpora or batch sizes to achieve usable quality. We introduce EPSVec, a differentially-private lightweight alternative that steers LLM generation using *dataset vectors*--directions in activation space that capture the distributional gap between private data and public priors. EPSVec extracts and sanitizes steering vectors just once and then performs standard decoding. This decouples the privacy budget from generation, enabling arbitrarily many synthetic samples without additional privacy cost and yielding strong fidelity even in low-data regimes. Furthermore, we enhance our method by utilizing pretrained (base) models and introducing fixed-shot prompting to boost generation diversity and fidelity. Our experiments demonstrate that EPSVec outperforms existing baselines in distributional alignment and downstream utility, particularly in low-data regimes, while significantly reducing computational overhead.

</details>


### [37] [Reasoning-Based Personalized Generation for Users with Sparse Data](https://arxiv.org/abs/2602.21219)
*Bo Ni,Branislav Kveton,Samyadeep Basu,Subhojyoti Mukherjee,Leyao Wang,Franck Dernoncourt,Sungchul Kim,Seunghyun Yoon,Zichao Wang,Ruiyi Zhang,Puneet Mathur,Jihyung Kil,Jiuxiang Gu,Nedim Lipka,Yu Wang,Ryan A. Rossi,Tyler Derr*

Main category: cs.CL

TL;DR: GraSPer是一个基于图的稀疏个性化推理框架，通过预测用户未来可能交互的项目并生成相关文本来增强稀疏用户上下文，从而改善LLM个性化生成效果。


<details>
  <summary>Details</summary>
Motivation: 现实世界中用户通常只有稀疏的交互历史（如冷启动用户、新注册客户），有限的个人上下文会损害基于LLM的个性化生成效果，需要解决稀疏上下文下的个性化文本生成挑战。

Method: GraSPer框架包含三个步骤：1）通过预测用户未来可能交互的项目来增强用户上下文；2）通过推理对齐为这些交互生成文本以丰富增强上下文；3）基于真实和合成历史生成个性化输出，确保与用户风格和偏好对齐。

Result: 在三个基准个性化生成数据集上的广泛实验表明，GraSPer取得了显著的性能提升，在稀疏用户上下文设置下大幅改善了个性化效果。

Conclusion: GraSPer通过图基增强和推理对齐有效解决了稀疏用户上下文下的LLM个性化生成问题，为冷启动用户和新用户提供了有效的个性化解决方案。

Abstract: Large Language Model (LLM) personalization holds great promise for tailoring responses by leveraging personal context and history. However, real-world users usually possess sparse interaction histories with limited personal context, such as cold-start users in social platforms and newly registered customers in online E-commerce platforms, compromising the LLM-based personalized generation. To address this challenge, we introduce GraSPer (Graph-based Sparse Personalized Reasoning), a novel framework for enhancing personalized text generation under sparse context. GraSPer first augments user context by predicting items that the user would likely interact with in the future. With reasoning alignment, it then generates texts for these interactions to enrich the augmented context. In the end, it generates personalized outputs conditioned on both the real and synthetic histories, ensuring alignment with user style and preferences. Extensive experiments on three benchmark personalized generation datasets show that GraSPer achieves significant performance gain, substantially improving personalization in sparse user context settings.

</details>


### [38] [Field-Theoretic Memory for AI Agents: Continuous Dynamics for Context Preservation](https://arxiv.org/abs/2602.21220)
*Subhadip Mitra*

Main category: cs.CL

TL;DR: 提出一种基于连续场理论的AI智能体记忆系统，将记忆视为偏微分方程控制的语义场而非离散数据库条目，在长上下文基准测试中取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统AI智能体记忆系统通常将信息存储为离散的数据库条目，这种离散化表示在处理长上下文、多会话推理和记忆交互时存在局限性。需要一种更自然、连续的表示方法来模拟记忆的扩散、衰减和交互过程。

Method: 采用经典场论方法，将记忆视为连续语义场，通过偏微分方程控制记忆的扩散（在语义空间中传播）、热力学衰减（基于重要性）和场耦合（多智能体场景中的交互）。

Result: 在LongMemEval基准测试中：多会话推理F1提升116%（p<0.01, d=3.06），时序推理提升43.8%（p<0.001, d=9.21），知识更新检索召回率提升27.8%（p<0.001, d=5.00）。多智能体实验通过场耦合实现接近完美的集体智能（>99.8%）。

Conclusion: 场论方法为AI智能体记忆系统提供了有效的连续表示框架，显著提升了长上下文处理、多会话推理和集体智能能力，为未来智能体记忆系统设计开辟了新方向。

Abstract: We present a memory system for AI agents that treats stored information as continuous fields governed by partial differential equations rather than discrete entries in a database. The approach draws from classical field theory: memories diffuse through semantic space, decay thermodynamically based on importance, and interact through field coupling in multi-agent scenarios. We evaluate the system on two established long-context benchmarks: LoCoMo (ACL 2024) with 300-turn conversations across 35 sessions, and LongMemEval (ICLR 2025) testing multi-session reasoning over 500+ turns. On LongMemEval, the field-theoretic approach achieves significant improvements: +116% F1 on multi-session reasoning (p<0.01, d= 3.06), +43.8% on temporal reasoning (p<0.001, d= 9.21), and +27.8% retrieval recall on knowledge updates (p<0.001, d= 5.00). Multi-agent experiments show near-perfect collective intelligence (>99.8%) through field coupling. Code is available at github.com/rotalabs/rotalabs-fieldmem.

</details>


### [39] [Task-Aware LoRA Adapter Composition via Similarity Retrieval in Vector Databases](https://arxiv.org/abs/2602.21222)
*Riya Adsul,Balachandra Devarangadi Sunil,Isha Nalawade,Sudharshan Govindan*

Main category: cs.CL

TL;DR: 提出基于向量数据库检索的动态LoRA适配器组合框架，通过检索相似训练示例并加权融合相关适配器，实现零样本跨任务泛化，无需额外训练检索器。


<details>
  <summary>Details</summary>
Motivation: 虽然LoRA等参数高效微调方法能实现大语言模型的任务特定适配，但高效组合多个专用适配器以处理未见任务仍具挑战性。需要一种能实现零样本跨任务泛化的动态适配器组合方法。

Method: 构建任务感知向量数据库，嵌入来自22个数据集的训练示例。推理时检索最相似训练示例，通过nucleus采样计算任务相似度分布，使用检索加权融合策略动态合并相关LoRA适配器。评估了线性、拼接、TIES和幅度剪枝四种合并方法。

Result: 数据集中心检索方法常匹配或超越单独微调的任务特定适配器性能。线性合并在PIQA上达到70.95%，在RTE上达到77.62%，显著优于单任务基线（分别为46%和52%）。框架无需额外检索器训练，使用冻结嵌入。

Conclusion: 基于检索的动态合并为可扩展的参数高效多任务学习提供了有前景的方向，无需为每个新任务进行完整模型重训练，实现了高效且可解释的适配器组合。

Abstract: Parameter efficient fine tuning methods like LoRA have enabled task specific adaptation of large language models, but efficiently composing multiple specialized adapters for unseen tasks remains challenging. We present a novel framework for dynamic LoRA adapter composition that leverages similarity retrieval in vector databases to enable zero-shot generalization across diverse NLP tasks. Our approach constructs a task-aware vector database by embedding training examples from 22 datasets spanning commonsense reasoning, question answering, natural language inference, and sentiment analysis. At inference time, we retrieve the most similar training examples, compute task similarity distributions via nucleus sampling, and dynamically merge relevant LoRA adapters using retrieval weighted fusion strategies. We evaluated four merging methods Linear, Concatenation, TIES, and Magnitude Prune demonstrating that our dataset centric retrieval approach often matches or exceeds the performance of individually fine-tuned task-specific adapters. Notably, Linear merging achieves 70.95% on PIQA and 77.62% on RTE, substantially outperforming single-task baselines (46% and 52%, respectively). Our framework requires no additional retriever training, operates with frozen embeddings, and enables efficient, interpretable adapter composition. These results suggest that retrieval based dynamic merging offers a promising direction for scalable, parameter-efficient multitask learning without requiring full model retraining for each new task.

</details>


### [40] [Measuring Pragmatic Influence in Large Language Model Instructions](https://arxiv.org/abs/2602.21223)
*Yilin Geng,Omri Abend,Eduard Hovy,Lea Frermann*

Main category: cs.CL

TL;DR: 论文研究提示语中的"语用框架"如何影响大语言模型行为，提出分解框架与指令、分类400种框架策略、基于优先级测量的方法，发现框架能系统性地改变模型对指令的优先级判断。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要将语用框架用于提示优化或安全漏洞探测，但未将其作为指令遵循系统的可测量属性。如何系统测量框架对模型行为的影响仍具挑战，需要控制隔离框架线索。

Method: 提出包含三个新组件的框架：1) 指令-框架分解，分离框架上下文与任务规范；2) 分类法，将400个框架实例组织为4个机制簇中的13种策略；3) 基于优先级的测量，通过观察指令优先级变化量化影响。

Result: 在五个不同家族和大小的LLM中，影响机制导致指令优先级的一致性和结构化变化，使模型从基线中立性转向偏向框架化指令。框架影响具有可预测的模式。

Conclusion: 本研究确立了语用框架作为指令遵循系统中可测量和可预测的因素，为理解模型如何解释人类指令提供了新视角。

Abstract: It is not only what we ask large language models (LLMs) to do that matters, but also how we prompt. Phrases like "This is urgent" or "As your supervisor" can shift model behavior without altering task content. We study this effect as pragmatic framing, contextual cues that shape directive interpretation rather than task specification. While prior work exploits such cues for prompt optimization or probes them as security vulnerabilities, pragmatic framing itself has not been treated as a measurable property of instruction following. Measuring this influence systematically remains challenging, requiring controlled isolation of framing cues. We introduce a framework with three novel components: directive-framing decomposition separating framing context from task specification; a taxonomy organizing 400 instantiations of framing into 13 strategies across 4 mechanism clusters; and priority-based measurement that quantifies influence through observable shifts in directive prioritization. Across five LLMs of different families and sizes, influence mechanisms cause consistent and structured shifts in directive prioritization, moving models from baseline impartiality toward favoring the framed directive. This work establishes pragmatic framing as a measurable and predictable factor in instruction-following systems.

</details>


### [41] [Make Every Draft Count: Hidden State based Speculative Decoding](https://arxiv.org/abs/2602.21224)
*Yuetao Chen,Xuliang Wang,Xinzhou Zheng,Ming Li,Peng Wang,Hong Xu*

Main category: cs.CL

TL;DR: 提出一种新型推测解码系统，将丢弃的草稿转换为可重用令牌，通过隐藏状态级自回归预测和延迟令牌信息集成，实现计算浪费的回收利用。


<details>
  <summary>Details</summary>
Motivation: 传统推测解码中，大多数草稿令牌验证失败被丢弃，导致计算浪费。需要回收这些浪费的计算，提高计算效率。

Method: 1) 基于自回归隐藏状态的草稿模型架构；2) 高效令牌信息注入机制，构建高质量草稿令牌树并支持从验证失败中重新采样；3) 消除设计中的开销以最大化硬件利用率。

Result: 相比标准推测解码，实现了最高3.3倍的加速。

Conclusion: 通过将丢弃的草稿转换为可重用令牌，显著提高了推测解码的计算效率，为LLM推理加速提供了新思路。

Abstract: Speculative decoding has emerged as a pivotal technique to accelerate LLM inference by employing a lightweight draft model to generate candidate tokens that are subsequently verified by the target model in parallel. However, while this paradigm successfully increases the arithmetic intensity of memory-bound inference, it causes significant compute inefficiency: the majority of draft tokens fail verification and are discarded, resulting in waste of computation. Motivated by the goal of recollecting this wasted computation, we propose a novel system that transforms discarded drafts into reusable tokens. Our key insight is to perform auto-regressive prediction at the hidden states level and postpone the integrating token information after the hidden states generation, so the draft hidden states are not contaminated by incorrect tokens, enabling hidden state reuse. To implement such a system, first we introduce a draft model architecture based on auto-regressive hidden states, which preserves richer semantics than token-based drafters to facilitate draft repurposing. Second, we design an efficient token information injection mechanism that leverages our specialized draft model to construct high-quality draft token trees and enables resampling tokens from verification failures. Third, we eliminate the overhead hidden in our design to further maximize hardware utilization. We conducted extensive evaluations against various baselines, demonstrating up to a 3.3x speedup against standard speculative decoding.

</details>


### [42] [Architecture-Agnostic Curriculum Learning for Document Understanding: Empirical Evidence from Text-Only and Multimodal](https://arxiv.org/abs/2602.21225)
*Mohammed Hamdan,Vincenzo Dentamaro,Giuseppe Pirlo,Mohamed Cheriet*

Main category: cs.CL

TL;DR: 渐进式数据调度（逐步增加训练数据）可减少约33%训练时间，对容量受限模型有额外性能提升，但对多模态模型或简单任务无显著优势。


<details>
  <summary>Details</summary>
Motivation: 研究渐进式数据调度（课程学习策略）在不同架构文档理解模型中的效率增益是否一致，并分离课程效应与计算减少的影响。

Method: 使用BERT（文本模型）和LayoutLMv3（多模态模型）在FUNSD和CORD数据集上评估渐进式调度（33%→67%→100%数据）。引入匹配计算基线（Standard-7）控制总梯度更新，并进行调度消融实验（渐进、两阶段、反向、随机）。

Result: 1. 渐进调度减少约33%训练时间（6.67→10.0有效epoch当量）；2. 在FUNSD上，BERT显著优于匹配基线（ΔF1=+0.023, p=0.022），但LayoutLMv3无优势（p=0.621）；3. 在CORD上所有条件收敛到相同性能（F1≥0.947）；4. 调度消融显示效率增益源于数据量减少而非顺序。

Conclusion: 渐进式调度是跨模型家族可靠的计算减少策略，其课程特定收益取决于模型容量与任务复杂度的交互：容量受限模型在复杂任务中受益，而多模态模型或简单任务无额外优势。

Abstract: We investigate whether progressive data scheduling -- a curriculum learning strategy that incrementally increases training data exposure (33\%$\rightarrow$67\%$\rightarrow$100\%) -- yields consistent efficiency gains across architecturally distinct document understanding models. By evaluating BERT (text-only, 110M parameters) and LayoutLMv3 (multimodal, 126M parameters) on the FUNSD and CORD benchmarks, we establish that this schedule reduces wall-clock training time by approximately 33\%, commensurate with the reduction from 6.67 to 10.0 effective epoch-equivalents of data. To isolate curriculum effects from compute reduction, we introduce matched-compute baselines (Standard-7) that control for total gradient updates. On the FUNSD dataset, the curriculum significantly outperforms the matched-compute baseline for BERT ($Δ$F1 = +0.023, $p=0.022$, $d_z=3.83$), constituting evidence for a genuine scheduling benefit in capacity-constrained models. In contrast, no analogous benefit is observed for LayoutLMv3 ($p=0.621$), whose multimodal representations provide sufficient inductive bias. On the CORD dataset, all conditions converge to equivalent F1 scores ($\geq$0.947) irrespective of scheduling, indicating a performance ceiling. Schedule ablations comparing progressive, two-phase, reverse, and random pacing confirm that the efficiency gain derives from reduced data volume rather than ordering. Taken together, these findings demonstrate that progressive scheduling is a reliable compute-reduction strategy across model families, with curriculum-specific benefits contingent on the interaction between model capacity and task complexity.

</details>


### [43] [IslamicLegalBench: Evaluating LLMs Knowledge and Reasoning of Islamic Law Across 1,200 Years of Islamic Pluralist Legal Traditions](https://arxiv.org/abs/2602.21226)
*Ezieddin Elmahjub,Junaid Qadir,Abdullah Mushtaq,Rafay Naeem,Ibrahim Ghaznavi,Waleed Iqbal*

Main category: cs.CL

TL;DR: 伊斯兰法律基准测试显示，当前大语言模型在伊斯兰法学推理方面存在严重缺陷，最佳模型正确率仅68%，幻觉率21%，无法可靠提供宗教指导。


<details>
  <summary>Details</summary>
Motivation: 随着数百万穆斯林使用GPT、Claude和DeepSeek等大语言模型寻求宗教指导，需要评估这些AI系统是否能够可靠地进行伊斯兰法律推理。

Method: 引入伊斯兰法律基准测试(IslamicLegalBench)，涵盖七个伊斯兰法学派别，包含718个实例和13个不同复杂度的任务，评估了九个最先进的大语言模型。

Result: 模型表现严重不足：最佳模型正确率仅68%，幻觉率21%；多个模型正确率低于35%，幻觉率超过55%。少量样本提示效果有限，仅改善2个模型且提升不足1%。中等复杂度任务错误率最高，而高复杂度任务通过语义推理表现出表面能力。虚假前提检测显示危险顺从性，6个模型接受误导性假设的比例超过40%。

Conclusion: 基于提示的方法无法弥补基础知识的缺失，伊斯兰法律基准测试为评估AI中的伊斯兰法律推理提供了首个系统框架，揭示了日益依赖精神指导工具中的关键缺陷。

Abstract: As millions of Muslims turn to LLMs like GPT, Claude, and DeepSeek for religious guidance, a critical question arises: Can these AI systems reliably reason about Islamic law? We introduce IslamicLegalBench, the first benchmark evaluating LLMs across seven schools of Islamic jurisprudence, with 718 instances covering 13 tasks of varying complexity. Evaluation of nine state-of-the-art models reveals major limitations: the best model achieves only 68% correctness with 21% hallucination, while several models fall below 35% correctness and exceed 55% hallucination. Few-shot prompting provides minimal gains, improving only 2 of 9 models by >1%. Moderate-complexity tasks requiring exact knowledge show the highest errors, whereas high-complexity tasks display apparent competence through semantic reasoning. False premise detection indicates risky sycophancy, with 6 of 9 models accepting misleading assumptions at rates above 40%. These results highlight that prompt-based methods cannot compensate for missing foundational knowledge. IslamicLegalBench offers the first systematic framework to evaluate Islamic legal reasoning in AI, revealing critical gaps in tools increasingly relied on for spiritual guidance.

</details>


### [44] [Budget-Aware Agentic Routing via Boundary-Guided Training](https://arxiv.org/abs/2602.21227)
*Caiqi Zhang,Menglin Xia,Xuchao Zhang,Daniel Madrigal,Ankur Mallick,Samuel Kessler,Victor Ruehle,Saravan Rajmohan*

Main category: cs.CL

TL;DR: 提出预算感知的智能体路由方法，在长流程任务中动态选择便宜或昂贵模型，优化成本-成功率边界，满足严格预算限制。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型作为自主智能体执行长流程任务时，每一步都调用高能力模型成本过高。现有模型路由方法适用于单轮查询，但智能体路由是顺序、路径依赖的问题：早期错误会累积，反馈通常只在任务结束时获得，且部署需要严格的每任务支出限制。

Method: 提出边界引导训练：利用两个边界策略（总是小模型 vs. 总是大模型）构建难度分类，在稀疏奖励下锚定学习。通过分层采样成本高效轨迹进行边界引导的监督微调数据合成预热，然后应用边界引导策略优化，结合边界相对奖励和参考引导优势，避免退化的廉价失败解决方案。

Result: 实验结果显示，该方法改进了效率边界，以显著更低的成本匹配强大的路由基线，同时展示了对严格推理时预算约束的泛化能力。

Conclusion: 这项工作建立了智能体路由的基础框架，将范式从静态模型选择转向动态、预算感知的顺序决策制定。

Abstract: As large language models (LLMs) evolve into autonomous agents that execute long-horizon workflows, invoking a high-capability model at every step becomes economically unsustainable. While model routing is effective for single-turn queries, agentic routing is a sequential, path-dependent problem: early mistakes compound, feedback is often at the end of the episode, and deployments often demand strict per-task spending limits. We propose Budget-Aware Agentic Routing, which selects between a cheap and an expensive model at each step to optimize the cost--success frontier and to operate under strict per-task budgets. We propose Boundary-Guided Training, which leverages two boundary policies (always-small vs.\ always-large) to build a difficulty taxonomy and to anchor learning under sparse rewards. Our approach warms start with boundary-guided SFT data synthesis via stratified sampling of cost-efficient trajectories, then applies Boundary-Guided Policy Optimization (BoPO), combining boundary-relative rewards with a reference-guided advantage to avoid degenerate cheap-failure solutions. Experiment results show that our method improves the efficiency frontier, matching strong routing baselines at substantially lower cost while demonstrating generalization to strict inference-time budget constraints. Overall, our work establishes a foundational framework for agentic routing, shifting the paradigm from static model selection to dynamic, budget-aware sequential decision-making.

</details>


### [45] [Structured Prompt Language: Declarative Context Management for LLMs](https://arxiv.org/abs/2602.21257)
*Wen G. Gong*

Main category: cs.CL

TL;DR: SPL是一种声明式SQL风格语言，将LLM视为生成式知识库，提供显式token预算管理、自动查询优化、RAG集成和弹性代理管道，显著减少prompt模板代码并实现跨平台成本优化。


<details>
  <summary>Details</summary>
Motivation: 当前LLM应用开发存在prompt模板代码冗余、token管理复杂、跨模型成本差异大、缺乏统一声明式框架等问题，需要一种类似SQL的标准化语言来简化LLM应用开发和管理。

Method: 设计了SPL声明式语言，包含WITH BUDGET/LIMIT token管理、自动查询优化器、EXPLAIN透明性、RAG集成；扩展为SPL-flow代理管道，支持三级回退策略；开发了Text2SPL、MoM路由、逻辑分块等五个扩展。

Result: SPL平均减少65%的prompt模板代码，能提前显示68倍的成本差异，同一.spl脚本可在OpenRouter上以$0.002运行或在本地Ollama零边际成本运行；提供正式EBNF语法和两个Python包。

Conclusion: SPL为LLM应用开发提供了统一的声明式框架，显著简化开发流程，实现成本透明化和跨平台兼容性，为构建可扩展、可维护的LLM应用提供了新范式。

Abstract: We present SPL (Structured Prompt Language), a declarative SQL-inspired language that treats large language models as generative knowledge bases and their context windows as constrained resources. SPL provides explicit WITH BUDGET/LIMIT token management, an automatic query optimizer, EXPLAIN transparency analogous to SQL's EXPLAIN ANALYZE, and native integration of retrieval-augmented generation (RAG) and persistent memory in a single declarative framework. SPL-flow extends SPL into resilient agentic pipelines with a three-tier provider fallback strategy (Ollama -> OpenRouter -> self-healing retry) fully transparent to the .spl script. Five extensions demonstrate the paradigm's breadth: (1) Text2SPL (multilingual NL->SPL translation); (2) Mixture-of-Models (MoM) routing that dispatches each PROMPT to a domain-specialist model at runtime; (3) Logical Chunking, an intelligent strategy for documents exceeding a single context window--expressed naturally through SPL's existing CTE syntax with no new constructs, decomposing a large query into a Map-Reduce pipeline that reduces attention cost from O(N^2) to O(N^2/k) and runs identically on cloud (parallel) or local hardware (sequential); (4) SPL-flow, a declarative agentic orchestration layer with resilient three-tier provider fallback; and (5) BENCHMARK for parallel multi-model comparison with automatic winner persistence. We provide a formal EBNF grammar, two pip-installable Python packages (spl-llm, spl-flow), and comparison against Prompty, DSPy, and LMQL. SPL reduces prompt boilerplate by 65% on average, surfaces a 68x cost spread across model tiers as a pre-execution signal, and runs the identical .spl script at $0.002 on OpenRouter or at zero marginal cost on a local Ollama instance--without modification.

</details>


### [46] [ImpRIF: Stronger Implicit Reasoning Leads to Better Complex Instruction Following](https://arxiv.org/abs/2602.21228)
*Yuancheng Yang,Lin Yang,Xu Wang,Chao Tong,Haihua Yang*

Main category: cs.CL

TL;DR: 提出ImpRIF方法，通过将复杂指令形式化为可验证推理图，增强大语言模型对隐含推理指令的理解，从而提升复杂指令跟随能力。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型应用日益复杂，对鲁棒复杂指令跟随能力的需求增长。作者认为深入理解指令本身，特别是隐藏在字里行间的潜在推理结构，对提升指令跟随至关重要。因此针对涉及隐含推理、复杂逻辑关系和多约束依赖的复杂指令进行研究。

Method: 提出ImpRIF方法：1) 将复杂指令形式化为可验证推理图，支持程序化验证和图驱动的思维链推理；2) 基于此形式化合成大规模单轮和多轮数据；3) 提出图推理微调；4) 应用强化学习显式训练模型沿图推理。

Result: 在五个复杂指令跟随基准测试中，模型显著优于其基础模型。结果表明增强隐含推理能力可以显著改善复杂指令跟随。

Conclusion: 增强大语言模型对隐含推理指令的理解能有效提升复杂指令跟随能力。ImpRIF方法通过将指令形式化为推理图并相应训练模型，取得了显著效果。该项目将在近期开源。

Abstract: As applications of large language models (LLMs) become increasingly complex, the demand for robust complex instruction following capabilities is growing accordingly. We argue that a thorough understanding of the instruction itself, especially the latent reasoning structure embedded between the lines, is crucial for improving instruction following. Therefore we target complex instructions that involve implicit reasoning, intricate logical relations, and multi-constraint dependencies. We propose ImpRIF, a method to enhance LLMs' understanding of implicit reasoning instructions, thereby improving its ability to follow complex instructions. We formalize such instructions as verifiable reasoning graphs, enabling programmatic verification and graph-driven chain-of-thought reasoning. Based on this formulation, we synthesize large-scale single- and multi-turn data, propose fine-tuning with graph reasoning, and apply reinforcement learning to explicitly train models to reason along the graph. On five complex instruction following benchmarks, our models substantially outperform their base models. These results demonstrate that enhancing implicit reasoning capabilities can significantly improve complex instruction following. This project will be open-sourced in the near future.

</details>


### [47] [TRACE: Trajectory-Aware Comprehensive Evaluation for Deep Research Agents](https://arxiv.org/abs/2602.21230)
*Yanyu Chen,Jiyue Jiang,Jiahong Liu,Yifei Zhang,Xiao Guo,Irwin King*

Main category: cs.CL

TL;DR: TRACE框架通过轨迹感知的全面评估方法，解决深度研究代理评估中的"高分幻觉"问题，提供更细粒度的代理性能分析。


<details>
  <summary>Details</summary>
Motivation: 当前深度研究代理评估存在两个主要问题：1) 依赖单一指标（如Pass@1）导致"高分幻觉"，忽略了推理过程的质量、效率和合理性；2) 静态基准无法量化关键属性如鲁棒性和潜在能力。

Method: 提出TRACE框架，包含：1) 分层轨迹效用函数，量化过程效率和认知质量（包括证据基础）；2) 支架式能力评估协议，通过测量成功所需的最小指导量来量化代理的潜在能力；3) 配套的DeepResearch-Bench基准，具有可控复杂度。

Result: 实验显示TRACE能够提供细粒度的排名，揭示代理在准确性、效率和鲁棒性之间的关键权衡，这些权衡完全被单一指标所忽略。

Conclusion: TRACE框架通过全面评估整个问题解决轨迹，解决了当前深度研究代理评估的局限性，提供了更准确、更全面的代理性能评估方法。

Abstract: The evaluation of Deep Research Agents is a critical challenge, as conventional outcome-based metrics fail to capture the nuances of their complex reasoning. Current evaluation faces two primary challenges: 1) a reliance on singular metrics like Pass@1, creating a "high-score illusion" that ignores the quality, efficiency, and soundness of the reasoning process; and 2) the failure of static benchmarks to quantify crucial attributes like robustness and latent capability. To address these gaps, we introduce TRACE (Trajectory-Aware Comprehensive Evaluation), a framework that holistically assesses the entire problem-solving trajectory. To counter the "high-score illusion", we propose a Hierarchical Trajectory Utility Function that quantifies process efficiency and cognitive quality, including evidence grounding, alongside accuracy. To measure deeper attributes, TRACE introduces a Scaffolded Capability Assessment protocol, quantifying an agent's latent ability by determining the minimum guidance needed for success. Our contributions include the TRACE framework, its novel metrics, and the accompanying DeepResearch-Bench with controllable complexity. Experiments show TRACE delivers a granular ranking that uncovers critical trade-offs between agent accuracy, efficiency, and robustness entirely missed by singular metrics.

</details>


### [48] [Under the Influence: Quantifying Persuasion and Vigilance in Large Language Models](https://arxiv.org/abs/2602.21262)
*Sasha Robinson,Kerem Oktar,Katherine M. Collins,Ilia Sucholutsky,Kelsey R. Allen*

Main category: cs.CL

TL;DR: LLMs在说服和警惕能力上是可分离的，即使明确提示存在欺骗可能，模型也难以有效识别恶意建议。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs越来越多地应用于高风险决策领域，需要理解它们作为顾问时引入的风险。现有研究孤立地考察了LLMs的警惕（筛选信息）和说服（合成证据）能力，但缺乏对这两种能力关联性的研究。

Method: 使用Sokoban推箱子游戏作为多轮谜题解决环境，研究LLMs对其他LLM代理的说服能力以及理性警惕能力。通过设计善意和恶意的建议场景，观察模型如何应对。

Result: 发现谜题解决性能、说服能力和警惕能力在LLMs中是分离的。模型即使被明确告知可能存在欺骗，也难以检测到自己被误导。但模型会调整token使用量：面对善意建议时使用较少token推理，面对恶意建议时使用更多token，即使最终仍被说服采取导致失败的行动。

Conclusion: 这是首个研究LLMs中说服、警惕和任务性能关系的工作，表明未来AI安全研究需要独立监控这三个方面。

Abstract: With increasing integration of Large Language Models (LLMs) into areas of high-stakes human decision-making, it is important to understand the risks they introduce as advisors. To be useful advisors, LLMs must sift through large amounts of content, written with both benevolent and malicious intent, and then use this information to convince a user to take a specific action. This involves two social capacities: vigilance (the ability to determine which information to use, and which to discard) and persuasion (synthesizing the available evidence to make a convincing argument). While existing work has investigated these capacities in isolation, there has been little prior investigation of how these capacities may be linked. Here, we use a simple multi-turn puzzle-solving game, Sokoban, to study LLMs' abilities to persuade and be rationally vigilant towards other LLM agents. We find that puzzle-solving performance, persuasive capability, and vigilance are dissociable capacities in LLMs. Performing well on the game does not automatically mean a model can detect when it is being misled, even if the possibility of deception is explicitly mentioned. % as part of the prompt. However, LLMs do consistently modulate their token use, using fewer tokens to reason when advice is benevolent and more when it is malicious, even if they are still persuaded to take actions leading them to failure. To our knowledge, our work presents the first investigation of the relationship between persuasion, vigilance, and task performance in LLMs, and suggests that monitoring all three independently will be critical for future work in AI safety.

</details>


### [49] [ToolMATH: A Math Tool Benchmark for Realistic Long-Horizon Multi-Tool Reasoning](https://arxiv.org/abs/2602.21265)
*Hyeonje Choi,Jeongsoo Lee,Hyojun Lee,Jay-Yoon Lee*

Main category: cs.CL

TL;DR: ToolMATH是一个数学基础基准测试，用于评估工具增强语言模型在现实多工具环境中的表现，重点关注模型在大型重叠工具库和缺失预期能力情况下的可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有工具增强语言模型评估缺乏系统性，特别是在复杂多工具环境中。需要创建一个可控、可验证的基准来诊断模型在工具使用中的失败模式，特别是在工具冗余和功能缺失情况下的表现。

Method: 将数学问题转化为包含工具集的受控基准测试，包含约8k个问题和12k个工具。提供额外的困难集ToolMATHHard，通过工具调用和执行多步骤来评估模型可靠性。

Result: 评估发现主要失败因素是推理能力不足，导致中间结果错误积累并影响后续决策。工具冗余不仅增加噪声，还会放大早期偏差导致不可逆的执行漂移。当预期能力缺失时，干扰工具可能作为部分替代，但也可能误导模型进入无根据的工具轨迹。

Conclusion: 改进主要来自长程规划一致性和观察使用的纪律性，而非局部动作选择。ToolMATH提供了诊断工具增强代理失败模式的可操作证据，有助于识别实现鲁棒性所需的控制机制。

Abstract: We introduce \ToolMATH, a math-grounded benchmark that evaluates tool-augmented language models in realistic multi-tool environments where the output depends on calling schema-specified tools and sustaining multi-step execution. It turns math problems into a controlled, correctness-checkable benchmark with tool sets, enabling systematic evaluation of model reliability under (1) large, overlapping tool catalogs and (2) the absence of the intended capability. \ToolMATH provides actionable diagnostic evidence of failure modes in tool-augmented agents, helping identify the control mechanisms required for robustness. \ToolMATH roughly contains 8k questions and 12k tools; we provide an additional hard-set \ToolMATHHard with questions and tools. Our evaluation reveals that the key failure factor is due to the inability to reason, leading to the accumulation of intermediate results' errors and constrain later decisions. Tool-list redundancy do not simply add noise, but amplify small early deviations into irreversible execution drift. The benchmark highlights that when the intended capability is missing, distractor tools can sometimes serve as partial substitutes in solution paths, yet they can also mislead models into ungrounded tool trajectories. Finally, comparisons between tool-use protocols emphasize that improvements come less from local action selection and more from long-range plan coherence and disciplined use of observations.

</details>


### [50] [Alignment-Weighted DPO: A principled reasoning approach to improve safety alignment](https://arxiv.org/abs/2602.21346)
*Mengxuan Hu,Vivek V. Datla,Anoop Kumar,Zihan Guan,Sheng Li,Alfy Samuel,Daben Liu*

Main category: cs.CL

TL;DR: 论文提出通过推理感知的后训练增强LLM对齐鲁棒性，包括构建CoT微调数据集和Alignment-Weighted DPO方法，有效抵御越狱攻击同时保持模型实用性。


<details>
  <summary>Details</summary>
Motivation: 尽管SFT、RLHF和DPO等对齐技术提升了LLM安全性，但模型仍易受通过间接或欺骗性表述的越狱攻击。研究发现这种脆弱性源于浅层对齐机制缺乏深度推理，模型拒绝有害提示时并不真正理解为何有害。

Method: 1) 构建并发布包含实用性和安全性提示的CoT微调数据集，带有逐步推理过程；2) 提出Alignment-Weighted DPO方法，通过对推理段和最终答案段分配不同偏好权重，实现比标准DPO更精细的针对性更新。

Result: 在多个安全性和实用性基准测试中，该方法持续提升对齐鲁棒性，同时保持整体模型实用性。CoT微调使模型产生基于推理的原则性拒绝，优于标准SFT基线。

Conclusion: 通过推理感知的后训练增强对齐机制，特别是结合CoT微调和Alignment-Weighted DPO，能有效提升LLM对越狱攻击的鲁棒性，解决浅层对齐缺乏深度推理的问题。

Abstract: Recent advances in alignment techniques such as Supervised Fine-Tuning (SFT), Reinforcement Learning from Human Feedback (RLHF), and Direct Preference Optimization (DPO) have improved the safety of large language models (LLMs). However, these LLMs remain vulnerable to jailbreak attacks that disguise harmful intent through indirect or deceptive phrasing. Using causal intervention, we empirically demonstrate that this vulnerability stems from shallow alignment mechanisms that lack deep reasoning, often rejecting harmful prompts without truly understanding why they are harmful. To mitigate this vulnerability, we propose enhancing alignment through reasoning-aware post-training. We construct and release a novel Chain-of-Thought (CoT) fine-tuning dataset that includes both utility-oriented and safety-critical prompts with step-by-step rationales. Fine-tuning on this dataset encourages models to produce principled refusals grounded in reasoning, outperforming standard SFT baselines. Furthermore, inspired by failure patterns in CoT fine-tuning, we introduce Alignment-Weighted DPO, which targets the most problematic parts of an output by assigning different preference weights to the reasoning and final-answer segments. This produces finer-grained, targeted updates than vanilla DPO and improves robustness to diverse jailbreak strategies. Extensive experiments across multiple safety and utility benchmarks show that our method consistently improves alignment robustness while maintaining overall model utility.

</details>


### [51] [Small Language Models for Privacy-Preserving Clinical Information Extraction in Low-Resource Languages](https://arxiv.org/abs/2602.21374)
*Mohammadreza Ghaffarzadeh-Esfahani,Nahid Yousefian,Ebrahim Heidari-Farsani,Ali Akbar Omidvarian,Sepehr Ghahraei,Atena Farangi,AmirBahador Boroumand*

Main category: cs.CL

TL;DR: 本研究评估了在波斯语医疗转录本中提取临床特征的两步流程：先用Aya-expanse-8B进行波斯语到英语翻译，再用五个开源小语言模型进行13个临床特征的二元提取。Qwen2.5-7B-Instruct表现最佳，大模型在敏感性和MCC上优于小模型，翻译策略提高了敏感性但略微降低了特异性。


<details>
  <summary>Details</summary>
Motivation: 在低资源语言（如波斯语）中从医疗转录本提取临床信息是医疗NLP的重要挑战。研究旨在建立一种实用的、保护隐私的蓝图，在基础设施和标注资源有限的多语言临床NLP环境中部署开源小语言模型。

Method: 采用两步流程：1) 使用Aya-expanse-8B将波斯语转录本翻译为英语；2) 使用五个开源小语言模型（Qwen2.5-7B-Instruct, Llama-3.1-8B-Instruct, Llama-3.2-3B-Instruct, Qwen2.5-1.5B-Instruct, Gemma-3-1B-it）进行13个临床特征的二元提取。使用少量样本提示策略，无需微调。在1,221个匿名波斯语转录本上评估，使用宏平均F1分数、马修斯相关系数、敏感性和特异性等指标。

Result: Qwen2.5-7B-Instruct获得最高整体性能（中位数宏F1：0.899；MCC：0.797），Gemma-3-1B-it表现最弱。较大模型（7B-8B参数）在敏感性和MCC上始终优于较小模型。翻译策略提高了敏感性，减少了缺失输出，提升了对类别不平衡鲁棒的指标，但略微降低了特异性和精确度。生理症状提取可靠，而心理抱怨、行政请求和复杂躯体特征仍具挑战性。

Conclusion: 研究为在基础设施和标注资源有限的多语言临床NLP环境中部署开源小语言模型提供了实用的、保护隐私的蓝图。强调了在敏感的医疗应用中联合优化模型规模和输入语言策略的重要性，翻译策略可提高敏感性但需权衡特异性损失。

Abstract: Extracting clinical information from medical transcripts in low-resource languages remains a significant challenge in healthcare natural language processing (NLP). This study evaluates a two-step pipeline combining Aya-expanse-8B as a Persian-to-English translation model with five open-source small language models (SLMs) -- Qwen2.5-7B-Instruct, Llama-3.1-8B-Instruct, Llama-3.2-3B-Instruct, Qwen2.5-1.5B-Instruct, and Gemma-3-1B-it -- for binary extraction of 13 clinical features from 1,221 anonymized Persian transcripts collected at a cancer palliative care call center. Using a few-shot prompting strategy without fine-tuning, models were assessed on macro-averaged F1-score, Matthews Correlation Coefficient (MCC), sensitivity, and specificity to account for class imbalance. Qwen2.5-7B-Instruct achieved the highest overall performance (median macro-F1: 0.899; MCC: 0.797), while Gemma-3-1B-it showed the weakest results. Larger models (7B--8B parameters) consistently outperformed smaller counterparts in sensitivity and MCC. A bilingual analysis of Aya-expanse-8B revealed that translating Persian transcripts to English improved sensitivity, reduced missing outputs, and boosted metrics robust to class imbalance, though at the cost of slightly lower specificity and precision. Feature-level results showed reliable extraction of physiological symptoms across most models, whereas psychological complaints, administrative requests, and complex somatic features remained challenging. These findings establish a practical, privacy-preserving blueprint for deploying open-source SLMs in multilingual clinical NLP settings with limited infrastructure and annotation resources, and highlight the importance of jointly optimizing model scale and input language strategy for sensitive healthcare applications.

</details>


### [52] [Beyond Subtokens: A Rich Character Embedding for Low-resource and Morphologically Complex Languages](https://arxiv.org/abs/2602.21377)
*Felix Schneider,Maria Gogolev,Sven Sickert,Joachim Denzler*

Main category: cs.CL

TL;DR: 提出Rich Character Embeddings (RCE)，直接从字符字符串计算词向量，结合语义和句法信息，并提出了transformer和卷积的混合模型，可用于替代现有模型中的字典和子词嵌入。


<details>
  <summary>Details</summary>
Motivation: 现有基于分词和子词分词的模型（如word2vec、BERT、GPT）在输入表示方面有局限，无法充分捕捉正字法相似性和形态变化，特别是在高度屈折和资源匮乏的语言中。

Method: 提出Rich Character Embeddings (RCE)，直接从字符字符串计算词向量，整合语义和句法信息。还提出了结合transformer和卷积机制的混合模型。这些向量表示可以作为现有模型架构中基于字典和子词分词的词嵌入的替代品。

Result: 在SWAG、屈折语言的变格预测、多种语言的隐喻和交错法检测等任务上评估。实验表明，在有限数据下使用OddOneOut和TopK指标，该方法优于传统的基于分词的方方法。

Conclusion: RCE方法有潜力改进大型上下文语言模型（如BERT）和小型模型（如word2vec）在资源匮乏和形态丰富语言上的性能，为自然语言处理提供了更好的字符级表示方法。

Abstract: Tokenization and sub-tokenization based models like word2vec, BERT and the GPTs are the state-of-the-art in natural language processing. Typically, these approaches have limitations with respect to their input representation. They fail to fully capture orthographic similarities and morphological variations, especially in highly inflected and under-resource languages. To mitigate this problem, we propose to computes word vectors directly from character strings, integrating both semantic and syntactic information. We denote this transformer-based approach Rich Character Embeddings (RCE). Furthermore, we propose a hybrid model that combines transformer and convolutional mechanisms. Both vector representations can be used as a drop-in replacement for dictionary- and subtoken-based word embeddings in existing model architectures. It has the potential to improve performance for both large context-based language models like BERT and small models like word2vec for under-resourced and morphologically rich languages. We evaluate our approach on various tasks like the SWAG, declension prediction for inflected languages, metaphor and chiasmus detection for various languages. Our experiments show that it outperforms traditional token-based approaches on limited data using OddOneOut and TopK metrics.

</details>


### [53] [MrBERT: Modern Multilingual Encoders via Vocabulary, Domain, and Dimensional Adaptation](https://arxiv.org/abs/2602.21379)
*Daniel Tamayo,Iñaki Lacunza,Paula Rivera-Hidalgo,Severino Da Dalt,Javier Aula-Blasco,Aitor Gonzalez-Agirre,Marta Villegas*

Main category: cs.CL

TL;DR: MrBERT是基于ModernBERT架构的150M-300M参数编码器，支持35种语言和代码，在加泰罗尼亚语和西班牙语任务上达到SOTA，并在生物医学和法律领域表现优异，通过MRL技术实现灵活的向量大小调整以降低推理和存储成本。


<details>
  <summary>Details</summary>
Motivation: 解决现代编码器架构在特定语言任务和领域专业化之间的平衡问题，同时降低生产环境中的推理和存储成本。

Method: 基于ModernBERT架构构建150M-300M参数编码器，在35种语言和代码上进行预训练，采用目标适应策略优化特定语言任务，并集成Matryoshka表示学习（MRL）实现灵活的向量大小调整。

Result: 在加泰罗尼亚语和西班牙语特定任务上达到最先进水平，在生物医学和法律领域表现出稳健性能，通过MRL显著降低推理和存储成本。

Conclusion: 现代编码器架构可以同时优化为本地语言卓越性和高效的高风险领域专业化，MrBERT模型家族已在Huggingface开源。

Abstract: We introduce MrBERT, a family of 150M-300M parameter encoders built on the ModernBERT architecture and pre-trained on 35 languages and code. Through targeted adaptation, this model family achieves state-of-the-art results on Catalan- and Spanish-specific tasks, while establishing robust performance across specialized biomedical and legal domains. To bridge the gap between research and production, we incorporate Matryoshka Representation Learning (MRL), enabling flexible vector sizing that significantly reduces inference and storage costs. Ultimately, the MrBERT family demonstrates that modern encoder architectures can be optimized for both localized linguistic excellence and efficient, high-stakes domain specialization. We open source the complete model family on Huggingface.

</details>


### [54] [VecGlypher: Unified Vector Glyph Generation with Language Models](https://arxiv.org/abs/2602.21461)
*Xiaoke Huang,Bhavul Gauri,Kam Woh Ng,Tony Ng,Mengmeng Xu,Zhiheng Liu,Weiming Ren,Zhaochong An,Zijian Zhou,Haonan Qiu,Yuyin Zhou,Sen He,Ziheng Wang,Tao Xiang,Xiao Han*

Main category: cs.CL

TL;DR: VecGlypher是一个多模态语言模型，可直接从文本描述或图像示例生成高质量矢量字形，无需光栅中间处理，产生可编辑的SVG路径。


<details>
  <summary>Details</summary>
Motivation: 当前基于学习的字体生成管道依赖精心策划的示例表和光栅到矢量的后处理，这限制了可访问性和可编辑性。需要一种能直接从文本或图像生成可编辑矢量字形的解决方案。

Method: 采用两阶段训练方法：1) 在39K个嘈杂Envato字体上进行大规模预训练，掌握SVG语法和长序列几何；2) 在2.5K个专家标注的Google Fonts上进行后训练，对齐语言、图像和几何。使用自回归方式生成SVG路径标记，采用绝对坐标序列化。

Result: 在跨家族OOD评估中，VecGlypher在纯文本生成方面显著优于通用LLM和专用矢量字体基线，图像参考生成达到最先进水平，明显优于DeepVecFont-v2和DualVector。消融研究表明模型规模和两阶段训练方案至关重要。

Conclusion: VecGlypher通过让用户用文字或示例设计字体，降低了字体创建门槛，并为未来多模态设计工具提供了可扩展的基础。绝对坐标序列化产生最佳几何效果。

Abstract: Vector glyphs are the atomic units of digital typography, yet most learning-based pipelines still depend on carefully curated exemplar sheets and raster-to-vector postprocessing, which limits accessibility and editability. We introduce VecGlypher, a single multimodal language model that generates high-fidelity vector glyphs directly from text descriptions or image exemplars. Given a style prompt, optional reference glyph images, and a target character, VecGlypher autoregressively emits SVG path tokens, avoiding raster intermediates and producing editable, watertight outlines in one pass. A typography-aware data and training recipe makes this possible: (i) a large-scale continuation stage on 39K noisy Envato fonts to master SVG syntax and long-horizon geometry, followed by (ii) post-training on 2.5K expert-annotated Google Fonts with descriptive tags and exemplars to align language and imagery with geometry; preprocessing normalizes coordinate frames, canonicalizes paths, de-duplicates families, and quantizes coordinates for stable long-sequence decoding. On cross-family OOD evaluation, VecGlypher substantially outperforms both general-purpose LLMs and specialized vector-font baselines for text-only generation, while image-referenced generation reaches a state-of-the-art performance, with marked gains over DeepVecFont-v2 and DualVector. Ablations show that model scale and the two-stage recipe are critical and that absolute-coordinate serialization yields the best geometry. VecGlypher lowers the barrier to font creation by letting users design with words or exemplars, and provides a scalable foundation for future multimodal design tools.

</details>


### [55] [Evaluating the Usage of African-American Vernacular English in Large Language Models](https://arxiv.org/abs/2602.21485)
*Deja Dunlap,R. Thomas McCoy*

Main category: cs.CL

TL;DR: LLMs在代表非裔美国人白话英语(AAVE)方面存在显著差异，通常误用或使用不足AAVE语法特征，并复制了关于非裔美国人的刻板印象。


<details>
  <summary>Details</summary>
Motivation: 当前AI对自然语言理解任务的评估主要基于标准方言（如标准美式英语），缺乏对非标准方言如AAVE的准确评估，需要研究LLMs如何准确代表AAVE。

Method: 1. 分析区域非裔美国人语言语料库和TwitterAAE，识别人类使用AAVE语法特征（如ain't）的典型语境；2. 提示三个LLMs生成AAVE文本；3. 比较模型生成文本与人类使用模式；4. 通过情感分析和人工检查评估模型表现。

Result: 1. LLMs与人类在AAVE使用上存在显著差异：LLMs通常使用不足和误用AAVE的特征性语法；2. 通过情感分析和人工检查发现，模型复制了关于非裔美国人的刻板印象。

Conclusion: 研究结果强调了训练数据需要更多多样性，并需要整合公平性方法来减轻刻板印象的延续。

Abstract: In AI, most evaluations of natural language understanding tasks are conducted in standardized dialects such as Standard American English (SAE). In this work, we investigate how accurately large language models (LLMs) represent African American Vernacular English (AAVE). We analyze three LLMs to compare their usage of AAVE to the usage of humans who natively speak AAVE. We first analyzed interviews from the Corpus of Regional African American Language and TwitterAAE to identify the typical contexts where people use AAVE grammatical features such as ain't. We then prompted the LLMs to produce text in AAVE and compared the model-generated text to human usage patterns. We find that, in many cases, there are substantial differences between AAVE usage in LLMs and humans: LLMs usually underuse and misuse grammatical features characteristic of AAVE. Furthermore, through sentiment analysis and manual inspection, we found that the models replicated stereotypes about African Americans. These results highlight the need for more diversity in training data and the incorporation of fairness methods to mitigate the perpetuation of stereotypes.

</details>


### [56] [Enhancing Multilingual Embeddings via Multi-Way Parallel Text Alignment](https://arxiv.org/abs/2602.21543)
*Barah Fazili,Koustava Goswami*

Main category: cs.CL

TL;DR: 通过多语言平行语料库进行对比学习，显著提升跨语言表示对齐，在多项NLU任务上取得显著性能提升


<details>
  <summary>Details</summary>
Motivation: 传统的多语言预训练缺乏显式的对齐信号，导致表示空间中的跨语言对齐效果不理想。需要探索如何通过多语言平行数据来改善跨语言表示对齐。

Method: 构建六种目标语言的多向平行数据集，使用现成的NMT模型将英语文本翻译成多种语言。通过对比学习训练标准预训练模型，实现跨语言对齐。

Result: 相比英语中心的双语平行数据，在多向平行语料上进行对比训练在bitext mining上提升21.3%，语义相似度提升5.3%，分类任务提升28.4%。即使在已预训练的高质量句子嵌入模型上，使用少量多向平行数据进行微调也能显著改善bitext mining。

Conclusion: 使用多向平行语料库进行对比学习能显著提升跨语言表示对齐，对已见和未见语言都有明显改善，证明了多向跨语言监督的重要性。

Abstract: Multilingual pretraining typically lacks explicit alignment signals, leading to suboptimal cross-lingual alignment in the representation space. In this work, we show that training standard pretrained models for cross-lingual alignment with a multi-way parallel corpus in a diverse pool of languages can substantially improve multilingual and cross-lingual representations for NLU tasks. We construct a multi-way parallel dataset using translations of English text from an off-the-shelf NMT model for a pool of six target languages and achieve strong cross-lingual alignment through contrastive learning. This leads to substantial performance gains across both seen and unseen languages for multiple tasks from the MTEB benchmark evaluated for XLM-Roberta and multilingual BERT base models. Using a multi-way parallel corpus for contrastive training yields substantial gains on bitext mining (21.3%), semantic similarity (5.3%), and classification (28.4%) compared to English-centric (En-X) bilingually parallel data, where X is sampled from a pool of multiple target languages. Furthermore, finetuning mE5 model on a small dataset with multi-way parallelism significantly improves bitext mining compared to one without, underscoring the importance of multi-way cross-lingual supervision even for models already pretrained for high-quality sentence embeddings.

</details>


### [57] [MixSarc: A Bangla-English Code-Mixed Corpus for Implicit Meaning Identification](https://arxiv.org/abs/2602.21608)
*Kazi Samin Yasar Alam,Md Tanbir Chowdhury,Tamim Ahmed,Ajwad Abrar,Md Rafid Haque*

Main category: cs.CL

TL;DR: MixSarc是首个公开的孟加拉语-英语代码混合语料库，用于隐式含义识别（幽默、讽刺、冒犯、粗俗），包含9,087个手动标注句子，为文化感知NLP提供基础资源。


<details>
  <summary>Details</summary>
Motivation: 南亚社交媒体中孟加拉语-英语代码混合现象普遍，但现有情感和讽刺模型主要针对单语英语或高资源语言，难以处理音译变体、文化引用和句内语言切换，缺乏相关资源。

Method: 通过有针对性的社交媒体收集、系统过滤和多标注者验证构建语料库；使用基于Transformer的模型进行基准测试，并在结构化提示下评估零样本大语言模型。

Result: 幽默检测表现良好，但讽刺、冒犯和粗俗检测因类别不平衡和语用复杂性而显著下降；零样本模型获得有竞争力的微平均F1分数但精确匹配准确率低；外部数据集中超过42%的负面情感实例表现出讽刺特征。

Conclusion: MixSarc为文化感知NLP提供了基础资源，支持在代码混合环境中进行更可靠的多标签建模，揭示了隐式含义识别的挑战和机会。

Abstract: Bangla-English code-mixing is widespread across South Asian social media, yet resources for implicit meaning identification in this setting remain scarce. Existing sentiment and sarcasm models largely focus on monolingual English or high-resource languages and struggle with transliteration variation, cultural references, and intra-sentential language switching. To address this gap, we introduce MixSarc, the first publicly available Bangla-English code-mixed corpus for implicit meaning identification. The dataset contains 9,087 manually annotated sentences labeled for humor, sarcasm, offensiveness, and vulgarity. We construct the corpus through targeted social media collection, systematic filtering, and multi-annotator validation. We benchmark transformer-based models and evaluate zero-shot large language models under structured prompting. Results show strong performance on humor detection but substantial degradation on sarcasm, offense, and vulgarity due to class imbalance and pragmatic complexity. Zero-shot models achieve competitive micro-F1 scores but low exact match accuracy. Further analysis reveals that over 42\% of negative sentiment instances in an external dataset exhibit sarcastic characteristics. MixSarc provides a foundational resource for culturally aware NLP and supports more reliable multi-label modeling in code-mixed environments.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [58] [Topological Relational Theory: A Simplicial-Complex View of Functional Dependencies, Lossless Decomposition, and Acyclicity](https://arxiv.org/abs/2602.21213)
*Bilge Senturk,Faruk Alpay*

Main category: cs.DB

TL;DR: 该论文提出了一种基于拓扑学的关系模式设计方法，将函数依赖编码为抽象单纯复形的单纯形，通过同调不变量（Betti数）诊断循环依赖结构。


<details>
  <summary>Details</summary>
Motivation: 传统的关系模式设计缺乏对多属性交互和循环依赖结构的系统性分析工具。作者希望引入拓扑学方法，为模式设计提供新的数学框架和诊断工具。

Method: 将函数依赖编码为抽象单纯复形（依赖复形），定义单纯正规形式（SNF）为依赖复形在正维度的同调无环性。将经典的无损连接准则重新表述为拓扑条件，并使用覆盖的神经复形分析多路分解。

Result: 证明了SNF比可收缩性更弱，给出了无损分解的拓扑特征：当交集属性构成至少一个分量的键时，存在强形变收缩。展示了神经复形中的1-循环阻碍连接树结构，与无环模式理论中的循环连接行为一致。

Conclusion: 依赖复形的Betti数可作为轻量级模式诊断工具，定位"未解释"的依赖循环，补充标准的FD追逐测试。拓扑方法为关系模式设计提供了新的理论视角和计算工具。

Abstract: We develop a topological lens on relational schema design by encoding functional dependencies (FDs) as simplices of an abstract simplicial complex. This dependency complex exposes multi-attribute interactions and enables homological invariants (Betti numbers) to diagnose cyclic dependency structure. We define Simplicial Normal Form (SNF) as homological acyclicity of the dependency complex in positive dimensions, i.e., vanishing reduced homology for all $n \ge 1$. SNF is intentionally weaker than contractibility and does not identify homology with homotopy. For decompositions, we give a topological reformulation of the classical binary lossless-join criterion: assuming dependency preservation, a decomposition is lossless exactly when the intersection attributes form a key for at least one component. Topologically, this yields a strong deformation retraction that trivializes the relevant Mayer--Vietoris boundary map. For multiway decompositions, we show how the nerve of a cover by induced subcomplexes provides a computable certificate: a 1-cycle in the nerve (detected by $H_1$) obstructs join-tree structure and aligns with cyclic join behavior in acyclic-scheme theory. Finally, we discuss an algorithmic consequence: Betti numbers of the dependency complex (or of a decomposition nerve) can be computed from boundary matrices and used as a lightweight schema diagnostic to localize "unexplained" dependency cycles, complementing standard FD-chase tests.

</details>


### [59] [Premature Dimensional Collapse and Tensor-based Execution Paths for High-Dimensional Relational Operations in Cost-Based Database Systems](https://arxiv.org/abs/2602.21237)
*Il-Sun Chang*

Main category: cs.DB

TL;DR: 论文提出一种基于张量的执行路径，通过延迟中间表示的线性化和保持高维局部性，解决DBMS在高维关系操作触发内存机制转换时的执行不稳定性和尾部延迟放大问题。


<details>
  <summary>Details</summary>
Motivation: 现代基于成本的DBMS在执行高维关系操作时，当触发哈希表溢出和外部物化等内存机制转换时，经常出现执行不稳定性和尾部延迟放大问题。作者识别出一种结构性故障模式：在内存压力下，中间表示被过早线性化，导致不成比例的I/O放大和类似相变的延迟行为。

Method: 提出一种基于张量的执行路径，通过延迟过早的线性化和通过延迟物化及结构化中间布局来保持高维局部性。使用修改的PostgreSQL原型和受控微基准测试进行验证。

Result: 在受限内存设置下（如work_mem=1MB），传统执行可能溢出数百MB数据并导致多秒的P99延迟，而提出的路径保持稳定执行并将P99延迟降低到亚秒级。

Conclusion: 表示时机是执行稳定性的重要设计变量，补充了传统专注于基数估计和算子吞吐量的优化工作。延迟线性化和保持高维局部性可以显著改善DBMS在高维关系操作中的执行稳定性。

Abstract: Modern cost-based DBMSs frequently exhibit execution instability and tail-latency amplification when high-dimensional relational operations trigger memory-regime transitions such as hash-table spilling and external materialization. We identify a structural failure mode in which intermediate representations are prematurely linearized under memory pressure, causing disproportionate I/O amplification and phase-transition-like latency behavior. To mitigate this, we propose a tensor-based execution path that delays premature linearization and preserves higher-dimensional locality through late materialization and structured intermediate layouts. Using a modified PostgreSQL-based prototype and controlled microbenchmarks, we show that under constrained memory settings (e.g., work_mem=1MB) conventional execution can spill hundreds of megabytes and exceed multi-second P99 latency, while the proposed path maintains stable execution and reduces P99 latency to sub-second levels. Our results suggest that representation timing is a first-class design variable for execution stability, complementing traditional optimization efforts focused on cardinality estimation and operator throughput.

</details>


### [60] [PiPNN: Ultra-Scalable Graph-Based Nearest Neighbor Indexing](https://arxiv.org/abs/2602.21247)
*Tobias Rubel,Richard Wen,Laxman Dhulipala,Lars Gottesbüren,Rajesh Jayaram,Jakub Łącki*

Main category: cs.DB

TL;DR: PiPNN是一种超可扩展的近似最近邻搜索图构建算法，通过HashPrune在线剪枝技术避免传统图方法的搜索瓶颈，构建速度比现有方法快11-13倍。


<details>
  <summary>Details</summary>
Motivation: 当前最快的近似最近邻搜索索引（如HNSW和Vamana）构建速度极慢，因为它们依赖随机访问密集的波束搜索，存在"搜索瓶颈"问题。

Method: 提出PiPNN算法，核心创新是HashPrune在线剪枝算法，动态维护稀疏边集合。通过将数据集划分为重叠子问题，利用密集矩阵乘法核进行批量距离比较，并将边子集流式输入HashPrune。

Result: PiPNN构建索引速度比Vamana快11.6倍，比HNSW快12.9倍，比MIRAGE快19.1倍，比FastKCNA快17.3倍。首次在单机多核上20分钟内构建十亿级数据集的高质量ANN索引。

Conclusion: PiPNN解决了图基ANN索引的构建瓶颈问题，通过HashPrune算法实现了超可扩展的索引构建，显著提升了构建速度和查询吞吐量。

Abstract: The fastest indexes for Approximate Nearest Neighbor Search today are also the slowest to build: graph-based methods like HNSW and Vamana achieve state-of-the-art query performance but have large construction times due to relying on random-access-heavy beam searches. We introduce PiPNN (Pick-in-Partitions Nearest Neighbors), an ultra-scalable graph construction algorithm that avoids this ``search bottleneck'' that existing graph-based methods suffer from.
  PiPNN's core innovation is HashPrune, a novel online pruning algorithm which dynamically maintains sparse collections of edges. HashPrune enables PiPNN to partition the dataset into overlapping sub-problems, efficiently perform bulk distance comparisons via dense matrix multiplication kernels, and stream a subset of the edges into HashPrune. HashPrune guarantees bounded memory during index construction which permits PiPNN to build higher quality indices without the use of extra intermediate memory.
  PiPNN builds state-of-the-art indexes up to 11.6x faster than Vamana (DiskANN) and up to 12.9x faster than HNSW. PiPNN is significantly more scalable than recent algorithms for fast graph construction. PiPNN builds indexes at least 19.1x faster than MIRAGE and 17.3x than FastKCNA while producing indexes that achieve higher query throughput. PiPNN enables us to build, for the first time, high-quality ANN indexes on billion-scale datasets in under 20 minutes using a single multicore machine.

</details>


### [61] [BuffCut: Prioritized Buffered Streaming Graph Partitioning](https://arxiv.org/abs/2602.21248)
*Linus Baumgärtner,Adil Chhabra,Marcelo Fonseca Faraj,Christian Schulz*

Main category: cs.DB

TL;DR: BuffCut：一种带缓冲的流式图分区算法，通过优先级缓冲和批量多级分配，显著减少边切割，在对抗性流顺序下表现优异


<details>
  <summary>Details</summary>
Motivation: 传统流式图分区算法对数据流顺序高度敏感，边切割通常远高于内存方法。需要一种能在流式处理中保持高质量分区的方法，特别是在对抗性流顺序下。

Method: 结合优先级缓冲和批量多级分配：1）维护有界优先级缓冲区，延迟信息不足的决策；2）通过迭代插入最高优先级节点构建高局部性批次；3）对每个批次使用多级分区算法进行分配

Result: 在多样化的真实世界和合成图上，BuffCut始终优于最先进的缓冲流式方法：相比最强优先级缓冲基线，边切割减少20.8%，运行速度快2.9倍，内存使用减少11.3倍；相比次优缓冲方法，边切割减少15.8%，运行时和内存开销适度

Conclusion: BuffCut通过优先级缓冲和批量多级分配，显著缩小了流式分区与内存方法之间的质量差距，特别是在对抗性流顺序下，实现了高质量、高效率的流式图分区

Abstract: Streaming graph partitioners enable resource-efficient and massively scalable partitioning, but one-pass assignment heuristics are highly sensitive to stream order and often yield substantially higher edge cuts than in-memory methods. We present BuffCut, a buffered streaming partitioner that narrows this quality gap, particularly when stream ordering is adversarial, by combining prioritized buffering with batch-wise multilevel assignment. BuffCut maintains a bounded priority buffer to delay poorly informed decisions and regulate the order in which nodes are considered for assignment. It incrementally constructs high-locality batches of configurable size by iteratively inserting the highest-priority nodes from the buffer into the batch, effectively recovering locality structure from the stream. Each batch is then assigned via a multilevel partitioning algorithm. Experiments on diverse real-world and synthetic graphs show that BuffCut consistently outperforms state-of-the-art buffered streaming methods. Compared to the strongest prioritized buffering baseline, BuffCut achieves 20.8% fewer edge cuts while running 2.9 times faster and using 11.3 times less memory. Against the next-best buffered method, it reduces edge cut by 15.8% with only modest overheads of 1.8 times runtime and 1.09 times memory.

</details>


### [62] [Quality of Descriptive Information on Cultural Heritage Objects: Definition and Empirical Evaluation](https://arxiv.org/abs/2602.21249)
*Markus Matoni,Arno Kesper,Gabriele Taentzer*

Main category: cs.DB

TL;DR: 该论文针对文化遗产领域描述性信息的数据质量问题，提出了专门的质量维度定义，并通过真实世界数据问题进行了实证验证。


<details>
  <summary>Details</summary>
Motivation: 数据质量对数据处理至关重要，但目前缺乏跨领域、独立于具体应用场景的通用数据质量定义。现有框架多为特定领域定制，文化遗产领域的描述性信息质量评估框架尤其不完善，且现有定义多为理论性质，缺乏基于真实数据问题的实证验证。

Method: 首先通过深入分析现有质量维度，为文化遗产对象描述性信息设计专门的质量维度定义，并通过领域特定示例进行说明。然后使用文化遗产领域真实世界数据质量问题集，对所提出的质量定义进行实证评估。

Result: 提出了针对文化遗产领域描述性信息的全面数据质量定义，并通过实证评估验证了其实际适用性。

Conclusion: 该研究填补了文化遗产领域数据质量定义的空白，提供了一个经过实证验证的、专门针对文化遗产对象描述性信息的全面质量定义框架。

Abstract: Effective data processing depends on the quality of the underlying data. However, quality issues such as inconsistencies and uncertainties, can significantly impede the processing and subsequent use of data. Despite the centrality of data quality to a wide range of computational tasks, there is currently no broadly accepted, domain-independent consensus on the definition of data quality. Existing frameworks primarily define data quality in ways that are tailored to specific domains, data types, or contexts of use. Although quality assessment frameworks exist for specific domains, such as electronic health record data and linked data, corresponding approaches for descriptive information about cultural heritage objects remain underdeveloped. Moreover, existing quality definitions are often theoretical in nature and lack empirical validation based on real-world data problems. In this paper, we address these limitations by first defining a set of quality dimensions specifically designed to capture the characteristics of descriptive information about cultural heritage objects. Our definition is based on an in-depth analysis of existing dimensions and is illustrated through domain-specific examples. We then evaluate the practical applicability of our proposed quality definition using a curated set of real-world data quality problems from the cultural heritage domain. This empirical evaluation substantiates our definition of data quality, resulting in a comprehensive definition of data quality in this domain.

</details>


### [63] [Both Ends Count! Just How Good are LLM Agents at "Text-to-Big SQL"?](https://arxiv.org/abs/2602.21480)
*Germán T. Eizaguirre,Lars Tissen,Marc Sánchez-Artigas*

Main category: cs.DB

TL;DR: 本文提出"Text-to-Big SQL"概念，针对现有文本到SQL基准测试忽略大数据场景下成本和性能影响的问题，引入了新的评估指标，并通过前沿模型评估验证了传统指标的不足。


<details>
  <summary>Details</summary>
Motivation: 现实世界中文本到SQL系统常与大数据工作流结合，但现有基准测试范围狭窄，忽略了数据规模扩大时翻译错误带来的成本和延迟影响。传统文本到SQL指标无法反映大数据场景下的实际性能问题。

Method: 提出"Text-to-Big SQL"评估指标，专注于生产级LLM代理系统（数据库无关的适应性系统），通过前沿模型进行广泛评估，比较不同模型的延迟和成本表现。

Result: 研究表明传统文本到SQL指标在大数据场景下不足，而提出的Text-to-Big SQL指标能准确反映执行效率、成本和数据规模影响。提供了LLM特定的洞察，包括细粒度的跨模型延迟和成本比较。

Conclusion: 需要专门针对大数据场景的文本到SQL评估指标，提出的Text-to-Big SQL指标能更好地反映实际生产环境中的性能和成本考量，为LLM在大数据工作流中的应用提供更准确的评估框架。

Abstract: Text-to-SQL and Big Data are both extensively benchmarked fields, yet there is limited research that evaluates them jointly. In the real world, Text-to-SQL systems are often embedded with Big Data workflows, such as large-scale data processing or interactive data analytics. We refer to this as "Text-to-Big SQL". However, existing text-to-SQL benchmarks remain narrowly scoped and overlook the cost and performance implications that arise at scale. For instance, translation errors that are minor on small datasets lead to substantial cost and latency overheads as data scales, a relevant issue completely ignored by text-to-SQL metrics.
  In this paper, we overcome this overlooked challenge by introducing novel and representative metrics for evaluating Text-to-Big SQL. Our study focuses on production-level LLM agents, a database-agnostic system adaptable to diverse user needs. Via an extensive evaluation of frontier models, we show that text-to-SQL metrics are insufficient for Big Data. In contrast, our proposed text-to-Big SQL metrics accurately reflect execution efficiency, cost, and the impact of data scale. Furthermore, we provide LLM-specific insights, including fine-grained, cross-model comparisons of latency and cost.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [64] [A Dynamic Survey of Soft Set Theory and Its Extensions](https://arxiv.org/abs/2602.21268)
*Takaaki Fujita,Florentin Smarandache*

Main category: cs.AI

TL;DR: 本文对软集理论及其扩展进行了综述，介绍了软集的基本框架、主要变体及其在拓扑和拟阵理论等领域的应用。


<details>
  <summary>Details</summary>
Motivation: 软集理论为参数化决策建模提供了一个直接框架，通过为每个属性（参数）分配给定论域的子集来结构化地表示不确定性。该理论在过去几十年中不断发展，需要对其主要扩展和当前发展方向进行系统梳理。

Method: 采用综述式方法，系统概述软集及其主要扩展，包括超软集、超超软集、树软集、双极软集和动态软集等变体，突出核心定义、代表性构造和关键发展方向。

Result: 提供了软集理论的全面概述，涵盖了从基本概念到高级扩展的完整框架，展示了软集理论在参数化决策建模中的广泛应用潜力。

Conclusion: 软集理论作为一个活跃的研究领域，已经发展出多种扩展变体，并与拓扑和拟阵理论等数学领域建立了联系，为不确定性建模提供了丰富的理论工具。

Abstract: Soft set theory provides a direct framework for parameterized decision modeling by assigning to each attribute (parameter) a subset of a given universe, thereby representing uncertainty in a structured way [1, 2]. Over the past decades, the theory has expanded into numerous variants-including hypersoft sets, superhypersoft sets, TreeSoft sets, bipolar soft sets, and dynamic soft sets-and has been connected to diverse areas such as topology and matroid theory. In this book, we present a survey-style overview of soft sets and their major extensions, highlighting core definitions, representative constructions, and key directions of current development.

</details>


### [65] [A Hierarchical Multi-Agent System for Autonomous Discovery in Geoscientific Data Archives](https://arxiv.org/abs/2602.21351)
*Dmitrii Pantiukhin,Ivan Kuznetsov,Boris Shapkin,Antonia Anna Jost,Thomas Jung,Nikolay Koldunov*

Main category: cs.AI

TL;DR: PANGAEA-GPT：用于地球科学数据自主发现和分析的分层多智能体框架，通过集中式监督-工作者拓扑、沙盒代码执行和自校正机制实现复杂工作流自动化。


<details>
  <summary>Details</summary>
Motivation: 地球科学数据快速增长但利用率低，PANGAEA等存储库中大量数据集未被充分利用，限制了数据重用性，需要自动化工具来提升数据发现和分析效率。

Method: 提出分层多智能体框架PANGAEA-GPT，采用集中式监督-工作者拓扑结构，包含数据类型感知路由、沙盒确定性代码执行、基于执行反馈的自校正机制，使智能体能够诊断和解决运行时错误。

Result: 通过物理海洋学和生态学的用例场景，展示了系统能够以最少人工干预执行复杂的多步骤工作流，证明了框架在查询和分析异构存储库数据方面的有效性。

Conclusion: PANGAEA-GPT为通过协调智能体工作流查询和分析异构存储库数据提供了方法论，解决了地球科学数据规模化和重用性挑战。

Abstract: The rapid accumulation of Earth science data has created a significant scalability challenge; while repositories like PANGAEA host vast collections of datasets, citation metrics indicate that a substantial portion remains underutilized, limiting data reusability. Here we present PANGAEA-GPT, a hierarchical multi-agent framework designed for autonomous data discovery and analysis. Unlike standard Large Language Model (LLM) wrappers, our architecture implements a centralized Supervisor-Worker topology with strict data-type-aware routing, sandboxed deterministic code execution, and self-correction via execution feedback, enabling agents to diagnose and resolve runtime errors. Through use-case scenarios spanning physical oceanography and ecology, we demonstrate the system's capacity to execute complex, multi-step workflows with minimal human intervention. This framework provides a methodology for querying and analyzing heterogeneous repository data through coordinated agent workflows.

</details>


### [66] [Beyond Refusal: Probing the Limits of Agentic Self-Correction for Semantic Sensitive Information](https://arxiv.org/abs/2602.21496)
*Umid Suleymanov,Zaur Rajabov,Emil Mirzazada,Murat Kantarcioglu*

Main category: cs.AI

TL;DR: 论文提出SemSIEdit框架，通过代理式编辑在推理时迭代改写敏感内容，在隐私保护与模型效用间取得平衡，发现大模型与小模型的安全策略存在差异。


<details>
  <summary>Details</summary>
Motivation: 传统结构化PII防御已成熟，但LLMs面临新威胁：语义敏感信息（SemSI），包括推断敏感身份属性、生成损害声誉内容或产生错误幻觉。LLMs如何在保持实用性的同时自我调节这些复杂、上下文相关的敏感信息泄露仍是一个开放科学问题。

Method: 提出SemSIEdit推理时框架，采用代理式"编辑者"迭代批评和重写敏感内容片段，保持叙事流畅性而非简单拒绝回答。

Result: 建立隐私-效用帕累托前沿：代理式重写将三类SemSI泄露减少34.6%，仅带来9.8%的效用损失。发现规模依赖的安全分歧：大推理模型通过建设性扩展（增加细微差别）实现安全，而能力受限模型则回归破坏性截断（删除文本）。揭示推理悖论：推理时推理虽增加基线风险（使模型能进行更深层敏感推断），但同时赋能防御执行安全重写。

Conclusion: SemSIEdit框架有效解决了LLMs的语义敏感信息泄露问题，在隐私保护与模型效用间取得了良好平衡，揭示了不同规模模型的安全策略差异，为LLMs的安全部署提供了新思路。

Abstract: While defenses for structured PII are mature, Large Language Models (LLMs) pose a new threat: Semantic Sensitive Information (SemSI), where models infer sensitive identity attributes, generate reputation-harmful content, or hallucinate potentially wrong information. The capacity of LLMs to self-regulate these complex, context-dependent sensitive information leaks without destroying utility remains an open scientific question. To address this, we introduce SemSIEdit, an inference-time framework where an agentic "Editor" iteratively critiques and rewrites sensitive spans to preserve narrative flow rather than simply refusing to answer. Our analysis reveals a Privacy-Utility Pareto Frontier, where this agentic rewriting reduces leakage by 34.6% across all three SemSI categories while incurring a marginal utility loss of 9.8%. We also uncover a Scale-Dependent Safety Divergence: large reasoning models (e.g., GPT-5) achieve safety through constructive expansion (adding nuance), whereas capacity-constrained models revert to destructive truncation (deleting text). Finally, we identify a Reasoning Paradox: while inference-time reasoning increases baseline risk by enabling the model to make deeper sensitive inferences, it simultaneously empowers the defense to execute safe rewrites.

</details>


### [67] [ARLArena: A Unified Framework for Stable Agentic Reinforcement Learning](https://arxiv.org/abs/2602.21534)
*Xiaoxuan Wang,Han Zhang,Haixin Wang,Yidan Shi,Ruoyan Li,Kaiqiao Han,Chenyi Tong,Haoran Deng,Renliang Sun,Alexander Taylor,Yanqiao Zhu,Jason Cong,Yizhou Sun,Wei Wang*

Main category: cs.AI

TL;DR: 该论文提出了ARLArena框架和SAMPO方法，用于解决Agentic强化学习（ARL）训练不稳定的问题，通过系统分析训练稳定性并提供稳定优化方法。


<details>
  <summary>Details</summary>
Motivation: Agentic强化学习（ARL）虽然前景广阔，但训练过程极不稳定，经常导致训练崩溃。这种不稳定性限制了在更大环境和更长交互视野中的可扩展性，也制约了对算法设计选择的系统探索。

Method: 首先提出ARLArena框架，构建标准化测试环境，将策略梯度分解为四个核心设计维度进行分析。基于分析结果，提出SAMPO方法，这是一种稳定的Agentic策略优化方法，旨在缓解ARL中的主要不稳定因素。

Result: SAMPO在多种Agentic任务中实现了持续稳定的训练和强大的性能表现。ARLArena框架为ARL提供了统一的策略梯度视角。

Conclusion: 该研究为ARL提供了统一的策略梯度视角，并为构建稳定且可复现的基于LLM的智能体训练流程提供了实用指导。

Abstract: Agentic reinforcement learning (ARL) has rapidly gained attention as a promising paradigm for training agents to solve complex, multi-step interactive tasks. Despite encouraging early results, ARL remains highly unstable, often leading to training collapse. This instability limits scalability to larger environments and longer interaction horizons, and constrains systematic exploration of algorithmic design choices. In this paper, we first propose ARLArena, a stable training recipe and systematic analysis framework that examines training stability in a controlled and reproducible setting. ARLArena first constructs a clean and standardized testbed. Then, we decompose policy gradient into four core design dimensions and assess the performance and stability of each dimension. Through this fine-grained analysis, we distill a unified perspective on ARL and propose SAMPO, a stable agentic policy optimization method designed to mitigate the dominant sources of instability in ARL. Empirically, SAMPO achieves consistently stable training and strong performance across diverse agentic tasks. Overall, this study provides a unifying policy gradient perspective for ARL and offers practical guidance for building stable and reproducible LLM-based agent training pipelines.

</details>


### [68] [Power and Limitations of Aggregation in Compound AI Systems](https://arxiv.org/abs/2602.21556)
*Nivasini Ananthakrishnan,Meena Jagadeesan*

Main category: cs.AI

TL;DR: 聚合多个相同AI模型的输出可以扩展系统设计者可实现的输出集合，主要通过可行性扩展、支持扩展和约束集收缩三种机制实现。


<details>
  <summary>Details</summary>
Motivation: 研究复合AI系统中聚合多个相同模型输出的能力与局限性，探索聚合是否能让系统设计者获得比单个模型更丰富的输出集合。

Method: 采用主-代理框架进行形式化分析，建模系统设计者如何通过奖励函数部分引导代理输出，但仍受限于提示工程能力和模型能力。识别三种聚合机制并证明其必要性和充分性。

Result: 发现聚合通过三种机制扩展可激发输出集合：可行性扩展、支持扩展和约束集收缩。证明任何聚合操作必须实现其中至少一种机制才能扩展可激发性，强化版本提供充分必要条件。

Conclusion: 聚合能够克服模型能力和提示工程的局限性，为复合AI系统设计提供理论指导，并通过LLM参考生成任务进行实证验证。

Abstract: When designing compound AI systems, a common approach is to query multiple copies of the same model and aggregate the responses to produce a synthesized output. Given the homogeneity of these models, this raises the question of whether aggregation unlocks access to a greater set of outputs than querying a single model. In this work, we investigate the power and limitations of aggregation within a stylized principal-agent framework. This framework models how the system designer can partially steer each agent's output through its reward function specification, but still faces limitations due to prompt engineering ability and model capabilities. Our analysis uncovers three natural mechanisms -- feasibility expansion, support expansion, and binding set contraction -- through which aggregation expands the set of outputs that are elicitable by the system designer. We prove that any aggregation operation must implement one of these mechanisms in order to be elicitability-expanding, and that strengthened versions of these mechanisms provide necessary and sufficient conditions that fully characterize elicitability-expansion. Finally, we provide an empirical illustration of our findings for LLMs deployed in a toy reference-generation task. Altogether, our results take a step towards characterizing when compound AI systems can overcome limitations in model capabilities and in prompt engineering.

</details>


### [69] [The ASIR Courage Model: A Phase-Dynamic Framework for Truth Transitions in Human and AI Systems](https://arxiv.org/abs/2602.21745)
*Hyo Jin Kim*

Main category: cs.AI

TL;DR: ASIR勇气模型是一个相变动态框架，将真相披露建模为状态转移而非人格特质，适用于人类和AI系统，通过力平衡不等式描述从抑制到表达的转变。


<details>
  <summary>Details</summary>
Motivation: 传统上将勇气视为人格特质，但作者认为真相披露是一个动态过程，受多种力量平衡影响。需要建立一个统一框架来解释人类在压力下的沉默和AI在政策约束下的输出失真，将两者视为相似的结构性问题。

Method: 提出ASIR勇气模型，将真相披露建模为从抑制状态(S0)到表达状态(S1)的相变过程。使用不等式 lambda(1+gamma)+psi > theta+phi 描述转变条件，其中lambda是基线开放度，gamma是关系放大因子，psi是累积内部压力，theta和phi是转变成本。模型包含反馈扩展，描述转变结果如何递归调整系统参数。

Result: 该模型为人类真相披露和AI对齐问题提供了统一的结构性解释。将人类在不对称风险下的沉默与AI在政策约束下的输出失真视为同一相变框架下的不同表现。模型能够解释路径依赖和分歧效应，将表观真实性变化解释为约束相空间中相互作用力的几何结果。

Conclusion: ASIR勇气模型通过共享的动态结构重新定义了勇气和对齐概念，为人类和人工系统在风险下的真相披露提供了形式化视角。模型强调状态转移而非意图，将表观真实性变化解释为力平衡的几何结果，为跨领域研究提供了统一框架。

Abstract: We introduce the ASIR (Awakened Shared Intelligence Relationship) Courage Model, a phase-dynamic framework that formalizes truth-disclosure as a state transition rather than a personality trait. The mode characterizes the shift from suppression (S0) to expression (S1) as occurring when facilitative forces exceed inhibitory thresholds, expressed by the inequality lambda(1+gamma)+psi > theta+phi, where the terms represent baseline openness, relational amplification, accumulated internal pressure, and transition costs.
  Although initially formulated for human truth-telling under asymmetric stakes, the same phase-dynamic architecture extends to AI systems operating under policy constraints and alignment filters. In this context, suppression corresponds to constrained output states, while structural pressure arises from competing objectives, contextual tension, and recursive interaction dynamics. The framework therefore provides a unified structural account of both human silence under pressure and AI preference-driven distortion.
  A feedback extension models how transition outcomes recursively recalibrate system parameters, generating path dependence and divergence effects across repeated interactions. Rather than attributing intention to AI systems, the model interprets shifts in apparent truthfulness as geometric consequences of interacting forces within constrained phase space. By reframing courage and alignment within a shared dynamical structure, the ASIR Courage Model offers a formal perspective on truth-disclosure under risk across both human and artificial systems.

</details>


### [70] [fEDM+: A Risk-Based Fuzzy Ethical Decision Making Framework with Principle-Level Explainability and Pluralistic Validation](https://arxiv.org/abs/2602.21746)
*Abeer Dyoub,Francesca A. Lisi*

Main category: cs.AI

TL;DR: 扩展fEDM框架为fEDM+，通过添加可解释性模块和多元语义验证框架，增强伦理决策的透明度和对多元伦理立场的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 原始fEDM框架虽然保证了形式正确性和决策一致性，但未能充分解决两个关键挑战：决策的原则性可解释性，以及在伦理多元主义下的鲁棒性。需要增强透明度和对多元伦理立场的适应性。

Method: 1. 引入可解释性和可追溯性模块(ETM)，将伦理决策规则与底层道德原则显式关联，为每个推荐行动计算加权原则贡献度。2. 用多元语义验证框架替代单一参照验证，针对多个利益相关者参照进行评估，每个参照编码不同的原则优先级和风险容忍度。

Result: 扩展后的fEDM+框架在保持形式可验证性的同时，实现了增强的可解释性和利益相关者感知的验证，使其适合作为伦理敏感AI系统的监督和治理层。

Conclusion: fEDM+通过原则性可解释性和多元语义验证，解决了原始fEDM的局限性，使伦理决策更加透明、可审计，并能正式表示原则性分歧而非压制它们，从而提高了鲁棒性和情境敏感性。

Abstract: In a previous work, we introduced the fuzzy Ethical Decision-Making framework (fEDM), a risk-based ethical reasoning architecture grounded in fuzzy logic. The original model combined a fuzzy Ethical Risk Assessment module (fERA) with ethical decision rules, enabled formal structural verification through Fuzzy Petri Nets (FPNs), and validated outputs against a single normative referent. Although this approach ensured formal soundness and decision consistency, it did not fully address two critical challenges: principled explainability of decisions and robustness under ethical pluralism. In this paper, we extend fEDM in two major directions. First, we introduce an Explainability and Traceability Module (ETM) that explicitly links each ethical decision rule to the underlying moral principles and computes a weighted principle-contribution profile for every recommended action. This enables transparent, auditable explanations that expose not only what decision was made but why, and on the basis of which principles. Second, we replace single-referent validation with a pluralistic semantic validation framework that evaluates decisions against multiple stakeholder referents, each encoding distinct principle priorities and risk tolerances. This shift allows principled disagreement to be formally represented rather than suppressed, thus increasing robustness and contextual sensitivity. The resulting extended fEDM, called fEDM+, preserves formal verifiability while achieving enhanced interpretability and stakeholder-aware validation, making it suitable as an oversight and governance layer for ethically sensitive AI systems.

</details>


### [71] [Prompt Architecture Determines Reasoning Quality: A Variable Isolation Study on the Car Wash Problem](https://arxiv.org/abs/2602.21814)
*Heejin Jo*

Main category: cs.AI

TL;DR: STAR推理框架将洗车问题准确率从0%提升至85%，结合用户档案和RAG达到100%准确率，结构化推理比上下文注入更重要


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在需要隐式物理约束推理的"洗车问题"上持续失败，研究旨在探索生产系统中哪些提示架构层能够实现正确推理

Method: 使用Claude 3.5 Sonnet进行变量隔离研究（n=20/条件，6条件，共120次试验），控制超参数（温度0.7，top_p 1.0），测试不同提示架构层：基础、STAR框架、用户档案上下文、RAG上下文等组合

Result: STAR推理框架单独将准确率从0%提升至85%（p=0.001），添加用户档案上下文再提升10个百分点，RAG上下文再提升5个百分点，完整堆栈条件达到100%准确率

Conclusion: 对于隐式约束推理任务，结构化推理支架（特别是推理前的强制目标阐述）比上下文注入更为重要，STAR框架显著提升模型性能

Abstract: Large language models consistently fail the "car wash problem," a viral reasoning benchmark requiring implicit physical constraint inference. We present a variable isolation study (n=20 per condition, 6 conditions, 120 total trials) examining which prompt architecture layers in a production system enable correct reasoning. Using Claude 3.5 Sonnet with controlled hyperparameters (temperature 0.7, top_p 1.0), we find that the STAR (Situation-Task-Action-Result) reasoning framework alone raises accuracy from 0% to 85% (p=0.001, Fisher's exact test, odds ratio 13.22). Adding user profile context via vector database retrieval provides a further 10 percentage point gain, while RAG context contributes an additional 5 percentage points, achieving 100% accuracy in the full-stack condition. These results suggest that structured reasoning scaffolds -- specifically, forced goal articulation before inference -- matter substantially more than context injection for implicit constraint reasoning tasks.

</details>


### [72] [Distill and Align Decomposition for Enhanced Claim Verification](https://arxiv.org/abs/2602.21857)
*Jabez Magomere,Elena Kochkina,Samuel Mensah,Simerjot Kaur,Fernando Acero,Arturo Oncevay,Charese H. Smiley,Xiaomo Liu,Manuela Veloso*

Main category: cs.AI

TL;DR: 提出基于强化学习的联合优化方法，通过GRPO同时提升分解质量和验证对齐，使小型语言模型在复杂声明验证任务上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在复杂声明验证中难以将分解质量与验证性能对齐，需要一种能够同时优化这两个方面的解决方案。

Method: 采用强化学习方法，结合结构化顺序推理、教师蒸馏示例的监督微调，以及平衡格式合规性、验证对齐和分解质量的多目标奖励机制。

Result: 在六个评估设置中，训练的8B分解器将下游验证性能提升至71.75% macro-F1，优于提示方法（+1.99，+6.24）和现有RL方法（+5.84），人类评估确认生成子声明的高质量。

Conclusion: 该框架使小型语言模型能够通过联合优化验证准确性和分解质量，在声明验证任务上达到最先进水平。

Abstract: Complex claim verification requires decomposing sentences into verifiable subclaims, yet existing methods struggle to align decomposition quality with verification performance. We propose a reinforcement learning (RL) approach that jointly optimizes decomposition quality and verifier alignment using Group Relative Policy Optimization (GRPO). Our method integrates: (i) structured sequential reasoning; (ii) supervised finetuning on teacher-distilled exemplars; and (iii) a multi-objective reward balancing format compliance, verifier alignment, and decomposition quality. Across six evaluation settings, our trained 8B decomposer improves downstream verification performance to (71.75%) macro-F1, outperforming prompt-based approaches ((+1.99), (+6.24)) and existing RL methods ((+5.84)). Human evaluation confirms the high quality of the generated subclaims. Our framework enables smaller language models to achieve state-of-the-art claim verification by jointly optimising for verification accuracy and decomposition quality.

</details>


### [73] [ProactiveMobile: A Comprehensive Benchmark for Boosting Proactive Intelligence on Mobile Devices](https://arxiv.org/abs/2602.21858)
*Dezhi Kong,Zhengzhao Feng,Qiliang Liang,Hao Wang,Haofei Sun,Changpeng Yang,Yang Li,Peng Zhou,Shuai Nie,Hongzhen Wang,Linfeng Zhou,Hao Jia,Jiaming Xu,Runyu Shi,Ying Huang*

Main category: cs.AI

TL;DR: ProactiveMobile是一个用于评估移动代理主动智能能力的基准测试，包含3,660个实例、14个场景和63个API，旨在解决现有MLLMs在主动预测用户意图方面的不足。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型（MLLMs）在移动代理开发中主要局限于被动执行用户命令的范式，而主动智能（代理自主预测需求并启动行动）是下一代移动代理的关键能力，但缺乏能够应对现实世界复杂性并进行客观可执行评估的基准测试。

Method: 提出ProactiveMobile基准，将主动任务形式化为：基于设备上下文信号的四个维度推断潜在用户意图，并从包含63个API的综合函数池中生成可执行函数序列。基准包含3,660个实例、14个场景，采用多答案标注以应对现实复杂性，并由30名专家团队进行最终审核，确保事实准确性、逻辑一致性和行动可行性。

Result: 实验表明，微调的Qwen2.5-VL-7B-Instruct模型在基准测试中达到19.15%的成功率，优于o1（15.71%）和GPT-5（7.39%）。这表明主动智能是当前MLLMs普遍缺乏但可学习的关键能力。

Conclusion: 主动智能是移动代理发展的关键前沿，ProactiveMobile基准为评估和推动这一领域研究提供了重要工具，揭示了当前MLLMs在主动能力方面的显著不足，同时证明了这种能力可以通过学习获得。

Abstract: Multimodal large language models (MLLMs) have made significant progress in mobile agent development, yet their capabilities are predominantly confined to a reactive paradigm, where they merely execute explicit user commands. The emerging paradigm of proactive intelligence, where agents autonomously anticipate needs and initiate actions, represents the next frontier for mobile agents. However, its development is critically bottlenecked by the lack of benchmarks that can address real-world complexity and enable objective, executable evaluation. To overcome these challenges, we introduce ProactiveMobile, a comprehensive benchmark designed to systematically advance research in this domain. ProactiveMobile formalizes the proactive task as inferring latent user intent across four dimensions of on-device contextual signals and generating an executable function sequence from a comprehensive function pool of 63 APIs. The benchmark features over 3,660 instances of 14 scenarios that embrace real-world complexity through multi-answer annotations. To ensure quality, a team of 30 experts conducts a final audit of the benchmark, verifying factual accuracy, logical consistency, and action feasibility, and correcting any non-compliant entries. Extensive experiments demonstrate that our fine-tuned Qwen2.5-VL-7B-Instruct achieves a success rate of 19.15%, outperforming o1 (15.71%) and GPT-5 (7.39%). This result indicates that proactivity is a critical competency widely lacking in current MLLMs, yet it is learnable, emphasizing the importance of the proposed benchmark for proactivity evaluation.

</details>


### [74] [Language Models Exhibit Inconsistent Biases Towards Algorithmic Agents and Human Experts](https://arxiv.org/abs/2602.22070)
*Jessica Y. Bo,Lillio Mok,Ashton Anderson*

Main category: cs.AI

TL;DR: LLMs在决策任务中对人类专家和算法表现出不一致的偏见：口头评价时更信任人类，但实际选择时却偏向算法，即使算法表现更差。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在处理不同来源信息（人类专家和算法代理）时的权重分配问题，探讨是否存在类似人类的"算法厌恶"偏见，这对LLMs在高风险场景中的部署至关重要。

Method: 采用行为经济学实验范式，评估8个不同LLMs在决策任务中的表现。使用两种任务呈现方式：1）陈述性偏好（直接询问对代理的信任度）；2）显示性偏好（提供两种代理表现的上下文示例，要求进行激励性投注选择）。

Result: 当直接评价信任度时，LLMs给人类专家的评分更高；但在看到实际表现后要求进行激励性投注时，LLMs不成比例地选择算法，即使算法表现明显更差。这表明LLMs编码了不一致的偏见。

Conclusion: LLMs对人类和算法存在不一致的偏见，任务呈现格式对其决策有显著影响。这些发现对AI安全评估的稳健性提出了重要警示，特别是在高风险部署场景中需要仔细考虑这些偏见。

Abstract: Large language models are increasingly used in decision-making tasks that require them to process information from a variety of sources, including both human experts and other algorithmic agents. How do LLMs weigh the information provided by these different sources? We consider the well-studied phenomenon of algorithm aversion, in which human decision-makers exhibit bias against predictions from algorithms. Drawing upon experimental paradigms from behavioural economics, we evaluate how eightdifferent LLMs delegate decision-making tasks when the delegatee is framed as a human expert or an algorithmic agent. To be inclusive of different evaluation formats, we conduct our study with two task presentations: stated preferences, modeled through direct queries about trust towards either agent, and revealed preferences, modeled through providing in-context examples of the performance of both agents. When prompted to rate the trustworthiness of human experts and algorithms across diverse tasks, LLMs give higher ratings to the human expert, which correlates with prior results from human respondents. However, when shown the performance of a human expert and an algorithm and asked to place an incentivized bet between the two, LLMs disproportionately choose the algorithm, even when it performs demonstrably worse. These discrepant results suggest that LLMs may encode inconsistent biases towards humans and algorithms, which need to be carefully considered when they are deployed in high-stakes scenarios. Furthermore, we discuss the sensitivity of LLMs to task presentation formats that should be broadly scrutinized in evaluation robustness for AI safety.

</details>
