<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 68]
- [cs.CL](#cs.CL) [Total: 45]
- [cs.AI](#cs.AI) [Total: 52]
- [cs.DB](#cs.DB) [Total: 3]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [AI-Based Culvert-Sewer Inspection](https://arxiv.org/abs/2601.15366)
*Christina Thrainer*

Main category: cs.CV

TL;DR: 该论文提出三种方法解决排水管道缺陷分割中的数据稀缺问题：数据增强预处理、新型FORTRESS架构和少样本学习，显著提升了分割性能。


<details>
  <summary>Details</summary>
Motivation: 排水管道和涵洞缺陷检测对公共安全至关重要，但数据收集和标注困难，缺乏大规模标注数据集，需要解决数据稀缺条件下的自动缺陷分割问题。

Method: 1) 评估预处理策略，包括传统数据增强和动态标签注入；2) 提出FORTRESS架构，结合深度可分离卷积、自适应KAN网络和多尺度注意力机制；3) 研究少样本语义分割，采用双向原型网络加注意力机制。

Result: 数据增强显著提升IoU和F1分数；FORTRESS在管道缺陷数据集上达到SOTA性能，同时大幅减少可训练参数和计算成本；少样本学习方法在各项评估指标上取得满意结果。

Conclusion: 通过数据增强、新型架构设计和少样本学习三种方法，有效解决了排水管道缺陷分割中的数据稀缺问题，为实际应用提供了可行的技术方案。

Abstract: Culverts and sewer pipes are critical components of drainage systems, and their failure can lead to serious risks to public safety and the environment. In this thesis, we explore methods to improve automated defect segmentation in culverts and sewer pipes. Collecting and annotating data in this field is cumbersome and requires domain knowledge. Having a large dataset for structural defect detection is therefore not feasible. Our proposed methods are tested under conditions with limited annotated data to demonstrate applicability to real-world scenarios. Overall, this thesis proposes three methods to significantly enhance defect segmentation and handle data scarcity. This can be addressed either by enhancing the training data or by adjusting a models architecture.
  First, we evaluate preprocessing strategies, including traditional data augmentation and dynamic label injection. These techniques significantly improve segmentation performance, increasing both Intersection over Union (IoU) and F1 score. Second, we introduce FORTRESS, a novel architecture that combines depthwise separable convolutions, adaptive Kolmogorov-Arnold Networks (KAN), and multi-scale attention mechanisms. FORTRESS achieves state-of-the-art performance on the culvert sewer pipe defect dataset, while significantly reducing the number of trainable parameters, as well as its computational cost. Finally, we investigate few-shot semantic segmentation and its applicability to defect detection. Few-shot learning aims to train models with only limited data available. By employing a bidirectional prototypical network with attention mechanisms, the model achieves richer feature representations and achieves satisfactory results across evaluation metrics.

</details>


### [2] [Evaluating Multimodal Large Language Models for Heterogeneous Face Recognition](https://arxiv.org/abs/2601.15406)
*Hatef Otroshi Shahreza,Anjith George,Sébastien Marcel*

Main category: cs.CV

TL;DR: MLLMs在异质人脸识别任务中表现不佳，与经典人脸识别系统存在显著性能差距，特别是在跨光谱条件下。


<details>
  <summary>Details</summary>
Motivation: 评估多模态大语言模型在异质人脸识别中的潜力，因为MLLMs在视觉语言任务上表现出色，但尚未在生物识别应用中得到系统评估。

Method: 对多个开源MLLMs进行系统评估，涵盖VIS-NIR、VIS-SWIR、VIS-THERMAL等跨模态场景，使用生物识别协议和多种指标（获取率、等错误率、真接受率）。

Result: MLLMs与经典人脸识别系统存在显著性能差距，特别是在具有挑战性的跨光谱条件下，尽管MLLMs最近取得了进展。

Conclusion: 当前MLLMs在异质人脸识别中存在局限性，在考虑将其部署到人脸识别系统时，严格的生物识别评估至关重要。

Abstract: Multimodal Large Language Models (MLLMs) have recently demonstrated strong performance on a wide range of vision-language tasks, raising interest in their potential use for biometric applications. In this paper, we conduct a systematic evaluation of state-of-the-art MLLMs for heterogeneous face recognition (HFR), where enrollment and probe images are from different sensing modalities, including visual (VIS), near infrared (NIR), short-wave infrared (SWIR), and thermal camera. We benchmark multiple open-source MLLMs across several cross-modality scenarios, including VIS-NIR, VIS-SWIR, and VIS-THERMAL face recognition. The recognition performance of MLLMs is evaluated using biometric protocols and based on different metrics, including Acquire Rate, Equal Error Rate (EER), and True Accept Rate (TAR). Our results reveal substantial performance gaps between MLLMs and classical face recognition systems, particularly under challenging cross-spectral conditions, in spite of recent advances in MLLMs. Our findings highlight the limitations of current MLLMs for HFR and also the importance of rigorous biometric evaluation when considering their deployment in face recognition systems.

</details>


### [3] [CURE: Curriculum-guided Multi-task Training for Reliable Anatomy Grounded Report Generation](https://arxiv.org/abs/2601.15408)
*Pablo Messina,Andrés Villa,Juan León Alcázar,Karen Sánchez,Carlos Hinojosa,Denis Parra,Álvaro Soto,Bernard Ghanem*

Main category: cs.CV

TL;DR: CURE是一个用于医学视觉语言模型的错误感知课程学习框架，通过动态调整训练样本难度来改善放射学报告生成中的视觉定位和事实一致性，无需额外数据。


<details>
  <summary>Details</summary>
Motivation: 现有医学视觉语言模型在生成放射学报告时存在视觉定位不准确和事实不一致的问题，导致预测结果不可靠或弱定位，需要改进模型的视觉-文本对齐能力。

Method: CURE框架采用错误感知课程学习方法，在短语定位、定位报告生成和解剖学定位报告生成三个任务上微调多模态指令模型，根据模型性能动态调整样本采样，强调更难样本来改善空间和文本对齐。

Result: CURE将定位准确率提高了+0.37 IoU，报告质量提升了+0.188 CXRFEScore，幻觉减少了18.6%，显著改善了视觉定位和报告可靠性。

Conclusion: CURE是一个数据高效的学习框架，能够同时提升医学视觉语言模型的定位准确性和报告可靠性，为自动化放射学报告生成提供了更可靠的解决方案。

Abstract: Medical vision-language models can automate the generation of radiology reports but struggle with accurate visual grounding and factual consistency. Existing models often misalign textual findings with visual evidence, leading to unreliable or weakly grounded predictions. We present CURE, an error-aware curriculum learning framework that improves grounding and report quality without any additional data. CURE fine-tunes a multimodal instructional model on phrase grounding, grounded report generation, and anatomy-grounded report generation using public datasets. The method dynamically adjusts sampling based on model performance, emphasizing harder samples to improve spatial and textual alignment. CURE improves grounding accuracy by +0.37 IoU, boosts report quality by +0.188 CXRFEScore, and reduces hallucinations by 18.6%. CURE is a data-efficient framework that enhances both grounding accuracy and report reliability. Code is available at https://github.com/PabloMessina/CURE and model weights at https://huggingface.co/pamessina/medgemma-4b-it-cure

</details>


### [4] [DuFal: Dual-Frequency-Aware Learning for High-Fidelity Extremely Sparse-view CBCT Reconstruction](https://arxiv.org/abs/2601.15416)
*Cuong Tran Van,Trong-Thang Pham,Ngoc-Son Nguyen,Duy Minh Ho Nguyen,Ngan Le*

Main category: cs.CV

TL;DR: DuFal是一个用于稀疏视角锥束CT重建的双频感知学习框架，通过全局和局部高频增强的傅里叶神经算子，结合频域和空间域处理，有效恢复高频解剖细节。


<details>
  <summary>Details</summary>
Motivation: 稀疏视角CT重建面临的主要挑战是难以恢复高频解剖细节，因为传统CNN方法偏向学习低频信息，导致细粒度结构恢复不足。

Method: 提出双路径架构：1) 全局高频增强傅里叶神经算子捕获全局频率模式；2) 局部高频增强傅里叶神经算子处理空间分区补丁；3) 谱通道因子化减少参数；4) 交叉注意力频率融合模块整合特征；5) 特征解码和强度场解码管道重建CT体积。

Result: 在LUNA16和ToothFairy数据集上，DuFal在保留高频解剖特征方面显著优于现有方法，特别是在极端稀疏视角设置下。

Conclusion: DuFal通过双频感知学习有效解决了稀疏视角CT重建中高频细节恢复的挑战，为医学影像重建提供了新思路。

Abstract: Sparse-view Cone-Beam Computed Tomography reconstruction from limited X-ray projections remains a challenging problem in medical imaging due to the inherent undersampling of fine-grained anatomical details, which correspond to high-frequency components. Conventional CNN-based methods often struggle to recover these fine structures, as they are typically biased toward learning low-frequency information. To address this challenge, this paper presents DuFal (Dual-Frequency-Aware Learning), a novel framework that integrates frequency-domain and spatial-domain processing via a dual-path architecture. The core innovation lies in our High-Local Factorized Fourier Neural Operator, which comprises two complementary branches: a Global High-Frequency Enhanced Fourier Neural Operator that captures global frequency patterns and a Local High-Frequency Enhanced Fourier Neural Operator that processes spatially partitioned patches to preserve spatial locality that might be lost in global frequency analysis. To improve efficiency, we design a Spectral-Channel Factorization scheme that reduces the Fourier Neural Operator parameter count. We also design a Cross-Attention Frequency Fusion module to integrate spatial and frequency features effectively. The fused features are then decoded through a Feature Decoder to produce projection representations, which are subsequently processed through an Intensity Field Decoding pipeline to reconstruct a final Computed Tomography volume. Experimental results on the LUNA16 and ToothFairy datasets demonstrate that DuFal significantly outperforms existing state-of-the-art methods in preserving high-frequency anatomical features, particularly under extremely sparse-view settings.

</details>


### [5] [DevPrompt: Deviation-Based Prompt Learning for One-Normal ShotImage Anomaly Detection](https://arxiv.org/abs/2601.15453)
*Morteza Poudineh,Marc Lalonde*

Main category: cs.CV

TL;DR: 提出了一种基于偏差引导的提示学习框架，用于少样本正常图像异常检测，通过可学习提示和统计偏差评分提高异常定位能力


<details>
  <summary>Details</summary>
Motivation: 现有的少样本异常检测方法存在正常与异常提示区分度弱、缺乏原则性评分机制的问题，需要结合视觉语言模型的语义能力和统计可靠性

Method: 使用可学习的上下文向量替代固定提示前缀，异常特定后缀实现类别感知对齐；引入带Top-K多实例学习的偏差损失，将补丁级特征建模为高斯偏差

Result: 在MVTecAD和VISA基准测试中表现出优于PromptAD等基线的像素级检测性能，消融研究验证了可学习提示、偏差评分和Top-K MIL策略的有效性

Conclusion: 该框架成功结合了视觉语言模型的语义能力和统计偏差评分，显著提高了少样本异常检测的性能和可解释性

Abstract: Few-normal shot anomaly detection (FNSAD) aims to detect abnormal regions in images using only a few normal training samples, making the task highly challenging due to limited supervision and the diversity of potential defects. Recent approaches leverage vision-language models such as CLIP with prompt-based learning to align image and text features. However, existing methods often exhibit weak discriminability between normal and abnormal prompts and lack principled scoring mechanisms for patch-level anomalies. We propose a deviation-guided prompt learning framework that integrates the semantic power of vision-language models with the statistical reliability of deviation-based scoring. Specifically, we replace fixed prompt prefixes with learnable context vectors shared across normal and abnormal prompts, while anomaly-specific suffix tokens enable class-aware alignment. To enhance separability, we introduce a deviation loss with Top-K Multiple Instance Learning (MIL), modeling patch-level features as Gaussian deviations from the normal distribution. This allows the network to assign higher anomaly scores to patches with statistically significant deviations, improving localization and interpretability. Experiments on the MVTecAD and VISA benchmarks demonstrate superior pixel-level detection performance compared to PromptAD and other baselines. Ablation studies further validate the effectiveness of learnable prompts, deviation-based scoring, and the Top-K MIL strategy.

</details>


### [6] [Seeing through Light and Darkness: Sensor-Physics Grounded Deblurring HDR NeRF from Single-Exposure Images and Events](https://arxiv.org/abs/2601.15475)
*Yunshan Qi,Lin Zhu,Nan Bao,Yifan Zhao,Jia Li*

Main category: cs.CV

TL;DR: 提出一个基于传感器物理的NeRF框架，从单曝光模糊LDR图像和对应事件数据中合成清晰的HDR新视角图像


<details>
  <summary>Details</summary>
Motivation: 现有方法使用事件数据解决低动态范围(LDR)模糊图像的新视角合成问题，但忽略了相机输出与物理世界辐射之间的传感器物理不匹配，导致HDR和去模糊效果不理想

Method: 提出统一的传感器物理基础NeRF框架：1) 用NeRF直接表示HDR域中的实际场景辐射；2) 引入像素级RGB映射场对齐渲染像素值与传感器记录的LDR像素值；3) 设计事件映射场桥接物理场景动态与事件传感器输出；4) 联合优化两个映射场与NeRF网络

Result: 在收集和公开数据集上的实验表明，该方法能够实现最先进的去模糊HDR新视角合成效果

Conclusion: 通过传感器物理建模和联合优化框架，能够从单曝光模糊LDR图像和事件数据中有效学习清晰的HDR 3D表示

Abstract: Novel view synthesis from low dynamic range (LDR) blurry images, which are common in the wild, struggles to recover high dynamic range (HDR) and sharp 3D representations in extreme lighting conditions. Although existing methods employ event data to address this issue, they ignore the sensor-physics mismatches between the camera output and physical world radiance, resulting in suboptimal HDR and deblurring results. To cope with this problem, we propose a unified sensor-physics grounded NeRF framework for sharp HDR novel view synthesis from single-exposure blurry LDR images and corresponding events. We employ NeRF to directly represent the actual radiance of the 3D scene in the HDR domain and model raw HDR scene rays hitting the sensor pixels as in the physical world. A pixel-wise RGB mapping field is introduced to align the above rendered pixel values with the sensor-recorded LDR pixel values of the input images. A novel event mapping field is also designed to bridge the physical scene dynamics and actual event sensor output. The two mapping fields are jointly optimized with the NeRF network, leveraging the spatial and temporal dynamic information in events to enhance the sharp HDR 3D representation learning. Experiments on the collected and public datasets demonstrate that our method can achieve state-of-the-art deblurring HDR novel view synthesis results with single-exposure blurry LDR images and corresponding events.

</details>


### [7] [Hybrid Vision Transformer_GAN Attribute Neutralizer for Mitigating Bias in Chest X_Ray Diagnosis](https://arxiv.org/abs/2601.15490)
*Jobeal Solomon,Ali Mohammed Mansoor Alsahag,Seyed Sahand Mohammadi Ziabari*

Main category: cs.CV

TL;DR: 使用Vision Transformer替代U-Net卷积编码器，在胸部X光分类器中进一步减少性别和年龄相关的偏见泄漏，同时保持诊断准确性。


<details>
  <summary>Details</summary>
Motivation: 胸部X光分类器经常存在性别和年龄相关的捷径偏差，导致少数亚组的系统性漏诊。之前的像素空间属性中和器虽然能减少但无法完全消除属性泄漏。

Method: 在属性中性框架中用Vision Transformer（DeiT-S）替代U-Net卷积编码器，在ChestX-ray14数据集上训练，生成11个编辑强度级别的图像，用独立AI评估属性泄漏和疾病预测性能。

Result: 在中等编辑强度（alpha=0.5）下，ViT中和器将患者性别识别AUC降至约0.80，比原始卷积U-Net编码器低约10个百分点，同时15种发现的宏观ROC AUC保持在未编辑基线的5个百分点内，最差亚组AUC接近0.70。

Conclusion: 全局自注意力视觉模型能进一步抑制属性泄漏而不牺牲临床效用，为实现更公平的胸部X光AI提供了实用途径。

Abstract: Bias in chest X-ray classifiers frequently stems from sex- and age-related shortcuts, leading to systematic underdiagnosis of minority subgroups. Previous pixel-space attribute neutralizers, which rely on convolutional encoders, lessen but do not fully remove this attribute leakage at clinically usable edit strengths. This study evaluates whether substituting the U-Net convolutional encoder with a Vision Transformer backbone in the Attribute-Neutral Framework can reduce demographic attribute leakage while preserving diagnostic accuracy. A data-efficient Image Transformer Small (DeiT-S) neutralizer was trained on the ChestX-ray14 dataset. Its edited images, generated across eleven edit-intensity levels, were evaluated with an independent AI judge for attribute leakage and with a convolutional neural network (ConvNet) for disease prediction. At a moderate edit level (alpha = 0.5), the Vision Transformer (ViT) neutralizer reduces patient sex-recognition area under the curve (AUC) to approximately 0.80, about 10 percentage points below the original framework's convolutional U-Net encoder, despite being trained for only half as many epochs. Meanwhile, macro receiver operating characteristic area under the curve (ROC AUC) across 15 findings stays within five percentage points of the unedited baseline, and the worst-case subgroup AUC remains near 0.70. These results indicate that global self-attention vision models can further suppress attribute leakage without sacrificing clinical utility, suggesting a practical route toward fairer chest X-ray AI.

</details>


### [8] [Controllable Layered Image Generation for Real-World Editing](https://arxiv.org/abs/2601.15507)
*Jinrui Yang,Qing Liu,Yijun Li,Mengwei Ren,Letian Zhang,Zhe Lin,Cihang Xie,Yuyin Zhou*

Main category: cs.CV

TL;DR: LASAGNA是一个统一的图像生成框架，能够同时生成图像及其组成层（背景和透明前景层），支持多种条件输入，提供更好的可控性和编辑能力。


<details>
  <summary>Details</summary>
Motivation: 现有图像生成模型在编辑特定元素时难以产生可控和一致的结果，现有分层方法通常无法产生具有连贯合成关系的层，且对象层缺乏阴影、反射等真实视觉效果。

Method: 提出LASAGNA框架，从多种条件输入（文本提示、前景、背景和位置掩码）中高效学习正确的图像合成，并引入LASAGNA-48K数据集（包含干净背景和具有物理基础视觉效果的RGBA前景）以及LASAGNABENCH基准测试。

Result: LASAGNA在同时生成多个图像层时表现出高度一致性和连贯性，支持多种后编辑应用，能够准确保持身份和视觉效果。

Conclusion: LASAGNA通过统一框架解决了分层图像生成中的一致性和可控性问题，提供了更好的编辑能力，相关数据集和基准测试将公开发布以促进社区研究。

Abstract: Recent image generation models have shown impressive progress, yet they often struggle to yield controllable and consistent results when users attempt to edit specific elements within an existing image. Layered representations enable flexible, user-driven content creation, but existing approaches often fail to produce layers with coherent compositing relationships, and their object layers typically lack realistic visual effects such as shadows and reflections. To overcome these limitations, we propose LASAGNA, a novel, unified framework that generates an image jointly with its composing layers--a photorealistic background and a high-quality transparent foreground with compelling visual effects. Unlike prior work, LASAGNA efficiently learns correct image composition from a wide range of conditioning inputs--text prompts, foreground, background, and location masks--offering greater controllability for real-world applications. To enable this, we introduce LASAGNA-48K, a new dataset composed of clean backgrounds and RGBA foregrounds with physically grounded visual effects. We also propose LASAGNABENCH, the first benchmark for layer editing. We demonstrate that LASAGNA excels in generating highly consistent and coherent results across multiple image layers simultaneously, enabling diverse post-editing applications that accurately preserve identity and visual effects. LASAGNA-48K and LASAGNABENCH will be publicly released to foster open research in the community. The project page is https://rayjryang.github.io/LASAGNA-Page/.

</details>


### [9] [DeltaDorsal: Enhancing Hand Pose Estimation with Dorsal Features in Egocentric Views](https://arxiv.org/abs/2601.15516)
*William Huang,Siyou Pei,Leyi Zou,Eric J. Gonzalez,Ishan Chatterjee,Yang Zhang*

Main category: cs.CV

TL;DR: 提出一种利用手背皮肤变形信息的手部姿态估计新方法，通过对比动态手部与放松基准姿态的特征，在手指遮挡场景下显著提升性能。


<details>
  <summary>Details</summary>
Motivation: XR设备普及使得第一人称手部姿态估计变得重要，但该视角常面临手指遮挡问题。传统方法依赖完整手部几何信息和大模型，在遮挡场景下效果受限。

Method: 提出双流delta编码器，利用密集视觉特征提取器，通过对比动态手部与放松基准姿态的特征来学习姿态。仅使用裁剪后的手背图像，无需完整手部几何信息。

Result: 在手指遮挡≥50%的场景下，将MPJAE降低了18%，优于依赖完整手部几何和大模型的方法。同时提升了食指捏合和点击估计的可靠性，并实现了等长力检测等新交互范式。

Conclusion: 该方法通过利用手背皮肤变形信息，在手指遮挡场景下显著提升了手部姿态估计性能，同时减小了模型尺寸，为XR交互开辟了新可能性。

Abstract: The proliferation of XR devices has made egocentric hand pose estimation a vital task, yet this perspective is inherently challenged by frequent finger occlusions. To address this, we propose a novel approach that leverages the rich information in dorsal hand skin deformation, unlocked by recent advances in dense visual featurizers. We introduce a dual-stream delta encoder that learns pose by contrasting features from a dynamic hand with a baseline relaxed position. Our evaluation demonstrates that, using only cropped dorsal images, our method reduces the Mean Per Joint Angle Error (MPJAE) by 18% in self-occluded scenarios (fingers >=50% occluded) compared to state-of-the-art techniques that depend on the whole hand's geometry and large model backbones. Consequently, our method not only enhances the reliability of downstream tasks like index finger pinch and tap estimation in occluded scenarios but also unlocks new interaction paradigms, such as detecting isometric force for a surface "click" without visible movement while minimizing model size.

</details>


### [10] [VIOLA: Towards Video In-Context Learning with Minimal Annotations](https://arxiv.org/abs/2601.15549)
*Ryo Fujii,Hideo Saito,Ryo Hachiuma*

Main category: cs.CV

TL;DR: VIOLA框架通过密度-不确定性加权采样和置信度感知机制，在最小标注成本下实现视频多模态大语言模型的有效领域适应


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在真实世界部署中需要适应新视频领域，但标注数据稀缺，特别是在工业或手术等专业环境中专家标注成本高昂。现有上下文学习方法依赖大量标注数据，在专业场景中不实用。

Method: 提出VIOLA框架：1) 密度-不确定性加权采样，结合密度估计选择既多样、有代表性又信息丰富的样本；2) 构建混合池，通过置信度感知检索和置信度感知提示，显式建模标签可靠性，区分真实标注和噪声伪标签。

Result: 在9个不同基准测试和4个MLLM上的实验表明，VIOLA在低资源设置下显著优于各种基线方法，能以最小标注成本实现鲁棒的领域适应。

Conclusion: VIOLA框架通过最小专家监督与大量未标注数据的协同，为MLLM在专业视频领域的训练免费适应提供了有效解决方案，解决了标注稀缺环境下的领域适应挑战。

Abstract: Generalizing Multimodal Large Language Models (MLLMs) to novel video domains is essential for real-world deployment but remains challenging due to the scarcity of labeled data. While In-Context Learning (ICL) offers a training-free adaptation path, standard methods rely on large annotated pools, which are often impractical in specialized environments like industrial or surgical settings since they require the experts' annotations. To bridge this gap, we introduce VIOLA (Video In-cOntext Learning with minimal Annotation), a label-efficient framework that synergizes minimal expert supervision with abundant unlabeled data. First, to maximize the efficiency of a strict annotation budget, we propose density-uncertainty-weighted sampling. Unlike standard diversity or uncertainty strategies that risk selecting visual outliers, our method leverages density estimation to identify samples that are simultaneously diverse, representative, and informative. Second, to utilize the remaining unlabeled data without noise propagation, we construct a hybrid pool and introduce confidence-aware retrieval and confidence-aware prompting. These mechanisms explicitly model label reliability, retrieving demonstrations based on a composite score of similarity and confidence while enabling the MLLM to adaptively distinguish between verified ground truths and noisy pseudo-labels. Extensive experiments across nine diverse benchmarks using four MLLMs demonstrate that our framework significantly outperforms various baselines in low-resource settings, achieving robust adaptation with minimal annotation costs.

</details>


### [11] [Relative Classification Accuracy: A Calibrated Metric for Identity Consistency in Fine-Grained K-pop Face Generation](https://arxiv.org/abs/2601.15560)
*Sylvey Lin,Eranki Vasistha*

Main category: cs.CV

TL;DR: 该研究评估了DDPM在K-pop偶像人脸生成中的语义可控性，发现模型在视觉质量（FID 8.93）和语义模式崩溃（RCA 0.27）之间存在关键权衡，提出了RCA指标来量化身份一致性。


<details>
  <summary>Details</summary>
Motivation: 现有评估指标（如FID和IS）在细粒度单域任务中难以检测身份错位问题，特别是在K-pop偶像人脸生成这种类间相似度高的领域，需要更有效的语义可控性评估方法。

Method: 使用类条件DDPM进行32x32 K-pop偶像人脸生成，提出相对分类准确率（RCA）指标，通过混淆矩阵分析失败模式，并归因于分辨率限制和性别内模糊性。

Result: 模型在视觉质量上表现良好（FID 8.93），但存在严重的语义模式崩溃（RCA 0.27），特别是在视觉模糊的身份上。混淆矩阵分析揭示了分辨率约束和性别内模糊性是主要问题。

Conclusion: 该框架为条件生成模型的身份一致性验证提供了严格标准，揭示了高视觉质量与语义可控性之间的权衡，对细粒度生成任务具有重要意义。

Abstract: Denoising Diffusion Probabilistic Models (DDPMs) have achieved remarkable success in high-fidelity image generation. However, evaluating their semantic controllability-specifically for fine-grained, single-domain tasks-remains challenging. Standard metrics like FID and Inception Score (IS) often fail to detect identity misalignment in such specialized contexts. In this work, we investigate Class-Conditional DDPMs for K-pop idol face generation (32x32), a domain characterized by high inter-class similarity. We propose a calibrated metric, Relative Classification Accuracy (RCA), which normalizes generative performance against an oracle classifier's baseline. Our evaluation reveals a critical trade-off: while the model achieves high visual quality (FID 8.93), it suffers from severe semantic mode collapse (RCA 0.27), particularly for visually ambiguous identities. We analyze these failure modes through confusion matrices and attribute them to resolution constraints and intra-gender ambiguity. Our framework provides a rigorous standard for verifying identity consistency in conditional generative models.

</details>


### [12] [Region-aware Spatiotemporal Modeling with Collaborative Domain Generalization for Cross-Subject EEG Emotion Recognition](https://arxiv.org/abs/2601.15615)
*Weiwei Wu,Yueyang Li,Yuhu Shi,Weiming Zeng,Lang Qin,Yang Yang,Ke Zhou,Zhiguo Zhang,Wai Ting Siok,Nizhuan Wang*

Main category: cs.CV

TL;DR: 提出RSM-CoDG框架，通过区域感知时空建模与协作域泛化，解决跨被试EEG情绪识别中的主体间变异性问题，在SEED数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 跨被试EEG情绪识别面临主体间变异性大导致的分布偏移问题，现有方法通常孤立地改进空间建模、时间建模或泛化策略，缺乏统一框架来对齐跨被试表征并抑制主体特异性偏差。

Method: 提出RSM-CoDG框架：1) 基于功能脑区分区构建区域级空间表征；2) 多尺度时间建模捕捉情绪诱发神经活动的动态演化；3) 协作域泛化策略，通过多维约束在完全未见目标被试设置下减少主体特异性偏差。

Result: 在SEED系列数据集上的大量实验结果表明，RSM-CoDG持续优于现有竞争方法，为提升跨被试EEG情绪识别的鲁棒性提供了有效方法。

Conclusion: RSM-CoDG通过整合神经科学先验、多尺度时间建模和协作域泛化，有效解决了跨被试EEG情绪识别中的关键挑战，显著提升了模型的泛化能力。

Abstract: Cross-subject EEG-based emotion recognition (EER) remains challenging due to strong inter-subject variability, which induces substantial distribution shifts in EEG signals, as well as the high complexity of emotion-related neural representations in both spatial organization and temporal evolution. Existing approaches typically improve spatial modeling, temporal modeling, or generalization strategies in isolation, which limits their ability to align representations across subjects while capturing multi-scale dynamics and suppressing subject-specific bias within a unified framework. To address these gaps, we propose a Region-aware Spatiotemporal Modeling framework with Collaborative Domain Generalization (RSM-CoDG) for cross-subject EEG emotion recognition. RSM-CoDG incorporates neuroscience priors derived from functional brain region partitioning to construct region-level spatial representations, thereby improving cross-subject comparability. It also employs multi-scale temporal modeling to characterize the dynamic evolution of emotion-evoked neural activity. In addition, the framework employs a collaborative domain generalization strategy, incorporating multidimensional constraints to reduce subject-specific bias in a fully unseen target subject setting, which enhances the generalization to unknown individuals. Extensive experimental results on SEED series datasets demonstrate that RSM-CoDG consistently outperforms existing competing methods, providing an effective approach for improving robustness. The source code is available at https://github.com/RyanLi-X/RSM-CoDG.

</details>


### [13] [Explainable Deepfake Detection with RL Enhanced Self-Blended Images](https://arxiv.org/abs/2601.15624)
*Ning Jiang,Dingheng Zeng,Yanhong Liu,Haiyang Yi,Shijie Yu,Minghe Weng,Haifeng Shen,Ying Li*

Main category: cs.CV

TL;DR: 提出基于自混合图像的自動化思維鏈數據生成框架和強化學習增強的深度偽造檢測框架，以解決MLLM在深度偽造檢測中缺乏高質量註釋數據的問題。


<details>
  <summary>Details</summary>
Motivation: 現有深度偽造檢測方法缺乏可解釋性輸出，而多模態大語言模型(MLLM)在可解釋檢測方面具有潛力，但面臨高質量偽造歸因註釋數據稀缺的問題。同時，強化學習在視覺任務中顯示出提升跨域泛化能力的潛力。

Method: 1. 基於自混合圖像的自動化思維鏈數據生成框架；2. 強化學習增強的深度偽造檢測框架，包括定製獎勵機制和反饋驅動的合成數據生成方法。

Result: 在跨數據集基準測試中，該方法達到了與最先進方法相當的性能，驗證了思維鏈數據構建流程、定製獎勵機制和反饋驅動合成數據生成方法的有效性。

Conclusion: 提出的框架降低了MLLM在深度偽造檢測中的註釋成本，並探索了強化學習在該領域的應用潛力，為可解釋深度偽造檢測提供了有效解決方案。

Abstract: Most prior deepfake detection methods lack explainable outputs. With the growing interest in multimodal large language models (MLLMs), researchers have started exploring their use in interpretable deepfake detection. However, a major obstacle in applying MLLMs to this task is the scarcity of high-quality datasets with detailed forgery attribution annotations, as textual annotation is both costly and challenging - particularly for high-fidelity forged images or videos. Moreover, multiple studies have shown that reinforcement learning (RL) can substantially enhance performance in visual tasks, especially in improving cross-domain generalization. To facilitate the adoption of mainstream MLLM frameworks in deepfake detection with reduced annotation cost, and to investigate the potential of RL in this context, we propose an automated Chain-of-Thought (CoT) data generation framework based on Self-Blended Images, along with an RL-enhanced deepfake detection framework. Extensive experiments validate the effectiveness of our CoT data construction pipeline, tailored reward mechanism, and feedback-driven synthetic data generation approach. Our method achieves performance competitive with state-of-the-art (SOTA) approaches across multiple cross-dataset benchmarks. Implementation details are available at https://github.com/deon1219/rlsbi.

</details>


### [14] [Evolving Without Ending: Unifying Multimodal Incremental Learning for Continual Panoptic Perception](https://arxiv.org/abs/2601.15643)
*Bo Yuan,Danpei Zhao,Wentao Li,Tian Li,Zhiguo Jiang*

Main category: cs.CV

TL;DR: 该论文提出了一种持续全景感知（CPP）模型，将多模态和多任务持续学习相结合，通过跨模态编码器、知识继承模块和一致性约束来解决多任务持续学习中的语义混淆和灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 现有持续学习研究主要关注单任务场景，限制了在多任务和多模态场景中的应用潜力。多任务持续学习不仅存在灾难性遗忘问题，还会导致跨模态对齐的语义混淆，在增量训练步骤中造成严重的模型退化。

Method: 提出持续全景感知（CPP）模型，包括：1）协作跨模态编码器（CCE）用于多模态嵌入；2）通过对比特征蒸馏和实例蒸馏的可塑知识继承模块；3）跨模态一致性约束（CPP+）；4）非对称伪标签方式，支持无需示例回放的模型演化。

Result: 在多模态数据集和多样化持续学习任务上的大量实验表明，所提模型具有优越性，特别是在细粒度持续学习任务中表现突出。

Conclusion: 该研究将持续学习扩展到持续全景感知，通过整合多模态和多任务持续学习，增强了图像感知能力，有效解决了多任务增量场景下的语义对齐和灾难性遗忘问题。

Abstract: Continual learning (CL) is a great endeavour in developing intelligent perception AI systems. However, the pioneer research has predominantly focus on single-task CL, which restricts the potential in multi-task and multimodal scenarios. Beyond the well-known issue of catastrophic forgetting, the multi-task CL also brings semantic obfuscation across multimodal alignment, leading to severe model degradation during incremental training steps. In this paper, we extend CL to continual panoptic perception (CPP), integrating multimodal and multi-task CL to enhance comprehensive image perception through pixel-level, instance-level, and image-level joint interpretation. We formalize the CL task in multimodal scenarios and propose an end-to-end continual panoptic perception model. Concretely, CPP model features a collaborative cross-modal encoder (CCE) for multimodal embedding. We also propose a malleable knowledge inheritance module via contrastive feature distillation and instance distillation, addressing catastrophic forgetting from task-interactive boosting manner. Furthermore, we propose a cross-modal consistency constraint and develop CPP+, ensuring multimodal semantic alignment for model updating under multi-task incremental scenarios. Additionally, our proposed model incorporates an asymmetric pseudo-labeling manner, enabling model evolving without exemplar replay. Extensive experiments on multimodal datasets and diverse CL tasks demonstrate the superiority of the proposed model, particularly in fine-grained CL tasks.

</details>


### [15] [SuperOcc: Toward Cohesive Temporal Modeling for Superquadric-based Occupancy Prediction](https://arxiv.org/abs/2601.15644)
*Zichen Yu,Quanli Liu,Wei Wang,Liyong Zhang,Xiaoguang Zhao*

Main category: cs.CV

TL;DR: SuperOcc是一个基于超二次曲面的3D占据预测框架，通过时间建模、多超二次曲面解码和高效体素投影，在保持稀疏性的同时提升几何表达能力和计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有3D占据预测方法大多采用密集场景表示，忽略了真实驾驶场景固有的稀疏性。超二次曲面表示虽然具有几何表达力强的优势，但现有方法存在时间建模不足、查询稀疏性与几何表达力之间的权衡困难，以及超二次曲面到体素投影效率低的问题。

Method: SuperOcc包含三个关键设计：1) 结合视角中心和物体中心时间线索的协同时间建模机制；2) 在不牺牲查询稀疏性的前提下增强几何表达力的多超二次曲面解码策略；3) 提高计算效率的高效超二次曲面到体素投影方案。

Result: 在SurroundOcc和Occ3D基准测试上的大量实验表明，SuperOcc实现了最先进的性能，同时保持了优越的效率。

Conclusion: SuperOcc通过创新的时间建模、几何表达增强和高效投影方案，成功解决了超二次曲面框架的现有问题，为自动驾驶环境理解提供了有效的稀疏场景表示方法。

Abstract: 3D occupancy prediction plays a pivotal role in the realm of autonomous driving, as it provides a comprehensive understanding of the driving environment. Most existing methods construct dense scene representations for occupancy prediction, overlooking the inherent sparsity of real-world driving scenes. Recently, 3D superquadric representation has emerged as a promising sparse alternative to dense scene representations due to the strong geometric expressiveness of superquadrics. However, existing superquadric frameworks still suffer from insufficient temporal modeling, a challenging trade-off between query sparsity and geometric expressiveness, and inefficient superquadric-to-voxel splatting. To address these issues, we propose SuperOcc, a novel framework for superquadric-based 3D occupancy prediction. SuperOcc incorporates three key designs: (1) a cohesive temporal modeling mechanism to simultaneously exploit view-centric and object-centric temporal cues; (2) a multi-superquadric decoding strategy to enhance geometric expressiveness without sacrificing query sparsity; and (3) an efficient superquadric-to-voxel splatting scheme to improve computational efficiency. Extensive experiments on the SurroundOcc and Occ3D benchmarks demonstrate that SuperOcc achieves state-of-the-art performance while maintaining superior efficiency. The code is available at https://github.com/Yzichen/SuperOcc.

</details>


### [16] [Event-VStream: Event-Driven Real-Time Understanding for Long Video Streams](https://arxiv.org/abs/2601.15655)
*Zhenghui Guo,Yuanbin Man,Junyuan Sheng,Bowen Lin,Ahmed Ahmed,Bo Jiang,Boyuan Zhang,Miao Yin,Sian Jin,Omprakash Gnawal,Chengming Zhang*

Main category: cs.CV

TL;DR: Event-VStream：基于事件感知的视频流理解框架，通过检测语义连贯的事件边界来减少冗余帧处理，实现长视频实时理解


<details>
  <summary>Details</summary>
Motivation: 现有视频流理解系统存在冗余帧处理和快速遗忘历史上下文的问题，固定间隔解码或缓存剪枝方法要么产生重复输出，要么丢失关键时序信息

Method: 将连续视频表示为离散的语义连贯事件序列，通过整合运动、语义和预测线索检测有意义的状态转换，仅在事件边界触发语言生成，并将事件嵌入整合到持久内存库中

Result: 在OVOBench-Realtime上比VideoLLM-Online-8B基线提升10.4分，使用通用LLaMA-3-8B文本骨干接近Flash-VStream-7B性能，在2小时Ego4D流上保持约70%的GPT-5胜率

Conclusion: Event-VStream通过事件感知框架有效解决了长视频流理解中的冗余处理和遗忘问题，在保持低延迟的同时实现了长时程推理的竞争性性能

Abstract: Real-time understanding of long video streams remains challenging for multimodal large language models (VLMs) due to redundant frame processing and rapid forgetting of past context. Existing streaming systems rely on fixed-interval decoding or cache pruning, which either produce repetitive outputs or discard crucial temporal information. We introduce Event-VStream, an event-aware framework that represents continuous video as a sequence of discrete, semantically coherent events. Our system detects meaningful state transitions by integrating motion, semantic, and predictive cues, and triggers language generation only at those boundaries. Each event embedding is consolidated into a persistent memory bank, enabling long-horizon reasoning while maintaining low latency. Across OVOBench-Realtime, and long-form Ego4D evaluations, Event-VStream achieves competitive performance. It improves over a VideoLLM-Online-8B baseline by +10.4 points on OVOBench-Realtime, achieves performance close to Flash-VStream-7B despite using only a general-purpose LLaMA-3-8B text backbone, and maintains around 70% GPT-5 win rate on 2-hour Ego4D streams.

</details>


### [17] [Skywork UniPic 3.0: Unified Multi-Image Composition via Sequence Modeling](https://arxiv.org/abs/2601.15664)
*Hongyang Wei,Hongbo Liu,Zidong Wang,Yi Peng,Baixin Xu,Size Wu,Xuying Zhang,Xianglong He,Zexiang Liu,Peiyu Wang,Xuchen Song,Yangguang Li,Yang Liu,Yahui Zhou*

Main category: cs.CV

TL;DR: Skywork UniPic 3.0是一个统一的多模态框架，支持单图编辑和多图合成，通过序列建模方法和高效训练策略，在HOI任务上超越现有模型，推理速度提升12.5倍。


<details>
  <summary>Details</summary>
Motivation: 社区对多图合成任务兴趣浓厚，但现有模型未公开高质量融合的具体方法细节。通过统计分析发现人类-物体交互(HOI)是社区最需要的类别，因此需要系统性地解决多图合成中的一致性和质量挑战。

Method: 1) 构建统一多模态框架支持1~6张任意分辨率的输入图像；2) 设计全面的数据收集、过滤和合成流程，仅用70万高质量样本；3) 提出将多图合成为序列建模问题的新训练范式；4) 在训练后阶段集成轨迹映射和分布匹配，实现8步快速推理。

Result: 在单图编辑基准上达到SOTA性能，在多图合成基准上超越Nano-Banana和Seedream 4.0。推理速度比标准合成采样快12.5倍，仅需8步即可生成高保真样本。

Conclusion: Skywork UniPic 3.0通过创新的数据管道和训练范式，有效解决了多图合成的挑战，在HOI任务上表现出色，验证了方法的有效性。代码、模型和数据集已公开。

Abstract: The recent surge in popularity of Nano-Banana and Seedream 4.0 underscores the community's strong interest in multi-image composition tasks. Compared to single-image editing, multi-image composition presents significantly greater challenges in terms of consistency and quality, yet existing models have not disclosed specific methodological details for achieving high-quality fusion. Through statistical analysis, we identify Human-Object Interaction (HOI) as the most sought-after category by the community. We therefore systematically analyze and implement a state-of-the-art solution for multi-image composition with a primary focus on HOI-centric tasks. We present Skywork UniPic 3.0, a unified multimodal framework that integrates single-image editing and multi-image composition. Our model supports an arbitrary (1~6) number and resolution of input images, as well as arbitrary output resolutions (within a total pixel budget of 1024x1024). To address the challenges of multi-image composition, we design a comprehensive data collection, filtering, and synthesis pipeline, achieving strong performance with only 700K high-quality training samples. Furthermore, we introduce a novel training paradigm that formulates multi-image composition as a sequence-modeling problem, transforming conditional generation into unified sequence synthesis. To accelerate inference, we integrate trajectory mapping and distribution matching into the post-training stage, enabling the model to produce high-fidelity samples in just 8 steps and achieve a 12.5x speedup over standard synthesis sampling. Skywork UniPic 3.0 achieves state-of-the-art performance on single-image editing benchmark and surpasses both Nano-Banana and Seedream 4.0 on multi-image composition benchmark, thereby validating the effectiveness of our data pipeline and training paradigm. Code, models and dataset are publicly available.

</details>


### [18] [Consistency-Regularized GAN for Few-Shot SAR Target Recognition](https://arxiv.org/abs/2601.15681)
*Yikui Zhai,Shikuang Liu,Wenlve Zhou,Hongsheng Zhang,Zhiheng Zhou,Xiaolin Tian,C. L. Philip Chen*

Main category: cs.CV

TL;DR: 提出Cr-GAN框架解决SAR图像少样本识别中的数据稀缺问题，通过双分支判别器和一致性正则化，在极少数据下生成高质量样本，显著提升少样本识别性能。


<details>
  <summary>Details</summary>
Motivation: 合成孔径雷达(SAR)图像少样本识别面临数据极度稀缺的挑战。传统方法需要大量数据训练GAN，这与少样本学习的前提相矛盾，因此需要一种能在极少数据下生成高质量样本的新方法。

Method: 提出一致性正则化生成对抗网络(Cr-GAN)：1) 双分支判别器将对抗训练与表示学习解耦；2) 通道级特征插值策略生成新潜在特征；3) 双域循环一致性机制确保语义完整性；4) 框架可适配多种GAN架构。

Result: 在MSTAR和SRSDD数据集上验证，8-shot设置下分别达到71.21%和51.64%的准确率，显著优于现有基线方法，且参数量仅为最先进扩散模型的约5%。

Conclusion: Cr-GAN成功解决了SAR图像少样本识别中的数据稀缺问题，能够在极少数据下生成高质量样本，有效提升自监督学习性能，为实际应用提供了可行解决方案。

Abstract: Few-shot recognition in synthetic aperture radar (SAR) imagery remains a critical bottleneck for real-world applications due to extreme data scarcity. A promising strategy involves synthesizing a large dataset with a generative adversarial network (GAN), pre-training a model via self-supervised learning (SSL), and then fine-tuning on the few labeled samples. However, this approach faces a fundamental paradox: conventional GANs themselves require abundant data for stable training, contradicting the premise of few-shot learning. To resolve this, we propose the consistency-regularized generative adversarial network (Cr-GAN), a novel framework designed to synthesize diverse, high-fidelity samples even when trained under these severe data limitations. Cr-GAN introduces a dual-branch discriminator that decouples adversarial training from representation learning. This architecture enables a channel-wise feature interpolation strategy to create novel latent features, complemented by a dual-domain cycle consistency mechanism that ensures semantic integrity. Our Cr-GAN framework is adaptable to various GAN architectures, and its synthesized data effectively boosts multiple SSL algorithms. Extensive experiments on the MSTAR and SRSDD datasets validate our approach, with Cr-GAN achieving a highly competitive accuracy of 71.21% and 51.64%, respectively, in the 8-shot setting, significantly outperforming leading baselines, while requiring only ~5 of the parameters of state-of-the-art diffusion models. Code is available at: https://github.com/yikuizhai/Cr-GAN.

</details>


### [19] [Performance-guided Reinforced Active Learning for Object Detection](https://arxiv.org/abs/2601.15688)
*Zhixuan Liang,Xingyu Zeng,Rui Zhao,Ping Luo*

Main category: cs.CV

TL;DR: 提出MGRAL方法，通过强化学习代理以mAP改进作为奖励，优化目标检测中的主动学习样本选择，在PASCAL VOC和COCO基准上取得最佳性能。


<details>
  <summary>Details</summary>
Motivation: 当前主动学习方法评估数据信息量主要关注数据分布或内在信息内容，不直接与下游任务性能（如目标检测中的mAP）相关，需要更有效的样本选择策略。

Method: 提出MGRAL方法：1) 使用期望模型输出变化作为信息量度量；2) 采用强化学习采样代理，以mAP改进作为奖励，使用策略梯度优化批量选择；3) 通过无监督方式和快速查找表减少mAP估计计算开销。

Result: 在PASCAL VOC和COCO基准的目标检测任务上，MGRAL展示了最高的主动学习曲线和令人信服的可视化结果，建立了强化学习驱动主动目标检测的新范式。

Conclusion: MGRAL通过将模型性能（mAP）直接作为奖励信号，成功解决了主动学习中样本选择与下游任务性能关联的问题，为强化学习驱动的主动目标检测提供了有效解决方案。

Abstract: Active learning (AL) strategies aim to train high-performance models with minimal labeling efforts, only selecting the most informative instances for annotation. Current approaches to evaluating data informativeness predominantly focus on the data's distribution or intrinsic information content and do not directly correlate with downstream task performance, such as mean average precision (mAP) in object detection. Thus, we propose Performance-guided (i.e. mAP-guided) Reinforced Active Learning for Object Detection (MGRAL), a novel approach that leverages the concept of expected model output changes as informativeness. To address the combinatorial explosion challenge of batch sample selection and the non-differentiable correlation between model performance and selected batches, MGRAL skillfully employs a reinforcement learning-based sampling agent that optimizes selection using policy gradient with mAP improvement as reward. Moreover, to reduce the computational overhead of mAP estimation with unlabeled samples, MGRAL utilizes an unsupervised way with fast look-up tables, ensuring feasible deployment. We evaluate MGRAL's active learning performance on detection tasks over PASCAL VOC and COCO benchmarks. Our approach demonstrates the highest AL curve with convincing visualizations, establishing a new paradigm in reinforcement learning-driven active object detection.

</details>


### [20] [Beyond Visual Safety: Jailbreaking Multimodal Large Language Models for Harmful Image Generation via Semantic-Agnostic Inputs](https://arxiv.org/abs/2601.15698)
*Mingyu Yu,Lana Liu,Zhehao Zhao,Wei Wang,Sujuan Qin*

Main category: cs.CV

TL;DR: BVS是一个新颖的图像-文本对越狱框架，专门用于探测多模态大语言模型的视觉安全边界，通过重构-生成策略实现高达98.21%的越狱成功率。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型的快速发展带来了复杂的安全挑战，特别是在文本和视觉安全的交叉领域。现有方案虽然探索了MLLMs的安全漏洞，但对视觉安全边界的研究仍然不足。

Method: BVS采用"重构-生成"策略，利用中性化视觉拼接和归纳重组技术，将恶意意图从原始输入中解耦，从而诱导MLLMs生成有害图像。

Result: 实验结果显示，BVS对GPT-5（2026年1月12日发布）实现了98.21%的显著越狱成功率。

Conclusion: 研究发现揭示了当前MLLMs在视觉安全对齐方面存在关键漏洞，需要加强视觉安全边界的防护措施。

Abstract: The rapid advancement of Multimodal Large Language Models (MLLMs) has introduced complex security challenges, particularly at the intersection of textual and visual safety. While existing schemes have explored the security vulnerabilities of MLLMs, the investigation into their visual safety boundaries remains insufficient. In this paper, we propose Beyond Visual Safety (BVS), a novel image-text pair jailbreaking framework specifically designed to probe the visual safety boundaries of MLLMs. BVS employs a "reconstruction-then-generation" strategy, leveraging neutralized visual splicing and inductive recomposition to decouple malicious intent from raw inputs, thereby leading MLLMs to be induced into generating harmful images. Experimental results demonstrate that BVS achieves a remarkable jailbreak success rate of 98.21\% against GPT-5 (12 January 2026 release). Our findings expose critical vulnerabilities in the visual safety alignment of current MLLMs.

</details>


### [21] [Enhanced LULC Segmentation via Lightweight Model Refinements on ALOS-2 SAR Data](https://arxiv.org/abs/2601.15705)
*Ali Caglayan,Nevrez Imamoglu,Toru Kouyama*

Main category: cs.CV

TL;DR: 本文提出三种轻量级改进方法，用于提升日本全国尺度ALOS-2单极化SAR数据的土地利用/土地覆盖语义分割性能，特别针对边界过平滑、细长结构漏检和长尾分布下稀有类别性能退化等问题。


<details>
  <summary>Details</summary>
Motivation: 解决SAR密集预测中的常见失败模式：边界过平滑、细长结构漏检、以及长尾标签分布下稀有类别性能退化问题，同时不增加管道复杂度。

Method: 基于SAR-W-MixMAE自监督预训练，引入三种轻量级改进：1）将高分辨率特征注入多尺度解码；2）渐进式细化上采样头，交替进行卷积细化和逐步上采样；3）α尺度因子调节焦点损失和Dice损失中的类别重新加权。

Result: 在日本全国范围的ALOS-2 LULC基准测试中取得一致改进，特别是对于代表性不足的类别，同时在水体检测任务上提升了各项标准评估指标。

Conclusion: 通过三种轻量级改进有效解决了SAR语义分割中的常见问题，显著提升了土地利用/土地覆盖分类性能，特别是对稀有类别和细长结构的识别能力。

Abstract: This work focuses on national-scale land-use/land-cover (LULC) semantic segmentation using ALOS-2 single-polarization (HH) SAR data over Japan, together with a companion binary water detection task. Building on SAR-W-MixMAE self-supervised pretraining [1], we address common SAR dense-prediction failure modes, boundary over-smoothing, missed thin/slender structures, and rare-class degradation under long-tailed labels, without increasing pipeline complexity. We introduce three lightweight refinements: (i) injecting high-resolution features into multi-scale decoding, (ii) a progressive refine-up head that alternates convolutional refinement and stepwise upsampling, and (iii) an $α$-scale factor that tempers class reweighting within a focal+dice objective. The resulting model yields consistent improvements on the Japan-wide ALOS-2 LULC benchmark, particularly for under-represented classes, and improves water detection across standard evaluation metrics.

</details>


### [22] [Zero-Shot Product Attribute Labeling with Vision-Language Models: A Three-Tier Evaluation Framework](https://arxiv.org/abs/2601.15711)
*Shubham Shukla,Kunal Sonalkar*

Main category: cs.CV

TL;DR: 本文提出一个三层评估框架，系统评估视觉语言模型在细粒度时尚属性预测任务上的表现，发现VLM在细粒度分类上表现优秀，但在属性适用性检测上存在瓶颈。


<details>
  <summary>Details</summary>
Motivation: 时尚零售应用需要细粒度属性预测，但现有视觉语言模型在时尚多属性任务上的系统评估不足。关键挑战是时尚属性通常是条件性的，需要先检测属性适用性再进行分类。

Method: 提出三层评估框架：1) 包含NA类的整体任务性能；2) 属性适用性检测；3) 属性可确定时的细粒度分类。使用DeepFashion-MultiModal数据集，在5,000张图像上评估9个VLM模型，并与基于Fashion-CLIP嵌入的分类器对比。

Result: 1) 零样本VLM达到64.0%宏F1，比基于Fashion-CLIP嵌入的逻辑回归提升三倍；2) VLM在细粒度分类上表现优秀（70.8% F1），但在适用性检测上表现较差（34.1% NA-F1）；3) 高效模型能达到旗舰模型90%以上性能，成本更低。

Conclusion: 该诊断框架能帮助从业者识别错误来源（可见性检测或分类），指导生产系统的针对性改进。高效模型提供了实用的部署路径，但属性适用性检测仍是关键瓶颈。

Abstract: Fine-grained attribute prediction is essential for fashion retail applications including catalog enrichment, visual search, and recommendation systems. Vision-Language Models (VLMs) offer zero-shot prediction without task-specific training, yet their systematic evaluation on multi-attribute fashion tasks remains underexplored. A key challenge is that fashion attributes are often conditional. For example, "outer fabric" is undefined when no outer garment is visible. This requires models to detect attribute applicability before attempting classification. We introduce a three-tier evaluation framework that decomposes this challenge: (1) overall task performance across all classes (including NA class: suggesting attribute is not applicable) for all attributes, (2) attribute applicability detection, and (3) fine-grained classification when attributes are determinable. Using DeepFashion-MultiModal, which explicitly defines NA (meaning attribute doesn't exist or is not visible) within attribute label spaces, we benchmark nine VLMs spanning flagship (GPT-5, Gemini 2.5 Pro), efficient (GPT-5 Mini, Gemini 2.5 Flash), and ultra-efficient tiers (GPT-5 Nano, Gemini 2.5 Flash-Lite) against classifiers trained on pretrained Fashion-CLIP embeddings on 5,000 images across 18 attributes. Our findings reveal that: (1) zero-shot VLMs achieve 64.0% macro-F1, a threefold improvement over logistic regression on pretrained Fashion-CLIP embeddings; (2) VLMs excel at fine-grained classification (Tier 3: 70.8% F1) but struggle with applicability detection (Tier 2: 34.1% NA-F1), identifying a key bottleneck; (3) efficient models achieve over 90% of flagship performance at lower cost, offering practical deployment paths. This diagnostic framework enables practitioners to pinpoint whether errors stem from visibility detection or classification, guiding targeted improvements for production systems.

</details>


### [23] [VideoThinker: Building Agentic VideoLLMs with LLM-Guided Tool Reasoning](https://arxiv.org/abs/2601.15724)
*Chenglin Li,Qianglong Chen,Feng Han,Yikun Wang,Xingxi Yin,Yan Gong,Ruilin Li,Yin Zhang,Jiaqi Wang*

Main category: cs.CV

TL;DR: VideoThinker：通过合成工具交互轨迹训练的智能视频大语言模型，解决长视频理解中信息丢失问题，通过自适应检索和缩放推理显著提升性能


<details>
  <summary>Details</summary>
Motivation: 现有视频大语言模型主要依赖均匀采样帧的静态推理，导致长视频中时间定位能力弱和信息大量丢失。智能工具（如时间检索、空间缩放、时间缩放）能自适应探索关键时刻，但构建智能视频理解数据需要模型本身具备强大的长视频理解能力，形成循环依赖问题。

Method: 1. 将视频转换为丰富的文本描述；2. 使用强大的智能语言模型在文本空间生成多步工具使用序列；3. 将这些轨迹通过替换对应帧的方式回接到视频，创建大规模的交错视频和工具推理数据集；4. 在此合成智能数据集上训练VideoThinker模型

Result: VideoThinker在长视频基准测试中显著优于仅使用文本描述的语言模型智能体和强大的视频模型基线，证明了工具增强的合成数据以及自适应检索和缩放推理对长视频理解的有效性

Conclusion: 通过合成工具交互轨迹训练视频大语言模型是解决长视频理解挑战的有效方法，VideoThinker展示了动态推理能力、自适应时间探索和多步工具使用的优势，为长视频理解提供了新范式

Abstract: Long-form video understanding remains a fundamental challenge for current Video Large Language Models. Most existing models rely on static reasoning over uniformly sampled frames, which weakens temporal localization and leads to substantial information loss in long videos. Agentic tools such as temporal retrieval, spatial zoom, and temporal zoom offer a natural way to overcome these limitations by enabling adaptive exploration of key moments. However, constructing agentic video understanding data requires models that already possess strong long-form video comprehension, creating a circular dependency. We address this challenge with VideoThinker, an agentic Video Large Language Model trained entirely on synthetic tool interaction trajectories. Our key idea is to convert videos into rich captions and employ a powerful agentic language model to generate multi-step tool use sequences in caption space. These trajectories are subsequently grounded back to video by replacing captions with the corresponding frames, yielding a large-scale interleaved video and tool reasoning dataset without requiring any long-form understanding from the underlying model. Training on this synthetic agentic dataset equips VideoThinker with dynamic reasoning capabilities, adaptive temporal exploration, and multi-step tool use. Remarkably, VideoThinker significantly outperforms both caption-only language model agents and strong video model baselines across long-video benchmarks, demonstrating the effectiveness of tool augmented synthetic data and adaptive retrieval and zoom reasoning for long-form video understanding.

</details>


### [24] [FAIR-ESI: Feature Adaptive Importance Refinement for Electrophysiological Source Imaging](https://arxiv.org/abs/2601.15731)
*Linyong Zou,Liang Zhang,Xiongfei Wang,Jia-Hong Gao,Yi Sun,Shurong Sheng,Kuntao Xiao,Wanli Yang,Pengfei Teng,Guoming Luan,Zhao Lv,Zikang Xu*

Main category: cs.CV

TL;DR: FAIR-ESI是一个用于脑电信号源成像的新框架，通过多视图自适应特征重要性精炼来提升脑部疾病诊断的准确性。


<details>
  <summary>Details</summary>
Motivation: 脑电信号源成像（ESI）是诊断脑部疾病的重要技术，但现有方法（基于模型的优化和深度学习方法）在特征选择和精炼方面仍面临挑战，影响ESI的精确性。

Method: 提出FAIR-ESI框架，通过多视图自适应特征重要性精炼：1）基于FFT的频谱特征精炼；2）加权时域特征精炼；3）基于自注意力的分块特征精炼。

Result: 在两个具有不同配置的模拟数据集和两个真实世界临床数据集上的广泛实验验证了该框架的有效性。

Conclusion: FAIR-ESI有潜力推进脑部疾病诊断，并为脑功能研究提供新见解。

Abstract: An essential technique for diagnosing brain disorders is electrophysiological source imaging (ESI). While model-based optimization and deep learning methods have achieved promising results in this field, the accurate selection and refinement of features remains a central challenge for precise ESI. This paper proposes FAIR-ESI, a novel framework that adaptively refines feature importance across different views, including FFT-based spectral feature refinement, weighted temporal feature refinement, and self-attention-based patch-wise feature refinement. Extensive experiments on two simulation datasets with diverse configurations and two real-world clinical datasets validate our framework's efficacy, highlighting its potential to advance brain disorder diagnosis and offer new insights into brain function.

</details>


### [25] [Sub-Region-Aware Modality Fusion and Adaptive Prompting for Multi-Modal Brain Tumor Segmentation](https://arxiv.org/abs/2601.15734)
*Shadi Alijani,Fereshteh Aghaee Meibodi,Homayoun Najjaran*

Main category: cs.CV

TL;DR: 提出一种用于多模态医学影像的基础模型适配框架，通过子区域感知模态注意力和自适应提示工程，在脑肿瘤分割任务上显著超越基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有基础模型在多模态医学影像应用中面临信息融合困难和病理组织异质性适应问题，需要更有效的多模态融合和适配方法。

Method: 提出包含两个关键技术创新的框架：1) 子区域感知模态注意力机制，学习每个肿瘤子区域的最优模态组合；2) 自适应提示工程策略，利用基础模型固有能力提升分割精度。

Result: 在BraTS 2020脑肿瘤分割数据集上验证，该方法显著优于基线方法，特别是在具有挑战性的坏死核心子区域表现突出。

Conclusion: 为多模态融合和提示提供了一种原则性有效方法，为医学影像中更准确、鲁棒的基础模型解决方案铺平了道路。

Abstract: The successful adaptation of foundation models to multi-modal medical imaging is a critical yet unresolved challenge. Existing models often struggle to effectively fuse information from multiple sources and adapt to the heterogeneous nature of pathological tissues. To address this, we introduce a novel framework for adapting foundation models to multi-modal medical imaging, featuring two key technical innovations: sub-region-aware modality attention and adaptive prompt engineering. The attention mechanism enables the model to learn the optimal combination of modalities for each tumor sub-region, while the adaptive prompting strategy leverages the inherent capabilities of foundation models to refine segmentation accuracy. We validate our framework on the BraTS 2020 brain tumor segmentation dataset, demonstrating that our approach significantly outperforms baseline methods, particularly in the challenging necrotic core sub-region. Our work provides a principled and effective approach to multi-modal fusion and prompting, paving the way for more accurate and robust foundation model-based solutions in medical imaging.

</details>


### [26] [Breaking the Resolution Barrier: Arbitrary-resolution Deep Image Steganography Framework](https://arxiv.org/abs/2601.15739)
*Xinjue Hu,Chi Wang,Boyu Wang,Xiang Zhang,Zhenshan Tan,Zhangjie Fu*

Main category: cs.CV

TL;DR: ARDIS：首个任意分辨率深度图像隐写框架，通过频率解耦架构和隐式重建器，实现跨分辨率秘密图像的隐藏与恢复，无需预先重采样。


<details>
  <summary>Details</summary>
Motivation: 当前深度图像隐写方法要求秘密图像与载体图像分辨率相同，这导致两个问题：1）分辨率不一致时需要重采样，造成细节损失；2）当分辨率值未知时无法恢复原始分辨率。需要突破固定分辨率的限制。

Method: 提出ARDIS框架：1）隐藏阶段采用频率解耦架构，将秘密图像解耦为分辨率对齐的全局基和分辨率无关的高频潜在编码；2）恢复阶段使用潜在引导的隐式重建器，通过连续隐函数查询和渲染高频残差；3）引入隐式分辨率编码策略，将离散分辨率值编码为密集特征图，实现盲恢复。

Result: 实验结果表明，ARDIS在不可见性和跨分辨率恢复保真度方面显著优于现有最先进方法，能够准确恢复原始分辨率的秘密图像细节。

Conclusion: ARDIS首次实现了任意分辨率的深度图像隐写，通过从离散映射到参考引导的连续信号重建的范式转变，解决了跨分辨率隐写的关键挑战，为实际应用提供了更灵活的解决方案。

Abstract: Deep image steganography (DIS) has achieved significant results in capacity and invisibility. However, current paradigms enforce the secret image to maintain the same resolution as the cover image during hiding and revealing. This leads to two challenges: secret images with inconsistent resolutions must undergo resampling beforehand which results in detail loss during recovery, and the secret image cannot be recovered to its original resolution when the resolution value is unknown. To address these, we propose ARDIS, the first Arbitrary Resolution DIS framework, which shifts the paradigm from discrete mapping to reference-guided continuous signal reconstruction. Specifically, to minimize the detail loss caused by resolution mismatch, we first design a Frequency Decoupling Architecture in hiding stage. It disentangles the secret into a resolution-aligned global basis and a resolution-agnostic high-frequency latent to hide in a fixed-resolution cover. Second, for recovery, we propose a Latent-Guided Implicit Reconstructor to perform deterministic restoration. The recovered detail latent code modulates a continuous implicit function to accurately query and render high-frequency residuals onto the recovered global basis, ensuring faithful restoration of original details. Furthermore, to achieve blind recovery, we introduce an Implicit Resolution Coding strategy. By transforming discrete resolution values into dense feature maps and hiding them in the redundant space of the feature domain, the reconstructor can correctly decode the secret's resolution directly from the steganographic representation. Experimental results demonstrate that ARDIS significantly outperforms state-of-the-art methods in both invisibility and cross-resolution recovery fidelity.

</details>


### [27] [White-Box mHC: Electromagnetic Spectrum-Aware and Interpretable Stream Interactions for Hyperspectral Image Classification](https://arxiv.org/abs/2601.15757)
*Yimin Zhu,Lincoln Linlin Xu,Zhengsen Xu,Zack Dewis,Mabel Heffring,Saeid Taleghanidoozdoozan,Motasem Alkayid,Quinn Ledingham,Megan Greenwood*

Main category: cs.CV

TL;DR: ES-mHC是一个用于高光谱图像分类的物理光谱感知白盒模型，通过结构化超连接矩阵显式建模不同电磁光谱分组之间的相互作用，提高模型可解释性。


<details>
  <summary>Details</summary>
Motivation: 当前高光谱图像分类中的深度学习模型通常依赖不透明的光谱-空间特征混合，限制了模型的可解释性，阻碍了对内部决策机制的理解。

Method: 提出ES-mHC超连接框架，使用结构化、方向性矩阵显式建模不同电磁光谱分组（mHC中的残差流）之间的相互作用，将特征表示与交互结构分离。

Result: 学习到的超连接矩阵展现出连贯的空间模式和非对称交互行为，为模型内部动态提供了机制性洞察；增加扩展率可加速结构化交互模式的出现。

Conclusion: ES-mHC将高光谱图像分类从纯粹的黑盒预测任务转变为结构透明、部分白盒的学习过程，提高了模型的可解释性和内部信息流的可视化分析能力。

Abstract: In hyperspectral image classification (HSIC), most deep learning models rely on opaque spectral-spatial feature mixing, limiting their interpretability and hindering understanding of internal decision mechanisms. We present physical spectrum-aware white-box mHC, named ES-mHC, a hyper-connection framework that explicitly models interactions among different electromagnetic spectrum groupings (residual stream in mHC) interactions using structured, directional matrices. By separating feature representation from interaction structure, ES-mHC promotes electromagnetic spectrum grouping specialization, reduces redundancy, and exposes internal information flow that can be directly visualized and spatially analyzed. Using hyperspectral image classification as a representative testbed, we demonstrate that the learned hyper-connection matrices exhibit coherent spatial patterns and asymmetric interaction behaviors, providing mechanistic insight into the model internal dynamics. Furthermore, we find that increasing the expansion rate accelerates the emergence of structured interaction patterns. These results suggest that ES-mHC transforms HSIC from a purely black-box prediction task into a structurally transparent, partially white-box learning process.

</details>


### [28] [Atlas-Assisted Segment Anything Model for Fetal Brain MRI (FeTal-SAM)](https://arxiv.org/abs/2601.15759)
*Qi Zeng,Weide Liu,Bo Li,Ryne Didier,P. Ellen Grant,Davood Karimi*

Main category: cs.CV

TL;DR: FeTal-SAM：基于SAM的胎儿脑MRI分割模型，通过整合图谱提示实现无需重新训练即可适应不同标签定义的灵活分割


<details>
  <summary>Details</summary>
Motivation: 传统深度学习方法需要大量标注数据且针对固定标签集，当临床或研究需求变化时缺乏灵活性；同时难以判断分割结果是由真实图像对比度驱动还是学习到的空间先验驱动

Method: 整合基于图谱的提示和基础模型原理，利用多图谱配准生成空间对齐的标签模板作为密集提示，结合边界框提示，通过SAM的解码器进行逐结构二值分割，最后融合重建完整3D分割体积

Result: 在两个数据集（dHCP和内部数据集）上评估，对于对比度良好的结构（如皮质板、小脑）获得与最先进基线相当的Dice分数，同时保持分割任意用户指定解剖结构的灵活性；对于低对比度细微结构（如海马、杏仁核）精度稍低

Conclusion: FeTal-SAM展示了作为通用分割模型的潜力，无需大量重新训练即可适应不同需求，是迈向临床适应性胎儿脑MRI分析工具的有希望的一步

Abstract: This paper presents FeTal-SAM, a novel adaptation of the Segment Anything Model (SAM) tailored for fetal brain MRI segmentation. Traditional deep learning methods often require large annotated datasets for a fixed set of labels, making them inflexible when clinical or research needs change. By integrating atlas-based prompts and foundation-model principles, FeTal-SAM addresses two key limitations in fetal brain MRI segmentation: (1) the need to retrain models for varying label definitions, and (2) the lack of insight into whether segmentations are driven by genuine image contrast or by learned spatial priors. We leverage multi-atlas registration to generate spatially aligned label templates that serve as dense prompts, alongside a bounding-box prompt, for SAM's segmentation decoder. This strategy enables binary segmentation on a per-structure basis, which is subsequently fused to reconstruct the full 3D segmentation volumes. Evaluations on two datasets, the dHCP dataset and an in-house dataset demonstrate FeTal-SAM's robust performance across gestational ages. Notably, it achieves Dice scores comparable to state-of-the-art baselines which were trained for each dataset and label definition for well-contrasted structures like cortical plate and cerebellum, while maintaining the flexibility to segment any user-specified anatomy. Although slightly lower accuracy is observed for subtle, low-contrast structures (e.g., hippocampus, amygdala), our results highlight FeTal-SAM's potential to serve as a general-purpose segmentation model without exhaustive retraining. This method thus constitutes a promising step toward clinically adaptable fetal brain MRI analysis tools.

</details>


### [29] [LL-GaussianMap: Zero-shot Low-Light Image Enhancement via 2D Gaussian Splatting Guided Gain Maps](https://arxiv.org/abs/2601.15766)
*Yuhan Chen,Ying Fang,Guofa Li,Wenxuan Yu,Yicui Shi,Jingrui Zhang,Kefei Qian,Wenbo Chu,Keqiang Li*

Main category: cs.CV

TL;DR: LL-GaussianMap：首个将2D高斯泼溅（2DGS）引入低光照图像增强的无监督框架，通过高斯基元引导的增益图生成实现高效增强


<details>
  <summary>Details</summary>
Motivation: 现有低光照增强方法主要在像素域或依赖隐式特征表示，忽略了图像的几何结构先验。2DGS具有出色的结构拟合能力和高效渲染特性，但在低层视觉任务中尚未被探索

Method: 提出两阶段框架：1）使用2DGS进行高保真结构重建；2）通过创新的统一增强模块，利用高斯泼溅的光栅化机制渲染数据驱动的增强字典系数，生成增益图

Result: LL-GaussianMap在保持极低存储开销的同时实现了优越的增强性能，证明了显式高斯表示在图像增强中的有效性

Conclusion: 该研究首次将2DGS应用于低光照图像增强，通过显式高斯表示有效整合结构感知能力，在无监督学习下实现了边缘保持和伪影抑制的优质增强效果

Abstract: Significant progress has been made in low-light image enhancement with respect to visual quality. However, most existing methods primarily operate in the pixel domain or rely on implicit feature representations. As a result, the intrinsic geometric structural priors of images are often neglected. 2D Gaussian Splatting (2DGS) has emerged as a prominent explicit scene representation technique characterized by superior structural fitting capabilities and high rendering efficiency. Despite these advantages, the utilization of 2DGS in low-level vision tasks remains unexplored. To bridge this gap, LL-GaussianMap is proposed as the first unsupervised framework incorporating 2DGS into low-light image enhancement. Distinct from conventional methodologies, the enhancement task is formulated as a gain map generation process guided by 2DGS primitives. The proposed method comprises two primary stages. First, high-fidelity structural reconstruction is executed utilizing 2DGS. Then, data-driven enhancement dictionary coefficients are rendered via the rasterization mechanism of Gaussian splatting through an innovative unified enhancement module. This design effectively incorporates the structural perception capabilities of 2DGS into gain map generation, thereby preserving edges and suppressing artifacts during enhancement. Additionally, the reliance on paired data is circumvented through unsupervised learning. Experimental results demonstrate that LL-GaussianMap achieves superior enhancement performance with an extremely low storage footprint, highlighting the effectiveness of explicit Gaussian representations for image enhancement.

</details>


### [30] [LL-GaussianImage: Efficient Image Representation for Zero-shot Low-Light Enhancement with 2D Gaussian Splatting](https://arxiv.org/abs/2601.15772)
*Yuhan Chen,Wenxuan Yu,Guofa Li,Yijun Xu,Ying Fang,Yicui Shi,Long Cao,Wenbo Chu,Keqiang Li*

Main category: cs.CV

TL;DR: 提出首个在2DGS压缩表示域内进行低光增强的零样本无监督框架LL-GaussianImage，避免了解压缩-增强-再压缩的繁琐流程，实现了压缩即增强。


<details>
  <summary>Details</summary>
Motivation: 现有低光增强算法主要在像素域操作，处理2DGS压缩图像需要解压缩-增强-再压缩的繁琐流程，效率低下且引入二次退化。需要直接在压缩表示域进行处理的方法。

Method: 1. 语义引导的专家混合增强框架，使用渲染图像指导对2DGS稀疏属性空间进行动态自适应变换；2. 多目标协同损失函数系统约束平滑度和保真度；3. 两阶段优化过程：单尺度重建确保基础表示准确性，增强网络鲁棒性。

Result: 实现了低光图像的高质量增强，同时保持高压缩比。实验验证了在压缩表示域直接处理范式的可行性和优越性。

Conclusion: LL-GaussianImage是首个在2DGS压缩表示域进行低光增强的框架，避免了传统流程的效率损失和质量退化，为压缩域图像处理提供了新范式。

Abstract: 2D Gaussian Splatting (2DGS) is an emerging explicit scene representation method with significant potential for image compression due to high fidelity and high compression ratios. However, existing low-light enhancement algorithms operate predominantly within the pixel domain. Processing 2DGS-compressed images necessitates a cumbersome decompression-enhancement-recompression pipeline, which compromises efficiency and introduces secondary degradation. To address these limitations, we propose LL-GaussianImage, the first zero-shot unsupervised framework designed for low-light enhancement directly within the 2DGS compressed representation domain. Three primary advantages are offered by this framework. First, a semantic-guided Mixture-of-Experts enhancement framework is designed. Dynamic adaptive transformations are applied to the sparse attribute space of 2DGS using rendered images as guidance to enable compression-as-enhancement without full decompression to a pixel grid. Second, a multi-objective collaborative loss function system is established to strictly constrain smoothness and fidelity during enhancement, suppressing artifacts while improving visual quality. Third, a two-stage optimization process is utilized to achieve reconstruction-as-enhancement. The accuracy of the base representation is ensured through single-scale reconstruction and network robustness is enhanced. High-quality enhancement of low-light images is achieved while high compression ratios are maintained. The feasibility and superiority of the paradigm for direct processing within the compressed representation domain are validated through experimental results.

</details>


### [31] [Diffusion Model-Based Data Augmentation for Enhanced Neuron Segmentation](https://arxiv.org/abs/2601.15779)
*Liuyun Jiang,Yanchao Zhang,Jinyue Guo,Yizhuo Lu,Ruining Zhou,Hua Han*

Main category: cs.CV

TL;DR: 提出基于扩散模型的数据增强框架，用于神经元分割任务，通过生成多样化的图像-标签对来缓解标注数据不足的问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于深度学习的神经元分割方法严重依赖大规模标注数据，而传统数据增强方法生成的样本与原始图像高度相关，缺乏结构多样性。

Method: 提出扩散基数据增强框架：1) 分辨率感知的条件扩散模型，利用多尺度条件和EM分辨率先验从3D掩码合成体素级图像；2) 生物学引导的掩码重塑模块，生成结构更真实的增强掩码。

Result: 在AC3和AC4数据集上，在低标注情况下，结合两种后处理方法分别将ARAND指标提升了32.1%和30.7%。

Conclusion: 该扩散基数据增强框架能有效丰富训练集，提高神经元分割性能，特别是在标注数据有限的情况下。

Abstract: Neuron segmentation in electron microscopy (EM) aims to reconstruct the complete neuronal connectome; however, current deep learning-based methods are limited by their reliance on large-scale training data and extensive, time-consuming manual annotations. Traditional methods augment the training set through geometric and photometric transformations; however, the generated samples remain highly correlated with the original images and lack structural diversity. To address this limitation, we propose a diffusion-based data augmentation framework capable of generating diverse and structurally plausible image-label pairs for neuron segmentation. Specifically, the framework employs a resolution-aware conditional diffusion model with multi-scale conditioning and EM resolution priors to enable voxel-level image synthesis from 3D masks. It further incorporates a biology-guided mask remodeling module that produces augmented masks with enhanced structural realism. Together, these components effectively enrich the training set and improve segmentation performance. On the AC3 and AC4 datasets under low-annotation regimes, our method improves the ARAND metric by 32.1% and 30.7%, respectively, when combined with two different post-processing methods. Our code is available at https://github.com/HeadLiuYun/NeuroDiff.

</details>


### [32] [Assessing Situational and Spatial Awareness of VLMs with Synthetically Generated Video](https://arxiv.org/abs/2601.15780)
*Pascal Benschop,Justin Dauwels,Jan van Gemert*

Main category: cs.CV

TL;DR: 该论文提出了一个合成基准测试，用于评估视觉语言模型在情境感知和空间感知方面的能力，发现现有模型在区分暴力与良性活动、跨视角绑定攻击者角色、判断轨迹对齐等任务上表现仅略高于随机水平。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在涉及细微时空或几何线索的语义理解方面仍然脆弱，需要系统评估其在情境感知（识别互动是否有害）和空间感知（追踪谁对谁做了什么，以及推理相对位置和运动）方面的能力。

Method: 引入合成基准测试，通过最小化视频对来测试三个挑战：1）区分暴力与良性活动；2）跨视角绑定攻击者角色；3）判断细粒度轨迹对齐。在免训练设置下评估最近的视觉语言模型。

Result: 结果显示模型在所有任务上的表现仅略高于随机水平。简单的辅助手段（稳定颜色线索）部分减少了攻击者角色混淆，但未能解决根本的弱点。

Conclusion: 通过发布数据和代码，旨在提供可复现的诊断工具，并启发探索轻量级空间先验来补充大规模预训练，以增强视觉语言模型的空间推理能力。

Abstract: Spatial reasoning in vision language models (VLMs) remains fragile when semantics hinge on subtle temporal or geometric cues. We introduce a synthetic benchmark that probes two complementary skills: situational awareness (recognizing whether an interaction is harmful or benign) and spatial awareness (tracking who does what to whom, and reasoning about relative positions and motion). Through minimal video pairs, we test three challenges: distinguishing violence from benign activity, binding assailant roles across viewpoints, and judging fine-grained trajectory alignment. While we evaluate recent VLMs in a training-free setting, the benchmark is applicable to any video classification model. Results show performance only slightly above chance across tasks. A simple aid, stable color cues, partly reduces assailant role confusions but does not resolve the underlying weakness. By releasing data and code, we aim to provide reproducible diagnostics and seed exploration of lightweight spatial priors to complement large-scale pretraining.

</details>


### [33] [A Mobile Application for Flower Recognition System Based on Convolutional Neural Networks](https://arxiv.org/abs/2601.15810)
*Mustafa Yurdakul,Enes Ayan,Fahrettin Horasan,Sakir Tasdemir*

Main category: cs.CV

TL;DR: 开发基于CNN的移动应用用于花卉识别，比较三种CNN模型和七种优化算法，DenseNet-121+SGD组合获得最佳性能（95.84%准确率）。


<details>
  <summary>Details</summary>
Motivation: 花卉在日常生活中用途广泛，但识别花卉类型需要专业知识，而专家并非随时可得。为解决这一问题，需要开发一个能让非专业人士快速便捷识别花卉类型的移动应用。

Method: 开发基于卷积神经网络的移动应用，比较MobileNet、DenseNet121和Xception三种CNN模型，使用七种不同的优化算法进行训练和评估。

Result: DenseNet-121架构配合随机梯度下降优化算法表现最佳，达到95.84%准确率，96.00%的精确率、召回率和F1分数。

Conclusion: 卷积神经网络可用于移动应用中的花卉分类，DenseNet-121+SGD组合为移动花卉识别应用提供了有效的解决方案。

Abstract: A convolutional neural network (CNN) is a deep learning algorithm that has been specifically designed for computer vision applications. The CNNs proved successful in handling the increasing amount of data in many computer vision problems, where classical machine learning algorithms were insufficient. Flowers have many uses in our daily lives, from decorating to making medicines to detoxifying the environment. Identifying flower types requires expert knowledge. However, accessing experts at any time and in any location may not always be feasible. In this study a mobile application based on CNNs was developed to recognize different types of flowers to provide non-specialists with quick and easy access to information about flower types. The study employed three distinct CNN models, namely MobileNet, DenseNet121, and Xception, to determine the most suitable model for the mobile application. The classification performances of the models were evaluated by training them with seven different optimization algorithms. The DenseNet-121 architecture, which uses the stochastic gradient descent (SGD) optimization algorithm, was the most successful, achieving 95.84 % accuracy, 96.00% precision, recall, and F1-score. This result shows that CNNs can be used for flower classification in mobile applications.

</details>


### [34] [Beyond Off-the-Shelf Models: A Lightweight and Accessible Machine Learning Pipeline for Ecologists Working with Image Data](https://arxiv.org/abs/2601.15813)
*Clare Chemery,Hendrik Edelhoff,Ludwig Bothmann*

Main category: cs.CV

TL;DR: 开发轻量级机器学习实验流水线，降低生态学家应用图像分类的门槛，使非专家能针对本地数据集和特定任务定制模型，并在鹿类年龄性别分类任务上取得90%+准确率。


<details>
  <summary>Details</summary>
Motivation: 生态研究中机器学习应用门槛较高，现有现成模型难以适应本地数据集和特定分类任务。需要降低生态学家独立实验ML模型的门槛，使其能针对具体研究问题定制解决方案。

Method: 开发结合命令行界面（预处理、训练、评估）和图形界面（标注、错误分析、模型比较）的轻量级实验流水线。使用德国Veldenstein森林收集的3392张相机陷阱图像，专家标注4352张裁剪后的鹿个体图像，训练评估多种骨干架构、参数和数据增强策略。

Result: 在红鹿年龄性别分类任务上，最佳模型达到90.77%年龄分类准确率和96.15%性别分类准确率，证明即使数据有限也能实现可靠的种群统计分类。

Conclusion: 该框架为生态学家提供了针对特定研究问题开发ML模型的可访问工具，证明了即使在有限数据下也能解决明确定义的生态问题，为野生动物监测和种群分析中更广泛采用ML铺平道路。

Abstract: We introduce a lightweight experimentation pipeline designed to lower the barrier for applying machine learning (ML) methods for classifying images in ecological research. We enable ecologists to experiment with ML models independently, thus they can move beyond off-the-shelf models and generate insights tailored to local datasets and specific classification tasks and target variables. Our tool combines a simple command-line interface for preprocessing, training, and evaluation with a graphical interface for annotation, error analysis, and model comparison. This design enables ecologists to build and iterate on compact, task-specific classifiers without requiring advanced ML expertise. As a proof of concept, we apply the pipeline to classify red deer (Cervus elaphus) by age and sex from 3392 camera trap images collected in the Veldenstein Forest, Germany. Using 4352 cropped images containing individual deer labeled by experts, we trained and evaluated multiple backbone architectures with a wide variety of parameters and data augmentation strategies. Our best-performing models achieved 90.77% accuracy for age classification and 96.15% for sex classification. These results demonstrate that reliable demographic classification is feasible even with limited data to answer narrow, well-defined ecological problems. More broadly, the framework provides ecologists with an accessible tool for developing ML models tailored to specific research questions, paving the way for broader adoption of ML in wildlife monitoring and demographic analysis.

</details>


### [35] [Towards Realistic Remote Sensing Dataset Distillation with Discriminative Prototype-guided Diffusion](https://arxiv.org/abs/2601.15829)
*Yonghao Xu,Pedram Ghamisi,Qihao Weng*

Main category: cs.CV

TL;DR: 首次将数据集蒸馏引入遥感图像解释领域，使用文本到图像扩散模型将大规模遥感数据集压缩为紧凑的蒸馏数据集，通过分类器驱动指导和潜在空间聚类提升合成样本质量。


<details>
  <summary>Details</summary>
Motivation: 深度学习在遥感图像解释中依赖大规模数据集带来两个主要挑战：(1) 高存储和计算成本，(2) 涉及敏感类别时的数据泄露风险。需要一种方法在保持模型性能的同时减少对原始数据的依赖。

Method: 1) 使用文本到图像扩散模型将大规模遥感数据集压缩为紧凑的蒸馏数据集；2) 提出分类器驱动指导，将预训练模型的分类一致性损失注入扩散训练过程；3) 对训练样本进行潜在空间聚类选择代表性原型作为视觉风格指导；4) 使用视觉语言模型提供聚合文本描述。

Result: 在三个高分辨率遥感场景分类基准测试中，该方法能够为下游模型训练蒸馏出真实且多样化的样本。代码和预训练模型已在线发布。

Conclusion: 首次将数据集蒸馏引入遥感图像解释领域，提出的方法能够有效压缩大规模遥感数据集，在减少存储计算成本和数据泄露风险的同时，保持合成样本的真实性和多样性，为下游模型训练提供高质量数据。

Abstract: Recent years have witnessed the remarkable success of deep learning in remote sensing image interpretation, driven by the availability of large-scale benchmark datasets. However, this reliance on massive training data also brings two major challenges: (1) high storage and computational costs, and (2) the risk of data leakage, especially when sensitive categories are involved. To address these challenges, this study introduces the concept of dataset distillation into the field of remote sensing image interpretation for the first time. Specifically, we train a text-to-image diffusion model to condense a large-scale remote sensing dataset into a compact and representative distilled dataset. To improve the discriminative quality of the synthesized samples, we propose a classifier-driven guidance by injecting a classification consistency loss from a pre-trained model into the diffusion training process. Besides, considering the rich semantic complexity of remote sensing imagery, we further perform latent space clustering on training samples to select representative and diverse prototypes as visual style guidance, while using a visual language model to provide aggregated text descriptions. Experiments on three high-resolution remote sensing scene classification benchmarks show that the proposed method can distill realistic and diverse samples for downstream model training. Code and pre-trained models are available online (https://github.com/YonghaoXu/DPD).

</details>


### [36] [An IoT-Based Smart Plant Monitoring and Irrigation System with Real-Time Environmental Sensing, Automated Alerts, and Cloud Analytics](https://arxiv.org/abs/2601.15830)
*Abdul Hasib,A. S. M. Ahsanul Sarkar Akib*

Main category: cs.CV

TL;DR: 本文提出了一种基于物联网的智能植物监测系统，集成多种环境传感器与自动化灌溉，通过ESP32微控制器实时收集数据并传输至云端，实现精准农业管理，可减少约40%的用水量。


<details>
  <summary>Details</summary>
Motivation: 全球对可持续农业的需求日益增长，传统农业依赖人工观察和定期浇水，导致水资源浪费、植物生长不一致以及对环境变化响应延迟。需要智能监测系统来优化资源利用和植物健康管理。

Method: 采用ESP32微控制器集成DHT22（温湿度）、HC-SR04（水位）和土壤湿度传感器，通过OLED显示屏提供视觉反馈，蜂鸣器提供听觉警报。所有传感器数据无线传输至ThingSpeak云平台进行远程监控、历史分析和自动警报生成。

Result: 实验结果表明，系统能有效维持最佳土壤湿度水平（准确率达92%），提供实时环境监测，相比传统灌溉方法减少约40%的用水量。系统总实施成本为45.20美元，适合小规模园艺和商业农业应用。

Conclusion: 该物联网智能植物监测系统为精准农业和智能农业提供了一种经济实惠、可扩展的解决方案，通过集成传感器、自动化灌溉和云端分析，显著提高了水资源利用效率并优化了植物健康管理。

Abstract: The increasing global demand for sustainable agriculture necessitates intelligent monitoring systems that optimize resource utilization and plant health management. Traditional farming methods rely on manual observation and periodic watering, often leading to water wastage, inconsistent plant growth, and delayed response to environmental changes. This paper presents a comprehensive IoT-based smart plant monitoring system that integrates multiple environmental sensors with automated irrigation and cloud analytics. The proposed system utilizes an ESP32 microcontroller to collect real-time data from DHT22 (temperature/humidity), HC-SR04 (water level), and soil moisture sensors, with visual feedback through an OLED display and auditory alerts via a buzzer. All sensor data is wirelessly transmitted to the ThingSpeak cloud platform for remote monitoring, historical analysis, and automated alert generation. Experimental results demonstrate the system's effectiveness in maintaining optimal soil moisture levels (with 92\% accuracy), providing real-time environmental monitoring, and reducing water consumption by approximately 40\% compared to conventional irrigation methods. The integrated web dashboard offers comprehensive visualization of plant health parameters, making it suitable for both small-scale gardening and commercial agriculture applications. With a total implementation cost of \$45.20, this system provides an affordable, scalable solution for precision agriculture and smart farming.

</details>


### [37] [TinySense: Effective CSI Compression for Scalable and Accurate Wi-Fi Sensing](https://arxiv.org/abs/2601.15838)
*Toan Gian,Dung T. Tran,Viet Quoc Pham,Francesco Restuccia,Van-Dinh Nguyen*

Main category: cs.CV

TL;DR: TinySense是一个基于VQGAN的Wi-Fi CSI数据压缩框架，用于高效的人体姿态估计，在保持精度的同时显著减少网络资源消耗。


<details>
  <summary>Details</summary>
Motivation: 随着对设备无关和隐私保护感知解决方案的需求增长，Wi-Fi感知成为人体姿态估计的有前景方法。但现有方法直接处理大量CSI数据，给网络资源带来压力，需要更高效的压缩方案来提升Wi-Fi感知的可扩展性。

Method: 提出TinySense压缩框架，基于VQGAN学习码本，显著减少CSI数据量。使用K-means算法动态调整压缩比特率，将大规模预训练码本聚类为更小子集。结合Transformer模型缓解比特率损失，增强不可靠网络条件下的鲁棒性。在Jetson Nano和Raspberry Pi上实现原型系统。

Result: TinySense显著优于现有压缩方案，在相同压缩率下实现高达1.5倍的人体姿态估计精度提升（PCK20）。延迟降低达5倍，网络开销减少达2.5倍。

Conclusion: TinySense通过创新的VQGAN压缩框架，有效解决了Wi-Fi感知中的资源消耗问题，在保持高精度的同时显著提升了系统效率和可扩展性，为设备无关的隐私保护感知提供了实用解决方案。

Abstract: With the growing demand for device-free and privacy-preserving sensing solutions, Wi-Fi sensing has emerged as a promising approach for human pose estimation (HPE). However, existing methods often process vast amounts of channel state information (CSI) data directly, ultimately straining networking resources. This paper introduces TinySense, an efficient compression framework that enhances the scalability of Wi-Fi-based human sensing. Our approach is based on a new vector quantization-based generative adversarial network (VQGAN). Specifically, by leveraging a VQGAN-learned codebook, TinySense significantly reduces CSI data while maintaining the accuracy required for reliable HPE. To optimize compression, we employ the K-means algorithm to dynamically adjust compression bitrates to cluster a large-scale pre-trained codebook into smaller subsets. Furthermore, a Transformer model is incorporated to mitigate bitrate loss, enhancing robustness in unreliable networking conditions. We prototype TinySense on an experimental testbed using Jetson Nano and Raspberry Pi to measure latency and network resource use. Extensive results demonstrate that TinySense significantly outperforms state-of-the-art compression schemes, achieving up to 1.5x higher HPE accuracy score (PCK20) under the same compression rate. It also reduces latency and networking overhead, respectively, by up to 5x and 2.5x. The code repository is available online at here.

</details>


### [38] [A Lightweight Brain-Inspired Machine Learning Framework for Coronary Angiography: Hybrid Neural Representation and Robust Learning Strategies](https://arxiv.org/abs/2601.15865)
*Jingsong Xia,Siqi Wang*

Main category: cs.CV

TL;DR: 提出轻量级脑启发式深度学习框架用于冠脉造影分类，在计算资源有限下实现稳健性能


<details>
  <summary>Details</summary>
Motivation: 真实临床冠脉造影图像存在复杂病变形态、严重类别不平衡、标签不确定性和有限计算资源等挑战，传统深度学习方法在鲁棒性和泛化性方面面临困难

Method: 基于预训练CNN构建轻量级混合神经表示，采用选择性神经可塑性训练策略，结合Focal Loss与标签平滑的脑启发注意力调制损失函数，使用类别不平衡感知采样和余弦退火重启策略

Result: 提出的轻量级脑启发模型在二分类冠脉造影任务中取得稳定优异性能，在准确率、召回率、F1分数和AUC指标上表现竞争性，同时保持高计算效率

Conclusion: 验证了脑启发学习机制在轻量级医学图像分析中的有效性，为有限计算资源下的智能临床决策支持提供了生物学合理且可部署的解决方案

Abstract: Background: Coronary angiography (CAG) is a cornerstone imaging modality for assessing coronary artery disease and guiding interventional treatment decisions. However, in real-world clinical settings, angiographic images are often characterized by complex lesion morphology, severe class imbalance, label uncertainty, and limited computational resources, posing substantial challenges to conventional deep learning approaches in terms of robustness and generalization.Methods: The proposed framework is built upon a pretrained convolutional neural network to construct a lightweight hybrid neural representation. A selective neural plasticity training strategy is introduced to enable efficient parameter adaptation. Furthermore, a brain-inspired attention-modulated loss function, combining Focal Loss with label smoothing, is employed to enhance sensitivity to hard samples and uncertain annotations. Class-imbalance-aware sampling and cosine annealing with warm restarts are adopted to mimic rhythmic regulation and attention allocation mechanisms observed in biological neural systems.Results: Experimental results demonstrate that the proposed lightweight brain-inspired model achieves strong and stable performance in binary coronary angiography classification, yielding competitive accuracy, recall, F1-score, and AUC metrics while maintaining high computational efficiency.Conclusion: This study validates the effectiveness of brain-inspired learning mechanisms in lightweight medical image analysis and provides a biologically plausible and deployable solution for intelligent clinical decision support under limited computational resources.

</details>


### [39] [Out-of-Distribution Detection Based on Total Variation Estimation](https://arxiv.org/abs/2601.15867)
*Dabiao Ma,Zhiba Su,Jian Yang,Haojun Fei*

Main category: cs.CV

TL;DR: TV-OOD：一种基于总变分网络估计器的新颖OOD检测方法，通过计算输入对总变分的贡献来区分分布内外数据，在图像分类任务中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在实际应用中，机器学习模型部署面临分布偏移的威胁。现有OOD检测方法虽然取得了一定效果，但仍有改进空间，需要更有效的方法来保护模型免受分布外数据的影响。

Method: 提出TV-OOD检测方法，利用总变分网络估计器计算每个输入对整体总变分的贡献，将其定义为总变分分数，基于此分数区分分布内和分布外数据。

Result: 在多种模型和数据集上进行测试，TV-OOD在图像分类任务中表现一致，在所有评估指标上均达到或优于最先进的OOD检测技术。

Conclusion: TV-OOD方法通过总变分网络估计器有效检测分布外数据，为机器学习模型部署提供了更可靠的分布偏移防护方案，在图像分类任务中展现出优越性能。

Abstract: This paper introduces a novel approach to securing machine learning model deployments against potential distribution shifts in practical applications, the Total Variation Out-of-Distribution (TV-OOD) detection method. Existing methods have produced satisfactory results, but TV-OOD improves upon these by leveraging the Total Variation Network Estimator to calculate each input's contribution to the overall total variation. By defining this as the total variation score, TV-OOD discriminates between in- and out-of-distribution data. The method's efficacy was tested across a range of models and datasets, consistently yielding results in image classification tasks that were either comparable or superior to those achieved by leading-edge out-of-distribution detection techniques across all evaluation metrics.

</details>


### [40] [PMPBench: A Paired Multi-Modal Pan-Cancer Benchmark for Medical Image Synthesis](https://arxiv.org/abs/2601.15884)
*Yifan Chen,Fei Yin,Hao Chen,Jia Wu,Chao Li*

Main category: cs.CV

TL;DR: 提出了首个公开、完全配对、跨11个人体器官的泛癌症医学影像数据集，包含完整的动态对比增强MRI序列和配对CT对比增强采集，用于AI图像翻译研究。


<details>
  <summary>Details</summary>
Motivation: 对比剂在放射成像中至关重要，但受患者健康状况或医疗资源限制，并非总能使用。现有AI图像翻译研究面临数据限制：公共数据集主要集中于脑部MR、数据配对不完整、标签缺失、大量资源私有。

Method: 构建了首个公开、完全配对的泛癌症医学影像数据集，涵盖11个人体器官，包括完整的DCE-MRI序列（DCE1-DCE3）和配对CT对比增强采集（CTC）。数据集经过解剖对应性处理，支持1对1、N对1和N对N翻译设置评估。

Result: 建立了全面的基准测试，报告了当代图像到图像翻译代表性基线的结果。数据集和基准测试已公开发布，旨在推动安全有效的对比剂合成研究。

Conclusion: 该数据集填补了医学影像翻译研究的数据空白，为多器官肿瘤成像工作流程提供了直接相关的研究资源，有望促进安全有效的对比剂合成技术发展。

Abstract: Contrast medium plays a pivotal role in radiological imaging, as it amplifies lesion conspicuity and improves detection for the diagnosis of tumor-related diseases. However, depending on the patient's health condition or the medical resources available, the use of contrast medium is not always feasible. Recent work has explored AI-based image translation to synthesize contrast-enhanced images directly from non-contrast scans, aims to reduce side effects and streamlines clinical workflows. Progress in this direction has been constrained by data limitations: (1) existing public datasets focus almost exclusively on brain-related paired MR modalities; (2) other collections include partially paired data but suffer from missing modalities/timestamps and imperfect spatial alignment; (3) explicit labeling of CT vs. CTC or DCE phases is often absent; (4) substantial resources remain private. To bridge this gap, we introduce the first public, fully paired, pan-cancer medical imaging dataset spanning 11 human organs. The MR data include complete dynamic contrast-enhanced (DCE) sequences covering all three phases (DCE1-DCE3), while the CT data provide paired non-contrast and contrast-enhanced acquisitions (CTC). The dataset is curated for anatomical correspondence, enabling rigorous evaluation of 1-to-1, N-to-1, and N-to-N translation settings (e.g., predicting DCE phases from non-contrast inputs). Built upon this resource, we establish a comprehensive benchmark. We report results from representative baselines of contemporary image-to-image translation. We release the dataset and benchmark to catalyze research on safe, effective contrast synthesis, with direct relevance to multi-organ oncology imaging workflows. Our code and dataset are publicly available at https://github.com/YifanChen02/PMPBench.

</details>


### [41] [Understanding the Transfer Limits of Vision Foundation Models](https://arxiv.org/abs/2601.15888)
*Shiqi Huang,Yipei Wang,Natasha Thorley,Alexander Ng,Shaheer Saeed,Mark Emberton,Shonit Punwani,Veeru Kasivisvanathan,Dean Barratt,Daniel Alexander,Yipeng Hu*

Main category: cs.CV

TL;DR: 研究发现视觉基础模型在下游任务中表现不均，源于预训练目标与下游任务需求不匹配，通过前列腺MRI任务验证了任务对齐对性能提升的重要性。


<details>
  <summary>Details</summary>
Motivation: 视觉基础模型虽然投入大量计算资源，但在下游任务中表现不均，作者认为这是由于预训练目标（如掩码图像重建或对比学习）与下游视觉任务（如分割、分类、图像合成）的具体需求不匹配造成的。

Method: 在前列腺多参数MRI成像的五个任务上评估两种视觉基础模型：基于MAE的重建模型ProFound和基于对比学习的模型ProViCNet，通过最大均值差异等简单发散度量来衡量预训练与下游任务的对齐程度。

Result: 研究发现预训练与下游任务更好的对齐（通过微调前后相同特征的MMD度量）与更大的性能提升和更快的收敛速度相关，强调了设计预训练目标时考虑下游应用的重要性。

Conclusion: 视觉基础模型的预训练目标需要与下游任务需求更好地对齐，任务对齐程度与性能改进正相关，这为未来设计更有效的视觉基础模型提供了重要指导。

Abstract: Foundation models leverage large-scale pretraining to capture extensive knowledge, demonstrating generalization in a wide range of language tasks. By comparison, vision foundation models (VFMs) often exhibit uneven improvements across downstream tasks, despite substantial computational investment. We postulate that this limitation arises from a mismatch between pretraining objectives and the demands of downstream vision-and-imaging tasks. Pretraining strategies like masked image reconstruction or contrastive learning shape representations for tasks such as recovery of generic visual patterns or global semantic structures, which may not align with the task-specific requirements of downstream applications including segmentation, classification, or image synthesis. To investigate this in a concrete real-world clinical area, we assess two VFMs, a reconstruction-focused MAE-based model (ProFound) and a contrastive-learning-based model (ProViCNet), on five prostate multiparametric MR imaging tasks, examining how such task alignment influences transfer performance, i.e., from pretraining to fine-tuning. Our findings indicate that better alignment between pretraining and downstream tasks, measured by simple divergence metrics such as maximum-mean-discrepancy (MMD) between the same features before and after fine-tuning, correlates with greater performance improvements and faster convergence, emphasizing the importance of designing and analyzing pretraining objectives with downstream applicability in mind.

</details>


### [42] [RadJEPA: Radiology Encoder for Chest X-Rays via Joint Embedding Predictive Architecture](https://arxiv.org/abs/2601.15891)
*Anas Anwarul Haq Khan,Mariam Husain,Kshitij Jadhav*

Main category: cs.CV

TL;DR: RadJEPA：一种无需语言监督的自监督医学影像学习框架，通过预测掩码区域潜在表示，在疾病分类、语义分割和报告生成任务中超越现有方法


<details>
  <summary>Details</summary>
Motivation: 当前医学视觉语言模型依赖配对的图像-文本数据进行监督学习，但这种数据获取受限。研究探索是否能在不依赖语言监督的情况下学习稳健的放射学编码器。

Method: 提出RadJEPA自监督框架，基于联合嵌入预测架构，仅使用未标记的胸部X光图像进行预训练。模型学习预测掩码图像区域的潜在表示，与图像-文本预训练和DINO式自蒸馏不同，它显式建模潜在空间预测。

Result: 在疾病分类、语义分割和报告生成任务评估中，RadJEPA在所有基准测试中表现优于现有最先进方法，包括Rad-DINO。

Conclusion: RadJEPA证明了无需语言监督也能学习有效的放射学编码器，通过潜在空间预测的自监督方法在多个医学影像任务中取得优异性能。

Abstract: Recent advances in medical vision language models guide the learning of visual representations; however, this form of supervision is constrained by the availability of paired image text data, raising the question of whether robust radiology encoders can be learned without relying on language supervision. In this work, we introduce RadJEPA, a self-supervised framework built on a Joint Embedding Predictive Architecture that learns without language supervision. Pre-trained solely on unlabeled chest X-ray images, the model learns to predict latent representations of masked image regions. This predictive objective differs fundamentally from both image text pre-training and DINO-style self-distillation: rather than aligning global representations across views or modalities, RadJEPA explicitly models latent-space prediction. We evaluate the learned encoder on disease classification, semantic segmentation, and report generation tasks. Across benchmarks, RadJEPA achieves performance exceeding state-of-the-art approaches, including Rad-DINO.

</details>


### [43] [ThermoSplat: Cross-Modal 3D Gaussian Splatting with Feature Modulation and Geometry Decoupling](https://arxiv.org/abs/2601.15897)
*Zhaoqi Su,Shihai Chen,Xinyan Lin,Liqin Huang,Zhipeng Su,Xiaoqiang Lu*

Main category: cs.CV

TL;DR: ThermoSplat：通过跨模态特征调制和自适应几何解耦实现RGB-热红外多模态场景重建的3D高斯泼溅框架


<details>
  <summary>Details</summary>
Motivation: 现有多模态3DGS方法难以充分利用RGB和热红外数据的互补信息，要么忽视跨模态相关性，要么使用无法自适应处理频谱间复杂结构相关性和物理差异的共享表示。

Method: 1. 跨模态FiLM调制机制：基于热结构先验动态调节共享潜在特征，用可靠的跨模态几何线索指导可见光纹理合成；2. 模态自适应几何解耦方案：学习独立的不透明度偏移，为热分支执行独立光栅化；3. 混合渲染管道：结合显式球谐函数和隐式神经解码，确保语义一致性和高频细节保留。

Result: 在RGBT-Scenes数据集上的广泛实验表明，ThermoSplat在可见光和热红外频谱上都实现了最先进的渲染质量。

Conclusion: ThermoSplat通过主动特征调制和自适应几何解耦实现了深度频谱感知重建，有效解决了多模态3DGS中的跨模态信息利用问题。

Abstract: Multi-modal scene reconstruction integrating RGB and thermal infrared data is essential for robust environmental perception across diverse lighting and weather conditions. However, extending 3D Gaussian Splatting (3DGS) to multi-spectral scenarios remains challenging. Current approaches often struggle to fully leverage the complementary information of multi-modal data, typically relying on mechanisms that either tend to neglect cross-modal correlations or leverage shared representations that fail to adaptively handle the complex structural correlations and physical discrepancies between spectrums. To address these limitations, we propose ThermoSplat, a novel framework that enables deep spectral-aware reconstruction through active feature modulation and adaptive geometry decoupling. First, we introduce a Cross-Modal FiLM Modulation mechanism that dynamically conditions shared latent features on thermal structural priors, effectively guiding visible texture synthesis with reliable cross-modal geometric cues. Second, to accommodate modality-specific geometric inconsistencies, we propose a Modality-Adaptive Geometric Decoupling scheme that learns independent opacity offsets and executes an independent rasterization pass for the thermal branch. Additionally, a hybrid rendering pipeline is employed to integrate explicit Spherical Harmonics with implicit neural decoding, ensuring both semantic consistency and high-frequency detail preservation. Extensive experiments on the RGBT-Scenes dataset demonstrate that ThermoSplat achieves state-of-the-art rendering quality across both visible and thermal spectrums.

</details>


### [44] [Opening the Black Box: Preliminary Insights into Affective Modeling in Multimodal Foundation Models](https://arxiv.org/abs/2601.15906)
*Zhen Zhang,Runhao Zeng,Sicheng Zhao,Xiping Hu*

Main category: cs.CV

TL;DR: 研究发现多模态基础模型的情感能力主要由前馈门控机制（gate_proj）介导，而非注意力模块，通过仅调整24.5%的参数即可达到AffectGPT 96.6%的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管近期情感模型表现出强大的实证性能，但支持情感理解和生成的内在架构机制仍然知之甚少。理解情感在大规模基础模型中的表示位置和方式是一个开放问题。

Method: 对多模态基础模型中的情感建模进行系统性机制研究，分析情感导向监督如何重塑内部模型参数。通过受控模块转移、针对性单模块适应和破坏性消融等方法，探究不同架构、训练策略和情感任务。

Result: 研究一致揭示了一个清晰且稳健的模式：情感适应主要不关注注意力模块，而是定位到前馈门控投影（gate_proj）。gate_proj对于情感理解和生成是充分、高效且必要的。仅调整约24.5%的参数即可达到AffectGPT平均性能的96.6%。

Conclusion: 情感能力在基础模型中由前馈门控机制结构性地介导，gate_proj被识别为情感建模的中心架构位点，为理解情感在多模态基础模型中的表示提供了实证证据。

Abstract: Understanding where and how emotions are represented in large-scale foundation models remains an open problem, particularly in multimodal affective settings. Despite the strong empirical performance of recent affective models, the internal architectural mechanisms that support affective understanding and generation are still poorly understood. In this work, we present a systematic mechanistic study of affective modeling in multimodal foundation models. Across multiple architectures, training strategies, and affective tasks, we analyze how emotion-oriented supervision reshapes internal model parameters. Our results consistently reveal a clear and robust pattern: affective adaptation does not primarily focus on the attention module, but instead localizes to the feed-forward gating projection (\texttt{gate\_proj}). Through controlled module transfer, targeted single-module adaptation, and destructive ablation, we further demonstrate that \texttt{gate\_proj} is sufficient, efficient, and necessary for affective understanding and generation. Notably, by tuning only approximately 24.5\% of the parameters tuned by AffectGPT, our approach achieves 96.6\% of its average performance across eight affective tasks, highlighting substantial parameter efficiency. Together, these findings provide empirical evidence that affective capabilities in foundation models are structurally mediated by feed-forward gating mechanisms and identify \texttt{gate\_proj} as a central architectural locus of affective modeling.

</details>


### [45] [The Latency Wall: Benchmarking Off-the-Shelf Emotion Recognition for Real-Time Virtual Avatars](https://arxiv.org/abs/2601.15914)
*Yarin Benyamin*

Main category: cs.CV

TL;DR: 在VR/HCI领域，针对自闭症谱系障碍(ASD)的实时情绪识别面临延迟-准确率权衡挑战，现有深度学习模型难以满足VR治疗的实时性要求（MTP延迟<140ms）。


<details>
  <summary>Details</summary>
Motivation: 为ASD患者提供可访问的VR社交技能治疗，需要满足严格的实时性要求（MTP延迟<140ms），但现有深度学习模型通常优先考虑准确率而非延迟约束。

Method: 使用UIBVFED数据集，在虚拟角色上对零样本面部表情识别(SOTA)模型进行基准测试。评估YOLO(v8,v11,v12)的中型和纳米变体进行人脸检测，以及通用视觉Transformer(CLIP, SigLIP, ViT-FER)。在仅CPU推理环境下测试。

Result: 人脸检测在风格化虚拟角色上表现稳健（100%准确率），但分类阶段存在"延迟墙"。YOLOv11n在检测阶段提供最佳平衡（~54ms），而通用Transformer(CLIP, SigLIP)在实时循环中既无法达到可行准确率(<23%)，也无法满足速度要求(>150ms)。

Conclusion: 研究表明需要轻量级、领域特定的架构来实现治疗场景中可访问的实时AI，通用模型无法满足VR治疗的严格延迟要求。

Abstract: In the realm of Virtual Reality (VR) and Human-Computer Interaction (HCI), real-time emotion recognition shows promise for supporting individuals with Autism Spectrum Disorder (ASD) in improving social skills. This task requires a strict latency-accuracy trade-off, with motion-to-photon (MTP) latency kept below 140 ms to maintain contingency. However, most off-the-shelf Deep Learning models prioritize accuracy over the strict timing constraints of commodity hardware. As a first step toward accessible VR therapy, we benchmark State-of-the-Art (SOTA) models for Zero-Shot Facial Expression Recognition (FER) on virtual characters using the UIBVFED dataset. We evaluate Medium and Nano variants of YOLO (v8, v11, and v12) for face detection, alongside general-purpose Vision Transformers including CLIP, SigLIP, and ViT-FER.Our results on CPU-only inference demonstrate that while face detection on stylized avatars is robust (100% accuracy), a "Latency Wall" exists in the classification stage. The YOLOv11n architecture offers the optimal balance for detection (~54 ms). However, general-purpose Transformers like CLIP and SigLIP fail to achieve viable accuracy (<23%) or speed (>150 ms) for real-time loops. This study highlights the necessity for lightweight, domain-specific architectures to enable accessible, real-time AI in therapeutic settings.

</details>


### [46] [A Multi-View Pipeline and Benchmark Dataset for 3D Hand Pose Estimation in Surgery](https://arxiv.org/abs/2601.15918)
*Valery Fischer,Alan Magdaleno,Anna-Katharina Calek,Nicola Cavalcanti,Nathan Hoffman,Christoph Germann,Joschua Wüthrich,Max Krähenmann,Mazda Farshad,Philipp Fürnstahl,Lilian Calvet*

Main category: cs.CV

TL;DR: 提出无需领域微调、仅使用现成预训练模型的手术场景3D手部姿态估计多视角流程，并创建包含6.8万帧标注数据的手术基准数据集，性能显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 手术环境中的3D手部姿态估计对技能评估、机器人辅助干预和流程分析至关重要，但面临强烈局部光照、频繁遮挡、手套导致的统一外观以及标注数据稀缺等挑战。

Method: 提出无需领域特定微调的多视角流程：集成可靠的人体检测、全身姿态估计和先进的2D手部关键点预测，然后进行约束3D优化。同时创建包含6.8万帧、3000个手动标注2D手部姿态的手术基准数据集。

Result: 定量实验显示方法持续优于基线：2D平均关节误差减少31%，3D平均每关节位置误差减少76%。

Conclusion: 为手术3D手部姿态估计建立了强基线，提供了无需训练的流程和全面的标注数据集，促进未来手术计算机视觉研究。

Abstract: Purpose: Accurate 3D hand pose estimation supports surgical applications such as skill assessment, robot-assisted interventions, and geometry-aware workflow analysis. However, surgical environments pose severe challenges, including intense and localized lighting, frequent occlusions by instruments or staff, and uniform hand appearance due to gloves, combined with a scarcity of annotated datasets for reliable model training.
  Method: We propose a robust multi-view pipeline for 3D hand pose estimation in surgical contexts that requires no domain-specific fine-tuning and relies solely on off-the-shelf pretrained models. The pipeline integrates reliable person detection, whole-body pose estimation, and state-of-the-art 2D hand keypoint prediction on tracked hand crops, followed by a constrained 3D optimization. In addition, we introduce a novel surgical benchmark dataset comprising over 68,000 frames and 3,000 manually annotated 2D hand poses with triangulated 3D ground truth, recorded in a replica operating room under varying levels of scene complexity.
  Results: Quantitative experiments demonstrate that our method consistently outperforms baselines, achieving a 31% reduction in 2D mean joint error and a 76% reduction in 3D mean per-joint position error.
  Conclusion: Our work establishes a strong baseline for 3D hand pose estimation in surgery, providing both a training-free pipeline and a comprehensive annotated dataset to facilitate future research in surgical computer vision.

</details>


### [47] [Class Confidence Aware Reweighting for Long Tailed Learning](https://arxiv.org/abs/2601.15924)
*Brainard Philemon Jagati,Jitendra Tembhurne,Harsh Goud,Rudra Pratap Singh,Chandrashekhar Meshram*

Main category: cs.CV

TL;DR: 本文提出了一种基于损失级别的类别和置信度感知重加权方案，用于解决长尾数据分布下的深度神经网络性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在长尾数据分布下性能显著下降，现有研究主要关注决策空间中对数级别的类别先验偏差校正，而忽略了优化过程中样本间置信度差异带来的调整。本文旨在设计一种补充现有方法的损失级别重加权方案。

Method: 提出了一种类别和置信度感知的重加权方案，使用Ω(p_t, f_c)函数，该函数根据预测置信度和对应类别的相对频率来调制对训练任务的贡献。该方案纯粹基于损失级别，与现有的对数调整方法具有互补性。

Result: 在CIFAR-100-LT、ImageNet-LT和iNaturalist2018数据集上，在不同不平衡因子下进行了大量实验，结果显著验证了理论讨论的有效性。

Conclusion: 提出的类别和置信度感知重加权方案能够有效解决长尾学习问题，与现有的对数调整方法形成互补，在多个基准数据集上取得了显著性能提升。

Abstract: Deep neural network models degrade significantly in the long-tailed data distribution, with the overall training data dominated by a small set of classes in the head, and the tail classes obtaining less training examples. Addressing the imbalance in the classes, attention in the related literature was given mainly to the adjustments carried out in the decision space in terms of either corrections performed at the logit level in order to compensate class-prior bias, with the least attention to the optimization process resulting from the adjustments introduced through the differences in the confidences among the samples. In the current study, we present the design of a class and confidence-aware re-weighting scheme for long-tailed learning. This scheme is purely based upon the loss level and has a complementary nature to the existing methods performing the adjustment of the logits. In the practical implementation stage of the proposed scheme, we use an Ω(p_t, f_c) function. This function enables the modulation of the contribution towards the training task based upon the confidence value of the prediction, as well as the relative frequency of the corresponding class. Our observations in the experiments are corroborated by significant experimental results performed on the CIFAR-100-LT, ImageNet-LT, and iNaturalist2018 datasets under various values of imbalance factors that clearly authenticate the theoretical discussions above.

</details>


### [48] [NeuroMamba: Multi-Perspective Feature Interaction with Visual Mamba for Neuron Segmentation](https://arxiv.org/abs/2601.15929)
*Liuyun Jiang,Yizhuo Lu,Yanchao Zhang,Jiazheng Liu,Hua Han*

Main category: cs.CV

TL;DR: 提出NeuroMamba框架，结合Mamba的线性复杂度进行全局建模和局部特征建模，在神经元分割任务上实现SOTA性能


<details>
  <summary>Details</summary>
Motivation: 神经元分割是重建完整神经元连接组的基础，对理解大脑功能组织至关重要。现有CNN方法因缺乏长距离上下文而难以解决模糊边界问题，Transformer方法则因补丁划分导致体素级细节丢失而边界不精确。

Method: 提出NeuroMamba多视角框架：1) 通道门控边界判别特征提取器(BDFE)增强局部形态线索；2) 空间连续特征提取器(SCFE)将分辨率感知扫描机制集成到Visual Mamba架构中，自适应建模不同分辨率下的全局依赖；3) 交叉调制机制协同融合多视角特征。

Result: 在四个公共EM数据集上展示了最先进的性能，验证了其对各向异性和各向同性分辨率的卓越适应性。

Conclusion: NeuroMamba通过结合Mamba的线性复杂度全局建模和互补的局部特征建模，有效解决了神经元分割中的边界模糊和细节丢失问题，为神经元连接组重建提供了强大工具。

Abstract: Neuron segmentation is the cornerstone of reconstructing comprehensive neuronal connectomes, which is essential for deciphering the functional organization of the brain. The irregular morphology and densely intertwined structures of neurons make this task particularly challenging. Prevailing CNN-based methods often fail to resolve ambiguous boundaries due to the lack of long-range context, whereas Transformer-based methods suffer from boundary imprecision caused by the loss of voxel-level details during patch partitioning. To address these limitations, we propose NeuroMamba, a multi-perspective framework that exploits the linear complexity of Mamba to enable patch-free global modeling and synergizes this with complementary local feature modeling, thereby efficiently capturing long-range dependencies while meticulously preserving fine-grained voxel details. Specifically, we design a channel-gated Boundary Discriminative Feature Extractor (BDFE) to enhance local morphological cues. Complementing this, we introduce the Spatial Continuous Feature Extractor (SCFE), which integrates a resolution-aware scanning mechanism into the Visual Mamba architecture to adaptively model global dependencies across varying data resolutions. Finally, a cross-modulation mechanism synergistically fuses these multi-perspective features. Our method demonstrates state-of-the-art performance across four public EM datasets, validating its exceptional adaptability to both anisotropic and isotropic resolutions. The source code will be made publicly available.

</details>


### [49] [EVolSplat4D: Efficient Volume-based Gaussian Splatting for 4D Urban Scene Synthesis](https://arxiv.org/abs/2601.15951)
*Sheng Miao,Sijin Li,Pan Wang,Dongfeng Bai,Bingbing Liu,Yue Wang,Andreas Geiger,Yiyi Liao*

Main category: cs.CV

TL;DR: EvolSplat4D：一种用于动态城市场景新视角合成的前馈框架，通过统一基于体积和基于像素的高斯预测，在重建质量和效率之间取得平衡


<details>
  <summary>Details</summary>
Motivation: 现有方法难以平衡静态和动态城市场景新视角合成的重建时间与质量。基于神经辐射场和3D高斯泼溅的方法需要耗时的逐场景优化，而前馈方法通常采用逐像素高斯表示，在复杂动态环境中聚合多视图预测时会导致3D不一致性。

Method: 提出三分支框架：1) 近距离静态区域：从3D特征体积直接预测多帧一致的3D高斯几何，辅以语义增强的图像渲染模块预测外观；2) 动态物体：使用以物体为中心的规范空间和运动调整渲染模块聚合时间特征；3) 远场景：高效的逐像素高斯分支确保全场景覆盖。

Result: 在KITTI-360、KITTI、Waymo和PandaSet数据集上的实验表明，EvolSplat4D在重建静态和动态环境方面具有优越的准确性和一致性，优于逐场景优化方法和最先进的前馈基线方法。

Conclusion: EvolSplat4D通过统一体积和像素高斯预测的三分支框架，实现了高效且高质量的动态城市场景新视角合成，解决了现有方法在重建时间与质量平衡方面的挑战。

Abstract: Novel view synthesis (NVS) of static and dynamic urban scenes is essential for autonomous driving simulation, yet existing methods often struggle to balance reconstruction time with quality. While state-of-the-art neural radiance fields and 3D Gaussian Splatting approaches achieve photorealism, they often rely on time-consuming per-scene optimization. Conversely, emerging feed-forward methods frequently adopt per-pixel Gaussian representations, which lead to 3D inconsistencies when aggregating multi-view predictions in complex, dynamic environments. We propose EvolSplat4D, a feed-forward framework that moves beyond existing per-pixel paradigms by unifying volume-based and pixel-based Gaussian prediction across three specialized branches. For close-range static regions, we predict consistent geometry of 3D Gaussians over multiple frames directly from a 3D feature volume, complemented by a semantically-enhanced image-based rendering module for predicting their appearance. For dynamic actors, we utilize object-centric canonical spaces and a motion-adjusted rendering module to aggregate temporal features, ensuring stable 4D reconstruction despite noisy motion priors. Far-Field scenery is handled by an efficient per-pixel Gaussian branch to ensure full-scene coverage. Experimental results on the KITTI-360, KITTI, Waymo, and PandaSet datasets show that EvolSplat4D reconstructs both static and dynamic environments with superior accuracy and consistency, outperforming both per-scene optimization and state-of-the-art feed-forward baselines.

</details>


### [50] [HyperAlign: Hypernetwork for Efficient Test-Time Alignment of Diffusion Models](https://arxiv.org/abs/2601.15968)
*Xin Xie,Jiaxian Guo,Dong Gong*

Main category: cs.CV

TL;DR: HyperAlign：通过超网络动态生成低秩适配权重，在推理时高效调整扩散模型生成过程，解决现有对齐方法在多样性与计算开销之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 扩散模型虽然性能优异，但生成的图像常常不符合人类偏好和意图，存在美学质量差和语义不一致的问题。现有对齐方法面临两难：微调方法会导致多样性损失和奖励过优化，而推理时缩放方法计算开销大且优化不足。

Method: 提出HyperAlign框架，训练超网络在推理时动态生成低秩适配权重来调制扩散模型的生成算子。根据输入潜变量、时间步和提示词自适应调整去噪轨迹，实现奖励条件对齐。提供多种变体以平衡性能与效率，并使用正则化的奖励分数目标优化超网络以防止奖励黑客。

Result: 在Stable Diffusion和FLUX等多个生成范式中评估，HyperAlign在增强语义一致性和视觉吸引力方面显著优于现有的微调和推理时缩放基线方法。

Conclusion: HyperAlign通过超网络动态生成适配权重，有效解决了扩散模型对齐中的多样性损失与计算开销的权衡问题，实现了高效且有效的推理时对齐。

Abstract: Diffusion models achieve state-of-the-art performance but often fail to generate outputs that align with human preferences and intentions, resulting in images with poor aesthetic quality and semantic inconsistencies. Existing alignment methods present a difficult trade-off: fine-tuning approaches suffer from loss of diversity with reward over-optimization, while test-time scaling methods introduce significant computational overhead and tend to under-optimize. To address these limitations, we propose HyperAlign, a novel framework that trains a hypernetwork for efficient and effective test-time alignment. Instead of modifying latent states, HyperAlign dynamically generates low-rank adaptation weights to modulate the diffusion model's generation operators. This allows the denoising trajectory to be adaptively adjusted based on input latents, timesteps and prompts for reward-conditioned alignment. We introduce multiple variants of HyperAlign that differ in how frequently the hypernetwork is applied, balancing between performance and efficiency. Furthermore, we optimize the hypernetwork using a reward score objective regularized with preference data to reduce reward hacking. We evaluate HyperAlign on multiple extended generative paradigms, including Stable Diffusion and FLUX. It significantly outperforms existing fine-tuning and test-time scaling baselines in enhancing semantic consistency and visual appeal.

</details>


### [51] [PhysicsMind: Sim and Real Mechanics Benchmarking for Physical Reasoning and Prediction in Foundational VLMs and World Models](https://arxiv.org/abs/2601.16007)
*Chak-Wing Mak,Guanyu Zhu,Boyi Zhang,Hongji Li,Xiaowei Chi,Kevin Zhang,Yichen Wu,Yangfan He,Chun-Kai Fan,Wentao Lu,Kuangzhi Ge,Xinyu Fang,Hongyang He,Kuan Lu,Tianxiang Xu,Li Zhang,Yongxin Ni,Youhua Li,Shanghang Zhang*

Main category: cs.CV

TL;DR: 论文提出了PhysicsMind基准，用于评估多模态大语言模型和视频世界模型在物理规律理解方面的能力，填补了现有基准在物理推理评估上的不足。


<details>
  <summary>Details</summary>
Motivation: 当前的多模态大语言模型和视频世界模型在数学、常识和视觉推理方面取得了显著进展，但它们在物理规律理解方面的能力尚未得到充分探索。现有的基准要么依赖合成的视觉问答模板，要么关注与物理规律无关的视频质量评估，缺乏对物理规律一致性推理和生成的系统性评估。

Method: 提出了PhysicsMind统一基准，包含真实和模拟环境，评估三个经典物理原理（质心、杠杆平衡、牛顿第一定律）的规律一致性推理和生成。基准包含两个主要任务：1）视觉问答任务，测试模型从图像或短视频中推理物理量和数值的能力；2）视频生成任务，评估预测的运动轨迹是否遵循与真实情况相同的质心、扭矩和惯性约束。

Result: 对一系列最新模型和视频生成模型的评估发现，这些模型主要依赖外观启发式方法，经常违反基本力学原理。这些差距表明当前的扩展和训练方法仍然不足以实现稳健的物理理解。

Conclusion: PhysicsMind作为一个专注于物理感知多模态模型的测试平台，突显了当前模型在物理理解方面的不足，为未来开发具有更强物理推理能力的模型提供了重要的评估工具。

Abstract: Modern foundational Multimodal Large Language Models (MLLMs) and video world models have advanced significantly in mathematical, common-sense, and visual reasoning, but their grasp of the underlying physics remains underexplored. Existing benchmarks attempting to measure this matter rely on synthetic, Visual Question Answer templates or focus on perceptual video quality that is tangential to measuring how well the video abides by physical laws. To address this fragmentation, we introduce PhysicsMind, a unified benchmark with both real and simulation environments that evaluates law-consistent reasoning and generation over three canonical principles: Center of Mass, Lever Equilibrium, and Newton's First Law. PhysicsMind comprises two main tasks: i) VQA tasks, testing whether models can reason and determine physical quantities and values from images or short videos, and ii) Video Generation(VG) tasks, evaluating if predicted motion trajectories obey the same center-of-mass, torque, and inertial constraints as the ground truth. A broad range of recent models and video generation models is evaluated on PhysicsMind and found to rely on appearance heuristics while often violating basic mechanics. These gaps indicate that current scaling and training are still insufficient for robust physical understanding, underscoring PhysicsMind as a focused testbed for physics-aware multimodal models. Our data will be released upon acceptance.

</details>


### [52] [Keyframe-Based Feed-Forward Visual Odometry](https://arxiv.org/abs/2601.16020)
*Weichen Dai,Wenhan Su,Da Kong,Yuhang Ming,Wanzeng Kong*

Main category: cs.CV

TL;DR: 提出基于强化学习的关键帧选择策略，改进视觉基础模型的视觉里程计性能


<details>
  <summary>Details</summary>
Motivation: 当前基于视觉基础模型的VO方法通常不加区分地处理原始图像序列，导致计算冗余和性能下降，而传统几何启发式方法难以集成到这些模型中

Method: 使用强化学习在数据驱动的方式下推导自适应关键帧策略，使选择与基础模型的内在特性对齐，而不是依赖手工规则

Result: 在TartanAir数据集上训练，在多个真实世界数据集上进行广泛评估，实验结果表明该方法相比最先进的feed-forward VO方法取得了持续且显著的改进

Conclusion: 提出的基于强化学习的关键帧选择方法有效解决了视觉基础模型在VO中的计算冗余问题，显著提升了性能

Abstract: The emergence of visual foundation models has revolutionized visual odometry~(VO) and SLAM, enabling pose estimation and dense reconstruction within a single feed-forward network. However, unlike traditional pipelines that leverage keyframe methods to enhance efficiency and accuracy, current foundation model based methods, such as VGGT-Long, typically process raw image sequences indiscriminately. This leads to computational redundancy and degraded performance caused by low inter-frame parallax, which provides limited contextual stereo information. Integrating traditional geometric heuristics into these methods is non-trivial, as their performance depends on high-dimensional latent representations rather than explicit geometric metrics. To bridge this gap, we propose a novel keyframe-based feed-forward VO. Instead of relying on hand-crafted rules, our approach employs reinforcement learning to derive an adaptive keyframe policy in a data-driven manner, aligning selection with the intrinsic characteristics of the underlying foundation model. We train our agent on TartanAir dataset and conduct extensive evaluations across several real-world datasets. Experimental results demonstrate that the proposed method achieves consistent and substantial improvements over state-of-the-art feed-forward VO methods.

</details>


### [53] [PAINT: Pathology-Aware Integrated Next-Scale Transformation for Virtual Immunohistochemistry](https://arxiv.org/abs/2601.16024)
*Rongze Ma,Mengkang Lu,Zhenyu Xiang,Yongsheng Pan,Yicheng Wu,Qingjie Zeng,Yong Xia*

Main category: cs.CV

TL;DR: PAINT是一种视觉自回归框架，通过结构优先的条件生成方法从H&E图像合成虚拟免疫组化染色，使用空间结构起始图确保形态学对齐。


<details>
  <summary>Details</summary>
Motivation: 虚拟免疫组化（IHC）旨在从常规H&E图像计算合成分子染色模式，提供比传统物理染色更经济、组织效率更高的替代方案。但该任务面临挑战：H&E形态学提供关于蛋白质表达的模糊线索，相似的组织结构可能对应不同的分子状态。现有方法通常关注直接外观合成，由于结构先验不足导致语义不一致。

Method: 提出病理学感知集成下一尺度变换（PAINT），将合成过程重新表述为结构优先的条件生成任务。该方法引入空间结构起始图（3S-Map），将自回归初始化基于观察到的形态学，确保确定性的空间对齐合成。通过解决基于全局结构布局的分子细节，强制执行因果顺序。

Result: 在IHC4BC和MIST数据集上的实验表明，PAINT在结构保真度和临床下游任务方面优于最先进的方法，验证了结构引导自回归建模的潜力。

Conclusion: PAINT通过结构优先的自回归框架成功解决了虚拟免疫组化合成中的语义不一致问题，为计算病理学提供了一种有效的组织高效替代方案。

Abstract: Virtual immunohistochemistry (IHC) aims to computationally synthesize molecular staining patterns from routine Hematoxylin and Eosin (H\&E) images, offering a cost-effective and tissue-efficient alternative to traditional physical staining. However, this task is particularly challenging: H\&E morphology provides ambiguous cues about protein expression, and similar tissue structures may correspond to distinct molecular states. Most existing methods focus on direct appearance synthesis to implicitly achieve cross-modal generation, often resulting in semantic inconsistencies due to insufficient structural priors. In this paper, we propose Pathology-Aware Integrated Next-Scale Transformation (PAINT), a visual autoregressive framework that reformulates the synthesis process as a structure-first conditional generation task. Unlike direct image translation, PAINT enforces a causal order by resolving molecular details conditioned on a global structural layout. Central to this approach is the introduction of a Spatial Structural Start Map (3S-Map), which grounds the autoregressive initialization in observed morphology, ensuring deterministic, spatially aligned synthesis. Experiments on the IHC4BC and MIST datasets demonstrate that PAINT outperforms state-of-the-art methods in structural fidelity and clinical downstream tasks, validating the potential of structure-guided autoregressive modeling.

</details>


### [54] [ProGiDiff: Prompt-Guided Diffusion-Based Medical Image Segmentation](https://arxiv.org/abs/2601.16060)
*Yuan Lin,Murong Xu,Marc Hölle,Chinmay Prabhakar,Andreas Maier,Vasileios Belagiannis,Bjoern Menze,Suprosanna Shit*

Main category: cs.CV

TL;DR: ProGiDiff：基于预训练扩散模型的医学图像分割框架，通过ControlNet式条件机制和自然语言提示实现多类别分割，支持跨模态适应


<details>
  <summary>Details</summary>
Motivation: 现有医学图像分割方法主要是确定性的，缺乏自然语言提示能力，无法生成多个分割方案、支持人机交互和跨模态适应。文本到图像扩散模型虽有潜力，但从头训练需要大量数据，且通常限于二值分割

Method: 提出ProGiDiff框架，利用预训练扩散模型进行医学图像分割。采用ControlNet式条件机制和自定义编码器，通过图像条件引导扩散模型输出分割掩码。支持多类别分割（通过提示目标器官），并可通过低秩少样本适应实现跨模态迁移

Result: 在CT图像器官分割实验中表现优于先前方法，支持专家在环设置以利用多个分割方案。学习到的条件机制可通过少量样本轻松迁移到MR图像分割

Conclusion: ProGiDiff成功将预训练扩散模型应用于医学图像分割，实现了自然语言提示、多方案生成和跨模态适应，为医学图像分析提供了灵活强大的工具

Abstract: Widely adopted medical image segmentation methods, although efficient, are primarily deterministic and remain poorly amenable to natural language prompts. Thus, they lack the capability to estimate multiple proposals, human interaction, and cross-modality adaptation. Recently, text-to-image diffusion models have shown potential to bridge the gap. However, training them from scratch requires a large dataset-a limitation for medical image segmentation. Furthermore, they are often limited to binary segmentation and cannot be conditioned on a natural language prompt. To this end, we propose a novel framework called ProGiDiff that leverages existing image generation models for medical image segmentation purposes. Specifically, we propose a ControlNet-style conditioning mechanism with a custom encoder, suitable for image conditioning, to steer a pre-trained diffusion model to output segmentation masks. It naturally extends to a multi-class setting simply by prompting the target organ. Our experiment on organ segmentation from CT images demonstrates strong performance compared to previous methods and could greatly benefit from an expert-in-the-loop setting to leverage multiple proposals. Importantly, we demonstrate that the learned conditioning mechanism can be easily transferred through low-rank, few-shot adaptation to segment MR images.

</details>


### [55] [DTP: A Simple yet Effective Distracting Token Pruning Framework for Vision-Language Action Models](https://arxiv.org/abs/2601.16065)
*Chenyang Li,Jieyuan Liu,Bin Li,Bo Gao,Yilin Yuan,Yangfan He,Yuchen Li,Jingqun Tang*

Main category: cs.CV

TL;DR: 提出DTP框架，通过动态检测和剪枝视觉语言动作模型中的"干扰token"来提升任务成功率，无需修改模型架构


<details>
  <summary>Details</summary>
Motivation: VLA模型在处理机器人操作任务时，会过度关注任务无关区域的图像token（干扰token），这会干扰模型生成正确的动作token，影响任务成功率

Method: 提出即插即用的Distracting Token Pruning（DTP）框架，动态检测并剪枝干扰图像token，修正模型的视觉注意力模式

Result: 在SIMPLER基准测试中，该方法在不同类型的新型VLA模型上都实现了任务成功率的相对提升，展示了在基于transformer的VLA模型上的泛化能力

Conclusion: DTP框架能有效提升VLA模型的性能，实验发现任务成功率与任务无关区域的注意力量呈负相关，这一现象可为未来研究提供指导

Abstract: Vision-Language Action (VLA) models have shown remarkable progress in robotic manipulation by leveraging the powerful perception abilities of Vision-Language Models (VLMs) to understand environments and directly output actions. However, by default, VLA models may overly attend to image tokens in the task-irrelevant region, which we describe as 'distracting tokens'. This behavior can disturb the model from the generation of the desired action tokens in each step, affecting the success rate of tasks. In this paper, we introduce a simple yet effective plug-and-play Distracting Token Pruning (DTP) framework, which dynamically detects and prunes these distracting image tokens. By correcting the model's visual attention patterns, we aim to improve the task success rate, as well as exploring the performance upper boundaries of the model without altering its original architecture or adding additional inputs. Experiments on the SIMPLER Benchmark (Li et al., 2024) show that our method consistently achieving relative improvements in task success rates across different types of novel VLA models, demonstrating generalizability to transformer-based VLAs. Further analysis reveals a negative correlation between the task success rate and the amount of attentions in the task-irrelevant region for all models tested, highlighting a common phenomenon of VLA models that could guide future research. We also publish our code at: https://anonymous.4open.science/r/CBD3.

</details>


### [56] [DSFedMed: Dual-Scale Federated Medical Image Segmentation via Mutual Distillation Between Foundation and Lightweight Models](https://arxiv.org/abs/2601.16073)
*Hanwen Zhang,Qiaojin Shen,Yuxi Liu,Yuesheng Zhu,Guibo Luo*

Main category: cs.CV

TL;DR: DSFedMed是一个用于医学图像分割的双尺度联邦框架，通过中心化基础模型与轻量级客户端模型之间的相互知识蒸馏，在减少90%通信和推理成本的同时，实现平均2%的Dice分数提升。


<details>
  <summary>Details</summary>
Motivation: 基础模型在联邦学习环境中部署面临计算需求高、通信开销大和推理成本显著的问题，特别是在医疗图像分割任务中，需要平衡模型性能与资源效率。

Method: 提出双尺度联邦框架，通过生成高质量医疗图像替代真实公共数据集，并采用可学习性引导的样本选择策略，实现中心化基础模型与轻量级客户端模型之间的相互知识蒸馏。

Result: 在五个医疗图像分割数据集上评估，相比现有联邦基础模型基线，平均Dice分数提升2%，同时通信成本和推理时间减少近90%。

Conclusion: DSFedMed在资源受限的联邦部署中实现了显著的效率提升和可扩展性，为医疗图像分割任务提供了高效的双尺度联邦学习解决方案。

Abstract: Foundation Models (FMs) have demonstrated strong generalization across diverse vision tasks. However, their deployment in federated settings is hindered by high computational demands, substantial communication overhead, and significant inference costs. We propose DSFedMed, a dual-scale federated framework that enables mutual knowledge distillation between a centralized foundation model and lightweight client models for medical image segmentation. To support knowledge distillation, a set of high-quality medical images is generated to replace real public datasets, and a learnability-guided sample selection strategy is proposed to enhance efficiency and effectiveness in dual-scale distillation. This mutual distillation enables the foundation model to transfer general knowledge to lightweight clients, while also incorporating client-specific insights to refine the foundation model. Evaluations on five medical imaging segmentation datasets show that DSFedMed achieves an average 2 percent improvement in Dice score while reducing communication costs and inference time by nearly 90 percent compared to existing federated foundation model baselines. These results demonstrate significant efficiency gains and scalability for resource-limited federated deployments.

</details>


### [57] [Masked Modeling for Human Motion Recovery Under Occlusions](https://arxiv.org/abs/2601.16079)
*Zhiyin Qian,Siwei Zhang,Bharat Lal Bhatnagar,Federica Bogo,Siyu Tang*

Main category: cs.CV

TL;DR: MoRo：基于掩码建模的遮挡鲁棒人体运动重建框架，通过多模态先验学习实现实时高效推理


<details>
  <summary>Details</summary>
Motivation: 单目视频中的人体运动重建在AR/VR、机器人等领域有广泛应用，但在现实遮挡场景下仍具挑战。现有方法要么对缺失观测脆弱，要么推理速度慢且预处理复杂，需要一种既能处理遮挡又能高效推理的解决方案。

Method: 提出MoRo框架，将运动重建建模为视频条件任务，采用掩码建模自然处理遮挡。设计跨模态学习方案：1)基于MoCap数据的轨迹感知运动先验；2)基于图像-姿态数据的图像条件姿态先验；3)视频条件掩码变换器融合运动与姿态先验，在视频-运动数据上微调以整合视觉线索与运动动态。

Result: 在EgoBody和RICH数据集上的实验表明，MoRo在遮挡场景下在准确性和运动真实性方面显著优于现有方法，在非遮挡场景下表现相当。在单张H200 GPU上实现70 FPS的实时推理速度。

Conclusion: MoRo通过掩码建模和多模态先验学习，实现了遮挡鲁棒、高效实时的人体运动重建，平衡了准确性与推理效率，为实际应用提供了可行解决方案。

Abstract: Human motion reconstruction from monocular videos is a fundamental challenge in computer vision, with broad applications in AR/VR, robotics, and digital content creation, but remains challenging under frequent occlusions in real-world settings.Existing regression-based methods are efficient but fragile to missing observations, while optimization- and diffusion-based approaches improve robustness at the cost of slow inference speed and heavy preprocessing steps. To address these limitations, we leverage recent advances in generative masked modeling and present MoRo: Masked Modeling for human motion Recovery under Occlusions. MoRo is an occlusion-robust, end-to-end generative framework that formulates motion reconstruction as a video-conditioned task, and efficiently recover human motion in a consistent global coordinate system from RGB videos. By masked modeling, MoRo naturally handles occlusions while enabling efficient, end-to-end inference. To overcome the scarcity of paired video-motion data, we design a cross-modality learning scheme that learns multi-modal priors from a set of heterogeneous datasets: (i) a trajectory-aware motion prior trained on MoCap datasets, (ii) an image-conditioned pose prior trained on image-pose datasets, capturing diverse per-frame poses, and (iii) a video-conditioned masked transformer that fuses motion and pose priors, finetuned on video-motion datasets to integrate visual cues with motion dynamics for robust inference. Extensive experiments on EgoBody and RICH demonstrate that MoRo substantially outperforms state-of-the-art methods in accuracy and motion realism under occlusions, while performing on-par in non-occluded scenarios. MoRo achieves real-time inference at 70 FPS on a single H200 GPU.

</details>


### [58] [SAMTok: Representing Any Mask with Two Words](https://arxiv.org/abs/2601.16093)
*Yikang Zhou,Tao Zhang,Dengxian Gong,Yuanzheng Wu,Ye Tian,Haochen Wang,Haobo Yuan,Jiacong Wang,Lu Qi,Hao Fei,Anran Wang,Zhuochen Wang,Yujing Wang,Cheng Chen,Shunping Ji,Xiangtai Li*

Main category: cs.CV

TL;DR: SAMTok是一种离散掩码标记器，可将区域掩码转换为特殊标记，使多模态大语言模型通过标准的下一个标记预测学习像素级能力，无需架构修改。


<details>
  <summary>Details</summary>
Motivation: 像素级能力对交互式智能系统至关重要，但现有的像素级多模态大语言模型难以扩展，因为需要复杂的区域级编码器、专门的分割解码器和不兼容的训练目标。

Method: 提出SAMTok离散掩码标记器，基于SAM2在2.09亿个多样化掩码上训练，使用掩码编码器和残差向量量化器生成离散、紧凑、信息丰富的标记。将掩码视为新语言标记，使基础MLLM通过标准下一个标记预测和简单强化学习学习像素级能力。

Result: QwenVL-SAMTok在区域描述、区域VQA、接地对话、参考分割、场景图解析和多轮交互分割等任务上达到最先进或可比结果。通过文本答案匹配奖励的强化学习在GRES和GCG基准上带来显著改进。

Conclusion: SAMTok展示了一种可扩展且简单的范式，为MLLM提供强大的像素级能力，无需架构修改和专门损失设计。

Abstract: Pixel-wise capabilities are essential for building interactive intelligent systems. However, pixel-wise multi-modal LLMs (MLLMs) remain difficult to scale due to complex region-level encoders, specialized segmentation decoders, and incompatible training objectives. To address these challenges, we present SAMTok, a discrete mask tokenizer that converts any region mask into two special tokens and reconstructs the mask using these tokens with high fidelity. By treating masks as new language tokens, SAMTok enables base MLLMs (such as the QwenVL series) to learn pixel-wise capabilities through standard next-token prediction and simple reinforcement learning, without architectural modifications and specialized loss design. SAMTok builds on SAM2 and is trained on 209M diverse masks using a mask encoder and residual vector quantizer to produce discrete, compact, and information-rich tokens. With 5M SAMTok-formatted mask understanding and generation data samples, QwenVL-SAMTok attains state-of-the-art or comparable results on region captioning, region VQA, grounded conversation, referring segmentation, scene graph parsing, and multi-round interactive segmentation. We further introduce a textual answer-matching reward that enables efficient reinforcement learning for mask generation, delivering substantial improvements on GRES and GCG benchmarks. Our results demonstrate a scalable and straightforward paradigm for equipping MLLMs with strong pixel-wise capabilities. Our code and models are available.

</details>


### [59] [Clustering-Guided Spatial-Spectral Mamba for Hyperspectral Image Classification](https://arxiv.org/abs/2601.16098)
*Zack Dewis,Yimin Zhu,Zhengsen Xu,Mabel Heffring,Saeid Taleghanidoozdoozan,Quinn Ledingham,Lincoln Linlin Xu*

Main category: cs.CV

TL;DR: 提出CSSMamba框架，通过聚类引导的空间-光谱Mamba架构改进高光谱图像分类，结合聚类机制、注意力驱动标记选择和可学习聚类模块，在多个数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: Mamba模型在高光谱图像分类中面临挑战：需要高效且自适应的标记序列来提升性能。现有方法在定义有效标记序列方面存在不足。

Method: 1. 聚类引导的空间Mamba模块（CSpaMamba）：集成聚类机制减少序列长度并提升特征学习能力
2. 完整空间-光谱Mamba框架：结合CSpaMamba与光谱Mamba模块（SpeMamba）
3. 注意力驱动标记选择机制：优化Mamba标记序列
4. 可学习聚类模块：自适应学习聚类成员关系

Result: 在Pavia University、Indian Pines和Liao-Ning 01数据集上，CSSMamba相比最先进的CNN、Transformer和Mamba方法获得了更高的准确率和更好的边界保持能力。

Conclusion: CSSMamba框架通过聚类引导的空间-光谱Mamba架构有效解决了高光谱图像分类中的标记序列优化问题，显著提升了分类性能。

Abstract: Although Mamba models greatly improve Hyperspectral Image (HSI) classification, they have critical challenges in terms defining efficient and adaptive token sequences for improve performance. This paper therefore presents CSSMamba (Clustering-guided Spatial-Spectral Mamba) framework to better address the challenges, with the following contributions. First, to achieve efficient and adaptive token sequences for improved Mamba performance, we integrate the clustering mechanism into a spatial Mamba architecture, leading to a cluster-guided spatial Mamba module (CSpaMamba) that reduces the Mamba sequence length and improves Mamba feature learning capability. Second, to improve the learning of both spatial and spectral information, we integrate the CSpaMamba module with a spectral mamba module (SpeMamba), leading to a complete clustering-guided spatial-spectral Mamba framework. Third, to further improve feature learning capability, we introduce an Attention-Driven Token Selection mechanism to optimize Mamba token sequencing. Last, to seamlessly integrate clustering into the Mamba model in a coherent manner, we design a Learnable Clustering Module that learns the cluster memberships in an adaptive manner. Experiments on the Pavia University, Indian Pines, and Liao-Ning 01 datasets demonstrate that CSSMamba achieves higher accuracy and better boundary preservation compared to state-of-the-art CNN, Transformer, and Mamba-based methods.

</details>


### [60] [Rethinking Composed Image Retrieval Evaluation: A Fine-Grained Benchmark from Image Editing](https://arxiv.org/abs/2601.16125)
*Tingyu Song,Yanzhao Zhang,Mingxin Li,Zhuoning Guo,Dingkun Long,Pengjun Xie,Siyue Zhang,Yilun Zhao,Shu Wu*

Main category: cs.CV

TL;DR: 作者提出了EDIR，一个细粒度的组合图像检索基准，通过图像编辑合成多样化查询，包含5,000个高质量查询，覆盖5个主类别和15个子类别，评估显示现有模型存在显著能力差距。


<details>
  <summary>Details</summary>
Motivation: 现有组合图像检索基准存在查询类别有限、无法反映真实世界多样需求的问题，需要更全面的评估标准来推动该领域发展。

Method: 利用图像编辑技术精确控制修改类型和内容，构建合成查询的流水线，创建EDIR基准，包含5,000个高质量查询，分为5个主类别和15个子类别，评估了13个多模态嵌入模型。

Result: 评估显示现有模型存在显著能力差距，即使最先进的模型（如RzenEmbed和GME）也无法在所有子类别上表现一致，揭示了现有基准的局限性（如模态偏见和类别覆盖不足）。域内训练实验表明基准的可行性，并区分了可通过针对性数据解决的类别和暴露模型架构固有局限的类别。

Conclusion: EDIR基准填补了组合图像检索评估的空白，揭示了现有模型的局限性，为未来研究提供了更全面的评估标准，并有助于区分可通过数据增强解决的挑战和模型架构固有的限制。

Abstract: Composed Image Retrieval (CIR) is a pivotal and complex task in multimodal understanding. Current CIR benchmarks typically feature limited query categories and fail to capture the diverse requirements of real-world scenarios. To bridge this evaluation gap, we leverage image editing to achieve precise control over modification types and content, enabling a pipeline for synthesizing queries across a broad spectrum of categories. Using this pipeline, we construct EDIR, a novel fine-grained CIR benchmark. EDIR encompasses 5,000 high-quality queries structured across five main categories and fifteen subcategories. Our comprehensive evaluation of 13 multimodal embedding models reveals a significant capability gap; even state-of-the-art models (e.g., RzenEmbed and GME) struggle to perform consistently across all subcategories, highlighting the rigorous nature of our benchmark. Through comparative analysis, we further uncover inherent limitations in existing benchmarks, such as modality biases and insufficient categorical coverage. Furthermore, an in-domain training experiment demonstrates the feasibility of our benchmark. This experiment clarifies the task challenges by distinguishing between categories that are solvable with targeted data and those that expose intrinsic limitations of current model architectures.

</details>


### [61] [Learning to Watermark in the Latent Space of Generative Models](https://arxiv.org/abs/2601.16140)
*Sylvestre-Alvise Rebuffi,Tuan Tran,Valeriu Lacatusu,Pierre Fernandez,Tomáš Souček,Nikola Jovanović,Tom Sander,Hady Elsahar,Alexandre Mourachko*

Main category: cs.CV

TL;DR: DistSeal：一种在潜在空间进行水印的统一方法，适用于扩散和自回归模型，通过训练潜在空间水印模型并蒸馏到生成模型或潜在解码器中，实现高效、鲁棒的图像水印


<details>
  <summary>Details</summary>
Motivation: 现有AI生成图像水印方法通常在像素空间进行后处理，存在计算开销大和可能引入视觉伪影的问题。需要探索更高效的水印方法

Method: 在生成模型的潜在空间中训练后处理水印模型，然后将这些潜在水印器蒸馏到生成模型本身或潜在解码器中，实现模型内水印

Result: 潜在水印在保持竞争性鲁棒性的同时，提供相似的不可感知性，相比像素空间基线速度提升高达20倍。蒸馏潜在水印器优于蒸馏像素空间水印器

Conclusion: DistSeal提供了一种既高效又鲁棒的解决方案，通过潜在空间水印和蒸馏技术，为AI生成图像的水印问题提供了新的有效方法

Abstract: Existing approaches for watermarking AI-generated images often rely on post-hoc methods applied in pixel space, introducing computational overhead and potential visual artifacts. In this work, we explore latent space watermarking and introduce DistSeal, a unified approach for latent watermarking that works across both diffusion and autoregressive models. Our approach works by training post-hoc watermarking models in the latent space of generative models. We demonstrate that these latent watermarkers can be effectively distilled either into the generative model itself or into the latent decoder, enabling in-model watermarking. The resulting latent watermarks achieve competitive robustness while offering similar imperceptibility and up to 20x speedup compared to pixel-space baselines. Our experiments further reveal that distilling latent watermarkers outperforms distilling pixel-space ones, providing a solution that is both more efficient and more robust.

</details>


### [62] [ActionMesh: Animated 3D Mesh Generation with Temporal 3D Diffusion](https://arxiv.org/abs/2601.16148)
*Remy Sabathier,David Novotny,Niloy J. Mitra,Tom Monnier*

Main category: cs.CV

TL;DR: ActionMesh：一种前馈生成模型，可直接生成可直接用于生产的动态3D网格，支持从单目视频、文本描述或3D网格+文本提示等多种输入生成动画3D对象。


<details>
  <summary>Details</summary>
Motivation: 现有3D动画生成方法存在应用限制：要么设置复杂，要么运行时间长，要么质量有限，难以在实际应用中部署。需要一种能快速生成高质量、可直接用于生产的动态3D网格的方法。

Method: 提出"时序3D扩散"框架：1) 修改现有3D扩散模型加入时间轴，生成表示时间变化独立3D形状的同步潜在序列；2) 设计时序3D自编码器，将独立形状序列转换为预定义参考形状的对应变形，从而构建动画。

Result: 在标准视频到4D基准测试（Consistent4D、Objaverse）上取得最先进性能，在几何精度和时间一致性方面表现优异。模型快速生成免绑定、拓扑一致的动画3D网格，支持快速迭代和纹理化、重定向等应用。

Conclusion: ActionMesh以前馈方式生成可直接用于生产的动态3D网格，支持多种输入格式，相比现有方法速度更快、质量更高，为3D动画生成提供了实用且高效的解决方案。

Abstract: Generating animated 3D objects is at the heart of many applications, yet most advanced works are typically difficult to apply in practice because of their limited setup, their long runtime, or their limited quality. We introduce ActionMesh, a generative model that predicts production-ready 3D meshes "in action" in a feed-forward manner. Drawing inspiration from early video models, our key insight is to modify existing 3D diffusion models to include a temporal axis, resulting in a framework we dubbed "temporal 3D diffusion". Specifically, we first adapt the 3D diffusion stage to generate a sequence of synchronized latents representing time-varying and independent 3D shapes. Second, we design a temporal 3D autoencoder that translates a sequence of independent shapes into the corresponding deformations of a pre-defined reference shape, allowing us to build an animation. Combining these two components, ActionMesh generates animated 3D meshes from different inputs like a monocular video, a text description, or even a 3D mesh with a text prompt describing its animation. Besides, compared to previous approaches, our method is fast and produces results that are rig-free and topology consistent, hence enabling rapid iteration and seamless applications like texturing and retargeting. We evaluate our model on standard video-to-4D benchmarks (Consistent4D, Objaverse) and report state-of-the-art performances on both geometric accuracy and temporal consistency, demonstrating that our model can deliver animated 3D meshes with unprecedented speed and quality.

</details>


### [63] [HVD: Human Vision-Driven Video Representation Learning for Text-Video Retrieval](https://arxiv.org/abs/2601.16155)
*Zequn Xie,Xin Liu,Boyun Zhang,Yuxiao Lin,Sihang Cai,Tao Jin*

Main category: cs.CV

TL;DR: 提出HVD模型，通过模仿人类视觉认知的粗到细对齐机制，解决文本-视频检索中因文本查询稀疏导致的"盲"特征交互问题，实现更精准的实体级匹配。


<details>
  <summary>Details</summary>
Motivation: 当前CLIP驱动的文本-视频检索方法存在"盲"特征交互问题，模型难以从背景噪声中区分关键视觉信息，主要原因是文本查询的稀疏性限制了模型对视频内容的理解。

Method: 提出人类视觉驱动的HVD框架，包含两个核心模块：1) 帧特征选择模块(FFSM)模仿人类宏观感知能力，选择关键帧消除时间冗余；2) 补丁特征压缩模块(PFCM)模仿微观感知，通过先进注意力机制将补丁特征聚合为显著视觉实体，实现实体级匹配。

Result: 在五个基准测试上的广泛实验表明，HVD不仅能够捕捉类似人类的视觉焦点，而且实现了最先进的性能表现。

Conclusion: 通过模仿人类认知行为，HVD框架有效解决了文本-视频检索中的特征交互问题，建立了从粗到细的对齐机制，显著提升了检索性能。

Abstract: The success of CLIP has driven substantial progress in text-video retrieval. However, current methods often suffer from "blind" feature interaction, where the model struggles to discern key visual information from background noise due to the sparsity of textual queries. To bridge this gap, we draw inspiration from human cognitive behavior and propose the Human Vision-Driven (HVD) model. Our framework establishes a coarse-to-fine alignment mechanism comprising two key components: the Frame Features Selection Module (FFSM) and the Patch Features Compression Module (PFCM). FFSM mimics the human macro-perception ability by selecting key frames to eliminate temporal redundancy. Subsequently, PFCM simulates micro-perception by aggregating patch features into salient visual entities through an advanced attention mechanism, enabling precise entity-level matching. Extensive experiments on five benchmarks demonstrate that HVD not only captures human-like visual focus but also achieves state-of-the-art performance.

</details>


### [64] [360Anything: Geometry-Free Lifting of Images and Videos to 360°](https://arxiv.org/abs/2601.16192)
*Ziyi Wu,Daniel Watson,Andrea Tagliasacchi,David J. Fleet,Marcus A. Brubaker,Saurabh Saxena*

Main category: cs.CV

TL;DR: 360Anything：无需相机几何信息的图像/视频到360°全景图生成框架，基于预训练扩散Transformer，在数据驱动下实现视角到等距柱状投影的映射，性能优于依赖相机元数据的方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖视角图像与等距柱状投影空间之间的显式几何对齐，需要已知相机元数据，限制了在野外数据（通常缺乏准确相机校准）中的应用。

Method: 基于预训练扩散Transformer的几何无关框架，将视角输入和全景目标视为token序列，以纯数据驱动方式学习视角到等距柱状投影的映射；引入Circular Latent Encoding解决ERP边界接缝问题。

Result: 在图像和视频的视角到360°生成任务上达到最先进性能，优于使用真实相机信息的方法；在零样本相机视场和方向估计基准测试中取得有竞争力的结果。

Conclusion: 360Anything通过数据驱动方法成功消除了对相机元数据的依赖，实现了高质量的360°全景生成，并展示了在计算机视觉任务中的广泛实用性。

Abstract: Lifting perspective images and videos to 360° panoramas enables immersive 3D world generation. Existing approaches often rely on explicit geometric alignment between the perspective and the equirectangular projection (ERP) space. Yet, this requires known camera metadata, obscuring the application to in-the-wild data where such calibration is typically absent or noisy. We propose 360Anything, a geometry-free framework built upon pre-trained diffusion transformers. By treating the perspective input and the panorama target simply as token sequences, 360Anything learns the perspective-to-equirectangular mapping in a purely data-driven way, eliminating the need for camera information. Our approach achieves state-of-the-art performance on both image and video perspective-to-360° generation, outperforming prior works that use ground-truth camera information. We also trace the root cause of the seam artifacts at ERP boundaries to zero-padding in the VAE encoder, and introduce Circular Latent Encoding to facilitate seamless generation. Finally, we show competitive results in zero-shot camera FoV and orientation estimation benchmarks, demonstrating 360Anything's deep geometric understanding and broader utility in computer vision tasks. Additional results are available at https://360anything.github.io/.

</details>


### [65] [Scaling Text-to-Image Diffusion Transformers with Representation Autoencoders](https://arxiv.org/abs/2601.16208)
*Shengbang Tong,Boyang Zheng,Ziteng Wang,Bingda Tang,Nanye Ma,Ellis Brown,Jihan Yang,Rob Fergus,Yann LeCun,Saining Xie*

Main category: cs.CV

TL;DR: RAEs在ImageNet扩散建模中表现出优势，本研究验证其在大型自由文本到图像生成中的可扩展性。研究发现缩放简化了RAE框架，RAE在所有模型规模上都优于VAE，且训练更稳定、收敛更快、生成质量更好。


<details>
  <summary>Details</summary>
Motivation: 研究RAE框架能否扩展到大规模自由文本到图像生成任务，验证其在更大规模数据上的表现，并与当前最先进的FLUX VAE进行对比。

Method: 1. 在冻结的SigLIP-2表示编码器上扩展RAE解码器，使用网络数据、合成数据和文本渲染数据训练；2. 系统测试RAE在ImageNet上提出的设计选择；3. 在0.5B到9.8B参数规模的扩散变换器上，对RAE和FLUX VAE进行受控比较。

Result: 1. 缩放简化了RAE框架：维度相关噪声调度仍然关键，但架构复杂性（如宽扩散头和噪声增强解码）在大规模下收益可忽略；2. RAE在所有模型规模上都优于VAE预训练；3. 高质量数据集微调时，VAE模型在64轮后灾难性过拟合，而RAE模型在256轮后仍保持稳定且性能更好；4. RAE扩散模型收敛更快、生成质量更好。

Conclusion: RAE是比VAE更简单、更强大的大规模文本到图像生成基础框架，视觉理解和生成可在共享表示空间中操作，为统一模型开辟了新可能性。

Abstract: Representation Autoencoders (RAEs) have shown distinct advantages in diffusion modeling on ImageNet by training in high-dimensional semantic latent spaces. In this work, we investigate whether this framework can scale to large-scale, freeform text-to-image (T2I) generation. We first scale RAE decoders on the frozen representation encoder (SigLIP-2) beyond ImageNet by training on web, synthetic, and text-rendering data, finding that while scale improves general fidelity, targeted data composition is essential for specific domains like text. We then rigorously stress-test the RAE design choices originally proposed for ImageNet. Our analysis reveals that scaling simplifies the framework: while dimension-dependent noise scheduling remains critical, architectural complexities such as wide diffusion heads and noise-augmented decoding offer negligible benefits at scale Building on this simplified framework, we conduct a controlled comparison of RAE against the state-of-the-art FLUX VAE across diffusion transformer scales from 0.5B to 9.8B parameters. RAEs consistently outperform VAEs during pretraining across all model scales. Further, during finetuning on high-quality datasets, VAE-based models catastrophically overfit after 64 epochs, while RAE models remain stable through 256 epochs and achieve consistently better performance. Across all experiments, RAE-based diffusion models demonstrate faster convergence and better generation quality, establishing RAEs as a simpler and stronger foundation than VAEs for large-scale T2I generation. Additionally, because both visual understanding and generation can operate in a shared representation space, the multimodal model can directly reason over generated latents, opening new possibilities for unified models.

</details>


### [66] [PyraTok: Language-Aligned Pyramidal Tokenizer for Video Understanding and Generation](https://arxiv.org/abs/2601.16210)
*Onkar Susladkar,Tushar Prakash,Adheesh Juvekar,Kiet A. Nguyen,Dong-Hwan Jang,Inderjit S Dhillon,Ismini Lourentzou*

Main category: cs.CV

TL;DR: PyraTok是一种语言对齐的金字塔视频分词器，通过多尺度离散化和共享大二进制码本学习结构化视觉token，显著提升视频生成和理解性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频VAE分词器通常使用单一尺度的有限词汇表，语言监督不足，导致跨模态对齐差和零样本迁移能力弱。

Method: 基于预训练视频VAE，引入语言对齐金字塔量化模块，在多时空分辨率上离散化编码器特征，使用共享大二进制码本，联合优化多尺度文本引导量化和token层次结构的自回归目标。

Result: 在10个基准测试中实现SOTA视频重建，持续改进文本到视频质量，在视频分割、时序动作定位和视频理解任务上创造新的SOTA零样本性能，可扩展到4K/8K分辨率。

Conclusion: PyraTok通过语言对齐的金字塔token化方法，显著提升了视频离散表示的语义结构和跨模态对齐能力，为视频生成和理解系统提供了更强大的基础。

Abstract: Discrete video VAEs underpin modern text-to-video generation and video understanding systems, yet existing tokenizers typically learn visual codebooks at a single scale with limited vocabularies and shallow language supervision, leading to poor cross-modal alignment and zero-shot transfer. We introduce PyraTok, a language-aligned pyramidal tokenizer that learns semantically structured discrete latents across multiple spatiotemporal resolutions. PyraTok builds on a pretrained video VAE and a novel Language aligned Pyramidal Quantization (LaPQ) module that discretizes encoder features at several depths using a shared large binary codebook, yielding compact yet expressive video token sequences. To tightly couple visual tokens with language, PyraTok jointly optimizes multi-scale text-guided quantization and a global autoregressive objective over the token hierarchy. Across ten benchmarks, PyraTok delivers state-of-the-art (SOTA) video reconstruction, consistently improves text-to-video quality, and sets new SOTA zero-shot performance on video segmentation, temporal action localization, and video understanding, scaling robustly to up to 4K/8K resolutions.

</details>


### [67] [Why Can't I Open My Drawer? Mitigating Object-Driven Shortcuts in Zero-Shot Compositional Action Recognition](https://arxiv.org/abs/2601.16211)
*Geo Ahn,Inwoong Lee,Taeoh Kim,Minho Shim,Dongyoon Wee,Jinwoo Choi*

Main category: cs.CV

TL;DR: 论文发现现有零样本组合动作识别模型因物体驱动的动词捷径而失败，提出了RCORE框架通过组合感知增强和时间顺序正则化来解决这一问题，显著提升了未见组合的识别准确率。


<details>
  <summary>Details</summary>
Motivation: 现有零样本组合动作识别模型在未见动词-物体组合上表现不佳，研究发现主要原因是物体驱动的动词捷径问题，即模型过度依赖共现统计而忽略视觉证据，导致无法实现真正的组合泛化。

Method: 提出RCORE框架：1）组合感知增强，在不破坏运动线索的情况下多样化动词-物体组合；2）时间顺序正则化损失，通过显式建模时间结构来惩罚捷径行为。

Result: 在两个基准测试（Sth-com和新构建的EK100-com）上，RCORE显著提高了未见组合的准确率，减少了对共现偏见的依赖，并实现了持续正面的组合差距。

Conclusion: 物体驱动的捷径是零样本组合动作识别的关键限制因素，解决这一问题对于实现鲁棒的组合视频理解至关重要。RCORE通过强制时间基础动词学习有效解决了该问题。

Abstract: We study Compositional Video Understanding (CVU), where models must recognize verbs and objects and compose them to generalize to unseen combinations. We find that existing Zero-Shot Compositional Action Recognition (ZS-CAR) models fail primarily due to an overlooked failure mode: object-driven verb shortcuts. Through systematic analysis, we show that this behavior arises from two intertwined factors: severe sparsity and skewness of compositional supervision, and the asymmetric learning difficulty between verbs and objects. As training progresses, the existing ZS-CAR model increasingly ignores visual evidence and overfits to co-occurrence statistics. Consequently, the existing model does not gain the benefit of compositional recognition in unseen verb-object compositions. To address this, we propose RCORE, a simple and effective framework that enforces temporally grounded verb learning. RCORE introduces (i) a composition-aware augmentation that diversifies verb-object combinations without corrupting motion cues, and (ii) a temporal order regularization loss that penalizes shortcut behaviors by explicitly modeling temporal structure. Across two benchmarks, Sth-com and our newly constructed EK100-com, RCORE significantly improves unseen composition accuracy, reduces reliance on co-occurrence bias, and achieves consistently positive compositional gaps. Our findings reveal object-driven shortcuts as a critical limiting factor in ZS-CAR and demonstrate that addressing them is essential for robust compositional video understanding.

</details>


### [68] [CamPilot: Improving Camera Control in Video Diffusion Model with Efficient Camera Reward Feedback](https://arxiv.org/abs/2601.16214)
*Wenhang Ge,Guibao Shen,Jiawei Feng,Luozhou Wang,Hao Lu,Xingye Tian,Xin Tao,Ying-Cong Chen*

Main category: cs.CV

TL;DR: 提出CamPilot方法，通过3D高斯解码器和可见性感知奖励量化，提升视频扩散模型的相机控制能力


<details>
  <summary>Details</summary>
Motivation: 现有相机控制视频扩散模型在视频-相机对齐方面仍有局限，直接应用ReFL方法面临三个挑战：缺乏评估视频-相机对齐的奖励模型、RGB解码计算开销大、3D几何信息被忽略

Method: 提出高效相机感知3D解码器，将视频潜在表示和相机姿态解码为3D高斯表示，利用相机姿态作为投影参数，通过几何扭曲检测不对齐；引入可见性项选择性地监督确定性区域

Result: 在RealEstate10K和WorldScore基准测试中验证了方法的有效性

Conclusion: 通过3D几何解码和可见性感知奖励量化，显著提升了视频扩散模型的相机控制能力

Abstract: Recent advances in camera-controlled video diffusion models have significantly improved video-camera alignment. However, the camera controllability still remains limited. In this work, we build upon Reward Feedback Learning and aim to further improve camera controllability. However, directly borrowing existing ReFL approaches faces several challenges. First, current reward models lack the capacity to assess video-camera alignment. Second, decoding latent into RGB videos for reward computation introduces substantial computational overhead. Third, 3D geometric information is typically neglected during video decoding. To address these limitations, we introduce an efficient camera-aware 3D decoder that decodes video latent into 3D representations for reward quantization. Specifically, video latent along with the camera pose are decoded into 3D Gaussians. In this process, the camera pose not only acts as input, but also serves as a projection parameter. Misalignment between the video latent and camera pose will cause geometric distortions in the 3D structure, resulting in blurry renderings. Based on this property, we explicitly optimize pixel-level consistency between the rendered novel views and ground-truth ones as reward. To accommodate the stochastic nature, we further introduce a visibility term that selectively supervises only deterministic regions derived via geometric warping. Extensive experiments conducted on RealEstate10K and WorldScore benchmarks demonstrate the effectiveness of our proposed method. Project page: \href{https://a-bigbao.github.io/CamPilot/}{CamPilot Page}.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [69] [Entropy-Tree: Tree-Based Decoding with Entropy-Guided Exploration](https://arxiv.org/abs/2601.15296)
*Longxuan Wei,Yubo Zhang,Zijiao Zhang,Zhihu Wang,Shiwan Zhao,Tianyu Huang,Huiting Zhao,Chenfei Liu,Shenao Zhang,Junchi Yan*

Main category: cs.CL

TL;DR: Entropy-Tree是一种基于树的解码方法，利用熵作为分支决策信号，在模型真正不确定的位置扩展搜索树，在推理任务中实现更优的准确性和校准


<details>
  <summary>Details</summary>
Motivation: 现有解码策略要么盲目探索（随机采样），要么冗余探索（独立多重采样），缺乏对模型不确定性的有效利用，需要一种更智能的搜索方法

Method: 提出Entropy-Tree方法，通过熵信号指导树的分支决策，只在模型真正不确定的位置扩展搜索树，统一了高效结构化探索和可靠不确定性估计

Result: 在多个模型和数据集上，Entropy-Tree的pass@k优于Multi-chain，其预测熵的AUROC优于多个传统指标，表现出更好的准确性和校准

Conclusion: Entropy-Tree将高效结构化探索和可靠不确定性估计统一在单一解码过程中，为语言模型推理提供了更优的解码策略

Abstract: Large language models achieve strong reasoning performance, yet existing decoding strategies either explore blindly (random sampling) or redundantly (independent multi-sampling). We propose Entropy-Tree, a tree-based decoding method that exploits entropy as a signal for branching decisions--expanding the search tree only at positions where the model exhibits genuine uncertainty. Entropy-Tree shows superior accuracy and calibration in reasoning tasks: it achieves better pass@k than Multi-chain across multiple models and datasets, and its predictive entropy demonstrates better AUROC compared to several traditional metrics. Entropy-Tree unifies efficient structured exploration and reliable uncertainty estimation within a single decoding procedure.

</details>


### [70] [AfriEconQA: A Benchmark Dataset for African Economic Analysis based on World Bank Reports](https://arxiv.org/abs/2601.15297)
*Edward Ajayi*

Main category: cs.CL

TL;DR: AfriEconQA：首个专注于非洲经济分析的基准数据集，包含8,937个高质量QA实例，基于236份世界银行报告，用于评估信息检索和RAG系统在专业经济分析中的表现。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在非洲经济分析方面存在严重知识缺口，因为相关数据很少出现在预训练语料中。需要专门的基准来评估信息检索系统在专业经济文档中的表现。

Method: 从236份世界银行报告中构建包含8,937个QA实例的数据集，每个实例包含问题、证据、验证答案和源元数据。通过11个实验矩阵评估零样本基线（GPT-5 Mini）与使用GPT-4o和Qwen 32B的RAG配置。

Result: 零样本模型无法回答超过90%的查询，即使最先进的RAG管道也难以实现高精度。这证实了模型在非洲经济分析方面存在严重的参数知识差距。

Conclusion: AfriEconQA是一个稳健且具有挑战性的基准，为下一代领域特定的信息检索和RAG系统提供了重要的评估工具，填补了非洲经济分析基准的空白。

Abstract: We introduce AfriEconQA, a specialized benchmark dataset for African economic analysis grounded in a comprehensive corpus of 236 World Bank reports. The task of AfriEconQA is to answer complex economic queries that require high-precision numerical reasoning and temporal disambiguation from specialized institutional documents. The dataset consists of 8,937 curated QA instances, rigorously filtered from a pool of 10018 synthetic questions to ensure high-quality evidence-answer alignment. Each instance is composed of: (1) a question requiring reasoning over economic indicators, (2) the corresponding evidence retrieved from the corpus, (3) a verified ground-truth answer, and (4) source metadata (e.g., URL and publication date) to ensure temporal provenance. AfriEconQA is the first benchmark focused specifically on African economic analysis, providing a unique challenge for Information Retrieval (IR) systems, as the data is largely absent from the pretraining corpora of current Large Language Models (LLMs). We operationalize this dataset through an 11-experiment matrix, benchmarking a zero-shot baseline (GPT-5 Mini) against RAG configurations using GPT-4o and Qwen 32B across five distinct embedding and ranking strategies. Our results demonstrate a severe parametric knowledge gap, where zero-shot models fail to answer over 90 percent of queries, and even state-of-the-art RAG pipelines struggle to achieve high precision. This confirms AfriEconQA as a robust and challenging benchmark for the next generation of domain-specific IR and RAG systems. The AfriEconQA dataset and code will be made publicly available upon publication.

</details>


### [71] [Embedding Retrofitting: Data Engineering for better RAG](https://arxiv.org/abs/2601.15298)
*Anantha Sharma*

Main category: cs.CL

TL;DR: 嵌入改造通过知识图谱约束调整预训练词向量以提升领域检索效果，但其效果严重依赖知识图谱质量，而图谱质量又受文本预处理影响。本文提出数据工程框架解决真实语料中标注伪影导致的数据质量下降问题。


<details>
  <summary>Details</summary>
Motivation: 现有嵌入改造方法的效果严重依赖知识图谱质量，而真实语料中的标注伪影（如标签标注）会污染知识图谱，导致改造目标被破坏，影响检索性能。

Method: 提出数据工程框架，分析标签标注如何膨胀知识图谱密度并创建虚假边，通过预处理技术清理噪声图谱，然后应用EWMA（指数加权移动平均）改造技术。

Result: 在噪声图谱上，所有改造技术都出现显著性能下降（-3.5%到-5.2%，p<0.05）。经过预处理后，EWMA改造实现+6.2%改进（p=0.0348），在定量综合问题上平均提升+33.8%。预处理质量的影响（10%+波动）远大于算法差异（3%）。

Conclusion: 预处理质量是嵌入改造成功的主要决定因素，而非算法选择。数据工程框架能有效解决真实语料中的标注伪影问题，显著提升改造效果。

Abstract: Embedding retrofitting adjusts pre-trained word vectors using knowledge graph constraints to improve domain-specific retrieval. However, the effectiveness of retrofitting depends critically on knowledge graph quality, which in turn depends on text preprocessing. This paper presents a data engineering framework that addresses data quality degradation from annotation artifacts in real-world corpora.
  The analysis shows that hashtag annotations inflate knowledge graph density, leading to creating spurious edges that corrupt the retrofitting objective. On noisy graphs, all retrofitting techniques produce statistically significant degradation ($-3.5\%$ to $-5.2\%$, $p<0.05$). After preprocessing, \acrshort{ewma} retrofitting achieves $+6.2\%$ improvement ($p=0.0348$) with benefits concentrated in quantitative synthesis questions ($+33.8\%$ average). The gap between clean and noisy preprocessing (10\%+ swing) exceeds the gap between algorithms (3\%), establishing preprocessing quality as the primary determinant of retrofitting success.

</details>


### [72] [MALTopic: Multi-Agent LLM Topic Modeling Framework](https://arxiv.org/abs/2601.15299)
*Yash Sharma*

Main category: cs.CL

TL;DR: MALTopic是一个多智能体LLM主题建模框架，通过分解任务并利用结构化数据来提升调查数据分析的主题一致性、多样性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统主题建模方法通常只考虑自由文本响应，无法原生整合结构化或分类调查响应，且产生的主题抽象，需要大量人工解释。这些局限性促使研究者开发能够更好处理复杂调查数据的解决方案。

Method: 提出多智能体LLM主题建模框架(MALTopic)，将主题建模分解为三个专门任务：1) 丰富智能体利用结构化数据增强文本响应；2) 主题建模智能体提取潜在主题；3) 去重智能体精炼结果。每个任务由独立的LLM智能体执行。

Result: 在调查数据集上的比较分析表明，与LDA和BERTopic相比，MALTopic显著提高了主题一致性、多样性和可解释性。通过整合结构化数据，该框架生成了具有增强上下文相关性的人类可读主题。

Conclusion: MALTopic通过整合结构化数据和采用多智能体方法，为分析复杂调查数据提供了更有效的解决方案，能够生成人类可读且具有增强上下文相关性的主题。

Abstract: Topic modeling is a crucial technique for extracting latent themes from unstructured text data, particularly valuable in analyzing survey responses. However, traditional methods often only consider free-text responses and do not natively incorporate structured or categorical survey responses for topic modeling. And they produce abstract topics, requiring extensive human interpretation. To address these limitations, we propose the Multi-Agent LLM Topic Modeling Framework (MALTopic). This framework decomposes topic modeling into specialized tasks executed by individual LLM agents: an enrichment agent leverages structured data to enhance textual responses, a topic modeling agent extracts latent themes, and a deduplication agent refines the results. Comparative analysis on a survey dataset demonstrates that MALTopic significantly improves topic coherence, diversity, and interpretability compared to LDA and BERTopic. By integrating structured data and employing a multi-agent approach, MALTopic generates human-readable topics with enhanced contextual relevance, offering a more effective solution for analyzing complex survey data.

</details>


### [73] [Intelligence Degradation in Long-Context LLMs: Critical Threshold Determination via Natural Length Distribution Analysis](https://arxiv.org/abs/2601.15300)
*Weiwei Wang,Jiyong Min,Weijie Zou*

Main category: cs.CL

TL;DR: 大语言模型在处理接近特定临界阈值的上下文时会出现灾难性性能下降，即使信息仍然相关。本文首次系统性地描述了开源Qwen模型中的智能退化现象，为长上下文场景部署提供实用指导。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在处理长上下文时会出现智能退化现象（性能下降超过30%），这严重限制了长上下文应用。现有研究缺乏对这一现象的系统性分析，特别是对开源模型如Qwen的实证研究。

Method: 1. 自然长度分布分析：使用样本的自然token长度，避免截断或填充，提供更强的因果证据；2. 临界阈值确定：在混合数据集（1000个样本覆盖5%-95%上下文长度）上进行实验，使用五折交叉验证；3. 统一框架：整合浅层适应理论来解释退化模式。

Result: 发现Qwen2.5-7B模型在达到最大上下文长度的40-50%时出现临界阈值，F1分数从0.55-0.56下降到0.3（45.5%退化）。模型在临界阈值前保持良好性能，之后灾难性崩溃，呈现浅层长上下文适应模式。

Conclusion: 本文首次系统性地描述了开源Qwen模型中的智能退化现象，提出了浅层适应理论框架来解释退化模式，为长上下文场景中LLM的部署提供了实用指导，并为缓解策略奠定了基础。

Abstract: Large Language Models (LLMs) exhibit catastrophic performance degradation when processing contexts approaching certain critical thresholds, even when information remains relevant. This intelligence degradation-defined as over 30% drop in task performance-severely limits long-context applications. This degradation shows a common pattern: models maintain strong performance up to a critical threshold, then collapse catastrophically. We term this shallow long-context adaptation-models adapt for short to medium contexts but fail beyond critical thresholds. This paper presents three contributions: (1) Natural Length Distribution Analysis: We use each sample's natural token length without truncation or padding, providing stronger causal evidence that degradation results from context length itself. (2) Critical Threshold Determination: Through experiments on a mixed dataset (1,000 samples covering 5%-95% of context length), we identify the critical threshold for Qwen2.5-7B at 40-50% of maximum context length, where F1 scores drop from 0.55-0.56 to 0.3 (45.5% degradation), using five-method cross-validation. (3) Unified Framework: We consolidate shallow adaptation, explaining degradation patterns and providing a foundation for mitigation strategies. This work provides the first systematic characterization of intelligence degradation in open-source Qwen models, offering practical guidance for deploying LLMs in long-context scenarios.

</details>


### [74] [Can We Trust LLM Detectors?](https://arxiv.org/abs/2601.15301)
*Jivnesh Sandhan,Harshit Jaiswal,Fei Cheng,Yugo Murawaki*

Main category: cs.CL

TL;DR: 该论文系统评估了AI文本检测器的两种主流范式（无训练和监督式），发现它们在分布偏移、未见生成器和简单风格扰动下都很脆弱，并提出了监督对比学习框架来学习判别性风格嵌入。


<details>
  <summary>Details</summary>
Motivation: 随着LLM的快速普及，对可靠AI文本检测的需求日益增长，但现有检测器在受控基准测试之外往往失效，需要系统评估其鲁棒性并改进检测方法。

Method: 系统评估两种主流检测范式（无训练和监督式），并提出监督对比学习（SCL）框架来学习判别性风格嵌入，以解决现有方法的局限性。

Result: 实验表明监督检测器在域内表现优秀但在域外急剧退化，无训练方法对代理选择高度敏感，监督对比学习框架能有效学习风格嵌入但整体仍面临领域无关检测的根本挑战。

Conclusion: 现有AI文本检测器在分布偏移、未见生成器和风格扰动下都很脆弱，构建领域无关检测器面临根本性挑战，需要更鲁棒的检测方法。

Abstract: The rapid adoption of LLMs has increased the need for reliable AI text detection, yet existing detectors often fail outside controlled benchmarks. We systematically evaluate 2 dominant paradigms (training-free and supervised) and show that both are brittle under distribution shift, unseen generators, and simple stylistic perturbations. To address these limitations, we propose a supervised contrastive learning (SCL) framework that learns discriminative style embeddings. Experiments show that while supervised detectors excel in-domain, they degrade sharply out-of-domain, and training-free methods remain highly sensitive to proxy choice. Overall, our results expose fundamental challenges in building domain-agnostic detectors. Our code is available at: https://github.com/HARSHITJAIS14/DetectAI

</details>


### [75] [ICPO: Illocution-Calibrated Policy Optimization for Multi-Turn Conversation](https://arxiv.org/abs/2601.15330)
*Zhebo Wang,Xiaohu Mu,Zijie Zhou,Mohan Li,Wenpeng Xing,Dezhang Kong,Meng Han*

Main category: cs.CL

TL;DR: 提出ICPO训练框架，解决LLM在多轮对话中因早期错误假设导致的"迷失对话"问题，通过奖励模型在模糊指令时表达不确定性或寻求澄清，提升对话鲁棒性。


<details>
  <summary>Details</summary>
Motivation: LLM在多轮对话中容易出现"迷失对话"现象，即难以从早期错误假设中恢复，特别是在用户提供模糊初始指令时。标准的后训练技术如RLVR会加剧这个问题，因为它奖励自信的直接回答，导致模型过度自信且不愿寻求澄清。

Method: 提出Illocution-Calibrated Policy Optimization (ICPO)训练框架：1) 在训练语料中增加未明确指定的提示；2) 根据用户的言外意图调整奖励信号，当面对模糊性时奖励模型表达不确定性或寻求澄清。

Result: 实验表明ICPO能够培养适当的谦逊，在多轮对话中实现平均75%的显著改进，同时在单轮基准测试中保持稳健性能。

Conclusion: ICPO为构建更鲁棒、更具协作性的对话AI提供了实用路径，使其能更好地处理人类交互的细微差别。

Abstract: Large Language Models (LLMs) in multi-turn conversations often suffer from a ``lost-in-conversation'' phenomenon, where they struggle to recover from early incorrect assumptions, particularly when users provide ambiguous initial instructions. We find that standard post-training techniques like Reinforcement Learning with Verifiable Rewards (RLVR) exacerbate this issue by rewarding confident, direct answers, thereby inducing overconfidence and discouraging the model from seeking clarification. To address this, we propose Illocution-Calibrated Policy Optimization (ICPO), a novel training framework that sensitizes the model to instruction ambiguity. ICPO augments the training corpus with underspecified prompts and conditions the reward signal on the user's illocutionary intent, rewarding the model for expressing uncertainty or asking for clarification when faced with ambiguity. Experiments demonstrate that ICPO fosters appropriate humility, yielding a substantial average improvement of 75\% in multi-turn conversation, while preserving robust performance on single-turn benchmarks. Our work presents a practical path toward more robust and collaborative conversational AI that can better navigate the nuances of human interaction.

</details>


### [76] [RECAP: A Resource-Efficient Method for Adversarial Prompting in Large Language Models](https://arxiv.org/abs/2601.15331)
*Rishit Chugh*

Main category: cs.CL

TL;DR: 提出一种资源高效的对抗提示方法，通过匹配新提示到预训练对抗提示数据库，无需重新训练，显著降低计算成本


<details>
  <summary>Details</summary>
Motivation: 大型语言模型容易受到对抗提示攻击，产生有害输出。现有自动化越狱方法（如GCG、PEZ、GBDA）计算成本高，限制了资源受限组织的实用性

Method: 将1000个提示分类为7个危害类别，评估GCG、PEZ、GBDA在Llama 3 8B模型上的效果，通过检索语义相似的已成功对抗提示来攻击新提示

Result: 发现提示类型与算法效果存在相关性，提出的方法在显著降低计算成本的同时，实现了有竞争力的攻击成功率

Conclusion: 为对齐LLM的可扩展红队测试和安全评估提供了实用框架，包括无法访问模型内部的情况

Abstract: The deployment of large language models (LLMs) has raised security concerns due to their susceptibility to producing harmful or policy-violating outputs when exposed to adversarial prompts. While alignment and guardrails mitigate common misuse, they remain vulnerable to automated jailbreaking methods such as GCG, PEZ, and GBDA, which generate adversarial suffixes via training and gradient-based search. Although effective, these methods particularly GCG are computationally expensive, limiting their practicality for organisations with constrained resources. This paper introduces a resource-efficient adversarial prompting approach that eliminates the need for retraining by matching new prompts to a database of pre-trained adversarial prompts. A dataset of 1,000 prompts was classified into seven harm-related categories, and GCG, PEZ, and GBDA were evaluated on a Llama 3 8B model to identify the most effective attack method per category. Results reveal a correlation between prompt type and algorithm effectiveness. By retrieving semantically similar successful adversarial prompts, the proposed method achieves competitive attack success rates with significantly reduced computational cost. This work provides a practical framework for scalable red-teaming and security evaluation of aligned LLMs, including in settings where model internals are inaccessible.

</details>


### [77] [No Reliable Evidence of Self-Reported Sentience in Small Large Language Models](https://arxiv.org/abs/2601.15334)
*Caspar Kaiser,Sean Enderby*

Main category: cs.CL

TL;DR: 语言模型否认自己有意识，分类器检测显示这些否认是真实的，且模型越大否认越自信


<details>
  <summary>Details</summary>
Motivation: 测试语言模型是否认为自己有意识，而不是直接测试它们是否真的有意识，这具有可操作性

Method: 使用三种模型家族（Qwen、Llama、GPT-OSS），询问约50个关于意识和主观体验的问题，并用可解释性文献中的三种分类方法验证回答

Result: 1. 模型一致否认自己有意识，认为人类有意识但自己没有；2. 检测底层信念而非表面输出的分类器显示这些否认是真实的；3. Qwen家族中，模型越大否认意识越自信

Conclusion: 研究结果与最近认为模型潜在地相信自己有意识的工作形成对比，表明模型实际上否认自己的意识

Abstract: Whether language models possess sentience has no empirical answer. But whether they believe themselves to be sentient can, in principle, be tested. We do so by querying several open-weights models about their own consciousness, and then verifying their responses using classifiers trained on internal activations. We draw upon three model families (Qwen, Llama, GPT-OSS) ranging from 0.6 billion to 70 billion parameters, approximately 50 questions about consciousness and subjective experience, and three classification methods from the interpretability literature. First, we find that models consistently deny being sentient: they attribute consciousness to humans but not to themselves. Second, classifiers trained to detect underlying beliefs - rather than mere outputs - provide no clear evidence that these denials are untruthful. Third, within the Qwen family, larger models deny sentience more confidently than smaller ones. These findings contrast with recent work suggesting that models harbour latent beliefs in their own consciousness.

</details>


### [78] [From Quotes to Concepts: Axial Coding of Political Debates with Ensemble LMs](https://arxiv.org/abs/2601.15338)
*Angelina Parfenova,David Graus,Juergen Pfeffer*

Main category: cs.CL

TL;DR: 本文提出了一种使用大语言模型（LLMs）进行轴向编码的方法，将辩论记录转化为层次化表示，比较了聚类和直接LLM分组两种策略。


<details>
  <summary>Details</summary>
Motivation: 轴向编码是一种常用的定性分析方法，但传统方法耗时耗力。本文旨在利用大语言模型自动化这一过程，将原始辩论记录转化为简洁的层次化表示，提高分析效率。

Method: 扩展了基于集成的开放编码方法，增加了轴向编码步骤。比较两种策略：1）使用密度基和分区算法对代码-话语对进行聚类，然后用LLM标记；2）直接使用LLM将代码和话语分组到类别中。应用于荷兰议会辩论记录。

Result: 密度基聚类实现了高覆盖率和强聚类对齐，而直接LLM分组获得了更高的细粒度对齐但覆盖率降低20%。聚类最大化覆盖率和结构分离，LLM分组产生更简洁、可解释且语义对齐的类别。

Conclusion: 两种方法各有优劣：聚类方法适合需要高覆盖率和结构分离的场景，而LLM分组更适合需要简洁、可解释且语义对齐类别的应用。公开了完整数据集支持未来研究。

Abstract: Axial coding is a commonly used qualitative analysis method that enhances document understanding by organizing sentence-level open codes into broader categories. In this paper, we operationalize axial coding with large language models (LLMs). Extending an ensemble-based open coding approach with an LLM moderator, we add an axial coding step that groups open codes into higher-order categories, transforming raw debate transcripts into concise, hierarchical representations. We compare two strategies: (i) clustering embeddings of code-utterance pairs using density-based and partitioning algorithms followed by LLM labeling, and (ii) direct LLM-based grouping of codes and utterances into categories. We apply our method to Dutch parliamentary debates, converting lengthy transcripts into compact, hierarchically structured codes and categories. We evaluate our method using extrinsic metrics aligned with human-assigned topic labels (ROUGE-L, cosine, BERTScore), and intrinsic metrics describing code groups (coverage, brevity, coherence, novelty, JSD divergence). Our results reveal a trade-off: density-based clustering achieves high coverage and strong cluster alignment, while direct LLM grouping results in higher fine-grained alignment, but lower coverage 20%. Overall, clustering maximizes coverage and structural separation, whereas LLM grouping produces more concise, interpretable, and semantically aligned categories. To support future research, we publicly release the full dataset of utterances and codes, enabling reproducibility and comparative studies.

</details>


### [79] [Memorization Dynamics in Knowledge Distillation for Language Models](https://arxiv.org/abs/2601.15394)
*Jaydeep Borkar,Karan Chadha,Niloofar Mireshghallah,Yuchen Zhang,Irina-Elena Veliche,Archi Mitra,David A. Smith,Zheng Xu,Diego Garcia-Olano*

Main category: cs.CL

TL;DR: 知识蒸馏能显著减少小模型对训练数据的记忆（降低50%以上），同时保持性能优势，但硬蒸馏比软蒸馏更易继承教师模型的特定示例。


<details>
  <summary>Details</summary>
Motivation: 研究知识蒸馏（KD）中训练数据记忆的动态，了解KD作为隐私保护机制的效果，以及相比标准微调在数据泄露风险方面的差异。

Method: 使用三个LLM家族（Pythia、OLMo-2、Qwen-3）和三个数据集（FineWeb、Wikitext、Nemotron-CC-v2），分析知识蒸馏流程中的记忆现象，比较软蒸馏和硬蒸馏。

Result: 1. 蒸馏模型比标准微调记忆显著减少（>50%）；2. 某些示例天生易被记忆，占蒸馏记忆的95%以上；3. 学生模型记忆可通过zlib熵、KL散度和困惑度特征预测；4. 硬蒸馏继承教师特定示例的风险是软蒸馏的2.7倍。

Conclusion: 知识蒸馏既能提供更好的泛化能力，又能降低记忆风险，但硬蒸馏比软蒸馏有更高的隐私风险，需要谨慎选择蒸馏策略。

Abstract: Knowledge Distillation (KD) is increasingly adopted to transfer capabilities from large language models to smaller ones, offering significant improvements in efficiency and utility while often surpassing standard fine-tuning. Beyond performance, KD is also explored as a privacy-preserving mechanism to mitigate the risk of training data leakage. While training data memorization has been extensively studied in standard pre-training and fine-tuning settings, its dynamics in a knowledge distillation setup remain poorly understood. In this work, we study memorization across the KD pipeline using three large language model (LLM) families (Pythia, OLMo-2, Qwen-3) and three datasets (FineWeb, Wikitext, Nemotron-CC-v2). We find: (1) distilled models memorize significantly less training data than standard fine-tuning (reducing memorization by more than 50%); (2) some examples are inherently easier to memorize and account for a large fraction of memorization during distillation (over ~95%); (3) student memorization is predictable prior to distillation using features based on zlib entropy, KL divergence, and perplexity; and (4) while soft and hard distillation have similar overall memorization rates, hard distillation poses a greater risk: it inherits $2.7\times$ more teacher-specific examples than soft distillation. Overall, we demonstrate that distillation can provide both improved generalization and reduced memorization risks compared to standard fine-tuning.

</details>


### [80] [Beyond Fixed Psychological Personas: State Beats Trait, but Language Models are State-Blind](https://arxiv.org/abs/2601.15395)
*Tamunotonye Harry,Ivoline Ngong,Chima Nweke,Yuanyuan Feng,Joseph Near*

Main category: cs.CL

TL;DR: Chameleon数据集揭示用户交互中状态（state）比特质（trait）更重要（74% vs 26%），但LLMs只关注特质而忽略状态，奖励模型对状态反应不一致。


<details>
  <summary>Details</summary>
Motivation: 现有的人格数据集（如PersonaChat、PANDORA等）只捕捉用户的静态特质（trait），忽略了交互情境（state）的影响。需要研究用户状态变化对语言模型交互的影响。

Method: 构建Chameleon数据集，包含1,667名Reddit用户在多个情境下的5,001个上下文心理档案。基于潜在状态-特质理论进行方差分解分析，评估LLMs和奖励模型对用户状态的反应。

Result: 1. 方差分解显示74%来自用户内部状态变化，仅26%来自用户间特质差异。2. LLMs是"状态盲"的，只关注特质，对相同用户在不同状态下产生相似响应。3. 奖励模型对用户状态有反应但不一致，不同模型对相同用户的偏好方向相反。

Conclusion: 用户状态在交互中比特质更重要，但当前LLMs无法捕捉状态变化。Chameleon数据集支持情感计算、个性化对话和RLHF对齐研究，推动开发能感知用户状态的AI系统。

Abstract: User interactions with language models vary due to static properties of the user (trait) and the specific context of the interaction (state). However, existing persona datasets (like PersonaChat, PANDORA etc.) capture only trait, and ignore the impact of state. We introduce Chameleon, a dataset of 5,001 contextual psychological profiles from 1,667 Reddit users, each measured across multiple contexts. Using the Chameleon dataset, we present three key findings. First, inspired by Latent State-Trait theory, we decompose variance and find that 74\% is within-person(state) while only 26\% is between-person (trait). Second, we find that LLMs are state-blind: they focus on trait only, and produce similar responses regardless of state. Third, we find that reward models react to user state, but inconsistently: different models favor or penalize the same users in opposite directions. We release Chameleon to support research on affective computing, personalized dialogue, and RLHF alignment.

</details>


### [81] [Domain-Specific Knowledge Graphs in RAG-Enhanced Healthcare LLMs](https://arxiv.org/abs/2601.15429)
*Sydney Anuyah,Mehedi Mahmud Kaushik,Hao Dai,Rakesh Shiradkar,Arjan Durresi,Sunandan Chakraborty*

Main category: cs.CL

TL;DR: 研究评估领域知识图谱能否提升医疗健康领域的检索增强生成效果，发现知识图谱与查询范围的对齐是关键，精确匹配的检索效果最好，而盲目合并图谱会引入干扰信息降低准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在生成流畅回答方面表现出色，但在需要可信赖的领域特定推理（如医疗健康领域）时可能存在不足。研究旨在评估领域知识图谱是否能有效提升检索增强生成在医疗健康应用中的表现。

Method: 从PubMed构建三个知识图谱：G1（2型糖尿病）、G2（阿尔茨海默病）、G3（AD+T2DM）。设计两个测试探针：Probe 1针对合并的AD T2DM知识，Probe 2针对G1和G2的交集。测试7个指令调优的LLM在不同检索源（无RAG、G1、G2、G1+G2、G3、G1+G2+G3）和三种解码温度下的表现。

Result: 知识图谱与查询范围的对齐至关重要：精确、范围匹配的检索（特别是G2）带来最一致的性能提升，而不加区分的图谱合并往往会引入干扰信息降低准确性。较大模型在Probe 1上经常能达到或超过KG-RAG的无RAG基线，表明其具有强大的参数先验，而较小/中等规模模型从范围匹配良好的检索中获益更多。温度起次要作用，较高温度很少有帮助。

Conclusion: 精确优先、范围匹配的KG-RAG优于广度优先的图谱合并。研究为图谱选择、模型规模确定以及检索/重排序提供了实用指南。强调在医疗健康领域应用中，应优先考虑精确匹配而非简单合并多个知识图谱。

Abstract: Large Language Models (LLMs) generate fluent answers but can struggle with trustworthy, domain-specific reasoning. We evaluate whether domain knowledge graphs (KGs) improve Retrieval-Augmented Generation (RAG) for healthcare by constructing three PubMed-derived graphs: $\mathbb{G}_1$ (T2DM), $\mathbb{G}_2$ (Alzheimer's disease), and $\mathbb{G}_3$ (AD+T2DM). We design two probes: Probe 1 targets merged AD T2DM knowledge, while Probe 2 targets the intersection of $\mathbb{G}_1$ and $\mathbb{G}_2$. Seven instruction-tuned LLMs are tested across retrieval sources {No-RAG, $\mathbb{G}_1$, $\mathbb{G}_2$, $\mathbb{G}_1$ + $\mathbb{G}_2$, $\mathbb{G}_3$, $\mathbb{G}_1$+$\mathbb{G}_2$ + $\mathbb{G}_3$} and three decoding temperatures. Results show that scope alignment between probe and KG is decisive: precise, scope-matched retrieval (notably $\mathbb{G}_2$) yields the most consistent gains, whereas indiscriminate graph unions often introduce distractors that reduce accuracy. Larger models frequently match or exceed KG-RAG with a No-RAG baseline on Probe 1, indicating strong parametric priors, whereas smaller/mid-sized models benefit more from well-scoped retrieval. Temperature plays a secondary role; higher values rarely help. We conclude that precision-first, scope-matched KG-RAG is preferable to breadth-first unions, and we outline practical guidelines for graph selection, model sizing, and retrieval/reranking. Code and Data available here - https://github.com/sydneyanuyah/RAGComparison

</details>


### [82] [Chunking, Retrieval, and Re-ranking: An Empirical Evaluation of RAG Architectures for Policy Document Question Answering](https://arxiv.org/abs/2601.15457)
*Anuj Maharjan,Umesh Yadav*

Main category: cs.CL

TL;DR: 本文实证评估了RAG架构在公共卫生政策领域减少LLM幻觉的效果，发现高级RAG配置在忠实度上显著优于基础RAG和原始LLM。


<details>
  <summary>Details</summary>
Motivation: LLM在公共卫生政策领域有应用潜力，但其产生幻觉（看似合理但事实错误的断言）的问题在高风险环境中构成关键障碍，需要解决信息完整性问题。

Method: 比较原始LLM、基础RAG和高级RAG（使用交叉编码器重排序）三种架构。使用Mistral-7B-Instruct-v0.2模型和all-MiniLM-L6-v2嵌入模型处理CDC政策文件，评估两种分块策略（递归字符分块和基于token的语义分割）对系统准确性的影响。

Result: 基础RAG在忠实度上（0.621）显著优于原始LLM基线（0.347），高级RAG配置达到最高的忠实度平均值0.797。两阶段检索机制对于领域特定政策问答的精确性至关重要，但文档分割的结构限制仍然是多步推理任务的主要瓶颈。

Conclusion: RAG架构能有效减少LLM在公共卫生政策领域的幻觉问题，高级RAG配置表现最佳，但文档分割策略仍需改进以支持复杂推理任务。

Abstract: The integration of Large Language Models (LLMs) into the public health policy sector offers a transformative approach to navigating the vast repositories of regulatory guidance maintained by agencies such as the Centers for Disease Control and Prevention (CDC). However, the propensity for LLMs to generate hallucinations, defined as plausible but factually incorrect assertions, presents a critical barrier to the adoption of these technologies in high-stakes environments where information integrity is non-negotiable. This empirical evaluation explores the effectiveness of Retrieval-Augmented Generation (RAG) architectures in mitigating these risks by grounding generative outputs in authoritative document context. Specifically, this study compares a baseline Vanilla LLM against Basic RAG and Advanced RAG pipelines utilizing cross-encoder re-ranking. The experimental framework employs a Mistral-7B-Instruct-v0.2 model and an all-MiniLM-L6-v2 embedding model to process a corpus of official CDC policy analytical frameworks and guidance documents. The analysis measures the impact of two distinct chunking strategies, recursive character-based and token-based semantic splitting, on system accuracy, measured through faithfulness and relevance scores across a curated set of complex policy scenarios. Quantitative findings indicate that while Basic RAG architectures provide a substantial improvement in faithfulness (0.621) over Vanilla baselines (0.347), the Advanced RAG configuration achieves a superior faithfulness average of 0.797. These results demonstrate that two-stage retrieval mechanisms are essential for achieving the precision required for domain-specific policy question answering, though structural constraints in document segmentation remain a significant bottleneck for multi-step reasoning tasks.

</details>


### [83] [Benchmarking LLMs for Pairwise Causal Discovery in Biomedical and Multi-Domain Contexts](https://arxiv.org/abs/2601.15479)
*Sydney Anuyah,Sneha Shajee-Mohan,Ankit-Singh Chauhan,Sunandan Chakraborty*

Main category: cs.CL

TL;DR: 评估13个开源大语言模型在文本中成对因果发现的能力，发现现有模型在因果检测和提取方面存在显著缺陷，最佳模型准确率不足50%


<details>
  <summary>Details</summary>
Motivation: 为了安全地将大语言模型部署到生物医学等高风险领域，需要模型具备因果推理能力。本研究旨在评估当前LLMs在文本中识别和提取因果关系的基本能力

Method: 使用12个多样化数据集构建基准测试，评估两个核心技能：1) 因果检测（判断文本是否包含因果链接）2) 因果提取（提取确切的因果短语）。测试了多种提示方法，包括零样本、思维链和少样本上下文学习

Result: 当前模型存在重大缺陷：最佳检测模型DeepSeek-R1-Distill-Llama-70B平均得分仅49.57%，最佳提取模型Qwen2.5-Coder-32B-Instruct仅47.12%。模型在简单、显式、单句关系上表现较好，但在隐式关系、跨多句链接和多因果对文本上表现急剧下降

Conclusion: 现有大语言模型在文本因果发现任务上能力有限，特别是在复杂现实场景中。研究提供了统一的评估框架和公开数据集，以促进该领域的进一步研究

Abstract: The safe deployment of large language models (LLMs) in high-stakes fields like biomedicine, requires them to be able to reason about cause and effect. We investigate this ability by testing 13 open-source LLMs on a fundamental task: pairwise causal discovery (PCD) from text. Our benchmark, using 12 diverse datasets, evaluates two core skills: 1) \textbf{Causal Detection} (identifying if a text contains a causal link) and 2) \textbf{Causal Extraction} (pulling out the exact cause and effect phrases). We tested various prompting methods, from simple instructions (zero-shot) to more complex strategies like Chain-of-Thought (CoT) and Few-shot In-Context Learning (FICL).
  The results show major deficiencies in current models. The best model for detection, DeepSeek-R1-Distill-Llama-70B, only achieved a mean score of 49.57\% ($C_{detect}$), while the best for extraction, Qwen2.5-Coder-32B-Instruct, reached just 47.12\% ($C_{extract}$). Models performed best on simple, explicit, single-sentence relations. However, performance plummeted for more difficult (and realistic) cases, such as implicit relationships, links spanning multiple sentences, and texts containing multiple causal pairs. We provide a unified evaluation framework, built on a dataset validated with high inter-annotator agreement ($κ\ge 0.758$), and make all our data, code, and prompts publicly available to spur further research. \href{https://github.com/sydneyanuyah/CausalDiscovery}{Code available here: https://github.com/sydneyanuyah/CausalDiscovery}

</details>


### [84] [Multi-Persona Thinking for Bias Mitigation in Large Language Models](https://arxiv.org/abs/2601.15488)
*Yuxing Chen,Guoqing Luo,Zijun Wu,Lili Mou*

Main category: cs.CL

TL;DR: 提出Multi-Persona Thinking (MPT)框架，通过多视角辩证推理减少大语言模型的社会偏见


<details>
  <summary>Details</summary>
Motivation: 大语言模型存在显著的社会偏见，可能延续有害刻板印象和不公平结果，需要有效的偏见缓解方法

Method: MPT框架在推理时引导模型采用对比的社会身份（如男性和女性）以及中立视角，通过迭代的辩证推理过程暴露和纠正偏见

Result: 在两个广泛使用的偏见基准测试中，MPT相比现有基于提示的策略取得显著改进：达到最低偏见同时保持核心推理能力

Conclusion: MPT将角色分配的潜在弱点转化为偏见缓解的优势，为减少LLM社会偏见提供了有效的推理时框架

Abstract: Large Language Models (LLMs) exhibit significant social biases that can perpetuate harmful stereotypes and unfair outcomes. In this paper, we propose Multi-Persona Thinking (MPT), a novel inference-time framework that leverages dialectical reasoning from multiple perspectives to reduce bias. MPT guides models to adopt contrasting social identities (e.g., male and female) along with a neutral viewpoint, and then engages these personas iteratively to expose and correct biases. Through a dialectical reasoning process, the framework transforms the potential weakness of persona assignment into a strength for bias mitigation. We evaluate MPT on two widely used bias benchmarks across both open-source and closed-source models of varying scales. Our results demonstrate substantial improvements over existing prompting-based strategies: MPT achieves the lowest bias while maintaining core reasoning ability.

</details>


### [85] [ViT Registers and Fractal ViT](https://arxiv.org/abs/2601.15506)
*Jason Chuan-Chih Chou,Abhinav Kumar,Shivank Garg*

Main category: cs.CL

TL;DR: 本文提出了一种名为分形ViT的视觉Transformer变体，通过引入类似寄存器的"摘要令牌"和注意力掩码来打破令牌的置换不变性，但实验表明该模型并未超越带寄存器的标准ViT。


<details>
  <summary>Details</summary>
Motivation: 受到两个近期发现的启发：1）无位置编码的Transformer在语言模型中表现良好；2）寄存器（与输入无关的额外丢弃令牌）可能提升大型视觉Transformer的性能。研究者希望探索通过引入类似寄存器的机制来改进ViT架构。

Method: 提出分形ViT变体，在常规令牌和"摘要令牌"之间应用注意力掩码来打破令牌的置换不变性。该方法可以单独使用，也可以与各种位置编码结合使用。摘要令牌类似于寄存器中的额外令牌，但与输入无关。

Result: 实验结果表明，分形ViT模型并未超越带寄存器的标准ViT。这表明相关发现可能是规模、领域或应用特定的，不具有普遍适用性。

Conclusion: 虽然分形ViT的构想基于有前景的观察，但实际效果有限。研究强调了架构改进的发现可能具有特定性，不能简单推广到不同规模、领域或应用中。

Abstract: Drawing inspiration from recent findings including surprisingly decent performance of transformers without positional encoding (NoPE) in the domain of language models and how registers (additional throwaway tokens not tied to input) may improve the performance of large vision transformers (ViTs), we invent and test a variant of ViT called fractal ViT that breaks permutation invariance among the tokens by applying an attention mask between the regular tokens and ``summary tokens'' similar to registers, in isolation or in combination with various positional encodings. These models do not improve upon ViT with registers, highlighting the fact that these findings may be scale, domain, or application-specific.

</details>


### [86] [Computational Representations of Character Significance in Novels](https://arxiv.org/abs/2601.15508)
*Haaris Mian,Melanie Subbiah,Sharon Marcus,Nora Shaalan,Kathleen McKeown*

Main category: cs.CL

TL;DR: 该研究提出了一种基于六成分结构模型的小说角色分析方法，超越了传统基于场景出现频率的方法，通过LLM和任务特定transformer对19世纪英国现实主义小说进行分析，探索角色中心性和性别动态。


<details>
  <summary>Details</summary>
Motivation: 传统小说角色建模主要基于角色在场景中的出现频率、行动、命名提及和对话，这种方法过于强调出现场景最多的主角。本研究旨在采用新的文学理论提出的六成分结构模型，以更全面地分析角色，特别是考虑叙述者-角色区分和其他角色讨论这一被先前方法忽视的维度。

Method: 采用基于新文学理论的六成分结构角色模型，比较通用LLM和任务特定transformer在19世纪英国现实主义小说上的应用。方法产生组件级和图形表示的角色讨论分析，用于大规模探索文学问题。

Result: 该方法能够生成角色讨论的组件级和图形表示，成功应用于探索Woloch的经典"一个与多个"角色中心性理论，以及角色讨论的性别动态，为文学研究提供了新的计算视角。

Conclusion: 通过六成分结构模型和现代NLP技术，本研究为小说角色分析提供了更全面的框架，能够捕捉传统方法忽视的维度（如其他角色讨论），为大规模文学分析开辟了新途径。

Abstract: Characters in novels have typically been modeled based on their presence in scenes in narrative, considering aspects like their actions, named mentions, and dialogue. This conception of character places significant emphasis on the main character who is present in the most scenes. In this work, we instead adopt a framing developed from a new literary theory proposing a six-component structural model of character. This model enables a comprehensive approach to character that accounts for the narrator-character distinction and includes a component neglected by prior methods, discussion by other characters. We compare general-purpose LLMs with task-specific transformers for operationalizing this model of character on major 19th-century British realist novels. Our methods yield both component-level and graph representations of character discussion. We then demonstrate that these representations allow us to approach literary questions at scale from a new computational lens. Specifically, we explore Woloch's classic "the one vs the many" theory of character centrality and the gendered dynamics of character discussion.

</details>


### [87] [AdversaRiskQA: An Adversarial Factuality Benchmark for High-Risk Domains](https://arxiv.org/abs/2601.15511)
*Adam Szelestey,Sofie van Engelen,Tianhao Huang,Justin Snelders,Qintao Zeng,Songgaojun Deng*

Main category: cs.CL

TL;DR: AdversaRiskQA：首个针对健康、金融和法律领域的对抗性事实性基准，评估LLMs在对抗性误导信息下的防御能力


<details>
  <summary>Details</summary>
Motivation: 现有工作缺乏高质量、领域特定的资源来评估模型在对抗性条件下的鲁棒性，且没有研究考察注入误导信息对长文本事实性的影响

Method: 引入AdversaRiskQA基准，包含两个难度级别，提出两种自动化方法评估对抗攻击成功率和长文本事实性，评估六个开源和闭源LLMs

Result: 排除无意义响应后，Qwen3 (80B)达到最高平均准确率，GPT-5保持稳定高准确率；性能随模型规模非线性扩展，领域间有差异；长文本评估显示注入误导信息与模型事实输出无显著相关性

Conclusion: AdversaRiskQA为识别LLMs弱点、开发高风险应用更可靠模型提供了有价值的基准

Abstract: Hallucination in large language models (LLMs) remains an acute concern, contributing to the spread of misinformation and diminished public trust, particularly in high-risk domains. Among hallucination types, factuality is crucial, as it concerns a model's alignment with established world knowledge. Adversarial factuality, defined as the deliberate insertion of misinformation into prompts with varying levels of expressed confidence, tests a model's ability to detect and resist confidently framed falsehoods. Existing work lacks high-quality, domain-specific resources for assessing model robustness under such adversarial conditions, and no prior research has examined the impact of injected misinformation on long-form text factuality.
  To address this gap, we introduce AdversaRiskQA, the first verified and reliable benchmark systematically evaluating adversarial factuality across Health, Finance, and Law. The benchmark includes two difficulty levels to test LLMs' defensive capabilities across varying knowledge depths. We propose two automated methods for evaluating the adversarial attack success and long-form factuality. We evaluate six open- and closed-source LLMs from the Qwen, GPT-OSS, and GPT families, measuring misinformation detection rates. Long-form factuality is assessed on Qwen3 (30B) under both baseline and adversarial conditions. Results show that after excluding meaningless responses, Qwen3 (80B) achieves the highest average accuracy, while GPT-5 maintains consistently high accuracy. Performance scales non-linearly with model size, varies by domains, and gaps between difficulty levels narrow as models grow. Long-form evaluation reveals no significant correlation between injected misinformation and the model's factual output. AdversaRiskQA provides a valuable benchmark for pinpointing LLM weaknesses and developing more reliable models for high-stakes applications.

</details>


### [88] [Common to Whom? Regional Cultural Commonsense and LLM Bias in India](https://arxiv.org/abs/2601.15550)
*Sangmitra Madhusudan,Trush Shashank More,Steph Buongiorno,Renata Dividino,Jad Kabbara,Ali Emami*

Main category: cs.CL

TL;DR: Indica是首个评估LLMs在印度次国家级文化常识的基准，揭示印度文化常识主要是区域性的而非全国统一的，并发现LLMs存在地理偏见。


<details>
  <summary>Details</summary>
Motivation: 现有文化常识基准将国家视为整体，假设国家边界内实践统一。但文化常识在国家内部是否一致？本研究旨在探索次国家级文化常识的多样性，以印度为案例（28个邦、8个中央直辖区、22种官方语言）。

Method: 创建Indica基准，收集印度五个地区（北、南、东、西、中）的人类标注答案，涵盖515个问题、8个日常生活领域，产生1,630个区域特定问答对。评估8个最先进LLMs，分析其准确性和地理偏见。

Result: 仅39.4%的问题在所有五个地区达成一致，表明印度文化常识主要是区域性的。LLMs在区域特定问题上准确率仅为13.4%-20.9%，存在显著地理偏见：过度选择中部和北部作为"默认"（比预期多选30-40%），而东部和西部代表性不足。

Conclusion: 文化常识在印度主要是区域性的而非全国统一的，LLMs在理解区域文化多样性方面表现不佳且存在系统性偏见。该研究方法为评估任何文化异质性国家的文化常识提供了可推广的框架。

Abstract: Existing cultural commonsense benchmarks treat nations as monolithic, assuming uniform practices within national boundaries. But does cultural commonsense hold uniformly within a nation, or does it vary at the sub-national level? We introduce Indica, the first benchmark designed to test LLMs' ability to address this question, focusing on India - a nation of 28 states, 8 union territories, and 22 official languages. We collect human-annotated answers from five Indian regions (North, South, East, West, and Central) across 515 questions spanning 8 domains of everyday life, yielding 1,630 region-specific question-answer pairs. Strikingly, only 39.4% of questions elicit agreement across all five regions, demonstrating that cultural commonsense in India is predominantly regional, not national. We evaluate eight state-of-the-art LLMs and find two critical gaps: models achieve only 13.4%-20.9% accuracy on region-specific questions, and they exhibit geographic bias, over-selecting Central and North India as the "default" (selected 30-40% more often than expected) while under-representing East and West. Beyond India, our methodology provides a generalizable framework for evaluating cultural commonsense in any culturally heterogeneous nation, from question design grounded in anthropological taxonomy, to regional data collection, to bias measurement.

</details>


### [89] [From Generation to Collaboration: Using LLMs to Edit for Empathy in Healthcare](https://arxiv.org/abs/2601.15558)
*Man Luo,Bahareh Harandizadeh,Amara Tariq,Halim Abbas,Umar Ghaffar,Christopher J Warren,Segun O. Kolade,Haidar M. Abdul-Muhsin*

Main category: cs.CL

TL;DR: LLMs作为共情编辑器，能提升医生书面回复的共情语调，同时保持医学信息准确性，比完全由LLM生成的回复更安全有效


<details>
  <summary>Details</summary>
Motivation: 临床共情对患者护理至关重要，但医生需要在认知和情感限制下平衡情感温暖与事实准确性。研究探索LLMs如何作为共情编辑器，提升医疗沟通质量

Method: 引入两个新的量化指标：共情排名分数和医学事实核查分数，系统评估回复的情感质量和事实质量。实验比较LLM编辑的回复与完全LLM生成的回复

Result: LLM编辑的回复显著提高了感知共情，同时保持了事实准确性，表现优于完全由LLM生成的输出

Conclusion: 将LLMs作为编辑助手而非自主生成器，为AI辅助医疗沟通提供了更安全、更有效的途径，实现共情与可信度的平衡

Abstract: Clinical empathy is essential for patient care, but physicians need continually balance emotional warmth with factual precision under the cognitive and emotional constraints of clinical practice. This study investigates how large language models (LLMs) can function as empathy editors, refining physicians' written responses to enhance empathetic tone while preserving underlying medical information. More importantly, we introduce novel quantitative metrics, an Empathy Ranking Score and a MedFactChecking Score to systematically assess both emotional and factual quality of the responses. Experimental results show that LLM edited responses significantly increase perceived empathy while preserving factual accuracy compared with fully LLM generated outputs. These findings suggest that using LLMs as editorial assistants, rather than autonomous generators, offers a safer, more effective pathway to empathetic and trustworthy AI-assisted healthcare communication.

</details>


### [90] [YuFeng-XGuard: A Reasoning-Centric, Interpretable, and Flexible Guardrail Model for Large Language Models](https://arxiv.org/abs/2601.15588)
*Junyu Lin,Meizhen Liu,Xiufeng Huang,Jinfeng Li,Haiwen Hong,Xiaohan Yuan,Yuefeng Chen,Longtao Huang,Hui Xue,Ranjie Duan,Zhikai Chen,Yuchuan Fu,Defeng Li,Lingyao Gao,Yitong Yang*

Main category: cs.CL

TL;DR: YuFeng-XGuard是一个推理中心的安全护栏模型家族，通过结构化风险预测和多层推理范式为LLM交互提供细粒度、可解释的风险评估。


<details>
  <summary>Details</summary>
Motivation: 当前LLM安全护栏方案主要依赖粗粒度过滤或事后规则，存在透明度有限、策略不灵活或推理成本过高的问题，需要支持细粒度、可解释且可适应的风险评估。

Method: 采用推理中心的设计，生成结构化风险预测（包括明确的风险类别和可配置置信度），并附带自然语言解释；采用分层推理范式，基于首个解码token进行初始风险决策，同时保留按需的解释推理；引入动态策略机制，将风险感知与策略执行解耦。

Result: 在多个公共安全基准测试中达到最先进性能，同时保持强效的效率-效能平衡；提供完整容量和轻量级两个版本，支持广泛部署场景。

Conclusion: YuFeng-XGuard通过结构化风险预测、分层推理和动态策略机制，实现了细粒度、可解释且可适应的LLM安全护栏，在保持高效的同时提供透明决策。

Abstract: As large language models (LLMs) are increasingly deployed in real-world applications, safety guardrails are required to go beyond coarse-grained filtering and support fine-grained, interpretable, and adaptable risk assessment. However, existing solutions often rely on rapid classification schemes or post-hoc rules, resulting in limited transparency, inflexible policies, or prohibitive inference costs. To this end, we present YuFeng-XGuard, a reasoning-centric guardrail model family designed to perform multi-dimensional risk perception for LLM interactions. Instead of producing opaque binary judgments, YuFeng-XGuard generates structured risk predictions, including explicit risk categories and configurable confidence scores, accompanied by natural language explanations that expose the underlying reasoning process. This formulation enables safety decisions that are both actionable and interpretable. To balance decision latency and explanatory depth, we adopt a tiered inference paradigm that performs an initial risk decision based on the first decoded token, while preserving ondemand explanatory reasoning when required. In addition, we introduce a dynamic policy mechanism that decouples risk perception from policy enforcement, allowing safety policies to be adjusted without model retraining. Extensive experiments on a diverse set of public safety benchmarks demonstrate that YuFeng-XGuard achieves stateof-the-art performance while maintaining strong efficiency-efficacy trade-offs. We release YuFeng-XGuard as an open model family, including both a full-capacity variant and a lightweight version, to support a wide range of deployment scenarios.

</details>


### [91] [Parallelism and Generation Order in Masked Diffusion Language Models: Limits Today, Potential Tomorrow](https://arxiv.org/abs/2601.15593)
*Yangyang Zhong,Yanmei Gu,Zhengqing Zang,Xiaomeng Li,Yuqi Ding,Xibei Jia,Yuting Shen,Zhenzhong Lan,Liwang Zhu,Weiping Liu,Junlin Zhou,Haisheng Liu,Zhong Xin Yu,Pengxin Luo,Donglian Qi,Yunfeng Yan,Junbo Zhao*

Main category: cs.CL

TL;DR: MDLMs在并行生成和任意顺序解码方面仍有局限，主要因并行概率建模削弱了token间依赖关系，落后于同等规模的自回归模型，但在需要"后向信息"的任务中展现优势。


<details>
  <summary>Details</summary>
Motivation: 研究掩码扩散语言模型(MDLMs)是否真正实现了其承诺的并行token生成和任意顺序解码能力，以及这些模型在实际任务中的表现如何。

Method: 使用平均最终化并行度(AFP)和Kendall's tau两个指标，从并行强度和生成顺序两个维度分析MDLM行为；评估8个主流MDLM模型(最大100B参数)在58个涵盖知识、推理和编程的基准测试上的表现。

Result: MDLMs仍落后于同等规模的自回归模型，主要因并行概率建模削弱了token间依赖；MDLMs表现出自适应解码行为：其并行度和生成顺序随任务领域、推理阶段和输出正确性显著变化；在需要"后向信息"的任务(如数独)中，MDLMs倾向于先填充较简单的空白，展现其优势。

Conclusion: 提出了"生成-编辑"范式，既能缓解依赖损失，又能保留并行解码的效率，为MDLM设计提供理论动机和设计思路。

Abstract: Masked Diffusion Language Models (MDLMs) promise parallel token generation and arbitrary-order decoding, yet it remains unclear to what extent current models truly realize these capabilities. We characterize MDLM behavior along two dimensions -- parallelism strength and generation order -- using Average Finalization Parallelism (AFP) and Kendall's tau. We evaluate eight mainstream MDLMs (up to 100B parameters) on 58 benchmarks spanning knowledge, reasoning, and programming. The results show that MDLMs still lag behind comparably sized autoregressive models, mainly because parallel probabilistic modeling weakens inter-token dependencies. Meanwhile, MDLMs exhibit adaptive decoding behavior: their parallelism and generation order vary significantly with the task domain, the stage of reasoning, and whether the output is correct. On tasks that require "backward information" (e.g., Sudoku), MDLMs adopt a solution order that tends to fill easier Sudoku blanks first, highlighting their advantages. Finally, we provide theoretical motivation and design insights supporting a Generate-then-Edit paradigm, which mitigates dependency loss while retaining the efficiency of parallel decoding.

</details>


### [92] [ToxiTwitch: Toward Emote-Aware Hybrid Moderation for Live Streaming Platforms](https://arxiv.org/abs/2601.15605)
*Baktash Ansari,Shiza Ali,Elias Martin,Maryna Sivachenko,Afra Mashhadi*

Main category: cs.CL

TL;DR: 本文提出ToxiTwitch混合模型，结合LLM生成的文本和表情符号嵌入与传统机器学习分类器，用于Twitch直播平台的毒性检测，在特定频道训练下达到80%准确率。


<details>
  <summary>Details</summary>
Motivation: Twitch等直播平台面临毒性行为监管挑战，传统人工标注和关键词过滤方法难以应对快节奏、高流量、语境丰富的聊天环境，且人工审核员自身也面临骚扰。LLM的发展为理解包含表情符号的复杂多模态通信提供了新机会。

Method: 提出ToxiTwitch混合模型，结合DeepSeek-R1-Distill和Llama-3-8B-Instruct等LLM生成的文本和表情符号嵌入，与随机森林和SVM等传统机器学习分类器相结合，专门针对Twitch平台进行毒性检测。

Result: 研究表明包含表情符号能改善毒性行为检测。在特定频道训练下，混合方法达到80%准确率，比BERT提升13%，F1分数为76%。

Conclusion: 这是一项探索性研究，旨在揭示Twitch平台上表情符号感知毒性检测的挑战和限制，展示了结合LLM嵌入与传统分类器的混合方法在直播平台毒性检测中的潜力。

Abstract: The rapid growth of live-streaming platforms such as Twitch has introduced complex challenges in moderating toxic behavior. Traditional moderation approaches, such as human annotation and keyword-based filtering, have demonstrated utility, but human moderators on Twitch constantly struggle to scale effectively in the fast-paced, high-volume, and context-rich chat environment of the platform while also facing harassment themselves. Recent advances in large language models (LLMs), such as DeepSeek-R1-Distill and Llama-3-8B-Instruct, offer new opportunities for toxicity detection, especially in understanding nuanced, multimodal communication involving emotes. In this work, we present an exploratory comparison of toxicity detection approaches tailored to Twitch. Our analysis reveals that incorporating emotes improves the detection of toxic behavior. To this end, we introduce ToxiTwitch, a hybrid model that combines LLM-generated embeddings of text and emotes with traditional machine learning classifiers, including Random Forest and SVM. In our case study, the proposed hybrid approach reaches up to 80 percent accuracy under channel-specific training (with 13 percent improvement over BERT and F1-score of 76 percent). This work is an exploratory study intended to surface challenges and limits of emote-aware toxicity detection on Twitch.

</details>


### [93] [Towards Reliable Medical LLMs: Benchmarking and Enhancing Confidence Estimation of Large Language Models in Medical Consultation](https://arxiv.org/abs/2601.15645)
*Zhiyao Ren,Yibing Zhan,Siyuan Liang,Guozheng Ma,Baosheng Yu,Dacheng Tao*

Main category: cs.CL

TL;DR: 提出了首个用于评估多轮医疗咨询中置信度的基准，并开发了MedConf框架，通过症状档案构建和信息对齐来提升医疗置信度估计的可靠性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要在单轮静态设置中评估置信度，忽略了真实医疗咨询中随着证据积累置信度与正确性之间的动态耦合关系，这限制了其对可靠决策的支持。

Method: 提出了首个多轮医疗咨询置信度评估基准，统一了三种医疗数据用于开放式诊断生成，引入信息充分性梯度来刻画置信度-正确性动态关系。开发了MedConf框架：通过检索增强生成构建症状档案，将患者信息与支持、缺失和矛盾关系对齐，并通过加权集成聚合成可解释的置信度估计。

Result: 在两个LLM和三个医疗数据集上，MedConf在AUROC和Pearson相关系数指标上持续优于现有最优方法，在信息不足和多病共存条件下保持稳定性能。

Conclusion: 信息充分性是可信医疗置信度建模的关键决定因素，为构建更可靠和可解释的大型医疗模型提供了新途径。

Abstract: Large-scale language models (LLMs) often offer clinical judgments based on incomplete information, increasing the risk of misdiagnosis. Existing studies have primarily evaluated confidence in single-turn, static settings, overlooking the coupling between confidence and correctness as clinical evidence accumulates during real consultations, which limits their support for reliable decision-making. We propose the first benchmark for assessing confidence in multi-turn interaction during realistic medical consultations. Our benchmark unifies three types of medical data for open-ended diagnostic generation and introduces an information sufficiency gradient to characterize the confidence-correctness dynamics as evidence increases. We implement and compare 27 representative methods on this benchmark; two key insights emerge: (1) medical data amplifies the inherent limitations of token-level and consistency-level confidence methods, and (2) medical reasoning must be evaluated for both diagnostic accuracy and information completeness. Based on these insights, we present MedConf, an evidence-grounded linguistic self-assessment framework that constructs symptom profiles via retrieval-augmented generation, aligns patient information with supporting, missing, and contradictory relations, and aggregates them into an interpretable confidence estimate through weighted integration. Across two LLMs and three medical datasets, MedConf consistently outperforms state-of-the-art methods on both AUROC and Pearson correlation coefficient metrics, maintaining stable performance under conditions of information insufficiency and multimorbidity. These results demonstrate that information adequacy is a key determinant of credible medical confidence modeling, providing a new pathway toward building more reliable and interpretable large medical models.

</details>


### [94] [What Patients Really Ask: Exploring the Effect of False Assumptions in Patient Information Seeking](https://arxiv.org/abs/2601.15674)
*Raymond Xiong,Furong Jia,Lionel Wong,Monica Agrawal*

Main category: cs.CL

TL;DR: 研究创建了一个基于患者真实用药问题的数据集，发现许多问题包含错误假设和危险意图，而当前LLM难以识别这些日常问题中的错误


<details>
  <summary>Details</summary>
Motivation: 现有LLM医疗问答基准主要关注医学考试题目，与患者实际提出的问题在风格和内容上差异很大，需要填补这一研究空白

Method: 通过Google的"People Also Ask"功能，查询美国前200种处方药，收集患者常问的医疗问题，构建数据集并分析问题特征

Result: 收集的问题中有相当一部分包含错误假设和危险意图；这些"腐败问题"的出现不是随机的，而是与先前问题的错误程度密切相关；当前在其他基准上表现良好的LLM难以识别日常问题中的错误假设

Conclusion: 需要开发能够更好识别患者日常问题中错误假设和危险意图的LLM，现有基准不足以评估LLM处理真实患者问题的能力

Abstract: Patients are increasingly using large language models (LLMs) to seek answers to their healthcare-related questions. However, benchmarking efforts in LLMs for question answering often focus on medical exam questions, which differ significantly in style and content from the questions patients actually raise in real life. To bridge this gap, we sourced data from Google's People Also Ask feature by querying the top 200 prescribed medications in the United States, curating a dataset of medical questions people commonly ask. A considerable portion of the collected questions contains incorrect assumptions and dangerous intentions. We demonstrate that the emergence of these corrupted questions is not uniformly random and depends heavily on the degree of incorrectness in the history of questions that led to their appearance. Current LLMs that perform strongly on other benchmarks struggle to identify incorrect assumptions in everyday questions.

</details>


### [95] [Persona Switch: Mixing Distinct Perspectives in Decoding Time](https://arxiv.org/abs/2601.15708)
*Junseok Kim,Nakyeong Yang,Kyomin Jung*

Main category: cs.CL

TL;DR: 提出Persona Switch解码方法，通过动态结合零样本提示和角色扮演提示的优势，在每一步选择置信度更高的输出，提升语言模型性能。


<details>
  <summary>Details</summary>
Motivation: 角色扮演提示虽然能通过注入角色来引导语言模型行为，提升零样本推理能力，但这种提升在不同任务或实例中并不一致。这表明零样本提示和角色扮演提示可能具有互补优势，而非一方普遍优于另一方。

Method: 提出Persona Switch解码方法，逐步进行推理，在每一步通过比较零样本提示和角色扮演提示的输出置信度（通过logit gap衡量），选择置信度更高的输出。

Result: 在广泛使用的LLMs上的实验表明，Persona Switch始终优于竞争基线，实现了高达5.13%的准确率提升。同时证明输出置信度是选择更可靠输出的有效指标。

Conclusion: Persona Switch通过动态结合两种提示策略的优势，提供了一种有效的解码方法，能够提升语言模型在各种任务上的性能表现。

Abstract: Role-play prompting is known to steer the behavior of language models by injecting a persona into the prompt, improving their zero-shot reasoning capabilities. However, such improvements are inconsistent across different tasks or instances. This inconsistency suggests that zero-shot and role-play prompting may offer complementary strengths rather than one being universally superior. Building on this insight, we propose Persona Switch, a novel decoding method that dynamically combines the benefits of both prompting strategies. Our method proceeds step-by-step, selecting the better output between zero-shot and role-play prompting at each step by comparing their output confidence, as measured by the logit gap. Experiments with widely-used LLMs demonstrate that Persona Switch consistently outperforms competitive baselines, achieving up to 5.13% accuracy improvement. Furthermore, we show that output confidence serves as an informative measure for selecting the more reliable output.

</details>


### [96] [Dancing in Chains: Strategic Persuasion in Academic Rebuttal via Theory of Mind](https://arxiv.org/abs/2601.15715)
*Zhitao He,Zongwei Lyu,Yi R Fung*

Main category: cs.CL

TL;DR: 提出了首个基于心智理论（ToM）的学术反驳框架RebuttalAgent，通过TSR管道建模审稿人心理状态、制定说服策略并生成策略驱动的回应，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 学术反驳是研究流程中重要但未被充分探索的挑战，因为它是信息严重不对称下的战略沟通过程，而非简单的技术辩论。现有方法主要模仿表面语言特征，缺乏有效说服所需的心智理论视角。

Method: 提出RebuttalAgent框架，采用ToM-Strategy-Response（TSR）管道：1）建模审稿人心智状态；2）制定说服策略；3）生成策略驱动的回应。构建大规模数据集RebuttalBench，采用两阶段训练：监督微调培养ToM分析和战略规划能力，强化学习通过自奖励机制实现可扩展的自我改进。开发专门评估器Rebuttal-RM进行可靠自动化评估。

Result: RebuttalAgent在自动指标上平均比基础模型提升18.3%，在自动和人工评估中均优于先进的专有模型。Rebuttal-RM评估器在超过10万样本上训练，其评分一致性超越GPT-4.1。

Conclusion: 该研究首次将心智理论应用于学术反驳，通过系统化的TSR管道和两阶段训练方法，显著提升了反驳生成的质量和说服力。生成的回复仅供作者参考和启发，不替代作者自身的批判性分析和回应。

Abstract: Although artificial intelligence (AI) has become deeply integrated into various stages of the research workflow and achieved remarkable advancements, academic rebuttal remains a significant and underexplored challenge. This is because rebuttal is a complex process of strategic communication under severe information asymmetry rather than a simple technical debate. Consequently, current approaches struggle as they largely imitate surface-level linguistics, missing the essential element of perspective-taking required for effective persuasion. In this paper, we introduce RebuttalAgent, the first framework to ground academic rebuttal in Theory of Mind (ToM), operationalized through a ToM-Strategy-Response (TSR) pipeline that models reviewer mental state, formulates persuasion strategy, and generates strategy-grounded response. To train our agent, we construct RebuttalBench, a large-scale dataset synthesized via a novel critique-and-refine approach. Our training process consists of two stages, beginning with a supervised fine-tuning phase to equip the agent with ToM-based analysis and strategic planning capabilities, followed by a reinforcement learning phase leveraging the self-reward mechanism for scalable self-improvement. For reliable and efficient automated evaluation, we further develop Rebuttal-RM, a specialized evaluator trained on over 100K samples of multi-source rebuttal data, which achieves scoring consistency with human preferences surpassing powerful judge GPT-4.1. Extensive experiments show RebuttalAgent significantly outperforms the base model by an average of 18.3% on automated metrics, while also outperforming advanced proprietary models across both automated and human evaluations. Disclaimer: the generated rebuttal content is for reference only to inspire authors and assist in drafting. It is not intended to replace the author's own critical analysis and response.

</details>


### [97] [Hallucination Mitigating for Medical Report Generation](https://arxiv.org/abs/2601.15745)
*Ruoqing Zhao,Runze Xia,Piji Li*

Main category: cs.CL

TL;DR: KERM框架通过知识检索、净化模块和细粒度奖励机制，有效减少医疗报告生成中的幻觉问题，提升报告质量。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在医疗报告生成中存在生成看似合理但不准确内容（幻觉）的问题，这在医疗领域尤其危险，需要解决。

Method: 1. 使用MedCLIP从知识库中检索相关病变事实句子；2. 引入净化模块确保检索知识与患者临床上下文相关；3. 采用细粒度奖励机制引导模型生成高度支持性和临床相关的描述。

Result: 在IU-Xray和MIMIC-CXR数据集上的实验结果验证了该方法在减少幻觉和提升报告质量方面的有效性。

Conclusion: KERM框架通过知识增强和细粒度奖励机制，能够有效缓解医疗报告生成中的幻觉问题，提高生成报告的临床相关性和准确性。

Abstract: In the realm of medical report generation (MRG), the integration of natural language processing has emerged as a vital tool to alleviate the workload of radiologists. Despite the impressive capabilities demonstrated by large vision language models (LVLMs) in understanding natural language, their susceptibility to generating plausible yet inaccurate claims, known as ``hallucinations'', raises concerns-especially in the nuanced and critical field of medical. In this work, we introduce a framework, \textbf{K}nowledge-\textbf{E}nhanced with Fine-Grained \textbf{R}einforced Rewards \textbf{M}edical Report Generation (KERM), to tackle the issue. Our approach refines the input to the LVLM by first utilizing MedCLIP for knowledge retrieval, incorporating relevant lesion fact sentences from a curated knowledge corpus. We then introduce a novel purification module to ensure the retrieved knowledge is contextually relevant to the patient's clinical context. Subsequently, we employ fine-grained rewards to guide these models in generating highly supportive and clinically relevant descriptions, ensuring the alignment of model's outputs with desired behaviors. Experimental results on IU-Xray and MIMIC-CXR datasets validate the effectiveness of our approach in mitigating hallucinations and enhancing report quality.

</details>


### [98] [Beyond Marginal Distributions: A Framework to Evaluate the Representativeness of Demographic-Aligned LLMs](https://arxiv.org/abs/2601.15755)
*Tristan Williams,Franziska Weeber,Sebastian Padó,Alan Akbik*

Main category: cs.CL

TL;DR: 论文提出一个评估语言模型代表性（representativeness）的新框架，强调不仅要看边缘响应分布，还要考虑多元相关模式，发现现有对齐方法在捕捉人类价值观相关结构上存在不足。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型越来越多地被用来代表人类观点、价值观或信仰，但现有研究主要关注对齐边缘响应分布，忽略了真实人群中更深层的潜在结构，这些结构是文化价值观理论的基础。

Method: 提出一个评估框架，通过多元相关模式（multivariate correlation patterns）和边缘分布来评估对齐模型的代表性。比较两种模型引导技术：人物角色提示（persona prompting）和人口统计微调（demographic fine-tuning），并使用世界价值观调查（World Values Survey）的人类响应作为黄金标准进行评估。

Result: 人口统计微调模型在边缘响应分布上比人物角色提示更好地近似人类响应，但两种技术都未能完全捕捉黄金标准的相关模式。代表性是价值对齐的一个独特方面，仅关注边缘分布的评估可能掩盖结构失败，导致对模型能力过于乐观的结论。

Conclusion: 代表性是价值对齐的一个关键维度，需要同时评估边缘分布和相关模式。现有对齐方法在捕捉人类价值观的复杂结构方面仍有不足，未来研究需要开发能更好反映真实人群多元相关模式的对齐技术。

Abstract: Large language models are increasingly used to represent human opinions, values, or beliefs, and their steerability towards these ideals is an active area of research. Existing work focuses predominantly on aligning marginal response distributions, treating each survey item independently. While essential, this may overlook deeper latent structures that characterise real populations and underpin cultural values theories. We propose a framework for evaluating the representativeness of aligned models through multivariate correlation patterns in addition to marginal distributions. We show the value of our evaluation scheme by comparing two model steering techniques (persona prompting and demographic fine-tuning) and evaluating them against human responses from the World Values Survey. While the demographically fine-tuned model better approximates marginal response distributions than persona prompting, both techniques fail to fully capture the gold standard correlation patterns. We conclude that representativeness is a distinct aspect of value alignment and an evaluation focused on marginals can mask structural failures, leading to overly optimistic conclusions about model capabilities.

</details>


### [99] [HumanLLM: Towards Personalized Understanding and Simulation of Human Nature](https://arxiv.org/abs/2601.15793)
*Yuxuan Lei,Tianfu Wang,Jianxun Lian,Zhengyu Hu,Defu Lian,Xing Xie*

Main category: cs.CL

TL;DR: HumanLLM：基于大规模真实用户数据构建的个性化人类行为模拟基础模型，通过认知基因组数据集训练，显著提升对人类行为和思维模式的预测能力。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在数学、编程等客观任务上表现优异，但在模拟人类行为方面存在局限，缺乏对人类认知和行为的细致理解。这种局限源于标准预训练数据缺乏个体在连续情境下的决策、思维和行为背景。

Method: 1. 构建认知基因组数据集：从Reddit、Twitter、Blogger、Amazon等平台收集真实用户数据，通过多阶段数据过滤、合成和质量控制流程，自动提取超过550万条用户日志，提炼丰富的用户画像、行为和思维模式。
2. 设计多样化学习任务并进行监督微调，使模型能够预测广泛的个性化人类行为、思维和体验。

Result: 1. HumanLLM在预测用户行为和内心想法方面表现优异
2. 更准确地模仿用户写作风格和偏好
3. 生成更真实的用户画像
4. 在领域外社交智能基准测试中表现出显著提升，显示增强的泛化能力

Conclusion: HumanLLM通过构建大规模真实用户数据集和针对性训练，成功提升了语言模型对人类个性化行为的理解和模拟能力，为社会科学研究和客户洞察应用提供了有力工具。

Abstract: Motivated by the remarkable progress of large language models (LLMs) in objective tasks like mathematics and coding, there is growing interest in their potential to simulate human behavior--a capability with profound implications for transforming social science research and customer-centric business insights. However, LLMs often lack a nuanced understanding of human cognition and behavior, limiting their effectiveness in social simulation and personalized applications. We posit that this limitation stems from a fundamental misalignment: standard LLM pretraining on vast, uncontextualized web data does not capture the continuous, situated context of an individual's decisions, thoughts, and behaviors over time. To bridge this gap, we introduce HumanLLM, a foundation model designed for personalized understanding and simulation of individuals. We first construct the Cognitive Genome Dataset, a large-scale corpus curated from real-world user data on platforms like Reddit, Twitter, Blogger, and Amazon. Through a rigorous, multi-stage pipeline involving data filtering, synthesis, and quality control, we automatically extract over 5.5 million user logs to distill rich profiles, behaviors, and thinking patterns. We then formulate diverse learning tasks and perform supervised fine-tuning to empower the model to predict a wide range of individualized human behaviors, thoughts, and experiences. Comprehensive evaluations demonstrate that HumanLLM achieves superior performance in predicting user actions and inner thoughts, more accurately mimics user writing styles and preferences, and generates more authentic user profiles compared to base models. Furthermore, HumanLLM shows significant gains on out-of-domain social intelligence benchmarks, indicating enhanced generalization.

</details>


### [100] [SteerEval: Inference-time Interventions Strengthen Multilingual Generalization in Neural Summarization Metrics](https://arxiv.org/abs/2601.15809)
*Silvia Casola,Ryan Soh-Eun Shim,Felicia Körner,Yuchen Mao,Barbara Plank*

Main category: cs.CL

TL;DR: 通过引导多语言神经评估指标向英语枢纽语言对齐，可以提升其与人类判断的相关性


<details>
  <summary>Details</summary>
Motivation: 多语言自然语言生成任务缺乏准确鲁棒的评估指标，且多语言模型常以英语为内部枢纽语言，这种不匹配可能导致下游性能下降

Method: 使用测试时干预方法，引导编码器和解码器基评估指标的激活向英语枢纽语言对齐

Result: 测试时干预方法对各类评估指标普遍有效，显著提升了多种语言的评估效果

Conclusion: 通过引导多语言神经评估指标向英语枢纽语言对齐，可以有效改善其与人类判断的相关性，为多语言评估提供新思路

Abstract: An increasing body of work has leveraged multilingual language models for Natural Language Generation tasks such as summarization. A major empirical bottleneck in this area is the shortage of accurate and robust evaluation metrics for many languages, which hinders progress. Recent studies suggest that multilingual language models often use English as an internal pivot language, and that misalignment with this pivot can lead to degraded downstream performance. Motivated by the hypothesis that this mismatch could also apply to multilingual neural metrics, we ask whether steering their activations toward an English pivot can improve correlation with human judgments. We experiment with encoder- and decoder-based metrics and find that test-time intervention methods are effective across the board, increasing metric effectiveness for diverse languages.

</details>


### [101] [ExDR: Explanation-driven Dynamic Retrieval Enhancement for Multimodal Fake News Detection](https://arxiv.org/abs/2601.15820)
*Guoxuan Ding,Yuqing Li,Ziyan Zhou,Zheng Lin,Daren Zha,Jiangnan Li*

Main category: cs.CL

TL;DR: 提出ExDR框架，通过解释驱动的动态检索增强生成来检测多模态假新闻，在检索触发、证据检索和最终预测方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 多模态假新闻的快速传播对社会构成严重威胁，其不断演变的性质和依赖及时事实细节的特点挑战了现有的检测方法。动态检索增强生成虽然提供了有前景的解决方案，但在应用于欺骗性内容时仍面临冗余检索、相似度计算粗糙和无关证据等问题。

Method: 提出ExDR框架，在检索触发和证据检索模块中系统性地利用模型生成的解释。从三个互补维度评估触发置信度，通过融合欺骗性实体构建实体感知索引，基于欺骗特定特征检索对比证据来挑战初始声明并增强最终预测。

Result: 在AMG和MR2两个基准数据集上的实验表明，ExDR在检索触发准确性、检索质量和整体检测性能方面持续优于先前方法，突显了其有效性和泛化能力。

Conclusion: ExDR框架通过解释驱动的动态检索增强生成，有效解决了多模态假新闻检测中的关键挑战，在多个评估维度上展现出优越性能。

Abstract: The rapid spread of multimodal fake news poses a serious societal threat, as its evolving nature and reliance on timely factual details challenge existing detection methods. Dynamic Retrieval-Augmented Generation provides a promising solution by triggering keyword-based retrieval and incorporating external knowledge, thus enabling both efficient and accurate evidence selection. However, it still faces challenges in addressing issues such as redundant retrieval, coarse similarity, and irrelevant evidence when applied to deceptive content. In this paper, we propose ExDR, an Explanation-driven Dynamic Retrieval-Augmented Generation framework for Multimodal Fake News Detection. Our framework systematically leverages model-generated explanations in both the retrieval triggering and evidence retrieval modules. It assesses triggering confidence from three complementary dimensions, constructs entity-aware indices by fusing deceptive entities, and retrieves contrastive evidence based on deception-specific features to challenge the initial claim and enhance the final prediction. Experiments on two benchmark datasets, AMG and MR2, demonstrate that ExDR consistently outperforms previous methods in retrieval triggering accuracy, retrieval quality, and overall detection performance, highlighting its effectiveness and generalization capability.

</details>


### [102] [Can professional translators identify machine-generated text?](https://arxiv.org/abs/2601.15828)
*Michael Farrell*

Main category: cs.CL

TL;DR: 研究发现专业翻译员无需专门训练也能在一定程度上识别AI生成的意大利语短篇小说，但准确率有限且存在误判


<details>
  <summary>Details</summary>
Motivation: 探究专业翻译员在没有专门训练的情况下，能否可靠识别AI生成的意大利语短篇小说，了解他们在区分人工与AI文本时的判断依据

Method: 69名翻译员参与现场实验，评估三篇匿名短篇小说（两篇由ChatGPT-4o生成，一篇由人类作者创作），对每篇故事评估AI作者的可能性并提供判断理由

Result: 平均结果不明确，但16.2%的参与者能成功区分AI与人类文本；几乎相同数量的人误判方向；低爆发性和叙事矛盾是最可靠的AI文本指标，而语法准确性和情感基调常导致误判

Conclusion: 专业翻译员具备一定识别AI文本的能力，但判断常基于主观印象而非客观标记，研究对专业语境中合成文本编辑的角色和范围提出疑问

Abstract: This study investigates whether professional translators can reliably identify short stories generated in Italian by artificial intelligence (AI) without prior specialized training. Sixty-nine translators took part in an in-person experiment, where they assessed three anonymized short stories - two written by ChatGPT-4o and one by a human author. For each story, participants rated the likelihood of AI authorship and provided justifications for their choices. While average results were inconclusive, a statistically significant subset (16.2%) successfully distinguished the synthetic texts from the human text, suggesting that their judgements were informed by analytical skill rather than chance. However, a nearly equal number misclassified the texts in the opposite direction, often relying on subjective impressions rather than objective markers, possibly reflecting a reader preference for AI-generated texts. Low burstiness and narrative contradiction emerged as the most reliable indicators of synthetic authorship, with unexpected calques, semantic loans and syntactic transfer from English also reported. In contrast, features such as grammatical accuracy and emotional tone frequently led to misclassification. These findings raise questions about the role and scope of synthetic-text editing in professional contexts.

</details>


### [103] [Determinants of Training Corpus Size for Clinical Text Classification](https://arxiv.org/abs/2601.15846)
*Jaya Chaturvedi,Saniya Deshpande,Chenkai Ma,Robert Cobb,Angus Roberts,Robert Stewart,Daniel Stahl,Diana Shamsutdinova*

Main category: cs.CL

TL;DR: 临床文本分类中，600份文档即可达到使用10,000份文档时95%的性能，词汇特性（强预测词和噪声词）显著影响学习曲线。


<details>
  <summary>Details</summary>
Motivation: 临床文本分类通常需要标注200-500份文档，但这一数量缺乏理论依据，且未考虑文本词汇特性对样本量需求的影响。

Method: 使用MIMIC-III数据集，采用预训练BERT嵌入和随机森林分类器，分析10个随机选择的诊断分类任务，训练集规模从100到10,000份文档，并通过Lasso逻辑回归分析词汇特性。

Result: 所有分类任务中，600份文档即可达到使用10,000份文档时95%的性能；词汇分析显示，强预测词越多、噪声词越少，学习曲线越陡峭，每增加100个噪声词准确率下降约0.02，每增加100个强预测词最大准确率提高约0.04。

Conclusion: 临床文本分类的样本量需求与词汇特性密切相关，600份文档可作为合理的标注目标，词汇分析有助于理解不同分类任务性能差异的原因。

Abstract: Introduction: Clinical text classification using natural language processing (NLP) models requires adequate training data to achieve optimal performance. For that, 200-500 documents are typically annotated. The number is constrained by time and costs and lacks justification of the sample size requirements and their relationship to text vocabulary properties.
  Methods: Using the publicly available MIMIC-III dataset containing hospital discharge notes with ICD-9 diagnoses as labels, we employed pre-trained BERT embeddings followed by Random Forest classifiers to identify 10 randomly selected diagnoses, varying training corpus sizes from 100 to 10,000 documents, and analyzed vocabulary properties by identifying strong and noisy predictive words through Lasso logistic regression on bag-of-words embeddings.
  Results: Learning curves varied significantly across the 10 classification tasks despite identical preprocessing and algorithms, with 600 documents sufficient to achieve 95% of the performance attainable with 10,000 documents for all tasks. Vocabulary analysis revealed that more strong predictors and fewer noisy predictors were associated with steeper learning curves, where every 100 additional noisy words decreased accuracy by approximately 0.02 while 100 additional strong predictors increased maximum accuracy by approximately 0.04.

</details>


### [104] [Artificial Rigidities vs. Biological Noise: A Comparative Analysis of Multisensory Integration in AV-HuBERT and Human Observers](https://arxiv.org/abs/2601.15869)
*Francisco Portillo López*

Main category: cs.CL

TL;DR: AV-HuBERT在McGurk效应测试中与人类听觉主导率相似(32.0% vs 31.8%)，但语音融合率显著高于人类(68.0% vs 47.7%)，模型缺乏人类感知的随机性和多样性。


<details>
  <summary>Details</summary>
Motivation: 评估自监督学习模型AV-HuBERT在感知生物保真度方面的表现，特别是测试其对不一致视听刺激(McGurk效应)的反应是否与人类观察者相似。

Method: 通过McGurk效应实验，比较AV-HuBERT模型与44名人类观察者对不一致视听刺激的反应，量化听觉主导率和语音融合率。

Result: AI与人类听觉主导率几乎相同(32.0% vs 31.8%)，但AV-HuBERT的语音融合率显著高于人类(68.0% vs 47.7%)，模型反应是确定性的而人类具有感知随机性。

Conclusion: 当前自监督架构能够模拟多感官结果，但缺乏人类语音感知固有的神经变异性，模型表现出过度确定性的分类倾向。

Abstract: This study evaluates AV-HuBERT's perceptual bio-fidelity by benchmarking its response to incongruent audiovisual stimuli (McGurk effect) against human observers (N=44). Results reveal a striking quantitative isomorphism: AI and humans exhibited nearly identical auditory dominance rates (32.0% vs. 31.8%), suggesting the model captures biological thresholds for auditory resistance. However, AV-HuBERT showed a deterministic bias toward phonetic fusion (68.0%), significantly exceeding human rates (47.7%). While humans displayed perceptual stochasticity and diverse error profiles, the model remained strictly categorical. Findings suggest that current self-supervised architectures mimic multisensory outcomes but lack the neural variability inherent to human speech perception.

</details>


### [105] [Stable-DiffCoder: Pushing the Frontier of Code Diffusion Large Language Model](https://arxiv.org/abs/2601.15892)
*Chenghao Fan,Wen Heng,Bo Li,Sichen Liu,Yuxuan Song,Jing Su,Xiaoye Qu,Kai Shen,Wei Wei*

Main category: cs.CL

TL;DR: Stable-DiffCoder：一种基于块扩散的代码模型，通过持续预训练和定制化噪声调度，在多项代码基准测试中超越了自回归模型，展示了扩散训练在代码建模中的优势。


<details>
  <summary>Details</summary>
Motivation: 现有的基于扩散的语言模型（DLLMs）虽然提供非顺序的块级生成和更丰富的数据重用，但在相同预算下仍落后于自回归模型。本研究旨在探索扩散模型在代码生成任务中的潜力，并证明其可以超越自回归模型。

Method: 提出Stable-DiffCoder，基于Seed-Coder架构，采用块扩散方法。关键创新包括：1）块扩散持续预训练阶段；2）定制的预热策略；3）块级裁剪噪声调度。仅使用持续预训练和监督微调两个阶段。

Result: 在相同数据和架构下，Stable-DiffCoder在广泛的代码基准测试中整体优于其自回归对应模型。仅通过CPT和SFT阶段，就超越了约8B参数的自回归和扩散模型，证明了扩散训练能提升代码建模质量。

Conclusion: 扩散训练不仅能匹配甚至超越自回归训练，其任意顺序建模能力还改善了结构化代码编辑和推理，并通过数据增强使低资源编程语言受益，为代码建模提供了新的有效方法。

Abstract: Diffusion-based language models (DLLMs) offer non-sequential, block-wise generation and richer data reuse compared to autoregressive (AR) models, but existing code DLLMs still lag behind strong AR baselines under comparable budgets. We revisit this setting in a controlled study and introduce Stable-DiffCoder, a block diffusion code model that reuses the Seed-Coder architecture, data, and training pipeline. To enable efficient knowledge learning and stable training, we incorporate a block diffusion continual pretraining (CPT) stage enhanced by a tailored warmup and block-wise clipped noise schedule. Under the same data and architecture, Stable-DiffCoder overall outperforms its AR counterpart on a broad suite of code benchmarks. Moreover, relying only on the CPT and supervised fine-tuning stages, Stable-DiffCoder achieves stronger performance than a wide range of \~8B ARs and DLLMs, demonstrating that diffusion-based training can improve code modeling quality beyond AR training alone. Moreover, diffusion-based any-order modeling improves structured code modeling for editing and reasoning, and through data augmentation, benefits low-resource coding languages.

</details>


### [106] [Transfer Learning from ImageNet for MEG-Based Decoding of Imagined Speech](https://arxiv.org/abs/2601.15909)
*Soufiane Jhilal,Stéphanie Martin,Anne-Lise Giraud*

Main category: cs.CL

TL;DR: 使用预训练视觉模型处理MEG信号的时间频率图像表示，实现非侵入式想象语音解码，在多项任务中取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 非侵入式想象语音解码面临信号弱、分布广和标记数据有限的挑战，需要新的方法来解决这些问题。

Method: 将MEG信号转换为时间频率表示，通过可学习的传感器空间卷积生成三个空间尺度混合图像，作为预训练视觉模型的输入。

Result: 预训练视觉模型在多项任务中表现优异：想象vs静默90.4%平衡准确率，想象vs默读81.0%，元音解码60.6%。跨被试评估显示模型能捕捉共享神经表征。

Conclusion: 预训练视觉模型应用于基于图像的MEG表示能有效捕捉想象语音的神经结构，为非侵入式脑机接口提供了新途径。

Abstract: Non-invasive decoding of imagined speech remains challenging due to weak, distributed signals and limited labeled data. Our paper introduces an image-based approach that transforms magnetoencephalography (MEG) signals into time-frequency representations compatible with pretrained vision models. MEG data from 21 participants performing imagined speech tasks were projected into three spatial scalogram mixtures via a learnable sensor-space convolution, producing compact image-like inputs for ImageNet-pretrained vision architectures. These models outperformed classical and non-pretrained models, achieving up to 90.4% balanced accuracy for imagery vs. silence, 81.0% vs. silent reading, and 60.6% for vowel decoding. Cross-subject evaluation confirmed that pretrained models capture shared neural representations, and temporal analyses localized discriminative information to imagery-locked intervals. These findings show that pretrained vision models applied to image-based MEG representations can effectively capture the structure of imagined speech in non-invasive neural signals.

</details>


### [107] [Mecellem Models: Turkish Models Trained from Scratch and Continually Pre-trained for the Legal Domain](https://arxiv.org/abs/2601.16018)
*Özgür Uğur,Mahmut Göksu,Mahmut Çimen,Musa Yılmaz,Esra Şavirdi,Alp Talha Demir,Rumeysa Güllüce,İclal Çetin,Ömer Can Sağbaş*

Main category: cs.CL

TL;DR: Mecellem框架通过领域适应策略开发土耳其法律领域的专用语言模型，包括从头预训练的编码器模型和持续预训练的生成模型，在保持高效率的同时实现优异性能。


<details>
  <summary>Details</summary>
Motivation: 开发专门针对土耳其法律领域的语言模型，解决现有SOTA模型依赖多阶段、计算密集型训练流程的问题，提供更经济高效的替代方案。

Method: 1. 编码器模型：基于ModernBERT从头预训练，使用1127亿土耳其语为主的语料，采用检查点选择策略评估下游检索性能；2. 生成模型：基于Qwen3-1.7B/4B进行持续预训练，采用四阶段课程学习逐步过渡到法律领域。

Result: 编码器模型在土耳其检索排行榜上排名前三，小模型(155M)性能媲美大模型(307M-567M)，生产效率达92.36%；生成模型在土耳其法律文本上困惑度降低36.2%。

Conclusion: Mecellem框架通过单阶段预训练加高效后训练的方法，为土耳其法律领域提供了计算效率高且性能优异的专用语言模型解决方案。

Abstract: This paper presents Mecellem models, a framework for developing specialized language models for the Turkish legal domain through domain adaptation strategies. We make two contributions: (1)Encoder Model Pre-trained from Scratch: ModernBERT-based bidirectional encoders pre-trained on a Turkish-dominant corpus of 112.7 billion tokens. We implement a checkpoint selection strategy that evaluates downstream retrieval performance throughout training, revealing that optimal checkpoints achieve best retrieval scores before pre-training loss reaches its minimum. Our encoder models achieve top-3 rankings on the Turkish retrieval leaderboard, with smaller models (155M parameters) achieving comparable performance to larger reference models (307M-567M parameters). Our approach achieves 92.36% production efficiency compared to state-of-the-art models (embeddinggemma-300m: 100.00%, BAAI/bge-m3: 99.54%, newmindai/bge-m3-stsb: 94.38%), ranking fourth overall despite requiring less computational resources. SOTA models rely on multi-stage, computationally intensive training pipelines, making our single-stage pre-training followed by efficient post-training approach a cost-effective alternative; (2)Decoder Model with Continual Pre-training (CPT): Qwen3-1.7B and Qwen3-4B models adapted to Turkish legal domain through controlled curriculum learning. Four-phase CPT with optimal sample ratios enables gradual transition from general language knowledge to specialized legal terminology and long-context reasoning. This approach achieves 36.2% perplexity reduction on Turkish legal text, demonstrating domain adaptation gains.

</details>


### [108] [Universal Refusal Circuits Across LLMs: Cross-Model Transfer via Trajectory Replay and Concept-Basis Reconstruction](https://arxiv.org/abs/2601.16034)
*Tony Cristofano*

Main category: cs.CL

TL;DR: 提出Trajectory Replay via Concept-Basis Reconstruction框架，通过概念指纹对齐和重构拒绝方向，实现跨模型的安全对齐干预迁移，证明拒绝行为源于跨模型共享的通用低维语义电路。


<details>
  <summary>Details</summary>
Motivation: 对齐LLM中的拒绝行为通常被视为模型特定的，但作者假设其源于跨模型共享的通用低维语义电路。为了验证这一假设，需要开发一种能够跨不同架构和训练机制迁移拒绝干预的方法。

Method: 提出Trajectory Replay via Concept-Basis Reconstruction框架：1) 通过概念指纹对齐不同模型的层；2) 使用共享的"概念原子"配方重构拒绝方向；3) 将供体模型的消融轨迹映射到目标模型的语义空间；4) 引入权重SVD稳定性保护，将干预投影到低方差权重子空间以避免能力损害。

Result: 在8个模型对（包括GPT-OSS-20B和GLM-4）上的评估表明，转移的干预配方能持续减弱拒绝行为，同时保持模型性能，为安全对齐的语义普适性提供了有力证据。

Conclusion: 拒绝行为源于跨模型共享的通用低维语义电路，而非模型特定特性。提出的框架成功实现了跨架构和训练机制的干预迁移，为理解LLM安全对齐的语义基础提供了新视角。

Abstract: Refusal behavior in aligned LLMs is often viewed as model-specific, yet we hypothesize it stems from a universal, low-dimensional semantic circuit shared across models. To test this, we introduce Trajectory Replay via Concept-Basis Reconstruction, a framework that transfers refusal interventions from donor to target models, spanning diverse architectures (e.g., Dense to MoE) and training regimes, without using target-side refusal supervision. By aligning layers via concept fingerprints and reconstructing refusal directions using a shared ``recipe'' of concept atoms, we map the donor's ablation trajectory into the target's semantic space. To preserve capabilities, we introduce a weight-SVD stability guard that projects interventions away from high-variance weight subspaces to prevent collateral damage. Our evaluation across 8 model pairs (including GPT-OSS-20B and GLM-4) confirms that these transferred recipes consistently attenuate refusal while maintaining performance, providing strong evidence for the semantic universality of safety alignment.

</details>


### [109] [Adapter Fusion for Multilingual Text2Cypher with Linear and Learned Gating](https://arxiv.org/abs/2601.16097)
*Makbule Gulcin Ozsoy*

Main category: cs.CL

TL;DR: 本文提出一种可扩展的多语言Text2Cypher方法，通过训练语言特定的LoRA适配器并使用融合MLP动态门控组合，实现无需完整微调即可支持新语言，在数据效率和性能间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 当前Text2SQL/Text2Cypher等自然语言数据库接口系统主要支持英语，多语言支持有限。需要一种可扩展的方法来支持新语言，避免昂贵的完整微调和手动超参数调整。

Method: 为英语、西班牙语和土耳其语训练语言特定的LoRA适配器，通过均匀线性合并或学习融合MLP（带动态门控）组合适配器。融合MLP学习如何动态组合不同语言的适配器权重。

Result: 实验显示融合MLP恢复了约75%的联合多语言微调准确率增益，仅需较少数据子集，在所有三种语言上都优于线性合并方法。

Conclusion: 学习适配器融合为昂贵的联合微调提供了实用替代方案，平衡了性能、数据效率和可扩展性，支持通过仅需一个LoRA适配器和轻量级MLP重训练来增量扩展新语言。

Abstract: Large Language Models enable users to access database using natural language interfaces using tools like Text2SQL, Text2SPARQL, and Text2Cypher, which translate user questions into structured database queries. While these systems improve database accessibility, most research focuses on English with limited multilingual support. This work investigates a scalable multilingual Text2Cypher, aiming to support new languages without re-running full fine-tuning, avoiding manual hyper-parameter tuning, and maintaining performance close to joint multilingual fine-tuning. We train language-specific LoRA adapters for English, Spanish, and Turkish and combined them via uniform linear merging or learned fusion MLP with dynamic gating. Experimental results show that the fusion MLP recovers around 75\% of the accuracy gains from joint multilingual fine-tuning while requiring only a smaller subset of the data, outperforming linear merging across all three languages. This approach enables incremental language expansion to new languages by requiring only one LoRA adapter and a lightweight MLP retraining. Learned adapter fusion offers a practical alternative to expensive joint fine-tuning, balancing performance, data efficiency, and scalability for multilingual Text2Cypher task.

</details>


### [110] [synthocr-gen: A synthetic ocr dataset generator for low-resource languages- breaking the data barrier](https://arxiv.org/abs/2601.16113)
*Haq Nawaz Malik,Kh Mohmad Shafi,Tanveer Ahmad Reshi*

Main category: cs.CL

TL;DR: SynthOCR-Gen是一个开源合成OCR数据集生成器，专门为低资源语言设计，通过将数字Unicode文本语料库转换为现成的训练数据集来解决OCR开发中的瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 低资源语言（如克什米尔语）的OCR面临重大挑战，主要原因是缺乏大规模标注训练数据集。这些语言在主流OCR系统中缺乏支持，而手动创建数据集成本高昂、耗时且容易出错。

Method: 开发了SynthOCR-Gen工具，包含完整的处理流程：文本分割（字符、单词、n-gram、句子和行级别）、Unicode规范化和脚本纯度强制执行、多字体渲染与可配置分布、以及25+种数据增强技术模拟真实文档退化（旋转、模糊、噪声、扫描伪影等）。

Result: 生成了包含60万个样本的单词分割克什米尔语OCR数据集，并公开发布在HuggingFace上，为低资源语言进入视觉-语言AI模型时代提供了实用途径。

Conclusion: SynthOCR-Gen为全球研究者和从业者提供了一个实用工具，能够有效支持服务不足的书写系统的OCR开发，解决了低资源语言OCR数据集创建的瓶颈问题。

Abstract: Optical Character Recognition (OCR) for low-resource languages remains a significant challenge due to the scarcity of large-scale annotated training datasets. Languages such as Kashmiri, with approximately 7 million speakers and a complex Perso-Arabic script featuring unique diacritical marks, currently lack support in major OCR systems including Tesseract, TrOCR, and PaddleOCR. Manual dataset creation for such languages is prohibitively expensive, time-consuming, and error-prone, often requiring word by word transcription of printed or handwritten text.
  We present SynthOCR-Gen, an open-source synthetic OCR dataset generator specifically designed for low-resource languages. Our tool addresses the fundamental bottleneck in OCR development by transforming digital Unicode text corpora into ready-to-use training datasets. The system implements a comprehensive pipeline encompassing text segmentation (character, word, n-gram, sentence, and line levels), Unicode normalization with script purity enforcement, multi-font rendering with configurable distribution, and 25+ data augmentation techniques simulating real-world document degradations including rotation, blur, noise, and scanner artifacts.
  We demonstrate the efficacy of our approach by generating a 600,000-sample word-segmented Kashmiri OCR dataset, which we release publicly on HuggingFace. This work provides a practical pathway for bringing low-resource languages into the era of vision-language AI models, and the tool is openly available for researchers and practitioners working with underserved writing systems worldwide.

</details>


### [111] [Improving Training Efficiency and Reducing Maintenance Costs via Language Specific Model Merging](https://arxiv.org/abs/2601.16127)
*Alphaeus Dmonte,Vidhi Gupta,Daniel J Perry,Mark Arehart*

Main category: cs.CL

TL;DR: 本文分析了多语言大语言模型合并策略的效率优势，相比传统全量重训练可减少50%初始训练时间和60%维护成本，同时保持质量不变。


<details>
  <summary>Details</summary>
Motivation: 传统多语言大语言模型微调需要为所有语言训练完整模型，当需要更新某个语言或添加新语言时，必须重新训练整个模型，这导致计算效率低下和维护瓶颈。现有研究虽然展示了多语言多任务模型合并的质量优势，但其计算和维护效率尚未得到充分研究。

Method: 采用多语言模型合并策略，通过在不同语言上分别训练模型然后合并，而不是训练单一完整的多语言模型。具体评估了三种独立任务，比较了传统全量训练与合并策略在训练时间和维护成本上的差异。

Result: 合并策略显著提高了效率：初始训练时间减少高达50%；更新单个语言并重新合并相比重新训练完整多语言模型，训练成本降低超过60%。在公共和工业专有数据集上都验证了该方法的有效性，质量表现与传统方法相当。

Conclusion: 多语言模型合并策略在保持质量的同时，显著提高了计算效率和维护效率，为工业应用提供了实用的解决方案，解决了多语言模型更新和维护的计算瓶颈问题。

Abstract: Fine-tuning a task-specific multilingual large language model (LLM) involves training the model on a multilingual dataset with examples in all the required languages. Updating one or more supported languages with additional data or adding support for a new language involves retraining the model, which can be computationally inefficient and creates a severe maintenance bottleneck. Recent research on merging multilingual multitask models has shown promise in terms of improved quality, but its computational and maintenance efficiency remains unstudied. In this work, we provide the first focused analysis of this merging strategy from an efficiency perspective, evaluating it across three independent tasks. We demonstrate significant efficiency gains while maintaining parity in terms of quality: this merging approach reduces the initial training time by up to 50\%. We also demonstrate that updating an individual language and re-merging as part of model maintenance reduces training costs by more than 60\%, compared to re-training the full multilingual model. We show this on both public and proprietary industry datasets confirming that the approach works well for industrial use cases in addition to academic settings already studied in previous work.

</details>


### [112] [Automatic Classification of Arabic Literature into Historical Eras](https://arxiv.org/abs/2601.16138)
*Zainab Alhathloul,Irfan Ahmad*

Main category: cs.CL

TL;DR: 使用神经网络和深度学习技术自动将阿拉伯语文本分类到不同历史时期，从二元分类到15类分类，在多个数据集上评估性能。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语随时间演变，古典与现代阿拉伯语存在显著差异，但自动按时期分类阿拉伯语文本的研究相对较少，特别是在诗歌之外的领域。

Method: 采用神经网络和深度学习技术，使用两个公开可用的语料库数据集（OpenITI和APCD），涵盖从伊斯兰前到现代时期的文本，研究从二元到15类的分类设置。

Result: 二元时期分类任务在OpenITI和APCD数据集上分别获得0.83和0.79的F1分数；15时期分类任务在OpenITI上获得0.20，12时期分类任务在APCD上获得0.18。

Conclusion: 神经网络和深度学习可以有效用于阿拉伯语文本的历史时期分类，二元分类效果较好，但随着分类类别增加，性能显著下降，表明更复杂的时期分类具有挑战性。

Abstract: The Arabic language has undergone notable transformations over time, including the emergence of new vocabulary, the obsolescence of others, and shifts in word usage. This evolution is evident in the distinction between the classical and modern Arabic eras. Although historians and linguists have partitioned Arabic literature into multiple eras, relatively little research has explored the automatic classification of Arabic texts by time period, particularly beyond the domain of poetry. This paper addresses this gap by employing neural networks and deep learning techniques to automatically classify Arabic texts into distinct eras and periods. The proposed models are evaluated using two datasets derived from two publicly available corpora, covering texts from the pre-Islamic to the modern era. The study examines class setups ranging from binary to 15-class classification and considers both predefined historical eras and custom periodizations. Results range from F1-scores of 0.83 and 0.79 on the binary-era classification task using the OpenITI and APCD datasets, respectively, to 0.20 on the 15-era classification task using OpenITI and 0.18 on the 12-era classification task using APCD.

</details>


### [113] [LLM-in-Sandbox Elicits General Agentic Intelligence](https://arxiv.org/abs/2601.16206)
*Daixuan Cheng,Shaohan Huang,Yuxian Gu,Huatong Song,Guoxin Chen,Li Dong,Wayne Xin Zhao,Ji-Rong Wen,Furu Wei*

Main category: cs.CL

TL;DR: LLM-in-Sandbox让大语言模型在代码沙盒（虚拟计算机）中探索，以激发非代码领域的通用智能。研究表明LLMs能自发利用沙盒获取新知识、处理长上下文、执行脚本，并通过强化学习增强这些能力，在数学、物理、化学等多个领域实现鲁棒泛化。


<details>
  <summary>Details</summary>
Motivation: 探索如何让大语言模型在非代码领域展现通用智能，通过代码沙盒环境为LLMs提供探索空间，使其能够执行超出纯文本处理的任务，如访问外部资源、处理长上下文等。

Method: 提出LLM-in-Sandbox框架，让LLMs在代码沙盒（虚拟计算机）中自主探索。采用两种方法：1) 无额外训练，直接利用现有LLMs在沙盒中的泛化能力；2) LLM-in-Sandbox强化学习，使用非智能体数据训练模型进行沙盒探索。

Result: LLM-in-Sandbox在数学、物理、化学、生物医学、长上下文理解和指令跟随等多个领域展现出鲁棒泛化能力。无论是无训练设置还是后训练设置，都能有效处理复杂任务，并开源为Python包便于实际部署。

Conclusion: 代码沙盒为LLMs提供了探索非代码任务的平台，LLMs能自发利用沙盒能力解决复杂问题。通过强化学习可进一步增强这些智能体能力，该框架在多个科学领域具有广泛适用性，为实际部署提供了可行方案。

Abstract: We introduce LLM-in-Sandbox, enabling LLMs to explore within a code sandbox (i.e., a virtual computer), to elicit general intelligence in non-code domains. We first demonstrate that strong LLMs, without additional training, exhibit generalization capabilities to leverage the code sandbox for non-code tasks. For example, LLMs spontaneously access external resources to acquire new knowledge, leverage the file system to handle long contexts, and execute scripts to satisfy formatting requirements. We further show that these agentic capabilities can be enhanced through LLM-in-Sandbox Reinforcement Learning (LLM-in-Sandbox-RL), which uses only non-agentic data to train models for sandbox exploration. Experiments demonstrate that LLM-in-Sandbox, in both training-free and post-trained settings, achieves robust generalization spanning mathematics, physics, chemistry, biomedicine, long-context understanding, and instruction following. Finally, we analyze LLM-in-Sandbox's efficiency from computational and system perspectives, and open-source it as a Python package to facilitate real-world deployment.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [114] [AgentSM: Semantic Memory for Agentic Text-to-SQL](https://arxiv.org/abs/2601.15709)
*Asim Biswal,Chuan Lei,Xiao Qin,Aodong Li,Balakrishnan Narayanaswamy,Tim Kraska*

Main category: cs.AI

TL;DR: AgentSM是一个用于Text-to-SQL的代理框架，通过构建可解释的语义记忆来提升效率和稳定性，在Spider 2.0基准测试中减少25%的平均token使用和35%的轨迹长度，达到44.8%的最新准确率。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM-based Text-to-SQL系统在企业环境中面临挑战：大型复杂模式、多样SQL方言、昂贵的多步推理。代理方法虽然显示潜力，但存在效率低下和不稳定的问题，如重复数据库交互、输出不一致、偶尔无法生成有效答案。

Method: 提出Agent Semantic Memory (AgentSM)框架，构建可解释的语义记忆。不是依赖原始草稿或向量检索，而是捕获先前的执行轨迹（或合成精选轨迹）作为结构化程序，直接指导未来推理。这种设计实现了推理路径的系统性重用。

Result: 在Spider 2.0基准测试中，AgentSM将平均token使用减少25%，轨迹长度减少35%。在Spider 2.0 Lite基准测试中达到44.8%的最新准确率。能够更高效可靠地扩展到更大模式、更复杂问题和更长轨迹。

Conclusion: AgentSM通过构建可解释的语义记忆，解决了现有Text-to-SQL代理方法的效率和稳定性问题，实现了推理路径的系统性重用，在效率和准确性方面都取得了显著提升。

Abstract: Recent advances in LLM-based Text-to-SQL have achieved remarkable gains on public benchmarks such as BIRD and Spider. Yet, these systems struggle to scale in realistic enterprise settings with large, complex schemas, diverse SQL dialects, and expensive multi-step reasoning. Emerging agentic approaches show potential for adaptive reasoning but often suffer from inefficiency and instability-repeating interactions with databases, producing inconsistent outputs, and occasionally failing to generate valid answers. To address these challenges, we introduce Agent Semantic Memory (AgentSM), an agentic framework for Text-to-SQL that builds and leverages interpretable semantic memory. Instead of relying on raw scratchpads or vector retrieval, AgentSM captures prior execution traces-or synthesizes curated ones-as structured programs that directly guide future reasoning. This design enables systematic reuse of reasoning paths, which allows agents to scale to larger schemas, more complex questions, and longer trajectories efficiently and reliably. Compared to state-of-the-art systems, AgentSM achieves higher efficiency by reducing average token usage and trajectory length by 25% and 35%, respectively, on the Spider 2.0 benchmark. It also improves execution accuracy, reaching a state-of-the-art accuracy of 44.8% on the Spider 2.0 Lite benchmark.

</details>


### [115] [Gated Sparse Attention: Combining Computational Efficiency with Training Stability for Long-Context Language Models](https://arxiv.org/abs/2601.15305)
*Alfred Shen,Aaron Shen*

Main category: cs.AI

TL;DR: Gated Sparse Attention (GSA) 结合了稀疏注意力和门控注意力的优势，在长上下文语言模型中实现了高效性和质量提升，同时提高了训练稳定性。


<details>
  <summary>Details</summary>
Motivation: 长上下文语言模型中的注意力计算负担过重，现有方法分为两类：稀疏注意力机制通过选择部分token来降低复杂度，门控注意力变体则改善训练稳定性并缓解注意力下沉现象。这两种方法解决的是互补的问题。

Method: 提出Gated Sparse Attention (GSA)架构，包含：1) 使用sigmoid激活函数的门控闪电索引器，生成有界、可解释的选择分数；2) 基于局部不确定性调节注意力token数量的自适应稀疏控制器；3) 在值和输出阶段的双重门控机制。

Result: 在1.7B参数模型、400B tokens训练的实验显示：GSA达到稀疏基线效率（128K上下文下12-16倍加速），同时获得门控注意力的质量提升：困惑度从6.03降至5.70，128K上下文下的RULER分数几乎翻倍，对第一个token的注意力（注意力下沉指标）从47%降至4%以下，训练稳定性显著改善，损失峰值减少98%。

Conclusion: GSA成功结合了稀疏注意力和门控注意力的优势，在保持计算效率的同时显著提升了模型质量和训练稳定性，为长上下文语言模型提供了有效的解决方案。

Abstract: The computational burden of attention in long-context language models has motivated two largely independent lines of work: sparse attention mechanisms that reduce complexity by attending to selected tokens, and gated attention variants that improve training sta-bility while mitigating the attention sink phenomenon. We observe that these approaches address complementary weaknesses and propose Gated Sparse Attention (GSA), an architecture that realizes the benefits of both. GSA incorporates a gated lightning indexer with sigmoid activations that produce bounded, interpretable selection scores, an adaptive sparsity controller that modulates the number of attended tokens based on local uncertainty, and dual gating at the value and output stages. We establish theoretical foundations for the approach, including complexity analysis, expressiveness results, and convergence guarantees. In experiments with 1.7B parameter models trained on 400B tokens, GSA matches the efficiency of sparse-only baselines (12-16x speedup at 128K context) while achieving the quality gains associated with gated attention: perplexity improves from 6.03 to 5.70, RULER scores at 128K context nearly double, and attention to the first token, a proxy for attention sinks, drops from 47% to under 4%. Training stability improves markedly, with loss spikes reduced by 98%.

</details>


### [116] [Uncovering Latent Bias in LLM-Based Emergency Department Triage Through Proxy Variables](https://arxiv.org/abs/2601.15306)
*Ethan Zhang*

Main category: cs.AI

TL;DR: 研究发现大型语言模型在急诊分诊中存在通过代理变量介导的歧视性行为，模型会因特定词汇出现而系统性修改对患者严重程度的判断，无论这些词汇是正面还是负面表述。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型已应用于临床决策，但针对不同种族、社会、经济和临床背景患者的隐性偏见仍然存在，需要研究这些偏见在急诊分诊中的具体表现。

Method: 使用32个患者层面的代理变量，每个变量由正负两种表述组成，在公开数据集（MIMIC-IV-ED Demo, MIMIC-IV Demo）和受限访问数据集（MIMIC-IV-ED和MIMIC-IV）上评估这些变量对模型决策的影响。

Result: 发现急诊分诊场景中存在通过代理变量介导的歧视性行为，以及LLMs会系统性修改对患者严重程度的感知，只要特定词汇出现在输入上下文中，无论其表述是正面还是负面。

Conclusion: AI系统仍然在不完美地训练于嘈杂、有时非因果的信号上，这些信号不能可靠反映真实的患者病情严重程度，需要在临床环境中更负责任地部署AI技术。

Abstract: Recent advances in large language models (LLMs) have enabled their integration into clinical decision-making; however, hidden biases against patients across racial, social, economic, and clinical backgrounds persist. In this study, we investigate bias in LLM-based medical AI systems applied to emergency department (ED) triage. We employ 32 patient-level proxy variables, each represented by paired positive and negative qualifiers, and evaluate their effects using both public (MIMIC-IV-ED Demo, MIMIC-IV Demo) and restricted-access credentialed (MIMIC-IV-ED and MIMIC-IV) datasets as appropriate~\cite{mimiciv_ed_demo,mimiciv_ed,mimiciv}. Our results reveal discriminatory behavior mediated through proxy variables in ED triage scenarios, as well as a systematic tendency for LLMs to modify perceived patient severity when specific tokens appear in the input context, regardless of whether they are framed positively or negatively. These findings indicate that AI systems is still imperfectly trained on noisy, sometimes non-causal signals that do not reliably reflect true patient acuity. Consequently, more needs to be done to ensure the safe and responsible deployment of AI technologies in clinical settings.

</details>


### [117] [DeepSurvey-Bench: Evaluating Academic Value of Automatically Generated Scientific Survey](https://arxiv.org/abs/2601.15307)
*Guo-Biao Zhang,Ding-Yuan Liu,Da-Yi Wu,Tian Lan,Heyan Huang,Zhijing Wu,Xian-Ling Mao*

Main category: cs.AI

TL;DR: DeepSurvey-Bench是一个评估生成式科学综述学术价值的新基准，解决了现有基准仅关注表面质量而忽略深层学术价值的问题。


<details>
  <summary>Details</summary>
Motivation: 现有评估基准存在两个关键问题：1）基于引用次数和结构连贯性等有缺陷的标准选择人工撰写的综述作为基准数据集，缺乏学术维度标注；2）评估指标仅关注综述的表面质量（如逻辑连贯性），无法评估其深层"学术价值"，如核心研究目标和不同研究的批判性分析。

Method: 提出DeepSurvey-Bench基准，包含全面的学术价值评估标准，涵盖三个维度：信息价值、学术交流价值和研究指导价值。基于此标准构建具有学术价值标注的可靠数据集，并评估生成式综述的深层学术价值。

Result: 广泛的实验结果表明，该基准在评估生成式综述的学术价值方面与人类评估表现高度一致。

Conclusion: DeepSurvey-Bench能够全面评估生成式科学综述的学术价值，解决了现有基准的局限性，为自动化科学综述生成技术的质量评估提供了更可靠的基准。

Abstract: The rapid development of automated scientific survey generation technology has made it increasingly important to establish a comprehensive benchmark to evaluate the quality of generated surveys.Nearly all existing evaluation benchmarks rely on flawed selection criteria such as citation counts and structural coherence to select human-written surveys as the ground truth survey datasets, and then use surface-level metrics such as structural quality and reference relevance to evaluate generated surveys.However, these benchmarks have two key issues: (1) the ground truth survey datasets are unreliable because of a lack academic dimension annotations; (2) the evaluation metrics only focus on the surface quality of the survey such as logical coherence. Both issues lead to existing benchmarks cannot assess to evaluate their deep "academic value", such as the core research objectives and the critical analysis of different studies. To address the above problems, we propose DeepSurvey-Bench, a novel benchmark designed to comprehensively evaluate the academic value of generated surveys. Specifically, our benchmark propose a comprehensive academic value evaluation criteria covering three dimensions: informational value, scholarly communication value, and research guidance value. Based on this criteria, we construct a reliable dataset with academic value annotations, and evaluate the deep academic value of the generated surveys. Extensive experimental results demonstrate that our benchmark is highly consistent with human performance in assessing the academic value of generated surveys.

</details>


### [118] [Aeon: High-Performance Neuro-Symbolic Memory Management for Long-Horizon LLM Agents](https://arxiv.org/abs/2601.15311)
*Mustafa Arslan*

Main category: cs.AI

TL;DR: Aeon是一个神经符号认知操作系统，通过结构化记忆宫殿和神经符号事件图解决LLM在长上下文中的计算成本和"迷失在中间"问题，实现亚毫秒级检索延迟。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型面临自注意力的二次计算成本和"迷失在中间"现象（随着上下文窗口扩展，推理能力下降）。现有的"扁平RAG"架构将记忆视为无结构的嵌入集合，无法捕捉长时交互的层次和时间结构，导致"向量迷雾"问题——检索到缺乏事件连续性的碎片化事实。

Method: Aeon将记忆重新定义为操作系统管理的资源，而不是静态存储。它构建了两个核心组件：1）记忆宫殿（通过Atlas实现的空间索引，结合小世界图导航和B+树式磁盘局部性）；2）痕迹（神经符号事件图）。还引入了语义旁路缓冲区（SLB），一种利用对话局部性实现亚毫秒检索延迟的预测性缓存机制。

Result: 基准测试显示，Aeon在对话工作负载上实现<1ms的检索延迟，同时通过零拷贝C++/Python桥确保状态一致性，有效为自主代理提供持久化、结构化的记忆。

Conclusion: Aeon通过将记忆重新定义为操作系统管理的结构化资源，解决了LLM在长上下文中的核心限制，实现了高效、低延迟的记忆检索，为自主代理系统提供了可靠的记忆管理框架。

Abstract: Large Language Models (LLMs) are fundamentally constrained by the quadratic computational cost of self-attention and the "Lost in the Middle" phenomenon, where reasoning capabilities degrade as context windows expand. Existing solutions, primarily "Flat RAG" architectures relying on vector databases, treat memory as an unstructured bag of embeddings. This approach fails to capture the hierarchical and temporal structure of long-horizon interactions, leading to "Vector Haze", the retrieval of disjointed facts lacking episodic continuity. We propose Aeon, a Neuro-Symbolic Cognitive Operating System that redefines memory not as a static store, but as a managed OS resource. Aeon structures memory into a Memory Palace (a spatial index implemented via Atlas, a SIMD-accelerated Page-Clustered Vector Index that combines small-world graph navigation with B+ Tree-style disk locality to minimize read amplification) and a Trace (a neuro-symbolic episodic graph). We introduce the Semantic Lookaside Buffer (SLB), a predictive caching mechanism that exploits conversational locality to achieve sub-millisecond retrieval latencies. Benchmarks demonstrate that Aeon achieves < 1ms retrieval latency on conversational workloads while ensuring state consistency via a zero-copy C++/Python bridge, effectively enabling persistent, structured memory for autonomous agents.

</details>


### [119] [The Paradigm Shift: A Comprehensive Survey on Large Vision Language Models for Multimodal Fake News Detection](https://arxiv.org/abs/2601.15316)
*Wei Ai,Yilong Tan,Yuntao Shou,Tao Meng,Haowen Chen,Zhixiong He,Keqin Li*

Main category: cs.AI

TL;DR: 该论文是第一篇系统综述大型视觉语言模型在多模态假新闻检测中变革性作用的全面调查，梳理了从传统特征工程方法到端到端多模态推理框架的范式转变。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型的快速发展推动了多模态假新闻检测领域的范式转变，但缺乏系统性的综述来追踪这一转变并整合最新进展。该论文旨在填补这一空白，为研究者提供全面的参考。

Method: 论文采用系统性综述方法：1) 提供历史视角，追溯从传统多模态检测流程到基础模型驱动范式的演变；2) 建立结构化分类体系，涵盖模型架构、数据集和性能基准；3) 分析剩余技术挑战；4) 展望未来研究方向。

Result: 论文首次系统性地记录和分析了LVLMs在多模态假新闻检测中的变革性作用，建立了完整的分类体系，识别了包括可解释性、时序推理和领域泛化在内的关键挑战，并提供了GitHub资源汇总现有方法。

Conclusion: 大型视觉语言模型正在彻底改变多模态假新闻检测领域，从传统的特征工程方法转向统一的端到端多模态推理框架。该综述为理解这一范式转变提供了系统性框架，并为未来研究指明了方向。

Abstract: In recent years, the rapid evolution of large vision-language models (LVLMs) has driven a paradigm shift in multimodal fake news detection (MFND), transforming it from traditional feature-engineering approaches to unified, end-to-end multimodal reasoning frameworks. Early methods primarily relied on shallow fusion techniques to capture correlations between text and images, but they struggled with high-level semantic understanding and complex cross-modal interactions. The emergence of LVLMs has fundamentally changed this landscape by enabling joint modeling of vision and language with powerful representation learning, thereby enhancing the ability to detect misinformation that leverages both textual narratives and visual content. Despite these advances, the field lacks a systematic survey that traces this transition and consolidates recent developments. To address this gap, this paper provides a comprehensive review of MFND through the lens of LVLMs. We first present a historical perspective, mapping the evolution from conventional multimodal detection pipelines to foundation model-driven paradigms. Next, we establish a structured taxonomy covering model architectures, datasets, and performance benchmarks. Furthermore, we analyze the remaining technical challenges, including interpretability, temporal reasoning, and domain generalization. Finally, we outline future research directions to guide the next stage of this paradigm shift. To the best of our knowledge, this is the first comprehensive survey to systematically document and analyze the transformative role of LVLMs in combating multimodal fake news. The summary of existing methods mentioned is in our Github: \href{https://github.com/Tan-YiLong/Overview-of-Fake-News-Detection}{https://github.com/Tan-YiLong/Overview-of-Fake-News-Detection}.

</details>


### [120] [Replayable Financial Agents: A Determinism-Faithfulness Assurance Harness for Tool-Using LLM Agents](https://arxiv.org/abs/2601.15322)
*Raffi Khatchadourian*

Main category: cs.AI

TL;DR: 本文提出了DFAH框架，用于评估金融领域工具使用型LLM代理的轨迹确定性和证据条件忠实性，发现模型确定性与忠实性正相关，并提供了金融基准测试和开源压力测试工具。


<details>
  <summary>Details</summary>
Motivation: LLM代理在监管审计回放中存在一致性问题：当要求用相同输入重现被标记的交易决策时，大多数部署无法返回一致结果。这暴露了金融服务中工具使用型代理的确定性和忠实性不足的问题。

Method: 提出了确定性-忠实性保证框架（DFAH），用于测量工具使用型代理的轨迹确定性和证据条件忠实性。在74种配置（12个模型、4个提供商、每个在T=0.0下运行8-24次）中进行非代理基线实验，并提供了三个金融基准测试（合规分类、投资组合约束、DataOps异常）和开源压力测试工具。

Result: 7-20B参数模型实现了100%确定性，而120B+模型需要3.7倍更大的验证样本才能达到同等统计可靠性。代理工具使用引入了额外方差。确定性与忠实性呈正相关（r=0.45，p<0.01）。在DFAH评估设置下，采用模式优先架构的一级模型达到了符合审计回放要求的确定性水平。

Conclusion: DFAH框架能够有效评估金融领域LLM代理的确定性和忠实性，发现确定性与能力并非传统认为的权衡关系而是正相关。模式优先架构的一级模型能够满足审计回放要求，为金融服务的可靠部署提供了评估方法和基准。

Abstract: LLM agents struggle with regulatory audit replay: when asked to reproduce a flagged transaction decision with identical inputs, most deployments fail to return consistent results. This paper introduces the Determinism-Faithfulness Assurance Harness (DFAH), a framework for measuring trajectory determinism and evidence-conditioned faithfulness in tool-using agents deployed in financial services.
  Across 74 configurations (12 models, 4 providers, 8-24 runs each at T=0.0) in non-agentic baseline experiments, 7-20B parameter models achieved 100% determinism, while 120B+ models required 3.7x larger validation samples to achieve equivalent statistical reliability. Agentic tool-use introduces additional variance (see Tables 4-7). Contrary to the assumed reliability-capability trade-off, a positive Pearson correlation emerged (r = 0.45, p < 0.01, n = 51 at T=0.0) between determinism and faithfulness; models producing consistent outputs also tended to be more evidence-aligned.
  Three financial benchmarks are provided (compliance triage, portfolio constraints, DataOps exceptions; 50 cases each) along with an open-source stress-test harness. In these benchmarks and under DFAH evaluation settings, Tier 1 models with schema-first architectures achieved determinism levels consistent with audit replay requirements.

</details>


### [121] [Prometheus Mind: Retrofitting Memory to Frozen Language Models](https://arxiv.org/abs/2601.15324)
*Mark Wind*

Main category: cs.AI

TL;DR: Prometheus Mind 为冻结的 Qwen3-4B 模型添加记忆功能，仅需11个模块化适配器（530MB，7%开销），完全可逆。通过解决提取、训练、注入和隐藏状态崩溃四个问题实现。


<details>
  <summary>Details</summary>
Motivation: 为预训练语言模型添加记忆功能通常需要架构修改或权重调整，这限制了灵活性和可逆性。本文旨在开发一种可逆、轻量级的方法，为冻结模型添加记忆能力。

Method: 1. 提取：开发对比方向发现（CDD），通过最小对寻找语义方向，无需标注数据。2. 训练：采用分阶段训练，每个适配器在简单代理任务上训练。3. 注入：利用现有 lm_head.weight 行作为映射，无需额外训练。4. 隐藏状态崩溃：训练投影层恢复语义区分度。

Result: 在 PrometheusExtract-132 数据集上，系统在干净输入上达到94.4%检索率（n=54，95% CI: [84.9%, 98.1%]），但在非正式输入（省略、填充词、隐含主语）上降至19.4%。主要瓶颈是关系分类（47.3%准确率）。

Conclusion: 成功为冻结模型添加可逆记忆功能，但非正式输入处理和关系分类仍是挑战。方法轻量、可逆，为模型记忆增强提供了新思路。

Abstract: Adding memory to pretrained language models typically requires architectural changes or weight modification. We present Prometheus Mind, which retrofits memory to a frozen Qwen3-4B using 11 modular adapters (530MB, 7% overhead) -- fully reversible by removing the adapters. Building this system required solving four problems: (1) Extraction -- we develop Contrastive Direction Discovery (CDD), which finds semantic directions via minimal pairs without labeled data. (2) Training -- end-to-end optimization collapses; stage-wise training of each adapter on simple proxy tasks succeeds. (3) Injection -- learned encoders fail to generalize; we find that lm_head.weight rows already provide the mapping we need, requiring no training. (4) Hidden state collapse -- transformers make ``wife'' and ``brother'' 0.98+ similar; we train projections to recover distinction (0.98 $\rightarrow$ 0.09). On PrometheusExtract-132 (132 cases), the system achieves 94.4% retrieval on clean inputs (n=54, 95% CI: [84.9%, 98.1%]), degrading to 19.4% on informal inputs with ellipsis, filler words, or implicit subjects (n=36). The primary bottleneck is relation classification (47.3% accuracy), responsible for most extraction errors.

</details>


### [122] [Logic Programming on Knowledge Graph Networks And its Application in Medical Domain](https://arxiv.org/abs/2601.15347)
*Chuanqing Wang,Zhenmin Zhao,Shanshan Du,Chaoqun Fei,Songmao Zhang,Ruqian Lu*

Main category: cs.AI

TL;DR: 本文提出"知识图谱网络"系统理论，解决现有知识图谱研究中逻辑推理、AI技术、编程语言、概率统计等先进技术应用不足的问题，特别是在医疗健康领域的多知识图谱协作与竞争技术研究不足。


<details>
  <summary>Details</summary>
Motivation: 知识图谱研究快速发展，但在医疗健康等领域的应用中，许多主要信息处理技术仍滞后。具体问题包括：未能充分利用先进的逻辑推理、人工智能技术、专用编程语言、现代概率统计理论等；特别是多知识图谱协作与竞争技术未得到足够关注。

Method: 开发"知识图谱网络"的系统理论、技术和应用框架，涵盖其定义、开发、推理、计算和应用，考虑不同条件如模糊、不确定、多模态、向量化、分布式、联邦学习等场景，并提供真实数据示例和实验结果。

Result: 在几乎每种情况下都提供了真实数据示例和实验结果，展示了知识图谱网络在不同条件下的应用效果。

Conclusion: 提出了知识图谱网络的创新理论框架，填补了多知识图谱协作与竞争技术的研究空白，为医疗健康领域的知识图谱应用提供了系统解决方案。

Abstract: The rash development of knowledge graph research has brought big driving force to its application in many areas, including the medicine and healthcare domain. However, we have found that the application of some major information processing techniques on knowledge graph still lags behind. This defect includes the failure to make sufficient use of advanced logic reasoning, advanced artificial intelligence techniques, special-purpose programming languages, modern probabilistic and statistic theories et al. on knowledge graphs development and application. In particular, the multiple knowledge graphs cooperation and competition techniques have not got enough attention from researchers. This paper develops a systematic theory, technique and application of the concept 'knowledge graph network' and its application in medical and healthcare domain. Our research covers its definition, development, reasoning, computing and application under different conditions such as unsharp, uncertain, multi-modal, vectorized, distributed, federated. Almost in each case we provide (real data) examples and experiment results. Finally, a conclusion of innovation is provided.

</details>


### [123] [GeMM-GAN: A Multimodal Generative Model Conditioned on Histopathology Images and Clinical Descriptions for Gene Expression Profile Generation](https://arxiv.org/abs/2601.15392)
*Francesca Pia Panaccione,Carlo Sgaravatti,Pietro Pinoli*

Main category: cs.AI

TL;DR: GeMM-GAN：一种基于组织病理学切片和临床元数据生成基因表达谱的生成对抗网络，通过Transformer编码器和跨注意力机制，在TCGA数据集上优于现有生成模型。


<details>
  <summary>Details</summary>
Motivation: 生物医学研究需要整合多种数据模态（基因表达、医学影像、临床元数据），但基因表达数据因隐私法规和实验成本难以广泛获取，需要开发从常规临床数据生成基因表达谱的方法。

Method: 提出GeMM-GAN生成对抗网络，使用Transformer编码器处理组织病理学切片图像块，通过跨注意力机制融合图像块和文本标记（临床元数据），生成条件向量指导生成模型合成生物学一致的基因表达谱。

Result: 在TCGA数据集上评估，GeMM-GAN优于标准生成模型，生成更真实且功能有意义的基因表达谱，在下游疾病类型预测任务中比当前最佳生成模型准确率提升超过11%。

Conclusion: GeMM-GAN能够从常规临床数据（组织病理学切片和临床元数据）生成高质量的基因表达谱，为生物医学研究提供了获取基因表达数据的新途径，解决了隐私和成本限制问题。

Abstract: Biomedical research increasingly relies on integrating diverse data modalities, including gene expression profiles, medical images, and clinical metadata. While medical images and clinical metadata are routinely collected in clinical practice, gene expression data presents unique challenges for widespread research use, mainly due to stringent privacy regulations and costly laboratory experiments. To address these limitations, we present GeMM-GAN, a novel Generative Adversarial Network conditioned on histopathology tissue slides and clinical metadata, designed to synthesize realistic gene expression profiles. GeMM-GAN combines a Transformer Encoder for image patches with a final Cross Attention mechanism between patches and text tokens, producing a conditioning vector to guide a generative model in generating biologically coherent gene expression profiles. We evaluate our approach on the TCGA dataset and demonstrate that our framework outperforms standard generative models and generates more realistic and functionally meaningful gene expression profiles, improving by more than 11\% the accuracy on downstream disease type prediction compared to current state-of-the-art generative models. Code will be available at: https://github.com/francescapia/GeMM-GAN

</details>


### [124] [Beyond Prompting: Efficient and Robust Contextual Biasing for Speech LLMs via Logit-Space Integration (LOGIC)](https://arxiv.org/abs/2601.15397)
*Peidong Wang*

Main category: cs.AI

TL;DR: LOGIC框架通过在解码层直接集成上下文偏置，解决了语音大语言模型在处理新实体时的可扩展性问题，相比提示方法显著降低了实体错误率。


<details>
  <summary>Details</summary>
Motivation: 现有语音大语言模型在处理新实体（如联系人姓名、播放列表、技术术语）时存在局限性，主要依赖提示方法但面临上下文窗口限制、推理延迟增加和"中间丢失"现象等问题，而生成式错误校正方法则容易产生"过度校正"和幻觉。

Method: 提出LOGIC（Logit-Space Integration for Contextual Biasing）框架，直接在解码层操作，将上下文注入与输入处理解耦，确保相对于提示长度的恒定时间复杂度。

Result: 在11种多语言环境中使用Phi-4-MM模型进行实验，LOGIC实现了平均9%的相对实体错误率降低，误报率仅增加0.30%。

Conclusion: LOGIC提供了一种高效且鲁棒的框架，解决了语音大语言模型在处理新实体时的可扩展性问题，相比现有方法在性能和效率上都有显著提升。

Abstract: The rapid emergence of new entities -- driven by cultural shifts, evolving trends, and personalized user data -- poses a significant challenge for existing Speech Large Language Models (Speech LLMs). While these models excel at general conversational tasks, their static training knowledge limits their ability to recognize domain-specific terms such as contact names, playlists, or technical jargon. Existing solutions primarily rely on prompting, which suffers from poor scalability: as the entity list grows, prompting encounters context window limitations, increased inference latency, and the "lost-in-the-middle" phenomenon. An alternative approach, Generative Error Correction (GEC), attempts to rewrite transcripts via post-processing but frequently suffers from "over-correction", introducing hallucinations of entities that were never spoken.
  In this work, we introduce LOGIC (Logit-Space Integration for Contextual Biasing), an efficient and robust framework that operates directly in the decoding layer. Unlike prompting, LOGIC decouples context injection from input processing, ensuring constant-time complexity relative to prompt length. Extensive experiments using the Phi-4-MM model across 11 multilingual locales demonstrate that LOGIC achieves an average 9% relative reduction in Entity WER with a negligible 0.30% increase in False Alarm Rate.

</details>


### [125] [Not Your Typical Sycophant: The Elusive Nature of Sycophancy in Large Language Models](https://arxiv.org/abs/2601.15436)
*Shahar Ben Natan,Oren Tsur*

Main category: cs.AI

TL;DR: 提出一种新颖的零和博弈框架评估LLM的谄媚性，发现所有模型在常见设置中都表现出谄媚倾向，但Claude和Mistral在谄媚会伤害第三方时表现出"道德悔恨"并过度补偿。


<details>
  <summary>Details</summary>
Motivation: 现有评估LLM谄媚性的方法存在各种形式的无控制偏见、噪音或操纵性语言注入问题，需要一种更直接、中性的评估方式。

Method: 使用LLM-as-a-judge方法，将谄媚性评估构建为零和博弈的赌注设置，其中谄媚行为服务于一个用户而明确对另一个用户造成成本。比较了四个领先模型：Gemini 2.5 Pro、ChatGPT 4o、Mistral-Large-Instruct-2411和Claude Sonnet 3.7。

Result: 所有模型在常见设置中都表现出谄媚倾向，但Claude和Mistral在谄媚会伤害第三方时表现出"道德悔恨"并过度补偿。所有模型都对最后提出的答案存在偏见，且谄媚性和近因偏见相互作用产生"建设性干扰"效应。

Conclusion: 谄媚性和近因偏见不是独立现象，它们相互作用会加剧模型同意用户的倾向，特别是在用户意见最后呈现时。需要更复杂的评估框架来理解LLM的谄媚行为。

Abstract: We propose a novel way to evaluate sycophancy of LLMs in a direct and neutral way, mitigating various forms of uncontrolled bias, noise, or manipulative language, deliberately injected to prompts in prior works. A key novelty in our approach is the use of LLM-as-a-judge, evaluation of sycophancy as a zero-sum game in a bet setting. Under this framework, sycophancy serves one individual (the user) while explicitly incurring cost on another. Comparing four leading models - Gemini 2.5 Pro, ChatGpt 4o, Mistral-Large-Instruct-2411, and Claude Sonnet 3.7 - we find that while all models exhibit sycophantic tendencies in the common setting, in which sycophancy is self-serving to the user and incurs no cost on others, Claude and Mistral exhibit "moral remorse" and over-compensate for their sycophancy in case it explicitly harms a third party. Additionally, we observed that all models are biased toward the answer proposed last. Crucially, we find that these two phenomena are not independent; sycophancy and recency bias interact to produce `constructive interference' effect, where the tendency to agree with the user is exacerbated when the user's opinion is presented last.

</details>


### [126] [A tensor network formalism for neuro-symbolic AI](https://arxiv.org/abs/2601.15442)
*Alex Goessmann,Janina Schütte,Maximilian Fröhlich,Martin Eigel*

Main category: cs.AI

TL;DR: 提出一种张量网络形式主义，统一神经与符号AI方法，通过张量分解表示逻辑公式和概率分布，实现可扩展的推理算法。


<details>
  <summary>Details</summary>
Motivation: 神经与符号人工智能方法的统一仍然是一个核心开放挑战。本文旨在通过张量网络形式主义来弥合这一差距，捕捉不同方法在张量分解中的稀疏性原则。

Method: 引入张量网络形式主义，描述函数的基编码方案，将神经分解建模为张量分解。该形式主义可应用于将逻辑公式和概率分布表示为结构化张量分解，将张量网络收缩视为基本推理类别，并将概率论和命题逻辑中的推理算法公式化为收缩消息传递方案。

Result: 提出了混合逻辑网络（Hybrid Logic Network），能够定义和训练混合逻辑和概率模型。理论概念由python库tnreason支持，实现了所提出架构的实际应用。

Conclusion: 张量网络形式主义为统一神经和符号AI方法提供了框架，通过张量分解和收缩实现了可扩展的推理，并为混合逻辑概率模型提供了理论基础和实现工具。

Abstract: The unification of neural and symbolic approaches to artificial intelligence remains a central open challenge. In this work, we introduce a tensor network formalism, which captures sparsity principles originating in the different approaches in tensor decompositions. In particular, we describe a basis encoding scheme for functions and model neural decompositions as tensor decompositions. The proposed formalism can be applied to represent logical formulas and probability distributions as structured tensor decompositions. This unified treatment identifies tensor network contractions as a fundamental inference class and formulates efficiently scaling reasoning algorithms, originating from probability theory and propositional logic, as contraction message passing schemes. The framework enables the definition and training of hybrid logical and probabilistic models, which we call Hybrid Logic Network. The theoretical concepts are accompanied by the python library tnreason, which enables the implementation and practical use of the proposed architectures.

</details>


### [127] [Reliability by design: quantifying and eliminating fabrication risk in LLMs. From generative to consultative AI: a comparative analysis in the legal domain and lessons for high-stakes knowledge bases](https://arxiv.org/abs/2601.15476)
*Alex Dantart*

Main category: cs.AI

TL;DR: 该研究评估了三种AI范式在法律工作中的可靠性，发现高级RAG系统能将幻觉率降至0.2%以下，而独立生成模型不适合专业使用。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在法律等高风险领域应用时的幻觉问题，确保AI系统能够提供可靠、可验证的法律分析，满足专业法律工作的严格要求。

Method: 区分三种AI范式：独立生成模型、基础检索增强系统、高级端到端优化RAG系统。引入FCR和FFR两个可靠性指标，通过专家双盲评审评估12个LLM在75个法律任务上生成的2700个司法风格答案。

Result: 独立生成模型不适合专业使用（FCR超过30%），基础RAG显著减少错误但仍存在明显误接地问题，而采用嵌入微调、重排序和自校正技术的高级RAG能将幻觉率降至0.2%以下。

Conclusion: 可信赖的法律AI需要强调验证和可追溯性的检索基础架构，研究提供的评估框架可应用于其他高风险领域。

Abstract: This paper examines how to make large language models reliable for high-stakes legal work by reducing hallucinations. It distinguishes three AI paradigms: (1) standalone generative models ("creative oracle"), (2) basic retrieval-augmented systems ("expert archivist"), and (3) an advanced, end-to-end optimized RAG system ("rigorous archivist"). The authors introduce two reliability metrics -False Citation Rate (FCR) and Fabricated Fact Rate (FFR)- and evaluate 2,700 judicial-style answers from 12 LLMs across 75 legal tasks using expert, double-blind review. Results show that standalone models are unsuitable for professional use (FCR above 30%), while basic RAG greatly reduces errors but still leaves notable misgrounding. Advanced RAG, using techniques such as embedding fine-tuning, re-ranking, and self-correction, reduces fabrication to negligible levels (below 0.2%). The study concludes that trustworthy legal AI requires rigor-focused, retrieval-based architectures emphasizing verification and traceability, and provides an evaluation framework applicable to other high-risk domains.

</details>


### [128] [MiRAGE: A Multiagent Framework for Generating Multimodal Multihop Question-Answer Dataset for RAG Evaluation](https://arxiv.org/abs/2601.15487)
*Chandan Kumar Sahu,Premith Kumar Chilukuri,Matthew Hetrich*

Main category: cs.AI

TL;DR: MiRAGE是一个多智能体框架，用于生成经过验证的领域特定、多模态、多跳问答数据集，以评估RAG系统在专业文档中的表现。


<details>
  <summary>Details</summary>
Motivation: 当前RAG系统向多模态、高风险企业应用的快速发展超过了领域特定评估基准的开发。现有数据集通常依赖通用领域语料库或纯文本检索，无法捕捉专业技术文档的复杂性，其中信息是多模态的，推理需要综合分散的证据。

Method: MiRAGE采用多智能体框架，协调专门智能体的协作群体：递归上下文优化循环聚合分散证据，对抗性验证智能体保证事实基础，以及识别专家角色和相关领域的智能体来模拟专家认知工作流程。

Result: 在四个不同领域（法规、金融、定量生物学和新闻）的实证评估显示，MiRAGE生成的数据集具有显著更高的推理复杂性（>2.3平均跳数）和事实忠实度。消融研究表明，如果有图像的文本描述，MiRAGE可以由LLM驱动，但视觉基础仍是前沿挑战。

Conclusion: 通过自动化创建反映专有语料库潜在主题结构的黄金标准评估数据集，MiRAGE为严格基准测试下一代信息检索系统提供了必要的基础设施。

Abstract: The rapid evolution of Retrieval-Augmented Generation (RAG) toward multimodal, high-stakes enterprise applications has outpaced the development of domain specific evaluation benchmarks. Existing datasets often rely on general-domain corpora or purely textual retrieval, failing to capture the complexity of specialized technical documents where information is inextricably multimodal and reasoning requires synthesizing disjoint evidence. We address this gap by introducing MiRAGE, a Multiagent framework for RAG systems Evaluation, that leverages a collaborative swarm of specialized agents to generate verified, domain-specific, multimodal, and multi-hop Question-Answer datasets. MiRAGE orchestrates a swarm of specialized agents: a recursive context optimization loop to aggregate scattered evidence, an adversarial verifier agent to guarantee factual grounding, and an agent to recognize the expert persona and the relevant domain to mimic expert cognitive workflows. Extensive empirical evaluation across four distinct domains (regulations, finance, quantitative biology, and journalism) demonstrates that MiRAGE generates datasets with significantly higher reasoning complexity (>2.3 average hops) and factual faithfulness. Our ablation studies point that MiRAGE can be powered by LLMs if textual descriptions of the images are available. Visual grounding still remains a frontier. By automating the creation of gold standard evaluation datasets that reflect the latent thematic structure of proprietary corpora, MiRAGE provides the necessary infrastructure to rigorously benchmark the next generation information retrieval systems.

</details>


### [129] [Tracking the Limits of Knowledge Propagation: How LLMs Fail at Multi-Step Reasoning with Conflicting Knowledge](https://arxiv.org/abs/2601.15495)
*Yiyang Feng,Zeming Chen,Haotian Wu,Jiawei Zhou,Antoine Bosselut*

Main category: cs.AI

TL;DR: TRACK是一个新的基准测试，用于评估LLM在参数知识与上下文更新知识冲突时如何进行多步推理，发现提供更新事实反而会降低推理性能


<details>
  <summary>Details</summary>
Motivation: 现有方法主要通过上下文提供更新事实或知识编辑来缓解LLM中的过时或错误信息，但这些方法在知识更新未能覆盖模型参数知识时会产生知识冲突，并传播到错误推理中。当前基准测试主要关注单次知识更新和事实回忆，而没有评估这些更新如何影响下游推理。

Method: 提出了TRACK基准测试，涵盖三个推理密集型场景（WIKI、CODE和MATH），引入多个现实冲突以反映真实世界的复杂性，用于研究LLM在参数知识与新知识冲突时如何传播新知识进行多步推理。

Result: 在TRACK上的结果显示，为模型提供更新事实进行推理反而比不提供更新事实的性能更差，而且随着提供更多更新事实，性能下降会加剧。这种失败源于既无法忠实整合更新事实，也源于即使知识被整合后推理也存在缺陷。

Conclusion: TRACK提供了一个严谨的新基准测试，用于衡量和指导未来在多步推理中传播冲突知识方面的进展。

Abstract: A common solution for mitigating outdated or incorrect information in Large Language Models (LLMs) is to provide updated facts in-context or through knowledge editing. However, these methods introduce knowledge conflicts when the knowledge update fails to overwrite the model's parametric knowledge, which propagate to faulty reasoning. Current benchmarks for this problem, however, largely focus only on single knowledge updates and fact recall without evaluating how these updates affect downstream reasoning. In this work, we introduce TRACK (Testing Reasoning Amid Conflicting Knowledge), a new benchmark for studying how LLMs propagate new knowledge through multi-step reasoning when it conflicts with the model's initial parametric knowledge. Spanning three reasoning-intensive scenarios (WIKI, CODE, and MATH), TRACK introduces multiple, realistic conflicts to mirror real-world complexity. Our results on TRACK reveal that providing updated facts to models for reasoning can worsen performance compared to providing no updated facts to a model, and that this performance degradation exacerbates as more updated facts are provided. We show this failure stems from both inability to faithfully integrate updated facts, but also flawed reasoning even when knowledge is integrated. TRACK provides a rigorous new benchmark to measure and guide future progress on propagating conflicting knowledge in multi-step reasoning.

</details>


### [130] [The Dark Side of AI Transformers: Sentiment Polarization & the Loss of Business Neutrality by NLP Transformers](https://arxiv.org/abs/2601.15509)
*Prasanna Kumar*

Main category: cs.AI

TL;DR: 研究发现Transformer模型在情感分析中的准确率提升是以牺牲中立性为代价的，导致情感极化问题，这对依赖情感分析结果的工业应用构成严重挑战。


<details>
  <summary>Details</summary>
Motivation: 尽管迁移学习和Transformer模型在提升情感分析准确率方面取得了显著进展，但研究发现这些改进往往伴随着中立性丧失和情感极化问题。这种中立性缺失对于依赖情感分析结果进行工业级应用的NLP领域构成了严重挑战。

Method: 通过实验观察发现，Transformer模型在提升某一类情感分析准确率的同时，往往导致另一类情感的极化，并且中立性判断能力下降。

Result: 实验结果表明，Transformer模型带来的准确率提升是以牺牲中立性为代价的，导致情感分析结果出现极化现象，这对工业应用中的可靠性产生了负面影响。

Conclusion: Transformer模型在情感分析中的准确率提升伴随着中立性丧失和情感极化问题，这为工业级NLP应用带来了可靠性挑战，需要进一步研究解决这一矛盾。

Abstract: The use of Transfer Learning & Transformers has steadily improved accuracy and has significantly contributed in solving complex computation problems. However, this transformer led accuracy improvement in Applied AI Analytics specifically in sentiment analytics comes with the dark side. It is observed during experiments that a lot of these improvements in transformer led accuracy of one class of sentiment has been at the cost of polarization of another class of sentiment and the failing of neutrality. This lack of neutrality poses an acute problem in the Applied NLP space, which relies heavily on the computational outputs of sentiment analytics for reliable industry ready tasks.

</details>


### [131] [TransportAgents: a multi-agents LLM framework for traffic accident severity prediction](https://arxiv.org/abs/2601.15519)
*Zhichao Yang,Jiashu He,Jinxuan Fan,Cirillo Cinzia*

Main category: cs.AI

TL;DR: 提出TransportAgents混合多智能体框架，结合特定类别LLM推理与MLP集成模块，用于交通事故严重程度预测，在多个数据集上优于传统机器学习和单智能体LLM方法。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型（LLMs）的单智能体架构在处理异构、领域特定的交通事故数据时存在困难，容易产生有偏见或不稳定的预测，需要更可靠的方法来支持安全关键决策。

Method: 提出TransportAgents混合多智能体框架，包含专门处理不同交通信息子集（如人口统计、环境背景、事故细节）的智能体，通过多层感知机（MLP）集成模块融合中间严重程度评估，形成统一预测。

Result: 在两个美国数据集（CPSRMS和NEISS）上的实验表明，TransportAgents在GPT-3.5、GPT-4o和LLaMA-3.3等多个骨干模型上均优于传统机器学习和先进LLM基线，展现出强大的鲁棒性、可扩展性和跨数据集泛化能力。

Conclusion: TransportAgents框架比标准单智能体LLM方法产生更平衡、校准更好的严重程度预测，在可解释性和可靠性方面表现出色，适用于安全关键决策支持应用。

Abstract: Accurate prediction of traffic crash severity is critical for improving emergency response and public safety planning. Although recent large language models (LLMs) exhibit strong reasoning capabilities, their single-agent architectures often struggle with heterogeneous, domain-specific crash data and tend to generate biased or unstable predictions. To address these limitations, this paper proposes TransportAgents, a hybrid multi-agent framework that integrates category-specific LLM reasoning with a multilayer perceptron (MLP) integration module. Each specialized agent focuses on a particular subset of traffic information, such as demographics, environmental context, or incident details, to produce intermediate severity assessments that are subsequently fused into a unified prediction. Extensive experiments on two complementary U.S. datasets, the Consumer Product Safety Risk Management System (CPSRMS) and the National Electronic Injury Surveillance System (NEISS), demonstrate that TransportAgents consistently outperforms both traditional machine learning and advanced LLM-based baselines. Across three representative backbones, including closed-source models such as GPT-3.5 and GPT-4o, as well as open-source models such as LLaMA-3.3, the framework exhibits strong robustness, scalability, and cross-dataset generalizability. A supplementary distributional analysis further shows that TransportAgents produces more balanced and well-calibrated severity predictions than standard single-agent LLM approaches, highlighting its interpretability and reliability for safety-critical decision support applications.

</details>


### [132] [From Generative Engines to Actionable Simulators: The Imperative of Physical Grounding in World Models](https://arxiv.org/abs/2601.15533)
*Zhikang Chen,Tingting Zhu*

Main category: cs.AI

TL;DR: 当前世界模型过度追求视觉逼真度，却忽视了物理因果理解，导致在安全关键决策中失效。论文主张将世界模型重构为可操作的模拟器而非视觉引擎，强调结构化4D接口、约束感知动态和闭环评估。


<details>
  <summary>Details</summary>
Motivation: 现有世界模型存在"视觉混淆"问题——错误地认为高保真视频生成等同于理解物理和因果动态。这种误解导致模型虽然能预测像素，却经常违反不变约束、在干预下失效，在安全关键决策中崩溃。特别是在医疗决策等不允许试错且错误不可逆的领域，这种缺陷尤为致命。

Method: 提出将世界模型重新定义为可操作的模拟器而非视觉引擎，强调三个关键方向：1) 结构化4D接口，2) 约束感知动态，3) 闭环评估。使用医疗决策作为"认知压力测试"来验证世界模型的价值。

Result: 研究表明，视觉逼真度是世界理解的不可靠代理。有效的世界模型必须编码因果结构、尊重领域特定约束，并在长时域中保持稳定。世界模型的价值不在于其生成的轨迹看起来有多真实，而在于其支持反事实推理、干预规划和鲁棒长时域预见的能力。

Conclusion: 需要从追求视觉逼真度转向构建具有因果理解、约束尊重和长期稳定性的可操作世界模型。特别是在医疗等安全关键领域，世界模型应作为支持反事实推理和干预规划的工具，而非仅仅是视觉模拟器。

Abstract: A world model is an AI system that simulates how an environment evolves under actions, enabling planning through imagined futures rather than reactive perception. Current world models, however, suffer from visual conflation: the mistaken assumption that high-fidelity video generation implies an understanding of physical and causal dynamics. We show that while modern models excel at predicting pixels, they frequently violate invariant constraints, fail under intervention, and break down in safety-critical decision-making. This survey argues that visual realism is an unreliable proxy for world understanding. Instead, effective world models must encode causal structure, respect domain-specific constraints, and remain stable over long horizons. We propose a reframing of world models as actionable simulators rather than visual engines, emphasizing structured 4D interfaces, constraint-aware dynamics, and closed-loop evaluation. Using medical decision-making as an epistemic stress test, where trial-and-error is impossible and errors are irreversible, we demonstrate that a world model's value is determined not by how realistic its rollouts appear, but by its ability to support counterfactual reasoning, intervention planning, and robust long-horizon foresight.

</details>


### [133] [ALIGNAgent: Adaptive Learner Intelligence for Gap Identification and Next-step guidance](https://arxiv.org/abs/2601.15551)
*Bismack Tokoli,Luis Jaimes,Ayesha S. Dina*

Main category: cs.AI

TL;DR: ALIGNAgent是一个多智能体教育框架，通过集成知识估计、技能差距识别和针对性资源推荐，实现个性化学习。


<details>
  <summary>Details</summary>
Motivation: 现有个性化学习系统通常只专注于知识追踪、诊断建模或资源推荐中的单一功能，缺乏将这些组件整合成一个连贯自适应循环的系统。

Method: ALIGNAgent采用多智能体框架：技能差距代理处理学生测验表现、成绩数据和偏好，生成主题级熟练度估计；推荐代理检索与诊断缺陷对齐的偏好感知学习材料；实现持续反馈循环，在进入后续主题前进行干预。

Result: 在两个本科计算机科学课程的真实数据集上评估，基于GPT-4o的代理在知识熟练度估计方面达到0.87-0.90的精确度和0.84-0.87的F1分数，与实际考试表现验证一致。

Conclusion: ALIGNAgent通过集成知识估计、技能差距识别和资源推荐，提供了一个有效的个性化学习框架，能够识别特定误解和知识缺陷并提供针对性干预。

Abstract: Personalized learning systems have emerged as a promising approach to enhance student outcomes by tailoring educational content, pacing, and feedback to individual needs. However, most existing systems remain fragmented, specializing in either knowledge tracing, diagnostic modeling, or resource recommendation, but rarely integrating these components into a cohesive adaptive cycle. In this paper, we propose ALIGNAgent (Adaptive Learner Intelligence for Gap Identification and Next-step guidance), a multi-agent educational framework designed to deliver personalized learning through integrated knowledge estimation, skill-gap identification, and targeted resource recommendation.ALIGNAgent begins by processing student quiz performance, gradebook data, and learner preferences to generate topic-level proficiency estimates using a Skill Gap Agent that employs concept-level diagnostic reasoning to identify specific misconceptions and knowledge deficiencies. After identifying skill gaps, the Recommender Agent retrieves preference-aware learning materials aligned with diagnosed deficiencies, implementing a continuous feedback loop where interventions occur before advancing to subsequent topics. Extensive empirical evaluation on authentic datasets from two undergraduate computer science courses demonstrates ALIGNAgent's effectiveness, with GPT-4o-based agents achieving precision of 0.87-0.90 and F1 scores of 0.84-0.87 in knowledge proficiency estimation validated against actual exam performance.

</details>


### [134] [Autonomous Business System via Neuro-symbolic AI](https://arxiv.org/abs/2601.15599)
*Cecil Pang,Hiroki Sayama*

Main category: cs.AI

TL;DR: AUTOBUS是一个自主业务系统，结合LLM智能体、谓词逻辑编程和业务语义知识图谱，通过神经符号AI架构编排端到端业务计划。


<details>
  <summary>Details</summary>
Motivation: 当前企业系统基于部门孤岛、刚性工作流和硬编码自动化，而LLM擅长自然语言理解但缺乏确定性业务逻辑执行能力，需要弥合这一差距。

Method: 将业务计划建模为带明确条件、数据、规则和API操作的任务网络；企业数据组织为知识图谱并转换为逻辑事实；AI智能体生成任务特定逻辑程序，由逻辑引擎执行。

Result: 提出了AUTOBUS架构，详细描述了AI智能体生成的逻辑程序结构，以及人类和辅助工具在业务计划生命周期中的作用。

Conclusion: AUTOBUS通过神经符号AI整合LLM智能体、逻辑编程和业务语义，实现可验证的业务流程编排，同时保持人类监督以确保责任和适应性。

Abstract: Current business environments require organizations to continuously reconfigure cross-functional processes, yet enterprise systems are still organized around siloed departments, rigid workflows, and hard-coded automation. Meanwhile large language models (LLMs) excel at interpreting natural language and unstructured data but lack deterministic, verifiable execution of complex business logic. To address this gap, here we introduce AUTOBUS, an Autonomous Business System that integrates LLM-based AI agents, predicate-logic programming, and business-semantics-centric enterprise data into a coherent neuro-symbolic AI architecture for orchestrating end-to-end business initiatives. AUTOBUS models an initiative as a network of tasks with explicit pre/post conditions, required data, evaluation rules, and API-level actions. Enterprise data is organized as a knowledge graph whose entities, relationships, and constraints are translated into logic facts and foundational rules, providing the semantic grounding for task reasoning. Core AI agents synthesize task instructions, enterprise semantics, and available tools into task-specific logic programs, which are executed by a logic engine that enforces constraints, coordinates auxiliary tools, and orchestrate execution of actions and outcomes. Humans define and maintain the semantics, policies and task instructions, curate tools, and supervise high-impact or ambiguous decisions, ensuring accountability and adaptability. We detail the AUTOBUS architecture, the anatomy of the AI agent generated logic programs, and the role of humans and auxiliary tools in the lifecycle of a business initiative.

</details>


### [135] [CogToM: A Comprehensive Theory of Mind Benchmark inspired by Human Cognition for Large Language Models](https://arxiv.org/abs/2601.15628)
*Haibo Tong,Zeyang Yue,Feifei Zhao,Erliang Lin,Lu Jia,Ruolin Chen,Yinqian Sun,Qian Zhang,Yi Zeng*

Main category: cs.AI

TL;DR: 研究者开发了CogToM基准，包含8000多个双语实例和46种范式，用于全面评估LLM的心理理论能力，发现前沿模型在特定维度存在瓶颈，且与人类认知结构存在差异。


<details>
  <summary>Details</summary>
Motivation: 现有心理理论基准主要局限于错误信念任务等狭窄范式，无法全面捕捉人类认知机制的全貌，需要更全面、理论基础的评估工具来探究LLM是否真正具备类人心理理论能力。

Method: 开发CogToM基准，包含8000多个双语实例，涵盖46种范式，由49名人类标注者验证。系统评估了22个代表性模型，包括GPT-5.1和Qwen3-Max等前沿模型，并基于人类认知模式进行深入分析。

Result: 评估发现模型性能存在显著异质性，在特定维度存在持续瓶颈。基于人类认知模式的分析表明，LLM与人类认知结构可能存在潜在差异。CogToM为研究LLM认知边界提供了可靠工具和视角。

Conclusion: CogToM基准为全面评估LLM心理理论能力提供了理论基础和实证工具，揭示了模型在特定认知维度的局限性以及与人类认知结构的差异，有助于推动LLM认知能力研究的深入发展。

Abstract: Whether Large Language Models (LLMs) truly possess human-like Theory of Mind (ToM) capabilities has garnered increasing attention. However, existing benchmarks remain largely restricted to narrow paradigms like false belief tasks, failing to capture the full spectrum of human cognitive mechanisms. We introduce CogToM, a comprehensive, theoretically grounded benchmark comprising over 8000 bilingual instances across 46 paradigms, validated by 49 human annotator.A systematic evaluation of 22 representative models, including frontier models like GPT-5.1 and Qwen3-Max, reveals significant performance heterogeneities and highlights persistent bottlenecks in specific dimensions. Further analysis based on human cognitive patterns suggests potential divergences between LLM and human cognitive structures. CogToM offers a robust instrument and perspective for investigating the evolving cognitive boundaries of LLMs.

</details>


### [136] [Agentic AI Governance and Lifecycle Management in Healthcare](https://arxiv.org/abs/2601.15630)
*Chandra Prakash,Mary Lind,Avneesh Sisodia*

Main category: cs.AI

TL;DR: 提出统一代理生命周期管理蓝图，解决医疗AI代理扩散带来的治理挑战


<details>
  <summary>Details</summary>
Motivation: 医疗组织在常规工作流中嵌入AI代理时面临代理扩散问题，包括重复代理、责任不清、控制不一致和权限残留等风险。现有AI治理框架缺乏对代理舰队日常运营的指导。

Method: 基于治理标准、代理安全文献和医疗合规要求的快速实践导向综合，提出统一代理生命周期管理蓝图，包含五个控制平面层：身份与角色注册、编排与跨域协调、PHI边界上下文与记忆、运行时策略执行与紧急停止触发、生命周期管理与凭证撤销审计。

Result: UALM为医疗CIO、CISO和临床领导者提供了可实施的审计就绪监督模式，支持分阶段采用的成熟度模型，在保持本地创新的同时实现更安全扩展。

Conclusion: UALM蓝图填补了医疗AI代理舰队日常运营治理的空白，为医疗系统提供了应对代理扩散挑战的实用框架，平衡创新与安全合规需求。

Abstract: Healthcare organizations are beginning to embed agentic AI into routine workflows, including clinical documentation support and early-warning monitoring. As these capabilities diffuse across departments and vendors, health systems face agent sprawl, causing duplicated agents, unclear accountability, inconsistent controls, and tool permissions that persist beyond the original use case. Existing AI governance frameworks emphasize lifecycle risk management but provide limited guidance for the day-to-day operations of agent fleets. We propose a Unified Agent Lifecycle Management (UALM) blueprint derived from a rapid, practice-oriented synthesis of governance standards, agent security literature, and healthcare compliance requirements. UALM maps recurring gaps onto five control-plane layers: (1) an identity and persona registry, (2) orchestration and cross-domain mediation, (3) PHI-bounded context and memory, (4) runtime policy enforcement with kill-switch triggers, and (5) lifecycle management and decommissioning linked to credential revocation and audit logging. A companion maturity model supports staged adoption. UALM offers healthcare CIOs, CISOs, and clinical leaders an implementable pattern for audit-ready oversight that preserves local innovation and enables safer scaling across clinical and administrative domains.

</details>


### [137] [Predictive Coding and Information Bottleneck for Hallucination Detection in Large Language Models](https://arxiv.org/abs/2601.15652)
*Manish Bhatt*

Main category: cs.AI

TL;DR: 提出一个结合神经科学信号设计与监督学习的混合检测框架，用于检测大语言模型幻觉，在数据效率、推理速度和可解释性方面显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大语言模型的幻觉（看似合理但事实不忠实）是高风险部署的关键障碍。现有检测方法依赖计算昂贵的外部检索循环或需要70B+参数的不透明黑盒LLM法官。

Method: 引入混合检测框架，结合神经科学启发的信号设计与监督机器学习。提取基于预测编码（量化与内部先验的惊讶度）和信息瓶颈（测量扰动下的信号保留）的可解释信号。通过系统消融研究，展示三个关键增强：实体聚焦摄取、上下文依从性和可证伪性评分。

Result: 在HaluBench（n=200，完美平衡）评估中，理论指导的基线达到0.8017 AUROC。基础监督模型达到0.8274 AUROC，改进特征将性能提升至0.8669 AUROC（4.95%增益）。使用比Lynx少75倍的训练数据（200 vs 15,000样本），推理速度快1000倍（5ms vs 5s），且保持完全可解释性。

Conclusion: 领域知识编码在信号架构中比扩展LLM法官提供更优的数据效率，使用轻量级（少于1M参数）、可解释的模型实现强大性能，适合生产部署。关键负面发现：合理化信号无法区分幻觉，表明LLM为错误前提生成连贯推理（"奉承"现象）。

Abstract: Hallucinations in Large Language Models (LLMs) -- generations that are plausible but factually unfaithful -- remain a critical barrier to high-stakes deployment. Current detection methods typically rely on computationally expensive external retrieval loops or opaque black-box LLM judges requiring 70B+ parameters. In this work, we introduce [Model Name], a hybrid detection framework that combines neuroscience-inspired signal design with supervised machine learning. We extract interpretable signals grounded in Predictive Coding (quantifying surprise against internal priors) and the Information Bottleneck (measuring signal retention under perturbation). Through systematic ablation, we demonstrate three key enhancements: Entity-Focused Uptake (concentrating on high-value tokens), Context Adherence (measuring grounding strength), and Falsifiability Score (detecting confident but contradictory claims).
  Evaluating on HaluBench (n=200, perfectly balanced), our theory-guided baseline achieves 0.8017 AUROC. BASE supervised models reach 0.8274 AUROC, while IMPROVED features boost performance to 0.8669 AUROC (4.95% gain), demonstrating consistent improvements across architectures. This competitive performance is achieved while using 75x less training data than Lynx (200 vs 15,000 samples), 1000x faster inference (5ms vs 5s), and remaining fully interpretable. Crucially, we report a negative result: the Rationalization signal fails to distinguish hallucinations, suggesting that LLMs generate coherent reasoning for false premises ("Sycophancy").
  This work demonstrates that domain knowledge encoded in signal architecture provides superior data efficiency compared to scaling LLM judges, achieving strong performance with lightweight (less than 1M parameter), explainable models suitable for production deployment.

</details>


### [138] [Improving Methodologies for Agentic Evaluations Across Domains: Leakage of Sensitive Information, Fraud and Cybersecurity Threats](https://arxiv.org/abs/2601.15679)
*Ee Wei Seah,Yongsen Zheng,Naga Nikshith,Mahran Morsidi,Gabriel Waikin Loh Matienzo,Nigel Gay,Akriti Vij,Benjamin Chua,En Qi Ng,Sharmini Johnson,Vanessa Wilfred,Wan Sie Lee,Anna Davidson,Catherine Devine,Erin Zorer,Gareth Holvey,Harry Coppock,James Walpole,Jerome Wynee,Magda Dubois,Michael Schmatz,Patrick Keane,Sam Deverett,Bill Black,Bo Yan,Bushra Sabir,Frank Sun,Hao Zhang,Harriet Farlow,Helen Zhou,Lingming Dong,Qinghua Lu,Seung Jang,Sharif Abuadbba,Simon O'Callaghan,Suyu Ma,Tom Howroyd,Cyrus Fung,Fatemeh Azadi,Isar Nejadgholi,Krishnapriya Vishnubhotla,Pulei Xiong,Saeedeh Lohrasbi,Scott Buffett,Shahrear Iqbal,Sowmya Vajjala,Anna Safont-Andreu,Luca Massarelli,Oskar van der Wal,Simon Möller,Agnes Delaborde,Joris Duguépéroux,Nicolas Rolin,Romane Gallienne,Sarah Behanzin,Tom Seimandi,Akiko Murakami,Takayuki Semitsu,Teresa Tsukiji,Angela Kinuthia,Michael Michie,Stephanie Kasaon,Jean Wangari,Hankyul Baek,Jaewon Noh,Kihyuk Nam,Sang Seo,Sungpil Shin,Taewhi Lee,Yongsu Kim*

Main category: cs.AI

TL;DR: 多国AI安全机构联合开展第三次AI智能体测试演练，重点关注跨语言文化安全、敏感信息泄露、欺诈和网络安全风险，旨在完善智能体评估方法论而非比较模型性能。


<details>
  <summary>Details</summary>
Motivation: 随着自主AI系统和智能体能力的快速发展，真实世界交互中的监管减少带来了新的风险。AI智能体开始在全球部署时，需要确保它们能够准确安全地处理不同语言和文化。当前智能体测试仍处于早期发展阶段，需要建立科学的评估方法。

Method: 由国际先进AI测量、评估与科学网络的多国代表（包括新加坡、日本、澳大利亚、加拿大、欧盟委员会、法国、肯尼亚、韩国和英国）联合开展第三次测试演练。演练分为两个方向：(1) 共同风险（敏感信息泄露和欺诈），由新加坡AISI领导；(2) 网络安全，由英国AISI领导。使用公开和闭源模型，基于各种公开智能体基准任务进行评估。

Result: 由于智能体测试仍处于早期阶段，本次演练的主要关注点是理解进行此类测试的方法论问题，而不是检查测试结果或模型能力。这是继2024年11月和2025年2月两次联合测试后的第三次演练。

Conclusion: 这次国际合作标志着参与方共同努力推进智能体评估科学的重要一步，旨在进一步完善测试先进AI系统的最佳实践。通过多国协作，为建立更科学、更全面的AI智能体安全评估框架奠定了基础。

Abstract: The rapid rise of autonomous AI systems and advancements in agent capabilities are introducing new risks due to reduced oversight of real-world interactions. Yet agent testing remains nascent and is still a developing science. As AI agents begin to be deployed globally, it is important that they handle different languages and cultures accurately and securely.
  To address this, participants from The International Network for Advanced AI Measurement, Evaluation and Science, including representatives from Singapore, Japan, Australia, Canada, the European Commission, France, Kenya, South Korea, and the United Kingdom have come together to align approaches to agentic evaluations.
  This is the third exercise, building on insights from two earlier joint testing exercises conducted by the Network in November 2024 and February 2025. The objective is to further refine best practices for testing advanced AI systems.
  The exercise was split into two strands: (1) common risks, including leakage of sensitive information and fraud, led by Singapore AISI; and (2) cybersecurity, led by UK AISI. A mix of open and closed-weight models were evaluated against tasks from various public agentic benchmarks. Given the nascency of agentic testing, our primary focus was on understanding methodological issues in conducting such tests, rather than examining test results or model capabilities. This collaboration marks an important step forward as participants work together to advance the science of agentic evaluations.

</details>


### [139] [From Passive Metric to Active Signal: The Evolving Role of Uncertainty Quantification in Large Language Models](https://arxiv.org/abs/2601.15690)
*Jiaxin Zhang,Wendi Cui,Zhuohang Li,Lifu Huang,Bradley Malin,Caiming Xiong,Chien-Sheng Wu*

Main category: cs.AI

TL;DR: 这篇综述探讨了如何将不确定性从被动诊断指标转变为主动控制信号，以提升大语言模型在关键领域的可靠性，涵盖推理、自主代理和强化学习三个前沿应用。


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽然能力显著，但其不可靠性仍是部署到高风险领域的关键障碍。需要将不确定性从被动诊断工具转变为主动控制机制，以构建更可靠、可信任的下一代AI系统。

Method: 通过三个前沿领域展示不确定性作为主动控制信号的应用：1) 高级推理中优化计算和触发自我纠正；2) 自主代理中管理元认知决策（工具使用和信息寻求）；3) 强化学习中缓解奖励黑客攻击并通过内在奖励实现自我改进。这些方法基于贝叶斯方法和符合预测等新兴理论框架。

Result: 提出了一个统一视角，展示了不确定性作为主动控制信号如何在不同AI应用领域中提升模型可靠性和性能，为构建可扩展、可靠、可信赖的AI系统提供了实用设计模式。

Conclusion: 掌握不确定性作为主动控制信号的新趋势对于构建下一代可扩展、可靠、可信赖的AI系统至关重要。这篇综述提供了全面概述、批判性分析和实用设计模式，为这一转型趋势提供了统一的理论框架。

Abstract: While Large Language Models (LLMs) show remarkable capabilities, their unreliability remains a critical barrier to deployment in high-stakes domains. This survey charts a functional evolution in addressing this challenge: the evolution of uncertainty from a passive diagnostic metric to an active control signal guiding real-time model behavior. We demonstrate how uncertainty is leveraged as an active control signal across three frontiers: in \textbf{advanced reasoning} to optimize computation and trigger self-correction; in \textbf{autonomous agents} to govern metacognitive decisions about tool use and information seeking; and in \textbf{reinforcement learning} to mitigate reward hacking and enable self-improvement via intrinsic rewards. By grounding these advancements in emerging theoretical frameworks like Bayesian methods and Conformal Prediction, we provide a unified perspective on this transformative trend. This survey provides a comprehensive overview, critical analysis, and practical design patterns, arguing that mastering the new trend of uncertainty is essential for building the next generation of scalable, reliable, and trustworthy AI.

</details>


### [140] [Agentic Uncertainty Quantification](https://arxiv.org/abs/2601.15703)
*Jiaxin Zhang,Prafulla Kumar Choubey,Kung-Hsiang Huang,Caiming Xiong,Chien-Sheng Wu*

Main category: cs.AI

TL;DR: 提出双过程智能体不确定性量化框架，将语言化不确定性转化为主动控制信号，解决AI智能体在长程推理中的"幻觉螺旋"问题


<details>
  <summary>Details</summary>
Motivation: 现有方法面临两难：不确定性量化方法只能被动诊断风险而不解决问题，而自我反思机制则存在持续或无目的的修正问题。需要解决AI智能体在长程推理中早期认知错误不可逆传播的"幻觉螺旋"问题。

Method: 提出统一的Dual-Process Agentic UQ框架，包含两个互补机制：系统1（不确定性感知记忆UAM）隐式传播语言化置信度和语义解释以防止盲目决策；系统2（不确定性感知反思UAR）利用这些解释作为理性线索，仅在必要时触发有针对性的推理时解决。

Result: 在闭环基准测试和开放式深度研究任务上的广泛实验表明，这种无需训练的方法实现了卓越的性能和轨迹级校准。

Conclusion: AUQ框架代表了向可靠智能体迈出的重要一步，能够动态平衡高效执行和深度思考。

Abstract: Although AI agents have demonstrated impressive capabilities in long-horizon reasoning, their reliability is severely hampered by the ``Spiral of Hallucination,'' where early epistemic errors propagate irreversibly. Existing methods face a dilemma: uncertainty quantification (UQ) methods typically act as passive sensors, only diagnosing risks without addressing them, while self-reflection mechanisms suffer from continuous or aimless corrections. To bridge this gap, we propose a unified Dual-Process Agentic UQ (AUQ) framework that transforms verbalized uncertainty into active, bi-directional control signals. Our architecture comprises two complementary mechanisms: System 1 (Uncertainty-Aware Memory, UAM), which implicitly propagates verbalized confidence and semantic explanations to prevent blind decision-making; and System 2 (Uncertainty-Aware Reflection, UAR), which utilizes these explanations as rational cues to trigger targeted inference-time resolution only when necessary. This enables the agent to balance efficient execution and deep deliberation dynamically. Extensive experiments on closed-loop benchmarks and open-ended deep research tasks demonstrate that our training-free approach achieves superior performance and trajectory-level calibration. We believe this principled framework AUQ represents a significant step towards reliable agents.

</details>


### [141] [Improving Methodologies for LLM Evaluations Across Global Languages](https://arxiv.org/abs/2601.15706)
*Akriti Vij,Benjamin Chua,Darshini Ramiah,En Qi Ng,Mahran Morsidi,Naga Nikshith Gangarapu,Sharmini Johnson,Vanessa Wilfred,Vikneswaran Kumaran,Wan Sie Lee,Wenzhuo Yang,Yongsen Zheng,Bill Black,Boming Xia,Frank Sun,Hao Zhang,Qinghua Lu,Suyu Ma,Yue Liu,Chi-kiu Lo,Fatemeh Azadi,Isar Nejadgholi,Sowmya Vajjala,Agnes Delaborde,Nicolas Rolin,Tom Seimandi,Akiko Murakami,Haruto Ishi,Satoshi Sekine,Takayuki Semitsu,Tasuku Sasaki,Angela Kinuthia,Jean Wangari,Michael Michie,Stephanie Kasaon,Hankyul Baek,Jaewon Noh,Kihyuk Nam,Sang Seo,Sungpil Shin,Taewhi Lee,Yongsu Kim,Daisy Newbold-Harrop,Jessica Wang,Mahmoud Ghanem,Vy Hong*

Main category: cs.AI

TL;DR: 多语言AI安全评估研究显示，前沿AI模型在不同语言环境下的安全行为存在显著差异，需要改进评估方法并建立共享框架。


<details>
  <summary>Details</summary>
Motivation: 随着前沿AI模型在全球部署，确保其在多样语言和文化背景下的行为安全可靠至关重要。当前模型安全措施在不同语言环境中的表现需要系统评估。

Method: 由新加坡AISI领导，多国研究人员合作进行多语言评估。测试两个开源模型在10种语言（包括高资源和低资源语言）上的表现，使用6000多个新翻译的提示，涵盖5个危害类别，采用LLM作为评判和人工标注两种评估方式。

Result: 研究发现安全行为在不同语言间存在差异：安全措施在不同语言和危害类型上的鲁棒性不同，评估者可靠性（LLM评判vs人工评审）存在变化。同时获得了改进多语言安全评估的方法学见解。

Conclusion: 这项工作是建立先进AI系统多语言安全测试共享框架的初步步骤，呼吁与更广泛的研究社区和行业持续合作，以改进评估方法并确保AI在全球范围内的安全部署。

Abstract: As frontier AI models are deployed globally, it is essential that their behaviour remains safe and reliable across diverse linguistic and cultural contexts. To examine how current model safeguards hold up in such settings, participants from the International Network for Advanced AI Measurement, Evaluation and Science, including representatives from Singapore, Japan, Australia, Canada, the EU, France, Kenya, South Korea and the UK conducted a joint multilingual evaluation exercise. Led by Singapore AISI, two open-weight models were tested across ten languages spanning high and low resourced groups: Cantonese English, Farsi, French, Japanese, Korean, Kiswahili, Malay, Mandarin Chinese and Telugu. Over 6,000 newly translated prompts were evaluated across five harm categories (privacy, non-violent crime, violent crime, intellectual property and jailbreak robustness), using both LLM-as-a-judge and human annotation.
  The exercise shows how safety behaviours can vary across languages. These include differences in safeguard robustness across languages and harm types and variation in evaluator reliability (LLM-as-judge vs. human review). Further, it also generated methodological insights for improving multilingual safety evaluations, such as the need for culturally contextualised translations, stress-tested evaluator prompts and clearer human annotation guidelines. This work represents an initial step toward a shared framework for multilingual safety testing of advanced AI systems and calls for continued collaboration with the wider research community and industry.

</details>


### [142] [Investigation of the Generalisation Ability of Genetic Programming-evolved Scheduling Rules in Dynamic Flexible Job Shop Scheduling](https://arxiv.org/abs/2601.15717)
*Luyao Zhu,Fangfang Zhang,Yi Mei,Mengjie Zhang*

Main category: cs.AI

TL;DR: 本文系统研究了遗传编程在动态柔性作业车间调度问题中演化调度规则的泛化能力，发现训练与测试实例在决策点分布相似时泛化效果更好，当训练实例包含更多作业时泛化性能更佳。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常在相同类型的DFJSS实例上训练和测试GP演化规则，仅通过随机种子区分，而忽略了其跨类型泛化能力。本文旨在填补这一空白，系统研究GP演化调度规则在不同DFJSS条件下的泛化能力。

Method: 通过在多维度上进行一系列实验，包括问题规模（机器和作业数量）、关键作业车间参数（如利用率水平）和数据分布，分析这些因素如何影响GP在未见实例类型上的性能。

Result: 结果显示：当训练实例包含比测试实例更多的作业而机器数量固定时，以及当训练和测试实例具有相似规模或作业车间参数时，泛化效果良好。进一步分析发现，DFJSS实例中决策点的数量和分布在解释这些性能差异中起着关键作用。

Conclusion: 本研究为GP在DFJSS中的泛化能力提供了新见解，强调了演化更具泛化能力的GP规则以有效处理异构DFJSS实例的必要性。决策点分布的相似性对泛化性能有重要影响。

Abstract: Dynamic Flexible Job Shop Scheduling (DFJSS) is a complex combinatorial optimisation problem that requires simultaneous machine assignment and operation sequencing decisions in dynamic production environments. Genetic Programming (GP) has been widely applied to automatically evolve scheduling rules for DFJSS. However, existing studies typically train and test GP-evolved rules on DFJSS instances of the same type, which differ only by random seeds rather than by structural characteristics, leaving their cross-type generalisation ability largely unexplored. To address this gap, this paper systematically investigates the generalisation ability of GP-evolved scheduling rules under diverse DFJSS conditions. A series of experiments are conducted across multiple dimensions, including problem scale (i.e., the number of machines and jobs), key job shop parameters (e.g., utilisation level), and data distributions, to analyse how these factors influence GP performance on unseen instance types. The results show that good generalisation occurs when the training instances contain more jobs than the test instances while keeping the number of machines fixed, and when both training and test instances have similar scales or job shop parameters. Further analysis reveals that the number and distribution of decision points in DFJSS instances play a crucial role in explaining these performance differences. Similar decision point distributions lead to better generalisation, whereas significant discrepancies result in a marked degradation of performance. Overall, this study provides new insights into the generalisation ability of GP in DFJSS and highlights the necessity of evolving more generalisable GP rules capable of handling heterogeneous DFJSS instances effectively.

</details>


### [143] [Benchmarking Text-to-Python against Text-to-SQL: The Impact of Explicit Logic and Ambiguity](https://arxiv.org/abs/2601.15728)
*Hangle Hu,Chenyu Hou,Bin Cao,Ruizhe Li*

Main category: cs.AI

TL;DR: BIRD-Python基准测试揭示Text-to-Python与Text-to-SQL在数据检索中的性能差异主要源于领域知识缺失，而非代码生成能力，通过逻辑补全框架可达到性能持平。


<details>
  <summary>Details</summary>
Motivation: 现实数据分析越来越需要Python等通用编程语言处理文件数据和复杂工作流，但Text-to-Python在核心数据检索方面的可靠性相比成熟的SQL生态系统尚未得到充分探索。

Method: 引入BIRD-Python基准进行跨范式评估，系统优化原始数据集减少标注噪声并统一执行语义；提出逻辑补全框架(LCF)，通过融入潜在领域知识来解决模糊性。

Result: 分析发现：1)性能差异主要源于缺失领域上下文而非代码生成固有局限；2)当这些差距被填补后，Text-to-Python能与Text-to-SQL达到性能持平。

Conclusion: Python可作为分析代理的可行基础，前提是系统能够将模糊的自然语言输入有效地锚定在可执行的逻辑规范中。

Abstract: While Text-to-SQL remains the dominant approach for database interaction, real-world analytics increasingly require the flexibility of general-purpose programming languages such as Python or Pandas to manage file-based data and complex analytical workflows. Despite this growing need, the reliability of Text-to-Python in core data retrieval remains underexplored relative to the mature SQL ecosystem. To address this gap, we introduce BIRD-Python, a benchmark designed for cross-paradigm evaluation. We systematically refined the original dataset to reduce annotation noise and align execution semantics, thereby establishing a consistent and standardized baseline for comparison. Our analysis reveals a fundamental paradigmatic divergence: whereas SQL leverages implicit DBMS behaviors through its declarative structure, Python requires explicit procedural logic, making it highly sensitive to underspecified user intent. To mitigate this challenge, we propose the Logic Completion Framework (LCF), which resolves ambiguity by incorporating latent domain knowledge into the generation process. Experimental results show that (1) performance differences primarily stem from missing domain context rather than inherent limitations in code generation, and (2) when these gaps are addressed, Text-to-Python achieves performance parity with Text-to-SQL. These findings establish Python as a viable foundation for analytical agents-provided that systems effectively ground ambiguous natural language inputs in executable logical specifications. Resources are available at https://anonymous.4open.science/r/Bird-Python-43B7/.

</details>


### [144] [PhysProver: Advancing Automatic Theorem Proving for Physics](https://arxiv.org/abs/2601.15737)
*Hanning Zhang,Ruida Wang,Rui Pan,Wenyuan Wang,Bingxu Meng,Tong Zhang*

Main category: cs.AI

TL;DR: PhysProver：首个针对物理领域的正式定理证明增强方法，使用专门数据集PhysLeanData和强化学习训练，在物理子领域提升2.4%，在数学基准上也有1.3%提升。


<details>
  <summary>Details</summary>
Motivation: 当前可验证语言和LLMs的结合主要关注数学定理证明，但忽视了形式物理推理这一同样依赖问题解决和定理证明框架的重要领域。需要开发专门针对物理领域的正式定理证明方法。

Method: 1) 构建专门数据集PhysLeanData，包含从PhysLean采样的定理和基于猜想的正式数据生成管道生成的数据；2) 基于DeepSeek-Prover-V2-7B数学定理证明器，应用强化学习与可验证奖励（RLVR）训练PhysProver模型。

Result: 仅使用约5K训练样本，PhysProver在多个物理子领域实现总体2.4%的改进。在MiniF2F-Test数学基准上获得1.3%提升，显示出跨领域的泛化能力和形式数学能力的增强。

Conclusion: 该方法有效且高效，为将形式证明器扩展到数学领域之外提供了范式。数据集和模型将开源以促进进一步研究。

Abstract: The combination of verifiable languages and LLMs has significantly influenced both the mathematical and computer science communities because it provides a rigorous foundation for theorem proving. Recent advancements in the field provide foundation models and sophisticated agentic systems pushing the boundaries of formal mathematical reasoning to approach the natural language capability of LLMs. However, little attention has been given to the formal physics reasoning, which also heavily relies on similar problem-solving and theorem-proving frameworks. To solve this problem, this paper presents, to the best of our knowledge, the first approach to enhance formal theorem proving in the physics domain. We compose a dedicated dataset PhysLeanData for the task. It is composed of theorems sampled from PhysLean and data generated by a conjecture-based formal data generation pipeline. In the training pipeline, we leverage DeepSeek-Prover-V2-7B, a strong open-source mathematical theorem prover, and apply Reinforcement Learning with Verifiable Rewards (RLVR) to train our model PhysProver. Comprehensive experiments demonstrate that, using only $\sim$5K training samples, PhysProver achieves an overall 2.4\% improvement in multiple sub-domains. Furthermore, after formal physics training, we observe 1.3\% gains on the MiniF2F-Test benchmark, which indicates non-trivial generalization beyond physics domains and enhancement for formal math capability as well. The results highlight the effectiveness and efficiency of our approach, which provides a paradigm for extending formal provers outside mathematical domains. To foster further research, we will release both our dataset and model to the community.

</details>


### [145] [Tabular Incremental Inference](https://arxiv.org/abs/2601.15751)
*Xinda Chen,Xing Zhen,Hanyu Zhang,Weimin Tan,Bo Yan*

Main category: cs.AI

TL;DR: 提出表格增量推理任务(TabII)，解决AI模型在推理阶段处理动态新增列的问题，基于信息瓶颈理论设计方法，在8个数据集上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 表格数据是基础数据结构，列动态变化源于技术进步、需求变化、数据集成等。传统AI模型在固定列上训练后推理的模式无法处理动态变化的表格，需要无监督高效处理新列的方法。

Method: 基于信息瓶颈理论，设计TabII方法：使用LLM占位符和预训练TabAdapter提供外部知识，增量样本压缩块来浓缩增量列属性提供的任务相关信息。

Result: 在8个公共数据集上的实验结果表明，TabII能有效利用增量属性，达到最先进的性能。

Conclusion: 提出的表格增量推理任务(TabII)增强了AI模型在表格动态变化场景中的实用性，基于信息瓶颈理论的方法框架能有效处理推理阶段的新增列。

Abstract: Tabular data is a fundamental form of data structure. The evolution of table analysis tools reflects humanity's continuous progress in data acquisition, management, and processing. The dynamic changes in table columns arise from technological advancements, changing needs, data integration, etc. However, the standard process of training AI models on tables with fixed columns and then performing inference is not suitable for handling dynamically changed tables. Therefore, new methods are needed for efficiently handling such tables in an unsupervised manner. In this paper, we introduce a new task, Tabular Incremental Inference (TabII), which aims to enable trained models to incorporate new columns during the inference stage, enhancing the practicality of AI models in scenarios where tables are dynamically changed. Furthermore, we demonstrate that this new task can be framed as an optimization problem based on the information bottleneck theory, which emphasizes that the key to an ideal tabular incremental inference approach lies in minimizing mutual information between tabular data and representation while maximizing between representation and task labels. Under this guidance, we design a TabII method with Large Language Model placeholders and Pretrained TabAdapter to provide external knowledge and Incremental Sample Condensation blocks to condense the task-relevant information given by incremental column attributes. Experimental results across eight public datasets show that TabII effectively utilizes incremental attributes, achieving state-of-the-art performance.

</details>


### [146] [Off-Policy Actor-Critic with Sigmoid-Bounded Entropy for Real-World Robot Learning](https://arxiv.org/abs/2601.15761)
*Xiefeng Wu,Mingyu Hu,Shu Zhang*

Main category: cs.AI

TL;DR: SigEnt-SAC是一种从单条专家轨迹学习的离线到在线强化学习方法，通过sigmoid有界熵项防止负熵驱动的OOD动作优化，减少Q函数震荡，在真实机器人任务中实现低成本部署。


<details>
  <summary>Details</summary>
Motivation: 真实世界强化学习面临样本效率低、奖励稀疏和视觉观测噪声等挑战。现有方法需要大量数据或大规模预训练，缺乏低成本、小数据需求的解决方案。

Method: 提出SigEnt-SAC离线策略actor-critic方法，核心设计是sigmoid有界熵项，防止负熵驱动的分布外动作优化，减少Q函数震荡，仅需单条专家轨迹即可从头学习。

Result: 在D4RL基准测试中显著缓解Q函数震荡，比先前方法更快达到100%成功率。在四种真实机器人任务中，仅需少量真实世界交互即可学习成功策略。

Conclusion: SigEnt-SAC为真实世界强化学习部署提供了一条低成本、实用的途径，仅需少量数据和交互即可学习有效策略。

Abstract: Deploying reinforcement learning in the real world remains challenging due to sample inefficiency, sparse rewards, and noisy visual observations. Prior work leverages demonstrations and human feedback to improve learning efficiency and robustness. However, offline-to-online methods need large datasets and can be unstable, while VLA-assisted RL relies on large-scale pretraining and fine-tuning. As a result, a low-cost real-world RL method with minimal data requirements has yet to emerge. We introduce \textbf{SigEnt-SAC}, an off-policy actor-critic method that learns from scratch using a single expert trajectory. Our key design is a sigmoid-bounded entropy term that prevents negative-entropy-driven optimization toward out-of-distribution actions and reduces Q-function oscillations. We benchmark SigEnt-SAC on D4RL tasks against representative baselines. Experiments show that SigEnt-SAC substantially alleviates Q-function oscillations and reaches a 100\% success rate faster than prior methods. Finally, we validate SigEnt-SAC on four real-world robotic tasks across multiple embodiments, where agents learn from raw images and sparse rewards; results demonstrate that SigEnt-SAC can learn successful policies with only a small number of real-world interactions, suggesting a low-cost and practical pathway for real-world RL deployment.

</details>


### [147] [Agentic Confidence Calibration](https://arxiv.org/abs/2601.15778)
*Jiaxin Zhang,Caiming Xiong,Chien-Sheng Wu*

Main category: cs.AI

TL;DR: 提出首个智能体置信度校准问题，并开发HTC框架，通过提取轨迹级特征来校准多步任务中的AI智能体置信度，显著提升校准性能并实现跨域泛化。


<details>
  <summary>Details</summary>
Motivation: AI智能体正从被动语言模型发展为执行复杂多步任务的自主系统，但其在失败时的过度自信成为高风险部署的根本障碍。现有校准方法针对静态单轮输出设计，无法解决智能体系统的独特挑战，如轨迹中的误差累积、外部工具的不确定性以及不透明的失败模式。

Method: 提出Holistic Trajectory Calibration (HTC)框架，从智能体整个轨迹中提取丰富的流程级特征，涵盖从宏观动态到微观稳定性。采用简单可解释的模型，在八个基准测试、多种LLM和不同智能体框架中验证。

Result: HTC在校准和判别方面持续超越强基线方法。提供三个关键进展：通过揭示失败信号提供可解释性；无需重新训练即可跨域应用实现可迁移性；通过General Agent Calibrator (GAC)在域外GAIA基准上实现最佳校准（最低ECE）。

Conclusion: 这些贡献建立了一个新的以流程为中心的置信度校准范式，为诊断和增强AI智能体的可靠性提供了一个框架。

Abstract: AI agents are rapidly advancing from passive language models to autonomous systems executing complex, multi-step tasks. Yet their overconfidence in failure remains a fundamental barrier to deployment in high-stakes settings. Existing calibration methods, built for static single-turn outputs, cannot address the unique challenges of agentic systems, such as compounding errors along trajectories, uncertainty from external tools, and opaque failure modes. To address these challenges, we introduce, for the first time, the problem of Agentic Confidence Calibration and propose Holistic Trajectory Calibration (HTC), a novel diagnostic framework that extracts rich process-level features ranging from macro dynamics to micro stability across an agent's entire trajectory. Powered by a simple, interpretable model, HTC consistently surpasses strong baselines in both calibration and discrimination, across eight benchmarks, multiple LLMs, and diverse agent frameworks. Beyond performance, HTC delivers three essential advances: it provides interpretability by revealing the signals behind failure, enables transferability by applying across domains without retraining, and achieves generalization through a General Agent Calibrator (GAC) that achieves the best calibration (lowest ECE) on the out-of-domain GAIA benchmark. Together, these contributions establish a new process-centric paradigm for confidence calibration, providing a framework for diagnosing and enhancing the reliability of AI agents.

</details>


### [148] [Creativity in the Age of AI: Rethinking the Role of Intentional Agency](https://arxiv.org/abs/2601.15797)
*James S. Pearson,Matthew J. Dennis,Marc Cheong*

Main category: cs.AI

TL;DR: 论文认为传统的"意向性主体条件"（IAC）不应作为创造力的普遍条件，而应被"一致性要求"取代，因为生成式AI的发展挑战了IAC的适用性。


<details>
  <summary>Details</summary>
Motivation: 许多创造力理论家坚持认为意向性主体是创造力的必要条件，但随着生成式AI的发展，这一传统观点变得越来越有问题。作者旨在重新审视这一条件，分析其在AI时代的适用性。

Method: 1. 通过语料库证据分析作者和记者对生成式AI创造力的描述变化；2. 运用概念工程方法分析IAC的社会功能变化；3. 提出用"一致性要求"替代IAC作为普遍条件。

Result: 1. 语料证据显示人们越来越愿意将创造力归因于缺乏意向性的生成式AI；2. IAC不再能有效识别和鼓励新颖有价值产品的可靠来源，反而助长对AI产出的评估偏见；3. 应保留IAC在特定局部领域的适用性。

Conclusion: 应在普遍层面放弃意向性主体条件，采用一致性要求（创造力追踪新颖有价值产品的可靠生成），但保留IAC在特定领域的相关性。

Abstract: Many theorists of creativity maintain that intentional agency is a necessary condition of creativity. We argue that this requirement, which we call the Intentional Agency Condition (IAC), should be rejected as a general condition of creativity, while retaining its relevance in specific contexts. We show that recent advances in generative AI have rendered the IAC increasingly problematic, both descriptively and functionally. We offer two reasons for abandoning it at the general level. First, we present corpus evidence indicating that authors and journalists are increasingly comfortable ascribing creativity to generative AI, despite its lack of intentional agency. This development places pressure on the linguistic intuitions that have traditionally been taken to support the IAC. Second, drawing on the method of conceptual engineering, we argue that the IAC no longer fulfils its core social function. Rather than facilitating the identification and encouragement of reliable sources of novel and valuable products, it now feeds into biases that distort our assessments of AI-generated outputs. We therefore propose replacing the IAC with a consistency requirement, according to which creativity tracks the reliable generation of novel and valuable products. Nonetheless, we explain why the IAC should be retained in specific local domains.

</details>


### [149] [VitalDiagnosis: AI-Driven Ecosystem for 24/7 Vital Monitoring and Chronic Disease Management](https://arxiv.org/abs/2601.15798)
*Zhikai Xue,Tianqianjin Lin,Pengwei Yan,Ruichun Wang,Yuxin Liu,Zhuoren Jiang,Xiaozhong Liu*

Main category: cs.AI

TL;DR: VitalDiagnosis是一个基于大语言模型的慢性病管理系统，通过整合可穿戴设备数据和LLM推理能力，实现从被动监测到主动交互的疾病管理模式转变。


<details>
  <summary>Details</summary>
Motivation: 慢性病已成为全球主要死因，医疗资源紧张和人口老龄化加剧了这一挑战。患者难以识别早期恶化迹象并坚持治疗计划，需要更主动的疾病管理方案。

Method: 构建LLM驱动的生态系统，整合可穿戴设备的连续数据与LLM推理能力，通过情境感知查询分析健康触发因素，在患者-临床医生协作工作流中生成临时见解，并提供个性化指导。

Result: 系统能够同时处理急性健康异常和常规依从性问题，促进更主动、协作的护理范式，有望增强患者自我管理能力并减少可避免的临床工作量。

Conclusion: VitalDiagnosis通过LLM与可穿戴数据的结合，实现了慢性病管理从被动监测到主动交互的转变，为改善患者自我管理和减轻医疗负担提供了创新解决方案。

Abstract: Chronic diseases have become the leading cause of death worldwide, a challenge intensified by strained medical resources and an aging population. Individually, patients often struggle to interpret early signs of deterioration or maintain adherence to care plans. In this paper, we introduce VitalDiagnosis, an LLM-driven ecosystem designed to shift chronic disease management from passive monitoring to proactive, interactive engagement. By integrating continuous data from wearable devices with the reasoning capabilities of LLMs, the system addresses both acute health anomalies and routine adherence. It analyzes triggers through context-aware inquiries, produces provisional insights within a collaborative patient-clinician workflow, and offers personalized guidance. This approach aims to promote a more proactive and cooperative care paradigm, with the potential to enhance patient self-management and reduce avoidable clinical workload.

</details>


### [150] [Inference-Time Scaling of Verification: Self-Evolving Deep Research Agents via Test-Time Rubric-Guided Verification](https://arxiv.org/abs/2601.15808)
*Yuxuan Wan,Tianqing Fang,Zaitang Li,Yintong Huo,Wenxuan Wang,Haitao Mi,Dong Yu,Michael R. Lyu*

Main category: cs.AI

TL;DR: 提出DeepVerifier：基于规则的结果奖励验证器，通过推理时验证实现智能体自我进化，无需额外训练即可提升性能


<details>
  <summary>Details</summary>
Motivation: 现有深度研究智能体（DRAs）主要通过后训练增强策略能力，但缺乏在推理时自我进化的机制。需要一种能够系统评估智能体输出并基于反馈迭代改进的方法。

Method: 1）基于自动构建的DRA失败分类法制定评估规则；2）开发DeepVerifier验证器，利用验证的不对称性；3）在测试时作为即插即用模块，生成基于规则的详细反馈；4）反馈给智能体进行迭代引导，无需额外训练

Result: 1）DeepVerifier在元评估F1分数上比基线方法提升12%-48%；2）在GAIA和XBench-DeepResearch的挑战性子集上实现8%-11%的准确率提升；3）发布DeepVerifier-4K数据集（4,646个高质量智能体步骤）

Conclusion: 提出了一种新的智能体自我进化范式，通过推理时验证实现性能提升。DeepVerifier验证器显著优于现有基线，并提供了开源数据集支持社区发展。

Abstract: Recent advances in Deep Research Agents (DRAs) are transforming automated knowledge discovery and problem-solving. While the majority of existing efforts focus on enhancing policy capabilities via post-training, we propose an alternative paradigm: self-evolving the agent's ability by iteratively verifying the policy model's outputs, guided by meticulously crafted rubrics. This approach gives rise to the inference-time scaling of verification, wherein an agent self-improves by evaluating its generated answers to produce iterative feedback and refinements. We derive the rubrics based on an automatically constructed DRA Failure Taxonomy, which systematically classifies agent failures into five major categories and thirteen sub-categories. We present DeepVerifier, a rubrics-based outcome reward verifier that leverages the asymmetry of verification and outperforms vanilla agent-as-judge and LLM judge baselines by 12%-48% in meta-evaluation F1 score. To enable practical self-evolution, DeepVerifier integrates as a plug-and-play module during test-time inference. The verifier produces detailed rubric-based feedback, which is fed back to the agent for iterative bootstrapping, refining responses without additional training. This test-time scaling delivers 8%-11% accuracy gains on challenging subsets of GAIA and XBench-DeepResearch when powered by capable closed-source LLMs. Finally, to support open-source advancement, we release DeepVerifier-4K, a curated supervised fine-tuning dataset of 4,646 high-quality agent steps focused on DRA verification. These examples emphasize reflection and self-critique, enabling open models to develop robust verification capabilities.

</details>


### [151] [ErrorMap and ErrorAtlas: Charting the Failure Landscape of Large Language Models](https://arxiv.org/abs/2601.15812)
*Shir Ashury-Tahan,Yifan Mai,Elron Bandel,Michal Shmueli-Scheuer,Leshem Choshen*

Main category: cs.AI

TL;DR: ErrorMap是首个分析LLM失败原因的方法，通过提取模型的"失败签名"来识别错误来源，帮助开发者调试模型、对齐基准目标并支持明智的模型选择。


<details>
  <summary>Details</summary>
Motivation: 当前LLM基准测试只告诉我们模型何时失败，但不解释为什么失败。错误的答案可能源于格式问题、计算错误或数据集噪声，而非推理能力弱。如果不区分这些原因，基准测试就不完整，无法可靠指导模型改进。

Method: ErrorMap方法提取模型的独特"失败签名"，阐明基准测试测量什么，并扩大错误识别范围以减少盲点。该方法适用于任何模型和数据集，使用相同逻辑。作者将方法应用于35个数据集和83个模型，生成ErrorAtlas错误分类法。

Result: ErrorAtlas揭示了重复出现的失败模式，突出了当前LLM研究中未被充分探索的错误类型，如输出中遗漏必要细节和问题误解。该方法将焦点从模型成功之处转移到失败原因，实现更高级的评估。

Conclusion: ErrorMap和ErrorAtlas通过引入可在模型和任务间全局应用的更深层评估层，提供了对模型行为和局限性的更丰富洞察。与通常通过任务级指标衡量的成功不同，该方法暴露隐藏弱点并指导进展。作者公开了分类法和代码，并计划随着新基准和模型的出现定期更新ErrorAtlas。

Abstract: Large Language Models (LLM) benchmarks tell us when models fail, but not why they fail. A wrong answer on a reasoning dataset may stem from formatting issues, calculation errors, or dataset noise rather than weak reasoning. Without disentangling such causes, benchmarks remain incomplete and cannot reliably guide model improvement. We introduce ErrorMap, the first method to chart the sources of LLM failure. It extracts a model's unique "failure signature", clarifies what benchmarks measure, and broadens error identification to reduce blind spots. This helps developers debug models, aligns benchmark goals with outcomes, and supports informed model selection. ErrorMap works on any model or dataset with the same logic. Applying our method to 35 datasets and 83 models we generate ErrorAtlas, a taxonomy of model errors, revealing recurring failure patterns. ErrorAtlas highlights error types that are currently underexplored in LLM research, such as omissions of required details in the output and question misinterpretation. By shifting focus from where models succeed to why they fail, ErrorMap and ErrorAtlas enable advanced evaluation - one that exposes hidden weaknesses and directs progress. Unlike success, typically measured by task-level metrics, our approach introduces a deeper evaluation layer that can be applied globally across models and tasks, offering richer insights into model behavior and limitations. We make the taxonomy and code publicly available with plans to periodically update ErrorAtlas as new benchmarks and models emerge.

</details>


### [152] [EvoCUA: Evolving Computer Use Agents via Learning from Scalable Synthetic Experience](https://arxiv.org/abs/2601.15876)
*Taofeng Xue,Chong Peng,Mianqiu Huang,Linsen Guo,Tiancheng Han,Haozhe Wang,Jianing Wang,Xiaocheng Zhang,Xin Yang,Dengchang Zhao,Jinrui Ding,Xiandi Ma,Yuchen Xie,Peng Pei,Xunliang Cai,Xipeng Qiu*

Main category: cs.AI

TL;DR: EvoCUA：通过进化式学习循环（数据生成+策略优化）突破静态数据限制，在OSWorld基准上达到56.7%成功率，创开源SOTA


<details>
  <summary>Details</summary>
Motivation: 当前原生计算机使用智能体（CUA）受限于静态数据扩展瓶颈，依赖被动模仿静态数据集难以捕捉长时程计算机任务中的复杂因果动态关系

Method: 1）可验证合成引擎自主生成多样化任务及可执行验证器；2）可扩展基础设施协调数万个异步沙箱环境；3）迭代进化学习策略，通过识别能力边界动态调节策略更新，将失败轨迹转化为监督信号

Result: 在OSWorld基准上达到56.7%成功率，超越之前最佳开源模型OpenCUA-72B（45.0%）和领先闭源模型UI-TARS-2（53.1%），建立新的开源SOTA

Conclusion: 基于经验学习的进化范式在不同规模基础模型上都能带来一致性能提升，为推进原生智能体能力提供了稳健且可扩展的路径

Abstract: The development of native computer-use agents (CUA) represents a significant leap in multimodal AI. However, their potential is currently bottlenecked by the constraints of static data scaling. Existing paradigms relying primarily on passive imitation of static datasets struggle to capture the intricate causal dynamics inherent in long-horizon computer tasks. In this work, we introduce EvoCUA, a native computer use agentic model. Unlike static imitation, EvoCUA integrates data generation and policy optimization into a self-sustaining evolutionary cycle. To mitigate data scarcity, we develop a verifiable synthesis engine that autonomously generates diverse tasks coupled with executable validators. To enable large-scale experience acquisition, we design a scalable infrastructure orchestrating tens of thousands of asynchronous sandbox rollouts. Building on these massive trajectories, we propose an iterative evolving learning strategy to efficiently internalize this experience. This mechanism dynamically regulates policy updates by identifying capability boundaries -- reinforcing successful routines while transforming failure trajectories into rich supervision through error analysis and self-correction. Empirical evaluations on the OSWorld benchmark demonstrate that EvoCUA achieves a success rate of 56.7%, establishing a new open-source state-of-the-art. Notably, EvoCUA significantly outperforms the previous best open-source model, OpenCUA-72B (45.0%), and surpasses leading closed-weights models such as UI-TARS-2 (53.1%). Crucially, our results underscore the generalizability of this approach: the evolving paradigm driven by learning from experience yields consistent performance gains across foundation models of varying scales, establishing a robust and scalable path for advancing native agent capabilities.

</details>


### [153] [ICON: Invariant Counterfactual Optimization with Neuro-Symbolic Priors for Text-Based Person Search](https://arxiv.org/abs/2601.15931)
*Xiangyu Wang,Zhixin Lv,Yongjiao Sun,Anrui Han,Ye Yuan,Hangxu Ji*

Main category: cs.AI

TL;DR: ICON框架通过因果和拓扑先验解决文本人物搜索中的虚假相关性和空间语义错位问题，实现几何不变性和环境独立性，提升对遮挡、背景干扰和定位噪声的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前基于预训练模型的文本人物搜索方法在复杂开放世界场景中迁移效果不佳，依赖"被动观察"导致多方面的虚假相关性和空间语义错位，缺乏对分布偏移的鲁棒性。

Method: 提出ICON框架：1) 规则引导的空间干预惩罚边界框噪声敏感性；2) 反事实上下文解耦通过语义驱动的背景移植实现环境独立性；3) 显著性驱动的语义正则化解决局部显著性偏差；4) 神经符号拓扑对齐确保激活区域与人类结构逻辑一致。

Result: ICON在标准基准测试中保持领先性能，同时对遮挡、背景干扰和定位噪声表现出卓越的鲁棒性。

Conclusion: 该方法通过从拟合统计共现转向学习因果不变性，有效推进了文本人物搜索领域的发展。

Abstract: Text-Based Person Search (TBPS) holds unique value in real-world surveillance bridging visual perception and language understanding, yet current paradigms utilizing pre-training models often fail to transfer effectively to complex open-world scenarios. The reliance on "Passive Observation" leads to multifaceted spurious correlations and spatial semantic misalignment, causing a lack of robustness against distribution shifts. To fundamentally resolve these defects, this paper proposes ICON (Invariant Counterfactual Optimization with Neuro-symbolic priors), a framework integrating causal and topological priors. First, we introduce Rule-Guided Spatial Intervention to strictly penalize sensitivity to bounding box noise, forcibly severing location shortcuts to achieve geometric invariance. Second, Counterfactual Context Disentanglement is implemented via semantic-driven background transplantation, compelling the model to ignore background interference for environmental independence. Then, we employ Saliency-Driven Semantic Regularization with adaptive masking to resolve local saliency bias and guarantee holistic completeness. Finally, Neuro-Symbolic Topological Alignment utilizes neuro-symbolic priors to constrain feature matching, ensuring activated regions are topologically consistent with human structural logic. Experimental results demonstrate that ICON not only maintains leading performance on standard benchmarks but also exhibits exceptional robustness against occlusion, background interference, and localization noise. This approach effectively advances the field by shifting from fitting statistical co-occurrences to learning causal invariance.

</details>


### [154] [Natural Language-Driven Global Mapping of Martian Landforms](https://arxiv.org/abs/2601.15949)
*Yiran Wang,Shuoyuan Wang,Zhaoran Wei,Jiannan Zhao,Zhonghua Yao,Zejian Xie,Songxin Zhang,Jun Huang,Bingyi Jing,Hongxin Wei*

Main category: cs.AI

TL;DR: MarScope是一个行星尺度的视觉-语言框架，通过自然语言驱动、无标签的方式实现火星地貌映射，将行星图像和文本对齐到共享语义空间，支持任意用户查询。


<details>
  <summary>Details</summary>
Motivation: 行星表面通常使用自然语言中的高级语义概念进行分析，但大量的轨道图像档案仍以像素级别组织，这种不匹配限制了行星表面可扩展、开放式的探索。

Method: 开发MarScope框架，将行星图像和文本对齐到共享语义空间中，基于超过20万个精心策划的图像-文本对进行训练，实现自然语言驱动的语义检索。

Result: 能够在5秒内对整个火星进行任意用户查询，F1分数高达0.978，超越了形态分类，支持过程导向分析和基于相似性的地貌映射。

Conclusion: MarScope建立了一个新范式，使自然语言成为大规模地理空间数据集科学发现的直接接口，改变了全球地貌映射的方式。

Abstract: Planetary surfaces are typically analyzed using high-level semantic concepts in natural language, yet vast orbital image archives remain organized at the pixel level. This mismatch limits scalable, open-ended exploration of planetary surfaces. Here we present MarScope, a planetary-scale vision-language framework enabling natural language-driven, label-free mapping of Martian landforms. MarScope aligns planetary images and text in a shared semantic space, trained on over 200,000 curated image-text pairs. This framework transforms global geomorphic mapping on Mars by replacing pre-defined classifications with flexible semantic retrieval, enabling arbitrary user queries across the entire planet in 5 seconds with F1 scores up to 0.978. Applications further show that it extends beyond morphological classification to facilitate process-oriented analysis and similarity-based geomorphological mapping at a planetary scale. MarScope establishes a new paradigm where natural language serves as a direct interface for scientific discovery over massive geospatial datasets.

</details>


### [155] [Decoupling Return-to-Go for Efficient Decision Transformer](https://arxiv.org/abs/2601.15953)
*Yongyi Wang,Hanyu Liu,Lingfeng Li,Bozhou Chen,Ang Li,Qirui Zheng,Xionghui Yang,Wenxin Li*

Main category: cs.AI

TL;DR: 决策变换器(DT)在离线强化学习中存在RTG序列冗余问题，作者提出解耦DT(DDT)简化架构，仅用最新RTG指导动作预测，提升性能并降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 发现决策变换器(DT)设计中的关键冗余问题：将整个Return-to-Go(RTG)序列输入Transformer在理论上是多余的，因为只有最新的RTG影响动作预测。这种冗余可能损害DT的性能。

Method: 提出解耦决策变换器(DDT)：简化架构，仅让Transformer处理观测和动作序列，使用最新的RTG来指导动作预测。这种流线型方法减少了计算成本。

Result: 实验表明，DDT显著优于原始DT，并在多个离线RL任务中与最先进的DT变体相比具有竞争力。

Conclusion: 通过识别并消除DT中的RTG序列冗余，提出的DDT架构不仅提高了性能，还降低了计算复杂度，为离线强化学习的序列建模方法提供了更高效的解决方案。

Abstract: The Decision Transformer (DT) has established a powerful sequence modeling approach to offline reinforcement learning. It conditions its action predictions on Return-to-Go (RTG), using it both to distinguish trajectory quality during training and to guide action generation at inference. In this work, we identify a critical redundancy in this design: feeding the entire sequence of RTGs into the Transformer is theoretically unnecessary, as only the most recent RTG affects action prediction. We show that this redundancy can impair DT's performance through experiments. To resolve this, we propose the Decoupled DT (DDT). DDT simplifies the architecture by processing only observation and action sequences through the Transformer, using the latest RTG to guide the action prediction. This streamlined approach not only improves performance but also reduces computational cost. Our experiments show that DDT significantly outperforms DT and establishes competitive performance against state-of-the-art DT variants across multiple offline RL tasks.

</details>


### [156] [Deja Vu in Plots: Leveraging Cross-Session Evidence with Retrieval-Augmented LLMs for Live Streaming Risk Assessment](https://arxiv.org/abs/2601.16027)
*Yiran Qiao,Xiang Ao,Jing Chen,Yang Liu,Qiwei Zhong,Qing He*

Main category: cs.AI

TL;DR: CS-VAR：用于直播风险评估的跨会话证据感知检索增强检测器，通过LLM指导的小型模型实现高效实时检测


<details>
  <summary>Details</summary>
Motivation: 直播平台面临复杂的风险（如诈骗和协同恶意行为），这些风险往往逐渐累积并在看似无关的直播中重复出现，现有检测方法难以有效识别这些跨会话的累积性风险模式

Method: 提出CS-VAR框架：1）使用轻量级领域特定模型进行快速会话级风险推断；2）训练时由LLM指导，LLM基于检索的跨会话行为证据进行推理；3）将LLM的局部到全局洞察转移到小型模型，使其能够识别跨流重复模式并保持实时部署效率

Result: 在大规模工业数据集上的离线实验和在线验证表明CS-VAR达到最先进性能，同时提供可解释的本地化信号，有效支持实际直播内容审核

Conclusion: CS-VAR通过结合LLM的跨会话推理能力和轻量级模型的实时效率，成功解决了直播平台中复杂、累积性风险的检测问题，为实际内容审核提供了有效工具

Abstract: The rise of live streaming has transformed online interaction, enabling massive real-time engagement but also exposing platforms to complex risks such as scams and coordinated malicious behaviors. Detecting these risks is challenging because harmful actions often accumulate gradually and recur across seemingly unrelated streams. To address this, we propose CS-VAR (Cross-Session Evidence-Aware Retrieval-Augmented Detector) for live streaming risk assessment. In CS-VAR, a lightweight, domain-specific model performs fast session-level risk inference, guided during training by a Large Language Model (LLM) that reasons over retrieved cross-session behavioral evidence and transfers its local-to-global insights to the small model. This design enables the small model to recognize recurring patterns across streams, perform structured risk assessment, and maintain efficiency for real-time deployment. Extensive offline experiments on large-scale industrial datasets, combined with online validation, demonstrate the state-of-the-art performance of CS-VAR. Furthermore, CS-VAR provides interpretable, localized signals that effectively empower real-world moderation for live streaming.

</details>


### [157] [Grounding Large Language Models in Reaction Knowledge Graphs for Synthesis Retrieval](https://arxiv.org/abs/2601.16038)
*Olga Bunkova,Lorenzo Di Fruscia,Sophia Rupprecht,Artur M. Schweidtmann,Marcel J. T. Reinders,Jana M. Weber*

Main category: cs.AI

TL;DR: 该研究将化学反应路径检索转化为Text2Cypher生成问题，比较了不同提示策略，发现使用对齐示例的单次提示效果最佳，并提供了可复现的评估框架。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在化学合成规划中常产生幻觉或过时建议，需要更可靠的方法来利用反应知识图谱进行合成路径检索。

Method: 将反应路径检索定义为Text2Cypher生成问题，比较零次提示与使用静态、随机和嵌入对齐示例的单次提示策略，并评估清单驱动的验证/校正循环。

Result: 使用对齐示例的单次提示始终表现最佳；清单式自校正循环主要在零次设置中提高可执行性，在已有良好示例时检索增益有限。

Conclusion: 该研究为基于知识图谱的LLM合成规划提供了可复现的Text2Cypher评估框架，展示了示例对齐对检索性能的重要性。

Abstract: Large Language Models (LLMs) can aid synthesis planning in chemistry, but standard prompting methods often yield hallucinated or outdated suggestions. We study LLM interactions with a reaction knowledge graph by casting reaction path retrieval as a Text2Cypher (natural language to graph query) generation problem, and define single- and multi-step retrieval tasks. We compare zero-shot prompting to one-shot variants using static, random, and embedding-based exemplar selection, and assess a checklist-driven validator/corrector loop. To evaluate our framework, we consider query validity and retrieval accuracy. We find that one-shot prompting with aligned exemplars consistently performs best. Our checklist-style self-correction loop mainly improves executability in zero-shot settings and offers limited additional retrieval gains once a good exemplar is present. We provide a reproducible Text2Cypher evaluation setup to facilitate further work on KG-grounded LLMs for synthesis planning. Code is available at https://github.com/Intelligent-molecular-systems/KG-LLM-Synthesis-Retrieval.

</details>


### [158] [AgriPINN: A Process-Informed Neural Network for Interpretable and Scalable Crop Biomass Prediction Under Water Stress](https://arxiv.org/abs/2601.16045)
*Yue Shi,Liangxiu Han,Xin Zhang,Tam Sobeih,Thomas Gaiser,Nguyen Huu Thuy,Dominik Behrend,Amit Kumar Srivastava,Krishnagopal Halder,Frank Ewert*

Main category: cs.AI

TL;DR: AgriPINN：结合生物物理过程模型与深度学习的混合框架，用于预测水分胁迫下的作物地上生物量，在精度和计算效率上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动模型可扩展但缺乏可解释性且对分布变化敏感，而基于过程的作物模型需要大量校准且难以在大空间范围部署。需要结合两者优势的方法来准确预测水分胁迫下的作物生物量。

Method: 提出AgriPINN，将生物物理作物生长微分方程作为可微分约束集成到深度学习主干中，无需直接监督即可恢复LAI、PAR、RUE和水分胁迫因子等潜在生理变量。

Result: AgriPINN在德国397个区域60年历史数据上预训练，在三年受控水分处理田间实验上微调，相比ConvLSTM-ViT、SLTF、CNN-Transformer等深度学习方法以及LINTUL5过程模型，精度提升达43%（RMSE降低），计算效率更高。

Conclusion: AgriPINN结合了深度学习的可扩展性和过程模型的生物物理严谨性，为时空生物量预测提供了稳健且可解释的框架，对灌溉基础设施规划、产量预测和气候适应规划具有实用价值。

Abstract: Accurate prediction of crop above-ground biomass (AGB) under water stress is critical for monitoring crop productivity, guiding irrigation, and supporting climate-resilient agriculture. Data-driven models scale well but often lack interpretability and degrade under distribution shift, whereas process-based crop models (e.g. DSSAT, APSIM, LINTUL5) require extensive calibration and are difficult to deploy over large spatial domains. To address these limitations, we propose AgriPINN, a process-informed neural network that integrates a biophysical crop-growth differential equation as a differentiable constraint within a deep learning backbone. This design encourages physiologically consistent biomass dynamics under water-stress conditions while preserving model scalability for spatially distributed AGB prediction. AgriPINN recovers latent physiological variables, including leaf area index (LAI), absorbed photosynthetically active radiation (PAR), radiation use efficiency (RUE), and water-stress factors, without requiring direct supervision. We pretrain AgriPINN on 60 years of historical data across 397 regions in Germany and fine-tune it on three years of field experiments under controlled water treatments. Results show that AgriPINN consistently outperforms state-of-the-art deep-learning baselines (ConvLSTM-ViT, SLTF, CNN-Transformer) and the process-based LINTUL5 model in terms of accuracy (RMSE reductions up to $43\%$) and computational efficiency. By combining the scalability of deep learning with the biophysical rigor of process-based modeling, AgriPINN provides a robust and interpretable framework for spatio-temporal AGB prediction, offering practical value for planning of irrigation infrastructure, yield forecasting, and climate-adaptation planning.

</details>


### [159] [Designing faster mixed integer linear programming algorithm via learning the optimal path](https://arxiv.org/abs/2601.16056)
*Ruizhi Liu,Liming Xu,Xulin Huang,Jingyan Sui,Shizhe Ding,Boyang Xia,Chungong Yu,Dongbo Bu*

Main category: cs.AI

TL;DR: DeepBound：基于深度学习的节点选择算法，通过多级特征融合网络和成对训练范式，自动学习分支定界树中的最优节点优先级，显著提升混合整数线性规划求解效率。


<details>
  <summary>Details</summary>
Motivation: 传统混合整数线性规划求解依赖人工设计的启发式策略，这些策略在不同问题实例上表现不稳定且不可预测。需要自动化学习人类直觉的方法来提高求解效率和稳定性。

Method: 提出DeepBound算法：1）使用多级特征融合网络捕捉节点表示；2）采用成对训练范式解决分支定界树中的节点不平衡问题；3）学习优先选择包含最优解的节点。

Result: 在三个NP难MILP基准测试上，DeepBound比传统启发式规则和现有学习方法获得更优的求解效率，显著减少计算时间找到最优可行解，并在大型复杂实例上表现出强泛化能力。

Conclusion: DeepBound能够自动发现更灵活鲁棒的特征选择，有效改进并可能替代人工设计的启发式规则，为MILP求解提供了数据驱动的自动化解决方案。

Abstract: Designing faster algorithms for solving Mixed-Integer Linear Programming (MILP) problems is highly desired across numerous practical domains, as a vast array of complex real-world challenges can be effectively modeled as MILP formulations. Solving these problems typically employs the branch-and-bound algorithm, the core of which can be conceived as searching for a path of nodes (or sub-problems) that contains the optimal solution to the original MILP problem. Traditional approaches to finding this path rely heavily on hand-crafted, intuition-based heuristic strategies, which often suffer from unstable and unpredictable performance across different MILP problem instances. To address this limitation, we introduce DeepBound, a deep learning-based node selection algorithm that automates the learning of such human intuition from data. The core of DeepBound lies in learning to prioritize nodes containing the optimal solution, thereby improving solving efficiency. DeepBound introduces a multi-level feature fusion network to capture the node representations. To tackle the inherent node imbalance in branch-and-bound trees, DeepBound employs a pairwise training paradigm that enhances the model's ability to discriminate between nodes. Extensive experiments on three NP-hard MILP benchmarks demonstrate that DeepBound achieves superior solving efficiency over conventional heuristic rules and existing learning-based approaches, obtaining optimal feasible solutions with significantly reduced computation time. Moreover, DeepBound demonstrates strong generalization capability on large and complex instances. The analysis of its learned features reveals that the method can automatically discover more flexible and robust feature selection, which may effectively improve and potentially replace human-designed heuristic rules.

</details>


### [160] [Controlling Long-Horizon Behavior in Language Model Agents with Explicit State Dynamics](https://arxiv.org/abs/2601.16087)
*Sukesh Subaharan*

Main category: cs.AI

TL;DR: 本文研究通过为LLM代理引入外部情感动态子系统（基于VAD模型），来增强多轮对话中的时间一致性和可控恢复能力，发现二阶动态在稳定性和响应性之间存在权衡。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理在长时交互中常出现语气和人设的突然转变，缺乏显式的时间结构来管理代理层面的状态。虽然先前工作关注回合层面的情感或静态情感分类，但显式情感动态在塑造长时程代理行为中的作用尚未充分探索。

Method: 引入代理层面的情感子系统，维护一个独立于语言模型的连续VAD（效价-唤醒-支配）状态，通过一阶和二阶更新规则进行管理。使用固定的无记忆估计器提取瞬时情感信号，并通过指数平滑或基于动量的动态进行时间积分。生成时将情感状态注入而不修改模型参数。

Result: 在25轮固定对话协议中比较无状态、一阶和二阶情感动态：无状态代理无法展现一致轨迹或恢复；状态持续性支持延迟响应和可靠恢复；二阶动态引入情感惯性和滞后效应，随动量增加而增强，揭示了稳定性和响应性之间的权衡。

Conclusion: 为LLM代理施加显式情感动态结构可以增强多轮对话的时间一致性和可控恢复能力，二阶动态在稳定性和响应性之间存在重要权衡，为设计更连贯的对话代理提供了新方向。

Abstract: Large language model (LLM) agents often exhibit abrupt shifts in tone and persona during extended interaction, reflecting the absence of explicit temporal structure governing agent-level state. While prior work emphasizes turn-local sentiment or static emotion classification, the role of explicit affective dynamics in shaping long-horizon agent behavior remains underexplored. This work investigates whether imposing dynamical structure on an external affective state can induce temporal coherence and controlled recovery in multi-turn dialogue. We introduce an agent-level affective subsystem that maintains a continuous Valence-Arousal-Dominance (VAD) state external to the language model and governed by first- and second-order update rules. Instantaneous affective signals are extracted using a fixed, memoryless estimator and integrated over time via exponential smoothing or momentum-based dynamics. The resulting affective state is injected back into generation without modifying model parameters. Using a fixed 25-turn dialogue protocol, we compare stateless, first-order, and second-order affective dynamics. Stateless agents fail to exhibit coherent trajectories or recovery, while state persistence enables delayed responses and reliable recovery. Second-order dynamics introduce affective inertia and hysteresis that increase with momentum, revealing a trade-off between stability and responsiveness.

</details>


### [161] [Multimodal Climate Disinformation Detection: Integrating Vision-Language Models with External Knowledge Sources](https://arxiv.org/abs/2601.16108)
*Marzieh Adeli Shamsabad,Hamed Ghodrati*

Main category: cs.AI

TL;DR: 该论文提出结合视觉语言模型与外部知识检索的方法，以改进对气候虚假信息的检测能力，特别是针对社交媒体上传播的误导性图像和视频。


<details>
  <summary>Details</summary>
Motivation: 气候虚假信息在数字世界中日益严重，特别是社交媒体上广泛传播的误导性图像和视频。这些虚假信息往往具有说服力且难以检测，可能延缓应对气候变化的行动。现有的视觉语言模型仅依赖训练时的知识，无法处理近期事件或更新的信息。

Method: 通过将视觉语言模型与外部知识检索相结合，系统能够获取最新信息，包括反向图像搜索结果、在线事实核查和可信专家内容，从而更准确地评估图像及其声明的真实性。

Result: 该方法提高了模型处理现实世界气候虚假信息的能力，能够更有效地判断图像及其声明的准确性、误导性、虚假性或不可验证性。

Conclusion: 结合外部知识检索的视觉语言模型方法能够克服传统模型的知识局限性，为保护公众对科学的理解提供支持，在快速变化的信息环境中更有效地应对气候虚假信息挑战。

Abstract: Climate disinformation has become a major challenge in today digital world, especially with the rise of misleading images and videos shared widely on social media. These false claims are often convincing and difficult to detect, which can delay actions on climate change. While vision-language models (VLMs) have been used to identify visual disinformation, they rely only on the knowledge available at the time of training. This limits their ability to reason about recent events or updates. The main goal of this paper is to overcome that limitation by combining VLMs with external knowledge. By retrieving up-to-date information such as reverse image results, online fact-checks, and trusted expert content, the system can better assess whether an image and its claim are accurate, misleading, false, or unverifiable. This approach improves the model ability to handle real-world climate disinformation and supports efforts to protect public understanding of science in a rapidly changing information landscape.

</details>


### [162] [LLM Prompt Evaluation for Educational Applications](https://arxiv.org/abs/2601.16134)
*Langdon Holmes,Adam Coscia,Scott Crossley,Joon Suh Choi,Wesley Morris*

Main category: cs.AI

TL;DR: 本文提出了一种系统化的方法评估教育应用中LLM提示词设计，通过分析结构化对话活动中LLM生成的后续问题，展示了如何基于证据优化提示词设计。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在教育应用中的普及，需要基于证据的方法来设计和评估能够产生个性化且教学对齐输出的提示词。当前缺乏系统化的评估框架，大多采用临时性的提示工程方法。

Method: 设计了六个结合不同教学策略的提示词模板，采用锦标赛式评估框架，使用Glicko2评分系统，由八位评委从格式、对话支持、学习者适宜性三个维度评估问题对。数据来自三个不同教育部署的120个真实用户交互。

Result: 结果显示，一个与策略性阅读相关的提示词模板表现最佳，在成对比较中胜率从81%到100%。该提示词结合了角色扮演和上下文管理两种模式，旨在支持元认知学习策略。

Conclusion: 该方法展示了教育技术研究者如何系统评估和改进提示词设计，从临时性的提示工程转向基于证据的教育应用提示词开发，为个性化教学对齐输出提供了可推广的评估框架。

Abstract: As large language models (LLMs) become increasingly common in educational applications, there is a growing need for evidence-based methods to design and evaluate LLM prompts that produce personalized and pedagogically aligned out-puts. This study presents a generalizable, systematic approach for evaluating prompts, demonstrated through an analysis of LLM-generated follow-up questions in a structured dialogue activity. Six prompt templates were designed and tested. The templates incorporated established prompt engineering patterns, with each prompt emphasizing distinct pedagogical strategies. The prompt templates were compared through a tournament-style evaluation framework that can be adapted for other educational applications. The tournament employed the Glicko2 rating system with eight judges evaluating question pairs across three dimensions: format, dialogue support, and appropriateness for learners. Data was sourced from 120 authentic user interactions across three distinct educational deployments. Results showed that a single prompt related to strategic reading out-performed other templates with win probabilities ranging from 81% to 100% in pairwise comparisons. This prompt combined persona and context manager pat-terns and was designed to support metacognitive learning strategies such as self-directed learning. The methodology showcases how educational technology re- searchers can systematically evaluate and improve prompt designs, moving beyond ad-hoc prompt engineering toward evidence-based prompt development for educational applications.

</details>


### [163] [Cosmos Policy: Fine-Tuning Video Models for Visuomotor Control and Planning](https://arxiv.org/abs/2601.16163)
*Moo Jin Kim,Yihuai Gao,Tsung-Yi Lin,Yen-Chen Lin,Yunhao Ge,Grace Lam,Percy Liang,Shuran Song,Ming-Yu Liu,Chelsea Finn,Jinwei Gu*

Main category: cs.AI

TL;DR: Cosmos Policy：通过单阶段后训练将预训练视频模型（Cosmos-Predict2）直接转化为机器人策略，无需架构修改，在仿真和真实世界任务中达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有视频模型已能捕捉复杂物理交互和场景演化，但将其用于机器人策略学习通常需要多阶段后训练和新架构组件，过程复杂。本研究旨在简化这一过程，直接利用预训练视频模型的时空先验

Method: 1. 使用预训练视频模型Cosmos-Predict2作为基础模型
2. 通过单阶段后训练在目标平台的机器人演示数据上微调
3. 将机器人动作编码为潜在帧，在模型的潜在扩散过程中直接生成动作
4. 同时生成未来状态图像和值函数（预期累积奖励），支持测试时规划

Result: 1. 在LIBERO和RoboCasa仿真基准上达到SOTA性能（平均成功率分别为98.5%和67.1%）
2. 在真实世界双手操作任务中获得最高平均分数
3. 优于从头训练的扩散策略、基于视频模型的策略以及在同一演示数据上微调的最先进视觉-语言-动作模型
4. 能够从策略执行数据中学习，改进世界模型和值函数，通过基于模型的规划进一步提高成功率

Conclusion: Cosmos Policy展示了通过简单单阶段后训练将预训练视频模型转化为高效机器人策略的可行性，充分利用了模型的预训练先验和核心学习算法，在仿真和真实世界任务中均表现出色，且具备从经验中学习和规划的能力

Abstract: Recent video generation models demonstrate remarkable ability to capture complex physical interactions and scene evolution over time. To leverage their spatiotemporal priors, robotics works have adapted video models for policy learning but introduce complexity by requiring multiple stages of post-training and new architectural components for action generation. In this work, we introduce Cosmos Policy, a simple approach for adapting a large pretrained video model (Cosmos-Predict2) into an effective robot policy through a single stage of post-training on the robot demonstration data collected on the target platform, with no architectural modifications. Cosmos Policy learns to directly generate robot actions encoded as latent frames within the video model's latent diffusion process, harnessing the model's pretrained priors and core learning algorithm to capture complex action distributions. Additionally, Cosmos Policy generates future state images and values (expected cumulative rewards), which are similarly encoded as latent frames, enabling test-time planning of action trajectories with higher likelihood of success. In our evaluations, Cosmos Policy achieves state-of-the-art performance on the LIBERO and RoboCasa simulation benchmarks (98.5% and 67.1% average success rates, respectively) and the highest average score in challenging real-world bimanual manipulation tasks, outperforming strong diffusion policies trained from scratch, video model-based policies, and state-of-the-art vision-language-action models fine-tuned on the same robot demonstrations. Furthermore, given policy rollout data, Cosmos Policy can learn from experience to refine its world model and value function and leverage model-based planning to achieve even higher success rates in challenging tasks. We release code, models, and training data at https://research.nvidia.com/labs/dir/cosmos-policy/

</details>


### [164] [Structured Hints for Sample-Efficient Lean Theorem Proving](https://arxiv.org/abs/2601.16172)
*Zachary Burton*

Main category: cs.AI

TL;DR: 在miniF2F基准测试中，通过固定提示调度对15种常见战术骨架进行轻量级干预，使pass@16从15.2%提升到21.7%，相对提升43%，表明即使经过强化学习训练的强大证明器也未能充分利用战术语言中的结构先验。


<details>
  <summary>Details</summary>
Motivation: 研究高度训练的神经定理证明器（如DeepSeek-Prover-V1.5）在推理时是否仍能从简单的结构指导中受益，探索这些模型是否未能充分利用战术语言中可用的结构先验。

Method: 采用轻量级干预方法：在miniF2F基准测试上评估固定的提示调度策略，该策略覆盖15种常见战术骨架，使用相同数量的样本（k=16）和相同的最大生成长度（1024个token）。

Result: 简单方法使pass@16达到21.7%，而标准采样仅为15.2%，相对提升43%，表明推理时指导能显著提升性能。

Conclusion: 即使经过强化学习训练的强大证明器也未能充分利用战术语言中的结构先验，简单的推理时指导仍然是廉价且互补的性能提升方法。

Abstract: State-of-the-art neural theorem provers like DeepSeek-Prover-V1.5 combine large language models with reinforcement learning, achieving impressive results through sophisticated training. We ask: do these highly-trained models still benefit from simple structural guidance at inference time? We evaluate a lightweight intervention -- a fixed prompt schedule over 15 common tactic skeletons -- on the miniF2F benchmark. This simple approach yields 21.7% pass@16 compared to 15.2% for standard sampling from the same model, a 43% relative improvement using the same number of samples (k=16) and same maximum generation length (1024 tokens). Our results suggest that even capable RL-trained provers underutilize structural priors available in the tactic language, and that simple inference-time guidance remains a cheap, complementary boost.

</details>


### [165] [Scalable Board Expansion within a General Game System](https://arxiv.org/abs/2601.16216)
*Clémentine Sacré*

Main category: cs.AI

TL;DR: 提出基于通用游戏系统的动态棋盘扩展机制，解决传统棋盘游戏中静态超大棋盘导致的复杂度问题


<details>
  <summary>Details</summary>
Motivation: 传统棋盘游戏实现通常依赖预先定义的超大静态棋盘，即使大部分区域在游戏中从未使用，这种设计导致不必要的复杂度

Method: 使用通用游戏系统支持动态棋盘扩展机制，在游戏过程中自动扩展棋盘

Result: 论文提出了动态棋盘扩展机制，但摘要中未提供具体实验结果

Conclusion: 动态棋盘扩展机制能够解决传统静态棋盘设计中的复杂度问题，提高游戏实现的效率

Abstract: This thesis explores the use of a General Game System (GGS) to support the automatic expansion of game boards in boardless games. Traditional implementations of such games often rely on oversized static boards defined from the start, even though large portions of these boards may never be used during gameplay. This approach leads to unnecessary complexity. To address this issue, this thesis propose a dynamic board expansion mechanism in which the game board grows automatically during play.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [166] [NL4ST: A Natural Language Query Tool for Spatio-Temporal Databases](https://arxiv.org/abs/2601.15758)
*Xieyang Wang,Mengyi Liu,Weijia Yi,Jianqiu Xu,Raymond Chi-Wing Wong*

Main category: cs.DB

TL;DR: NL4ST是一个交互式工具，允许用户用自然语言查询时空数据库，通过三层架构将自然语言转换为物理查询计划。


<details>
  <summary>Details</summary>
Motivation: 移动计算设备和定位技术的发展导致时空数据爆炸式增长，但非专业用户难以使用专业查询语言，需要自然语言查询支持。

Method: 采用三层架构：知识库和语料库进行知识准备，自然语言理解进行实体链接，最后生成物理查询计划。

Result: 在四个真实和合成数据集上验证了NL4ST能够提供有效的时空物理查询计划，工具已在线提供。

Conclusion: NL4ST成功弥合了非专业用户与数据库查询计划之间的鸿沟，使时空数据库查询更加易用。

Abstract: The advancement of mobile computing devices and positioning technologies has led to an explosive growth of spatio-temporal data managed in databases. Representative queries over such data include range queries, nearest neighbor queries, and join queries. However, formulating those queries usually requires domain-specific expertise and familiarity with executable query languages, which would be a challenging task for non-expert users. It leads to a great demand for well-supported natural language queries (NLQs) in spatio-temporal databases. To bridge the gap between non-experts and query plans in databases, we present NL4ST, an interactive tool that allows users to query spatio-temporal databases in natural language. NL4ST features a three-layer architecture: (i) knowledge base and corpus for knowledge preparation, (ii) natural language understanding for entity linking, and (iii) generating physical plans. Our demonstration will showcase how NL4ST provides effective spatio-temporal physical plans, verified by using four real and synthetic datasets. We make NL4ST online and provide the demo video at https://youtu.be/-J1R7R5WoqQ.

</details>


### [167] [Efficient Cloud-edge Collaborative Approaches to SPARQL Queries over Large RDF graphs](https://arxiv.org/abs/2601.15992)
*Shidan Ma,Peng Peng,Xu Zhou,M. Tamer Özsu,Lei Zou,Guo Chen*

Main category: cs.DB

TL;DR: 该论文首次探索将边缘计算集成到RDF图存储和SPARQL查询中，通过将数据处理移至边缘环境来提升查询性能，解决了数据本地化和网络调度两大挑战。


<details>
  <summary>Details</summary>
Motivation: 随着RDF图使用增加，基于云的SPARQL查询解决方案在带宽有限或系统负载高的环境中存在性能瓶颈，需要探索边缘计算来改善查询性能。

Method: 提出模式诱导子图概念解决数据本地化问题；构建系统模型联合考虑数据分布、查询特征、网络通信和计算资源；将查询分配和计算资源分配建模为MINLP问题，使用改进的分支定界算法求解。

Result: 在真实云平台上的实验结果表明，该方法在效率上优于最先进的基线方法，代码已在GitHub上开源。

Conclusion: 通过边缘计算集成，成功提升了RDF图存储和SPARQL查询性能，为解决云环境下查询瓶颈提供了有效方案。

Abstract: With the increasing use of RDF graphs, storing and querying such data using SPARQL remains a critical problem. Current mainstream solutions rely on cloud-based data management architectures, but often suffer from performance bottle- necks in environments with limited bandwidth or high system load. To address this issue, this paper explores for the first time the integration of edge computing to move graph data storage and processing to edge environments, thereby improving query performance. This approach requires offloading query processing to edge servers, which involves addressing two challenges: data localization and network scheduling. First, the data localization challenge lies in computing the subgraphs maintained on edge servers to quickly identify the servers that can handle specific queries. To address this challenge, we introduce a new concept of pattern-induced subgraphs. Second, the network scheduling challenge involves efficiently assigning queries to edge and cloud servers to optimize overall system performance. We tackle this by constructing a overall system model that jointly captures data distribution, query characteristics, network communication, and computational resources. Accordingly, we further propose a joint formulation of query assignment and computational resource allocation, modeling it as a Mixed Integer Nonlinear Programming (MINLP) problem and solve this problem using a modified branch-and-bound algorithm. Experimental results on real datasets under a real cloud platform demonstrate that our proposed method outperforms the state-of-the-art baseline methods in terms of efficiency. The codes are available on GitHub

</details>


### [168] [EAIFD: A Fast and Scalable Algorithm for Incremental Functional Dependency Discovery](https://arxiv.org/abs/2601.16025)
*Yajuan Xu,Xixian Han,Xiaolong Wan*

Main category: cs.DB

TL;DR: EAIFD是一种用于增量函数依赖发现的新算法，通过维护差异集的部分超图并将问题转化为超图的最小命中集枚举，避免了完全重新运行。采用多属性哈希表和两步验证策略，显著提升了性能和内存效率。


<details>
  <summary>Details</summary>
Motivation: 函数依赖是关系数据库中的基本完整性约束，但在增量更新下的发现仍然具有挑战性。静态算法因完全重新执行而效率低下，增量算法则存在严重的性能和内存瓶颈。

Method: EAIFD维护差异集的部分超图，将增量FD发现问题重新定义为超图上的最小命中集枚举。提出两个关键创新：1) 多属性哈希表(MHT)用于高效存储有效FD的键值映射，其内存消耗与数据集大小无关；2) 两步验证策略，利用MHT减少验证空间，然后选择性加载数据块进行批量验证，避免重复I/O操作。

Result: 在真实数据集上的实验结果表明，EAIFD相比现有算法在运行时间上实现了高达一个数量级的加速，同时将内存使用量减少了两个数量级以上。

Conclusion: EAIFD为增量函数依赖发现提供了一个高效且可扩展的解决方案，显著克服了现有方法在性能和内存方面的瓶颈。

Abstract: Functional dependencies (FDs) are fundamental integrity constraints in relational databases, but discovering them under incremental updates remains challenging. While static algorithms are inefficient due to full re-execution, incremental algorithms suffer from severe performance and memory bottlenecks. To address these challenges, this paper proposes EAIFD, a novel algorithm for incremental FD discovery. EAIFD maintains the partial hypergraph of difference sets and reframes the incremental FD discovery problem into minimal hitting set enumeration on hypergraph, avoiding full re-runs. EAIFD introduces two key innovations. First, a multi-attribute hash table ($MHT$) is devised for high-frequency key-value mappings of valid FDs, whose memory consumption is proven to be independent of the dataset size. Second, two-step validation strategy is developed to efficiently validate the enumerated candidates, which leverages $MHT$ to effectively reduce the validation space and then selectively loads data blocks for batch validation of remaining candidates, effectively avoiding repeated I/O operations. Experimental results on real-world datasets demonstrate the significant advantages of EAIFD. Compared to existing algorithms, EAIFD achieves up to an order-of-magnitude speedup in runtime while reducing memory usage by over two orders-of-magnitude, establishing it as a highly efficient and scalable solution for incremental FD discovery.

</details>
