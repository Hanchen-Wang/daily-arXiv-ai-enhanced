<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 161]
- [cs.CL](#cs.CL) [Total: 111]
- [cs.DB](#cs.DB) [Total: 5]
- [cs.AI](#cs.AI) [Total: 69]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Scientific Image Synthesis: Benchmarking, Methodologies, and Downstream Utility](https://arxiv.org/abs/2601.17027)
*Honglin Lin,Chonghan Qin,Zheng Liu,Qizhi Pei,Yu Li,Zhanping Zhong,Xin Gao,Yanfeng Wang,Conghui He,Lijun Wu*

Main category: cs.CV

TL;DR: ImgCoder框架通过"理解-规划-编码"工作流提升科学图像合成的逻辑准确性，SciGenBench评估生成图像的信息效用和逻辑有效性，验证高质量合成科学图像可提升多模态推理能力。


<details>
  <summary>Details</summary>
Motivation: 多模态推理受限于难以合成科学严谨的图像，现有文本到图像模型常产生视觉合理但科学错误的输出，存在视觉-逻辑分歧问题，限制了其在科学推理中的价值。

Method: 提出ImgCoder逻辑驱动框架，采用"理解-规划-编码"工作流提升结构精度；引入SciGenBench评估生成图像的信息效用和逻辑有效性；分析像素生成和程序化合成两种范式。

Result: 评估揭示了像素模型存在系统性失败模式，发现了表达力-精度权衡；在严格验证的合成科学图像上微调大型多模态模型可获得一致的推理提升，显示出类似文本领域的扩展趋势。

Conclusion: 高保真科学图像合成是解锁大规模多模态推理能力的可行路径，逻辑驱动的程序化合成方法能有效解决视觉-逻辑分歧问题，为科学推理提供可靠的多模态数据。

Abstract: While synthetic data has proven effective for improving scientific reasoning in the text domain, multimodal reasoning remains constrained by the difficulty of synthesizing scientifically rigorous images. Existing Text-to-Image (T2I) models often produce outputs that are visually plausible yet scientifically incorrect, resulting in a persistent visual-logic divergence that limits their value for downstream reasoning. Motivated by recent advances in next-generation T2I models, we conduct a systematic study of scientific image synthesis across generation paradigms, evaluation, and downstream use. We analyze both direct pixel-based generation and programmatic synthesis, and propose ImgCoder, a logic-driven framework that follows an explicit "understand - plan - code" workflow to improve structural precision. To rigorously assess scientific correctness, we introduce SciGenBench, which evaluates generated images based on information utility and logical validity. Our evaluation reveals systematic failure modes in pixel-based models and highlights a fundamental expressiveness-precision trade-off. Finally, we show that fine-tuning Large Multimodal Models (LMMs) on rigorously verified synthetic scientific images yields consistent reasoning gains, with potential scaling trends analogous to the text domain, validating high-fidelity scientific synthesis as a viable path to unlocking massive multimodal reasoning capabilities.

</details>


### [2] [Data-Efficient Meningioma Segmentation via Implicit Spatiotemporal Mixing and Sim2Real Semantic Injection](https://arxiv.org/abs/2601.17031)
*Yunhao Xu,Fuquan Zong,Yexuan Xing,Chulong Zhang,Guang Yang,Shilong Yang,Xiaokun Liang,Juan Yu*

Main category: cs.CV

TL;DR: 提出双增强框架，结合空间流形扩展和语义对象注入，通过INR建模连续速度场和线性混合变形场，以及Sim2Real病灶注入模块，在有限标注下提升医学图像分割的数据利用效率。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割性能越来越取决于数据利用效率而非原始数据量。对于脑膜瘤等复杂病理，需要充分利用有限高质量标注中的潜在信息，最大化现有数据集价值。

Method: 提出双增强框架：1) 使用隐式神经表示(INR)建模连续速度场，在变形空间进行线性插值，从少量锚点生成解剖学合理的结构变化；2) Sim2Real病灶注入模块，将病灶纹理移植到健康解剖背景中构建高保真模拟域，弥合合成增强与真实病理的差距。

Result: 在混合数据集上的综合实验表明，该框架显著提升了nnU-Net和U-Mamba等最先进模型的数据效率和鲁棒性。

Conclusion: 该框架为有限标注预算下的高性能医学图像分析提供了有效策略，通过协同整合空间和语义增强，最大化现有数据集的价值。

Abstract: The performance of medical image segmentation is increasingly defined by the efficiency of data utilization rather than merely the volume of raw data. Accurate segmentation, particularly for complex pathologies like meningiomas, demands that models fully exploit the latent information within limited high-quality annotations. To maximize the value of existing datasets, we propose a novel dual-augmentation framework that synergistically integrates spatial manifold expansion and semantic object injection. Specifically, we leverage Implicit Neural Representations (INR) to model continuous velocity fields. Unlike previous methods, we perform linear mixing on the integrated deformation fields, enabling the efficient generation of anatomically plausible variations by interpolating within the deformation space. This approach allows for the extensive exploration of structural diversity from a small set of anchors. Furthermore, we introduce a Sim2Real lesion injection module. This module constructs a high-fidelity simulation domain by transplanting lesion textures into healthy anatomical backgrounds, effectively bridging the gap between synthetic augmentation and real-world pathology. Comprehensive experiments on a hybrid dataset demonstrate that our framework significantly enhances the data efficiency and robustness of state-of-the-art models, including nnU-Net and U-Mamba, offering a potent strategy for high-performance medical image analysis with limited annotation budgets.

</details>


### [3] [Diagnosis Support of Sickle Cell Anemia by Classifying Red Blood Cell Shape in Peripheral Blood Images](https://arxiv.org/abs/2601.17032)
*Wilkie Delgado-Font,Miriela Escobedo-Nicot,Manuel González-Hidalgo,Silena Herold-Garcia,Antoni Jaume-i-Capó,Arnau Mir*

Main category: cs.CV

TL;DR: 提出一种基于外周血涂片图像分析的自动化红细胞分类方法，用于镰状细胞贫血诊断，通过Chan-Vese主动轮廓模型分割和形状分析描述子（CSF和ESF）分类正常与变形红细胞。


<details>
  <summary>Details</summary>
Motivation: 传统显微镜观察红细胞变形（如镰状细胞贫血）耗时且依赖专家，主观性强、错误率高，需要自动化、客观的诊断方法。

Method: 使用Chan-Vese主动轮廓模型分割血涂片图像中的红细胞，然后通过圆形形状因子（CSF）和椭圆形形状因子（ESF）进行形状分析，对正常、细长及其他变形红细胞进行分类，并对簇状遮挡细胞进行椭圆拟合调整。

Result: 实验结果显示该方法优于现有方法，F-measure值达到0.97（正常细胞）和0.95（细长细胞），整体多类性能指标优秀，适用于镰状细胞贫血的临床治疗和诊断支持。

Conclusion: 提出的自动化红细胞分类方法能有效辅助镰状细胞贫血诊断，提供客观、准确的细胞形态分析，具有临床应用价值。

Abstract: Red blood cell (RBC) deformation is the consequence of several diseases, including sickle cell anemia, which causes recurring episodes of pain and severe pronounced anemia. Monitoring patients with these diseases involves the observation of peripheral blood samples under a microscope, a time-consuming procedure. Moreover, a specialist is required to perform this technique, and owing to the subjective nature of the observation of isolated RBCs, the error rate is high. In this paper, we propose an automated method for differentially enumerating RBCs that uses peripheral blood smear image analysis. In this method, the objects of interest in the image are segmented using a Chan-Vese active contour model. An analysis is then performed to classify the RBCs, also called erythrocytes, as normal or elongated or having other deformations, using the basic shape analysis descriptors: circular shape factor (CSF) and elliptical shape factor (ESF). To analyze cells that become partially occluded in a cluster during sample preparation, an elliptical adjustment is performed to allow the analysis of erythrocytes with discoidal and elongated shapes. The images of patient blood samples used in the study were acquired by a clinical laboratory specialist in the Special Hematology Department of the ``Dr. Juan Bruno Zayas'' General Hospital in Santiago de Cuba. A comparison of the results obtained by the proposed method in our experiments with those obtained by some state-of-the-art methods showed that the proposed method is superior for the diagnosis of sickle cell anemia. This superiority is achieved for evidenced by the obtained F-measure value (0.97 for normal cells and 0.95 for elongated ones) and several overall multiclass performance measures. The results achieved by the proposed method are suitable for the purpose of clinical treatment and diagnostic support of sickle cell anemia.

</details>


### [4] [AMVICC: A Novel Benchmark for Cross-Modal Failure Mode Profiling for VLMs and IGMs](https://arxiv.org/abs/2601.17037)
*Aahana Basappa,Pranay Goel,Anusri Karra,Anish Karra,Asa Gilmore,Kevin Zhu*

Main category: cs.CV

TL;DR: 研究者创建了AMVICC基准，用于系统评估多模态大语言模型和图像生成模型在视觉推理任务中的失败模式，发现模型在物体方向、数量、空间关系等基本视觉概念上存在共同和特定的失败模式。


<details>
  <summary>Details</summary>
Motivation: 尽管机器学习快速发展，但视觉语言模型在理解和生成基本视觉概念（如物体方向、数量、空间关系）方面仍存在明显缺陷，这凸显了基础视觉推理能力的不足，需要系统评估跨模态的失败模式。

Method: 通过将MMVP基准问题转化为显式和隐式提示，创建了AMVICC基准，用于分析不同模态的失败模式。测试了11个MLLM和3个IGM在九个视觉推理类别上的表现。

Result: 失败模式在模型和模态间有共享性，但也有模型特定和模态特定的失败。IGM在处理显式提示时特别困难，表明对细粒度视觉属性的控制能力不足。

Conclusion: 这项工作为未来的跨模态对齐研究奠定了基础，提供了一个框架来探究生成和理解失败是否源于共享的局限性，以指导统一视觉语言建模的未来改进。

Abstract: We investigated visual reasoning limitations of both multimodal large language models (MLLMs) and image generation models (IGMs) by creating a novel benchmark to systematically compare failure modes across image-to-text and text-to-image tasks, enabling cross-modal evaluation of visual understanding. Despite rapid growth in machine learning, vision language models (VLMs) still fail to understand or generate basic visual concepts such as object orientation, quantity, or spatial relationships, which highlighted gaps in elementary visual reasoning. By adapting MMVP benchmark questions into explicit and implicit prompts, we create \textit{AMVICC}, a novel benchmark for profiling failure modes across various modalities. After testing 11 MLLMs and 3 IGMs in nine categories of visual reasoning, our results show that failure modes are often shared between models and modalities, but certain failures are model-specific and modality-specific, and this can potentially be attributed to various factors. IGMs consistently struggled to manipulate specific visual components in response to prompts, especially in explicit prompts, suggesting poor control over fine-grained visual attributes. Our findings apply most directly to the evaluation of existing state-of-the-art models on structured visual reasoning tasks. This work lays the foundation for future cross-modal alignment studies, offering a framework to probe whether generation and interpretation failures stem from shared limitations to guide future improvements in unified vision-language modeling.

</details>


### [5] [Hybrid Deep Feature Extraction and ML for Construction and Demolition Debris Classification](https://arxiv.org/abs/2601.17038)
*Obai Alashram,Nejad Alagha,Mahmoud AlKakuri,Zeeshan Swaveel,Abigail Copiaco*

Main category: cs.CV

TL;DR: 该研究提出了一种混合视觉管道，结合深度特征提取与传统机器学习分类器，用于建筑垃圾自动分类，在真实数据集上达到99.5%的准确率。


<details>
  <summary>Details</summary>
Motivation: 建筑业产生大量废弃物，有效的分类对于可持续废物管理和资源回收至关重要。现有方法需要更高效、准确的自动化分类解决方案。

Method: 收集了阿联酋真实建筑工地的1,800张平衡高质量图像，涵盖陶瓷/瓷砖、混凝土、垃圾/废物、木材四类材料。使用预训练的Xception网络提取深度特征，然后系统评估SVM、kNN、Bagged Trees、LDA和逻辑回归等多种机器学习分类器。

Result: 混合管道（Xception特征+简单分类器如线性SVM、kNN、Bagged Trees）实现了最先进的性能，准确率和宏F1分数高达99.5%，超越了更复杂或端到端的深度学习方法。

Conclusion: 该方法为稳健、可现场部署的建筑垃圾识别提供了操作优势，并为未来与机器人和现场自动化系统的集成提供了途径。

Abstract: The construction industry produces significant volumes of debris, making effective sorting and classification critical for sustainable waste management and resource recovery. This study presents a hybrid vision-based pipeline that integrates deep feature extraction with classical machine learning (ML) classifiers for automated construction and demolition (C\&D) debris classification. A novel dataset comprising 1,800 balanced, high-quality images representing four material categories, Ceramic/Tile, Concrete, Trash/Waste, and Wood was collected from real construction sites in the UAE, capturing diverse real-world conditions. Deep features were extracted using a pre-trained Xception network, and multiple ML classifiers, including SVM, kNN, Bagged Trees, LDA, and Logistic Regression, were systematically evaluated. The results demonstrate that hybrid pipelines using Xception features with simple classifiers such as Linear SVM, kNN, and Bagged Trees achieve state-of-the-art performance, with up to 99.5\% accuracy and macro-F1 scores, surpassing more complex or end-to-end deep learning approaches. The analysis highlights the operational benefits of this approach for robust, field-deployable debris identification and provides pathways for future integration with robotics and onsite automation systems.

</details>


### [6] [MANGO: A Global Single-Date Paired Dataset for Mangrove Segmentation](https://arxiv.org/abs/2601.17039)
*Junhyuk Heo,Beomkyu Choi,Hyunjin Shin,Darongsae Kwon*

Main category: cs.CV

TL;DR: 提出了MANGO数据集，包含42,703个标注的图像-掩码对，覆盖124个国家，用于全球红树林监测


<details>
  <summary>Details</summary>
Motivation: 现有红树林监测数据集存在局限性：只有年度地图产品而没有单日期图像-掩码对、局限于特定区域而非全球覆盖、或不可公开访问，这阻碍了深度学习在红树林检测中的进展

Method: 检索2020年红树林区域所有可用的Sentinel-2影像，使用目标检测驱动的方法选择与红树林年度掩码对齐的最佳单日期观测，利用像素级坐标参考确保自适应和代表性的图像-掩码配对

Result: 构建了MANGO大规模全球数据集，包含42,703个标注的图像-掩码对，覆盖124个国家，并在不同语义分割架构下建立了国家不相交分割的基准

Conclusion: MANGO数据集为可扩展和可靠的全球红树林监测奠定了基础，解决了现有数据集的局限性，促进了深度学习在红树林检测中的应用

Abstract: Mangroves are critical for climate-change mitigation, requiring reliable monitoring for effective conservation. While deep learning has emerged as a powerful tool for mangrove detection, its progress is hindered by the limitations of existing datasets. In particular, many resources provide only annual map products without curated single-date image-mask pairs, limited to specific regions rather than global coverage, or remain inaccessible to the public. To address these challenges, we introduce MANGO, a large-scale global dataset comprising 42,703 labeled image-mask pairs across 124 countries. To construct this dataset, we retrieve all available Sentinel-2 imagery within the year 2020 for mangrove regions and select the best single-date observations that align with the mangrove annual mask. This selection is performed using a target detection-driven approach that leverages pixel-wise coordinate references to ensure adaptive and representative image-mask pairings. We also provide a benchmark across diverse semantic segmentation architectures under a country-disjoint split, establishing a foundation for scalable and reliable global mangrove monitoring.

</details>


### [7] [FP-THD: Full page transcription of historical documents](https://arxiv.org/abs/2601.17040)
*H Neji,J Nogueras-Iso,J Lacasta,MÁ Latre,FJ García-Marco*

Main category: cs.CV

TL;DR: 提出一个用于转录15-16世纪拉丁文历史文献的管道，通过布局分析模型提取文本行，再使用OCR模型进行识别，保留特殊字符和符号以维持历史文本的原始风格和意义。


<details>
  <summary>Details</summary>
Motivation: 15-16世纪拉丁文历史文献的转录面临特殊挑战，需要保留具有特定含义的字符和特殊符号，以确保历史文本保持其原始风格和意义。现有方法在处理这类文献时难以有效保留这些特征。

Method: 提出一个管道方法：1）使用布局分析模型分析历史文本图像以提取文本行；2）将提取的文本行输入OCR模型进行识别；3）扩展现有的文本行识别方法，结合布局分析模型；4）使用掩码自编码器处理不同类型的文本（手写、印刷、多语言）。

Result: 该管道能够有效处理整页文档并产生高效结果。在多个数据集上的评估表明，掩码自编码器能够有效处理不同类型的文本，包括手写、印刷和多语言文本。

Conclusion: 提出的管道方法能够有效转录15-16世纪拉丁文历史文献，保留特殊字符和符号，确保历史文本的原始风格和意义得以维持。该方法在多种文本类型上表现出良好的处理能力。

Abstract: The transcription of historical documents written in Latin in XV and XVI centuries has special challenges as it must maintain the characters and special symbols that have distinct meanings to ensure that historical texts retain their original style and significance. This work proposes a pipeline for the transcription of historical documents preserving these special features. We propose to extend an existing text line recognition method with a layout analysis model. We analyze historical text images using a layout analysis model to extract text lines, which are then processed by an OCR model to generate a fully digitized page. We showed that our pipeline facilitates the processing of the page and produces an efficient result. We evaluated our approach on multiple datasets and demonstrate that the masked autoencoder effectively processes different types of text, including handwritten, printed and multi-language.

</details>


### [8] [Arabic Sign Language Recognition using Multimodal Approach](https://arxiv.org/abs/2601.17041)
*Ghadeer Alanazi,Abir Benabid*

Main category: cs.CV

TL;DR: 该研究提出了一种结合Leap Motion和RGB摄像头的多模态方法，用于阿拉伯手语识别，通过融合两种传感器的数据来提高识别准确率。


<details>
  <summary>Details</summary>
Motivation: 现有阿拉伯手语识别系统依赖单一传感器（Leap Motion或RGB摄像头），存在复杂手部方向跟踪不足和3D手部运动识别不精确的问题，需要多模态方法来克服这些限制。

Method: 采用双并行子网络架构：1) 针对Leap Motion数据的自定义密集神经网络，包含dropout和L2正则化；2) 基于微调VGG16模型的图像子网络，采用数据增强技术。两种模态的特征表示在融合模型中拼接，通过全连接层处理，最后使用SoftMax激活进行分类。

Result: 在包含18个阿拉伯手语单词的自定义数据集上评估，正确识别了13个单词，总体准确率达到78%，初步验证了多模态融合在手语识别中的可行性。

Conclusion: 多模态融合方法在阿拉伯手语识别中具有潜力，但需要进一步优化和数据集扩展以提高性能，为未来研究提供了方向。

Abstract: Arabic Sign Language (ArSL) is an essential communication method for individuals in the Deaf and Hard-of-Hearing community. However, existing recognition systems face significant challenges due to their reliance on single sensor approaches like Leap Motion or RGB cameras. These systems struggle with limitations such as inadequate tracking of complex hand orientations and imprecise recognition of 3D hand movements. This research paper aims to investigate the potential of a multimodal approach that combines Leap Motion and RGB camera data to explore the feasibility of recognition of ArSL. The system architecture includes two parallel subnetworks: a custom dense neural network for Leap Motion data, incorporating dropout and L2 regularization, and an image subnetwork based on a fine-tuned VGG16 model enhanced with data augmentation techniques. Feature representations from both modalities are concatenated in a fusion model and passed through fully connected layers, with final classification performed via SoftMax activation to analyze spatial and temporal features of hand gestures. The system was evaluated on a custom dataset comprising 18 ArSL words, of which 13 were correctly recognized, yielding an overall accuracy of 78%. These results offer preliminary insights into the viability of multimodal fusion for sign language recognition and highlight areas for further optimization and dataset expansion.

</details>


### [9] [Interpretable and Sparse Linear Attention with Decoupled Membership-Subspace Modeling via MCR2 Objective](https://arxiv.org/abs/2601.17042)
*Tianyuan Liu,Libin Hou,Linyuan Wang,Bin Yan*

Main category: cs.CV

TL;DR: 提出解耦成员矩阵和子空间矩阵的注意力机制DMSA，提升Transformer的可解释性和效率


<details>
  <summary>Details</summary>
Motivation: 现有MCR2驱动的白盒Transformer中，成员矩阵和子空间矩阵紧密耦合，导致在错误的token投影下产生冗余编码，需要解耦以提升效率和可解释性

Method: 解耦MCR2目标中的成员矩阵和子空间U，直接从输入学习成员矩阵，然后从全空间S推导稀疏子空间，通过梯度展开得到可解释的稀疏线性注意力算子DMSA

Result: 在ToST中用DMSA替换注意力模块（称为DMST），在ImageNet-1K上比ToST提升1.08%-1.45%的top-1准确率，同时实现更快的编码降维率，相比传统Transformer具有更高的计算效率和可解释性

Conclusion: 提出的DMSA注意力机制成功解耦了成员矩阵和子空间矩阵，为视觉建模提供了可靠的白盒解决方案，在保持可解释性的同时提升了效率和性能

Abstract: Maximal Coding Rate Reduction (MCR2)-driven white-box transformer, grounded in structured representation learning, unifies interpretability and efficiency, providing a reliable white-box solution for visual modeling. However, in existing designs, tight coupling between "membership matrix" and "subspace matrix U" in MCR2 causes redundant coding under incorrect token projection. To this end, we decouple the functional relationship between the "membership matrix" and "subspaces U" in the MCR2 objective and derive an interpretable sparse linear attention operator from unrolled gradient descent of the optimized objective. Specifically, we propose to directly learn the membership matrix from inputs and subsequently derive sparse subspaces from the fullspace S. Consequently, gradient unrolling of the optimized MCR2 objective yields an interpretable sparse linear attention operator: Decoupled Membership-Subspace Attention (DMSA). Experimental results on visual tasks show that simply replacing the attention module in Token Statistics Transformer (ToST) with DMSA (we refer to as DMST) not only achieves a faster coding reduction rate but also outperforms ToST by 1.08%-1.45% in top-1 accuracy on the ImageNet-1K dataset. Compared with vanilla Transformer architectures, DMST exhibits significantly higher computational efficiency and interpretability.

</details>


### [10] [Atomic Depth Estimation From Noisy Electron Microscopy Data Via Deep Learning](https://arxiv.org/abs/2601.17046)
*Matan Leibovich,Mai Tan,Adria Marcos-Morales,Sreyas Mohan,Peter A. Crozier,Carlos Fernandez-Granda*

Main category: cs.CV

TL;DR: 提出一种从噪声TEM图像中提取3D原子级信息的新方法，将深度估计转化为语义分割问题，使用深度学习生成像素级深度分割图


<details>
  <summary>Details</summary>
Motivation: 传统TEM图像受噪声影响严重，难以准确提取3D原子级结构信息，需要开发能够处理噪声的深度估计方法

Method: 将深度估计转化为语义分割问题，训练深度卷积神经网络，使用合成噪声污染的模拟数据生成像素级深度分割图

Result: 方法应用于CeO2纳米颗粒的模拟和真实TEM数据，深度估计结果准确、校准良好且对噪声具有鲁棒性

Conclusion: 提出的基于深度学习的语义分割方法能够有效从噪声TEM图像中提取准确的3D原子级深度信息

Abstract: We present a novel approach for extracting 3D atomic-level information from transmission electron microscopy (TEM) images affected by significant noise. The approach is based on formulating depth estimation as a semantic segmentation problem. We address the resulting segmentation problem by training a deep convolutional neural network to generate pixel-wise depth segmentation maps using simulated data corrupted by synthetic noise. The proposed method was applied to estimate the depth of atomic columns in CeO2 nanoparticles from simulated images and real-world TEM data. Our experiments show that the resulting depth estimates are accurate, calibrated and robust to noise.

</details>


### [11] [A Contrastive Pre-trained Foundation Model for Deciphering Imaging Noisomics across Modalities](https://arxiv.org/abs/2601.17047)
*Yuanjie Gu,Yiqun Wang,Chaohui Yu,Ang Xuan,Fan Wang,Zhi Lu,Biqin Dong*

Main category: cs.CV

TL;DR: Noisomics框架通过对比预训练基础模型，将噪声从抑制对象转变为可解码的信息资源，仅需100个训练样本即可超越传统需要10万样本的方法，实现零样本泛化。


<details>
  <summary>Details</summary>
Motivation: 当前成像噪声表征方法数据密集且设备依赖性强，现代传感器将物理信号与复杂算法伪影纠缠在一起。现有范式难以在不使用大规模监督数据集的情况下分离这些因素，通常将噪声视为干扰而非信息资源。

Method: 提出Noisomics框架，采用对比预训练基础模型，利用流形假设和合成噪声基因组，通过对比学习分离语义信号与随机扰动。该方法打破了传统深度学习缩放定律。

Result: 仅使用100个训练样本即可超越监督基线使用10万样本的性能，将数据和计算依赖降低三个数量级。在12个多样化域外数据集上验证了强大的零样本泛化能力，估计误差减少63.8%，决定系数提高85.1%。

Conclusion: 通过将噪声解码为多参数足迹，将随机退化重新定义为重要的信息资源，无需先验设备校准即可实现精确成像诊断，在消费摄影和深层组织显微镜等多个尺度上都有应用价值。

Abstract: Characterizing imaging noise is notoriously data-intensive and device-dependent, as modern sensors entangle physical signals with complex algorithmic artifacts. Current paradigms struggle to disentangle these factors without massive supervised datasets, often reducing noise to mere interference rather than an information resource. Here, we introduce "Noisomics", a framework shifting the focus from suppression to systematic noise decoding via the Contrastive Pre-trained (CoP) Foundation Model. By leveraging the manifold hypothesis and synthetic noise genome, CoP employs contrastive learning to disentangle semantic signals from stochastic perturbations. Crucially, CoP breaks traditional deep learning scaling laws, achieving superior performance with only 100 training samples, outperforming supervised baselines trained on 100,000 samples, thereby reducing data and computational dependency by three orders of magnitude. Extensive benchmarking across 12 diverse out-of-domain datasets confirms its robust zero-shot generalization, demonstrating a 63.8% reduction in estimation error and an 85.1% improvement in the coefficient of determination compared to the conventional training strategy. We demonstrate CoP's utility across scales: from deciphering non-linear hardware-noise interplay in consumer photography to optimizing photon-efficient protocols for deep-tissue microscopy. By decoding noise as a multi-parametric footprint, our work redefines stochastic degradation as a vital information resource, empowering precise imaging diagnostics without prior device calibration.

</details>


### [12] [SiMiC: Context-Aware Silicon Microstructure Characterization Using Attention-Based Convolutional Neural Networks for Field-Emission Tip Analysis](https://arxiv.org/abs/2601.17048)
*Jing Jie Tan,Rupert Schreiner,Matthias Hausladen,Ali Asgharzade,Simon Edler,Julian Bartsch,Michael Bachmann,Andreas Schels,Ban-Hoe Kwan,Danny Wee-Kiat Ng,Yan-Chai Hum*

Main category: cs.CV

TL;DR: SiMiC：基于注意力机制CNN的硅微结构表征方法，用于场发射尖端分析，减少人工干预并提高测量一致性


<details>
  <summary>Details</summary>
Motivation: 传统SEM分析需要人工评估特征几何形状，效率低且重复性差，需要自动化、高效的微结构表征方法

Method: 开发硅基场发射尖端专用数据集，构建包含注意力机制的自定义CNN架构，用于多类微结构分类和尺寸预测

Result: 与传统图像处理技术相比，SiMiC在保持可解释性的同时实现高精度，建立了数据驱动的微结构分析框架

Conclusion: 该框架为场发射性能相关的微结构分析奠定基础，可关联发射器几何形状与发射行为，指导优化冷阴极和SEM电子源设计

Abstract: Accurate characterization of silicon microstructures is essential for advancing microscale fabrication, quality control, and device performance. Traditional analysis using Scanning Electron Microscopy (SEM) often requires labor-intensive, manual evaluation of feature geometry, limiting throughput and reproducibility. In this study, we propose SiMiC: Context-Aware Silicon Microstructure Characterization Using Attention-Based Convolutional Neural Networks for Field-Emission Tip Analysis. By leveraging deep learning, our approach efficiently extracts morphological features-such as size, shape, and apex curvature-from SEM images, significantly reducing human intervention while improving measurement consistency. A specialized dataset of silicon-based field-emitter tips was developed, and a customized CNN architecture incorporating attention mechanisms was trained for multi-class microstructure classification and dimensional prediction. Comparative analysis with classical image processing techniques demonstrates that SiMiC achieves high accuracy while maintaining interpretability. The proposed framework establishes a foundation for data-driven microstructure analysis directly linked to field-emission performance, opening avenues for correlating emitter geometry with emission behavior and guiding the design of optimized cold-cathode and SEM electron sources. The related dataset and algorithm repository that could serve as a baseline in this area can be found at https://research.jingjietan.com/?q=SIMIC

</details>


### [13] [Summary of the Unusual Activity Recognition Challenge for Developmental Disability Support](https://arxiv.org/abs/2601.17049)
*Christina Garcia,Nhat Tan Le,Taihei Fujioka,Umang Dobhal,Milyun Ni'ma Shoumi,Thanh Nha Nguyen,Sozo Inoue*

Main category: cs.CV

TL;DR: ISAS 2025举办的"识别未见：姿态数据中的异常行为识别"挑战赛，旨在通过非侵入式姿态数据自动识别发育障碍人士设施中的异常行为，吸引了40个团队参与，采用LOSO评估策略，结果显示在噪声低维数据中建模罕见突发行为的挑战性。


<details>
  <summary>Details</summary>
Motivation: 该挑战赛旨在解决发育障碍人士设施中异常行为自动识别的关键需求，使用非侵入式姿态估计数据，以促进医疗保健和行为监测领域的社会责任AI应用发展。

Method: 挑战赛使用从模拟场景视频中提取的骨骼关键点数据，数据集反映了真实世界的行为不平衡和时间不规则性，采用Leave-One-Subject-Out (LOSO)评估策略确保主体无关的泛化能力，主要使用宏平均F1分数评估模型性能。

Result: 40个团队参与了挑战赛，应用了从经典机器学习到深度学习架构的多种方法。结果显示在噪声、低维数据中建模罕见、突发行为具有挑战性，强调了在行为建模中捕捉时间和上下文细微差别的重要性。

Conclusion: 该挑战赛强调了在低维噪声数据中识别异常行为的困难，为未来医疗保健和行为监测领域的社会责任AI应用提供了重要见解，有助于推动该领域的发展。

Abstract: This paper presents an overview of the Recognize the Unseen: Unusual Behavior Recognition from Pose Data Challenge, hosted at ISAS 2025. The challenge aims to address the critical need for automated recognition of unusual behaviors in facilities for individuals with developmental disabilities using non-invasive pose estimation data. Participating teams were tasked with distinguishing between normal and unusual activities based on skeleton keypoints extracted from video recordings of simulated scenarios. The dataset reflects real-world imbalance and temporal irregularities in behavior, and the evaluation adopted a Leave-One-Subject-Out (LOSO) strategy to ensure subject-agnostic generalization. The challenge attracted broad participation from 40 teams applying diverse approaches ranging from classical machine learning to deep learning architectures. Submissions were assessed primarily using macro-averaged F1 scores to account for class imbalance. The results highlight the difficulty of modeling rare, abrupt actions in noisy, low-dimensional data, and emphasize the importance of capturing both temporal and contextual nuances in behavior modeling. Insights from this challenge may contribute to future developments in socially responsible AI applications for healthcare and behavior monitoring.

</details>


### [14] [Single-Pixel Vision-Language Model for Intrinsic Privacy-Preserving Behavioral Intelligence](https://arxiv.org/abs/2601.17050)
*Hongjun An,Yiliang Song,Jiawei Shao,Zhe Sun,Xuelong Li*

Main category: cs.CV

TL;DR: SP-VLM框架通过单像素传感和视觉语言模型实现隐私保护的行为监控，在隐私敏感环境中平衡安全监测与个人隐私保护


<details>
  <summary>Details</summary>
Motivation: 在洗手间、更衣室等隐私敏感环境中，传统监控因隐私法规和伦理问题受限，但欺凌、骚扰等不良社会互动又需要及时干预，需要一种既能保护隐私又能进行安全监控的技术方案

Method: 提出单像素视觉语言模型（SP-VLM），通过低维单像素模态捕捉人体动态，结合视觉语言模型推断复杂行为模式，实现隐私保护的行为分析

Result: 单像素传感能有效抑制身份可恢复性，使先进人脸识别系统在低于临界采样率时失效；同时SP-VLM能从严重降级的单像素观测中提取有意义的行为语义，实现异常检测、人数统计和活动理解

Conclusion: SP-VLM为隐私敏感空间的安全监控提供了一条人权对齐的路径，在保护个人身份隐私的同时支持及时干预，避免侵入式监控常态化

Abstract: Adverse social interactions, such as bullying, harassment, and other illicit activities, pose significant threats to individual well-being and public safety, leaving profound impacts on physical and mental health. However, these critical events frequently occur in privacy-sensitive environments like restrooms, and changing rooms, where conventional surveillance is prohibited or severely restricted by stringent privacy regulations and ethical concerns. Here, we propose the Single-Pixel Vision-Language Model (SP-VLM), a novel framework that reimagines secure environmental monitoring. It achieves intrinsic privacy-by-design by capturing human dynamics through inherently low-dimensional single-pixel modalities and inferring complex behavioral patterns via seamless vision-language integration. Building on this framework, we demonstrate that single-pixel sensing intrinsically suppresses identity recoverability, rendering state-of-the-art face recognition systems ineffective below a critical sampling rate. We further show that SP-VLM can nonetheless extract meaningful behavioral semantics, enabling robust anomaly detection, people counting, and activity understanding from severely degraded single-pixel observations. Combining these findings, we identify a practical sampling-rate regime in which behavioral intelligence emerges while personal identity remains strongly protected. Together, these results point to a human-rights-aligned pathway for safety monitoring that can support timely intervention without normalizing intrusive surveillance in privacy-sensitive spaces.

</details>


### [15] [Synthetic Data Guided Feature Selection for Robust Activity Recognition in Older Adults](https://arxiv.org/abs/2601.17053)
*Shuhao Que,Dieuwke van Dartel,Ilse Heeringa,Han Hegeman,Miriam Vollenbroek-Hutten,Ying Wang*

Main category: cs.CV

TL;DR: 开发用于髋部骨折康复的稳健人体活动识别系统，通过合成数据增强提升老年患者活动监测准确性


<details>
  <summary>Details</summary>
Motivation: 髋部骨折康复期间的身体活动监测对老年患者功能恢复至关重要，但现有基于可穿戴设备的监测系统主要针对中青年人群开发，在步态缓慢多变的老年患者中表现不可靠

Method: 研究纳入24名80岁以上健康老年人，在模拟自由生活条件下佩戴腰部和前大腿加速度计进行日常活动；采用留一法交叉验证评估模型鲁棒性，利用合成数据提升模型泛化能力，开发特征干预模型

Result: 特征干预模型结合合成数据指导，在行走、站立、坐、躺和姿势转换等活动中取得高F1分数（0.816-0.997），相比无合成数据模型显著提升了临床重要的姿势转换检测能力

Conclusion: 初步结果证明了老年人群中稳健活动识别的可行性，但需要在髋部骨折患者群体中进一步验证以评估临床实用性

Abstract: Physical activity during hip fracture rehabilitation is essential for mitigating long-term functional decline in geriatric patients. However, it is rarely quantified in clinical practice. Existing continuous monitoring systems with commercially available wearable activity trackers are typically developed in middle-aged adults and therefore perform unreliably in older adults with slower and more variable gait patterns. This study aimed to develop a robust human activity recognition (HAR) system to improve continuous physical activity recognition in the context of hip fracture rehabilitation. 24 healthy older adults aged over 80 years were included to perform activities of daily living (walking, standing, sitting, lying down, and postural transfers) under simulated free-living conditions for 75 minutes while wearing two accelerometers positioned on the lower back and anterior upper thigh. Model robustness was evaluated using leave-one-subject-out cross-validation. The synthetic data demonstrated potential to improve generalization across participants. The resulting feature intervention model (FIM), aided by synthetic data guidance, achieved reliable activity recognition with mean F1-scores of 0.896 for walking, 0.927 for standing, 0.997 for sitting, 0.937 for lying down, and 0.816 for postural transfers. Compared with a control condition model without synthetic data, the FIM significantly improved the postural transfer detection, i.e., an activity class of high clinical relevance that is often overlooked in existing HAR literature. In conclusion, these preliminary results demonstrate the feasibility of robust activity recognition in older adults. Further validation in hip fracture patient populations is required to assess the clinical utility of the proposed monitoring system.

</details>


### [16] [Ego4OOD: Rethinking Egocentric Video Domain Generalization via Covariate Shift Scoring](https://arxiv.org/abs/2601.17056)
*Zahra Vaseqi,James Clark*

Main category: cs.CV

TL;DR: 提出了Ego4OOD基准测试，用于评估第一人称视频动作识别的域泛化能力，通过聚类度量协变量偏移，并采用一对多二元训练目标提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有第一人称视频域泛化基准常混淆协变量偏移与概念偏移，难以可靠评估模型跨输入分布的泛化能力。需要构建强调可测量协变量多样性、减少概念偏移的基准。

Method: 1) 从Ego4D构建Ego4OOD基准，包含八个地理域，使用语义连贯的时刻级动作类别；2) 提出基于聚类的协变量偏移度量；3) 采用一对多二元训练目标，将多类动作识别分解为独立二元分类任务。

Result: 轻量级两层全连接网络在Argo1M和Ego4OOD上达到与最先进方法竞争的性能，参数更少且无需额外模态。实证分析显示协变量偏移度量与识别性能存在明确关系。

Conclusion: Ego4OOD基准和量化域表征对于研究第一人称视频的分布外泛化至关重要。一对多二元训练目标特别适合协变量偏移场景，能减少特征分布偏移下视觉相似类间的干扰。

Abstract: Egocentric video action recognition under domain shifts remains challenging due to large intra-class spatio-temporal variability, long-tailed feature distributions, and strong correlations between actions and environments. Existing benchmarks for egocentric domain generalization often conflate covariate shifts with concept shifts, making it difficult to reliably evaluate a model's ability to generalize across input distributions. To address this limitation, we introduce Ego4OOD, a domain generalization benchmark derived from Ego4D that emphasizes measurable covariate diversity while reducing concept shift through semantically coherent, moment-level action categories. Ego4OOD spans eight geographically distinct domains and is accompanied by a clustering-based covariate shift metric that provides a quantitative proxy for domain difficulty. We further leverage a one-vs-all binary training objective that decomposes multi-class action recognition into independent binary classification tasks. This formulation is particularly well-suited for covariate shift by reducing interference between visually similar classes under feature distribution shift. Using this formulation, we show that a lightweight two-layer fully connected network achieves performance competitive with state-of-the-art egocentric domain generalization methods on both Argo1M and Ego4OOD, despite using fewer parameters and no additional modalities. Our empirical analysis demonstrates a clear relationship between measured covariate shift and recognition performance, highlighting the importance of controlled benchmarks and quantitative domain characterization for studying out-of-distribution generalization in egocentric video.

</details>


### [17] [A Computer Vision Pipeline for Iterative Bullet Hole Tracking in Rifle Zeroing](https://arxiv.org/abs/2601.17062)
*Robert M. Belcher,Brendan C. Degryse,Leonard R. Kosta,Christopher J. Lowrance*

Main category: cs.CV

TL;DR: 提出基于计算机视觉的自动弹孔检测与迭代跟踪系统，用于步枪瞄准镜校准，结合YOLOv8检测和IoU分析，通过新颖的数据增强和预处理技术实现高精度检测和迭代分配。


<details>
  <summary>Details</summary>
Motivation: 传统步枪瞄准镜校准需要人工检查弹孔，存在安全协议延迟和人为错误风险。需要自动化系统来实时检测和区分不同射击迭代的弹孔。

Method: 使用YOLOv8进行小目标检测，结合IoU分析区分序列图像中的弹孔。提出新颖的数据增强技术（移除而非添加对象）模拟真实射击序列，并采用ORB-based透视校正预处理管道标准化目标方向。

Result: 系统在弹孔检测上达到97.0%的平均精度，在将弹孔分配到正确射击迭代上达到88.8%的准确率。

Conclusion: 该系统成功实现了自动化的弹孔检测和迭代跟踪，不仅适用于步枪校准，还可扩展到需要时间区分视觉相似物体的其他领域。

Abstract: Adjusting rifle sights, a process commonly called "zeroing," requires shooters to identify and differentiate bullet holes from multiple firing iterations. Traditionally, this process demands physical inspection, introducing delays due to range safety protocols and increasing the risk of human error. We present an end-to-end computer vision system for automated bullet hole detection and iteration-based tracking directly from images taken at the firing line. Our approach combines YOLOv8 for accurate small-object detection with Intersection over Union (IoU) analysis to differentiate bullet holes across sequential images. To address the scarcity of labeled sequential data, we propose a novel data augmentation technique that removes rather than adds objects to simulate realistic firing sequences. Additionally, we introduce a preprocessing pipeline that standardizes target orientation using ORB-based perspective correction, improving model accuracy. Our system achieves 97.0% mean average precision on bullet hole detection and 88.8% accuracy in assigning bullet holes to the correct firing iteration. While designed for rifle zeroing, this framework offers broader applicability in domains requiring the temporal differentiation of visually similar objects.

</details>


### [18] [A Mechanistic View on Video Generation as World Models: State and Dynamics](https://arxiv.org/abs/2601.17067)
*Luozhou Wang,Zhifei Chen,Yihua Du,Dongyu Yan,Wenhang Ge,Guibao Shen,Xinli Xu,Leyi Wu,Man Chen,Tianshuo Xu,Peiran Ren,Xin Tao,Pengfei Wan,Ying-Cong Chen*

Main category: cs.CV

TL;DR: 该论文提出了一个连接视频生成模型与世界模型理论的新分类框架，强调从视觉保真度到功能基准的评估转变，并指出了增强持久性和因果推理的关键前沿。


<details>
  <summary>Details</summary>
Motivation: 当前大规模视频生成模型虽然展现出物理连贯性，但"无状态"的视频架构与经典的状态中心世界模型理论之间存在差距。需要弥合这一差距，推动视频生成模型从生成视觉上合理的视频发展为构建强大的通用世界模拟器。

Method: 提出了以状态构建和动态建模为两大支柱的新分类法。将状态构建分为隐式范式（上下文管理）和显式范式（潜在压缩），动态建模则通过知识整合和架构重构进行分析。同时倡导从视觉保真度评估转向功能基准测试。

Result: 建立了一个系统性的分类框架，能够分析现有视频生成模型与世界模型理论的关系。识别了当前研究的关键挑战和未来发展方向。

Conclusion: 通过解决持久性（数据驱动记忆和压缩保真度）和因果性（潜在因子解耦和推理先验整合）这两个关键前沿，视频生成领域可以从生成视觉上合理的视频发展为构建稳健的通用世界模拟器。

Abstract: Large-scale video generation models have demonstrated emergent physical coherence, positioning them as potential world models. However, a gap remains between contemporary "stateless" video architectures and classic state-centric world model theories. This work bridges this gap by proposing a novel taxonomy centered on two pillars: State Construction and Dynamics Modeling. We categorize state construction into implicit paradigms (context management) and explicit paradigms (latent compression), while dynamics modeling is analyzed through knowledge integration and architectural reformulation. Furthermore, we advocate for a transition in evaluation from visual fidelity to functional benchmarks, testing physical persistence and causal reasoning. We conclude by identifying two critical frontiers: enhancing persistence via data-driven memory and compressed fidelity, and advancing causality through latent factor decoupling and reasoning-prior integration. By addressing these challenges, the field can evolve from generating visually plausible videos to building robust, general-purpose world simulators.

</details>


### [19] [Superpixel-Based Image Segmentation Using Squared 2-Wasserstein Distances](https://arxiv.org/abs/2601.17071)
*Jisui Huang,Andreas Alpers,Ke Chen,Na Lei*

Main category: cs.CV

TL;DR: 提出一种基于最优传输的两级聚类图像分割方法，先通过线性最小二乘分配将像素聚合成超像素，再使用2-Wasserstein距离贪婪合并超像素，在强不均匀性图像中实现高效准确分割。


<details>
  <summary>Details</summary>
Motivation: 传统基于平均颜色距离的超像素合并策略在处理强不均匀性图像时效果有限，需要一种数学统一的框架来提升分割准确性。

Method: 两级聚类方法：第一级将像素通过线性最小二乘分配（离散最优传输特例）聚合成超像素；第二级使用平方2-Wasserstein距离贪婪合并超像素为对象级分割。

Result: 数值实验表明该方法在挑战性图像上提高了分割准确性，同时保持了高计算效率。

Conclusion: 基于最优传输的分布距离框架为图像分割提供了数学统一的解决方案，在强不均匀性条件下优于传统方法。

Abstract: We present an efficient method for image segmentation in the presence of strong inhomogeneities. The approach can be interpreted as a two-level clustering procedure: pixels are first grouped into superpixels via a linear least-squares assignment problem, which can be viewed as a special case of a discrete optimal transport (OT) problem, and these superpixels are subsequently greedily merged into object-level segments using the squared 2-Wasserstein distance between their empirical distributions. In contrast to conventional superpixel merging strategies based on mean-color distances, our framework employs a distributional OT distance, yielding a mathematically unified formulation across both clustering levels. Numerical experiments demonstrate that this perspective leads to improved segmentation accuracy on challenging images while retaining high computational efficiency.

</details>


### [20] [GlassesGB: Controllable 2D GAN-Based Eyewear Personalization for 3D Gaussian Blendshapes Head Avatars](https://arxiv.org/abs/2601.17088)
*Rui-Yang Ju,Jen-Shiun Chiang*

Main category: cs.CV

TL;DR: GlassesGB是一个支持3D头部虚拟形象可定制眼镜生成的框架，将2D生成定制与3D头部虚拟形象渲染相结合，解决了VR应用中个性化眼镜设计的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有虚拟试戴系统大多只能在预定义的眼镜模板上操作，缺乏细粒度的用户驱动定制能力。虽然GlassesGAN支持个性化2D眼镜设计，但其仅限于2D图像生成。需要将2D生成定制与3D头部虚拟形象渲染相结合，实现VR应用中的个性化眼镜设计。

Method: 基于3D高斯混合形状在头部重建中的成功，将3D高斯混合形状技术与2D生成定制技术相结合，提出GlassesGB框架，支持3D头部虚拟形象的可定制眼镜生成。

Result: GlassesGB有效桥接了2D生成定制与3D头部虚拟形象渲染，实现了可定制的眼镜生成，解决了VR应用中个性化眼镜设计的挑战。代码已开源。

Conclusion: GlassesGB框架成功实现了3D头部虚拟形象的可定制眼镜生成，为VR应用中的个性化眼镜设计提供了有效解决方案，弥合了2D生成定制与3D渲染之间的差距。

Abstract: Virtual try-on systems allow users to interactively try different products within VR scenarios. However, most existing VTON methods operate only on predefined eyewear templates and lack support for fine-grained, user-driven customization. While GlassesGAN enables personalized 2D eyewear design, its capability remains limited to 2D image generation. Motivated by the success of 3D Gaussian Blendshapes in head reconstruction, we integrate these two techniques and propose GlassesGB, a framework that supports customizable eyewear generation for 3D head avatars. GlassesGB effectively bridges 2D generative customization with 3D head avatar rendering, addressing the challenge in achieving personalized eyewear design for VR applications. The implementation code is available at https://ruiyangju.github.io/GlassesGB.

</details>


### [21] [GRASP: Guided Region-Aware Sparse Prompting for Adapting MLLMs to Remote Sensing](https://arxiv.org/abs/2601.17089)
*Qigan Sun,Chaoning Zhang,Jianwei Zhang,Xudong Wang,Jiehui Xie,Pengcheng Zheng,Haoyu Wang,Sungyoung Lee,Chi-lok Andy Tai,Yang Yang,Heng Tao Shen*

Main category: cs.CV

TL;DR: 提出GRASP方法，通过引导区域感知稀疏提示解决遥感图像中MLLMs微调的问题，在保持参数效率的同时提升性能


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs微调方法直接应用于遥感图像时存在过拟合背景噪声或忽略目标细节的问题，主要由于遥感图像的大尺度变化、稀疏目标分布和复杂区域语义特征

Method: 提出GRASP参数高效微调策略，引入与冻结视觉标记网格中空间块相关的空间结构化软提示，通过问题引导的稀疏融合机制动态聚合任务特定上下文到紧凑全局提示

Result: 在多个RSVQA基准测试中，GRASP相比现有微调和基于提示的方法实现了有竞争力的性能，同时保持高参数效率

Conclusion: GRASP通过引导区域感知稀疏提示有效解决了遥感图像中MLLMs微调的挑战，在参数效率和高性能之间取得了良好平衡

Abstract: In recent years, Multimodal Large Language Models (MLLMs) have made significant progress in visual question answering tasks. However, directly applying existing fine-tuning methods to remote sensing (RS) images often leads to issues such as overfitting on background noise or neglecting target details. This is primarily due to the large-scale variations, sparse target distributions, and complex regional semantic features inherent in RS images. These challenges limit the effectiveness of MLLMs in RS tasks. To address these challenges, we propose a parameter-efficient fine-tuning (PEFT) strategy called Guided Region-Aware Sparse Prompting (GRASP). GRASP introduces spatially structured soft prompts associated with spatial blocks extracted from a frozen visual token grid. Through a question-guided sparse fusion mechanism, GRASP dynamically aggregates task-specific context into a compact global prompt, enabling the model to focus on relevant regions while filtering out background noise. Extensive experiments on multiple RSVQA benchmarks show that GRASP achieves competitive performance compared to existing fine-tuning and prompt-based methods while maintaining high parameter efficiency.

</details>


### [22] [LoD Sketch Extraction from Architectural Models Using Generative AI: Dataset Construction for Multi-Level Architectural Design Generation](https://arxiv.org/abs/2601.17095)
*Xusheng Du,Athiwat Kongkaeo,Ye Zhang,Haoran Xie*

Main category: cs.CV

TL;DR: 提出一个基于生成式AI的自动LoD草图提取框架，能从高细节建筑模型逐步简化生成几何一致的多层次细节表示，解决训练数据缺乏问题。


<details>
  <summary>Details</summary>
Motivation: 传统LoD建模依赖人工操作，耗时费力且易产生几何不一致。生成式AI为从草图生成多层次建筑模型提供了新可能，但缺乏高质量配对的LoD训练数据限制了应用。

Method: 提出自动LoD草图提取框架，集成计算机视觉技术和生成式AI方法，建立从详细表示到体量抽象的渐进提取流程，自动生成几何一致且层次连贯的多LoD表示。

Result: 方法在LoD级别间保持强几何一致性：LoD3到LoD2的SSIM为0.7319，LoD2到LoD1的SSIM为0.7532；归一化Hausdorff距离分别为图像对角线的25.1%和61.0%，表明抽象过程中的几何偏差得到控制。

Conclusion: 该框架在保持全局结构的同时实现了跨LoD级别的渐进语义简化，为AI驱动的多层次建筑生成和分层建模提供了可靠数据和技术支持。

Abstract: For architectural design, representation across multiple Levels of Details (LoD) is essential for achieving a smooth transition from conceptual massing to detailed modeling. However, traditional LoD modeling processes rely on manual operations that are time-consuming, labor-intensive, and prone to geometric inconsistencies. While the rapid advancement of generative artificial intelligence (AI) has opened new possibilities for generating multi-level architectural models from sketch inputs, its application remains limited by the lack of high-quality paired LoD training data. To address this issue, we propose an automatic LoD sketch extraction framework using generative AI models, which progressively simplifies high-detail architectural models to automatically generate geometrically consistent and hierarchically coherent multi-LoD representations. The proposed framework integrates computer vision techniques with generative AI methods to establish a progressive extraction pipeline that transitions from detailed representations to volumetric abstractions. Experimental results demonstrate that the method maintains strong geometric consistency across LoD levels, achieving SSIM values of 0.7319 and 0.7532 for the transitions from LoD3 to LoD2 and from LoD2 to LoD1, respectively, with corresponding normalized Hausdorff distances of 25.1% and 61.0% of the image diagonal, reflecting controlled geometric deviation during abstraction. These results verify that the proposed framework effectively preserves global structure while achieving progressive semantic simplification across different LoD levels, providing reliable data and technical support for AI-driven multi-level architectural generation and hierarchical modeling.

</details>


### [23] [Performance uncertainty in medical image analysis: a large-scale investigation of confidence intervals](https://arxiv.org/abs/2601.17103)
*Pascaline André,Charles Heitz,Evangelia Christodoulou,Annika Reinke,Carole H. Sudre,Michela Antonelli,Patrick Godau,M. Jorge Cardoso,Antoine Gilson,Sophie Tezenas du Montcel,Gaël Varoquaux,Lena Maier-Hein,Olivier Colliot*

Main category: cs.CV

TL;DR: 医疗影像AI性能评估中置信区间方法的大规模实证分析，揭示了影响CI可靠性的关键因素


<details>
  <summary>Details</summary>
Motivation: 医疗影像AI的性能不确定性量化对可靠验证和临床转化至关重要，但社区对多种CI方法及其在不同场景下的行为缺乏了解

Method: 对24个分割和分类任务进行大规模实证分析，每个任务组使用19个训练模型，涵盖广泛性能指标、多种聚合策略和常用CI方法

Result: 发现五个主要发现：1)可靠CI所需样本量从几十到几千不等；2)CI行为受性能指标选择强烈影响；3)聚合策略显著影响CI可靠性；4)机器学习问题类型调节这些效应；5)不同CI方法在不同用例中可靠性和精度不同

Conclusion: 这些结果为制定医疗影像AI性能不确定性报告的未来指南提供了关键组成部分

Abstract: Performance uncertainty quantification is essential for reliable validation and eventual clinical translation of medical imaging artificial intelligence (AI). Confidence intervals (CIs) play a central role in this process by indicating how precise a reported performance estimate is. Yet, due to the limited amount of work examining CI behavior in medical imaging, the community remains largely unaware of how many diverse CI methods exist and how they behave in specific settings. The purpose of this study is to close this gap. To this end, we conducted a large-scale empirical analysis across a total of 24 segmentation and classification tasks, using 19 trained models per task group, a broad spectrum of commonly used performance metrics, multiple aggregation strategies, and several widely adopted CI methods. Reliability (coverage) and precision (width) of each CI method were estimated across all settings to characterize their dependence on study characteristics. Our analysis revealed five principal findings: 1) the sample size required for reliable CIs varies from a few dozens to several thousands of cases depending on study parameters; 2) CI behavior is strongly affected by the choice of performance metric; 3) aggregation strategy substantially influences the reliability of CIs, e.g. they require more observations for macro than for micro; 4) the machine learning problem (segmentation versus classification) modulates these effects; 5) different CI methods are not equally reliable and precise depending on the use case. These results form key components for the development of future guidelines on reporting performance uncertainty in medical imaging AI.

</details>


### [24] [StealthMark: Harmless and Stealthy Ownership Verification for Medical Segmentation via Uncertainty-Guided Backdoors](https://arxiv.org/abs/2601.17107)
*Qinkai Yu,Chong Zhang,Gaojie Jin,Tianjin Huang,Wei Zhou,Wenhui Li,Xiaobo Jin,Bo Huang,Yitian Zhao,Guang Yang,Gregory Y. H. Lip,Yalin Zheng,Aline Villavicencio,Yanda Meng*

Main category: cs.CV

TL;DR: 提出StealthMark方法，通过微调模型不确定性在不影响分割性能的情况下嵌入可验证水印，用于医学分割模型的黑盒所有权验证。


<details>
  <summary>Details</summary>
Motivation: 医学数据标注成本高且受隐私限制，训练好的分割模型成为重要知识产权。现有保护技术主要关注分类和生成任务，医学分割模型保护研究不足。

Method: 通过微妙调整模型不确定性而不改变最终分割输出，结合LIME等模型无关解释方法提取特征归因，在特定触发条件下显示可验证水印（设计为QR码）。

Result: 在四个医学影像数据集和五个主流分割模型上验证，StealthMark在SAM模型上ASR超过95%，Dice和AUC分数下降小于1%，显著优于基于后门的水印方法。

Conclusion: StealthMark提供了一种有效、隐蔽且无害的医学分割模型所有权验证方法，具有实际部署潜力。

Abstract: Annotating medical data for training AI models is often costly and limited due to the shortage of specialists with relevant clinical expertise. This challenge is further compounded by privacy and ethical concerns associated with sensitive patient information. As a result, well-trained medical segmentation models on private datasets constitute valuable intellectual property requiring robust protection mechanisms. Existing model protection techniques primarily focus on classification and generative tasks, while segmentation models-crucial to medical image analysis-remain largely underexplored. In this paper, we propose a novel, stealthy, and harmless method, StealthMark, for verifying the ownership of medical segmentation models under black-box conditions. Our approach subtly modulates model uncertainty without altering the final segmentation outputs, thereby preserving the model's performance. To enable ownership verification, we incorporate model-agnostic explanation methods, e.g. LIME, to extract feature attributions from the model outputs. Under specific triggering conditions, these explanations reveal a distinct and verifiable watermark. We further design the watermark as a QR code to facilitate robust and recognizable ownership claims. We conducted extensive experiments across four medical imaging datasets and five mainstream segmentation models. The results demonstrate the effectiveness, stealthiness, and harmlessness of our method on the original model's segmentation performance. For example, when applied to the SAM model, StealthMark consistently achieved ASR above 95% across various datasets while maintaining less than a 1% drop in Dice and AUC scores, significantly outperforming backdoor-based watermarking methods and highlighting its strong potential for practical deployment. Our implementation code is made available at: https://github.com/Qinkaiyu/StealthMark.

</details>


### [25] [iFSQ: Improving FSQ for Image Generation with 1 Line of Code](https://arxiv.org/abs/2601.17124)
*Bin Lin,Zongjian Li,Yuwei Niu,Kaixiong Gong,Yunyang Ge,Yunlong Lin,Mingzhe Zheng,JianWei Zhang,Miles Yang,Zhao Zhong,Liefeng Bo,Li Yuan*

Main category: cs.CV

TL;DR: iFSQ通过简单的分布匹配映射解决FSQ激活崩溃问题，统一了离散和连续表示，发现4比特/维是最佳平衡点，AR模型收敛快但扩散模型上限更高


<details>
  <summary>Details</summary>
Motivation: 当前图像生成领域分裂为基于离散token的自回归模型和基于连续潜变量的扩散模型，这种分裂源于VQ-VAEs和VAEs的区别，阻碍了统一建模和公平基准测试。虽然FSQ提供了理论桥梁，但其等间隔量化会导致激活崩溃，需要在重建保真度和信息效率之间权衡。

Method: 提出iFSQ方法，将原始FSQ中的激活函数替换为分布匹配映射，强制实施均匀先验。这种简单策略只需一行代码，但数学上保证最优的bin利用率和重建精度。使用iFSQ作为受控基准进行分析，并将表示对齐（REPA）方法适配到AR模型中，得到LlamaGen-REPA。

Result: 发现两个关键洞察：1）离散和连续表示之间的最佳平衡点约为每维度4比特；2）在相同重建约束下，AR模型表现出快速的初始收敛，而扩散模型能达到更高的性能上限，表明严格的序列排序可能限制生成质量的上界。

Conclusion: iFSQ通过简单的分布匹配映射解决了FSQ的激活崩溃问题，为统一离散和连续表示提供了有效方案。研究揭示了离散和连续表示的最佳平衡点，并比较了AR模型和扩散模型的不同特性，为图像生成模型设计提供了重要指导。

Abstract: The field of image generation is currently bifurcated into autoregressive (AR) models operating on discrete tokens and diffusion models utilizing continuous latents. This divide, rooted in the distinction between VQ-VAEs and VAEs, hinders unified modeling and fair benchmarking. Finite Scalar Quantization (FSQ) offers a theoretical bridge, yet vanilla FSQ suffers from a critical flaw: its equal-interval quantization can cause activation collapse. This mismatch forces a trade-off between reconstruction fidelity and information efficiency. In this work, we resolve this dilemma by simply replacing the activation function in original FSQ with a distribution-matching mapping to enforce a uniform prior. Termed iFSQ, this simple strategy requires just one line of code yet mathematically guarantees both optimal bin utilization and reconstruction precision. Leveraging iFSQ as a controlled benchmark, we uncover two key insights: (1) The optimal equilibrium between discrete and continuous representations lies at approximately 4 bits per dimension. (2) Under identical reconstruction constraints, AR models exhibit rapid initial convergence, whereas diffusion models achieve a superior performance ceiling, suggesting that strict sequential ordering may limit the upper bounds of generation quality. Finally, we extend our analysis by adapting Representation Alignment (REPA) to AR models, yielding LlamaGen-REPA. Codes is available at https://github.com/Tencent-Hunyuan/iFSQ

</details>


### [26] [Scaling medical imaging report generation with multimodal reinforcement learning](https://arxiv.org/abs/2601.17151)
*Qianchu Liu,Sheng Zhang,Guanghui Qin,Yu Gu,Ying Jin,Sam Preston,Yanbo Xu,Sid Kiblawi,Wen-wai Yim,Tim Ossowski,Tristan Naumann,Mu Wei,Hoifung Poon*

Main category: cs.CV

TL;DR: UniRG是一个用于医学影像报告生成的通用框架，通过强化学习直接优化评估指标，在CXR报告生成中取得新的SOTA性能


<details>
  <summary>Details</summary>
Motivation: 前沿模型在自然语言理解方面表现出色，但在医学等多模态理解方面仍有能力差距。医学影像报告生成是一个典型例子，监督微调容易过拟合到表面模式

Method: 提出Universal Report Generation (UniRG)框架，利用强化学习作为统一机制，直接针对终端应用的评估指标进行优化

Result: 在ReXrank基准测试中，UniRG-CXR取得了新的整体SOTA，大幅超越先前的最先进方法

Conclusion: UniRG框架能够显著改进监督微调，并在不同机构和临床实践中实现持久的泛化能力

Abstract: Frontier models have demonstrated remarkable capabilities in understanding and reasoning with natural-language text, but they still exhibit major competency gaps in multimodal understanding and reasoning especially in high-value verticals such as biomedicine. Medical imaging report generation is a prominent example. Supervised fine-tuning can substantially improve performance, but they are prone to overfitting to superficial boilerplate patterns. In this paper, we introduce Universal Report Generation (UniRG) as a general framework for medical imaging report generation. By leveraging reinforcement learning as a unifying mechanism to directly optimize for evaluation metrics designed for end applications, UniRG can significantly improve upon supervised fine-tuning and attain durable generalization across diverse institutions and clinical practices. We trained UniRG-CXR on publicly available chest X-ray (CXR) data and conducted a thorough evaluation in CXR report generation with rigorous evaluation scenarios. On the authoritative ReXrank benchmark, UniRG-CXR sets new overall SOTA, outperforming prior state of the art by a wide margin.

</details>


### [27] [LGDWT-GS: Local and Global Discrete Wavelet-Regularized 3D Gaussian Splatting for Sparse-View Scene Reconstruction](https://arxiv.org/abs/2601.17185)
*Shima Salehi,Atharva Agashe,Andrew J. McFarland,Joshua Peeples*

Main category: cs.CV

TL;DR: 提出一种结合全局与局部频率正则化的少样本3D重建方法，解决3D高斯泼溅在稀疏视角下的几何稳定性与细节保留问题，并发布多光谱温室数据集和开源基准测试包。


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯泼溅（3DGS）模型在稀疏视角条件下存在几何不稳定和细节丢失的问题，需要一种能够同时稳定几何结构并保留精细细节的少样本3D重建方法。同时，缺乏专门的多光谱3D重建数据集和标准化评估协议。

Method: 提出一种新的少样本3D重建方法，集成全局和局部频率正则化来稳定几何结构并保留精细细节。同时创建了一个包含四个光谱波段的多光谱温室数据集，涵盖多种植物物种在受控条件下的数据。开发了开源基准测试包，定义了标准化的少样本重建评估协议。

Result: 在多光谱数据集和标准基准测试上的实验表明，所提方法相比现有基线能够实现更清晰、更稳定且光谱一致的3D重建结果。重建质量在几何稳定性和细节保留方面均有显著提升。

Conclusion: 提出的全局-局部频率正则化方法有效解决了3DGS在稀疏视角下的重建问题，同时发布的多光谱数据集和基准测试包为3D重建研究提供了有价值的资源和标准化评估框架。

Abstract: We propose a new method for few-shot 3D reconstruction that integrates global and local frequency regularization to stabilize geometry and preserve fine details under sparse-view conditions, addressing a key limitation of existing 3D Gaussian Splatting (3DGS) models. We also introduce a new multispectral greenhouse dataset containing four spectral bands captured from diverse plant species under controlled conditions. Alongside the dataset, we release an open-source benchmarking package that defines standardized few-shot reconstruction protocols for evaluating 3DGS-based methods. Experiments on our multispectral dataset, as well as standard benchmarks, demonstrate that the proposed method achieves sharper, more stable, and spectrally consistent reconstructions than existing baselines. The dataset and code for this work are publicly available

</details>


### [28] [Decoding Psychological States Through Movement: Inferring Human Kinesic Functions with Application to Built Environments](https://arxiv.org/abs/2601.17194)
*Cheyu Lin,Katherine A. Flanigan,Sirajum Munir*

Main category: cs.CV

TL;DR: 提出DUET数据集和运动学识别框架，用于隐私保护地测量社会基础设施中的社交互动，填补了建筑环境研究中缺乏标准化社交互动测量方法的空白。


<details>
  <summary>Details</summary>
Motivation: 当前建筑环境研究缺乏一致且隐私保护的社交互动测量方法，导致不同研究对"互动"的操作定义不一致，限制了评估设计干预对社交资本相关行为影响的能力。

Method: 引入DUET数据集（包含12种二元互动，涵盖5种运动学功能）和嵌入式运动学识别框架，使用隐私保护的骨骼运动数据直接推断交流功能，无需手工制作动作到功能的字典。

Result: 基准测试显示现有活动识别模型在DUET上的表现有限，验证了框架的有效性；识别框架揭示了运动学功能的结构化聚类，表示质量与分类性能强相关，并能跨主体和环境泛化。

Conclusion: DUET数据集和识别框架为建筑环境研究提供了隐私保护的社交互动测量工具，有助于评估设计干预对社交资本相关行为的影响，填补了方法论空白。

Abstract: Social infrastructure and other built environments are increasingly expected to support well-being and community resilience by enabling social interaction. Yet in civil and built-environment research, there is no consistent and privacy-preserving way to represent and measure socially meaningful interaction in these spaces, leaving studies to operationalize "interaction" differently across contexts and limiting practitioners' ability to evaluate whether design interventions are changing the forms of interaction that social capital theory predicts should matter. To address this field-level and methodological gap, we introduce the Dyadic User Engagement DataseT (DUET) dataset and an embedded kinesics recognition framework that operationalize Ekman and Friesen's kinesics taxonomy as a function-level interaction vocabulary aligned with social capital-relevant behaviors (e.g., reciprocity and attention coordination). DUET captures 12 dyadic interactions spanning all five kinesic functions-emblems, illustrators, affect displays, adaptors, and regulators-across four sensing modalities and three built-environment contexts, enabling privacy-preserving analysis of communicative intent through movement. Benchmarking six open-source, state-of-the-art human activity recognition models quantifies the difficulty of communicative-function recognition on DUET and highlights the limitations of ubiquitous monadic, action-level recognition when extended to dyadic, socially grounded interaction measurement. Building on DUET, our recognition framework infers communicative function directly from privacy-preserving skeletal motion without handcrafted action-to-function dictionaries; using a transfer-learning architecture, it reveals structured clustering of kinesic functions and a strong association between representation quality and classification performance while generalizing across subjects and contexts.

</details>


### [29] [Structural Complexity of Brain MRI reveals age-associated patterns](https://arxiv.org/abs/2601.17211)
*Anzhe Cheng,Italo Ivo Lima Dias Pinto,Paul Bogdan*

Main category: cs.CV

TL;DR: 将结构复杂度分析扩展到三维MRI信号，通过多尺度粗粒化量化信息损失，改进滑动窗口方法提高稳定性，发现脑结构复杂度随年龄系统性下降


<details>
  <summary>Details</summary>
Motivation: 将结构复杂度分析框架扩展到三维信号特别是脑MRI，解决传统块方法在粗分辨率下因采样有限导致的不稳定问题，实现对脑结构多尺度组织的量化分析

Method: 提出多尺度结构复杂度分析框架：1) 对三维MRI信号进行渐进空间尺度粗粒化；2) 量化连续分辨率间的信息损失；3) 引入滑动窗口粗粒化方案替代传统块方法，提高粗尺度估计的平滑性和鲁棒性

Result: 分析成年中晚期大样本结构MRI数据发现：1) 脑结构复杂度随年龄系统性下降；2) 最显著效应出现在较粗尺度；3) 改进的滑动窗口方法比传统块方法更稳定可靠

Conclusion: 结构复杂度分析是三维成像数据多尺度分析的有效信号处理工具，能可靠预测脑MRI的生物学年龄，滑动窗口改进提高了方法在粗尺度分析的鲁棒性

Abstract: We adapt structural complexity analysis to three-dimensional signals, with an emphasis on brain magnetic resonance imaging (MRI). This framework captures the multiscale organization of volumetric data by coarse-graining the signal at progressively larger spatial scales and quantifying the information lost between successive resolutions. While the traditional block-based approach can become unstable at coarse resolutions due to limited sampling, we introduce a sliding-window coarse-graining scheme that provides smoother estimates and improved robustness at large scales. Using this refined method, we analyze large structural MRI datasets spanning mid- to late adulthood and find that structural complexity decreases systematically with age, with the strongest effects emerging at coarser scales. These findings highlight structural complexity as a reliable signal processing tool for multiscale analysis of 3D imaging data, while also demonstrating its utility in predicting biological age from brain MRI.

</details>


### [30] [Spatiotemporal Semantic V2X Framework for Cooperative Collision Prediction](https://arxiv.org/abs/2601.17216)
*Murat Arda Onsu,Poonam Lohan,Burak Kantarci,Aisha Syed,Matthew Andrews,Sean Kennedy*

Main category: cs.CV

TL;DR: 提出基于语义V2X的实时碰撞预测框架，使用V-JEPA生成时空语义嵌入替代原始视频传输，大幅降低通信开销同时提升预测性能


<details>
  <summary>Details</summary>
Motivation: 智能交通系统需要实时碰撞预测，但传统方法传输原始视频或高维传感器数据不切实际，受限于车联网通信带宽和延迟约束

Method: 1) 路侧单元摄像头使用V-JEPA生成未来帧的时空语义嵌入；2) 构建城市交通数字孪生环境生成多样化交通场景；3) 通过V2X链路传输语义嵌入到车辆；4) 车辆端使用轻量级注意力探针和分类器解码嵌入预测碰撞

Result: 与原始视频传输相比，该框架将传输需求降低了四个数量级，同时碰撞预测的F1分数提高了10%

Conclusion: 语义V2X通信在智能交通系统中具有实现协作实时碰撞预测的潜力，在显著降低通信开销的同时保持预测准确性

Abstract: Intelligent Transportation Systems (ITS) demand real-time collision prediction to ensure road safety and reduce accident severity. Conventional approaches rely on transmitting raw video or high-dimensional sensory data from roadside units (RSUs) to vehicles, which is impractical under vehicular communication bandwidth and latency constraints. In this work, we propose a semantic V2X framework in which RSU-mounted cameras generate spatiotemporal semantic embeddings of future frames using the Video Joint Embedding Predictive Architecture (V-JEPA). To evaluate the system, we construct a digital twin of an urban traffic environment enabling the generation of d verse traffic scenarios with both safe and collision events. These embeddings of the future frame, extracted from V-JEPA, capture task-relevant traffic dynamics and are transmitted via V2X links to vehicles, where a lightweight attentive probe and classifier decode them to predict imminent collisions. By transmitting only semantic embeddings instead of raw frames, the proposed system significantly reduces communication overhead while maintaining predictive accuracy. Experimental results demonstrate that the framework with an appropriate processing method achieves a 10% F1-score improvement for collision prediction while reducing transmission requirements by four orders of magnitude compared to raw video. This validates the potential of semantic V2X communication to enable cooperative, real-time collision prediction in ITS.

</details>


### [31] [Semi-Supervised Domain Adaptation with Latent Diffusion for Pathology Image Classification](https://arxiv.org/abs/2601.17228)
*Tengyue Zhang,Ruiwen Ding,Luoting Zhuang,Yuxiao Wu,Erika F. Rodriguez,William Hsu*

Main category: cs.CV

TL;DR: 提出基于潜在扩散模型的半监督域适应框架，通过生成保留组织形态且具有目标域特征的合成图像，改善计算病理学中的域泛化能力。


<details>
  <summary>Details</summary>
Motivation: 计算病理学中的深度学习模型常因域偏移问题在不同队列和机构间泛化能力差。现有方法要么无法利用目标域的无标签数据，要么依赖可能扭曲组织结构的图像翻译方法。

Method: 提出半监督域适应框架，使用在源域和目标域无标签数据上训练的潜在扩散模型，通过条件化（基础模型特征、队列身份、组织制备方法）生成保留源域组织结构并引入目标域外观特征的合成图像，然后用这些合成图像和源域真实标签图像训练下游分类器。

Result: 在肺腺癌预后预测任务中，该方法显著提升了目标域测试集性能，加权F1分数从0.611提升到0.706，宏观F1分数从0.641提升到0.716，且未降低源域性能。

Conclusion: 基于目标感知的扩散模型合成数据增强为改善计算病理学中的域泛化提供了有前景且有效的方法。

Abstract: Deep learning models in computational pathology often fail to generalize across cohorts and institutions due to domain shift. Existing approaches either fail to leverage unlabeled data from the target domain or rely on image-to-image translation, which can distort tissue structures and compromise model accuracy. In this work, we propose a semi-supervised domain adaptation (SSDA) framework that utilizes a latent diffusion model trained on unlabeled data from both the source and target domains to generate morphology-preserving and target-aware synthetic images. By conditioning the diffusion model on foundation model features, cohort identity, and tissue preparation method, we preserve tissue structure in the source domain while introducing target-domain appearance characteristics. The target-aware synthetic images, combined with real, labeled images from the source cohort, are subsequently used to train a downstream classifier, which is then tested on the target cohort. The effectiveness of the proposed SSDA framework is demonstrated on the task of lung adenocarcinoma prognostication. The proposed augmentation yielded substantially better performance on the held-out test set from the target cohort, without degrading source-cohort performance. The approach improved the weighted F1 score on the target-cohort held-out test set from 0.611 to 0.706 and the macro F1 score from 0.641 to 0.716. Our results demonstrate that target-aware diffusion-based synthetic data augmentation provides a promising and effective approach for improving domain generalization in computational pathology.

</details>


### [32] [C-RADIOv4 (Tech Report)](https://arxiv.org/abs/2601.17237)
*Mike Ranzinger,Greg Heinrich,Collin McCarthy,Jan Kautz,Andrew Tao,Bryan Catanzaro,Pavlo Molchanov*

Main category: cs.CV

TL;DR: C-RADIOv4是C-RADIO模型系列的最新版本，通过多教师蒸馏技术构建统一的学生模型，在相同计算复杂度下显著提升下游任务性能，并新增了SAM3模仿能力、任意分辨率支持和ViTDet选项。


<details>
  <summary>Details</summary>
Motivation: 构建一个统一的视觉骨干网络，能够同时保留并改进多个专业教师模型的独特能力，在保持计算效率的同时提升核心指标，并增加新的功能特性。

Method: 采用多教师蒸馏方法，基于AM-RADIO/RADIOv2.5的设计，使用更新的教师模型集合（SigLIP2、DINOv3、SAM3）进行训练，提供SO400M（412M参数）和H（631M参数）两种变体。

Result: C-RADIOv4在核心指标上获得显著改进，获得了模仿SAM3的新能力，增强了任意分辨率支持，重新引入了ViTDet选项以大幅提高高分辨率下的效率，并采用更宽松的许可协议。

Conclusion: C-RADIOv4成功构建了一个统一的视觉骨干模型，在保持计算效率的同时显著提升了多任务性能，并增加了实用的新功能，为实际应用提供了更强大的工具。

Abstract: By leveraging multi-teacher distillation, agglomerative vision backbones provide a unified student model that retains and improves the distinct capabilities of multiple teachers. In this tech report, we describe the most recent release of the C-RADIO family of models, C-RADIOv4, which builds upon AM-RADIO/RADIOv2.5 in design, offering strong improvements on key downstream tasks at the same computational complexity. We release -SO400M (412M params), and -H (631M) model variants, both trained with an updated set of teachers: SigLIP2, DINOv3, and SAM3. In addition to improvements on core metrics and new capabilities from imitating SAM3, the C-RADIOv4 model family further improves any-resolution support, brings back the ViTDet option for drastically enhanced efficiency at high-resolution, and comes with a permissive license.

</details>


### [33] [Multi-stage Bridge Inspection System: Integrating Foundation Models with Location Anonymization](https://arxiv.org/abs/2601.17254)
*Takato Yasuno*

Main category: cs.CV

TL;DR: 日本桥梁损伤检测系统，结合区域隐私保护，使用SAM3检测钢筋腐蚀，DBSCAN补全遗漏区域，高斯模糊保护施工标志，优化OCR精度，GPU加速实现1.7秒/图像处理


<details>
  <summary>Details</summary>
Motivation: 日本法规要求每五年对基础设施进行视觉检查，现场拍摄的损伤图像常包含混凝土裂缝和钢筋暴露，同时施工标志会泄露区域信息。为确保基础设施安全使用而不引起公众焦虑，需要在准确提取损伤特征的同时保护区域隐私信息。

Method: 使用Segment Anything Model (SAM) 3检测钢筋腐蚀，DBSCAN算法自动补全遗漏区域，高斯模糊处理施工标志区域以保护隐私。采用四种预处理方法提高OCR精度，通过GPU优化实现快速处理。技术栈包括SAM3、PyTorch、OpenCV、pytesseract和scikit-learn。

Result: 系统实现了高效的桥梁损伤检测与区域信息保护，GPU优化后处理速度达到每张图像1.7秒，能够准确提取损伤特征同时保护施工标志中的区域隐私信息。

Conclusion: 提出的开源桥梁损伤检测系统成功平衡了损伤特征提取和区域隐私保护的需求，为基础设施安全检查提供了实用解决方案，既满足法规要求又避免引起公众不必要的焦虑。

Abstract: In Japan, civil infrastructure condition monitoring is mandated through visual inspection every five years. Field-captured damage images frequently contain concrete cracks and rebar exposure, often accompanied by construction signs revealing regional information. To enable safe infrastructure use without causing public anxiety, it is essential to protect regional information while accurately extracting damage features and visualizing key indicators for repair decision-making. This paper presents an open-source bridge damage detection system with regional privacy protection capabilities. We employ Segment Anything Model (SAM) 3 for rebar corrosion detection and utilize DBSCAN for automatic completion of missed regions. Construction sign regions are detected and protected through Gaussian blur. Four preprocessing methods improve OCR accuracy, and GPU optimization enables 1.7-second processing per image. The technology stack includes SAM3, PyTorch, OpenCV, pytesseract, and scikit-learn, achieving efficient bridge inspection with regional information protection.

</details>


### [34] [FineVAU: A Novel Human-Aligned Benchmark for Fine-Grained Video Anomaly Understanding](https://arxiv.org/abs/2601.17258)
*João Pereira,Vasco Lopes,João Neves,David Semedo*

Main category: cs.CV

TL;DR: FineVAU是一个新的视频异常理解基准，通过FVScore评估指标和FineW3数据集，专注于细粒度、领域特定的异常视频理解，解决了现有评估方法无法捕捉LVLM响应丰富性和视觉基础性的问题。


<details>
  <summary>Details</summary>
Motivation: 现有视频异常理解(VAU)评估存在缺陷：n-gram指标无法捕捉LVLM响应的丰富性和视觉基础性，而LLM评估过于关注语言质量而非事实相关性，导致主观判断与人类感知不一致。

Method: 1) 将VAU定义为三方面问题：事件(What)、参与实体(Who)、位置(Where)；2) 提出FVScore评估指标，评估LVLM答案中关键视觉元素的存在；3) 创建FineW3数据集，通过结构化全自动流程增强现有人工标注。

Result: 人类评估显示FVScore与人类异常感知有更好的对齐性。实验揭示LVLM在需要空间和细粒度时间理解的异常事件感知方面存在关键限制，尽管在粗粒度、静态信息和强视觉线索事件上表现良好。

Conclusion: FineVAU基准通过细粒度评估和数据集，推动了视频异常理解领域的发展，揭示了当前LVLM在时空理解方面的局限性，为未来研究提供了重要方向。

Abstract: Video Anomaly Understanding (VAU) is a novel task focused on describing unusual occurrences in videos. Despite growing interest, the evaluation of VAU remains an open challenge. Existing benchmarks rely on n-gram-based metrics (e.g., BLEU, ROUGE-L) or LLM-based evaluation. The first fails to capture the rich, free-form, and visually grounded nature of LVLM responses, while the latter focuses on assessing language quality over factual relevance, often resulting in subjective judgments that are misaligned with human perception. In this work, we address this issue by proposing FineVAU, a new benchmark for VAU that shifts the focus towards rich, fine-grained and domain-specific understanding of anomalous videos. We formulate VAU as a three-fold problem, with the goal of comprehensively understanding key descriptive elements of anomalies in video: events (What), participating entities (Who) and location (Where). Our benchmark introduces a) FVScore, a novel, human-aligned evaluation metric that assesses the presence of critical visual elements in LVLM answers, providing interpretable, fine-grained feedback; and b) FineW3, a novel, comprehensive dataset curated through a structured and fully automatic procedure that augments existing human annotations with high quality, fine-grained visual information. Human evaluation reveals that our proposed metric has a superior alignment with human perception of anomalies in comparison to current approaches. Detailed experiments on FineVAU unveil critical limitations in LVLM's ability to perceive anomalous events that require spatial and fine-grained temporal understanding, despite strong performance on coarse grain, static information, and events with strong visual cues.

</details>


### [35] [Inference-Time Loss-Guided Colour Preservation in Diffusion Sampling](https://arxiv.org/abs/2601.17259)
*Angad Singh Ahuja,Aarush Ram Anandh*

Main category: cs.CV

TL;DR: 提出一种无需额外训练、推理时区域约束的颜色保持方法，通过ROI修复、背景潜在重施加和梯度引导，在CIE Lab和线性RGB空间中控制颜色分布，解决扩散模型颜色控制失败问题。


<details>
  <summary>Details</summary>
Motivation: 文本到图像扩散系统在精确颜色控制方面存在持续失败，特别是在设计导向的工作流程中，输出必须满足用户指定的颜色目标。现有方法在满足平均颜色约束时仍会产生感知显著的局部失败。

Method: 结合ROI修复实现空间选择性，背景潜在重施加防止ROI外颜色漂移，通过CIE Lab和线性RGB中的复合损失进行梯度引导。损失函数不仅控制ROI平均颜色，还通过CVaR风格和软最大值惩罚控制像素误差分布的尾部，采用晚启动门控和时间相关调度稳定去噪步骤中的引导。

Result: 该方法提供了一种实用的、无需训练的机制，用于目标颜色遵守，可以集成到标准Stable Diffusion修复流程中，解决了仅基于平均颜色的基线方法产生的感知显著局部失败问题。

Conclusion: 提出的推理时区域约束颜色保持方法能够有效控制扩散模型的颜色输出，通过分布感知目标解决了颜色控制的关键挑战，为设计工作流程提供了实用的颜色控制解决方案。

Abstract: Precise color control remains a persistent failure mode in text-to-image diffusion systems, particularly in design-oriented workflows where outputs must satisfy explicit, user-specified color targets. We present an inference-time, region-constrained color preservation method that steers a pretrained diffusion model without any additional training. Our approach combines (i) ROI-based inpainting for spatial selectivity, (ii) background-latent re-imposition to prevent color drift outside the ROI, and (iii) latent nudging via gradient guidance using a composite loss defined in CIE Lab and linear RGB. The loss is constructed to control not only the mean ROI color but also the tail of the pixelwise error distribution through CVaR-style and soft-maximum penalties, with a late-start gate and a time-dependent schedule to stabilize guidance across denoising steps. We show that mean-only baselines can satisfy average color constraints while producing perceptually salient local failures, motivating our distribution-aware objective. The resulting method provides a practical, training-free mechanism for targeted color adherence that can be integrated into standard Stable Diffusion inpainting pipelines.

</details>


### [36] [Cross360: 360° Monocular Depth Estimation via Cross Projections Across Scales](https://arxiv.org/abs/2601.17271)
*Kun Huang,Fang-Lue Zhang,Neil Dodgson*

Main category: cs.CV

TL;DR: 提出Cross360，一种基于交叉注意力的架构，通过整合局部切面投影特征和全局等距柱面投影特征，解决360°深度估计中全局连续性和局部一致性的平衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有360°深度估计方法难以平衡全局连续性和局部一致性。局部块特征缺乏全局感知，而全局表示无法解决块边界处的特征提取不一致问题。

Method: 提出Cross360架构：1) Cross Projection Feature Alignment模块使用交叉注意力对齐局部切面投影特征与等距柱面投影的360°视野；2) Progressive Feature Aggregation with Attention模块渐进式精炼多尺度特征。

Result: Cross360在大多数基准数据集上显著优于现有方法，特别是在完整360°图像可用的情况下，证明了其在准确和全局一致的深度估计方面的有效性。

Conclusion: 通过交叉注意力机制整合局部和全局信息，Cross360成功解决了360°深度估计中的全局连续性和局部一致性问题，实现了更准确的深度估计。

Abstract: 360° depth estimation is a challenging research problem due to the difficulty of finding a representation that both preserves global continuity and avoids distortion in spherical images. Existing methods attempt to leverage complementary information from multiple projections, but struggle with balancing global and local consistency. Their local patch features have limited global perception, and the combined global representation does not address discrepancies in feature extraction at the boundaries between patches. To address these issues, we propose Cross360, a novel cross-attention-based architecture integrating local and global information using less-distorted tangent patches along with equirectangular features. Our Cross Projection Feature Alignment module employs cross-attention to align local tangent projection features with the equirectangular projection's 360° field of view, ensuring each tangent projection patch is aware of the global context. Additionally, our Progressive Feature Aggregation with Attention module refines multi-scaled features progressively, enhancing depth estimation accuracy. Cross360 significantly outperforms existing methods across most benchmark datasets, especially those in which the entire 360° image is available, demonstrating its effectiveness in accurate and globally consistent depth estimation. The code and model are available at https://github.com/huangkun101230/Cross360.

</details>


### [37] [Fluxamba: Topology-Aware Anisotropic State Space Models for Geological Lineament Segmentation in Multi-Source Remote Sensing](https://arxiv.org/abs/2601.17288)
*Jin Bai,Huiyao Zhang,Qi Wen,Shengyang Li,Xiaolin Tian,Atta ur Rahman*

Main category: cs.CV

TL;DR: Fluxamba：一种轻量级拓扑感知架构，用于地质线性特征分割，通过解耦特征方向与空间位置，在复杂各向异性拓扑中实现高效的长程依赖建模。


<details>
  <summary>Details</summary>
Motivation: 现有状态空间模型（SSMs）依赖刚性轴对齐扫描轨迹，与曲线目标存在拓扑不匹配，导致上下文碎片化和特征侵蚀。地质线性特征（如行星线理、地表裂缝）需要在复杂各向异性拓扑中捕获长程依赖。

Method: 提出Fluxamba架构，核心是结构通量块（SFB），包含各向异性结构门（ASG）和先验调制流（PMF），解耦特征方向与空间位置，沿目标内在几何动态门控上下文聚合。还包含分层空间调节器（HSR）用于多尺度语义对齐，以及高保真聚焦单元（HFFU）最大化微弱特征信噪比。

Result: 在多个地质基准测试（LROC-Lineament、LineaMapper、GeoCrack）上达到最先进水平。在LROC-Lineament数据集上F1分数89.22%，mIoU 89.87%。实时推理速度超过24 FPS，仅3.4M参数和6.3G FLOPs，计算成本比重量级基线降低两个数量级。

Conclusion: Fluxamba在分割保真度和机载部署可行性之间建立了新的帕累托前沿，通过拓扑感知特征校正框架解决了地质线性特征分割中的拓扑不匹配问题，实现了高效准确的地质特征提取。

Abstract: The precise segmentation of geological linear features, spanning from planetary lineaments to terrestrial fractures, demands capturing long-range dependencies across complex anisotropic topologies. Although State Space Models (SSMs) offer near-linear computational complexity, their dependence on rigid, axis-aligned scanning trajectories induces a fundamental topological mismatch with curvilinear targets, resulting in fragmented context and feature erosion. To bridge this gap, we propose Fluxamba, a lightweight architecture that introduces a topology-aware feature rectification framework. Central to our design is the Structural Flux Block (SFB), which orchestrates an anisotropic information flux by integrating an Anisotropic Structural Gate (ASG) with a Prior-Modulated Flow (PMF). This mechanism decouples feature orientation from spatial location, dynamically gating context aggregation along the target's intrinsic geometry rather than rigid paths. Furthermore, to mitigate serialization-induced noise in low-contrast environments, we incorporate a Hierarchical Spatial Regulator (HSR) for multi-scale semantic alignment and a High-Fidelity Focus Unit (HFFU) to explicitly maximize the signal-to-noise ratio of faint features. Extensive experiments on diverse geological benchmarks (LROC-Lineament, LineaMapper, and GeoCrack) demonstrate that Fluxamba establishes a new state-of-the-art. Notably, on the challenging LROC-Lineament dataset, it achieves an F1-score of 89.22% and mIoU of 89.87%. Achieving a real-time inference speed of over 24 FPS with only 3.4M parameters and 6.3G FLOPs, Fluxamba reduces computational costs by up to two orders of magnitude compared to heavy-weight baselines, thereby establishing a new Pareto frontier between segmentation fidelity and onboard deployment feasibility.

</details>


### [38] [Dynamic Meta-Ensemble Framework for Efficient and Accurate Deep Learning in Plant Leaf Disease Detection on Resource-Constrained Edge Devices](https://arxiv.org/abs/2601.17290)
*Weloday Fikadu Moges,Jianmei Su,Amin Waqas*

Main category: cs.CV

TL;DR: 提出动态元集成框架DMEF，通过自适应权重机制动态组合三个轻量级CNN模型，在资源受限的边缘设备上实现高精度植物病害检测。


<details>
  <summary>Details</summary>
Motivation: 边缘设备（如物联网传感器、智能手机）的计算资源和能源预算有限，限制了深度学习模型在植物病害检测中的部署。需要一种在资源约束下仍能保持高准确性的解决方案。

Method: DMEF框架采用自适应权重机制，动态组合MobileNetV2、NASNetMobile和InceptionV3三个轻量级CNN的预测结果。通过优化准确率提升(DeltaAcc)和计算效率（模型大小）之间的权衡，在训练过程中迭代更新集成权重，优先选择性能高且复杂度低的模型。

Result: 在马铃薯和玉米病害基准数据集上分别达到99.53%和96.61%的分类准确率，比独立模型和静态集成分别提升2.1%和6.3%。推理延迟<75ms，参数<100万，计算效率高。

Conclusion: DMEF在资源受限的边缘设备上实现了高精度植物病害诊断，具有<75ms的推理延迟和紧凑的模型大小，为边缘农业监测和可扩展的作物病害管理提供了可行方案，弥合了高精度AI与实际田间应用之间的差距。

Abstract: Deploying deep learning models for plant disease detection on edge devices such as IoT sensors, smartphones, and embedded systems is severely constrained by limited computational resources and energy budgets. To address this challenge, we introduce a novel Dynamic Meta-Ensemble Framework (DMEF) for high-accuracy plant disease diagnosis under resource constraints. DMEF employs an adaptive weighting mechanism that dynamically combines the predictions of three lightweight convolutional neural networks (MobileNetV2, NASNetMobile, and InceptionV3) by optimizing a trade-off between accuracy improvements (DeltaAcc) and computational efficiency (model size). During training, the ensemble weights are updated iteratively, favoring models exhibiting high performance and low complexity. Extensive experiments on benchmark datasets for potato and maize diseases demonstrate state-of-the-art classification accuracies of 99.53% and 96.61%, respectively, surpassing standalone models and static ensembles by 2.1% and 6.3%. With computationally efficient inference latency (<75ms) and a compact footprint (<1 million parameters), DMEF shows strong potential for edge-based agricultural monitoring, suggesting viability for scalable crop disease management. This bridges the gap between high-accuracy AI and practical field applications.

</details>


### [39] [ClinNet: Evidential Ordinal Regression with Bilateral Asymmetry and Prototype Memory for Knee Osteoarthritis Grading](https://arxiv.org/abs/2601.17315)
*Xiaoyang Li,Runni Zhou*

Main category: cs.CV

TL;DR: ClinNet：基于证据序数回归的膝关节骨关节炎分级可信框架，通过双边不对称编码器、诊断记忆库和证据序数头实现连续KL分级和不确定性估计


<details>
  <summary>Details</summary>
Motivation: 膝关节骨关节炎分级面临挑战：分级间差异细微、标注不确定性、疾病进展的序数特性。传统深度学习方法将其视为确定性多类分类，忽略了退化的连续性和专家标注的不确定性。

Method: 提出ClinNet框架，包含三个关键组件：1) 双边不对称编码器(BAE)显式建模内外侧结构差异；2) 诊断记忆库维护类级原型以稳定特征表示；3) 基于正态逆伽马分布的证据序数头联合估计连续KL分级和认知不确定性。

Result: ClinNet在实验中达到二次加权Kappa 0.892和准确率0.768，统计显著优于现有基线(p<0.001)。模型的不确定性估计能成功标记分布外样本和潜在误诊。

Conclusion: ClinNet通过证据序数回归方法有效解决了KOA分级问题，其不确定性估计为安全临床部署铺平了道路，实现了可信的膝关节骨关节炎分级。

Abstract: Knee osteoarthritis (KOA) grading based on radiographic images is a critical yet challenging task due to subtle inter-grade differences, annotation uncertainty, and the inherently ordinal nature of disease progression. Conventional deep learning approaches typically formulate this problem as deterministic multi-class classification, ignoring both the continuous progression of degeneration and the uncertainty in expert annotations. In this work, we propose ClinNet, a novel trustworthy framework that addresses KOA grading as an evidential ordinal regression problem. The proposed method integrates three key components: (1) a Bilateral Asymmetry Encoder (BAE) that explicitly models medial-lateral structural discrepancies; (2) a Diagnostic Memory Bank that maintains class-wise prototypes to stabilize feature representations; and (3) an Evidential Ordinal Head based on the Normal-Inverse-Gamma (NIG) distribution to jointly estimate continuous KL grades and epistemic uncertainty. Extensive experiments demonstrate that ClinNet achieves a Quadratic Weighted Kappa of 0.892 and Accuracy of 0.768, statistically outperforming state-of-the-art baselines (p < 0.001). Crucially, we demonstrate that the model's uncertainty estimates successfully flag out-of-distribution samples and potential misdiagnoses, paving the way for safe clinical deployment.

</details>


### [40] [SkyReels-V3 Technique Report](https://arxiv.org/abs/2601.17323)
*Debang Li,Zhengcong Fei,Tuanhui Li,Yikun Dou,Zheng Chen,Jiangping Yang,Mingyuan Fan,Jingtao Xu,Jiahua Wang,Baoxuan Gu,Mingshan Chang,Yuqiang Xie,Binjie Mao,Youqiang Zhang,Nuo Pang,Hao Zhang,Yuzhe Jin,Zhiheng Xu,Dixuan Lin,Guibin Chen,Yahui Zhou*

Main category: cs.CV

TL;DR: SkyReels-V3是一个基于扩散Transformer的统一多模态上下文学习框架，支持三种核心生成范式：参考图像到视频合成、视频扩展和音频引导视频生成，在视觉质量、指令跟随等关键指标上达到SOTA水平。


<details>
  <summary>Details</summary>
Motivation: 视频生成是构建世界模型的基础，多模态上下文推理是能力的关键测试。为了应对这一挑战，作者开发了SkyReels-V3，旨在通过统一的框架支持多种视频生成任务，提升生成视频的质量、一致性和可控性。

Method: 基于扩散Transformer构建统一多模态上下文学习框架。采用三种核心方法：1) 参考图像到视频合成：使用跨帧配对、图像编辑和语义重写的数据处理流程，结合图像视频混合训练和多分辨率联合优化；2) 视频扩展：集成时空一致性建模和大规模视频理解，支持无缝单镜头延续和智能多镜头切换；3) 音频引导视频生成：训练首尾帧插入模式并重构关键帧推理范式，优化音视频同步。

Result: SkyReels-V3在视觉质量、指令跟随和特定方面指标上达到最先进或接近最先进的性能，接近领先的闭源系统水平。模型能够生成高保真视频，保持强主体身份保留、时间一致性和叙事一致性。

Conclusion: SkyReels-V3通过统一的扩散Transformer框架成功实现了三种核心视频生成范式，在多模态上下文推理任务中表现出色，为构建世界模型提供了有效的视频生成基础。

Abstract: Video generation serves as a cornerstone for building world models, where multimodal contextual inference stands as the defining test of capability. In this end, we present SkyReels-V3, a conditional video generation model, built upon a unified multimodal in-context learning framework with diffusion Transformers. SkyReels-V3 model supports three core generative paradigms within a single architecture: reference images-to-video synthesis, video-to-video extension and audio-guided video generation. (i) reference images-to-video model is designed to produce high-fidelity videos with strong subject identity preservation, temporal coherence, and narrative consistency. To enhance reference adherence and compositional stability, we design a comprehensive data processing pipeline that leverages cross frame pairing, image editing, and semantic rewriting, effectively mitigating copy paste artifacts. During training, an image video hybrid strategy combined with multi-resolution joint optimization is employed to improve generalization and robustness across diverse scenarios. (ii) video extension model integrates spatio-temporal consistency modeling with large-scale video understanding, enabling both seamless single-shot continuation and intelligent multi-shot switching with professional cinematographic patterns. (iii) Talking avatar model supports minute-level audio-conditioned video generation by training first-and-last frame insertion patterns and reconstructing key-frame inference paradigms. On the basis of ensuring visual quality, synchronization of audio and videos has been optimized.
  Extensive evaluations demonstrate that SkyReels-V3 achieves state-of-the-art or near state-of-the-art performance on key metrics including visual quality, instruction following, and specific aspect metrics, approaching leading closed-source systems. Github: https://github.com/SkyworkAI/SkyReels-V3.

</details>


### [41] [SymbolSight: Minimizing Inter-Symbol Interference for Reading with Prosthetic Vision](https://arxiv.org/abs/2601.17326)
*Jasmine Lesner,Michael Beyeler*

Main category: cs.CV

TL;DR: SymbolSight框架通过优化视觉符号设计来减少视网膜假体阅读中的时序干扰，使用语言统计和模拟视觉选择符号-字母映射，显著降低混淆率。


<details>
  <summary>Details</summary>
Motivation: 视网膜假体的低空间分辨率和时序持久性导致阅读困难，特别是在序列字母呈现中，前一个符号的余像会干扰下一个符号的感知，造成系统性识别错误。

Method: 提出SymbolSight计算框架，使用模拟假体视觉和神经代理观察器估计符号对混淆度，结合语言特定的二元语法统计优化符号-字母映射，最小化相邻字母间的混淆。

Result: 在阿拉伯语、保加利亚语和英语的模拟中，优化的异构符号集将预测混淆降低了中位数22倍，相比原生字母表有显著改善。

Conclusion: 标准排版不适合序列低带宽假体视觉，计算建模能有效缩小视觉编码设计空间，为未来心理物理和临床评估生成高潜力候选方案。

Abstract: Retinal prostheses restore limited visual perception, but low spatial resolution and temporal persistence make reading difficult. In sequential letter presentation, the afterimage of one symbol can interfere with perception of the next, leading to systematic recognition errors. Rather than relying on future hardware improvements, we investigate whether optimizing the visual symbols themselves can mitigate this temporal interference. We present SymbolSight, a computational framework that selects symbol-to-letter mappings to minimize confusion among frequently adjacent letters. Using simulated prosthetic vision (SPV) and a neural proxy observer, we estimate pairwise symbol confusability and optimize assignments using language-specific bigram statistics. Across simulations in Arabic, Bulgarian, and English, the resulting heterogeneous symbol sets reduced predicted confusion by a median factor of 22 relative to native alphabets. These results suggest that standard typography is poorly matched to serial, low-bandwidth prosthetic vision and demonstrate how computational modeling can efficiently narrow the design space of visual encodings to generate high-potential candidates for future psychophysical and clinical evaluation.

</details>


### [42] [Learning with Geometric Priors in U-Net Variants for Polyp Segmentation](https://arxiv.org/abs/2601.17331)
*Fabian Vazquez,Jose A. Nuñez,Diego Adame,Alissen Moreno,Augustin Zhan,Huimin Li,Jinghao Yang,Haoteng Tang,Bin Fu,Pengfei Gu*

Main category: cs.CV

TL;DR: 提出几何先验引导模块(GPM)，通过深度图注入几何先验到U-Net架构中，提升息肉分割在低对比度或复杂场景下的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于CNN、Transformer和Mamba的U-Net变体在息肉分割中难以有效捕捉几何和结构信息，特别是在低对比度或杂乱的结肠镜场景下，这限制了早期结直肠癌检测的准确性。

Method: 提出几何先验引导模块(GPM)：1)在模拟的ColonDepth数据集上微调VGGT模型，生成针对内窥镜领域的息肉图像深度图；2)GPM处理这些深度图，将几何先验编码到编码器的特征图中；3)使用空间和通道注意力机制进一步精炼特征，强调局部空间和全局通道信息；4)GPM是即插即用模块，可无缝集成到各种U-Net变体中。

Result: 在五个公共息肉分割数据集上进行广泛实验，GPM在三个强基线模型上都带来了持续的性能提升，证明了方法的有效性。

Conclusion: 提出的GPM模块通过注入显式几何先验，有效增强了U-Net架构在息肉分割任务中捕捉几何和结构信息的能力，特别是在具有挑战性的结肠镜场景下，为计算机辅助诊断提供了更准确的工具。

Abstract: Accurate and robust polyp segmentation is essential for early colorectal cancer detection and for computer-aided diagnosis. While convolutional neural network-, Transformer-, and Mamba-based U-Net variants have achieved strong performance, they still struggle to capture geometric and structural cues, especially in low-contrast or cluttered colonoscopy scenes. To address this challenge, we propose a novel Geometric Prior-guided Module (GPM) that injects explicit geometric priors into U-Net-based architectures for polyp segmentation. Specifically, we fine-tune the Visual Geometry Grounded Transformer (VGGT) on a simulated ColonDepth dataset to estimate depth maps of polyp images tailored to the endoscopic domain. These depth maps are then processed by GPM to encode geometric priors into the encoder's feature maps, where they are further refined using spatial and channel attention mechanisms that emphasize both local spatial and global channel information. GPM is plug-and-play and can be seamlessly integrated into diverse U-Net variants. Extensive experiments on five public polyp segmentation datasets demonstrate consistent gains over three strong baselines. Code and the generated depth maps are available at: https://github.com/fvazqu/GPM-PolypSeg

</details>


### [43] [AGE-Net: Spectral--Spatial Fusion and Anatomical Graph Reasoning with Evidential Ordinal Regression for Knee Osteoarthritis Grading](https://arxiv.org/abs/2601.17336)
*Xiaoyang Li,Runni Zhou*

Main category: cs.CV

TL;DR: AGE-Net是一个用于膝关节X光片自动KL分级的深度学习框架，通过结合光谱-空间融合、解剖图推理和差分细化，在KL数据集上取得了0.9017的QWK分数，优于现有CNN基线。


<details>
  <summary>Details</summary>
Motivation: 膝关节X光片的自动KL分级面临三个主要挑战：1）细微的结构变化难以检测；2）长距离解剖依赖关系；3）分级边界附近的模糊性。这些挑战使得传统方法难以准确可靠地进行自动分级。

Method: 基于ConvNeXt架构，提出AGE-Net框架，包含三个核心模块：1）光谱-空间融合（SSF）模块；2）解剖图推理（AGR）模块；3）差分细化（DFR）模块。使用Normal-Inverse-Gamma证据回归头和成对序数排序约束来捕捉预测不确定性和保持标签序数性。

Result: 在膝关节KL数据集上，AGE-Net取得了0.9017 ± 0.0045的二次加权kappa（QWK）和0.2349 ± 0.0028的均方误差（MSE），在三个随机种子下表现稳定，显著优于强CNN基线。消融研究显示了各模块的一致增益。

Conclusion: AGE-Net通过整合多模态特征融合、解剖关系推理和不确定性建模，有效解决了膝关节KL分级中的挑战，实现了最先进的性能。该方法还具备良好的不确定性质量、鲁棒性和可解释性评估。

Abstract: Automated Kellgren--Lawrence (KL) grading from knee radiographs is challenging due to subtle structural changes, long-range anatomical dependencies, and ambiguity near grade boundaries. We propose AGE-Net, a ConvNeXt-based framework that integrates Spectral--Spatial Fusion (SSF), Anatomical Graph Reasoning (AGR), and Differential Refinement (DFR). To capture predictive uncertainty and preserve label ordinality, AGE-Net employs a Normal-Inverse-Gamma (NIG) evidential regression head and a pairwise ordinal ranking constraint. On a knee KL dataset, AGE-Net achieves a quadratic weighted kappa (QWK) of 0.9017 +/- 0.0045 and a mean squared error (MSE) of 0.2349 +/- 0.0028 over three random seeds, outperforming strong CNN baselines and showing consistent gains in ablation studies. We further outline evaluations of uncertainty quality, robustness, and explainability, with additional experimental figures to be included in the full manuscript.

</details>


### [44] [TEXTS-Diff: TEXTS-Aware Diffusion Model for Real-World Text Image Super-Resolution](https://arxiv.org/abs/2601.17340)
*Haodong He,Xin Zhan,Yancheng Bai,Rui Lan,Lei Sun,Xiangxiang Chu*

Main category: cs.CV

TL;DR: 提出Real-Texts数据集和TEXTS-Diff模型，解决真实世界文本图像超分辨率中文本区域恢复质量差的问题


<details>
  <summary>Details</summary>
Motivation: 现有文本图像超分辨率方法面临两个主要问题：1）现有数据集中文本图像数据稀缺，导致文本区域恢复效果差；2）基于孤立文本样本的数据集限制了背景重建质量

Method: 1）构建Real-Texts大规模高质量数据集，包含中英文真实场景文本图像；2）提出TEXTS-Aware Diffusion Model (TEXTS-Diff)，利用抽象概念理解视觉场景中的文本元素，结合具体文本区域增强文本细节

Result: 在多个评估指标上达到state-of-the-art性能，展现出优越的泛化能力和复杂场景下的文本恢复准确性，有效减少了文本区域的扭曲和幻觉伪影

Conclusion: 通过构建高质量数据集和提出文本感知扩散模型，显著提升了真实世界文本图像超分辨率的质量，特别是在文本可读性和背景保真度方面取得了突破

Abstract: Real-world text image super-resolution aims to restore overall visual quality and text legibility in images suffering from diverse degradations and text distortions. However, the scarcity of text image data in existing datasets results in poor performance on text regions. In addition, datasets consisting of isolated text samples limit the quality of background reconstruction. To address these limitations, we construct Real-Texts, a large-scale, high-quality dataset collected from real-world images, which covers diverse scenarios and contains natural text instances in both Chinese and English. Additionally, we propose the TEXTS-Aware Diffusion Model (TEXTS-Diff) to achieve high-quality generation in both background and textual regions. This approach leverages abstract concepts to improve the understanding of textual elements within visual scenes and concrete text regions to enhance textual details. It mitigates distortions and hallucination artifacts commonly observed in text regions, while preserving high-quality visual scene fidelity. Extensive experiments demonstrate that our method achieves state-of-the-art performance across multiple evaluation metrics, exhibiting superior generalization ability and text restoration accuracy in complex scenarios. All the code, model, and dataset will be released.

</details>


### [45] [STARS: Shared-specific Translation and Alignment for missing-modality Remote Sensing Semantic Segmentation](https://arxiv.org/abs/2601.17342)
*Tong Wang,Xiaodong Zhang,Guanzhou Chen,Jiaqi Wang,Chenxi Liu,Xiaoliang Tan,Wenchao Guo,Xuyang Li,Xuanrui Wang,Zifan Wang*

Main category: cs.CV

TL;DR: STARS：用于不完整多模态遥感输入的鲁棒语义分割框架，通过非对称对齐和像素级语义采样解决模态缺失问题


<details>
  <summary>Details</summary>
Motivation: 多模态遥感技术通过整合光学图像、SAR和DSM等异构数据增强地表语义理解，但实际应用中模态数据缺失是常见且严重的问题，导致传统多模态融合模型性能下降。现有方法存在特征崩溃和恢复特征过于泛化的局限性。

Method: 提出STARS框架，包含两个关键设计：1）带双向翻译和停止梯度的非对称对齐机制，防止特征崩溃并降低对超参数的敏感性；2）像素级语义采样对齐策略，结合类别平衡像素采样和跨模态语义对齐损失，缓解类别严重不平衡导致的对齐失败。

Result: 论文表明STARS框架能够有效处理不完整多模态输入，提高少数类别的识别性能，并降低对超参数的敏感性。

Conclusion: STARS为解决遥感应用中模态缺失问题提供了一个有效的解决方案，通过创新的对齐机制和采样策略提升了多模态语义分割的鲁棒性和性能。

Abstract: Multimodal remote sensing technology significantly enhances the understanding of surface semantics by integrating heterogeneous data such as optical images, Synthetic Aperture Radar (SAR), and Digital Surface Models (DSM). However, in practical applications, the missing of modality data (e.g., optical or DSM) is a common and severe challenge, which leads to performance decline in traditional multimodal fusion models. Existing methods for addressing missing modalities still face limitations, including feature collapse and overly generalized recovered features. To address these issues, we propose \textbf{STARS} (\textbf{S}hared-specific \textbf{T}ranslation and \textbf{A}lignment for missing-modality \textbf{R}emote \textbf{S}ensing), a robust semantic segmentation framework for incomplete multimodal inputs. STARS is built on two key designs. First, we introduce an asymmetric alignment mechanism with bidirectional translation and stop-gradient, which effectively prevents feature collapse and reduces sensitivity to hyperparameters. Second, we propose a Pixel-level Semantic sampling Alignment (PSA) strategy that combines class-balanced pixel sampling with cross-modality semantic alignment loss, to mitigate alignment failures caused by severe class imbalance and improve minority-class recognition.

</details>


### [46] [Revisiting Lightweight Low-Light Image Enhancement: From a YUV Color Space Perspective](https://arxiv.org/abs/2601.17349)
*Hailong Yan,Shice Liu,Xiangtao Zhang,Lujian Yao,Fengxiang Yang,Jinwei Chen,Bo Li*

Main category: cs.CV

TL;DR: 提出了一种基于YUV颜色空间的轻量级低光图像增强方法，通过频率域分析发现Y通道主要丢失低频内容而UV通道受高频噪声影响，设计了针对性的双流注意力模块，在保持模型轻量的同时实现了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 移动互联网时代需要轻量级低光图像增强技术，现有方法在视觉质量和模型紧凑性之间存在权衡。虽然最近的方法使用解耦策略简化架构设计，但忽略了通道特定的退化模式和跨通道交互，限制了性能。

Method: 通过频率域分析确认YUV颜色空间在低光图像增强中的优势，发现Y通道主要丢失低频内容，UV通道受高频噪声影响。提出基于YUV的新范式：为Y通道设计双流全局-局部注意力模块，为UV通道设计Y引导的局部感知频率注意力模块，以及用于最终特征融合的引导交互模块。

Result: 在多个基准测试中建立了新的最先进水平，以显著更低的参数数量提供了优越的视觉质量。

Conclusion: 通过频率域分析揭示了YUV颜色空间中不同通道的退化特性，并设计了针对性的注意力机制，实现了轻量级低光图像增强中视觉质量和模型紧凑性的更好平衡。

Abstract: In the current era of mobile internet, Lightweight Low-Light Image Enhancement (L3IE) is critical for mobile devices, which faces a persistent trade-off between visual quality and model compactness. While recent methods employ disentangling strategies to simplify lightweight architectural design, such as Retinex theory and YUV color space transformations, their performance is fundamentally limited by overlooking channel-specific degradation patterns and cross-channel interactions. To address this gap, we perform a frequency-domain analysis that confirms the superiority of the YUV color space for L3IE. We identify a key insight: the Y channel primarily loses low-frequency content, while the UV channels are corrupted by high-frequency noise. Leveraging this finding, we propose a novel YUV-based paradigm that strategically restores channels using a Dual-Stream Global-Local Attention module for the Y channel, a Y-guided Local-Aware Frequency Attention module for the UV channels, and a Guided Interaction module for final feature fusion. Extensive experiments validate that our model establishes a new state-of-the-art on multiple benchmarks, delivering superior visual quality with a significantly lower parameter count.

</details>


### [47] [NeRF-MIR: Towards High-Quality Restoration of Masked Images with Neural Radiance Fields](https://arxiv.org/abs/2601.17350)
*Xianliang Huang,Zhizhou Zhong,Shuhang Chen,Yi Xu,Juhong Guan,Shuigeng Zhou*

Main category: cs.CV

TL;DR: NeRF-MIR：一种基于NeRF的掩码图像修复方法，通过PERE策略优化光线发射，PIRE机制进行渐进式修复，以及动态加权损失函数，在掩码图像修复任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的NeRF方法在处理受损图像（如自然场景中常见的掩码图像）时效果有限，而当前缺乏专门针对NeRF的掩码图像修复方法，这限制了NeRF在实际场景中的应用。

Method: 1. PERE策略：基于补丁熵的光线发射策略，优化光线分布以更好地学习图像纹理；2. PIRE机制：渐进式迭代修复机制，通过自训练过程逐步修复掩码区域；3. 动态加权损失函数：自动调整掩码区域的损失权重；4. 构建了三个掩码数据集用于训练和评估。

Result: 在真实数据和构建的数据集上的大量实验表明，NeRF-MIR在掩码图像修复任务中优于现有方法，能够有效恢复受损的3D场景。

Conclusion: NeRF-MIR展示了NeRF在掩码图像修复领域的潜力，通过创新的光线发射策略、渐进修复机制和动态损失函数，为处理实际场景中的受损图像提供了有效的解决方案。

Abstract: Neural Radiance Fields (NeRF) have demonstrated remarkable performance in novel view synthesis. However, there is much improvement room on restoring 3D scenes based on NeRF from corrupted images, which are common in natural scene captures and can significantly impact the effectiveness of NeRF. This paper introduces NeRF-MIR, a novel neural rendering approach specifically proposed for the restoration of masked images, demonstrating the potential of NeRF in this domain. Recognizing that randomly emitting rays to pixels in NeRF may not effectively learn intricate image textures, we propose a \textbf{P}atch-based \textbf{E}ntropy for \textbf{R}ay \textbf{E}mitting (\textbf{PERE}) strategy to distribute emitted rays properly. This enables NeRF-MIR to fuse comprehensive information from images of different views. Additionally, we introduce a \textbf{P}rogressively \textbf{I}terative \textbf{RE}storation (\textbf{PIRE}) mechanism to restore the masked regions in a self-training process. Furthermore, we design a dynamically-weighted loss function that automatically recalibrates the loss weights for masked regions. As existing datasets do not support NeRF-based masked image restoration, we construct three masked datasets to simulate corrupted scenarios. Extensive experiments on real data and constructed datasets demonstrate the superiority of NeRF-MIR over its counterparts in masked image restoration.

</details>


### [48] [HyDeMiC: A Deep Learning-based Mineral Classifier using Hyperspectral Data](https://arxiv.org/abs/2601.17352)
*M. L. Mamud,Piyoosh Jaysaval,Frederick D Day-Lewis,M. K. Mudunuru*

Main category: cs.CV

TL;DR: 提出HyDeMiC卷积神经网络模型，用于高光谱矿物分类，在噪声环境下表现优异


<details>
  <summary>Details</summary>
Motivation: 传统分类方法（判别分析、逻辑回归、SVM）在处理高光谱数据时面临环境噪声、传感器限制和高维计算复杂性的挑战

Method: 使用USGS库中115种矿物光谱数据，通过卷积神经网络（CNN）构建HyDeMiC模型，将参考光谱与HSI传感器响应函数卷积生成训练数据集

Result: 在1%、2%、5%、10%噪声水平的合成数据集上评估，HyDeMiC在清洁和低噪声数据上达到近乎完美分类（MCC=1.00），在中等噪声条件下仍保持强劲性能

Conclusion: HyDeMiC在噪声环境下表现出鲁棒性，突显了其在高光谱成像实际应用中的潜力，特别是在噪声是主要挑战的真实场景中

Abstract: Hyperspectral imaging (HSI) has emerged as a powerful remote sensing tool for mineral exploration, capitalizing on unique spectral signatures of minerals. However, traditional classification methods such as discriminant analysis, logistic regression, and support vector machines often struggle with environmental noise in data, sensor limitations, and the computational complexity of analyzing high-dimensional HSI data. This study presents HyDeMiC (Hyperspectral Deep Learning-based Mineral Classifier), a convolutional neural network (CNN) model designed for robust mineral classification under noisy data. To train HyDeMiC, laboratory-measured hyperspectral data for 115 minerals spanning various mineral groups were used from the United States Geological Survey (USGS) library. The training dataset was generated by convolving reference mineral spectra with an HSI sensor response function. These datasets contained three copper-bearing minerals, Cuprite, Malachite, and Chalcopyrite, used as case studies for performance demonstration. The trained CNN model was evaluated on several synthetic 2D hyperspectral datasets with noise levels of 1%, 2%, 5%, and 10%. Our noisy data analysis aims to replicate realistic field conditions. The HyDeMiC's performance was assessed using the Matthews Correlation Coefficient (MCC), providing a comprehensive measure across different noise regimes. Results demonstrate that HyDeMiC achieved near-perfect classification accuracy (MCC = 1.00) on clean and low-noise datasets and maintained strong performance under moderate noise conditions. These findings emphasize HyDeMiC's robustness in the presence of moderate noise, highlighting its potential for real-world applications in hyperspectral imaging, where noise is often a significant challenge.

</details>


### [49] [PocketGS: On-Device Training of 3D Gaussian Splatting for High Perceptual Modeling](https://arxiv.org/abs/2601.17354)
*Wenzhi Guo,Guangchi Fang,Shu Yang,Bing Wang*

Main category: cs.CV

TL;DR: PocketGS：一种移动端3D高斯泼溅方法，能在设备资源受限条件下实现高质量3D场景建模


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯泼溅方法依赖资源不受限的训练假设，无法在移动设备上运行，因为移动设备有分钟级训练预算和硬件内存限制。需要一种能在这些严格约束下进行设备端3DGS训练的方法。

Method: 提出三个协同设计的算子：G算子构建几何保真点云先验；I算子注入局部表面统计信息来初始化各向异性高斯分布，减少早期条件差距；T算子通过缓存中间结果和索引映射梯度散射来展开alpha合成，实现稳定的移动端反向传播。

Result: PocketGS能够超越强大的主流工作站3DGS基线，提供高质量重建，实现了完全设备端的实用捕捉到渲染工作流程。

Conclusion: PocketGS解决了标准3DGS在移动设备上的基本矛盾，满足了训练效率、内存紧凑性和建模保真度的竞争需求，为移动端3D场景建模提供了可行方案。

Abstract: Efficient and high-fidelity 3D scene modeling is a long-standing pursuit in computer graphics. While recent 3D Gaussian Splatting (3DGS) methods achieve impressive real-time modeling performance, they rely on resource-unconstrained training assumptions that fail on mobile devices, which are limited by minute-scale training budgets and hardware-available peak-memory. We present PocketGS, a mobile scene modeling paradigm that enables on-device 3DGS training under these tightly coupled constraints while preserving high perceptual fidelity. Our method resolves the fundamental contradictions of standard 3DGS through three co-designed operators: G builds geometry-faithful point-cloud priors; I injects local surface statistics to seed anisotropic Gaussians, thereby reducing early conditioning gaps; and T unrolls alpha compositing with cached intermediates and index-mapped gradient scattering for stable mobile backpropagation. Collectively, these operators satisfy the competing requirements of training efficiency, memory compactness, and modeling fidelity. Extensive experiments demonstrate that PocketGS is able to outperform the powerful mainstream workstation 3DGS baseline to deliver high-quality reconstructions, enabling a fully on-device, practical capture-to-rendering workflow.

</details>


### [50] [UCAD: Uncertainty-guided Contour-aware Displacement for semi-supervised medical image segmentation](https://arxiv.org/abs/2601.17366)
*Chengbo Ding,Fenghe Tang,Shaohua Kevin Zhou*

Main category: cs.CV

TL;DR: UCAD提出了一种基于不确定性引导的轮廓感知位移框架，用于半监督医学图像分割，通过超像素生成解剖一致区域，并利用不确定性指导选择具有挑战性的区域进行位移，以提升分割准确性和语义一致性。


<details>
  <summary>Details</summary>
Motivation: 现有半监督分割中的位移策略仅操作矩形区域，忽略了解剖结构，导致边界扭曲和语义不一致。特别是在医学图像分割中，保持解剖结构的完整性至关重要。

Method: 1. 使用超像素生成与解剖边界对齐的解剖一致区域；2. 采用不确定性引导的选择机制，选择具有挑战性的区域进行位移以增强一致性学习；3. 提出动态不确定性加权一致性损失，自适应稳定训练并有效正则化未标记区域。

Result: 在有限标注条件下，UCAD在多个实验中一致优于最先进的半监督分割方法，实现了优越的分割准确性。

Conclusion: UCAD通过结合超像素生成解剖一致区域和不确定性引导的位移策略，有效解决了半监督医学图像分割中的边界扭曲和语义不一致问题，在有限标注下实现了更准确的分割结果。

Abstract: Existing displacement strategies in semi-supervised segmentation only operate on rectangular regions, ignoring anatomical structures and resulting in boundary distortions and semantic inconsistency. To address these issues, we propose UCAD, an Uncertainty-Guided Contour-Aware Displacement framework for semi-supervised medical image segmentation that preserves contour-aware semantics while enhancing consistency learning. Our UCAD leverages superpixels to generate anatomically coherent regions aligned with anatomy boundaries, and an uncertainty-guided selection mechanism to selectively displace challenging regions for better consistency learning. We further propose a dynamic uncertainty-weighted consistency loss, which adaptively stabilizes training and effectively regularizes the model on unlabeled regions. Extensive experiments demonstrate that UCAD consistently outperforms state-of-the-art semi-supervised segmentation methods, achieving superior segmentation accuracy under limited annotation. The code is available at:https://github.com/dcb937/UCAD.

</details>


### [51] [Physical Prompt Injection Attacks on Large Vision-Language Models](https://arxiv.org/abs/2601.17383)
*Chen Ling,Kai Hu,Hangcheng Liu,Xingshuo Han,Tianwei Zhang,Changhai Ou*

Main category: cs.CV

TL;DR: PPIA是首个针对大视觉语言模型的物理提示注入攻击，通过将恶意文本指令嵌入物理对象中，在无需访问模型内部的情况下实现黑盒、查询无关的攻击，攻击成功率高达98%。


<details>
  <summary>Details</summary>
Motivation: 现有提示注入攻击方法需要访问输入通道或了解用户查询，这在现实部署中很少成立。因此需要开发一种无需模型访问、仅通过视觉观察就能实施的物理攻击方法。

Method: 结合离线选择高识别度和语义有效的视觉提示，以及基于时空注意力的环境感知策略放置，确保注入的提示既可感知又能影响模型行为。

Result: 在10个最先进的LVLM上评估，包括视觉问答、规划和导航任务，PPIA攻击成功率高达98%，在不同物理条件（距离、视角、光照）下表现出强鲁棒性。

Conclusion: PPIA展示了LVLM在开放物理环境中部署时面临的新型安全威胁，需要开发针对物理提示注入攻击的防御机制。

Abstract: Large Vision-Language Models (LVLMs) are increasingly deployed in real-world intelligent systems for perception and reasoning in open physical environments. While LVLMs are known to be vulnerable to prompt injection attacks, existing methods either require access to input channels or depend on knowledge of user queries, assumptions that rarely hold in practical deployments. We propose the first Physical Prompt Injection Attack (PPIA), a black-box, query-agnostic attack that embeds malicious typographic instructions into physical objects perceivable by the LVLM. PPIA requires no access to the model, its inputs, or internal pipeline, and operates solely through visual observation. It combines offline selection of highly recognizable and semantically effective visual prompts with strategic environment-aware placement guided by spatiotemporal attention, ensuring that the injected prompts are both perceivable and influential on model behavior. We evaluate PPIA across 10 state-of-the-art LVLMs in both simulated and real-world settings on tasks including visual question answering, planning, and navigation, PPIA achieves attack success rates up to 98%, with strong robustness under varying physical conditions such as distance, viewpoint, and illumination. Our code is publicly available at https://github.com/2023cghacker/Physical-Prompt-Injection-Attack.

</details>


### [52] [ONRW: Optimizing inversion noise for high-quality and robust watermark](https://arxiv.org/abs/2601.17388)
*Xuan Ding,Xiu Yan,Chuanlong Xie,Yao Zhu*

Main category: cs.CV

TL;DR: 提出基于扩散模型的高质量鲁棒水印框架，通过空文本优化将干净图像转换为反转噪声，在潜在空间优化后通过扩散模型迭代去噪生成水印图像，显著提升对抗图像损坏的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习水印方法虽然能在不影响图像质量的情况下隐藏水印，但在传输过程中遇到图像损坏时缺乏鲁棒性，限制了实际应用价值。

Method: 1) 通过空文本优化将干净图像转换为反转噪声；2) 在潜在空间优化反转噪声；3) 通过扩散模型迭代去噪过程生成高质量水印图像；4) 引入自注意力约束和伪掩码策略防止图像原始语义失真。

Result: 在COCO数据集上，该方法在12种不同图像变换中平均比稳定签名方法高出10%，表现出卓越的鲁棒性和图像质量保持能力。

Conclusion: 提出的基于扩散模型的水印框架在保持高质量视觉输出的同时，显著增强了水印对抗各种图像损坏的鲁棒性，为实际应用提供了有效解决方案。

Abstract: Watermarking methods have always been effective means of protecting intellectual property, yet they face significant challenges. Although existing deep learning-based watermarking systems can hide watermarks in images with minimal impact on image quality, they often lack robustness when encountering image corruptions during transmission, which undermines their practical application value. To this end, we propose a high-quality and robust watermark framework based on the diffusion model. Our method first converts the clean image into inversion noise through a null-text optimization process, and after optimizing the inversion noise in the latent space, it produces a high-quality watermarked image through an iterative denoising process of the diffusion model. The iterative denoising process serves as a powerful purification mechanism, ensuring both the visual quality of the watermarked image and enhancing the robustness of the watermark against various corruptions. To prevent the optimizing of inversion noise from distorting the original semantics of the image, we specifically introduced self-attention constraints and pseudo-mask strategies. Extensive experimental results demonstrate the superior performance of our method against various image corruptions. In particular, our method outperforms the stable signature method by an average of 10\% across 12 different image transformations on COCO datasets. Our codes are available at https://github.com/920927/ONRW.

</details>


### [53] [SMV-EAR: Bring Spatiotemporal Multi-View Representation Learning into Efficient Event-Based Action Recognition](https://arxiv.org/abs/2601.17391)
*Rui Fan,Weidong Hao*

Main category: cs.CV

TL;DR: 本文提出了一种用于事件相机动作识别的新框架，通过平移不变的密集转换、双分支动态融合架构和生物启发的时间扭曲增强，显著提升了现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 事件相机动作识别具有隐私保护和效率优势，但现有的时空多视图表示学习方法存在平移变异的空间分箱表示和简单的早期拼接融合架构限制。

Method: 1) 通过平移不变的密集转换创建稀疏事件的时空多视图表示；2) 设计双分支动态融合架构，建模不同视图间运动特征的样本级互补性；3) 引入生物启发的时间扭曲增强，模拟真实世界人类动作的速度变化。

Result: 在HARDVS、DailyDVS-200和THU-EACT-50-CHL三个数据集上，相比现有SMVRL方法分别获得+7.0%、+10.7%和+10.2%的Top-1准确率提升，同时参数减少30.1%，计算量降低35.7%。

Conclusion: 该框架通过改进的表示学习、融合架构和数据增强，为事件相机动作识别建立了一个新颖且强大的范式，在性能和效率方面均有显著提升。

Abstract: Event cameras action recognition (EAR) offers compelling privacy-protecting and efficiency advantages, where temporal motion dynamics is of great importance. Existing spatiotemporal multi-view representation learning (SMVRL) methods for event-based object recognition (EOR) offer promising solutions by projecting H-W-T events along spatial axis H and W, yet are limited by its translation-variant spatial binning representation and naive early concatenation fusion architecture. This paper reexamines the key SMVRL design stages for EAR and propose: (i) a principled spatiotemporal multi-view representation through translation-invariant dense conversion of sparse events, (ii) a dual-branch, dynamic fusion architecture that models sample-wise complementarity between motion features from different views, and (iii) a bio-inspired temporal warping augmentation that mimics speed variability of real-world human actions. On three challenging EAR datasets of HARDVS, DailyDVS-200 and THU-EACT-50-CHL, we show +7.0%, +10.7%, and +10.2% Top-1 accuracy gains over existing SMVRL EOR method with surprising 30.1% reduced parameters and 35.7% lower computations, establishing our framework as a novel and powerful EAR paradigm.

</details>


### [54] [ReLE: A Scalable System and Structured Benchmark for Diagnosing Capability Anisotropy in Chinese LLMs](https://arxiv.org/abs/2601.17399)
*Rui Fang,Jian Li,Wei Chen,Bin Hu,Ying-Cong Chen,Xin Tang,Liang Diao*

Main category: cs.CV

TL;DR: ReLE是一个可扩展的实时评估系统，用于诊断大语言模型在不同领域的能力非均匀性（能力各向异性），通过混合评分机制和动态调度算法，在减少70%计算成本的同时保持高排名相关性。


<details>
  <summary>Details</summary>
Motivation: 当前中文大语言模型评估面临基准测试饱和和计算成本高昂的挑战，静态排行榜往往掩盖了模型在不同领域能力之间的结构性权衡，需要更精细的诊断工具来揭示模型的能力分布特征。

Method: 1) 构建领域×能力的正交评估矩阵，包含207,843个样本；2) 提出符号化混合评分机制，消除推理任务中基于嵌入的误判；3) 设计基于Neyman分配和噪声校正的动态方差感知调度器，优化计算资源分配。

Result: 评估了304个模型（189个商业模型，115个开源模型），动态调度器相比全量评估减少70%计算成本，同时保持ρ=0.96的排名相关性。发现模型排名对权重方案高度敏感，ReLE中的排名稳定性振幅为11.4，远高于传统基准的~5.0。

Conclusion: 现代模型是高度专业化的而非普遍优越的，ReLE可作为高频诊断监控工具，补充而非替代全面的静态基准测试，帮助理解模型能力分布和演化趋势。

Abstract: Large Language Models (LLMs) have achieved rapid progress in Chinese language understanding, yet accurately evaluating their capabilities remains challenged by benchmark saturation and prohibitive computational costs. While static leaderboards provide snapshot rankings, they often mask the structural trade-offs between capabilities. In this work, we present ReLE (Robust Efficient Live Evaluation), a scalable system designed to diagnose Capability Anisotropy, the non-uniformity of model performance across domains. Using ReLE, we evaluate 304 models (189 commercial, 115 open-source) across a Domain $\times$ Capability orthogonal matrix comprising 207,843 samples. We introduce two methodological contributions to address current evaluation pitfalls: (1) A Symbolic-Grounded Hybrid Scoring Mechanism that eliminates embedding-based false positives in reasoning tasks; (2) A Dynamic Variance-Aware Scheduler based on Neyman allocation with noise correction, which reduces compute costs by 70\% compared to full-pass evaluations while maintaining a ranking correlation of $ρ=0.96$. Our analysis reveals that aggregate rankings are highly sensitive to weighting schemes: models exhibit a Rank Stability Amplitude (RSA) of 11.4 in ReLE versus $\sim$5.0 in traditional benchmarks, confirming that modern models are highly specialized rather than generally superior. We position ReLE not as a replacement for comprehensive static benchmarks, but as a high-frequency diagnostic monitor for the evolving model landscape.

</details>


### [55] [HAAF: Hierarchical Adaptation and Alignment of Foundation Models for Few-Shot Pathology Anomaly Detection](https://arxiv.org/abs/2601.17405)
*Chunze Yang,Wenjie Zhao,Yue Tang,Junbo Lu,Jiusong Ge,Qidong Liu,Zeyu Gao,Chen Li*

Main category: cs.CV

TL;DR: HAAF框架通过跨层级缩放对齐机制解决视觉语言模型在精准病理分析中的粒度不匹配问题，显著提升细粒度异常检测性能


<details>
  <summary>Details</summary>
Motivation: 精准病理分析依赖于检测特定感兴趣区域内的细粒度形态异常，这些局部纹理丰富的线索（而非全局上下文）驱动专家诊断。视觉语言模型虽能利用语义先验实现数据效率，但面临粒度不匹配问题：通用表示无法解析细微缺陷。现有方法将模态视为独立流，未能将语义提示基于ROI特定的视觉上下文。

Method: 提出分层适应与对齐框架（HAAF），核心是跨层级缩放对齐（CLSA）机制：首先将视觉特征注入文本提示生成内容自适应描述符，然后这些描述符空间引导视觉编码器聚焦异常。此外，采用双分支推理策略，整合语义分数与几何原型，确保少样本设置下的稳定性。

Result: 在四个基准测试中，HAAF显著优于最先进方法，并在低资源场景下能有效扩展至领域特定骨干网络（如CONCH）。

Conclusion: HAAF通过分层适应与对齐有效解决了视觉语言模型在精准病理分析中的粒度不匹配问题，为细粒度异常检测提供了高效解决方案。

Abstract: Precision pathology relies on detecting fine-grained morphological abnormalities within specific Regions of Interest (ROIs), as these local, texture-rich cues - rather than global slide contexts - drive expert diagnostic reasoning. While Vision-Language (V-L) models promise data efficiency by leveraging semantic priors, adapting them faces a critical Granularity Mismatch, where generic representations fail to resolve such subtle defects. Current adaptation methods often treat modalities as independent streams, failing to ground semantic prompts in ROI-specific visual contexts. To bridge this gap, we propose the Hierarchical Adaptation and Alignment Framework (HAAF). At its core is a novel Cross-Level Scaled Alignment (CLSA) mechanism that enforces a sequential calibration order: visual features first inject context into text prompts to generate content-adaptive descriptors, which then spatially guide the visual encoder to spotlight anomalies. Additionally, a dual-branch inference strategy integrates semantic scores with geometric prototypes to ensure stability in few-shot settings. Experiments on four benchmarks show HAAF significantly outperforms state-of-the-art methods and effectively scales with domain-specific backbones (e.g., CONCH) in low-resource scenarios.

</details>


### [56] [Source-Free Domain Adaptation by Optimizing Batch-Wise Cosine Similarity](https://arxiv.org/abs/2601.17408)
*Harsharaj Pathak,Vineeth N Balasubramanian*

Main category: cs.CV

TL;DR: 提出一种基于邻域签名的源自由域自适应方法，通过优化目标域样本预测的相似性和差异性，使用单一损失函数实现更优的域适应效果。


<details>
  <summary>Details</summary>
Motivation: 现有SFDA方法依赖邻域一致性但容易受到误导性邻域信息的影响，需要更可靠的邻域信息学习机制来减少噪声邻居的负面影响。

Method: 提出邻域签名概念，通过优化目标域样本预测的相似性和差异性，使用单一损失函数学习更信息丰富的聚类并减少噪声邻居影响。

Result: 在具有挑战性的VisDA数据集上超越现有方法，在其他基准数据集上也取得有竞争力的结果。

Conclusion: 通过邻域签名概念和单一损失函数优化，能够有效实现源自由域自适应，减少噪声邻居影响，提升模型在目标域的适应性能。

Abstract: Source-Free Domain Adaptation (SFDA) is an emerging area of research that aims to adapt a model trained on a labeled source domain to an unlabeled target domain without accessing the source data. Most of the successful methods in this area rely on the concept of neighborhood consistency but are prone to errors due to misleading neighborhood information. In this paper, we explore this approach from the point of view of learning more informative clusters and mitigating the effect of noisy neighbors using a concept called neighborhood signature, and demonstrate that adaptation can be achieved using just a single loss term tailored to optimize the similarity and dissimilarity of predictions of samples in the target domain. In particular, our proposed method outperforms existing methods in the challenging VisDA dataset while also yielding competitive results on other benchmark datasets.

</details>


### [57] [Cloud-Enabled IoT System for Real-Time Environmental Monitoring and Remote Device Control Using Firebase](https://arxiv.org/abs/2601.17414)
*Abdul Hasib,A. S. M. Ahsanul Sarkar Akib*

Main category: cs.CV

TL;DR: 本文提出一个基于Firebase云数据库的物联网系统，用于环境监测和设备远程控制，具有低成本、高可靠性和实时同步的特点。


<details>
  <summary>Details</summary>
Motivation: 传统监测系统在实时数据访问、远程控制和云集成方面存在局限，物联网设备激增为远程监控应用创造了新机遇，需要开发更易访问、可扩展的解决方案。

Method: 使用ESP32微控制器连接DHT22温湿度传感器和HC-SR04超声波距离传感器，通过Google Firebase实时数据库实现数据同步和远程LED控制，构建云基接口平台。

Result: 系统实现99.2%的数据传输成功率，实时控制延迟低于1.5秒，支持持久化数据存储用于历史分析，总实现成本仅32.50美元。

Conclusion: 该系统为智能家居到工业监控等物联网应用提供了可扩展框架，Firebase集成无需复杂服务器基础设施，使资源有限的开发者和研究人员也能实现高级物联网应用。

Abstract: The proliferation of Internet of Things (IoT) devices has created unprecedented opportunities for remote monitoring and control applications across various domains. Traditional monitoring systems often suffer from limitations in real-time data accessibility, remote controllability, and cloud integration. This paper presents a cloud-enabled IoT system that leverages Google's Firebase Realtime Database for synchronized environmental monitoring and device control. The system utilizes an ESP32 microcontroller to interface with a DHT22 temperature/humidity sensor and an HC-SR04 ultrasonic distance sensor, while enabling remote control of two LED indicators through a cloud-based interface. Real-time sensor data is transmitted to Firebase, providing a synchronized platform accessible from multiple devices simultaneously. Experimental results demonstrate reliable data transmission with 99.2\% success rate, real-time control latency under 1.5 seconds, and persistent data storage for historical analysis. The system architecture offers a scalable framework for various IoT applications, from smart home automation to industrial monitoring, with a total implementation cost of \$32.50. The integration of Firebase provides robust cloud capabilities without requiring complex server infrastructure, making advanced IoT applications accessible to developers and researchers with limited resources.

</details>


### [58] [CoT-Seg: Rethinking Segmentation with Chain-of-Thought Reasoning and Self-Correction](https://arxiv.org/abs/2601.17420)
*Shiu-hong Kao,Chak Ho Huang,Huaiqian Liu,Yu-Wing Tai,Chi-Keung Tang*

Main category: cs.CV

TL;DR: CoT-Seg：无需训练的推理分割框架，结合思维链推理与自校正，利用预训练MLLMs处理复杂查询和域外图像


<details>
  <summary>Details</summary>
Motivation: 现有推理分割方法在处理复杂查询和域外图像时表现不足，受人类解决难题时逐步思考、查找信息、自我评估和修正的启发，需要开发更可靠的推理分割系统

Method: CoT-Seg框架：1) 利用预训练MLLMs（GPT-4o）将查询分解为元指令，提取细粒度语义；2) 自校正阶段：模型评估分割结果与原始查询的匹配度，识别不匹配并迭代优化掩码；3) 可结合检索增强推理，在输入信息不足时访问外部知识

Result: CoT-Seg显著提高了推理分割的可靠性和鲁棒性，特别是在模糊或易出错的情况下。为展示其处理挑战性案例的能力，提出了新数据集ReasonSeg-Hard

Conclusion: 思维链推理与自校正的结合为视觉语言驱动的分割提供了强大范式，无需微调即可处理复杂查询和域外图像

Abstract: Existing works of reasoning segmentation often fall short in complex cases, particularly when addressing complicated queries and out-of-domain images. Inspired by the chain-of-thought reasoning, where harder problems require longer thinking steps/time, this paper aims to explore a system that can think step-by-step, look up information if needed, generate results, self-evaluate its own results, and refine the results, in the same way humans approach harder questions. We introduce CoT-Seg, a training-free framework that rethinks reasoning segmentation by combining chain-of-thought reasoning with self-correction. Instead of fine-tuning, CoT-Seg leverages the inherent reasoning ability of pre-trained MLLMs (GPT-4o) to decompose queries into meta-instructions, extract fine-grained semantics from images, and identify target objects even under implicit or complex prompts. Moreover, CoT-Seg incorporates a self-correction stage: the model evaluates its own segmentation against the original query and reasoning trace, identifies mismatches, and iteratively refines the mask. This tight integration of reasoning and correction significantly improves reliability and robustness, especially in ambiguous or error-prone cases. Furthermore, our CoT-Seg framework allows easy incorporation of retrieval-augmented reasoning, enabling the system to access external knowledge when the input lacks sufficient information. To showcase CoT-Seg's ability to handle very challenging cases ,we introduce a new dataset ReasonSeg-Hard. Our results highlight that combining chain-of-thought reasoning, self-correction, offers a powerful paradigm for vision-language integration driven segmentation.

</details>


### [59] [Coronary Artery Segmentation and Vessel-Type Classification in X-Ray Angiography](https://arxiv.org/abs/2601.17429)
*Mehdi Yousefzadeh,Siavash Shirzadeh Barough,Ashkan Fakharifar,Yashar Tayyarazad,Narges Eghbali,Mohaddeseh Mozaffari,Hoda Taeb,Negar Sadat Rafiee Tabatabaee,Parsa Esfahanian,Ghazaleh Sadeghi Gohar,Amineh Safavirad,Saeideh Mazloomzadeh,Ehsan khalilipur,Armin Elahifar,Majid Maleki*

Main category: cs.CV

TL;DR: 该研究提出了一种用于X射线冠状动脉造影（XCA）的血管分割和血管类型标注方法，通过图像增强、经典滤波器的自适应参数调整以及深度学习模型，显著提高了分割精度和域外泛化能力。


<details>
  <summary>Details</summary>
Motivation: XCA是评估冠状动脉疾病的临床金标准，但由于低对比度、运动伪影、重叠和导管干扰等问题，常规数据中的血管分割困难，导致定量分析受限。可靠的血管分割和血管类型标注对于冠状动脉分析和下游测量至关重要。

Method: 从670个序列中选择最佳帧并进行超分辨率和增强处理。评估经典血管滤波器（Meijering、Frangi、Sato）的三种参数设置：每图像最优调参、全局均值设置、以及通过支持向量回归（SVR）的每图像参数预测。深度学习基线包括U-Net、FPN和Swin Transformer，使用冠状动脉单独标注和冠状动脉+导管合并标注进行训练。第二阶段进行血管类型标注（LAD、LCX、RCA）。外部评估使用公开的DCA1数据集。

Result: SVR每图像调参相比全局均值显著提升了所有经典滤波器的Dice分数（如Frangi：0.759 vs. 0.741）。在深度模型中，FPN在冠状动脉单独标注下达到0.914±0.007 Dice，合并标注进一步提升至0.931±0.006。在严格的域外测试DCA1上，Dice降至0.798（单独标注）和0.814（合并标注），但轻量域内微调可恢复至0.881±0.014和0.882±0.015。血管类型标注准确率：RCA 98.5%（Dice 0.844）、LAD 95.4%（0.786）、LCX 96.2%（0.794）。

Conclusion: 学习的每图像参数调整增强了经典分割流程，而高分辨率FPN模型和合并标注监督提高了稳定性和域外迁移能力，仅需少量适应即可获得良好性能。该方法为XCA的定量分析提供了可靠的分割和血管类型标注解决方案。

Abstract: X-ray coronary angiography (XCA) is the clinical reference standard for assessing coronary artery disease, yet quantitative analysis is limited by the difficulty of robust vessel segmentation in routine data. Low contrast, motion, foreshortening, overlap, and catheter confounding degrade segmentation and contribute to domain shift across centers. Reliable segmentation, together with vessel-type labeling, enables vessel-specific coronary analytics and downstream measurements that depend on anatomical localization. From 670 cine sequences (407 subjects), we select a best frame near peak opacification using a low-intensity histogram criterion and apply joint super-resolution and enhancement. We benchmark classical Meijering, Frangi, and Sato vesselness filters under per-image oracle tuning, a single global mean setting, and per-image parameter prediction via Support Vector Regression (SVR). Neural baselines include U-Net, FPN, and a Swin Transformer, trained with coronary-only and merged coronary+catheter supervision. A second stage assigns vessel identity (LAD, LCX, RCA). External evaluation uses the public DCA1 cohort. SVR per-image tuning improves Dice over global means for all classical filters (e.g., Frangi: 0.759 vs. 0.741). Among deep models, FPN attains 0.914+/-0.007 Dice (coronary-only), and merged coronary+catheter labels further improve to 0.931+/-0.006. On DCA1 as a strict external test, Dice drops to 0.798 (coronary-only) and 0.814 (merged), while light in-domain fine-tuning recovers to 0.881+/-0.014 and 0.882+/-0.015. Vessel-type labeling achieves 98.5% accuracy (Dice 0.844) for RCA, 95.4% (0.786) for LAD, and 96.2% (0.794) for LCX. Learned per-image tuning strengthens classical pipelines, while high-resolution FPN models and merged-label supervision improve stability and external transfer with modest adaptation.

</details>


### [60] [ReflexSplit: Single Image Reflection Separation via Layer Fusion-Separation](https://arxiv.org/abs/2601.17468)
*Chia-Ming Lee,Yu-Fan Lin,Jing-Hui Jung,Yu-Jou Hsiao,Chih-Chung Hsu,Yu-Lun Liu*

Main category: cs.CV

TL;DR: ReflexSplit提出了一种双流框架用于单图像反射分离，通过跨尺度门控融合、层融合-分离块和课程训练来解决非线性混合下的传输-反射混淆问题。


<details>
  <summary>Details</summary>
Motivation: 现有的单图像反射分离方法在非线性混合情况下存在传输-反射混淆问题，特别是在深层解码器中，这是由于隐式融合机制和多尺度协调不足导致的。

Method: 提出ReflexSplit双流框架，包含三个关键创新：(1)跨尺度门控融合(CrGF)自适应聚合语义先验、纹理细节和解码器上下文；(2)层融合-分离块(LFSB)交替进行融合和分离操作；(3)课程训练通过深度相关初始化和逐周期预热逐步加强差分分离。

Result: 在合成和真实世界基准测试中展示了最先进的性能，具有优越的感知质量和鲁棒的泛化能力。

Conclusion: ReflexSplit通过创新的双流架构和训练策略，有效解决了单图像反射分离中的非线性混合问题，实现了高质量的传输和反射层分离。

Abstract: Single Image Reflection Separation (SIRS) disentangles mixed images into transmission and reflection layers. Existing methods suffer from transmission-reflection confusion under nonlinear mixing, particularly in deep decoder layers, due to implicit fusion mechanisms and inadequate multi-scale coordination. We propose ReflexSplit, a dual-stream framework with three key innovations. (1) Cross-scale Gated Fusion (CrGF) adaptively aggregates semantic priors, texture details, and decoder context across hierarchical depths, stabilizing gradient flow and maintaining feature consistency. (2) Layer Fusion-Separation Blocks (LFSB) alternate between fusion for shared structure extraction and differential separation for layer-specific disentanglement. Inspired by Differential Transformer, we extend attention cancellation to dual-stream separation via cross-stream subtraction. (3) Curriculum training progressively strengthens differential separation through depth-dependent initialization and epoch-wise warmup. Extensive experiments on synthetic and real-world benchmarks demonstrate state-of-the-art performance with superior perceptual quality and robust generalization. Our code is available at https://github.com/wuw2135/ReflexSplit.

</details>


### [61] [PhaSR: Generalized Image Shadow Removal with Physically Aligned Priors](https://arxiv.org/abs/2601.17470)
*Chia-Ming Lee,Yu-Fan Lin,Yu-Jou Hsiao,Jing-Hui Jung,Yu-Lun Liu,Chih-Chung Hsu*

Main category: cs.CV

TL;DR: PhaSR通过双级先验对齐实现从单光源阴影到多光源环境照明的鲁棒阴影去除，包含物理对齐归一化和几何语义矫正注意力机制


<details>
  <summary>Details</summary>
Motivation: 在多样化光照条件下，将光照与内在反射率分离是阴影去除的关键挑战，特别是当物理先验未正确对齐时。传统方法在多光源照明下表现不佳

Method: 提出PhaSR框架：1) 物理对齐归一化(PAN)：通过灰度世界归一化、对数域Retinex分解和动态范围重组进行闭式光照校正；2) 几何语义矫正注意力(GSRA)：扩展差分注意力实现跨模态对齐，协调深度几何与DINO-v2语义嵌入

Result: 实验显示在阴影去除任务中具有竞争力，复杂度更低，并能泛化到传统方法在多光源照明下失败的环境光照场景

Conclusion: PhaSR通过双级先验对齐有效解决了多样化光照条件下的阴影去除问题，实现了从单光源到多光源环境的鲁棒性能

Abstract: Shadow removal under diverse lighting conditions requires disentangling illumination from intrinsic reflectance, a challenge compounded when physical priors are not properly aligned. We propose PhaSR (Physically Aligned Shadow Removal), addressing this through dual-level prior alignment to enable robust performance from single-light shadows to multi-source ambient lighting. First, Physically Aligned Normalization (PAN) performs closed-form illumination correction via Gray-world normalization, log-domain Retinex decomposition, and dynamic range recombination, suppressing chromatic bias. Second, Geometric-Semantic Rectification Attention (GSRA) extends differential attention to cross-modal alignment, harmonizing depth-derived geometry with DINO-v2 semantic embeddings to resolve modal conflicts under varying illumination. Experiments show competitive performance in shadow removal with lower complexity and generalization to ambient lighting where traditional methods fail under multi-source illumination. Our source code is available at https://github.com/ming053l/PhaSR.

</details>


### [62] [BMDS-Net: A Bayesian Multi-Modal Deep Supervision Network for Robust Brain Tumor Segmentation](https://arxiv.org/abs/2601.17504)
*Yan Zhou,Zhen Huang,Yingqiu Li,Yue Ouyang,Suncheng Xiang,Zehua Wang*

Main category: cs.CV

TL;DR: BMDS-Net：一种针对临床脑肿瘤分割的鲁棒可信框架，通过零初始化多模态融合和残差门控解码器监督提升稳定性，并采用贝叶斯微调提供不确定性量化，在缺失模态场景下表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前基于Transformer的脑肿瘤分割模型（如Swin UNETR）虽然在基准测试中表现优异，但在临床实践中存在两个关键问题：对缺失模态敏感（临床常见情况）和缺乏置信度校准。单纯追求Dice分数无法满足真实医疗部署的安全要求。

Method: 提出BMDS-Net统一框架：1）构建鲁棒确定性骨干网络，集成零初始化多模态上下文融合模块和残差门控深度解码器监督机制，实现稳定特征学习和精确边界划分；2）引入内存高效的贝叶斯微调策略，将网络转换为概率预测器，提供体素级不确定性图谱；3）在BraTS 2021数据集上进行全面实验验证。

Result: 在BraTS 2021数据集上，BMDS-Net不仅保持了竞争力的准确性，更重要的是在缺失模态场景下表现出卓越的稳定性（基线模型在此场景下失效），显著降低了Hausdorff距离，并提供不确定性图谱辅助临床决策。

Conclusion: BMDS-Net通过将临床鲁棒性和可信度置于简单指标最大化之上，为真实医疗环境中的脑肿瘤分割提供了更安全可靠的解决方案，特别适用于临床常见的缺失模态情况。

Abstract: Accurate brain tumor segmentation from multi-modal magnetic resonance imaging (MRI) is a prerequisite for precise radiotherapy planning and surgical navigation. While recent Transformer-based models such as Swin UNETR have achieved impressive benchmark performance, their clinical utility is often compromised by two critical issues: sensitivity to missing modalities (common in clinical practice) and a lack of confidence calibration. Merely chasing higher Dice scores on idealized data fails to meet the safety requirements of real-world medical deployment. In this work, we propose BMDS-Net, a unified framework that prioritizes clinical robustness and trustworthiness over simple metric maximization. Our contribution is three-fold. First, we construct a robust deterministic backbone by integrating a Zero-Init Multimodal Contextual Fusion (MMCF) module and a Residual-Gated Deep Decoder Supervision (DDS) mechanism, enabling stable feature learning and precise boundary delineation with significantly reduced Hausdorff Distance, even under modality corruption. Second, and most importantly, we introduce a memory-efficient Bayesian fine-tuning strategy that transforms the network into a probabilistic predictor, providing voxel-wise uncertainty maps to highlight potential errors for clinicians. Third, comprehensive experiments on the BraTS 2021 dataset demonstrate that BMDS-Net not only maintains competitive accuracy but, more importantly, exhibits superior stability in missing-modality scenarios where baseline models fail. The source code is publicly available at https://github.com/RyanZhou168/BMDS-Net.

</details>


### [63] [FMIR, a foundation model-based Image Registration Framework for Robust Image Registration](https://arxiv.org/abs/2601.17529)
*Fengting Zhang,Yue He,Qinghao Liu,Yaonan Wang,Xiang Chen,Hang Zhang*

Main category: cs.CV

TL;DR: FMIR是一个基于基础模型的医学图像配准框架，通过基础模型特征编码器和通用配准头，结合通道正则化策略，在单个数据集上训练即可实现SOTA域内性能，同时在域外图像上保持鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 深度学习虽然显著提升了医学图像配准速度，但其临床应用的瓶颈在于难以泛化到训练域之外，而医学数据集通常规模较小，这限制了模型的实用性。

Method: FMIR结合了基于基础模型的特征编码器（用于提取解剖结构）和通用配准头，采用通道正则化策略，仅需在单个数据集上进行训练。

Result: FMIR在域内配准性能达到SOTA水平，同时在域外图像上保持鲁棒性，展示了在有限资源下构建可泛化医学成像基础模型的可行路径。

Conclusion: 该研究为在资源有限的情况下构建可泛化的医学成像基础模型提供了一条可行路径，代码已开源。

Abstract: Deep learning has revolutionized medical image registration by achieving unprecedented speeds, yet its clinical application is hindered by a limited ability to generalize beyond the training domain, a critical weakness given the typically small scale of medical datasets. In this paper, we introduce FMIR, a foundation model-based registration framework that overcomes this limitation.Combining a foundation model-based feature encoder for extracting anatomical structures with a general registration head, and trained with a channel regularization strategy on just a single dataset, FMIR achieves state-of-the-art(SOTA) in-domain performance while maintaining robust registration on out-of-domain images.Our approach demonstrates a viable path toward building generalizable medical imaging foundation models with limited resources. The code is available at https://github.com/Monday0328/FMIR.git.

</details>


### [64] [Will It Zero-Shot?: Will It Zero-Shot?: Predicting Zero-Shot Classification Performance For Arbitrary Queries](https://arxiv.org/abs/2601.17535)
*Kevin Robbins,Xiaotong Liu,Yu Wu,Le Sun,Grady McPeak,Abby Stylianou,Robert Pless*

Main category: cs.CV

TL;DR: 本文提出使用生成图像增强文本评估方法，以更准确地预测视觉语言模型在特定任务上的零样本性能，无需标注数据。


<details>
  <summary>Details</summary>
Motivation: 当前用户难以评估预训练的视觉语言模型（如CLIP）是否适用于他们的特定任务，因为模型在一个领域表现良好可能在另一个领域失败，而非专业用户缺乏简单的方法来评估模型性能。

Method: 在基于文本比较评估方法的基础上，探索生成与任务相关的合成图像来评估和优化零样本准确率预测。通过生成图像来增强基线文本评分，并为用户提供用于评估的图像类型反馈。

Result: 实验表明，基于图像的方法相比纯文本评分显著提高了预测质量，帮助用户在没有标注样本的情况下预测VLM是否适用于他们的应用。

Conclusion: 生成图像增强的评估方法能够有效帮助用户预测视觉语言模型的适用性，提供更准确的零样本性能预测和可视化反馈。

Abstract: Vision-Language Models like CLIP create aligned embedding spaces for text and images, making it possible for anyone to build a visual classifier by simply naming the classes they want to distinguish. However, a model that works well in one domain may fail in another, and non-expert users have no straightforward way to assess whether their chosen VLM will work on their problem. We build on prior work using text-only comparisons to evaluate how well a model works for a given natural language task, and explore approaches that also generate synthetic images relevant to that task to evaluate and refine the prediction of zero-shot accuracy. We show that generated imagery to the baseline text-only scores substantially improves the quality of these predictions. Additionally, it gives a user feedback on the kinds of images that were used to make the assessment. Experiments on standard CLIP benchmark datasets demonstrate that the image-based approach helps users predict, without any labeled examples, whether a VLM will be effective for their application.

</details>


### [65] [OTI: A Model-free and Visually Interpretable Measure of Image Attackability](https://arxiv.org/abs/2601.17536)
*Jiaming Liang,Haowei Liu,Chi-Man Pun*

Main category: cs.CV

TL;DR: 提出一种新的图像可攻击性度量方法OTI（物体纹理强度），该方法是模型无关且视觉可解释的，通过测量图像语义物体的纹理强度来评估图像的可攻击性。


<details>
  <summary>Details</summary>
Motivation: 现有图像可攻击性度量方法存在两个主要局限：1）依赖模型代理提供先验知识（如梯度或最小扰动），但实践中许多任务特定模型不易获取；2）提取的特征缺乏视觉可解释性，难以直接理解与图像的关系。

Method: 提出物体纹理强度（OTI）作为图像可攻击性的模型无关且视觉可解释的度量方法。该方法从决策边界以及对抗扰动的中高频特性角度描述OTI原理，通过测量图像语义物体的纹理强度来评估可攻击性。

Result: 综合实验表明OTI方法有效且计算高效。OTI为对抗机器学习社区提供了对可攻击性的视觉理解，能够识别哪些图像更容易受到对抗攻击。

Conclusion: OTI是一种创新的图像可攻击性度量方法，解决了现有方法的局限性，具有模型无关性和视觉可解释性，在主动学习、对抗训练和攻击增强等应用中具有重要价值。

Abstract: Despite the tremendous success of neural networks, benign images can be corrupted by adversarial perturbations to deceive these models. Intriguingly, images differ in their attackability. Specifically, given an attack configuration, some images are easily corrupted, whereas others are more resistant. Evaluating image attackability has important applications in active learning, adversarial training, and attack enhancement. This prompts a growing interest in developing attackability measures. However, existing methods are scarce and suffer from two major limitations: (1) They rely on a model proxy to provide prior knowledge (e.g., gradients or minimal perturbation) to extract model-dependent image features. Unfortunately, in practice, many task-specific models are not readily accessible. (2) Extracted features characterizing image attackability lack visual interpretability, obscuring their direct relationship with the images. To address these, we propose a novel Object Texture Intensity (OTI), a model-free and visually interpretable measure of image attackability, which measures image attackability as the texture intensity of the image's semantic object. Theoretically, we describe the principles of OTI from the perspectives of decision boundaries as well as the mid- and high-frequency characteristics of adversarial perturbations. Comprehensive experiments demonstrate that OTI is effective and computationally efficient. In addition, our OTI provides the adversarial machine learning community with a visual understanding of attackability.

</details>


### [66] [Saliency Driven Imagery Preprocessing for Efficient Compression -- Industrial Paper](https://arxiv.org/abs/2601.17555)
*Justin Downes,Sam Saltwick,Anthony Chen*

Main category: cs.CV

TL;DR: 提出一种基于显著性图的卫星图像预处理方法，结合传统有损压缩标准，实现单张大型卫星图像内的可变比特率压缩


<details>
  <summary>Details</summary>
Motivation: 卫星图像数据量巨大（每天数百TB），存储和带宽成本高。许多下游任务只关注图像中的小区域，而标准压缩方法对整个图像同等处理，无法针对重要区域优化

Method: 使用显著性图驱动的图像预处理技术，结合传统有损压缩编码标准。通过可变大小的平滑核映射到不同的量化显著性水平，处理图像像素以优化下游压缩和编码方案

Result: 实现了单张大型卫星图像内的可变比特率压缩，能够在单个图像内根据区域重要性调整压缩率

Conclusion: 通过显著性图驱动的预处理与传统压缩标准结合，可以有效优化卫星图像压缩，针对下游任务关注区域提供更好的压缩效率

Abstract: The compression of satellite imagery remains an important research area as hundreds of terabytes of images are collected every day, which drives up storage and bandwidth costs. Although progress has been made in increasing the resolution of these satellite images, many downstream tasks are only interested in small regions of any given image. These areas of interest vary by task but, once known, can be used to optimize how information within the image is encoded. Whereas standard image encoding methods, even those optimized for remote sensing, work on the whole image equally, there are emerging methods that can be guided by saliency maps to focus on important areas. In this work we show how imagery preprocessing techniques driven by saliency maps can be used with traditional lossy compression coding standards to create variable rate image compression within a single large satellite image. Specifically, we use variable sized smoothing kernels that map to different quantized saliency levels to process imagery pixels in order to optimize downstream compression and encoding schemes.

</details>


### [67] [Sponge Tool Attack: Stealthy Denial-of-Efficiency against Tool-Augmented Agentic Reasoning](https://arxiv.org/abs/2601.17566)
*Qi Li,Xinchao Wang*

Main category: cs.CV

TL;DR: 提出Sponge Tool Attack (STA)攻击方法，通过重写输入提示来破坏LLM工具调用推理过程，造成计算开销但保持任务语义不变


<details>
  <summary>Details</summary>
Motivation: 现有LLM工具调用方法虽然高效实用，但其对工具调用过程恶意操纵的脆弱性尚未充分研究，需要探索这种攻击面

Method: STA采用迭代式多智能体协作框架，在仅查询访问假设下重写输入提示，将简洁推理轨迹转换为冗长复杂路径，保持语义保真度

Result: 在6个模型、12个工具、4个代理框架、13个数据集和5个领域上验证了STA的有效性，能显著增加计算开销

Conclusion: 揭示了LLM工具调用推理的安全脆弱性，STA攻击能在不修改模型或工具的情况下破坏推理效率，为安全防御提供重要启示

Abstract: Enabling large language models (LLMs) to solve complex reasoning tasks is a key step toward artificial general intelligence. Recent work augments LLMs with external tools to enable agentic reasoning, achieving high utility and efficiency in a plug-and-play manner. However, the inherent vulnerabilities of such methods to malicious manipulation of the tool-calling process remain largely unexplored. In this work, we identify a tool-specific attack surface and propose Sponge Tool Attack (STA), which disrupts agentic reasoning solely by rewriting the input prompt under a strict query-only access assumption. Without any modification on the underlying model or the external tools, STA converts originally concise and efficient reasoning trajectories into unnecessarily verbose and convoluted ones before arriving at the final answer. This results in substantial computational overhead while remaining stealthy by preserving the original task semantics and user intent. To achieve this, we design STA as an iterative, multi-agent collaborative framework with explicit rewritten policy control, and generates benign-looking prompt rewrites from the original one with high semantic fidelity. Extensive experiments across 6 models (including both open-source models and closed-source APIs), 12 tools, 4 agentic frameworks, and 13 datasets spanning 5 domains validate the effectiveness of STA.

</details>


### [68] [Stylizing ViT: Anatomy-Preserving Instance Style Transfer for Domain Generalization](https://arxiv.org/abs/2601.17586)
*Sebastian Doerrich,Francesco Di Salvo,Jonas Alle,Christian Ledig*

Main category: cs.CV

TL;DR: 提出Stylizing ViT，一种用于医学图像域泛化的新型视觉Transformer，通过权重共享的注意力块同时处理自注意力和交叉注意力，实现保持解剖结构一致性的风格迁移，用于数据增强和测试时增强。


<details>
  <summary>Details</summary>
Motivation: 医学图像分析中的深度学习模型由于数据异质性和稀缺性，在跨域和跨人口群体泛化方面存在困难。传统数据增强方法在显著域偏移下效果有限，现有风格增强方法要么风格多样性不足，要么会引入伪影。

Method: 提出Stylizing ViT，一种新颖的视觉Transformer编码器，采用权重共享的注意力块同时处理自注意力和交叉注意力。自注意力保持解剖结构一致性，交叉注意力执行风格迁移。该方法用于数据增强和测试时增强。

Result: 在组织病理学和皮肤病学的三个图像分类任务上评估，相比现有技术提高了鲁棒性（最高+13%准确率），生成无伪影的感知可信图像。测试时增强带来17%的性能提升。

Conclusion: Stylizing ViT通过创新的权重共享注意力设计，有效解决了医学图像域泛化问题，既能生成高质量的风格化图像用于数据增强，也能在推理时通过测试时增强进一步提升性能。

Abstract: Deep learning models in medical image analysis often struggle with generalizability across domains and demographic groups due to data heterogeneity and scarcity. Traditional augmentation improves robustness, but fails under substantial domain shifts. Recent advances in stylistic augmentation enhance domain generalization by varying image styles but fall short in terms of style diversity or by introducing artifacts into the generated images. To address these limitations, we propose Stylizing ViT, a novel Vision Transformer encoder that utilizes weight-shared attention blocks for both self- and cross-attention. This design allows the same attention block to maintain anatomical consistency through self-attention while performing style transfer via cross-attention. We assess the effectiveness of our method for domain generalization by employing it for data augmentation on three distinct image classification tasks in the context of histopathology and dermatology. Results demonstrate an improved robustness (up to +13% accuracy) over the state of the art while generating perceptually convincing images without artifacts. Additionally, we show that Stylizing ViT is effective beyond training, achieving a 17% performance improvement during inference when used for test-time augmentation. The source code is available at https://github.com/sdoerrich97/stylizing-vit .

</details>


### [69] [SPACE-CLIP: Spatial Perception via Adaptive CLIP Embeddings for Monocular Depth Estimation](https://arxiv.org/abs/2601.17657)
*Taewan Cho,Taeryang Kim,Andrew Jaeyong Choi*

Main category: cs.CV

TL;DR: SPACE-CLIP提出了一种双路径解码器架构，直接从冻结的CLIP视觉编码器中提取几何知识，无需文本编码器或文本提示，显著提升了深度估计性能。


<details>
  <summary>Details</summary>
Motivation: CLIP在语义理解方面表现出色，但天生难以感知几何结构。现有方法通过文本提示查询CLIP，这种方法间接且低效。需要一种更直接、高效的方法来解锁CLIP中的几何知识。

Method: 提出SPACE-CLIP架构：1）语义路径解释高层特征，使用FiLM进行全局上下文动态调节；2）结构路径从早期层提取细粒度空间细节；3）通过分层融合将两个互补流结合，实现语义上下文和精确几何的稳健合成。

Result: 在KITTI基准测试中，SPACE-CLIP显著优于之前的CLIP基方法。消融研究验证了双路径协同融合对成功的关键作用。

Conclusion: SPACE-CLIP提供了一种新颖、高效且架构优雅的蓝图，用于重新利用大规模视觉模型。该方法不仅是一个独立的深度估计器，而且是下一代具身AI系统（如VLA模型）中易于集成的空间感知模块。

Abstract: Contrastive Language-Image Pre-training (CLIP) has accomplished extraordinary success for semantic understanding but inherently struggles to perceive geometric structure. Existing methods attempt to bridge this gap by querying CLIP with textual prompts, a process that is often indirect and inefficient. This paper introduces a fundamentally different approach using a dual-pathway decoder. We present SPACE-CLIP, an architecture that unlocks and interprets latent geometric knowledge directly from a frozen CLIP vision encoder, completely bypassing the text encoder and its associated textual prompts. A semantic pathway interprets high-level features, dynamically conditioned on global context using feature-wise linear modulation (FiLM). In addition, a structural pathway extracts fine-grained spatial details from early layers. These complementary streams are hierarchically fused, enabling a robust synthesis of semantic context and precise geometry. Extensive experiments on the KITTI benchmark show that SPACE-CLIP dramatically outperforms previous CLIP-based methods. Our ablation studies validate that the synergistic fusion of our dual pathways is critical to this success. SPACE-CLIP offers a new, efficient, and architecturally elegant blueprint for repurposing large-scale vision models. The proposed method is not just a standalone depth estimator, but a readily integrable spatial perception module for the next generation of embodied AI systems, such as vision-language-action (VLA) models. Our model is available at https://github.com/taewan2002/space-clip

</details>


### [70] [Training-Free Text-to-Image Compositional Food Generation via Prompt Grafting](https://arxiv.org/abs/2601.17666)
*Xinyue Pan,Yuhao Chen,Fengqing Zhu*

Main category: cs.CV

TL;DR: 提出Prompt Grafting框架，通过两阶段提示控制解决多食物图像生成中的物体纠缠问题，实现可控的食物分离与混合


<details>
  <summary>Details</summary>
Motivation: 现实世界的餐食图像通常包含多种食物，但现有的文本到图像扩散模型在生成多食物图像时存在物体纠缠问题（如米饭和汤融合在一起），这影响了基于图像的饮食评估和食谱可视化等应用

Method: 提出Prompt Grafting训练免费框架，结合文本中的显式空间线索和采样过程中的隐式布局指导。采用两阶段过程：首先用布局提示建立不同区域，然后在布局稳定后将目标提示"嫁接"上去

Result: 在两个食物数据集上的实验表明，该方法显著提高了目标物体的存在率，并提供了可控分离的定性证据

Conclusion: Prompt Grafting框架有效解决了多食物图像生成中的物体纠缠问题，实现了用户可控制的食物分离与混合，为图像饮食评估和食谱可视化等应用提供了可靠的数据增强方法

Abstract: Real-world meal images often contain multiple food items, making reliable compositional food image generation important for applications such as image-based dietary assessment, where multi-food data augmentation is needed, and recipe visualization. However, modern text-to-image diffusion models struggle to generate accurate multi-food images due to object entanglement, where adjacent foods (e.g., rice and soup) fuse together because many foods do not have clear boundaries. To address this challenge, we introduce Prompt Grafting (PG), a training-free framework that combines explicit spatial cues in text with implicit layout guidance during sampling. PG runs a two-stage process where a layout prompt first establishes distinct regions and the target prompt is grafted once layout formation stabilizes. The framework enables food entanglement control: users can specify which food items should remain separated or be intentionally mixed by editing the arrangement of layouts. Across two food datasets, our method significantly improves the presence of target objects and provides qualitative evidence of controllable separation.

</details>


### [71] [Uni-RS: A Spatially Faithful Unified Understanding and Generation Model for Remote Sensing](https://arxiv.org/abs/2601.17673)
*Weiyu Zhang,Yuan Hu,Yong Li,Yu Liu*

Main category: cs.CV

TL;DR: Uni-RS模型解决遥感多模态模型中的空间反转问题：模型能识别图像中的空间关系，但在文本生成图像时无法忠实执行相同空间关系。通过空间布局规划、空间感知查询监督和图像-描述空间布局变换来提升空间忠实度。


<details>
  <summary>Details</summary>
Motivation: 现有统一的遥感多模态模型存在明显的空间反转诅咒：虽然能准确识别和描述图像中物体的位置，但在文本到图像生成时经常无法忠实执行相同的空间关系，而这些空间关系是遥感图像中的核心语义信息。

Method: 1. 显式空间布局规划：将文本指令转化为空间布局计划，将几何规划与视觉合成解耦。2. 空间感知查询监督：使可学习查询偏向于指令中明确指定的空间关系。3. 图像-描述空间布局变换：让模型接触系统性的几何一致的空间变换。

Result: 在多个基准测试上的广泛实验表明，该方法显著提高了文本到图像生成中的空间忠实度，同时在图像描述、视觉定位和VQA等多模态理解任务上保持了强大的性能。

Conclusion: Uni-RS是第一个专门为遥感设计的统一多模态模型，通过显式处理理解和生成之间的空间不对称性，有效解决了遥感多模态模型中的空间反转问题。

Abstract: Unified remote sensing multimodal models exhibit a pronounced spatial reversal curse: Although they can accurately recognize and describe object locations in images, they often fail to faithfully execute the same spatial relations during text-to-image generation, where such relations constitute core semantic information in remote sensing. Motivated by this observation, we propose Uni-RS, the first unified multimodal model tailored for remote sensing, to explicitly address the spatial asymmetry between understanding and generation. Specifically, we first introduce explicit Spatial-Layout Planning to transform textual instructions into spatial layout plans, decoupling geometric planning from visual synthesis. We then impose Spatial-Aware Query Supervision to bias learnable queries toward spatial relations explicitly specified in the instruction. Finally, we develop Image-Caption Spatial Layout Variation to expose the model to systematic geometry-consistent spatial transformations. Extensive experiments across multiple benchmarks show that our approach substantially improves spatial faithfulness in text-to-image generation, while maintaining strong performance on multimodal understanding tasks like image captioning, visual grounding, and VQA tasks.

</details>


### [72] [StyleDecoupler: Generalizable Artistic Style Disentanglement](https://arxiv.org/abs/2601.17697)
*Zexi Jia,Jinchao Zhang,Jie Zhou*

Main category: cs.CV

TL;DR: StyleDecoupler是一个信息论框架，通过利用单模态模型作为内容参考，从多模态视觉模型中分离纯风格特征，无需微调即可实现风格与内容的解耦。


<details>
  <summary>Details</summary>
Motivation: 艺术风格与语义内容深度纠缠，难以单独表示。现有视觉模型要么同时编码风格和内容（多模态），要么抑制风格专注于内容不变特征（单模态），这为风格解耦提供了机会。

Method: 利用单模态模型表示作为内容参考，通过互信息最小化从多模态嵌入中分离纯风格特征。StyleDecoupler作为即插即用模块在冻结的视觉语言模型上运行，无需微调。同时构建了WeART大规模艺术数据集（28万件作品，152种风格，1556位艺术家）。

Result: 在WeART和WikiART数据集上实现了最先进的风格检索性能，同时支持风格关系映射和生成模型评估等应用。

Conclusion: StyleDecoupler有效解决了艺术风格与内容的解耦问题，通过信息论框架实现了纯风格特征的提取，为艺术风格分析和生成提供了有力工具。

Abstract: Representing artistic style is challenging due to its deep entanglement with semantic content. We propose StyleDecoupler, an information-theoretic framework that leverages a key insight: multi-modal vision models encode both style and content, while uni-modal models suppress style to focus on content-invariant features. By using uni-modal representations as content-only references, we isolate pure style features from multi-modal embeddings through mutual information minimization. StyleDecoupler operates as a plug-and-play module on frozen Vision-Language Models without fine-tuning. We also introduce WeART, a large-scale benchmark of 280K artworks across 152 styles and 1,556 artists. Experiments show state-of-the-art performance on style retrieval across WeART and WikiART, while enabling applications like style relationship mapping and generative model evaluation. We release our method and dataset at this url.

</details>


### [73] [An AI-enabled tool for quantifying overlapping red blood cell sickling dynamics in microfluidic assays](https://arxiv.org/abs/2601.17703)
*Nikhil Kadivar,Guansheng Li,Jianlu Zheng,John M. Higgins,Ming Dao,George Em Karniadakis,Mengjia Xu*

Main category: cs.CV

TL;DR: 开发了一个自动化深度学习框架，用于在时间序列显微镜数据中量化红细胞群体，特别是在高密度和细胞重叠条件下，实现镰状细胞形态转变的准确识别和追踪。


<details>
  <summary>Details</summary>
Motivation: 理解镰状细胞动力学需要在不同生物物理条件下准确识别形态转变，特别是在高密度和细胞重叠的群体中。传统方法面临手动标注稀缺和细胞重叠的挑战。

Method: 开发了一个集成AI辅助标注、分割、分类和实例计数的深度学习框架。使用Roboflow平台标注实验图像生成训练数据集，训练nnU-Net分割模型，结合分水岭算法解决细胞重叠问题。

Result: 框架在仅需少量标注数据的情况下实现了高分割性能，能定量追踪红细胞形态的动态变化，通过高密度细胞悬浮将实验通量提高一倍以上，捕获药物依赖的镰状化行为，并揭示细胞形态演化的独特机械生物学特征。

Conclusion: 该AI驱动框架建立了一个可扩展且可重复的计算平台，用于研究细胞生物力学和评估微生理系统中的治疗效果。

Abstract: Understanding sickle cell dynamics requires accurate identification of morphological transitions under diverse biophysical conditions, particularly in densely packed and overlapping cell populations. Here, we present an automated deep learning framework that integrates AI-assisted annotation, segmentation, classification, and instance counting to quantify red blood cell (RBC) populations across varying density regimes in time-lapse microscopy data. Experimental images were annotated using the Roboflow platform to generate labeled dataset for training an nnU-Net segmentation model. The trained network enables prediction of the temporal evolution of the sickle cell fraction, while a watershed algorithm resolves overlapping cells to enhance quantification accuracy. Despite requiring only a limited amount of labeled data for training, the framework achieves high segmentation performance, effectively addressing challenges associated with scarce manual annotations and cell overlap. By quantitatively tracking dynamic changes in RBC morphology, this approach can more than double the experimental throughput via densely packed cell suspensions, capture drug-dependent sickling behavior, and reveal distinct mechanobiological signatures of cellular morphological evolution. Overall, this AI-driven framework establishes a scalable and reproducible computational platform for investigating cellular biomechanics and assessing therapeutic efficacy in microphysiological systems.

</details>


### [74] [Advancing Structured Priors for Sparse-Voxel Surface Reconstruction](https://arxiv.org/abs/2601.17720)
*Ting-Hsun Chi,Chu-Rong Chen,Chi-Tun Hsu,Hsuan-Ting Lin,Sheng-Yu Huang,Cheng Sun,Yu-Chiang Frank Wang*

Main category: cs.CV

TL;DR: 提出了一种结合3D高斯泼溅和稀疏体素光栅化优势的方法，通过智能体素初始化和改进的深度几何监督，在保持快速收敛的同时提升了几何精度和表面完整性。


<details>
  <summary>Details</summary>
Motivation: 现有两种显式表示方法各有优缺点：3D高斯泼溅收敛快且有几何先验，但表面保真度受限于点状参数化；稀疏体素光栅化能提供连续不透明度场和清晰几何，但均匀密集网格初始化收敛慢且未充分利用场景结构。需要结合两者优势。

Method: 1) 提出体素初始化方法，在合理位置放置体素并设置适当细节层次，为每场景优化提供强起点；2) 提出改进的深度几何监督，将多视图线索转换为直接的每射线深度正则化，增强深度一致性而不模糊边缘。

Result: 在标准基准测试中，相比先前方法在几何精度、细结构恢复和表面完整性方面都有改进，同时保持了快速收敛。

Conclusion: 通过结合3D高斯泼溅和稀疏体素光栅化的互补优势，提出的方法在保持快速收敛的同时显著提升了表面重建的几何精度和完整性。

Abstract: Reconstructing accurate surfaces with radiance fields has progressed rapidly, yet two promising explicit representations, 3D Gaussian Splatting and sparse-voxel rasterization, exhibit complementary strengths and weaknesses. 3D Gaussian Splatting converges quickly and carries useful geometric priors, but surface fidelity is limited by its point-like parameterization. Sparse-voxel rasterization provides continuous opacity fields and crisp geometry, but its typical uniform dense-grid initialization slows convergence and underutilizes scene structure. We combine the advantages of both by introducing a voxel initialization method that places voxels at plausible locations and with appropriate levels of detail, yielding a strong starting point for per-scene optimization. To further enhance depth consistency without blurring edges, we propose refined depth geometry supervision that converts multi-view cues into direct per-ray depth regularization. Experiments on standard benchmarks demonstrate improvements over prior methods in geometric accuracy, better fine-structure recovery, and more complete surfaces, while maintaining fast convergence.

</details>


### [75] [Implicit Neural Representation-Based Continuous Single Image Super Resolution: An Empirical Study](https://arxiv.org/abs/2601.17723)
*Tayyab Nasir,Daochang Liu,Ajmal Mian*

Main category: cs.CV

TL;DR: 该论文对基于隐式神经表示(INR)的任意尺度超分辨率方法进行了首次系统性实证研究，发现复杂INR方法相比早期方法提升有限，训练配置对性能影响显著，并提出能提升纹理保真度的新损失函数。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏对INR在任意尺度超分辨率中有效性的系统性实证研究，需要评估现有方法、训练配方（如缩放定律、目标设计、优化策略）的影响，以建立基准、识别饱和点并指明未来方向。

Method: 1. 在不同设置下比较现有技术，在多个图像质量指标上汇总性能结果；2. 提供统一框架和代码库以促进可重复比较；3. 研究受控训练配置对感知图像质量的影响；4. 提出新损失函数，在惩罚强度变化的同时保留边缘、纹理和细节。

Result: 1. 近期复杂INR方法相比早期方法仅有边际改进；2. 模型性能与训练配置强相关，这是先前工作忽视的因素；3. 提出的损失函数能跨架构提升纹理保真度，强调目标设计对特定感知增益的作用；4. 缩放定律适用于INR基ASSR，确认模型复杂度和数据多样性增加可带来可预测增益。

Conclusion: 该研究填补了INR基任意尺度超分辨率系统性实证分析的空白，揭示了训练配置的重要性大于架构创新，提出的损失函数能有效提升纹理质量，缩放定律的适用性为未来扩展提供了指导。

Abstract: Implicit neural representation (INR) has become the standard approach for arbitrary-scale image super-resolution (ASSR). To date, no empirical study has systematically examined the effectiveness of existing methods, nor investigated the effects of different training recipes, such as scaling laws, objective design, and optimization strategies. A rigorous empirical analysis is essential not only for benchmarking performance and revealing true gains but also for establishing the current state of ASSR, identifying saturation limits, and highlighting promising directions. We fill this gap by comparing existing techniques across diverse settings and presenting aggregated performance results on multiple image quality metrics. We contribute a unified framework and code repository to facilitate reproducible comparisons. Furthermore, we investigate the impact of carefully controlled training configurations on perceptual image quality and examine a new loss function that penalizes intensity variations while preserving edges, textures, and finer details during training. We conclude the following key insights that have been previously overlooked: (1) Recent, more complex INR methods provide only marginal improvements over earlier methods. (2) Model performance is strongly correlated to training configurations, a factor overlooked in prior works. (3) The proposed loss enhances texture fidelity across architectures, emphasizing the role of objective design for targeted perceptual gains. (4) Scaling laws apply to INR-based ASSR, confirming predictable gains with increased model complexity and data diversity.

</details>


### [76] [Flatten The Complex: Joint B-Rep Generation via Compositional $k$-Cell Particles](https://arxiv.org/abs/2601.17733)
*Junran Lu,Yuanqi Li,Hengji Li,Jie Guo,Yanwen Guo*

Main category: cs.CV

TL;DR: 提出了一种将B-Rep表示为k-cell粒子集合的新范式，通过多模态流匹配框架联合生成拓扑和几何，实现高质量CAD模型生成


<details>
  <summary>Details</summary>
Motivation: B-Rep是CAD中的标准表示，但生成建模面临挑战，因为其作为几何单元复合体的异质性将拓扑和几何纠缠在一起。现有方法采用级联序列处理层次结构，未能充分利用单元间的几何关系（如邻接和共享），限制了上下文感知和错误恢复能力。

Method: 将B-Rep重新表述为组合k-cell粒子集合：将每个拓扑实体编码为粒子组合，相邻单元在其界面共享相同潜在表示，从而促进共享边界上的几何耦合。使用多模态流匹配框架合成这些粒子集，支持无条件生成和条件任务（如单视图或点云3D重建）。

Result: 实验表明，该方法能生成高保真CAD模型，在有效性和可编辑性方面优于现有方法。显式和局部化的表示自然扩展到下游任务（如局部修复），并能直接合成非流形结构（如线框）。

Conclusion: 通过将B-Rep重新表述为组合粒子集合，解耦了刚性层次结构，统一了顶点、边和面，实现了具有全局上下文感知的拓扑和几何联合生成，为CAD生成建模提供了新范式。

Abstract: Boundary Representation (B-Rep) is the widely adopted standard
  in Computer-Aided Design (CAD) and manufacturing. However, generative modeling of B-Reps remains a formidable challenge due to their inherent heterogeneity as geometric cell complexes, which entangles topology with geometry across cells of varying orders (i.e., $k$-cells such as vertices, edges, faces). Previous methods typically rely on cascaded sequences to handle this hierarchy, which fails to fully exploit the geometric relationships between cells, such as adjacency and sharing, limiting context awareness and error recovery. To fill this gap, we introduce a novel paradigm that reformulates B-Reps into sets of compositional $k$-cell particles. Our approach encodes each topological entity as a composition of particles, where adjacent cells share identical latents at their interfaces, thereby promoting geometric coupling along shared boundaries. By decoupling the rigid hierarchy, our representation unifies vertices, edges, and faces, enabling the joint generation of topology and geometry with global context awareness.
  We synthesize these particle sets using a multi-modal flow matching framework to handle unconditional generation as well as precise conditional tasks, such as 3D reconstruction from single-view or point cloud. Furthermore, the explicit and localized nature of our representation naturally extends to downstream tasks like local in-painting and enables the direct synthesis of non-manifold structures (e.g., wireframes). Extensive experiments demonstrate that our method produces high-fidelity CAD models with superior validity and editability compared to state-of-the-art methods.

</details>


### [77] [The Script is All You Need: An Agentic Framework for Long-Horizon Dialogue-to-Cinematic Video Generation](https://arxiv.org/abs/2601.17737)
*Chenyu Mu,Xin He,Qu Yang,Wanshun Chen,Jiadi Yao,Huang Liu,Zihao Yi,Bo Zhao,Xingyu Chen,Ruotian Ma,Fanghua Ye,Erkun Yang,Cheng Deng,Zhaopeng Tu,Xiaolong Li,Linus*

Main category: cs.CV

TL;DR: 提出ScripterAgent框架，将对话转换为可执行的电影脚本，再通过DirectorAgent协调视频模型生成连贯的长篇叙事视频，解决现有模型在对话到视频生成中的语义鸿沟问题。


<details>
  <summary>Details</summary>
Motivation: 当前视频生成模型虽然能根据简单文本提示生成视觉内容，但难以从高级概念（如对话）生成长篇连贯的叙事视频，存在"语义鸿沟"问题。

Method: 1. 构建ScriptBench大规模多模态基准数据集；2. 训练ScripterAgent将粗略对话转换为细粒度可执行电影脚本；3. 使用DirectorAgent通过跨场景连续生成策略协调SOTA视频模型；4. 引入AI驱动的CriticAgent和新的视觉-脚本对齐(VSA)指标进行评估。

Result: 框架显著提高了所有测试视频模型的脚本忠实度和时间保真度，同时揭示了当前SOTA模型在视觉奇观与严格脚本遵循之间的关键权衡。

Conclusion: 该端到端代理框架成功弥合了创意想法与电影执行之间的语义鸿沟，为自动化电影制作的未来发展提供了有价值的见解。

Abstract: Recent advances in video generation have produced models capable of synthesizing stunning visual content from simple text prompts. However, these models struggle to generate long-form, coherent narratives from high-level concepts like dialogue, revealing a ``semantic gap'' between a creative idea and its cinematic execution. To bridge this gap, we introduce a novel, end-to-end agentic framework for dialogue-to-cinematic-video generation. Central to our framework is ScripterAgent, a model trained to translate coarse dialogue into a fine-grained, executable cinematic script. To enable this, we construct ScriptBench, a new large-scale benchmark with rich multimodal context, annotated via an expert-guided pipeline. The generated script then guides DirectorAgent, which orchestrates state-of-the-art video models using a cross-scene continuous generation strategy to ensure long-horizon coherence. Our comprehensive evaluation, featuring an AI-powered CriticAgent and a new Visual-Script Alignment (VSA) metric, shows our framework significantly improves script faithfulness and temporal fidelity across all tested video models. Furthermore, our analysis uncovers a crucial trade-off in current SOTA models between visual spectacle and strict script adherence, providing valuable insights for the future of automated filmmaking.

</details>


### [78] [Learning Sewing Patterns via Latent Flow Matching of Implicit Fields](https://arxiv.org/abs/2601.17740)
*Cong Cao,Ren Li,Corentin Dumery,Hao Li*

Main category: cs.CV

TL;DR: 提出基于隐式表示的缝纫图案建模方法，使用符号距离场表示面板边界，无符号距离场表示缝端点，通过连续潜在空间实现可微分网格化，支持图案生成、图像估计、补全和适配等应用。


<details>
  <summary>Details</summary>
Motivation: 缝纫图案定义了服装的结构基础，对时尚设计、制作和物理模拟至关重要。尽管自动图案生成有进展，但由于面板几何形状和缝线排列的广泛变化性，准确建模缝纫图案仍然困难。

Method: 1. 使用符号距离场表示每个面板的边界，无符号距离场识别缝端点；2. 将这些场编码到连续潜在空间，实现可微分网格化；3. 潜在流匹配模型学习面板组合的分布；4. 缝线预测模块从提取的边缘段恢复缝线关系。

Result: 能够准确建模和生成具有复杂结构的缝纫图案；相比现有方法，从图像估计缝纫图案的准确性有所提高；支持图案补全和适配等应用。

Conclusion: 该方法为数字时尚设计提供了实用的工具，能够有效处理缝纫图案建模中的复杂性和变异性问题。

Abstract: Sewing patterns define the structural foundation of garments and are essential for applications such as fashion design, fabrication, and physical simulation. Despite progress in automated pattern generation, accurately modeling sewing patterns remains difficult due to the broad variability in panel geometry and seam arrangements. In this work, we introduce a sewing pattern modeling method based on an implicit representation. We represent each panel using a signed distance field that defines its boundary and an unsigned distance field that identifies seam endpoints, and encode these fields into a continuous latent space that enables differentiable meshing. A latent flow matching model learns distributions over panel combinations in this representation, and a stitching prediction module recovers seam relations from extracted edge segments. This formulation allows accurate modeling and generation of sewing patterns with complex structures. We further show that it can be used to estimate sewing patterns from images with improved accuracy relative to existing approaches, and supports applications such as pattern completion and refitting, providing a practical tool for digital fashion design.

</details>


### [79] [Frequency-aware Neural Representation for Videos](https://arxiv.org/abs/2601.17741)
*Jun Zhu,Xinfeng Zhang,Lv Tang,Junhao Jiang,Gai Zhang,Jia Wang*

Main category: cs.CV

TL;DR: FaNeRV是一种频率感知的神经视频表示方法，通过显式解耦低频和高频分量来提升视频压缩性能，解决了现有INR方法中的频谱偏差问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于隐式神经表示(INR)的视频压缩框架存在固有的频谱偏差，倾向于低频分量，导致重建结果过度平滑和率失真性能不佳。

Method: 1. 提出多分辨率监督策略，通过分阶段监督引导网络逐步捕获全局结构和细粒度纹理；2. 动态高频注入机制，自适应地强调挑战性区域；3. 频率分解网络模块，改进不同频段的特征建模。

Result: 在标准基准测试中，FaNeRV显著优于最先进的INR方法，并与传统编解码器实现了竞争性的率失真性能。

Conclusion: FaNeRV通过频率感知的神经表示方法有效解决了INR中的频谱偏差问题，为视频压缩提供了高效且保真的重建方案。

Abstract: Implicit Neural Representations (INRs) have emerged as a promising paradigm for video compression. However, existing INR-based frameworks typically suffer from inherent spectral bias, which favors low-frequency components and leads to over-smoothed reconstructions and suboptimal rate-distortion performance. In this paper, we propose FaNeRV, a Frequency-aware Neural Representation for videos, which explicitly decouples low- and high-frequency components to enable efficient and faithful video reconstruction. FaNeRV introduces a multi-resolution supervision strategy that guides the network to progressively capture global structures and fine-grained textures through staged supervision . To further enhance high-frequency reconstruction, we propose a dynamic high-frequency injection mechanism that adaptively emphasizes challenging regions. In addition, we design a frequency-decomposed network module to improve feature modeling across different spectral bands. Extensive experiments on standard benchmarks demonstrate that FaNeRV significantly outperforms state-of-the-art INR methods and achieves competitive rate-distortion performance against traditional codecs.

</details>


### [80] [Video Compression with Hierarchical Temporal Neural Representation](https://arxiv.org/abs/2601.17743)
*Jun Zhu,Xinfeng Zhang,Lv Tang,Junhao Jiang,Gai Zhang,Jia Wang*

Main category: cs.CV

TL;DR: TeNeRV提出了一种层次化时间神经表示方法，通过帧间特征融合和GoP自适应调制来捕捉视频的短期和长期依赖关系，在率失真性能上优于现有INR方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于隐式神经表示（INR）的视频压缩方法将时间维度作为独立输入处理，限制了捕捉复杂时间依赖关系的能力。需要一种能够同时建模短期和长期时间依赖的方法。

Method: TeNeRV包含两个核心组件：1）帧间特征融合（IFF）模块，聚合相邻帧特征以保持局部时间一致性和捕捉细粒度运动；2）GoP自适应调制（GAM）机制，将视频划分为图像组并学习组特定先验，通过调制网络参数实现跨GoP的自适应表示。

Result: 大量实验表明，TeNeRV在率失真性能上持续优于现有的基于INR的方法，验证了所提方法的有效性。

Conclusion: TeNeRV通过层次化时间建模成功解决了INR方法中时间依赖关系捕捉不足的问题，为视频压缩提供了更有效的神经表示框架。

Abstract: Video compression has recently benefited from implicit neural representations (INRs), which model videos as continuous functions. INRs offer compact storage and flexible reconstruction, providing a promising alternative to traditional codecs. However, most existing INR-based methods treat the temporal dimension as an independent input, limiting their ability to capture complex temporal dependencies. To address this, we propose a Hierarchical Temporal Neural Representation for Videos, TeNeRV. TeNeRV integrates short- and long-term dependencies through two key components. First, an Inter-Frame Feature Fusion (IFF) module aggregates features from adjacent frames, enforcing local temporal coherence and capturing fine-grained motion. Second, a GoP-Adaptive Modulation (GAM) mechanism partitions videos into Groups-of-Pictures and learns group-specific priors. The mechanism modulates network parameters, enabling adaptive representations across different GoPs. Extensive experiments demonstrate that TeNeRV consistently outperforms existing INR-based methods in rate-distortion performance, validating the effectiveness of our proposed approach.

</details>


### [81] [Bridging Supervision Gaps: A Unified Framework for Remote Sensing Change Detection](https://arxiv.org/abs/2601.17747)
*Kaixuan Jiang,Chen Wu,Zhenghui Zhao,Chengxi Han*

Main category: cs.CV

TL;DR: UniCD是一个统一的遥感变化检测框架，通过耦合架构协同处理有监督、弱监督和无监督任务，在共享编码器基础上使用多分支协作学习机制，在多个数据集上取得最优性能。


<details>
  <summary>Details</summary>
Motivation: 现实场景中像素级变化标签获取成本高，现有模型难以适应不同标注可用性的多样化场景，需要一个统一的框架来处理不同监督级别的变化检测任务。

Method: UniCD采用共享编码器和多分支协作学习架构：1)有监督分支引入时空感知模块实现双时相特征高效融合；2)弱监督分支构建变化表示正则化，从粗粒度激活引导模型收敛；3)无监督分支提出语义先验驱动变化推理，将无监督任务转化为可控的弱监督路径优化。

Result: 在主流数据集上，UniCD在三种任务上都取得最优性能，在弱监督和无监督场景下表现尤为突出，在LEVIR-CD数据集上分别比当前最优方法提升12.72%和12.37%。

Conclusion: UniCD通过统一的耦合架构成功解决了不同监督级别变化检测任务的协同处理问题，消除了架构壁垒，实现了异构监督信号的深度融合，为实际应用提供了灵活有效的解决方案。

Abstract: Change detection (CD) aims to identify surface changes from multi-temporal remote sensing imagery. In real-world scenarios, Pixel-level change labels are expensive to acquire, and existing models struggle to adapt to scenarios with diverse annotation availability. To tackle this challenge, we propose a unified change detection framework (UniCD), which collaboratively handles supervised, weakly-supervised, and unsupervised tasks through a coupled architecture. UniCD eliminates architectural barriers through a shared encoder and multi-branch collaborative learning mechanism, achieving deep coupling of heterogeneous supervision signals. Specifically, UniCD consists of three supervision-specific branches. In the supervision branch, UniCD introduces the spatial-temporal awareness module (STAM), achieving efficient synergistic fusion of bi-temporal features. In the weakly-supervised branch, we construct change representation regularization (CRR), which steers model convergence from coarse-grained activations toward coherent and separable change modeling. In the unsupervised branch, we propose semantic prior-driven change inference (SPCI), which transforms unsupervised tasks into controlled weakly-supervised path optimization. Experiments on mainstream datasets demonstrate that UniCD achieves optimal performance across three tasks. It exhibits significant accuracy improvements in weakly and unsupervised scenarios, surpassing current state-of-the-art by 12.72% and 12.37% on LEVIR-CD, respectively.

</details>


### [82] [MV-S2V: Multi-View Subject-Consistent Video Generation](https://arxiv.org/abs/2601.17756)
*Ziyang Song,Xinyu Gong,Bangya Liu,Zelin Zhao*

Main category: cs.CV

TL;DR: 提出MV-S2V任务，从多视角参考图像生成视频，实现3D级别的主体一致性，通过合成数据管道和TS-RoPE技术解决数据稀缺和参考混淆问题。


<details>
  <summary>Details</summary>
Motivation: 现有S2V方法仅限于单视角参考，将任务简化为S2I+I2V流程，未能充分利用视频主体控制的潜力。需要解决多视角参考下的3D主体一致性问题。

Method: 1) 提出MV-S2V任务，从多视角参考图像生成视频；2) 开发合成数据管道生成定制化数据，辅以小规模真实数据集；3) 引入TS-RoPE技术区分不同主体和同一主体的不同视角。

Result: 框架实现了相对于多视角参考图像的优越3D主体一致性和高质量视觉输出，为基于主体的视频生成开辟了新方向。

Conclusion: MV-S2V任务解决了现有S2V方法的局限性，通过多视角参考实现了3D级别的主体一致性，为视频生成提供了更丰富的控制维度。

Abstract: Existing Subject-to-Video Generation (S2V) methods have achieved high-fidelity and subject-consistent video generation, yet remain constrained to single-view subject references. This limitation renders the S2V task reducible to an S2I + I2V pipeline, failing to exploit the full potential of video subject control. In this work, we propose and address the challenging Multi-View S2V (MV-S2V) task, which synthesizes videos from multiple reference views to enforce 3D-level subject consistency. Regarding the scarcity of training data, we first develop a synthetic data curation pipeline to generate highly customized synthetic data, complemented by a small-scale real-world captured dataset to boost the training of MV-S2V. Another key issue lies in the potential confusion between cross-subject and cross-view references in conditional generation. To overcome this, we further introduce Temporally Shifted RoPE (TS-RoPE) to distinguish between different subjects and distinct views of the same subject in reference conditioning. Our framework achieves superior 3D subject consistency w.r.t. multi-view reference images and high-quality visual outputs, establishing a new meaningful direction for subject-driven video generation. Our project page is available at <a href="https://szy-young.github.io/mv-s2v">this URL</a>

</details>


### [83] [Agreement-Driven Multi-View 3D Reconstruction for Live Cattle Weight Estimation](https://arxiv.org/abs/2601.17791)
*Rabin Dulal,Wenfeng Jia,Lihong Zheng,Jane Quinn*

Main category: cs.CV

TL;DR: 提出基于多视角RGB图像和SAM 3D重建的牛只体重非接触式估算方法，在低数据条件下使用集成回归模型获得良好效果


<details>
  <summary>Details</summary>
Motivation: 传统牛只体重测量方法（如走过式称重系统或体况评分）需要人工操作，影响生产效率和经济效益，需要开发低成本、非接触的自动化解决方案

Method: 使用多视角RGB图像，通过SAM 3D重建和一致性引导融合生成单个3D点云，在低数据条件下比较经典集成模型和深度学习模型进行体重回归

Result: SAM 3D多视角一致性融合优于其他3D生成方法，经典集成模型在农场实际场景中表现最稳定（R²=0.69±0.10，MAPE=2.22±0.56%）

Conclusion: 在农场大规模3D数据采集困难的条件下，提高重建质量比增加模型复杂度更重要，该方法适合农场实际部署

Abstract: Accurate cattle live weight estimation is vital for livestock management, welfare, and productivity. Traditional methods, such as manual weighing using a walk-over weighing system or proximate measurements using body condition scoring, involve manual handling of stock and can impact productivity from both a stock and economic perspective. To address these issues, this study investigated a cost-effective, non-contact method for live weight calculation in cattle using 3D reconstruction. The proposed pipeline utilized multi-view RGB images with SAM 3D-based agreement-guided fusion, followed by ensemble regression. Our approach generates a single 3D point cloud per animal and compares classical ensemble models with deep learning models under low-data conditions. Results show that SAM 3D with multi-view agreement fusion outperforms other 3D generation methods, while classical ensemble models provide the most consistent performance for practical farm scenarios (R$^2$ = 0.69 $\pm$ 0.10, MAPE = 2.22 $\pm$ 0.56 \%), making this practical for on-farm implementation. These findings demonstrate that improving reconstruction quality is more critical than increasing model complexity for scalable deployment on farms where producing a large volume of 3D data is challenging.

</details>


### [84] [ViTCoP: Accelerating Large Vision-Language Models via Visual and Textual Semantic Collaborative Pruning](https://arxiv.org/abs/2601.17818)
*Wen Luo,Peng Chen,Xiaotao Huang,LiQun Huang*

Main category: cs.CV

TL;DR: ViTCoP：视觉与文本语义协同剪枝框架，通过视觉编码器冗余过滤和LLM分层逐步协同剪枝，高效保留关键视觉token，显著降低LVLM计算成本


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型存在视觉token冗余问题，现有剪枝方法要么在视觉编码器中过早丢失关键信息，要么在LLM中导致所选token信息冗余，需要更有效的剪枝方案

Method: 提出ViTCoP框架：1）视觉编码器中进行冗余过滤；2）基于LLM分层特性进行逐步协同剪枝；3）引入K向量L2范数作为token显著性度量，兼容FlashAttention等加速技术

Result: 在多种LVLM上实验表明，ViTCoP在图像和视频理解任务上超越现有方法，显著降低推理延迟和GPU内存消耗，在极端剪枝率下优势更明显

Conclusion: ViTCoP通过视觉与文本语义协同剪枝，有效解决了LVLM视觉token冗余问题，实现了性能与效率的平衡，为高效视觉语言模型提供了新思路

Abstract: Large Vision-Language Models (LVLMs) incur high computational costs due to significant redundancy in their visual tokens. To effectively reduce this cost, researchers have proposed various visual token pruning methods. However, existing methods are generally limited, either losing critical visual information prematurely due to pruning in the vision encoder, or leading to information redundancy among the selected tokens due to pruning in the Large Language Models (LLMs). To address these challenges, we propose a Visual and Textual Semantic Collaborative Pruning framework (ViTCoP) that combines redundancy filtering in the vision encoder with step-wise co-pruning within the LLM based on its hierarchical characteristics, to efficiently preserve critical and informationally diverse visual tokens. Meanwhile, to ensure compatibility with acceleration techniques like FlashAttention, we introduce the L2 norm of K-vectors as the token saliency metric in the LLM. Extensive experiments on various Large Vision-Language Models demonstrate that ViTCoP not only achieves state-of-the-art performance surpassing existing methods on both image and video understanding tasks, but also significantly reduces model inference latency and GPU memory consumption. Notably, its performance advantage over other methods becomes even more pronounced under extreme pruning rates.

</details>


### [85] [VAE-REPA: Variational Autoencoder Representation Alignment for Efficient Diffusion Training](https://arxiv.org/abs/2601.17830)
*Mengmeng Wang,Dengyang Jiang,Liuzhuozheng Li,Yucheng Lin,Guojiang Shen,Xiangjie Kong,Yong Liu,Guang Dai,Jingdong Wang*

Main category: cs.CV

TL;DR: 提出了一种轻量级的内在引导框架，利用预训练VAE特征加速扩散变换器训练，无需外部依赖，仅增加4%计算开销


<details>
  <summary>Details</summary>
Motivation: 现有的扩散变换器训练加速方法（如REPA依赖外部编码器，SRA需要双模型设置）都会带来大量计算开销。需要一种轻量级的内在引导方法来提高训练效率。

Method: 利用现成的预训练VAE特征，通过轻量级投影层将扩散变换器的中间潜在特征与VAE特征对齐，使用特征对齐损失进行监督。VAE的重建特性确保了视觉先验的编码。

Result: 实验表明，该方法相比原始扩散变换器提高了生成质量和训练收敛速度，匹配或优于现有加速方法，仅增加4% GFLOPs计算开销，且无需外部引导模型成本。

Conclusion: 提出了一种简单有效的轻量级内在引导框架，利用预训练VAE特征加速扩散变换器训练，在保持高质量生成的同时显著提高训练效率。

Abstract: Denoising-based diffusion transformers, despite their strong generation performance, suffer from inefficient training convergence. Existing methods addressing this issue, such as REPA (relying on external representation encoders) or SRA (requiring dual-model setups), inevitably incur heavy computational overhead during training due to external dependencies. To tackle these challenges, this paper proposes \textbf{\namex}, a lightweight intrinsic guidance framework for efficient diffusion training. \name leverages off-the-shelf pre-trained Variational Autoencoder (VAE) features: their reconstruction property ensures inherent encoding of visual priors like rich texture details, structural patterns, and basic semantic information. Specifically, \name aligns the intermediate latent features of diffusion transformers with VAE features via a lightweight projection layer, supervised by a feature alignment loss. This design accelerates training without extra representation encoders or dual-model maintenance, resulting in a simple yet effective pipeline. Extensive experiments demonstrate that \name improves both generation quality and training convergence speed compared to vanilla diffusion transformers, matches or outperforms state-of-the-art acceleration methods, and incurs merely 4\% extra GFLOPs with zero additional cost for external guidance models.

</details>


### [86] [Geometry-Grounded Gaussian Splatting](https://arxiv.org/abs/2601.17835)
*Baowen Zhang,Chenxing Jiang,Heng Li,Shaojie Shen,Ping Tan*

Main category: cs.CV

TL;DR: 提出Geometry-Grounded Gaussian Splatting方法，将高斯原语视为随机实体，实现高质量形状重建


<details>
  <summary>Details</summary>
Motivation: 高斯溅射在新视角合成中表现出色，但现有方法难以从高斯原语中提取形状，存在多视角一致性差和对浮点敏感的问题

Method: 建立理论框架将高斯原语视为特定类型的随机实体，利用随机实体的体积特性高效渲染高质量深度图进行细粒度几何提取

Result: 在公开数据集上，该方法在所有基于高斯溅射的方法中取得了最佳的形状重建结果

Conclusion: 通过将高斯原语视为随机实体的理论框架，为Geometry-Grounded Gaussian Splatting提供了原则性基础，实现了高质量的形状重建

Abstract: Gaussian Splatting (GS) has demonstrated impressive quality and efficiency in novel view synthesis. However, shape extraction from Gaussian primitives remains an open problem. Due to inadequate geometry parameterization and approximation, existing shape reconstruction methods suffer from poor multi-view consistency and are sensitive to floaters. In this paper, we present a rigorous theoretical derivation that establishes Gaussian primitives as a specific type of stochastic solids. This theoretical framework provides a principled foundation for Geometry-Grounded Gaussian Splatting by enabling the direct treatment of Gaussian primitives as explicit geometric representations. Using the volumetric nature of stochastic solids, our method efficiently renders high-quality depth maps for fine-grained geometry extraction. Experiments show that our method achieves the best shape reconstruction results among all Gaussian Splatting-based methods on public datasets.

</details>


### [87] [SynMind: Reducing Semantic Hallucination in fMRI-Based Image Reconstruction](https://arxiv.org/abs/2601.17857)
*Lan Yang,Minghan Yang,Ke Li,Honggang Zhang,Kaiyue Pang,Yi-Zhe Song*

Main category: cs.CV

TL;DR: 该论文提出SynMind框架，通过将fMRI信号解析为句子级语义描述，结合视觉先验来改进fMRI图像重建，解决了现有方法语义对齐不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有fMRI图像重建方法虽然能生成逼真图像，但存在严重的语义错位问题——重要对象经常被替换或幻觉生成。这是因为现有方法过度依赖纠缠的视觉嵌入，优先考虑纹理和整体氛围等低层外观线索，而忽视了明确的语义身份。

Method: 提出SynMind框架：1) 将fMRI信号解析为丰富的句子级语义描述，反映人类视觉理解的分层和组合特性；2) 利用基础视觉语言模型生成类似人类的多粒度文本表示，捕捉对象身份和空间组织；3) 将这些明确的语义编码与视觉先验结合，作为预训练扩散模型的条件输入。

Result: SynMind在大多数定量指标上优于现有最先进方法。值得注意的是，通过将语义推理卸载到文本对齐模块，SynMind使用更小的Stable Diffusion 1.4和单个消费级GPU，就超越了基于SDXL的竞争方法。大规模人类评估证实SynMind生成的重建结果更符合人类视觉感知。神经可视化分析显示SynMind激活了更广泛且语义相关的大脑区域，减少了对高级视觉区域的过度依赖。

Conclusion: 通过重新思考fMRI解码中明确语义解释的作用，SynMind框架成功解决了现有方法语义对齐不足的问题。将fMRI信号解析为丰富的语义描述，并结合视觉先验，能够生成更符合人类视觉感知的图像重建结果，同时揭示了更广泛的语义相关大脑区域参与。

Abstract: Recent advances in fMRI-based image reconstruction have achieved remarkable photo-realistic fidelity. Yet, a persistent limitation remains: while reconstructed images often appear naturalistic and holistically similar to the target stimuli, they frequently suffer from severe semantic misalignment -- salient objects are often replaced or hallucinated despite high visual quality. In this work, we address this limitation by rethinking the role of explicit semantic interpretation in fMRI decoding. We argue that existing methods rely too heavily on entangled visual embeddings which prioritize low-level appearance cues -- such as texture and global gist -- over explicit semantic identity. To overcome this, we parse fMRI signals into rich, sentence-level semantic descriptions that mirror the hierarchical and compositional nature of human visual understanding. We achieve this by leveraging grounded VLMs to generate synthetic, human-like, multi-granularity textual representations that capture object identities and spatial organization. Built upon this foundation, we propose SynMind, a framework that integrates these explicit semantic encodings with visual priors to condition a pretrained diffusion model. Extensive experiments demonstrate that SynMind outperforms state-of-the-art methods across most quantitative metrics. Notably, by offloading semantic reasoning to our text-alignment module, SynMind surpasses competing methods based on SDXL while using the much smaller Stable Diffusion 1.4 and a single consumer GPU. Large-scale human evaluations further confirm that SynMind produces reconstructions more consistent with human visual perception. Neurovisualization analyses reveal that SynMind engages broader and more semantically relevant brain regions, mitigating the over-reliance on high-level visual areas.

</details>


### [88] [Domain Generalization with Quantum Enhancement for Medical Image Classification: A Lightweight Approach for Cross-Center Deployment](https://arxiv.org/abs/2601.17862)
*Jingsong Xia,Siqi Wang*

Main category: cs.CV

TL;DR: 提出轻量级量子增强域泛化框架，通过域对抗训练和量子特征增强层，提升医学影像AI在跨中心部署中的泛化能力，无需真实多中心标注数据。


<details>
  <summary>Details</summary>
Motivation: 医学影像AI模型在单中心/单设备上表现良好，但在真实世界跨中心部署时因域偏移导致性能下降，限制了临床泛化能力。需要解决域偏移问题，提高模型在未见目标域上的鲁棒性。

Method: 基于MobileNetV2的域不变编码器，包含三个关键组件：1) 多域成像偏移模拟（亮度、对比度、锐化、噪声扰动）；2) 梯度反转的域对抗训练；3) 轻量级量子特征增强层（参数化量子电路进行非线性特征映射和纠缠建模）。推理时采用测试时适应策略。

Result: 在模拟多中心医学影像数据集上，该方法显著优于无域泛化或无量子增强的基线模型，在未见域上实现了更低的域特定性能方差，提高了AUC和灵敏度。

Conclusion: 该方法展示了在有限计算资源下量子增强域泛化的临床潜力，为混合量子-经典医学影像系统提供了可行范式，能有效提升模型在真实世界跨中心部署中的泛化能力。

Abstract: Medical image artificial intelligence models often achieve strong performance in single-center or single-device settings, yet their effectiveness frequently deteriorates in real-world cross-center deployment due to domain shift, limiting clinical generalizability. To address this challenge, we propose a lightweight domain generalization framework with quantum-enhanced collaborative learning, enabling robust generalization to unseen target domains without relying on real multi-center labeled data. Specifically, a MobileNetV2-based domain-invariant encoder is constructed and optimized through three key components: (1) multi-domain imaging shift simulation using brightness, contrast, sharpening, and noise perturbations to emulate heterogeneous acquisition conditions; (2) domain-adversarial training with gradient reversal to suppress domain-discriminative features; and (3) a lightweight quantum feature enhancement layer that applies parameterized quantum circuits for nonlinear feature mapping and entanglement modeling. In addition, a test-time adaptation strategy is employed during inference to further alleviate distribution shifts. Experiments on simulated multi-center medical imaging datasets demonstrate that the proposed method significantly outperforms baseline models without domain generalization or quantum enhancement on unseen domains, achieving reduced domain-specific performance variance and improved AUC and sensitivity. These results highlight the clinical potential of quantum-enhanced domain generalization under constrained computational resources and provide a feasible paradigm for hybrid quantum--classical medical imaging systems.

</details>


### [89] [MV-SAM: Multi-view Promptable Segmentation using Pointmap Guidance](https://arxiv.org/abs/2601.17866)
*Yoonwoo Jeong,Cheng Sun,Yu-Chiang Frank Wang,Minsu Cho,Jaesung Choe*

Main category: cs.CV

TL;DR: MV-SAM：基于点图的多视图分割框架，通过将2D图像和提示提升到3D空间实现3D一致性，无需显式3D网络或标注3D数据


<details>
  <summary>Details</summary>
Motivation: 现有的可提示分割模型（如SAM）在扩展到视频和多视图图像时缺乏3D感知能力，导致结果不一致，需要昂贵的逐场景优化来保证3D一致性

Method: 利用视觉几何模型从未配准图像重建的3D点图（pointmaps），通过像素-点的一一对应关系，将SAM的图像嵌入和提示提升到3D空间，使用transformer解码器通过交叉注意力处理3D提示嵌入，利用3D位置嵌入隐式学习跨视图一致掩码

Result: 在SA-1B数据集上训练，在NVOS、SPIn-NeRF、ScanNet++、uCo3D和DL3DV等多个基准测试中表现优异，超越SAM2-Video，达到与逐场景优化基线相当的性能

Conclusion: MV-SAM通过点图实现2D交互与3D几何的对齐，为多视图分割提供了3D一致性的有效解决方案，无需显式3D网络或标注3D数据，具有良好的泛化能力

Abstract: Promptable segmentation has emerged as a powerful paradigm in computer vision, enabling users to guide models in parsing complex scenes with prompts such as clicks, boxes, or textual cues. Recent advances, exemplified by the Segment Anything Model (SAM), have extended this paradigm to videos and multi-view images. However, the lack of 3D awareness often leads to inconsistent results, necessitating costly per-scene optimization to enforce 3D consistency. In this work, we introduce MV-SAM, a framework for multi-view segmentation that achieves 3D consistency using pointmaps -- 3D points reconstructed from unposed images by recent visual geometry models. Leveraging the pixel-point one-to-one correspondence of pointmaps, MV-SAM lifts images and prompts into 3D space, eliminating the need for explicit 3D networks or annotated 3D data. Specifically, MV-SAM extends SAM by lifting image embeddings from its pretrained encoder into 3D point embeddings, which are decoded by a transformer using cross-attention with 3D prompt embeddings. This design aligns 2D interactions with 3D geometry, enabling the model to implicitly learn consistent masks across views through 3D positional embeddings. Trained on the SA-1B dataset, our method generalizes well across domains, outperforming SAM2-Video and achieving comparable performance with per-scene optimization baselines on NVOS, SPIn-NeRF, ScanNet++, uCo3D, and DL3DV benchmarks. Code will be released.

</details>


### [90] [VidLaDA: Bidirectional Diffusion Large Language Models for Efficient Video Understanding](https://arxiv.org/abs/2601.17868)
*Zhihao He,Tieyuan Chen,Kangyu Wang,Ziran Qin,Yang Shao,Chaofan Gan,Shijie Li,Zuxuan Wu,Weiyao Lin*

Main category: cs.CV

TL;DR: VidLaDA是一种基于扩散语言模型的视频LLM，使用双向注意力捕获双向依赖关系，解决了自回归视频LLM中的因果掩码偏差问题，并通过MARS-Cache框架加速推理


<details>
  <summary>Details</summary>
Motivation: 标准自回归视频LLM不可避免地受到因果掩码偏差的影响，阻碍了全局时空建模，导致理解效率低下

Method: 提出VidLaDA视频LLM，基于扩散语言模型利用双向注意力捕获双向依赖关系；引入MARS-Cache框架，通过异步视觉缓存刷新和帧级分块注意力加速推理，同时通过锚点令牌保持全局连接性

Result: VidLaDA在实验中优于扩散基线模型，可与最先进的自回归模型（如Qwen2.5-VL和LLaVA-Video）相媲美，MARS-Cache在不影响推理准确性的情况下实现了超过12倍的加速

Conclusion: VidLaDA通过扩散语言模型和双向注意力解决了自回归视频LLM的因果掩码偏差问题，MARS-Cache框架有效解决了扩散解码在大规模视频令牌上的推理瓶颈，实现了高效准确的视频理解

Abstract: Standard Autoregressive Video LLMs inevitably suffer from causal masking biases that hinder global spatiotemporal modeling, leading to suboptimal understanding efficiency. We propose VidLaDA, a Video LLM based on Diffusion Language Model utilizing bidirectional attention to capture bidirectional dependencies. To further tackle the inference bottleneck of diffusion decoding on massive video tokens, we introduce MARS-Cache. This framework accelerates inference by combining asynchronous visual cache refreshing with frame-wise chunk attention, effectively pruning redundancy while preserving global connectivity via anchor tokens. Extensive experiments show VidLaDA outperforms diffusion baselines and rivals state-of-the-art autoregressive models (e.g., Qwen2.5-VL and LLaVA-Video), with MARS-Cache delivering over 12x speedup without compromising reasoning accuracy. Code and checkpoints are open-sourced at https://github.com/ziHoHe/VidLaDA.

</details>


### [91] [Quran-MD: A Fine-Grained Multilingual Multimodal Dataset of the Quran](https://arxiv.org/abs/2601.17880)
*Muhammad Umar Salman,Mohammad Areeb Qazi,Mohammed Talha Alam*

Main category: cs.CV

TL;DR: Quran MD是一个全面的古兰经多模态数据集，集成了文本、语言和音频维度，包含经文和单词级别的数据，支持NLP、语音识别、语音合成等多种应用。


<details>
  <summary>Details</summary>
Motivation: 创建这个数据集的动机是为了整合古兰经的文本、语言和音频维度，捕捉丰富的古兰经诵读传统，支持计算语言学研究和数字伊斯兰研究。

Method: 数据集在经文级别提供阿拉伯原文、英文翻译和音标转写，以及来自32位不同诵读者的音频；在单词级别提供对齐的阿拉伯文字、英文翻译、音标转写和音频录音。

Result: 创建了一个全面的古兰经多模态数据集，支持多种应用，包括自然语言处理、语音识别、文本到语音合成、语言分析和数字伊斯兰研究。

Conclusion: 该数据集为古兰经诵读和研究的计算方法提供了独特资源，为多模态嵌入、语义检索、风格转换和个性化辅导系统奠定了基础，支持研究和社区应用。

Abstract: We present Quran MD, a comprehensive multimodal dataset of the Quran that integrates textual, linguistic, and audio dimensions at the verse and word levels. For each verse (ayah), the dataset provides its original Arabic text, English translation, and phonetic transliteration. To capture the rich oral tradition of Quranic recitation, we include verse-level audio from 32 distinct reciters, reflecting diverse recitation styles and dialectical nuances. At the word level, each token is paired with its corresponding Arabic script, English translation, transliteration, and an aligned audio recording, allowing fine-grained analysis of pronunciation, phonology, and semantic context. This dataset supports various applications, including natural language processing, speech recognition, text-to-speech synthesis, linguistic analysis, and digital Islamic studies. Bridging text and audio modalities across multiple reciters, this dataset provides a unique resource to advance computational approaches to Quranic recitation and study. Beyond enabling tasks such as ASR, tajweed detection, and Quranic TTS, it lays the foundation for multimodal embeddings, semantic retrieval, style transfer, and personalized tutoring systems that can support both research and community applications. The dataset is available at https://huggingface.co/datasets/Buraaq/quran-audio-text-dataset

</details>


### [92] [PEAfowl: Perception-Enhanced Multi-View Vision-Language-Action for Bimanual Manipulation](https://arxiv.org/abs/2601.17885)
*Qingyu Fan,Zhaoxiang Li,Yi Lu,Wang Chen,Qiu Shen,Xiao-xiao Long,Yinghao Cai,Tao Lu,Shuo Wang,Xun Cao*

Main category: cs.CV

TL;DR: PEAfowl是一个用于双手操作的感知增强多视角视觉语言动作模型，通过几何感知的3D表示和迭代式文本感知机制，显著提升了在杂乱场景中的操作性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言动作模型在双手操作中泛化能力不足，主要因为：(1) 多视角特征通过视角无关的token拼接融合，导致3D空间理解弱；(2) 语言作为全局条件注入，导致指令定位粗糙。

Method: PEAfowl提出：1) 空间推理：预测每个token的深度分布，进行可微3D提升，聚合局部跨视角邻居形成几何基础表示；2) 指令定位：用Perceiver风格的文本感知读取机制替代全局条件；3) 深度蒸馏：使用预训练深度教师进行训练时深度蒸馏，提供几何先验。

Result: 在RoboTwin 2.0的域随机化设置中，PEAfowl比最强基线提升了23.0个百分点的成功率。真实机器人实验证明了可靠的仿真到真实迁移，以及深度蒸馏带来的持续改进。

Conclusion: PEAfowl通过几何感知的跨视角表示和迭代式文本感知机制，显著提升了双手操作在杂乱场景中的性能，实现了有效的仿真到真实迁移。

Abstract: Bimanual manipulation in cluttered scenes requires policies that remain stable under occlusions, viewpoint and scene variations. Existing vision-language-action models often fail to generalize because (i) multi-view features are fused via view-agnostic token concatenation, yielding weak 3D-consistent spatial understanding, and (ii) language is injected as global conditioning, resulting in coarse instruction grounding.
  In this paper, we introduce PEAfowl, a perception-enhanced multi-view VLA policy for bimanual manipulation. For spatial reasoning, PEAfowl predicts per-token depth distributions, performs differentiable 3D lifting, and aggregates local cross-view neighbors to form geometrically grounded, cross-view consistent representations. For instruction grounding, we propose to replace global conditioning with a Perceiver-style text-aware readout over frozen CLIP visual features, enabling iterative evidence accumulation. To overcome noisy and incomplete commodity depth without adding inference overhead, we apply training-only depth distillation from a pretrained depth teacher to supervise the depth-distribution head, providing perception front-end with geometry-aware priors.
  On RoboTwin 2.0 under domain-randomized setting, PEAfowl improves the strongest baseline by 23.0 pp in success rate, and real-robot experiments further demonstrate reliable sim-to-real transfer and consistent improvements from depth distillation.
  Project website: https://peafowlvla.github.io/.

</details>


### [93] [Masked Depth Modeling for Spatial Perception](https://arxiv.org/abs/2601.17895)
*Bin Tan,Changjiang Sun,Xiage Qin,Hanat Adai,Zelin Fu,Tianxiang Zhou,Han Zhang,Yinghao Xu,Xing Zhu,Yujun Shen,Nan Xue*

Main category: cs.CV

TL;DR: LingBot-Depth是一个深度补全模型，通过掩码深度建模利用视觉上下文优化深度图，并采用自动化数据筛选流程进行可扩展训练，在深度精度和像素覆盖率方面优于顶级RGB-D相机。


<details>
  <summary>Details</summary>
Motivation: 空间视觉感知在自动驾驶和机器人操作等物理世界应用中至关重要。RGB-D相机虽然能捕获像素对齐的度量深度，但常受硬件限制和具有挑战性的成像条件（如镜面或纹理缺失表面）的影响。作者认为深度传感器的误差可视为反映底层几何模糊性的"掩码"信号。

Method: 提出LingBot-Depth深度补全模型，通过掩码深度建模利用视觉上下文优化深度图，并设计自动化数据筛选流程进行可扩展训练。模型在RGB和深度模态之间提供对齐的潜在表示。

Result: 模型在深度精度和像素覆盖率方面优于顶级RGB-D相机。在一系列下游任务上的实验结果表明，LingBot-Depth在RGB和深度模态之间提供了对齐的潜在表示。作者向空间感知社区发布了代码、检查点和300万RGB-深度对（包括200万真实数据和100万模拟数据）。

Conclusion: LingBot-Depth通过掩码深度建模和自动化数据筛选，有效解决了深度传感器在复杂成像条件下的局限性，为空间视觉感知任务提供了高质量的深度补全解决方案，并在RGB和深度模态对齐方面表现出色。

Abstract: Spatial visual perception is a fundamental requirement in physical-world applications like autonomous driving and robotic manipulation, driven by the need to interact with 3D environments. Capturing pixel-aligned metric depth using RGB-D cameras would be the most viable way, yet it usually faces obstacles posed by hardware limitations and challenging imaging conditions, especially in the presence of specular or texture-less surfaces. In this work, we argue that the inaccuracies from depth sensors can be viewed as "masked" signals that inherently reflect underlying geometric ambiguities. Building on this motivation, we present LingBot-Depth, a depth completion model which leverages visual context to refine depth maps through masked depth modeling and incorporates an automated data curation pipeline for scalable training. It is encouraging to see that our model outperforms top-tier RGB-D cameras in terms of both depth precision and pixel coverage. Experimental results on a range of downstream tasks further suggest that LingBot-Depth offers an aligned latent representation across RGB and depth modalities. We release the code, checkpoint, and 3M RGB-depth pairs (including 2M real data and 1M simulated data) to the community of spatial perception.

</details>


### [94] [Revisiting 3D Reconstruction Kernels as Low-Pass Filters](https://arxiv.org/abs/2601.17900)
*Shengjun Zhang,Min Chen,Yibo Wei,Mingyu Dong,Yueqi Duan*

Main category: cs.CV

TL;DR: 论文提出使用Jinc核函数作为理想的低通滤波器来解决3D重建中的频谱混叠问题，并通过调制核函数平衡空间效率和频域保真度，提升渲染性能。


<details>
  <summary>Details</summary>
Motivation: 从信号处理角度重新审视3D重建，发现离散采样引起的周期性频谱扩展是根本挑战。现有高斯、指数函数、学生t分布等重建核作为低通滤波器存在不理想的低通特性，导致高频分量与低频分量在离散时间信号频谱中重叠。

Method: 引入Jinc核函数，其在截止频率处具有瞬时降为零的幅度特性，对应理想低通滤波器。针对Jinc核在空间域衰减速度慢的问题，进一步提出调制核函数，在空间效率和频域保真度之间取得有效平衡。

Result: 实验结果表明，提出的Jinc核和调制核函数在3D重建中具有有效性，实现了优越的渲染性能。

Conclusion: 通过信号处理视角重新审视3D重建问题，提出基于理想低通滤波器的Jinc核和调制核函数，有效解决了频谱混叠问题，在保持频域保真度的同时提升了空间效率。

Abstract: 3D reconstruction is to recover 3D signals from the sampled discrete 2D pixels, with the goal to converge continuous 3D spaces. In this paper, we revisit 3D reconstruction from the perspective of signal processing, identifying the periodic spectral extension induced by discrete sampling as the fundamental challenge. Previous 3D reconstruction kernels, such as Gaussians, Exponential functions, and Student's t distributions, serve as the low pass filters to isolate the baseband spectrum. However, their unideal low-pass property results in the overlap of high-frequency components with low-frequency components in the discrete-time signal's spectrum. To this end, we introduce Jinc kernel with an instantaneous drop to zero magnitude exactly at the cutoff frequency, which is corresponding to the ideal low pass filters. As Jinc kernel suffers from low decay speed in the spatial domain, we further propose modulated kernels to strick an effective balance, and achieves superior rendering performance by reconciling spatial efficiency and frequency-domain fidelity. Experimental results have demonstrated the effectiveness of our Jinc and modulated kernels.

</details>


### [95] [Feature-Space Generative Models for One-Shot Class-Incremental Learning](https://arxiv.org/abs/2601.17905)
*Jack Foster,Kirill Paramonov,Mete Ozay,Umberto Michieli*

Main category: cs.CV

TL;DR: Gen1S：一种基于生成模型的单样本类增量学习方法，通过将嵌入空间映射到残差空间并学习基类残差分布来提升新类识别能力


<details>
  <summary>Details</summary>
Motivation: 单样本类增量学习（FSCIL）面临极大挑战，特别是当模型只能获得每个新类的单个样本且不允许进一步训练时。现有方法难以在这种极端条件下实现对新类的有效泛化。

Method: 提出Gen1S方法：1）将原始嵌入空间映射到残差空间（减去类别原型）；2）使用VAE或扩散模型学习基类残差的多模态分布；3）利用该结构先验提升新类识别能力

Result: Gen1S在多个基准测试和骨干架构上一致优于现有最先进方法，显著提升了新类识别性能

Conclusion: 通过将嵌入空间转换为残差空间并利用生成模型学习基类结构先验，可以有效解决单样本类增量学习的挑战，为极端数据稀缺场景下的持续学习提供了新思路

Abstract: Few-shot class-incremental learning (FSCIL) is a paradigm where a model, initially trained on a dataset of base classes, must adapt to an expanding problem space by recognizing novel classes with limited data. We focus on the challenging FSCIL setup where a model receives only a single sample (1-shot) for each novel class and no further training or model alterations are allowed after the base training phase. This makes generalization to novel classes particularly difficult. We propose a novel approach predicated on the hypothesis that base and novel class embeddings have structural similarity. We map the original embedding space into a residual space by subtracting the class prototype (i.e., the average class embedding) of input samples. Then, we leverage generative modeling with VAE or diffusion models to learn the multi-modal distribution of residuals over the base classes, and we use this as a valuable structural prior to improve recognition of novel classes. Our approach, Gen1S, consistently improves novel class recognition over the state of the art across multiple benchmarks and backbone architectures.

</details>


### [96] [Benchmarking Direct Preference Optimization for Medical Large Vision-Language Models](https://arxiv.org/abs/2601.17918)
*Dain Kim,Jiwoo Lee,Jaehoon Yun,Yong Hoe Koo,Qingyu Chen,Hyunjae Kim,Jaewoo Kang*

Main category: cs.CV

TL;DR: 该研究首次全面评估了医疗领域中多种DPO变体，发现现有方法在医疗LVLM上效果不稳定，且无法解决视觉误解错误，提出了针对性的偏好构建策略并取得了3.6%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在医疗应用中有巨大潜力，但部署受到对齐不足和可靠性问题的限制。虽然DPO已成为优化模型响应的有效框架，但在高风险医疗环境中的效果尚未充分探索，缺乏指导未来方法发展的实证基础。

Method: 对医疗领域中的多种DPO变体进行首次全面评估，在LLaVA-Med和HuatuoGPT-Vision两个医疗LVLM上测试了九种不同的DPO公式。基于发现的问题，提出了针对视觉误解错误的偏好构建策略。

Result: 发现当前DPO方法在监督微调上的增益不一致，效果在不同任务和骨干网络上差异显著，且无法解决基本的视觉误解错误。提出的针对性策略在视觉问答任务上比现有最强DPO基线提升了3.6%。

Conclusion: 该研究揭示了医疗领域中DPO方法的局限性，提出了改进方向，并通过开源框架为未来研究提供了完整的训练数据、模型检查点和代码库。

Abstract: Large Vision-Language Models (LVLMs) hold significant promise for medical applications, yet their deployment is often constrained by insufficient alignment and reliability. While Direct Preference Optimization (DPO) has emerged as a potent framework for refining model responses, its efficacy in high-stakes medical contexts remains underexplored, lacking the rigorous empirical groundwork necessary to guide future methodological advances. To bridge this gap, we present the first comprehensive examination of diverse DPO variants within the medical domain, evaluating nine distinct formulations across two medical LVLMs: LLaVA-Med and HuatuoGPT-Vision. Our results reveal several critical limitations: current DPO approaches often yield inconsistent gains over supervised fine-tuning, with their efficacy varying significantly across different tasks and backbones. Furthermore, they frequently fail to resolve fundamental visual misinterpretation errors. Building on these insights, we present a targeted preference construction strategy as a proof-of-concept that explicitly addresses visual misinterpretation errors frequently observed in existing DPO models. This design yields a 3.6% improvement over the strongest existing DPO baseline on visual question-answering tasks. To support future research, we release our complete framework, including all training data, model checkpoints, and our codebase at https://github.com/dmis-lab/med-vlm-dpo.

</details>


### [97] [RemEdit: Efficient Diffusion Editing with Riemannian Geometry](https://arxiv.org/abs/2601.17927)
*Eashan Adhikarla,Brian D. Davison*

Main category: cs.CV

TL;DR: RemEdit是一个基于扩散模型的图像编辑框架，通过黎曼流形导航和任务特定注意力剪枝，在保持语义保真度的同时实现实时编辑性能。


<details>
  <summary>Details</summary>
Motivation: 当前可控图像生成面临语义保真度和推理速度之间的关键权衡，现有方法难以同时满足编辑质量和实时性能的要求。

Method: 1. 将潜在空间建模为黎曼流形，使用Mamba模块学习流形结构以计算精确的测地线路径；2. 采用双SLERP混合技术和视觉语言模型的目标感知提示增强；3. 引入任务特定的注意力剪枝机制，通过轻量级剪枝头保留编辑关键标记。

Result: RemEdit超越了现有最先进的编辑框架，在50%剪枝率下仍保持实时性能，建立了实用且强大的图像编辑新基准。

Conclusion: RemEdit通过创新的流形导航和任务特定剪枝技术，成功解决了图像编辑中语义保真度与推理速度的权衡问题，为实际应用提供了高效解决方案。

Abstract: Controllable image generation is fundamental to the success of modern generative AI, yet it faces a critical trade-off between semantic fidelity and inference speed. The RemEdit diffusion-based framework addresses this trade-off with two synergistic innovations. First, for editing fidelity, we navigate the latent space as a Riemannian manifold. A mamba-based module efficiently learns the manifold's structure, enabling direct and accurate geodesic path computation for smooth semantic edits. This control is further refined by a dual-SLERP blending technique and a goal-aware prompt enrichment pass from a Vision-Language Model. Second, for additional acceleration, we introduce a novel task-specific attention pruning mechanism. A lightweight pruning head learns to retain tokens essential to the edit, enabling effective optimization without the semantic degradation common in content-agnostic approaches. RemEdit surpasses prior state-of-the-art editing frameworks while maintaining real-time performance under 50% pruning. Consequently, RemEdit establishes a new benchmark for practical and powerful image editing. Source code: https://www.github.com/eashanadhikarla/RemEdit.

</details>


### [98] [From Specialist to Generalist: Unlocking SAM's Learning Potential on Unlabeled Medical Images](https://arxiv.org/abs/2601.17934)
*Vi Vu,Thanh-Huy Nguyen,Tien-Thinh Nguyen,Ba-Thinh Lam,Hoang-Thien Nguyen,Tianyang Wang,Xingjian Li,Min Xu*

Main category: cs.CV

TL;DR: SC-SAM提出了一种专家-通用框架，通过U-Net和SAM的双向协同训练，利用未标记数据提升医学图像分割性能


<details>
  <summary>Details</summary>
Motivation: 虽然基础模型如SAM具有强大的泛化能力，但将其适应到医学图像仍面临领域偏移、标签稀缺以及PEFT无法利用未标记数据的问题。传统模型如U-Net在半监督医学学习中表现出色，但其辅助PEFT SAM的潜力尚未被充分挖掘

Method: 提出SC-SAM专家-通用框架：U-Net作为专家提供基于点的提示和伪标签来指导SAM的适应，同时SAM作为强大的通用监督器来正则化U-Net。这种相互指导形成双向协同训练循环，使两个模型都能有效利用未标记数据

Result: 在前列腺MRI和息肉分割基准测试中，该方法取得了最先进的结果，优于其他现有的半监督SAM变体，甚至超过了MedSAM等医学基础模型

Conclusion: 研究突出了专家-通用合作在标签高效医学图像分割中的价值，证明了传统模型与基础模型协同工作的有效性

Abstract: Foundation models like the Segment Anything Model (SAM) show strong generalization, yet adapting them to medical images remains difficult due to domain shift, scarce labels, and the inability of Parameter-Efficient Fine-Tuning (PEFT) to exploit unlabeled data. While conventional models like U-Net excel in semi-supervised medical learning, their potential to assist a PEFT SAM has been largely overlooked. We introduce SC-SAM, a specialist-generalist framework where U-Net provides point-based prompts and pseudo-labels to guide SAM's adaptation, while SAM serves as a powerful generalist supervisor to regularize U-Net. This reciprocal guidance forms a bidirectional co-training loop that allows both models to effectively exploit the unlabeled data. Across prostate MRI and polyp segmentation benchmarks, our method achieves state-of-the-art results, outperforming other existing semi-supervised SAM variants and even medical foundation models like MedSAM, highlighting the value of specialist-generalist cooperation for label-efficient medical image segmentation. Our code is available at https://github.com/vnlvi2k3/SC-SAM.

</details>


### [99] [DTC: A Deformable Transposed Convolution Module for Medical Image Segmentation](https://arxiv.org/abs/2601.17939)
*Chengkun Sun,Jinqian Pan,Renjie Liang,Zhengkang Fan,Xin Miao,Jiang Bian,Jie Xu*

Main category: cs.CV

TL;DR: 提出了一种用于医学图像分割的新型上采样方法——可变形转置卷积(DTC)，通过学习动态坐标而非固定位置来生成高分辨率特征图，提升细节恢复能力。


<details>
  <summary>Details</summary>
Motivation: 传统上采样方法（如转置卷积和线性插值）使用固定位置进行采样，可能无法捕捉预定义采样位置之外的结构信息，导致伪影或细节丢失。受可变形卷积启发，希望开发一种能学习动态采样位置的上采样方法。

Method: 提出可变形转置卷积(DTC)，该方法学习动态坐标（采样位置）来生成高分辨率特征图，适用于2D和3D医学图像分割任务。DTC可以有效地集成到现有的医学图像分割模型中。

Result: 在3D数据集（如BTCV15）和2D数据集（如ISIC18、BUSI）上的实验表明，DTC能够持续改善解码器的特征重建和细节恢复能力。

Conclusion: DTC作为一种新型上采样方法，通过学习动态采样位置，相比传统固定位置的上采样方法，能够更好地恢复医学图像分割中的细节信息，提升模型性能。

Abstract: In medical image segmentation, particularly in UNet-like architectures, upsampling is primarily used to transform smaller feature maps into larger ones, enabling feature fusion between encoder and decoder features and supporting multi-scale prediction. Conventional upsampling methods, such as transposed convolution and linear interpolation, operate on fixed positions: transposed convolution applies kernel elements to predetermined pixel or voxel locations, while linear interpolation assigns values based on fixed coordinates in the original feature map. These fixed-position approaches may fail to capture structural information beyond predefined sampling positions and can lead to artifacts or loss of detail. Inspired by deformable convolutions, we propose a novel upsampling method, Deformable Transposed Convolution (DTC), which learns dynamic coordinates (i.e., sampling positions) to generate high-resolution feature maps for both 2D and 3D medical image segmentation tasks. Experiments on 3D (e.g., BTCV15) and 2D datasets (e.g., ISIC18, BUSI) demonstrate that DTC can be effectively integrated into existing medical image segmentation models, consistently improving the decoder's feature reconstruction and detail recovery capability.

</details>


### [100] [FlowMorph: Physics-Consistent Self-Supervision for Label-Free Single-Cell Mechanics in Microfluidic Videos](https://arxiv.org/abs/2601.17947)
*Bora Yimenicioglu,Vishal Manikanden*

Main category: cs.CV

TL;DR: FlowMorph是一个物理一致的自监督框架，通过分析红细胞在微流控视频中的形状演化，学习无标签的力学代理参数k，用于评估红细胞机械性能。


<details>
  <summary>Details</summary>
Motivation: 红细胞的机械性能是血液和系统性疾病的重要生物标志物，但现有微流控分析方法依赖监督分割或手工特征提取，且未充分结合层流斯托克斯流动物理原理。

Method: FlowMorph使用低维参数化轮廓建模每个细胞，通过可微分的"流动中胶囊"模型结合层流平流和曲率正则化弹性松弛来推进边界点，优化包含轮廓重叠、细胞内流动一致性、面积守恒、壁约束和时间平滑度的损失函数。

Result: 在四个公开RBC微流控数据集上，FlowMorph在物理丰富视频中达到平均轮廓IoU 0.905，显著改善面积守恒和壁约束违反问题。力学代理参数k能有效区分坦克履带式和翻转动力学（AUC 0.863），仅需200个RT-DC事件校准即可预测表观杨氏模量（MAE 0.118 MPa）。

Conclusion: FlowMorph提供了一个物理一致的自监督框架，能够从无标签的微流控视频中学习红细胞的力学代理参数，在通道几何、光学和帧率变化下表现出良好的鲁棒性，为红细胞机械性能评估提供了新方法。

Abstract: Mechanical properties of red blood cells (RBCs) are promising biomarkers for hematologic and systemic disease, motivating microfluidic assays that probe deformability at throughputs of $10^3$--$10^6$ cells per experiment. However, existing pipelines rely on supervised segmentation or hand-crafted kymographs and rarely encode the laminar Stokes-flow physics that governs RBC shape evolution. We introduce FlowMorph, a physics-consistent self-supervised framework that learns a label-free scalar mechanics proxy $k$ for each tracked RBC from short brightfield microfluidic videos. FlowMorph models each cell by a low-dimensional parametric contour, advances boundary points through a differentiable ''capsule-in-flow'' combining laminar advection and curvature-regularized elastic relaxation, and optimizes a loss coupling silhouette overlap, intra-cellular flow agreement, area conservation, wall constraints, and temporal smoothness, using only automatically derived silhouettes and optical flow.
  Across four public RBC microfluidic datasets, FlowMorph achieves a mean silhouette IoU of $0.905$ on physics-rich videos with provided velocity fields and markedly improves area conservation and wall violations over purely data-driven baselines. On $\sim 1.5\times 10^5$ centered sequences, the scalar $k$ alone separates tank-treading from flipping dynamics with an AUC of $0.863$. Using only $200$ real-time deformability cytometry (RT-DC) events for calibration, a monotone map $E=g(k)$ predicts apparent Young's modulus with a mean absolute error of $0.118$\,MPa on $600$ held-out cells and degrades gracefully under shifts in channel geometry, optics, and frame rate.

</details>


### [101] [UPLiFT: Efficient Pixel-Dense Feature Upsampling with Local Attenders](https://arxiv.org/abs/2601.17950)
*Matthew Walmer,Saksham Suri,Anirud Aggarwal,Abhinav Shrivastava*

Main category: cs.CV

TL;DR: UPLiFT是一种通用像素密集轻量级特征变换架构，通过局部注意力算子实现高效的特征上采样，在保持较低推理成本的同时达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于交叉注意力的特征上采样方法存在效率扩展问题，而早期迭代上采样方法性能有限。需要一种既能保持高效推理成本又能达到先进性能的特征上采样方法。

Method: 提出UPLiFT架构，采用迭代上采样方法，并引入高效的局部注意力算子（Local Attender），使用完全局部的注意力池化公式来克服先前迭代上采样方法的局限性。

Result: UPLiFT在保持稳定特征的同时实现了SOTA性能，推理成本低于现有像素密集特征上采样器，并在生成下游任务中与最先进的耦合流匹配模型竞争。

Conclusion: UPLiFT提供了一种通用且高效的方法来创建更密集的特征，证明迭代上采样方法仍能与基于交叉注意力的方法竞争，并在效率方面具有优势。

Abstract: The space of task-agnostic feature upsampling has emerged as a promising area of research to efficiently create denser features from pre-trained visual backbones. These methods act as a shortcut to achieve dense features for a fraction of the cost by learning to map low-resolution features to high-resolution versions. While early works in this space used iterative upsampling approaches, more recent works have switched to cross-attention-based methods, which risk falling into the same efficiency scaling problems of the backbones they are upsampling. In this work, we demonstrate that iterative upsampling methods can still compete with cross-attention-based methods; moreover, they can achieve state-of-the-art performance with lower inference costs. We propose UPLiFT, an architecture for Universal Pixel-dense Lightweight Feature Transforms. We also propose an efficient Local Attender operator to overcome the limitations of prior iterative feature upsampling methods. This operator uses an alternative attentional pooling formulation defined fully locally. We show that our Local Attender allows UPLiFT to maintain stable features throughout upsampling, enabling state-of-the-art performance with lower inference costs than existing pixel-dense feature upsamplers. In addition, we apply UPLiFT to generative downstream tasks and show that it achieves competitive performance with state-of-the-art Coupled Flow Matching models for VAE feature upsampling. Altogether, UPLiFT offers a versatile and efficient approach to creating denser features.

</details>


### [102] [Domain-Expert-Guided Hybrid Mixture-of-Experts for Medical AI: Integrating Data-Driven Learning with Clinical Priors](https://arxiv.org/abs/2601.17977)
*Jinchen Gu,Nan Zhao,Lei Qiu,Lu Zhang*

Main category: cs.CV

TL;DR: 提出DKGH-MoE框架，结合数据驱动和领域专家知识，通过混合专家模型提升医学影像分析的性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 医学领域数据有限，传统MoE模型难以有效学习；临床实践中丰富的专家知识（如医生注视模式、诊断启发式）无法从有限数据中可靠学习。需要结合数据驱动和领域专家知识来获得互补优势。

Method: 提出DKGH-MoE模块：包含数据驱动的MoE从原始影像数据提取新特征，以及领域专家引导的MoE整合临床先验（特别是临床医生眼动注视线索）来强调高诊断相关区域。

Result: 通过整合领域专家洞察和数据驱动特征，DKGH-MoE提升了性能和可解释性。

Conclusion: DKGH-MoE是一个即插即用且可解释的模块，统一了数据驱动学习和领域专业知识，为医学影像分析提供了更稳健和临床意义的学习方法。

Abstract: Mixture-of-Experts (MoE) models increase representational capacity with modest computational cost, but their effectiveness in specialized domains such as medicine is limited by small datasets. In contrast, clinical practice offers rich expert knowledge, such as physician gaze patterns and diagnostic heuristics, that models cannot reliably learn from limited data. Combining data-driven experts, which capture novel patterns, with domain-expert-guided experts, which encode accumulated clinical insights, provides complementary strengths for robust and clinically meaningful learning. To this end, we propose Domain-Knowledge-Guided Hybrid MoE (DKGH-MoE), a plug-and-play and interpretable module that unifies data-driven learning with domain expertise. DKGH-MoE integrates a data-driven MoE to extract novel features from raw imaging data, and a domain-expert-guided MoE incorporates clinical priors, specifically clinician eye-gaze cues, to emphasize regions of high diagnostic relevance. By integrating domain expert insights with data-driven features, DKGH-MoE improves both performance and interpretability.

</details>


### [103] [MorphXAI: An Explainable Framework for Morphological Analysis of Parasites in Blood Smear Images](https://arxiv.org/abs/2601.18001)
*Aqsa Yousaf,Sint Sint Win,Megan Coffee,Habeeb Olufowobi*

Main category: cs.CV

TL;DR: MorphXAI是一个可解释的寄生虫检测框架，将形态学监督集成到预测流程中，同时定位寄生虫并提供临床相关的形态特征解释。


<details>
  <summary>Details</summary>
Motivation: 当前寄生虫感染诊断依赖人工检查血涂片，深度学习模型虽然性能好但缺乏可解释性，现有解释方法仅限于视觉热图，无法提供临床医生依赖的形态特征信息。

Method: 提出MorphXAI框架，将形态学监督直接集成到预测流程中，使模型能够同时定位寄生虫并表征临床相关属性（形状、曲率、可见点计数、鞭毛存在、发育阶段等）。创建了包含三种寄生虫物种（利什曼原虫、布氏锥虫、克氏锥虫）的临床标注数据集。

Result: 实验结果表明MorphXAI不仅提高了检测性能，还提供了结构化、具有生物学意义的解释。

Conclusion: MorphXAI框架统一了寄生虫检测与细粒度形态分析，为可解释的寄生虫分析建立了新基准，提高了临床实用性。

Abstract: Parasitic infections remain a pressing global health challenge, particularly in low-resource settings where diagnosis still depends on labor-intensive manual inspection of blood smears and the availability of expert domain knowledge. While deep learning models have shown strong performance in automating parasite detection, their clinical usefulness is constrained by limited interpretability. Existing explainability methods are largely restricted to visual heatmaps or attention maps, which highlight regions of interest but fail to capture the morphological traits that clinicians rely on for diagnosis. In this work, we present MorphXAI, an explainable framework that unifies parasite detection with fine-grained morphological analysis. MorphXAI integrates morphological supervision directly into the prediction pipeline, enabling the model to localize parasites while simultaneously characterizing clinically relevant attributes such as shape, curvature, visible dot count, flagellum presence, and developmental stage. To support this task, we curate a clinician-annotated dataset of three parasite species (Leishmania, Trypanosoma brucei, and Trypanosoma cruzi) with detailed morphological labels, establishing a new benchmark for interpretable parasite analysis. Experimental results show that MorphXAI not only improves detection performance over the baseline but also provides structured, biologically meaningful explanations.

</details>


### [104] [Strip-Fusion: Spatiotemporal Fusion for Multispectral Pedestrian Detection](https://arxiv.org/abs/2601.18008)
*Asiegbu Miracle Kanu-Asiegbu,Nitin Jotwani,Xiaoxiao Du*

Main category: cs.CV

TL;DR: 提出Strip-Fusion，一个鲁棒于输入图像未对齐、光照变化和严重遮挡的时空融合网络，用于多光谱行人检测。


<details>
  <summary>Details</summary>
Motivation: 现有多光谱行人检测方法主要关注空间融合而忽略时序信息，且RGB和热成像图像对可能未完美对齐。行人检测面临光照变化、遮挡等挑战。

Method: 提出Strip-Fusion时空融合网络，集成时序自适应卷积动态加权时空特征；设计KL散度损失缓解可见光和热成像模态不平衡；开发新的后处理算法减少误报。

Result: 在KAIST和CVC-14基准测试中表现优异，在严重遮挡和未对齐等挑战性条件下相比先前SOTA有显著改进。

Conclusion: Strip-Fusion通过时空融合和模态平衡处理，在多光谱行人检测中有效应对未对齐、光照变化和遮挡等挑战。

Abstract: Pedestrian detection is a critical task in robot perception. Multispectral modalities (visible light and thermal) can boost pedestrian detection performance by providing complementary visual information. Several gaps remain with multispectral pedestrian detection methods. First, existing approaches primarily focus on spatial fusion and often neglect temporal information. Second, RGB and thermal image pairs in multispectral benchmarks may not always be perfectly aligned. Pedestrians are also challenging to detect due to varying lighting conditions, occlusion, etc. This work proposes Strip-Fusion, a spatial-temporal fusion network that is robust to misalignment in input images, as well as varying lighting conditions and heavy occlusions. The Strip-Fusion pipeline integrates temporally adaptive convolutions to dynamically weigh spatial-temporal features, enabling our model to better capture pedestrian motion and context over time. A novel Kullback-Leibler divergence loss was designed to mitigate modality imbalance between visible and thermal inputs, guiding feature alignment toward the more informative modality during training. Furthermore, a novel post-processing algorithm was developed to reduce false positives. Extensive experimental results show that our method performs competitively for both the KAIST and the CVC-14 benchmarks. We also observed significant improvements compared to previous state-of-the-art on challenging conditions such as heavy occlusion and misalignment.

</details>


### [105] [Leveraging Persistence Image to Enhance Robustness and Performance in Curvilinear Structure Segmentation](https://arxiv.org/abs/2601.18045)
*Zhuangzhi Gao,Feixiang Zhou,He Zhao,Xiuju Chen,Xiaoxin Li,Qinkai Yu,Yitian Zhao,Alena Shantsila,Gregory Y. H. Lip,Eduard Shantsila,Yalin Zheng*

Main category: cs.CV

TL;DR: 提出PIs-Regressor和Topology SegNet框架，通过持久性图像(PI)将拓扑特征直接融入网络架构，而非依赖手工损失函数，在医学图像曲线结构分割中实现最先进性能。


<details>
  <summary>Details</summary>
Motivation: 医学图像中曲线结构分割对临床分析至关重要。现有方法主要通过手工损失函数编码拓扑属性（如连通性），但这种方法泛化能力差，且持久性图(PD)的非可微性和计算成本高，难以有效提取和嵌入拓扑特征。

Method: 提出PIs-Regressor模块学习持久性图像(PI) - 拓扑特征的可微有限表示。结合Topology SegNet，在网络的降采样和上采样阶段融合这些拓扑特征，将拓扑信息直接整合到网络架构中，而非辅助损失函数。

Result: 在三个曲线结构基准测试中展示了最先进的性能，在像素级准确性和拓扑保真度方面均有提升。实验表明拓扑特征的集成增强了模型鲁棒性，能有效处理医学图像中的过曝光和模糊等挑战。

Conclusion: 通过将拓扑特征直接融入网络架构而非依赖手工损失函数，实现了更鲁棒的曲线结构分割。该方法灵活，可与其他基于拓扑的方法无缝结合以进一步提升分割性能。

Abstract: Segmenting curvilinear structures in medical images is essential for analyzing morphological patterns in clinical applications. Integrating topological properties, such as connectivity, improves segmentation accuracy and consistency. However, extracting and embedding such properties - especially from Persistence Diagrams (PD) - is challenging due to their non-differentiability and computational cost. Existing approaches mostly encode topology through handcrafted loss functions, which generalize poorly across tasks. In this paper, we propose PIs-Regressor, a simple yet effective module that learns persistence image (PI) - finite, differentiable representations of topological features - directly from data. Together with Topology SegNet, which fuses these features in both downsampling and upsampling stages, our framework integrates topology into the network architecture itself rather than auxiliary losses. Unlike existing methods that depend heavily on handcrafted loss functions, our approach directly incorporates topological information into the network structure, leading to more robust segmentation. Our design is flexible and can be seamlessly combined with other topology-based methods to further enhance segmentation performance. Experimental results show that integrating topological features enhances model robustness, effectively handling challenges like overexposure and blurring in medical imaging. Our approach on three curvilinear benchmarks demonstrate state-of-the-art performance in both pixel-level accuracy and topological fidelity.

</details>


### [106] [Semi-Supervised Hyperspectral Image Classification with Edge-Aware Superpixel Label Propagation and Adaptive Pseudo-Labeling](https://arxiv.org/abs/2601.18049)
*Yunfei Qiu,Qiqiong Ma,Tianhua Lv,Li Fang,Shudong Zhou,Wei Yao*

Main category: cs.CV

TL;DR: 提出一个结合空间先验与动态学习机制的新型半监督高光谱图像分类框架，通过边缘感知超像素标签传播和动态历史融合预测等方法，解决边界标签扩散和伪标签不稳定问题。


<details>
  <summary>Details</summary>
Motivation: 高光谱图像标注成本高、样本有限，现有半监督学习方法面临边界标签扩散和伪标签不稳定的挑战，需要更鲁棒的分类框架。

Method: 1) 边缘感知超像素标签传播(EASLP)模块：结合边缘强度惩罚和邻域校正策略，缓解超像素分割中的标签扩散；2) 动态历史融合预测(DHP)：维护历史预测并动态加权当前结果，平滑伪标签波动；3) 自适应三元样本分类(ATSC)：基于置信度和一致性度量，分层利用易、模糊、难样本；4) 动态可靠性增强伪标签框架(DREPL)：整合DHP和ATSC，实现时空一致性优化。

Result: 在四个基准数据集上的评估表明，该框架能够保持优越的分类性能，有效解决了边界标签扩散和伪标签不稳定问题。

Conclusion: 提出的集成空间先验与动态学习机制的新型半监督高光谱分类框架，通过时空一致性优化，显著提升了分类鲁棒性和伪标签质量，为有限标注样本下的高光谱图像分类提供了有效解决方案。

Abstract: Significant progress has been made in semi-supervised hyperspectral image (HSI) classification regarding feature extraction and classification performance. However, due to high annotation costs and limited sample availability, semi-supervised learning still faces challenges such as boundary label diffusion and pseudo-label instability. To address these issues, this paper proposes a novel semi-supervised hyperspectral classification framework integrating spatial prior information with a dynamic learning mechanism. First, we design an Edge-Aware Superpixel Label Propagation (EASLP) module. By integrating edge intensity penalty with neighborhood correction strategy, it mitigates label diffusion from superpixel segmentation while enhancing classification robustness in boundary regions. Second, we introduce a Dynamic History-Fused Prediction (DHP) method. By maintaining historical predictions and dynamically weighting them with current results, DHP smoothens pseudo-label fluctuations and improves temporal consistency and noise resistance. Concurrently, incorporating condifence and consistency measures, the Adaptive Tripartite Sample Categorization (ATSC) strategy implements hierarchical utilization of easy, ambiguous, and hard samples, leading to enhanced pseudo-label quality and learning efficiency. The Dynamic Reliability-Enhanced Pseudo-Label Framework (DREPL), composed of DHP and ATSC, strengthens pseudo-label stability across temporal and sample domains. Through synergizes operation with EASLP, it achieves spatio-temporal consistency optimization. Evaluations on four benchmark datasets demonstrate its capability to maintain superior classification performance.

</details>


### [107] [Cross-Domain Transfer with Self-Supervised Spectral-Spatial Modeling for Hyperspectral Image Classification](https://arxiv.org/abs/2601.18088)
*Jianshu Chao,Tianhua Lv,Qiqiong Ma,Yunfei Qiu,Li Fang,Huifang Shen,Wei Yao*

Main category: cs.CV

TL;DR: 本文提出了一种无源域标签的自监督跨域迁移框架，通过S2Former模块实现光谱-空间协同建模，结合频率域约束增强细节识别能力，并在微调阶段使用扩散对齐蒸馏机制实现低标签条件下的鲁棒迁移学习。


<details>
  <summary>Details</summary>
Motivation: 当前自监督学习在高光谱表示方面潜力巨大，但在跨域迁移场景中应用不足。现有方法仍依赖源域标注且易受分布偏移影响，导致目标域泛化性能下降。需要开发无需源域标签、能在目标域少量样本下高效适应的跨域迁移方法。

Method: 1. 自监督预训练阶段：设计Spatial-Spectral Transformer (S2Former)模块，采用双分支空间-光谱transformer和双向交叉注意力机制实现光谱-空间协同建模；空间分支通过随机掩码增强结构感知，光谱分支捕捉细粒度差异；提出频率域约束(FDC)通过实快速傅里叶变换和高频幅度损失保持频域一致性。
2. 微调阶段：提出扩散对齐微调(DAFT)蒸馏机制，通过师生结构对齐语义演化轨迹，实现低标签条件下的鲁棒迁移学习。

Result: 在四个高光谱数据集上的实验结果表明，该方法具有稳定的分类性能和强大的跨域适应能力，验证了在资源受限条件下的有效性。

Conclusion: 提出的自监督跨域迁移框架能够在无需源域标签的情况下学习可迁移的光谱-空间联合表示，并在目标域少量样本下实现高效适应，为高光谱跨域迁移学习提供了有效解决方案。

Abstract: Self-supervised learning has demonstrated considerable potential in hyperspectral representation, yet its application in cross-domain transfer scenarios remains under-explored. Existing methods, however, still rely on source domain annotations and are susceptible to distribution shifts, leading to degraded generalization performance in the target domain. To address this, this paper proposes a self-supervised cross-domain transfer framework that learns transferable spectral-spatial joint representations without source labels and achieves efficient adaptation under few samples in the target domain. During the self-supervised pre-training phase, a Spatial-Spectral Transformer (S2Former) module is designed. It adopts a dual-branch spatial-spectral transformer and introduces a bidirectional cross-attention mechanism to achieve spectral-spatial collaborative modeling: the spatial branch enhances structural awareness through random masking, while the spectral branch captures fine-grained differences. Both branches mutually guide each other to improve semantic consistency. We further propose a Frequency Domain Constraint (FDC) to maintain frequency-domain consistency through real Fast Fourier Transform (rFFT) and high-frequency magnitude loss, thereby enhancing the model's capability to discern fine details and boundaries. During the fine-tuning phase, we introduce a Diffusion-Aligned Fine-tuning (DAFT) distillation mechanism. This aligns semantic evolution trajectories through a teacher-student structure, enabling robust transfer learning under low-label conditions. Experimental results demonstrate stable classification performance and strong cross-domain adaptability across four hyperspectral datasets, validating the method's effectiveness under resource-constrained conditions.

</details>


### [108] [Text-Pass Filter: An Efficient Scene Text Detector](https://arxiv.org/abs/2601.18098)
*Chuang Yang,Haozhao Ma,Xu Han,Yuan Yuan,Qi Wang*

Main category: cs.CV

TL;DR: TPF是一种直接分割整个文本的任意形状文本检测方法，通过模拟带通滤波器为每个文本构建特征-滤波器对，避免了传统收缩-扩展策略的固有局限性。


<details>
  <summary>Details</summary>
Motivation: 现有文本检测方法采用收缩-掩码扩展策略，但收缩操作会丢失文本边缘的视觉特征，混淆前景与背景差异，对文本特征识别带来固有局限性。

Method: 设计Text-Pass Filter (TPF)直接分割整个文本，模拟带通滤波器为每个文本构建特征-滤波器对；引入Reinforcement Ensemble Unit (REU)增强同一文本的特征一致性并扩大滤波器识别范围；使用Foreground Prior Unit (FPU)改善前景背景区分能力。

Result: 实验证明了REU和FPU的有效性，并展示了TPF方法的优越性，能够自然分离粘连文本而无需复杂的解码或后处理过程，实现实时文本检测。

Conclusion: TPF通过模拟带通滤波器机制，避免了传统方法的固有局限性，能够高效、准确地检测任意形状文本，特别是对于粘连文本和带状文本具有良好效果。

Abstract: To pursue an efficient text assembling process, existing methods detect texts via the shrink-mask expansion strategy. However, the shrinking operation loses the visual features of text margins and confuses the foreground and background difference, which brings intrinsic limitations to recognize text features. We follow this issue and design Text-Pass Filter (TPF) for arbitrary-shaped text detection. It segments the whole text directly, which avoids the intrinsic limitations. It is noteworthy that different from previous whole text region-based methods, TPF can separate adhesive texts naturally without complex decoding or post-processing processes, which makes it possible for real-time text detection. Concretely, we find that the band-pass filter allows through components in a specified band of frequencies, called its passband but blocks components with frequencies above or below this band. It provides a natural idea for extracting whole texts separately. By simulating the band-pass filter, TPF constructs a unique feature-filter pair for each text. In the inference stage, every filter extracts the corresponding matched text by passing its pass-feature and blocking other features. Meanwhile, considering the large aspect ratio problem of ribbon-like texts makes it hard to recognize texts wholly, a Reinforcement Ensemble Unit (REU) is designed to enhance the feature consistency of the same text and to enlarge the filter's recognition field to help recognize whole texts. Furthermore, a Foreground Prior Unit (FPU) is introduced to encourage TPF to discriminate the difference between the foreground and background, which improves the feature-filter pair quality. Experiments demonstrate the effectiveness of REU and FPU while showing the TPF's superiority.

</details>


### [109] [Computational Framework for Estimating Relative Gaussian Blur Kernels between Image Pairs](https://arxiv.org/abs/2601.18099)
*Akbar Saadat*

Main category: cs.CV

TL;DR: 提出零训练前向计算框架，用于实时估计高斯模糊参数，通过解析表达式计算离焦图像，实现合成模糊值估计误差低于1.7%


<details>
  <summary>Details</summary>
Motivation: 在先前高斯模型验证基础上，开发实时应用框架，无需训练即可处理图像模糊参数估计，解决实际应用中实时处理需求

Method: 基于离散计算解析表达式，从清晰图像计算离焦图像，通过高斯核标准差应用范围选择和最佳匹配，利用邻域相似性度量过滤多解问题

Result: 在真实图像上实验评估，合成模糊值估计的平均绝对误差低于1.7%，实际模糊图像强度与估计值差异保持在2%以下

Conclusion: 提出的零训练框架有效实现实时高斯模糊参数估计，解析表达式方法在保持低误差的同时满足实时应用需求

Abstract: Following the earlier verification for Gaussian model in \cite{ASaa2026}, this paper introduces a zero training forward computational framework for the model to realize it in real time applications. The framework is based on discrete calculation of the analytic expression of the defocused image from the sharper one for the application range of the standard deviation of the Gaussian kernels and selecting the best matches. The analytic expression yields multiple solutions at certain image points, but is filtered down to a single solution using similarity measures over neighboring points.The framework is structured to handle cases where two given images are partial blurred versions of each other. Experimental evaluations on real images demonstrate that the proposed framework achieves a mean absolute error (MAE) below $1.7\%$ in estimating synthetic blur values. Furthermore, the discrepancy between actual blurred image intensities and their corresponding estimates remains under $2\%$, obtained by applying the extracted defocus filters to less blurred images.

</details>


### [110] [Spatial-Conditioned Reasoning in Long-Egocentric Videos](https://arxiv.org/abs/2601.18100)
*James Tribble,Hao Wang,Si-En Hong,Chaoyi Zhou,Ashish Bastola,Siyu Huang,Abolfazl Razi*

Main category: cs.CV

TL;DR: 研究探索了在长时程第一人称视频中，显式空间信号如何影响VLM的空间推理能力，通过深度图与RGB帧融合来提升导航相关任务表现。


<details>
  <summary>Details</summary>
Motivation: 长时程第一人称视频存在视角漂移和缺乏持久几何上下文的问题，当前视觉语言模型在长序列中的空间推理能力有限，需要研究如何在不修改模型架构的情况下提升其空间理解能力。

Method: 1) 创建Sanpo-D数据集，对Google Sanpo数据集进行细粒度重新标注；2) 在导航导向的空间查询上对多个VLM进行基准测试；3) 通过将深度图与RGB帧融合来研究输入级归纳偏置的影响。

Result: 研究揭示了通用精度与空间专业化之间的权衡，表明深度感知和空间基础表示可以提升在行人检测和障碍物检测等安全关键任务上的性能。

Conclusion: 显式空间信号（如深度信息）能够有效增强VLM在长时程第一人称视频中的空间推理能力，特别是在安全关键导航任务中，为改进视觉导航系统提供了重要方向。

Abstract: Long-horizon egocentric video presents significant challenges for visual navigation due to viewpoint drift and the absence of persistent geometric context. Although recent vision-language models perform well on image and short-video reasoning, their spatial reasoning capability in long egocentric sequences remains limited. In this work, we study how explicit spatial signals influence VLM-based video understanding without modifying model architectures or inference procedures. We introduce Sanpo-D, a fine-grained re-annotation of the Google Sanpo dataset, and benchmark multiple VLMs on navigation-oriented spatial queries. To examine input-level inductive bias, we further fuse depth maps with RGB frames and evaluate their impact on spatial reasoning. Our results reveal a trade-off between general-purpose accuracy and spatial specialization, showing that depth-aware and spatially grounded representations can improve performance on safety-critical tasks such as pedestrian and obstruction detection.

</details>


### [111] [LungCRCT: Causal Representation based Lung CT Processing for Lung Cancer Treatment](https://arxiv.org/abs/2601.18118)
*Daeyoung Kim*

Main category: cs.CV

TL;DR: 提出LungCRCT框架，利用因果表示学习分析肺癌，支持因果干预分析并实现高精度肿瘤分类


<details>
  <summary>Details</summary>
Motivation: 肺癌早期症状不明显且易与其他呼吸系统疾病混淆，导致诊断延误。现有基于CNN或ViT的AI模型虽在检测和分类任务中表现良好，但存在相关性依赖、可解释性差等局限，难以扩展到治疗分析和因果干预模拟。

Method: 提出LungCRCT框架，采用基于图自动编码器的因果发现算法，结合距离相关性解缠和基于熵的图像重建优化，从肺癌进展的物理因果机制中提取因果表示。

Result: 框架不仅支持肺癌治疗的因果干预分析，还在恶性肿瘤分类任务中实现了93.91%的AUC分数，且下游模型轻量高效。

Conclusion: LungCRCT通过因果表示学习克服了传统深度学习的局限性，为肺癌分析提供了可解释且强大的框架，支持治疗干预模拟和精准分类。

Abstract: Due to silence in early stages, lung cancer has been one of the most leading causes of mortality in cancer patients world-wide. Moreover, major symptoms of lung cancer are hard to differentiate with other respiratory disease symptoms such as COPD, further leading patients to overlook cancer progression in early stages. Thus, to enhance survival rates in lung cancer, early detection from consistent proactive respiratory system monitoring becomes crucial. One of the most prevalent and effective methods for lung cancer monitoring would be low-dose computed tomography(LDCT) chest scans, which led to remarkable enhancements in lung cancer detection or tumor classification tasks under rapid advancements and applications of computer vision based AI models such as EfficientNet or ResNet in image processing. However, though advanced CNN models under transfer learning or ViT based models led to high performing lung cancer detections, due to its intrinsic limitations in terms of correlation dependence and low interpretability due to complexity, expansions of deep learning models to lung cancer treatment analysis or causal intervention analysis simulations are still limited. Therefore, this research introduced LungCRCT: a latent causal representation learning based lung cancer analysis framework that retrieves causal representations of factors within the physical causal mechanism of lung cancer progression. With the use of advanced graph autoencoder based causal discovery algorithms with distance Correlation disentanglement and entropy-based image reconstruction refinement, LungCRCT not only enables causal intervention analysis for lung cancer treatments, but also leads to robust, yet extremely light downstream models in malignant tumor classification tasks with an AUC score of 93.91%.

</details>


### [112] [Forward Consistency Learning with Gated Context Aggregation for Video Anomaly Detection](https://arxiv.org/abs/2601.18135)
*Jiahao Lyu,Minghua Zhao,Xuewen Huang,Yifei Chen,Shuangli Du,Jing Hu,Cheng Shi,Zhiyong Lv*

Main category: cs.CV

TL;DR: FoGA：一种轻量级视频异常检测模型，通过前向一致性学习和门控上下文聚合，仅含约200万参数，在边缘设备上实现高效检测


<details>
  <summary>Details</summary>
Motivation: 现有视频异常检测方法大多依赖大规模模型追求极致精度，难以在资源有限的边缘设备上部署；同时主流预测方法仅使用单帧未来预测误差，忽略了更长期的时间前向信息约束

Method: 基于Unet架构，对连续帧进行特征提取生成即时和前向预测；在跳跃连接中引入门控上下文聚合模块动态融合编码器和解码器特征；采用前向一致性损失联合优化，使用混合异常测量策略整合即时和前向帧的误差

Result: FoGA在实验中显著优于现有最先进方法，运行速度高达155 FPS，在性能和效率指标之间取得了优异平衡

Conclusion: FoGA是一种轻量级高效的视频异常检测模型，特别适合边缘设备部署，通过前向一致性学习和门控上下文聚合实现了性能与效率的良好权衡

Abstract: As a crucial element of public security, video anomaly detection (VAD) aims to measure deviations from normal patterns for various events in real-time surveillance systems. However, most existing VAD methods rely on large-scale models to pursue extreme accuracy, limiting their feasibility on resource-limited edge devices. Moreover, mainstream prediction-based VAD detects anomalies using only single-frame future prediction errors, overlooking the richer constraints from longer-term temporal forward information. In this paper, we introduce FoGA, a lightweight VAD model that performs Forward consistency learning with Gated context Aggregation, containing about 2M parameters and tailored for potential edge devices. Specifically, we propose a Unet-based method that performs feature extraction on consecutive frames to generate both immediate and forward predictions. Then, we introduce a gated context aggregation module into the skip connections to dynamically fuse encoder and decoder features at the same spatial scale. Finally, the model is jointly optimized with a novel forward consistency loss, and a hybrid anomaly measurement strategy is adopted to integrate errors from both immediate and forward frames for more accurate detection. Extensive experiments demonstrate the effectiveness of the proposed method, which substantially outperforms state-of-the-art competing methods, running up to 155 FPS. Hence, our FoGA achieves an excellent trade-off between performance and the efficiency metric.

</details>


### [113] [Agentic Very Long Video Understanding](https://arxiv.org/abs/2601.18157)
*Aniket Rege,Arka Sadhu,Yuliang Li,Kejie Li,Ramya Korlakai Vinayak,Yuning Chai,Yong Jae Lee,Hyo Jin Kim*

Main category: cs.CV

TL;DR: EGAgent是一个基于实体场景图的增强型代理框架，用于全天候可穿戴设备（如智能眼镜）的长期视频理解，通过结构化搜索和推理工具实现跨模态、时序连贯的复杂推理。


<details>
  <summary>Details</summary>
Motivation: 全天候个人AI助手需要超越短期孤立事件的连续纵向视频理解能力，现有方法受限于有限的上下文窗口，无法对超长视频流进行组合式多跳推理。

Method: EGAgent是一个以实体场景图为中心的增强代理框架，表示随时间变化的人物、地点、物体及其关系。系统为规划代理配备结构化搜索和推理工具，以及混合视觉和音频搜索能力。

Result: 在EgoLifeQA数据集上达到最先进的57.5%性能，在Video-MME（Long）数据集上达到74.1%的竞争性性能，用于复杂的纵向视频理解任务。

Conclusion: EGAgent通过实体场景图和代理框架解决了长期视频理解的挑战，实现了跨模态、时序连贯的复杂推理，为全天候AI助手提供了有效的解决方案。

Abstract: The advent of always-on personal AI assistants, enabled by all-day wearable devices such as smart glasses, demands a new level of contextual understanding, one that goes beyond short, isolated events to encompass the continuous, longitudinal stream of egocentric video. Achieving this vision requires advances in long-horizon video understanding, where systems must interpret and recall visual and audio information spanning days or even weeks. Existing methods, including large language models and retrieval-augmented generation, are constrained by limited context windows and lack the ability to perform compositional, multi-hop reasoning over very long video streams. In this work, we address these challenges through EGAgent, an enhanced agentic framework centered on entity scene graphs, which represent people, places, objects, and their relationships over time. Our system equips a planning agent with tools for structured search and reasoning over these graphs, as well as hybrid visual and audio search capabilities, enabling detailed, cross-modal, and temporally coherent reasoning. Experiments on the EgoLifeQA and Video-MME (Long) datasets show that our method achieves state-of-the-art performance on EgoLifeQA (57.5%) and competitive performance on Video-MME (Long) (74.1%) for complex longitudinal video understanding tasks.

</details>


### [114] [TempDiffReg: Temporal Diffusion Model for Non-Rigid 2D-3D Vascular Registration](https://arxiv.org/abs/2601.18168)
*Zehua Liu,Shihao Zou,Jincai Huang,Yanfang Zhang,Chao Tong,Weixin Si*

Main category: cs.CV

TL;DR: 提出一种用于TACE手术的2D-3D血管配准方法，采用从粗到细的策略，包含全局对齐模块SA-PnP和时序扩散模型TempDiffReg，显著提升配准精度和解剖合理性。


<details>
  <summary>Details</summary>
Motivation: TACE是肝癌治疗的首选方法，但手术中复杂的血管导航和解剖变异性使其极具挑战性。准确的2D-3D血管配准对于引导微导管和器械、实现精准定位和最佳治疗靶向至关重要。

Method: 采用从粗到细的配准策略：1) 全局对齐模块SA-PnP，建立2D和3D血管结构对应关系；2) TempDiffReg时序扩散模型，利用时序上下文迭代执行血管变形，捕捉复杂的解剖变化和局部结构变化。

Result: 在23名患者的626个多帧样本上评估，方法在准确性和解剖合理性方面均优于现有方法。具体而言，MSE为0.63mm，MAE为0.51mm，相比现有最佳方法分别降低66.7%和17.7%。

Conclusion: 该方法有潜力帮助经验不足的临床医生安全高效地执行复杂的TACE手术，最终提升手术效果和患者护理质量。代码和数据已开源。

Abstract: Transarterial chemoembolization (TACE) is a preferred treatment option for hepatocellular carcinoma and other liver malignancies, yet it remains a highly challenging procedure due to complex intra-operative vascular navigation and anatomical variability. Accurate and robust 2D-3D vessel registration is essential to guide microcatheter and instruments during TACE, enabling precise localization of vascular structures and optimal therapeutic targeting. To tackle this issue, we develop a coarse-to-fine registration strategy. First, we introduce a global alignment module, structure-aware perspective n-point (SA-PnP), to establish correspondence between 2D and 3D vessel structures. Second, we propose TempDiffReg, a temporal diffusion model that performs vessel deformation iteratively by leveraging temporal context to capture complex anatomical variations and local structural changes. We collected data from 23 patients and constructed 626 paired multi-frame samples for comprehensive evaluation. Experimental results demonstrate that the proposed method consistently outperforms state-of-the-art (SOTA) methods in both accuracy and anatomical plausibility. Specifically, our method achieves a mean squared error (MSE) of 0.63 mm and a mean absolute error (MAE) of 0.51 mm in registration accuracy, representing 66.7\% lower MSE and 17.7\% lower MAE compared to the most competitive existing approaches. It has the potential to assist less-experienced clinicians in safely and efficiently performing complex TACE procedures, ultimately enhancing both surgical outcomes and patient care. Code and data are available at: \textcolor{blue}{https://github.com/LZH970328/TempDiffReg.git}

</details>


### [115] [YOLO-DS: Fine-Grained Feature Decoupling via Dual-Statistic Synergy Operator for Object Detection](https://arxiv.org/abs/2601.18172)
*Lin Huang,Yujuan Tan,Weisheng Li,Shitai Shan,Liu Liu,Bo Liu,Linlin Shen,Jing Yu,Yue Niu*

Main category: cs.CV

TL;DR: YOLO-DS通过新颖的双统计协同算子(DSO)和门控模块，解决了YOLO系列检测器中异质物体响应建模不足的问题，在MS-COCO基准上相比YOLOv8实现了1.1%-1.7%的AP提升，且推理延迟增加极小。


<details>
  <summary>Details</summary>
Motivation: 现有YOLO检测器缺乏对共享特征通道中异质物体响应的显式建模，这限制了性能的进一步提升。需要一种能够有效区分不同类型物体的机制。

Method: 提出YOLO-DS框架，核心是双统计协同算子(DSO)，通过联合建模通道均值和峰均差来解耦物体特征。基于DSO设计了两个轻量级门控模块：用于自适应通道特征选择的DSG模块和用于深度特征加权的MSG模块。

Result: 在MS-COCO基准测试中，YOLO-DS在五个模型尺度(N, S, M, L, X)上均优于YOLOv8，AP提升1.1%到1.7%，推理延迟仅轻微增加。可视化、消融和对比研究验证了方法的有效性。

Conclusion: YOLO-DS通过显式建模异质物体响应，显著提升了一阶段目标检测的性能，同时保持了高效率，为YOLO系列检测器提供了有效的改进方案。

Abstract: One-stage object detection, particularly the YOLO series, strikes a favorable balance between accuracy and efficiency. However, existing YOLO detectors lack explicit modeling of heterogeneous object responses within shared feature channels, which limits further performance gains. To address this, we propose YOLO-DS, a framework built around a novel Dual-Statistic Synergy Operator (DSO). The DSO decouples object features by jointly modeling the channel-wise mean and the peak-to-mean difference. Building upon the DSO, we design two lightweight gating modules: the Dual-Statistic Synergy Gating (DSG) module for adaptive channel-wise feature selection, and the Multi-Path Segmented Gating (MSG) module for depth-wise feature weighting. On the MS-COCO benchmark, YOLO-DS consistently outperforms YOLOv8 across five model scales (N, S, M, L, X), achieving AP gains of 1.1% to 1.7% with only a minimal increase in inference latency. Extensive visualization, ablation, and comparative studies validate the effectiveness of our approach, demonstrating its superior capability in discriminating heterogeneous objects with high efficiency.

</details>


### [116] [\textsc{NaVIDA}: Vision-Language Navigation with Inverse Dynamics Augmentation](https://arxiv.org/abs/2601.18188)
*Weiye Zhu,Zekai Zhang,Xiangchen Wang,Hewei Pan,Teng Wang,Tiantian Geng,Rongtao Xu,Feng Zheng*

Main category: cs.CV

TL;DR: NaVIDA是一个新的视觉语言导航框架，通过逆动力学增强学习视觉-动作因果关系，使用分层概率动作分块扩展规划范围，并通过熵引导机制自适应执行，在减少参数量的同时实现更好的导航性能。


<details>
  <summary>Details</summary>
Motivation: 现有VLN方法主要依赖反应式的状态-动作映射，没有显式建模动作如何因果性地改变后续视觉观察。缺乏这种视觉-动作因果关系导致智能体无法预测自身动作引起的视觉变化，造成行为不稳定、泛化能力弱和轨迹累积误差。

Method: NaVIDA框架将策略学习与动作基础的视觉动力学和自适应执行相结合：1) 使用基于分块的逆动力学监督增强训练，学习视觉变化与对应动作的因果关系；2) 采用分层概率动作分块(HPAC)组织轨迹为多步分块，提供更长范围的视觉变化线索；3) 引入熵引导机制自适应设置动作分块的执行范围，减少误差累积。

Result: 实验表明NaVIDA在导航性能上优于最先进方法，且参数量更少(3B vs 8B)。真实机器人评估进一步验证了该方法的实际可行性和有效性。

Conclusion: NaVIDA通过显式建模视觉-动作因果关系，解决了VLN中行为不稳定和误差累积的问题，在减少参数的同时实现了更好的导航性能，为实际机器人应用提供了可行方案。

Abstract: Vision-and-Language Navigation (VLN) requires agents to interpret natural language instructions and act coherently in visually rich environments. However, most existing methods rely on reactive state-action mappings without explicitly modeling how actions causally transform subsequent visual observations. Lacking such vision-action causality, agents cannot anticipate the visual changes induced by its own actions, leading to unstable behaviors, weak generalization, and cumulative error along trajectory. To address these issues, we introduce \textsc{NaVIDA} (\textbf{Nav}igation with \textbf{I}nverse \textbf{D}ynamics \textbf{A}ugmentation), a unified VLN framework that couples policy learning with action-grounded visual dynamics and adaptive execution. \textsc{NaVIDA} augments training with chunk-based inverse-dynamics supervision to learn causal relationship between visual changes and corresponding actions. To structure this supervision and extend the effective planning range, \textsc{NaVIDA} employs hierarchical probabilistic action chunking (HPAC), which organizes trajectories into multi-step chunks and provides discriminative, longer-range visual-change cues. To further curb error accumulation and stabilize behavior at inference, an entropy-guided mechanism adaptively sets the execution horizon of action chunks. Extensive experiments show that \textsc{NaVIDA} achieves superior navigation performance compared to state-of-the-art methods with fewer parameters (3B vs. 8B). Real-world robot evaluations further validate the practical feasibility and effectiveness of our approach. Code and data will be available upon acceptance.

</details>


### [117] [Multi-Perspective Subimage CLIP with Keyword Guidance for Remote Sensing Image-Text Retrieval](https://arxiv.org/abs/2601.18190)
*Yifan Li,Shiying Wang,Jianqiang Huang*

Main category: cs.CV

TL;DR: MPS-CLIP：一个参数高效的遥感图像-文本检索框架，通过关键词引导的细粒度对齐和多视角表示，显著提升性能同时减少计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有VLP模型主要依赖粗粒度全局对齐，忽略了遥感图像密集、多尺度的语义特征。完全微调重型模型计算成本高且存在灾难性遗忘风险。

Method: 1) 使用LLM提取核心语义关键词，指导SAM生成语义相关子视角；2) 引入G^2A适配器高效适应冻结主干；3) MPR模块聚合局部线索为多视角嵌入；4) 混合损失函数结合多视角对比和加权三元组损失。

Result: 在RSICD和RSITMD基准测试中分别达到35.18%和48.40%的平均召回率(mR)，显著优于完全微调基线和最新竞争方法。

Conclusion: MPS-CLIP成功将检索范式从全局匹配转向关键词引导的细粒度对齐，以参数高效的方式实现了最先进的遥感图像-文本检索性能。

Abstract: Vision-Language Pre-training (VLP) models like CLIP have significantly advanced Remote Sensing Image-Text Retrieval (RSITR). However, existing methods predominantly rely on coarse-grained global alignment, which often overlooks the dense, multi-scale semantics inherent in overhead imagery. Moreover, adapting these heavy models via full fine-tuning incurs prohibitive computational costs and risks catastrophic forgetting. To address these challenges, we propose MPS-CLIP, a parameter-efficient framework designed to shift the retrieval paradigm from global matching to keyword-guided fine-grained alignment. Specifically, we leverage a Large Language Model (LLM) to extract core semantic keywords, guiding the Segment Anything Model (SamGeo) to generate semantically relevant sub-perspectives. To efficiently adapt the frozen backbone, we introduce a Gated Global Attention (G^2A) adapter, which captures global context and long-range dependencies with minimal overhead. Furthermore, a Multi-Perspective Representation (MPR) module aggregates these local cues into robust multi-perspective embeddings. The framework is optimized via a hybrid objective combining multi-perspective contrastive and weighted triplet losses, which dynamically selects maximum-response perspectives to suppress noise and enforce precise semantic matching. Extensive experiments on the RSICD and RSITMD benchmarks demonstrate that MPS-CLIP achieves state-of-the-art performance with 35.18% and 48.40% mean Recall (mR), respectively, significantly outperforming full fine-tuning baselines and recent competitive methods. Code is available at https://github.com/Lcrucial1f/MPS-CLIP.

</details>


### [118] [MindCine: Multimodal EEG-to-Video Reconstruction with Large-Scale Pretrained Models](https://arxiv.org/abs/2601.18192)
*Tian-Yi Zhou,Xuan-Hao Liu,Bao-Liang Lu,Wei-Long Zheng*

Main category: cs.CV

TL;DR: MindCine：一种通过多模态联合学习和预训练大EEG模型解决EEG到视频重建中单模态和数据稀缺问题的新框架


<details>
  <summary>Details</summary>
Motivation: EEG信号的非侵入性和高时间分辨率使其在重建人类动态视觉感知方面具有重要研究意义，但现有方法面临两个主要挑战：1）仅使用文本模态对齐EEG信号，忽略其他模态且容易过拟合；2）有限EEG-视频数据导致训练困难

Method: 提出MindCine框架：1）采用多模态联合学习策略，在训练阶段整合超越文本的多模态信息；2）利用预训练的大型EEG模型缓解数据稀缺问题以解码语义信息；3）专门设计具有因果注意力的Seq2Seq模型来解码感知信息

Result: 大量实验表明，MindCine在定性和定量评估上都优于现有最先进方法，结果强调了不同模态互补优势的有效性，并证明利用大规模EEG模型可以通过缓解数据有限相关的挑战来进一步提升重建性能

Conclusion: MindCine成功解决了EEG到视频重建中的单模态和数据稀缺问题，通过多模态联合学习和预训练EEG模型的结合，实现了在有限数据上的高保真视频重建，为EEG信号解码提供了新的有效方法

Abstract: Reconstructing human dynamic visual perception from electroencephalography (EEG) signals is of great research significance since EEG's non-invasiveness and high temporal resolution. However, EEG-to-video reconstruction remains challenging due to: 1) Single Modality: existing studies solely align EEG signals with the text modality, which ignores other modalities and are prone to suffer from overfitting problems; 2) Data Scarcity: current methods often have difficulty training to converge with limited EEG-video data. To solve the above problems, we propose a novel framework MindCine to achieve high-fidelity video reconstructions on limited data. We employ a multimodal joint learning strategy to incorporate beyond-text modalities in the training stage and leverage a pre-trained large EEG model to relieve the data scarcity issue for decoding semantic information, while a Seq2Seq model with causal attention is specifically designed for decoding perceptual information. Extensive experiments demonstrate that our model outperforms state-of-the-art methods both qualitatively and quantitatively. Additionally, the results underscore the effectiveness of the complementary strengths of different modalities and demonstrate that leveraging a large-scale EEG model can further enhance reconstruction performance by alleviating the challenges associated with limited data.

</details>


### [119] [QualiRAG: Retrieval-Augmented Generation for Visual Quality Understanding](https://arxiv.org/abs/2601.18195)
*Linhan Cao,Wei Sun,Weixia Zhang,Xiangyang Zhu,Kaiwei Zhang,Jun Jia,Dandan Zhu,Guangtao Zhai,Xiongkuo Min*

Main category: cs.CV

TL;DR: QualiRAG是一个无需训练的检索增强生成框架，利用大型多模态模型的潜在感知知识进行视觉质量评估，通过动态生成四种互补知识源实现证据驱动的推理。


<details>
  <summary>Details</summary>
Motivation: 当前视觉质量评估方法依赖监督微调或强化学习，需要大量人工标注且容易产生数据集特定偏差。需要一种无需训练的方法来利用大型多模态模型的感知知识。

Method: 提出QualiRAG框架，将问题分解为结构化请求，动态生成四种知识源：视觉元数据、主体定位、全局质量摘要和局部质量描述，然后进行相关性感知检索实现证据驱动的推理。

Result: 在视觉质量理解任务上显著优于开源通用LMM和VQA微调LMM，在视觉质量比较任务上表现竞争力，无需任何任务特定训练即可实现稳健的质量评估。

Conclusion: QualiRAG展示了无需训练即可有效利用大型多模态模型潜在感知知识进行视觉质量评估的可行性，为可解释质量理解提供了新范式。

Abstract: Visual quality assessment (VQA) is increasingly shifting from scalar score prediction toward interpretable quality understanding -- a paradigm that demands \textit{fine-grained spatiotemporal perception} and \textit{auxiliary contextual information}. Current approaches rely on supervised fine-tuning or reinforcement learning on curated instruction datasets, which involve labor-intensive annotation and are prone to dataset-specific biases. To address these challenges, we propose \textbf{QualiRAG}, a \textit{training-free} \textbf{R}etrieval-\textbf{A}ugmented \textbf{G}eneration \textbf{(RAG)} framework that systematically leverages the latent perceptual knowledge of large multimodal models (LMMs) for visual quality perception. Unlike conventional RAG that retrieves from static corpora, QualiRAG dynamically generates auxiliary knowledge by decomposing questions into structured requests and constructing four complementary knowledge sources: \textit{visual metadata}, \textit{subject localization}, \textit{global quality summaries}, and \textit{local quality descriptions}, followed by relevance-aware retrieval for evidence-grounded reasoning. Extensive experiments show that QualiRAG achieves substantial improvements over open-source general-purpose LMMs and VQA-finetuned LMMs on visual quality understanding tasks, and delivers competitive performance on visual quality comparison tasks, demonstrating robust quality assessment capabilities without any task-specific training. The code will be publicly available at https://github.com/clh124/QualiRAG.

</details>


### [120] [HomoFM: Deep Homography Estimation with Flow Matching](https://arxiv.org/abs/2601.18222)
*Mengfan He,Liangzheng Sun,Chunyu Li,Ziyang Meng*

Main category: cs.CV

TL;DR: 提出HomoFM框架，首次将流匹配技术引入单应性估计任务，通过建模连续点状速度场将噪声分布变换为配准坐标，并集成梯度反转层增强跨域鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有深度单应性估计方法通常将其视为直接回归或迭代优化问题，难以捕捉复杂几何变换或实现跨域泛化，需要更鲁棒和通用的解决方案。

Method: 将单应性估计重新表述为速度场学习问题，建模连续点状速度场将噪声分布变换为配准坐标；集成梯度反转层到特征提取主干，学习域不变表示以增强跨域鲁棒性。

Result: 在标准基准测试中，HomoFM在估计精度和鲁棒性方面均优于现有最先进方法，特别是在多模态匹配和变化光照等跨域场景中表现优异。

Conclusion: HomoFM通过引入流匹配技术和域适应策略，为单应性估计提供了更精确和鲁棒的解决方案，在复杂几何变换和跨域场景中展现出优越性能。

Abstract: Deep homography estimation has broad applications in computer vision and robotics. Remarkable progresses have been achieved while the existing methods typically treat it as a direct regression or iterative refinement problem and often struggling to capture complex geometric transformations or generalize across different domains. In this work, we propose HomoFM, a new framework that introduces the flow matching technique from generative modeling into the homography estimation task for the first time. Unlike the existing methods, we formulate homography estimation problem as a velocity field learning problem. By modeling a continuous and point-wise velocity field that transforms noisy distributions into registered coordinates, the proposed network recovers high-precision transformations through a conditional flow trajectory. Furthermore, to address the challenge of domain shifts issue, e.g., the cases of multimodal matching or varying illumination scenarios, we integrate a gradient reversal layer (GRL) into the feature extraction backbone. This domain adaptation strategy explicitly constrains the encoder to learn domain-invariant representations, significantly enhancing the network's robustness. Extensive experiments demonstrate the effectiveness of the proposed method, showing that HomoFM outperforms state-of-the-art methods in both estimation accuracy and robustness on standard benchmarks. Code and data resource are available at https://github.com/hmf21/HomoFM.

</details>


### [121] [Facial Emotion Recognition on FER-2013 using an EfficientNetB2-Based Approach](https://arxiv.org/abs/2601.18228)
*Sahil Naik,Soham Bagayatkar,Pavankumar Singh*

Main category: cs.CV

TL;DR: 提出基于EfficientNetB2的轻量级面部情绪识别方法，通过两阶段训练策略和多种优化技术，在FER-2013数据集上达到68.78%准确率，参数比VGG16少10倍，适合实时边缘应用。


<details>
  <summary>Details</summary>
Motivation: 现实世界面部情绪识别面临图像质量低、光照变化、姿势变化、背景干扰、类间差异小、标签噪声和类别不平衡等挑战，现有大型CNN模型计算成本高、内存密集，不适合实时应用。

Method: 使用EfficientNetB2构建轻量级管道，采用两阶段预热和微调策略，结合AdamW优化、解耦权重衰减、标签平滑(ε=0.06)、裁剪类别权重、dropout、混合精度训练和实时数据增强。

Result: 在FER-2013数据集上达到68.78%测试准确率，参数数量比VGG16基准少近10倍，训练稳定且泛化能力强，适合实时和边缘应用。

Conclusion: 提出的轻量级EfficientNetB2方法在保持高准确率的同时显著降低计算复杂度，解决了现实世界面部情绪识别的挑战，为实时边缘应用提供了实用解决方案。

Abstract: Detection of human emotions based on facial images in real-world scenarios is a difficult task due to low image quality, variations in lighting, pose changes, background distractions, small inter-class variations, noisy crowd-sourced labels, and severe class imbalance, as observed in the FER-2013 dataset of 48x48 grayscale images. Although recent approaches using large CNNs such as VGG and ResNet achieve reasonable accuracy, they are computationally expensive and memory-intensive, limiting their practicality for real-time applications. We address these challenges using a lightweight and efficient facial emotion recognition pipeline based on EfficientNetB2, trained using a two-stage warm-up and fine-tuning strategy. The model is enhanced with AdamW optimization, decoupled weight decay, label smoothing (epsilon = 0.06) to reduce annotation noise, and clipped class weights to mitigate class imbalance, along with dropout, mixed-precision training, and extensive real-time data augmentation. The model is trained using a stratified 87.5%/12.5% train-validation split while keeping the official test set intact, achieving a test accuracy of 68.78% with nearly ten times fewer parameters than VGG16-based baselines. Experimental results, including per-class metrics and learning dynamics, demonstrate stable training and strong generalization, making the proposed approach suitable for real-time and edge-based applications.

</details>


### [122] [V-Loop: Visual Logical Loop Verification for Hallucination Detection in Medical Visual Question Answering](https://arxiv.org/abs/2601.18240)
*Mengyuan Jin,Zehui Liao,Yong Xia*

Main category: cs.CV

TL;DR: 提出V-Loop框架，通过视觉逻辑循环验证检测医疗VQA中的幻觉，无需训练且即插即用，显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在医疗VQA中表现出色，但其输出容易产生与视觉事实矛盾的幻觉，这在高风险医疗场景中构成重大风险。现有不确定性方法虽然计算高效，但本质上是间接的，无法验证具体答案的事实正确性。

Method: 提出视觉逻辑循环验证(V-Loop)框架：1) MLLM生成主要答案；2) 从主要QA对中提取语义单元；3) 基于答案单元生成验证问题重新查询问题单元；4) 强制视觉注意力一致性确保两个问题依赖相同图像证据；5) 验证答案与预期语义内容匹配则逻辑循环闭合，否则标记为幻觉。

Result: 在多个医疗VQA基准测试和MLLM上的广泛实验表明，V-Loop始终优于现有自省方法，保持高效性，与不确定性方法结合使用时能进一步提升性能。

Conclusion: V-Loop通过形成视觉接地的逻辑循环来验证事实正确性，为医疗VQA中的幻觉检测提供了有效解决方案，无需训练且计算高效，显著提升了检测准确性。

Abstract: Multimodal Large Language Models (MLLMs) have shown remarkable capability in assisting disease diagnosis in medical visual question answering (VQA). However, their outputs remain vulnerable to hallucinations (i.e., responses that contradict visual facts), posing significant risks in high-stakes medical scenarios. Recent introspective detection methods, particularly uncertainty-based approaches, offer computational efficiency but are fundamentally indirect, as they estimate predictive uncertainty for an image-question pair rather than verifying the factual correctness of a specific answer. To address this limitation, we propose Visual Logical Loop Verification (V-Loop), a training-free and plug-and-play framework for hallucination detection in medical VQA. V-Loop introduces a bidirectional reasoning process that forms a visually grounded logical loop to verify factual correctness. Given an input, the MLLM produces an answer for the primary input pair. V-Loop extracts semantic units from the primary QA pair, generates a verification question by conditioning on the answer unit to re-query the question unit, and enforces visual attention consistency to ensure answering both primary question and verification question rely on the same image evidence. If the verification answer matches the expected semantic content, the logical loop closes, indicating factual grounding; otherwise, the primary answer is flagged as hallucinated. Extensive experiments on multiple medical VQA benchmarks and MLLMs show that V-Loop consistently outperforms existing introspective methods, remains highly efficient, and further boosts uncertainty-based approaches when used in combination.

</details>


### [123] [Vision-Language-Model-Guided Differentiable Ray Tracing for Fast and Accurate Multi-Material RF Parameter Estimation](https://arxiv.org/abs/2601.18242)
*Zerui Kang,Yishen Lim,Zhouyou Gu,Seung-Woo Ko,Tony Q. S. Quek,Jihong Park*

Main category: cs.CV

TL;DR: 提出基于视觉语言模型（VLM）引导的框架，加速并稳定多材料参数估计，通过语义先验指导物理优化，实现快速可靠的RF材料参数估计。


<details>
  <summary>Details</summary>
Motivation: 在6G系统中，准确的射频材料参数对电磁数字孪生至关重要，但基于梯度的逆射线追踪对初始化敏感且在有限测量下成本高昂。

Method: 使用VLM解析场景图像推断材料类别，通过ITU-R材料表映射到定量先验，提供导电率初始化；VLM进一步选择信息丰富的发射器/接收器位置以促进多样化、材料可区分的路径；基于这些先验，可微分射线追踪引擎使用测量的接收信号强度进行梯度优化。

Result: 在NVIDIA Sionna室内场景实验中，相比均匀或随机初始化及随机放置基线，收敛速度快2-4倍，最终参数误差低10-100倍，仅用少量接收器即可实现低于0.1%的平均相对误差。

Conclusion: VLM提供的语义先验能有效指导基于物理的优化，实现快速可靠的RF材料参数估计，VLM引导的位置选择减少了准确恢复所需的测量次数。

Abstract: Accurate radio-frequency (RF) material parameters are essential for electromagnetic digital twins in 6G systems, yet gradient-based inverse ray tracing (RT) remains sensitive to initialization and costly under limited measurements. This paper proposes a vision-language-model (VLM) guided framework that accelerates and stabilizes multi-material parameter estimation in a differentiable RT (DRT) engine. A VLM parses scene images to infer material categories and maps them to quantitative priors via an ITU-R material table, yielding informed conductivity initializations. The VLM further selects informative transmitter/receiver placements that promote diverse, material-discriminative paths. Starting from these priors, the DRT performs gradient-based refinement using measured received signal strengths. Experiments in NVIDIA Sionna on indoor scenes show 2-4$\times$ faster convergence and 10-100$\times$ lower final parameter error compared with uniform or random initialization and random placement baselines, achieving sub-0.1\% mean relative error with only a few receivers. Complexity analyses indicate per-iteration time scales near-linearly with the number of materials and measurement setups, while VLM-guided placement reduces the measurements required for accurate recovery. Ablations over RT depth and ray counts confirm further accuracy gains without significant per-iteration overhead. Results demonstrate that semantic priors from VLMs effectively guide physics-based optimization for fast and reliable RF material estimation.

</details>


### [124] [A multimodal vision foundation model for generalizable knee pathology](https://arxiv.org/abs/2601.18250)
*Kang Yu,Dingyu Wang,Zimu Yuan,Nan Zhou,Jiajun Liu,Jiaxin Liu,Shanggui Liu,Yaoyan Zheng,Huishu Yuan,Di Huang,Dong Jiang*

Main category: cs.CV

TL;DR: OrthoFoundation是一个针对肌肉骨骼病理学的多模态视觉基础模型，使用120万未标记的膝关节X光和MRI图像进行自监督对比学习预训练，在14个下游任务中达到SOTA性能，并展现出优秀的标签效率和跨解剖结构泛化能力。


<details>
  <summary>Details</summary>
Motivation: 肌肉骨骼疾病是全球残疾的主要原因，需要精确的医学影像解读。当前骨科AI方法依赖任务特定的监督学习，存在碎片化、需要大量标注数据、缺乏跨模态和临床场景泛化能力的问题。该领域基础模型的发展受到大规模、高质量开源数据集稀缺的限制。

Method: 构建了包含120万未标记膝关节X光和MRI图像的预训练数据集，使用Dinov3骨干网络，通过自监督对比学习训练模型以获取稳健的放射学表示。

Result: 在14个下游任务中达到SOTA性能：X光骨关节炎诊断准确率优异，MRI结构损伤检测排名第一；仅需50%标注数据即可匹配监督基线性能；尽管在膝关节图像上预训练，但能出色地泛化到髋、肩、踝等其他解剖结构。

Conclusion: OrthoFoundation代表了肌肉骨骼影像通用AI的重要进展，通过从大规模多模态数据中学习基础、关节无关的放射学语义，克服了传统模型的局限性，为减少标注负担和提高临床诊断准确性提供了稳健框架。

Abstract: Musculoskeletal disorders represent a leading cause of global disability, creating an urgent demand for precise interpretation of medical imaging. Current artificial intelligence (AI) approaches in orthopedics predominantly rely on task-specific, supervised learning paradigms. These methods are inherently fragmented, require extensive annotated datasets, and often lack generalizability across different modalities and clinical scenarios. The development of foundation models in this field has been constrained by the scarcity of large-scale, curated, and open-source musculoskeletal datasets. To address these challenges, we introduce OrthoFoundation, a multimodal vision foundation model optimized for musculoskeletal pathology. We constructed a pre-training dataset of 1.2 million unlabeled knee X-ray and MRI images from internal and public databases. Utilizing a Dinov3 backbone, the model was trained via self-supervised contrastive learning to capture robust radiological representations. OrthoFoundation achieves state-of-the-art (SOTA) performance across 14 downstream tasks. It attained superior accuracy in X-ray osteoarthritis diagnosis and ranked first in MRI structural injury detection. The model demonstrated remarkable label efficiency, matching supervised baselines using only 50% of labeled data. Furthermore, despite being pre-trained on knee images, OrthoFoundation exhibited exceptional cross-anatomy generalization to the hip, shoulder, and ankle. OrthoFoundation represents a significant advancement toward general-purpose AI for musculoskeletal imaging. By learning fundamental, joint-agnostic radiological semantics from large-scale multimodal data, it overcomes the limitations of conventional models, which provides a robust framework for reducing annotation burdens and enhancing diagnostic accuracy in clinical practice.

</details>


### [125] [Co-PLNet: A Collaborative Point-Line Network for Prompt-Guided Wireframe Parsing](https://arxiv.org/abs/2601.18252)
*Chao Wang,Xuanying Li,Cheng Dai,Jinglei Feng,Yuxiang Luo,Yuqi Ouyang,Hao Qin*

Main category: cs.CV

TL;DR: Co-PLNet：一种点线协同框架，通过空间提示交换解决线框解析中线段和连接点预测不匹配问题，提升几何结构感知的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有线框解析方法分别预测线段和连接点，然后进行后处理协调，导致不匹配和鲁棒性降低。需要一种能协同处理点线任务的方法。

Method: 提出Co-PLNet点线协同框架：1) 通过点线提示编码器(PLP-Encoder)将早期检测转换为空间提示；2) 使用交叉引导线解码器(CGL-Decoder)通过稀疏注意力机制基于互补提示细化预测，强制点线一致性。

Result: 在Wireframe和YorkUrban数据集上的实验显示，该方法在准确性和鲁棒性方面均有持续改进，同时具有良好的实时效率。

Conclusion: Co-PLNet通过点线协同的空间提示交换机制，有效提升了结构化几何感知的性能，为SLAM等下游任务提供了更可靠的几何表示。

Abstract: Wireframe parsing aims to recover line segments and their junctions to form a structured geometric representation useful for downstream tasks such as Simultaneous Localization and Mapping (SLAM). Existing methods predict lines and junctions separately and reconcile them post-hoc, causing mismatches and reduced robustness. We present Co-PLNet, a point-line collaborative framework that exchanges spatial cues between the two tasks, where early detections are converted into spatial prompts via a Point-Line Prompt Encoder (PLP-Encoder), which encodes geometric attributes into compact and spatially aligned maps. A Cross-Guidance Line Decoder (CGL-Decoder) then refines predictions with sparse attention conditioned on complementary prompts, enforcing point-line consistency and efficiency. Experiments on Wireframe and YorkUrban show consistent improvements in accuracy and robustness, together with favorable real-time efficiency, demonstrating our effectiveness for structured geometry perception.

</details>


### [126] [Depth to Anatomy: Learning Internal Organ Locations from Surface Depth Images](https://arxiv.org/abs/2601.18260)
*Eytan Kats,Kai Geissler,Daniel Mensing,Jochen G. Hirsch,Stefan Heldman,Mattias P. Heinrich*

Main category: cs.CV

TL;DR: 提出基于学习的框架，从单张2D深度图像直接预测多个内部器官的3D位置和形状，用于自动化患者定位


<details>
  <summary>Details</summary>
Motivation: 自动化患者定位对优化扫描流程和提高患者吞吐量很重要。利用RGB-D相机捕获的深度信息可以估计内部器官位置，实现更准确高效的定位

Method: 使用大规模全身MRI扫描数据集，合成深度图像与对应解剖分割配对，训练统一的卷积神经网络架构，直接从2D深度图像预测3D器官位置和形状

Result: 方法能准确定位多种解剖结构（包括骨骼和软组织），无需显式表面重建，展示了将深度传感器集成到放射学工作流程中的潜力

Conclusion: 该学习框架通过深度图像预测内部器官位置，有望简化扫描流程并改善患者体验，实现自动化患者定位

Abstract: Automated patient positioning plays an important role in optimizing scanning procedure and improving patient throughput. Leveraging depth information captured by RGB-D cameras presents a promising approach for estimating internal organ positions, thereby enabling more accurate and efficient positioning. In this work, we propose a learning-based framework that directly predicts the 3D locations and shapes of multiple internal organs from single 2D depth images of the body surface. Utilizing a large-scale dataset of full-body MRI scans, we synthesize depth images paired with corresponding anatomical segmentations to train a unified convolutional neural network architecture. Our method accurately localizes a diverse set of anatomical structures, including bones and soft tissues, without requiring explicit surface reconstruction. Experimental results demonstrate the potential of integrating depth sensors into radiology workflows to streamline scanning procedures and enhance patient experience through automated patient positioning.

</details>


### [127] [Revisiting Aerial Scene Classification on the AID Benchmark](https://arxiv.org/abs/2601.18263)
*Subhajeet Das,Susmita Ghosh,Abhiroop Chatterjee*

Main category: cs.CV

TL;DR: 该论文综述了航空图像分类的机器学习方法，并提出了Aerial-Y-Net模型，在AID数据集上达到91.72%的准确率。


<details>
  <summary>Details</summary>
Motivation: 航空图像在城市规划和环境保护中至关重要，但由于其异质性（包含建筑物、森林、山脉、空地等不同结构），开发鲁棒的场景分类模型仍然具有挑战性。

Method: 1. 对航空图像分类的机器学习方法进行文献综述，涵盖从手工特征（如SIFT、LBP）到传统CNN（如VGG、GoogLeNet）再到先进深度混合网络的方法。2. 设计了Aerial-Y-Net模型，这是一个具有空间注意力增强和多尺度特征融合机制的CNN模型。

Result: 在AID数据集上评估，Aerial-Y-Net模型达到了91.72%的准确率，优于多个基线架构。

Conclusion: Aerial-Y-Net作为基于注意力的模型，有助于更好地理解航空图像的复杂性，在航空图像分类任务中表现出色。

Abstract: Aerial images play a vital role in urban planning and environmental preservation, as they consist of various structures, representing different types of buildings, forests, mountains, and unoccupied lands. Due to its heterogeneous nature, developing robust models for scene classification remains a challenge. In this study, we conduct a literature review of various machine learning methods for aerial image classification. Our survey covers a range of approaches from handcrafted features (e.g., SIFT, LBP) to traditional CNNs (e.g., VGG, GoogLeNet), and advanced deep hybrid networks. In this connection, we have also designed Aerial-Y-Net, a spatial attention-enhanced CNN with multi-scale feature fusion mechanism, which acts as an attention-based model and helps us to better understand the complexities of aerial images. Evaluated on the AID dataset, our model achieves 91.72% accuracy, outperforming several baseline architectures.

</details>


### [128] [Contextual Range-View Projection for 3D LiDAR Point Clouds](https://arxiv.org/abs/2601.18301)
*Seyedali Mousavi,Seyedhamidreza Mousavi,Masoud Daneshtalab*

Main category: cs.CV

TL;DR: 提出两种新的LiDAR点云到距离图像投影机制：基于实例中心感知的CAP和基于类别权重感知的CWAP，解决传统深度优先投影导致的信息丢失问题


<details>
  <summary>Details</summary>
Motivation: 传统LiDAR点云到距离图像的投影采用深度优先策略（保留最近点），忽略了语义相关性和物体结构，导致重要上下文信息丢失。需要更智能的投影选择机制来保留更多语义信息

Method: 扩展深度优先规则，引入两种机制：1) CAP：根据点到实例中心的距离调整深度值，优先保留实例中心点而非噪声边界点；2) CWAP：通过用户定义的类别权重优先处理特定类别，提供灵活的投影策略

Result: 在SemanticKITTI数据集上评估，CAP在投影过程中保留了更多实例点，相比基线提升3.1% mIoU。CWAP能有效提升目标类别的性能，同时对其他类别影响极小

Conclusion: 提出的CAP和CWAP机制通过结合语义上下文信息改进了LiDAR点云投影，在保留更多实例信息和灵活处理特定类别方面优于传统深度优先方法

Abstract: Range-view projection provides an efficient method for transforming 3D LiDAR point clouds into 2D range image representations, enabling effective processing with 2D deep learning models. However, a major challenge in this projection is the many-to-one conflict, where multiple 3D points are mapped onto the same pixel in the range image, requiring a selection strategy. Existing approaches typically retain the point with the smallest depth (closest to the LiDAR), disregarding semantic relevance and object structure, which leads to the loss of important contextual information. In this paper, we extend the depth-based selection rule by incorporating contextual information from both instance centers and class labels, introducing two mechanisms: \textit{Centerness-Aware Projection (CAP)} and \textit{Class-Weighted-Aware Projection (CWAP)}. In CAP, point depths are adjusted according to their distance from the instance center, thereby prioritizing central instance points over noisy boundary and background points. In CWAP, object classes are prioritized through user-defined weights, offering flexibility in the projection strategy. Our evaluations on the SemanticKITTI dataset show that CAP preserves more instance points during projection, achieving up to a 3.1\% mIoU improvement compared to the baseline. Furthermore, CWAP enhances the performance of targeted classes while having a negligible impact on the performance of other classes

</details>


### [129] [SwipeGen: Bridging the Execution Gap in GUI Agents via Human-like Swipe Synthesis](https://arxiv.org/abs/2601.18305)
*Xuan Wang,Siyuan Su,Quantong Fu,Yongxiang Hu,Yangfan Zhou*

Main category: cs.CV

TL;DR: 提出SwipeGen自动生成人类滑动交互的管道，构建首个GUI代理滑动执行能力基准，并开发GUISwiper代理实现214%的性能提升


<details>
  <summary>Details</summary>
Motivation: 现有GUI代理在滑动交互处理上过于简化，无法准确模拟人类行为，这已成为任务完成的新瓶颈

Method: 将人类滑动手势分解为多个可量化维度，提出SwipeGen自动管道通过GUI探索合成人类滑动交互，并基于此构建基准和开发GUISwiper代理

Result: GUISwiper实现69.07%的滑动执行准确率，相比现有VLM基线提升214%

Conclusion: 通过系统化分解和合成人类滑动交互，显著提升了GUI代理的交互执行能力，为解决GUI代理执行瓶颈提供了有效方案

Abstract: With the widespread adoption of Graphical User Interface (GUI) agents for automating GUI interaction tasks, substantial research focused on improving GUI perception to ground task instructions into concrete action steps. However, the step execution capability of these agents has gradually emerged as a new bottleneck for task completion. In particular, existing GUI agents often adopt overly simplified strategies for handling swipe interactions, preventing them from accurately replicating human-like behavior. To address this limitation, we decompose human swipe gestures into multiple quantifiable dimensions and propose an automated pipeline SwipeGen to synthesize human-like swipe interactions through GUI exploration. Based on this pipeline, we construct and release the first benchmark for evaluating the swipe execution capability of GUI agents. Furthermore, leveraging the synthesized data, we propose GUISwiper, a GUI agent with enhanced interaction execution capabilities. Experimental results demonstrate that GUISwiper achieves a swipe execution accuracy of 69.07%, representing a 214% improvement over existing VLM baselines.

</details>


### [130] [A Tumor Aware DenseNet Swin Hybrid Learning with Boosted and Hierarchical Feature Spaces for Large-Scale Brain MRI Classification](https://arxiv.org/abs/2601.18330)
*Muhammad Ali Shah,Muhammad Mansoor Alam,Saddam Hussain Khan*

Main category: cs.CV

TL;DR: 提出EDSH框架用于脑肿瘤MRI分析，通过两个肿瘤感知实验设置分别解决不同类型肿瘤的诊断挑战，在40,260张图像数据集上达到98.50%的准确率和召回率。


<details>
  <summary>Details</summary>
Motivation: 脑肿瘤MRI分析需要同时捕捉细粒度纹理模式和长距离上下文依赖，现有方法难以有效解决不同类型肿瘤（如弥漫性胶质瘤、脑膜瘤、垂体瘤）的特定诊断挑战。

Method: 提出两个肿瘤感知实验设置：1）Boosted Feature Space (BFS)：定制DenseNet和SwinT分支学习互补的局部和全局表示，进行维度对齐、融合和增强；2）分层DenseNet-SwinT架构：DenseNet作为主干CNN学习结构化局部特征，SwinT建模全局肿瘤形态，采用深度特征提取和双残差连接。

Result: 在包含40,260张图像的大规模MRI数据集上评估，EDSH框架在测试未见数据集上达到98.50%的准确率和召回率，优于独立的CNN、Vision Transformer和混合方法。

Conclusion: EDSH框架通过联合学习局部纹理和全局上下文依赖，有效解决了不同类型脑肿瘤的诊断挑战，在脑肿瘤MRI分析中表现出优越性能。

Abstract: This study proposes an efficient Densely Swin Hybrid (EDSH) framework for brain tumor MRI analysis, designed to jointly capture fine grained texture patterns and long range contextual dependencies. Two tumor aware experimental setups are introduced to address class-specific diagnostic challenges. The first setup employs a Boosted Feature Space (BFS), where independently customized DenseNet and Swint branches learn complementary local and global representations that are dimension aligned, fused, and boosted, enabling highly sensitive detection of diffuse glioma patterns by successfully learning the features of irregular shape, poorly defined mass, and heterogeneous texture. The second setup adopts a hierarchical DenseNet Swint architecture with Deep Feature Extraction have Dual Residual connections (DFE and DR), in which DenseNet serves as a stem CNN for structured local feature learning, while Swin_t models global tumor morphology, effectively suppressing false negatives in meningioma and pituitary tumor classification by learning the features of well defined mass, location (outside brain) and enlargments in tumors (dural tail or upward extension). DenseNet is customized at the input level to match MRI spatial characteristics, leveraging dense residual connectivity to preserve texture information and mitigate vanishing-gradient effects. In parallel, Swint is tailored through task aligned patch embedding and shifted-window self attention to efficiently capture hierarchical global dependencies. Extensive evaluation on a large-scale MRI dataset (stringent 40,260 images across four tumor classes) demonstrates consistent superiority over standalone CNNs, Vision Transformers, and hybrids, achieving 98.50 accuracy and recall on the test unseen dataset.

</details>


### [131] [PPISP: Physically-Plausible Compensation and Control of Photometric Variations in Radiance Field Reconstruction](https://arxiv.org/abs/2601.18336)
*Isaac Deutsch,Nicolas Moënne-Loccoz,Gavriel State,Zan Gojcic*

Main category: cs.CV

TL;DR: 提出PPISP模块，通过物理可解释的ISP参数校正解决多视图3D重建中的光度不一致问题，在标准基准上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 多视图3D重建方法对相机光学特性和图像信号处理（ISP）变化导致的光度不一致非常敏感。现有方法如每帧潜变量或仿射颜色校正缺乏物理基础，对新视角泛化能力差。

Method: 提出物理可解释的ISP（PPISP）校正模块，通过基于物理的可解释变换分离相机固有特性和拍摄依赖效应。训练专门的PPISP控制器预测新视角的ISP参数，类似于真实相机中的自动曝光和自动白平衡。

Result: PPISP在标准基准测试中达到最先进性能，同时提供直观控制，支持在可用时集成元数据，并能在没有真实图像的情况下对新视角进行真实公平的评估。

Conclusion: PPISP通过物理可解释的ISP校正有效解决了多视图3D重建中的光度不一致问题，实现了对新视角的良好泛化，为相关领域提供了实用的解决方案。

Abstract: Multi-view 3D reconstruction methods remain highly sensitive to photometric inconsistencies arising from camera optical characteristics and variations in image signal processing (ISP). Existing mitigation strategies such as per-frame latent variables or affine color corrections lack physical grounding and generalize poorly to novel views. We propose the Physically-Plausible ISP (PPISP) correction module, which disentangles camera-intrinsic and capture-dependent effects through physically based and interpretable transformations. A dedicated PPISP controller, trained on the input views, predicts ISP parameters for novel viewpoints, analogous to auto exposure and auto white balance in real cameras. This design enables realistic and fair evaluation on novel views without access to ground-truth images. PPISP achieves SoTA performance on standard benchmarks, while providing intuitive control and supporting the integration of metadata when available. The source code is available at: https://github.com/nv-tlabs/ppisp

</details>


### [132] [Beyond Rigid: Benchmarking Non-Rigid Video Editing](https://arxiv.org/abs/2601.18340)
*Bingzheng Qu,Kehai Chen,Xuefeng Bai,Jun Yu,Min Zhang*

Main category: cs.CV

TL;DR: 提出了NRVBench，首个专门评估非刚性视频编辑的基准，包含高质量数据集、新评估指标NRVE-Acc和无需训练的基线方法VM-Edit，解决了现有方法在物理合理性和时间一致性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 文本驱动视频编辑在非刚性变形生成方面存在物理失真和时间闪烁问题，缺乏专门的评估基准来系统评估这些复杂动态效果。

Method: 1) 构建包含180个非刚性运动视频的数据集，涵盖6个物理类别，配备2340个细粒度任务指令和360个选择题；2) 提出基于视觉语言模型的NRVE-Acc评估指标，评估物理合规性、时间一致性和指令对齐；3) 提出无需训练的基线方法VM-Edit，采用双区域去噪机制实现结构感知控制。

Result: 实验表明现有方法在保持物理合理性方面存在不足，而提出的VM-Edit方法在标准和提出的指标上都表现出色，NRVBench可作为物理感知视频编辑的标准测试平台。

Conclusion: NRVBench填补了非刚性视频编辑评估的空白，提出的数据集、评估指标和基线方法为物理感知视频编辑的发展提供了重要基础。

Abstract: Despite the remarkable progress in text-driven video editing, generating coherent non-rigid deformations remains a critical challenge, often plagued by physical distortion and temporal flicker. To bridge this gap, we propose NRVBench, the first dedicated and comprehensive benchmark designed to evaluate non-rigid video editing. First, we curate a high-quality dataset consisting of 180 non-rigid motion videos from six physics-based categories, equipped with 2,340 fine-grained task instructions and 360 multiple-choice questions. Second, we propose NRVE-Acc, a novel evaluation metric based on Vision-Language Models that can rigorously assess physical compliance, temporal consistency, and instruction alignment, overcoming the limitations of general metrics in capturing complex dynamics. Third, we introduce a training-free baseline, VM-Edit, which utilizes a dual-region denoising mechanism to achieve structure-aware control, balancing structural preservation and dynamic deformation. Extensive experiments demonstrate that while current methods have shortcomings in maintaining physical plausibility, our method achieves excellent performance across both standard and proposed metrics. We believe the benchmark could serve as a standard testing platform for advancing physics-aware video editing.

</details>


### [133] [Q-Bench-Portrait: Benchmarking Multimodal Large Language Models on Portrait Image Quality Perception](https://arxiv.org/abs/2601.18346)
*Sijing Wu,Yunhao Li,Zicheng Zhang,Qi Jia,Xinyue Li,Huiyu Duan,Xiongkuo Min,Guangtao Zhai*

Main category: cs.CV

TL;DR: Q-Bench-Portrait：首个专门针对人像图像质量感知的综合性基准测试，包含2,765个图像-问题-答案三元组，评估20个开源和5个闭源MLLMs，发现当前模型在人像感知方面能力有限且不精确。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在通用图像的低层视觉基准测试上表现优异，但在具有独特结构和感知特性的人像图像领域的感知和评估能力尚未充分探索，需要专门的人像图像质量感知基准。

Method: 构建Q-Bench-Portrait基准，包含：(1) 多样化人像图像来源（自然、合成失真、AI生成、艺术、计算机图形图像）；(2) 全面质量维度（技术失真、AIGC特定失真、美学）；(3) 多种问题格式（单选、多选、判断、开放性问题），涵盖全局和局部层面。

Result: 评估了20个开源和5个闭源MLLMs，发现虽然当前模型在人像图像感知方面具有一定能力，但性能仍然有限且不精确，与人类判断存在明显差距。

Conclusion: Q-Bench-Portrait基准将促进增强通用和领域特定MLLMs的人像图像感知能力的研究，填补了人像图像质量评估领域的空白。

Abstract: Recent advances in multimodal large language models (MLLMs) have demonstrated impressive performance on existing low-level vision benchmarks, which primarily focus on generic images. However, their capabilities to perceive and assess portrait images, a domain characterized by distinct structural and perceptual properties, remain largely underexplored. To this end, we introduce Q-Bench-Portrait, the first holistic benchmark specifically designed for portrait image quality perception, comprising 2,765 image-question-answer triplets and featuring (1) diverse portrait image sources, including natural, synthetic distortion, AI-generated, artistic, and computer graphics images; (2) comprehensive quality dimensions, covering technical distortions, AIGC-specific distortions, and aesthetics; and (3) a range of question formats, including single-choice, multiple-choice, true/false, and open-ended questions, at both global and local levels. Based on Q-Bench-Portrait, we evaluate 20 open-source and 5 closed-source MLLMs, revealing that although current models demonstrate some competence in portrait image perception, their performance remains limited and imprecise, with a clear gap relative to human judgments. We hope that the proposed benchmark will foster further research into enhancing the portrait image perception capabilities of both general-purpose and domain-specific MLLMs.

</details>


### [134] [OREHAS: A fully automated deep-learning pipeline for volumetric endolymphatic hydrops quantification in MRI](https://arxiv.org/abs/2601.18368)
*Caterina Fuster-Barceló,Claudia Castrillón,Laura Rodrigo-Muñoz,Victor Manuel Vega-Suárez,Nicolás Pérez-Fernández,Gorka Bastarrika,Arrate Muñoz-Barrutia*

Main category: cs.CV

TL;DR: OREHAS是首个全自动量化内耳内淋巴积水的系统，通过深度学习从常规MRI中计算内淋巴与耳蜗体积比，仅需少量标注即可实现高精度三维分割。


<details>
  <summary>Details</summary>
Motivation: 当前内耳内淋巴积水的量化依赖于手动或半自动方法，存在操作者依赖性强、结果不一致的问题。需要开发全自动、可重复的量化系统，以支持大规模研究和临床诊断阈值校准。

Method: OREHAS整合三个组件：切片分类、内耳定位和序列特异性分割，形成单一工作流。仅需每患者3-6个标注切片进行训练，即可从完整MRI体积中自动计算每耳内淋巴与耳蜗体积比。

Result: 在外部验证队列中，OREHAS Dice分数达0.90（SPACE-MRC）和0.75（REAL-IR），与专家标注高度一致（VSI=74.3%），显著优于临床软件syngo.via（VSI=42.5%）。内淋巴体积测量更小且更符合生理实际。

Conclusion: OREHAS证明了仅需有限监督即可从标准MRI实现可靠、可重复的内淋巴积水量化。该系统减少操作者依赖，确保方法一致性，为大规模研究和临床诊断阈值校准提供坚实基础。

Abstract: We present OREHAS (Optimized Recognition & Evaluation of volumetric Hydrops in the Auditory System), the first fully automatic pipeline for volumetric quantification of endolymphatic hydrops (EH) from routine 3D-SPACE-MRC and 3D-REAL-IR MRI. The system integrates three components -- slice classification, inner ear localization, and sequence-specific segmentation -- into a single workflow that computes per-ear endolymphatic-to-vestibular volume ratios (ELR) directly from whole MRI volumes, eliminating the need for manual intervention.
  Trained with only 3 to 6 annotated slices per patient, OREHAS generalized effectively to full 3D volumes, achieving Dice scores of 0.90 for SPACE-MRC and 0.75 for REAL-IR. In an external validation cohort with complete manual annotations, OREHAS closely matched expert ground truth (VSI = 74.3%) and substantially outperformed the clinical syngo.via software (VSI = 42.5%), which tended to overestimate endolymphatic volumes. Across 19 test patients, vestibular measurements from OREHAS were consistent with syngo.via, while endolymphatic volumes were systematically smaller and more physiologically realistic.
  These results show that reliable and reproducible EH quantification can be achieved from standard MRI using limited supervision. By combining efficient deep-learning-based segmentation with a clinically aligned volumetric workflow, OREHAS reduces operator dependence, ensures methodological consistency. Besides, the results are compatible with established imaging protocols. The approach provides a robust foundation for large-scale studies and for recalibrating clinical diagnostic thresholds based on accurate volumetric measurements of the inner ear.

</details>


### [135] [Gaze Prediction in Virtual Reality Without Eye Tracking Using Visual and Head Motion Cues](https://arxiv.org/abs/2601.18372)
*Christos Petrou,Harris Partaourides,Athanasios Balomenos,Yannis Kopsinis,Sotirios Chatzis*

Main category: cs.CV

TL;DR: 提出结合HMD运动信号和视觉显著性的轻量级VR注视预测框架，在无直接眼动追踪条件下提升预测性能


<details>
  <summary>Details</summary>
Motivation: VR应用中注视预测对减少延迟和实现注视点渲染等技术至关重要，但直接眼动追踪常因硬件限制或隐私问题不可用

Method: 使用UniSal轻量级显著性编码器提取视频帧视觉特征，与HMD运动数据融合，通过TSMixer和LSTM时间序列预测模块预测未来注视方向

Result: 在EHTask数据集和商用VR硬件上的实验表明，该方法优于Center-of-HMD和Mean Gaze等基线方法

Conclusion: 该预测性注视建模方法能有效减少感知延迟，增强在直接眼动追踪受限的VR环境中的自然交互

Abstract: Gaze prediction plays a critical role in Virtual Reality (VR) applications by reducing sensor-induced latency and enabling computationally demanding techniques such as foveated rendering, which rely on anticipating user attention. However, direct eye tracking is often unavailable due to hardware limitations or privacy concerns. To address this, we present a novel gaze prediction framework that combines Head-Mounted Display (HMD) motion signals with visual saliency cues derived from video frames. Our method employs UniSal, a lightweight saliency encoder, to extract visual features, which are then fused with HMD motion data and processed through a time-series prediction module. We evaluate two lightweight architectures, TSMixer and LSTM, for forecasting future gaze directions. Experiments on the EHTask dataset, along with deployment on commercial VR hardware, show that our approach consistently outperforms baselines such as Center-of-HMD and Mean Gaze. These results demonstrate the effectiveness of predictive gaze modeling in reducing perceptual lag and enhancing natural interaction in VR environments where direct eye tracking is constrained.

</details>


### [136] [Estimation of geometric transformation matrices using grid-shaped pilot signals](https://arxiv.org/abs/2601.18385)
*Rinka Kawano,Masaki Kawamura*

Main category: cs.CV

TL;DR: 提出一种基于网格形导频信号的数字水印方法，通过分析图像几何变换后导频网格的变形来估计变换矩阵，实现对裁剪等几何攻击的鲁棒同步。


<details>
  <summary>Details</summary>
Motivation: 现有数字水印方法对裁剪攻击的鲁棒性不足，而裁剪会改变图像原点，使得水印同步变得困难。需要一种能够准确检测几何变换（特别是裁剪）以实现水印正确提取的方法。

Method: 在图像中嵌入网格形导频信号，水平和垂直线采用不同编码。当图像经过几何变换时，网格也随之变形。通过Radon变换分析变形网格的角度和间隔，估计变换矩阵。不同编码的网格线有助于确定网格方向，减少歧义。

Result: 通过各向异性缩放、旋转、剪切和裁剪等攻击的仿真实验表明，该方法能够准确估计变换矩阵，在单一攻击和复合攻击下均表现出低误差。

Conclusion: 提出的基于导频信号的数字水印方法能够有效估计几何变换，实现对裁剪等几何攻击的鲁棒同步，解决了现有方法在裁剪攻击下的不足。

Abstract: Digital watermarking techniques are essential to prevent unauthorized use of images. Since pirated images are often geometrically distorted by operations such as scaling and cropping, accurate synchronization - detecting the embedding position of the watermark - is critical for proper extraction. In particular, cropping changes the origin of the image, making synchronization difficult. However, few existing methods are robust against cropping. To address this issue, we propose a watermarking method that estimates geometric transformations applied to a stego image using a pilot signal, allowing synchronization even after cropping. A grid-shaped pilot signal with distinct horizontal and vertical values is embedded in the image. When the image is transformed, the grid is also distorted. By analyzing this distortion, the transformation matrix can be estimated. Applying the Radon transform to the distorted image allows estimation of the grid angles and intervals. In addition, since the horizontal and vertical grid lines are encoded differently, the grid orientation can be determined, which reduces ambiguity. To validate our method, we performed simulations with anisotropic scaling, rotation, shearing, and cropping. The results show that the proposed method accurately estimates transformation matrices with low error under both single and composite attacks.

</details>


### [137] [ARMOR: Agentic Reasoning for Methods Orchestration and Reparameterization for Robust Adversarial Attacks](https://arxiv.org/abs/2601.18386)
*Gabriel Lee Jun Rong,Christos Korgialas,Dion Jia Xu Ho,Pai Chet Ng,Xiaoxiao Miao,Konstantinos N. Plataniotis*

Main category: cs.CV

TL;DR: ARMOR框架使用VLM和LLM智能协调三种对抗攻击方法，通过实时调整参数和语义感知提升攻击效果


<details>
  <summary>Details</summary>
Motivation: 现有自动化攻击套件采用静态固定序列，缺乏战略适应性和语义感知能力，需要更智能的攻击协调框架

Method: 使用VLM引导的智能体协调CW、JSMA和STA三种对抗攻击方法，通过共享的"Mixing Desk"生成和合成扰动，LLM实时调整参数

Result: 在标准基准测试中，ARMOR实现了改进的跨架构迁移性，可靠地欺骗黑白盒目标，使用置信度和SSIM分数选择最佳攻击

Conclusion: ARMOR框架通过智能体协调和语义感知显著提升了对抗攻击的效果和适应性

Abstract: Existing automated attack suites operate as static ensembles with fixed sequences, lacking strategic adaptation and semantic awareness. This paper introduces the Agentic Reasoning for Methods Orchestration and Reparameterization (ARMOR) framework to address these limitations. ARMOR orchestrates three canonical adversarial primitives, Carlini-Wagner (CW), Jacobian-based Saliency Map Attack (JSMA), and Spatially Transformed Attacks (STA) via Vision Language Models (VLM)-guided agents that collaboratively generate and synthesize perturbations through a shared ``Mixing Desk". Large Language Models (LLMs) adaptively tune and reparameterize parallel attack agents in a real-time, closed-loop system that exploits image-specific semantic vulnerabilities. On standard benchmarks, ARMOR achieves improved cross-architecture transfer and reliably fools both settings, delivering a blended output for blind targets and selecting the best attack or blended attacks for white-box targets using a confidence-and-SSIM score.

</details>


### [138] [Efficient Complex-Valued Vision Transformers for MRI Classification Directly from k-Space](https://arxiv.org/abs/2601.18392)
*Moritz Rempe,Lukas T. Rotkopf,Marco Schlimbach,Helmut Becker,Fabian Hörst,Johannes Haubold,Philipp Dammann,Kevin Kröninger,Jens Kleesiek*

Main category: cs.CV

TL;DR: 提出kViT，一种直接在k空间数据上进行分类的复数视觉Transformer，通过径向k空间分块策略解决传统架构与MRI物理不匹配的问题，在保持性能的同时大幅降低计算资源消耗。


<details>
  <summary>Details</summary>
Motivation: 当前MRI深度学习应用主要基于重建后的幅度图像，这丢弃了相位信息且需要计算昂贵的变换。传统神经网络架构（卷积或网格分块）不适合k空间数据的全局、非局部特性。

Method: 提出复数视觉Transformer（kViT），设计径向k空间分块策略以尊重频域能量分布，直接在k空间数据上进行分类，避免图像重建过程。

Result: 在fastMRI和内部数据集上，kViT达到与图像域SOTA基线（ResNet、EfficientNet、ViT）相当的分类性能，对高加速因子表现出更强鲁棒性，训练时VRAM消耗降低高达68倍。

Conclusion: kViT为资源高效的直接扫描仪AI分析开辟了新途径，通过直接在k空间操作避免了图像重建的计算开销，同时保持了分类性能。

Abstract: Deep learning applications in Magnetic Resonance Imaging (MRI) predominantly operate on reconstructed magnitude images, a process that discards phase information and requires computationally expensive transforms. Standard neural network architectures rely on local operations (convolutions or grid-patches) that are ill-suited for the global, non-local nature of raw frequency-domain (k-Space) data. In this work, we propose a novel complex-valued Vision Transformer (kViT) designed to perform classification directly on k-Space data. To bridge the geometric disconnect between current architectures and MRI physics, we introduce a radial k-Space patching strategy that respects the spectral energy distribution of the frequency-domain. Extensive experiments on the fastMRI and in-house datasets demonstrate that our approach achieves classification performance competitive with state-of-the-art image-domain baselines (ResNet, EfficientNet, ViT). Crucially, kViT exhibits superior robustness to high acceleration factors and offers a paradigm shift in computational efficiency, reducing VRAM consumption during training by up to 68$\times$ compared to standard methods. This establishes a pathway for resource-efficient, direct-from-scanner AI analysis.

</details>


### [139] [Larger than memory image processing](https://arxiv.org/abs/2601.18407)
*Jon Sporring,David Stansby*

Main category: cs.CV

TL;DR: 针对PB级图像数据的内存外分析，提出基于流式处理的架构，通过切片流式执行、窗口操作和重叠感知分块最小化I/O，并设计DSL自动优化流水线调度。


<details>
  <summary>Details</summary>
Motivation: 处理PB级大型图像数据集（如1.4PB电子显微镜体积和150TB人体器官图谱）时面临内存不足问题，性能主要受I/O限制，需要高效的内存外分析方法。

Method: 采用流式处理架构，支持切片和分块两种数据表示；提出基于扫描的执行、窗口操作和重叠感知分块技术；设计领域特定语言（DSL）自动优化流水线调度、窗口大小选择和内存使用。

Result: 实现了近线性的I/O扫描和可预测的内存占用，显著提升超大型图像处理的吞吐量，无需全量数据驻留内存，与现有分割和形态学工具集成。

Conclusion: 流式处理架构是处理PB级图像数据的关键，通过DSL自动优化流水线调度，在有限内存条件下实现高效I/O，为超大规模图像分析提供可行方案。

Abstract: This report addresses larger-than-memory image analysis for petascale datasets such as 1.4 PB electron-microscopy volumes and 150 TB human-organ atlases. We argue that performance is fundamentally I/O-bound. We show that structuring analysis as streaming passes over data is crucial. For 3D volumes, two representations are popular: stacks of 2D slices (e.g., directories or multi-page TIFF) and 3D chunked layouts (e.g., Zarr/HDF5). While for a few algorithms, chunked layout on disk is crucial to keep disk I/O at a minimum, we show how the slice-based streaming architecture can be built on top of either image representation in a manner that minimizes disk I/O. This is in particular advantageous for algorithms relying on neighbouring values, since the slicing streaming architecture is 1D, which implies that there are only 2 possible sweeping orders, both of which are aligned with the order in which images are read from the disk. This is in contrast to 3D chunks, in which any sweep cannot be done without accessing each chunk at least 9 times. We formalize this with sweep-based execution (natural 2D/3D orders), windowed operations, and overlap-aware tiling to minimize redundant access. Building on these principles, we introduce a domain-specific language (DSL) that encodes algorithms with intrinsic knowledge of their optimal streaming and memory use; the DSL performs compile-time and run-time pipeline analyses to automatically select window sizes, fuse stages, tee and zip streams, and schedule passes for limited-RAM machines, yielding near-linear I/O scans and predictable memory footprints. The approach integrates with existing tooling for segmentation and morphology but reframes pre/post-processing as pipelines that privilege sequential read/write patterns, delivering substantial throughput gains for extremely large images without requiring full-volume residency in memory.

</details>


### [140] [3DGesPolicy: Phoneme-Aware Holistic Co-Speech Gesture Generation Based on Action Control](https://arxiv.org/abs/2601.18451)
*Xuanmeng Sha,Liyun Zhang,Tomohiro Mashita,Naoya Chiba,Yuki Uranishi*

Main category: cs.CV

TL;DR: 3DGesPolicy：基于扩散策略的动作框架，通过将整体手势生成重新定义为连续轨迹控制问题，解决了现有方法中身体运动语义不协调和空间不稳定问题，实现了语音、身体动作和面部表情的细粒度对齐。


<details>
  <summary>Details</summary>
Motivation: 现有整体协同手势生成方法存在两个主要问题：1) 身体运动与面部表情语义不协调，2) 空间不稳定无意义运动。这是由于现有方法采用部分分解或帧级回归方法导致的。

Method: 提出3DGesPolicy框架：1) 将整体手势生成重新定义为连续轨迹控制问题，采用机器人学中的扩散策略；2) 将帧间变化建模为统一的整体动作，学习帧间整体手势运动模式；3) 提出Gesture-Audio-Phoneme融合模块，深度整合多模态信号，实现语音语义、身体运动和面部表情的结构化细粒度对齐。

Result: 在BEAT2数据集上的大量定量和定性实验表明，3DGesPolicy在生成自然、富有表现力且高度语音对齐的整体手势方面优于其他最先进方法。

Conclusion: 3DGesPolicy通过动作框架和GAP融合模块，有效解决了整体协同手势生成中的语义协调和空间稳定性问题，实现了更自然、表达力更强的语音驱动手势生成。

Abstract: Generating holistic co-speech gestures that integrate full-body motion with facial expressions suffers from semantically incoherent coordination on body motion and spatially unstable meaningless movements due to existing part-decomposed or frame-level regression methods, We introduce 3DGesPolicy, a novel action-based framework that reformulates holistic gesture generation as a continuous trajectory control problem through diffusion policy from robotics. By modeling frame-to-frame variations as unified holistic actions, our method effectively learns inter-frame holistic gesture motion patterns and ensures both spatially and semantically coherent movement trajectories that adhere to realistic motion manifolds. To further bridge the gap in expressive alignment, we propose a Gesture-Audio-Phoneme (GAP) fusion module that can deeply integrate and refine multi-modal signals, ensuring structured and fine-grained alignment between speech semantics, body motion, and facial expressions. Extensive quantitative and qualitative experiments on the BEAT2 dataset demonstrate the effectiveness of our 3DGesPolicy across other state-of-the-art methods in generating natural, expressive, and highly speech-aligned holistic gestures.

</details>


### [141] [Comparative Evaluation of Machine Learning Algorithms for Affective State Recognition from Children's Drawings](https://arxiv.org/abs/2601.18414)
*Aura Loredana Dan*

Main category: cs.CV

TL;DR: 该论文比较了三种深度学习架构（MobileNet、EfficientNet、VGG16）在儿童绘画情感识别任务中的性能，特别关注分类准确性、鲁棒性和计算效率的权衡。


<details>
  <summary>Details</summary>
Motivation: 自闭症谱系障碍（ASD）儿童在情感表达和沟通方面存在困难，传统评估方法通常具有侵入性、主观性或难以一致应用。需要开发非侵入性的情感状态识别方法，特别是在早期儿童阶段。

Method: 使用迁移学习在心理学专家标注的儿童绘画数据集上训练三种深度学习架构：MobileNet、EfficientNet和VGG16。在统一的实验框架下比较这些模型的分类性能、鲁棒性和计算效率。

Result: 研究结果突出了轻量级架构和深层架构在基于绘画的情感计算任务中的权衡，特别是在移动和实时应用场景下。不同架构在准确性、计算效率和鲁棒性方面表现出不同的优势。

Conclusion: 该研究为儿童情感状态识别提供了基于机器学习的解决方案，特别强调了在移动和实时应用场景中模型选择时需要权衡计算效率和分类性能。为ASD儿童的早期情感评估提供了非侵入性工具。

Abstract: Autism spectrum disorder (ASD) represents a neurodevelopmental condition characterized by difficulties in expressing emotions and communication, particularly during early childhood. Understanding the affective state of children at an early age remains challenging, as conventional assessment methods are often intrusive, subjective, or difficult to apply consistently. This paper builds upon previous work on affective state recognition from children's drawings by presenting a comparative evaluation of machine learning models for emotion classification. Three deep learning architectures -- MobileNet, EfficientNet, and VGG16 -- are evaluated within a unified experimental framework to analyze classification performance, robustness, and computational efficiency. The models are trained using transfer learning on a dataset of children's drawings annotated with emotional labels provided by psychological experts. The results highlight important trade-offs between lightweight and deeper architectures when applied to drawing-based affective computing tasks, particularly in mobile and real-time application contexts.

</details>


### [142] [Fair-Eye Net: A Fair, Trustworthy, Multimodal Integrated Glaucoma Full Chain AI System](https://arxiv.org/abs/2601.18464)
*Wenbin Wei,Suyuan Yao,Cheng Huang,Xiangyu Gao*

Main category: cs.CV

TL;DR: Fair-Eye Net是一个公平的多模态AI系统，用于青光眼筛查到随访的完整临床流程，通过异构融合架构整合多种数据，减少诊断差异，实现早期风险预警。


<details>
  <summary>Details</summary>
Motivation: 青光眼是全球不可逆失明的主要原因，但现有筛查方法依赖单一测试或松散关联的检查，存在主观性和碎片化问题。高质量成像工具和专家资源的有限获取进一步影响了诊断的一致性和公平性。

Method: 开发了Fair-Eye Net系统，采用双流异构融合架构整合眼底照片、OCT结构指标、VF功能指数和人口统计学因素。使用不确定性感知的分层门控策略进行选择性预测和安全转诊，并通过公平性约束减少弱势亚组的漏诊。

Result: 系统达到AUC 0.912（特异性96.7%），将种族假阴性差异减少73.4%（从12.31%降至3.28%），保持稳定的跨域性能，并实现3-12个月的早期风险预警（敏感性92%，特异性88%）。

Conclusion: Fair-Eye Net将公平性作为主要目标与临床可靠性通过多任务学习优化，提供了临床转化和大规模部署的可重复路径，有助于推进全球眼健康公平。

Abstract: Glaucoma is a top cause of irreversible blindness globally, making early detection and longitudinal follow-up pivotal to preventing permanent vision loss. Current screening and progression assessment, however, rely on single tests or loosely linked examinations, introducing subjectivity and fragmented care. Limited access to high-quality imaging tools and specialist expertise further compromises consistency and equity in real-world use. To address these gaps, we developed Fair-Eye Net, a fair, reliable multimodal AI system closing the clinical loop from glaucoma screening to follow-up and risk alerting. It integrates fundus photos, OCT structural metrics, VF functional indices, and demographic factors via a dual-stream heterogeneous fusion architecture, with an uncertainty-aware hierarchical gating strategy for selective prediction and safe referral. A fairness constraint reduces missed diagnoses in disadvantaged subgroups. Experimental results show it achieved an AUC of 0.912 (96.7% specificity), cut racial false-negativity disparity by 73.4% (12.31% to 3.28%), maintained stable cross-domain performance, and enabled 3-12 months of early risk alerts (92% sensitivity, 88% specificity). Unlike post hoc fairness adjustments, Fair-Eye Net optimizes fairness as a primary goal with clinical reliability via multitask learning, offering a reproducible path for clinical translation and large-scale deployment to advance global eye health equity.

</details>


### [143] [On Procrustes Contamination in Machine Learning Applications of Geometric Morphometrics](https://arxiv.org/abs/2601.18448)
*Lloyd Austin Courtenay*

Main category: cs.CV

TL;DR: 该论文指出GPA预处理在机器学习中会导致数据污染，提出了新的重对齐方法，并通过模拟实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统GMM分析中，通常先对所有样本进行GPA对齐，再将数据分为训练集和测试集，这种做法可能导致统计依赖性，污染下游预测模型。

Method: 提出新的重对齐方法：测试集样本在模型拟合前先与训练集对齐，消除跨样本依赖性。通过2D和3D模拟实验，在不同样本量、地标密度和异速生长模式下验证效果。

Result: 模拟实验揭示了样本量与地标空间之间的"对角线"关系，反映了各向同性变异下RMSE的缩放规律。空间自相关对模型性能有重要影响，忽略地标关系会导致性能下降。

Conclusion: GMM在机器学习应用中需要仔细的预处理，提供了实用的重对齐指南，并阐明了Procrustes形状空间固有的基本统计约束。

Abstract: Geometric morphometrics (GMM) is widely used to quantify shape variation, more recently serving as input for machine learning (ML) analyses. Standard practice aligns all specimens via Generalized Procrustes Analysis (GPA) prior to splitting data into training and test sets, potentially introducing statistical dependence and contaminating downstream predictive models. Here, the effects of GPA-induced contamination are formally characterised using controlled 2D and 3D simulations across varying sample sizes, landmark densities, and allometric patterns. A novel realignment procedure is proposed, whereby test specimens are aligned to the training set prior to model fitting, eliminating cross-sample dependency. Simulations reveal a robust "diagonal" in sample-size vs. landmark-space, reflecting the scaling of RMSE under isotropic variation, with slopes analytically derived from the degrees of freedom in Procrustes tangent space. The importance of spatial autocorrelation among landmarks is further demonstrated using linear and convolutional regression models, highlighting performance degradation when landmark relationships are ignored. This work establishes the need for careful preprocessing in ML applications of GMM, provides practical guidelines for realignment, and clarifies fundamental statistical constraints inherent to Procrustes shape space.

</details>


### [144] [Low Cost, High Efficiency: LiDAR Place Recognition in Vineyards with Matryoshka Representation Learning](https://arxiv.org/abs/2601.18714)
*Judith Vilella-Cantos,Mauro Martini,Marcello Chiaberge,Mónica Ballesta,David Valiente*

Main category: cs.CV

TL;DR: 提出MinkUNeXt-VINE轻量级深度学习方法，通过预处理和Matryoshka表示学习多损失方法，在葡萄园环境中超越现有方法，实现低成本稀疏LiDAR输入的高效实时定位。


<details>
  <summary>Details</summary>
Motivation: 农业环境缺乏结构化特征和显著地标，使得移动机器人定位具有挑战性。虽然农业场景在物体分类和分割方面已有研究，但当前技术中地点识别任务仍不成熟。

Method: 提出MinkUNeXt-VINE方法，采用预处理和Matryoshka表示学习多损失方法，专注于低成本稀疏LiDAR输入和低维输出，确保实时场景下的高效率。

Result: 方法在葡萄园环境中超越现有技术，在低成本低分辨率输入数据上表现出鲁棒性能，通过综合消融研究验证了其效率权衡输出的有效性。

Conclusion: MinkUNeXt-VINE为农业环境中的地点识别提供了高效解决方案，在实时场景下表现出色，代码已公开供复现。

Abstract: Localization in agricultural environments is challenging due to their unstructured nature and lack of distinctive landmarks. Although agricultural settings have been studied in the context of object classification and segmentation, the place recognition task for mobile robots is not trivial in the current state of the art. In this study, we propose MinkUNeXt-VINE, a lightweight, deep-learning-based method that surpasses state-of-the-art methods in vineyard environments thanks to its pre-processing and Matryoshka Representation Learning multi-loss approach. Our method prioritizes enhanced performance with low-cost, sparse LiDAR inputs and lower-dimensionality outputs to ensure high efficiency in real-time scenarios. Additionally, we present a comprehensive ablation study of the results on various evaluation cases and two extensive long-term vineyard datasets employing different LiDAR sensors. The results demonstrate the efficiency of the trade-off output produced by this approach, as well as its robust performance on low-cost and low-resolution input data. The code is publicly available for reproduction.

</details>


### [145] [DisasterInsight: A Multimodal Benchmark for Function-Aware and Grounded Disaster Assessment](https://arxiv.org/abs/2601.18493)
*Sara Tehrani,Yonghao Xu,Leif Haglund,Amanda Berg,Michael Felsberg*

Main category: cs.CV

TL;DR: DisasterInsight是一个针对灾害响应的遥感视觉语言基准测试，重构xBD数据集为11.2万个建筑中心实例，支持多种任务评估，并提出了DI-Chat模型作为领域适应基线。


<details>
  <summary>Details</summary>
Motivation: 现有遥感视觉语言基准主要关注粗粒度标签和图像级识别，缺乏对灾害响应实际工作流程所需的功能理解和指令鲁棒性评估。

Method: 1) 重构xBD数据集为约112K建筑中心实例；2) 提出DI-Chat模型，通过LoRA参数高效微调现有VLM骨干网络；3) 支持建筑功能分类、损坏等级分类、灾害类型分类、计数和结构化报告生成等多任务评估。

Result: DI-Chat在损坏等级分类、灾害类型分类和报告生成质量方面显著提升，但建筑功能分类对所有评估模型仍具挑战性。现有通用和遥感VLM在损坏理解和结构化报告生成方面存在明显性能差距。

Conclusion: DisasterInsight为研究灾害图像中的基础多模态推理提供了统一基准，揭示了当前VLM在灾害分析任务中的局限性，并为领域适应方法提供了验证平台。

Abstract: Timely interpretation of satellite imagery is critical for disaster response, yet existing vision-language benchmarks for remote sensing largely focus on coarse labels and image-level recognition, overlooking the functional understanding and instruction robustness required in real humanitarian workflows. We introduce DisasterInsight, a multimodal benchmark designed to evaluate vision-language models (VLMs) on realistic disaster analysis tasks. DisasterInsight restructures the xBD dataset into approximately 112K building-centered instances and supports instruction-diverse evaluation across multiple tasks, including building-function classification, damage-level and disaster-type classification, counting, and structured report generation aligned with humanitarian assessment guidelines.
  To establish domain-adapted baselines, we propose DI-Chat, obtained by fine-tuning existing VLM backbones on disaster-specific instruction data using parameter-efficient Low-Rank Adaptation (LoRA). Extensive experiments on state-of-the-art generic and remote-sensing VLMs reveal substantial performance gaps across tasks, particularly in damage understanding and structured report generation. DI-Chat achieves significant improvements on damage-level and disaster-type classification as well as report generation quality, while building-function classification remains challenging for all evaluated models. DisasterInsight provides a unified benchmark for studying grounded multimodal reasoning in disaster imagery.

</details>


### [146] [From Cold Start to Active Learning: Embedding-Based Scan Selection for Medical Image Segmentation](https://arxiv.org/abs/2601.18532)
*Devon Levy,Bar Assayag,Laura Gaspar,Ilan Shimshoni,Bella Specktor-Fadida*

Main category: cs.CV

TL;DR: 提出一种结合基础模型嵌入与聚类的主动学习冷启动策略，以及整合空间多样性的不确定性主动学习框架，在医学图像分割中显著提升低数据场景下的分割精度。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割需要大量标注数据，但人工标注耗时且需要专业知识。主动学习通过优先标注信息量大的样本来缓解这一问题，但传统的冷启动策略和不确定性选择方法仍有改进空间。

Method: 1) 新颖的冷启动策略：结合基础模型嵌入与聚类，自动选择聚类数量并按比例采样，构建多样且有代表性的初始训练集；2) 不确定性主动学习框架：整合空间多样性指导样本选择；3) 提供直观可解释的候选样本特征空间分布可视化。

Result: 在三个数据集上评估：1) CheXmask数据集：冷启动策略将Dice从0.918提升至0.929，Hausdorff距离从32.41mm降至27.66mm；主动学习将Dice从0.919提升至0.939，Hausdorff距离从30.10mm降至19.16mm；2) Montgomery数据集：冷启动将Dice从0.928提升至0.950，Hausdorff距离从14.22mm降至9.38mm；3) SynthStrip数据集：冷启动略微影响Dice但降低Hausdorff距离，主动学习提升Dice并降低Hausdorff距离。

Conclusion: 提出的框架在低数据场景下持续优于基线方法，显著提升分割精度，为医学图像分割中的主动学习提供了有效的冷启动和样本选择策略。

Abstract: Accurate segmentation annotations are critical for disease monitoring, yet manual labeling remains a major bottleneck due to the time and expertise required. Active learning (AL) alleviates this burden by prioritizing informative samples for annotation, typically through a diversity-based cold-start phase followed by uncertainty-driven selection. We propose a novel cold-start sampling strategy that combines foundation-model embeddings with clustering, including automatic selection of the number of clusters and proportional sampling across clusters, to construct a diverse and representative initial training. This is followed by an uncertainty-based AL framework that integrates spatial diversity to guide sample selection. The proposed method is intuitive and interpretable, enabling visualization of the feature-space distribution of candidate samples. We evaluate our approach on three datasets spanning X-ray and MRI modalities. On the CheXmask dataset, the cold-start strategy outperforms random selection, improving Dice from 0.918 to 0.929 and reducing the Hausdorff distance from 32.41 to 27.66 mm. In the AL setting, combined entropy and diversity selection improves Dice from 0.919 to 0.939 and reduces the Hausdorff distance from 30.10 to 19.16 mm. On the Montgomery dataset, cold-start gains are substantial, with Dice improving from 0.928 to 0.950 and Hausdorff distance decreasing from 14.22 to 9.38 mm. On the SynthStrip dataset, cold-start selection slightly affects Dice but reduces the Hausdorff distance from 9.43 to 8.69 mm, while active learning improves Dice from 0.816 to 0.826 and reduces the Hausdorff distance from 7.76 to 6.38 mm. Overall, the proposed framework consistently outperforms baseline methods in low-data regimes, improving segmentation accuracy.

</details>


### [147] [SeNeDiF-OOD: Semantic Nested Dichotomy Fusion for Out-of-Distribution Detection Methodology in Open-World Classification. A Case Study on Monument Style Classification](https://arxiv.org/abs/2601.18739)
*Ignacio Antequera-Sánchez,Juan Luis Suárez-Díaz,Rosana Montes,Francisco Herrera*

Main category: cs.CV

TL;DR: 提出SeNeDiF-OOD方法，通过语义嵌套二分融合的层次结构解决OOD检测中异质数据（从低级损坏到语义偏移）的挑战，在MonuMAI建筑风格识别系统中验证效果显著优于传统基线。


<details>
  <summary>Details</summary>
Motivation: 开放世界环境中AI应用的可靠部署需要有效的OOD检测，但OOD数据的异质性（从低级损坏到语义偏移）使得单阶段检测器难以应对，需要更精细的检测方法。

Method: 提出基于语义嵌套二分融合（SeNeDiF-OOD）的层次框架，将检测任务分解为二进制融合节点的层次结构，每层集成与特定语义抽象级别对齐的决策边界。

Result: 在MonuMAI建筑风格识别系统的实际案例研究中，该方法显著优于传统基线，能有效过滤非纪念碑图像、未知建筑风格和对抗攻击等多样化OOD类别，同时保持分布内性能。

Conclusion: SeNeDiF-OOD的层次融合方法为解决OOD检测中的异质数据挑战提供了有效方案，在开放世界环境中展现出优越的检测性能。

Abstract: Out-of-distribution (OOD) detection is a fundamental requirement for the reliable deployment of artificial intelligence applications in open-world environments. However, addressing the heterogeneous nature of OOD data, ranging from low-level corruption to semantic shifts, remains a complex challenge that single-stage detectors often fail to resolve. To address this issue, we propose SeNeDiF-OOD, a novel methodology based on Semantic Nested Dichotomy Fusion. This framework decomposes the detection task into a hierarchical structure of binary fusion nodes, where each layer is designed to integrate decision boundaries aligned with specific levels of semantic abstraction. To validate the proposed framework, we present a comprehensive case study using MonuMAI, a real-world architectural style recognition system exposed to an open environment. This application faces a diverse range of inputs, including non-monument images, unknown architectural styles, and adversarial attacks, making it an ideal testbed for our proposal. Through extensive experimental evaluation in this domain, results demonstrate that our hierarchical fusion methodology significantly outperforms traditional baselines, effectively filtering these diverse OOD categories while preserving in-distribution performance.

</details>


### [148] [GenAgent: Scaling Text-to-Image Generation via Agentic Multimodal Reasoning](https://arxiv.org/abs/2601.18543)
*Kaixun Jiang,Yuzheng Wang,Junjie Zhou,Pandeng Li,Zhihang Liu,Chen-Wei Xie,Zhaoyu Chen,Yun Zheng,Wenqiang Zhang*

Main category: cs.CV

TL;DR: GenAgent是一个通过智能体框架统一视觉理解和生成的模型，它将理解任务交给多模态模型处理，而将生成任务委托给图像生成模型作为可调用工具，通过自主多轮交互迭代优化输出。


<details>
  <summary>Details</summary>
Motivation: 现有统一模型面临昂贵的训练成本以及理解与生成之间的权衡问题，而现有的模块化系统又受限于静态流水线。需要一种既能统一视觉理解与生成，又能支持自主多轮交互的智能体框架。

Method: 采用智能体框架：多模态模型负责理解，图像生成模型作为可调用工具负责生成。使用两阶段训练策略：1) 在高质量工具调用和反思数据上进行监督微调；2) 结合点式奖励（最终图像质量）和成对奖励（反思准确性）的端到端智能体强化学习，并使用轨迹重采样增强多轮探索。

Result: GenAgent显著提升了基础生成器（FLUX.1-dev）在GenEval++（+23.6%）和WISE（+14%）上的性能。框架展现出三个关键特性：1) 跨工具泛化能力；2) 测试时扩展性；3) 任务自适应推理能力。

Conclusion: GenAgent通过智能体框架成功统一了视觉理解和生成，避免了传统统一模型的训练成本和能力权衡问题，同时支持自主多轮交互和迭代优化，在多个基准上取得了显著性能提升。

Abstract: We introduce GenAgent, unifying visual understanding and generation through an agentic multimodal model. Unlike unified models that face expensive training costs and understanding-generation trade-offs, GenAgent decouples these capabilities through an agentic framework: understanding is handled by the multimodal model itself, while generation is achieved by treating image generation models as invokable tools. Crucially, unlike existing modular systems constrained by static pipelines, this design enables autonomous multi-turn interactions where the agent generates multimodal chains-of-thought encompassing reasoning, tool invocation, judgment, and reflection to iteratively refine outputs. We employ a two-stage training strategy: first, cold-start with supervised fine-tuning on high-quality tool invocation and reflection data to bootstrap agent behaviors; second, end-to-end agentic reinforcement learning combining pointwise rewards (final image quality) and pairwise rewards (reflection accuracy), with trajectory resampling for enhanced multi-turn exploration. GenAgent significantly boosts base generator(FLUX.1-dev) performance on GenEval++ (+23.6\%) and WISE (+14\%). Beyond performance gains, our framework demonstrates three key properties: 1) cross-tool generalization to generators with varying capabilities, 2) test-time scaling with consistent improvements across interaction rounds, and 3) task-adaptive reasoning that automatically adjusts to different tasks. Our code will be available at \href{https://github.com/deep-kaixun/GenAgent}{this url}.

</details>


### [149] [REMAC: Reference-Based Martian Asymmetrical Image Compression](https://arxiv.org/abs/2601.18547)
*Qing Ding,Mai Xu,Shengxi Li,Xin Deng,Xin Zou*

Main category: cs.CV

TL;DR: 提出REMAC方法，通过参考图像引导的熵编码和深度解码器架构，在降低火星图像编码器43.51%计算复杂度的同时，提升压缩性能0.2664 dB。


<details>
  <summary>Details</summary>
Motivation: 现有学习方法在火星图像压缩中存在两个关键问题：1) 忽视火星上有限的计算资源；2) 未利用火星图像间强相似性来提升压缩性能。基于对纹理、颜色和语义层面的图像相似性分析，需要开发适合火星环境的压缩方法。

Method: 提出REMAC方法：1) 参考引导熵模块和参考解码器利用参考图像信息；2) 深度多尺度解码器架构建模长距离空间依赖；3) 潜在特征回收机制进一步缓解计算约束；4) 将计算复杂度从编码器转移到资源丰富的解码器。

Result: 相比现有最佳方法，REMAC将编码器复杂度降低43.51%，同时获得0.2664 dB的BD-PSNR增益，在计算效率和压缩性能间取得良好平衡。

Conclusion: REMAC通过利用火星图像间相似性，实现了编码器计算复杂度显著降低和压缩性能提升，为受限通信环境下的火星图像传输提供了有效解决方案。

Abstract: To expedite space exploration on Mars, it is indispensable to develop an efficient Martian image compression method for transmitting images through the constrained Mars-to-Earth communication channel. Although the existing learned compression methods have achieved promising results for natural images from earth, there remain two critical issues that hinder their effectiveness for Martian image compression: 1) They overlook the highly-limited computational resources on Mars; 2) They do not utilize the strong \textit{inter-image} similarities across Martian images to advance image compression performance. Motivated by our empirical analysis of the strong \textit{intra-} and \textit{inter-image} similarities from the perspective of texture, color, and semantics, we propose a reference-based Martian asymmetrical image compression (REMAC) approach, which shifts computational complexity from the encoder to the resource-rich decoder and simultaneously improves compression performance. To leverage \textit{inter-image} similarities, we propose a reference-guided entropy module and a ref-decoder that utilize useful information from reference images, reducing redundant operations at the encoder and achieving superior compression performance. To exploit \textit{intra-image} similarities, the ref-decoder adopts a deep, multi-scale architecture with enlarged receptive field size to model long-range spatial dependencies. Additionally, we develop a latent feature recycling mechanism to further alleviate the extreme computational constraints on Mars. Experimental results show that REMAC reduces encoder complexity by 43.51\% compared to the state-of-the-art method, while achieving a BD-PSNR gain of 0.2664 dB.

</details>


### [150] [Automated Landmark Detection for assessing hip conditions: A Cross-Modality Validation of MRI versus X-ray](https://arxiv.org/abs/2601.18555)
*Roberto Di Via,Vito Paolo Pastore,Francesca Odone,Siôn Glyn-Jones,Irina Voiculescu*

Main category: cs.CV

TL;DR: 该研究验证了使用标准热图回归架构在MRI上实现与X射线相当的髋臼撞击症（FAI）标志点检测和诊断准确性，支持将自动化FAI评估整合到常规MRI工作流程中。


<details>
  <summary>Details</summary>
Motivation: 临床筛查决策常基于角度测量，特别是髋臼撞击症（FAI）筛查传统上依赖X射线角度测量。但评估撞击区域的高度和范围需要MRI扫描的3D视图。两种模态为外科医生提供不同方面的信息，需要验证MRI是否也能实现与X射线相当的定位和诊断准确性。

Method: 采用匹配队列验证研究（89名患者，配对MRI/X射线），使用标准热图回归架构评估跨模态临床等效性。在3D MRI体积的冠状视图中进行FAI评估，通过标志点检测实现定位。

Result: MRI实现了与X射线相当的定位和cam型撞击诊断准确性。该方法在3D MRI体积的冠状视图中展示了FAI评估的临床可行性，为通过放置更多标志点进行体积分析开辟了可能性。

Conclusion: 结果支持将自动化FAI评估整合到常规MRI工作流程中，为髋臼撞击症的跨模态评估提供了有效解决方案，并展示了在MRI上进行体积分析的潜力。

Abstract: Many clinical screening decisions are based on angle measurements. In particular, FemoroAcetabular Impingement (FAI) screening relies on angles traditionally measured on X-rays. However, assessing the height and span of the impingement area requires also a 3D view through an MRI scan. The two modalities inform the surgeon on different aspects of the condition. In this work, we conduct a matched-cohort validation study (89 patients, paired MRI/X-ray) using standard heatmap regression architectures to assess cross-modality clinical equivalence. Seen that landmark detection has been proven effective on X-rays, we show that MRI also achieves equivalent localisation and diagnostic accuracy for cam-type impingement. Our method demonstrates clinical feasibility for FAI assessment in coronal views of 3D MRI volumes, opening the possibility for volumetric analysis through placing further landmarks. These results support integrating automated FAI assessment into routine MRI workflows. Code is released at https://github.com/Malga-Vision/Landmarks-Hip-Conditions

</details>


### [151] [Generative Diffusion Augmentation with Quantum-Enhanced Discrimination for Medical Image Diagnosis](https://arxiv.org/abs/2601.18556)
*Jingsong Xia,Siqi Wang*

Main category: cs.CV

TL;DR: SDA-QEC框架结合简化扩散增强与量子增强分类，解决医学图像分类中的类别不平衡问题，在冠状动脉造影图像分类中取得优异性能。


<details>
  <summary>Details</summary>
Motivation: 真实医学数据集常存在严重类别不平衡问题，导致模型偏向多数类，少数类召回率低，影响诊断准确性并带来临床误诊风险。

Method: 提出SDA-QEC框架：1) 使用轻量级扩散增强器为少数类生成高质量合成样本，平衡训练分布；2) 在MobileNetV2架构中嵌入量子特征层，通过希尔伯特空间的高维特征映射增强模型判别能力。

Result: 在冠状动脉造影图像分类中，SDA-QEC达到98.33%准确率、98.78% AUC和98.33% F1分数，显著优于ResNet18、MobileNetV2、DenseNet121和VGG16等经典基线。同时获得98.33%灵敏度和98.33%特异性，实现临床部署所需的平衡性能。

Conclusion: 该方法验证了在真实医学成像任务中整合生成增强与量子增强建模的可行性，为开发在小样本、高度不平衡和高风险诊断场景中高度可靠的医学AI系统提供了新的研究路径。

Abstract: In biomedical engineering, artificial intelligence has become a pivotal tool for enhancing medical diagnostics, particularly in medical image classification tasks such as detecting pneumonia from chest X-rays and breast cancer screening. However, real-world medical datasets frequently exhibit severe class imbalance, where positive samples substantially outnumber negative samples, leading to biased models with low recall rates for minority classes. This imbalance not only compromises diagnostic accuracy but also poses clinical misdiagnosis risks. To address this challenge, we propose SDA-QEC (Simplified Diffusion Augmentation with Quantum-Enhanced Classification), an innovative framework that integrates simplified diffusion-based data augmentation with quantum-enhanced feature discrimination. Our approach employs a lightweight diffusion augmentor to generate high-quality synthetic samples for minority classes, rebalancing the training distribution. Subsequently, a quantum feature layer embedded within MobileNetV2 architecture enhances the model's discriminative capability through high-dimensional feature mapping in Hilbert space. Comprehensive experiments on coronary angiography image classification demonstrate that SDA-QEC achieves 98.33% accuracy, 98.78% AUC, and 98.33% F1-score, significantly outperforming classical baselines including ResNet18, MobileNetV2, DenseNet121, and VGG16. Notably, our framework simultaneously attains 98.33% sensitivity and 98.33% specificity, achieving a balanced performance critical for clinical deployment. The proposed method validates the feasibility of integrating generative augmentation with quantum-enhanced modeling in real-world medical imaging tasks, offering a novel research pathway for developing highly reliable medical AI systems in small-sample, highly imbalanced, and high-risk diagnostic scenarios.

</details>


### [152] [AI-enabled Satellite Edge Computing: A Single-Pixel Feature based Shallow Classification Model for Hyperspectral Imaging](https://arxiv.org/abs/2601.18560)
*Li Fang,Tianyu Li,Yanghong Lin,Shudong Zhou,Wei Yao*

Main category: cs.CV

TL;DR: 提出一种用于高光谱图像分类的高效AI卫星边缘计算范式，采用轻量级非深度学习框架，结合两阶段像素级标签传播方案，解决卫星资源受限和图像质量问题。


<details>
  <summary>Details</summary>
Motivation: 高光谱成像卫星传输速度成为瓶颈，特别是在灾害监测等需要快速响应的应用中。卫星平台资源受限，且机载处理面临传感器故障和扫描模式错误导致的图像质量问题。

Method: 采用轻量级非深度学习框架，结合少样本学习策略。提出两阶段像素级标签传播方案：第一阶段通过构建锚点-像素亲和矩阵传播选定锚点标签；第二阶段使用稀疏图的闭式解替代迭代计算。开发基于秩约束的图聚类算法确定锚点标签。

Result: 该方法使卫星能够实现自主决策，仅利用单像素级固有光谱特征，无需考虑深度神经网络所需的空间结构信息，适应卫星资源约束和图像质量问题。

Conclusion: 提出的AI卫星边缘计算范式有效解决了高光谱图像分类中的传输瓶颈和资源约束问题，通过轻量级框架和创新的标签传播方案，实现了卫星平台的自主决策能力。

Abstract: As the important component of the Earth observation system, hyperspectral imaging satellites provide high-fidelity and enriched information for the formulation of related policies due to the powerful spectral measurement capabilities. However, the transmission speed of the satellite downlink has become a major bottleneck in certain applications, such as disaster monitoring and emergency mapping, which demand a fast response ability. We propose an efficient AI-enabled Satellite Edge Computing paradigm for hyperspectral image classification, facilitating the satellites to attain autonomous decision-making. To accommodate the resource constraints of satellite platforms, the proposed method adopts a lightweight, non-deep learning framework integrated with a few-shot learning strategy. Moreover, onboard processing on satellites could be faced with sensor failure and scan pattern errors, which result in degraded image quality with bad/misaligned pixels and mixed noise. To address these challenges, we develop a novel two-stage pixel-wise label propagation scheme that utilizes only intrinsic spectral features at the single pixel level without the necessity to consider spatial structural information as requested by deep neural networks. In the first stage, initial pixel labels are obtained by propagating selected anchor labels through the constructed anchor-pixel affinity matrix. Subsequently, a top-k pruned sparse graph is generated by directly computing pixel-level similarities. In the second stage, a closed-form solution derived from the sparse graph is employed to replace iterative computations. Furthermore, we developed a rank constraint-based graph clustering algorithm to determine the anchor labels.

</details>


### [153] [Self-Refining Video Sampling](https://arxiv.org/abs/2601.18577)
*Sangwon Jang,Taekyung Ki,Jaehyeong Jo,Saining Xie,Jaehong Yoon,Sung Ju Hwang*

Main category: cs.CV

TL;DR: 提出自精炼视频采样方法，利用预训练视频生成器自身进行迭代内循环精炼，无需外部验证器或额外训练，显著提升运动连贯性和物理真实性。


<details>
  <summary>Details</summary>
Motivation: 现代视频生成器在复杂物理动态方面仍存在不足，现有方法使用外部验证器或增强数据训练，计算成本高且难以捕捉细粒度运动。

Method: 将预训练视频生成器解释为去噪自编码器，在推理时进行迭代内循环精炼；引入不确定性感知精炼策略，基于自一致性选择性地精炼区域，避免过度精炼导致的伪影。

Result: 在先进视频生成器上的实验表明，运动连贯性和物理对齐显著改善，相比默认采样器和基于引导的采样器获得超过70%的人类偏好。

Conclusion: 自精炼视频采样是一种简单有效的方法，通过利用生成器自身进行迭代精炼，无需额外训练或外部验证器，显著提升了视频生成的物理真实感。

Abstract: Modern video generators still struggle with complex physical dynamics, often falling short of physical realism. Existing approaches address this using external verifiers or additional training on augmented data, which is computationally expensive and still limited in capturing fine-grained motion. In this work, we present self-refining video sampling, a simple method that uses a pre-trained video generator trained on large-scale datasets as its own self-refiner. By interpreting the generator as a denoising autoencoder, we enable iterative inner-loop refinement at inference time without any external verifier or additional training. We further introduce an uncertainty-aware refinement strategy that selectively refines regions based on self-consistency, which prevents artifacts caused by over-refinement. Experiments on state-of-the-art video generators demonstrate significant improvements in motion coherence and physics alignment, achieving over 70\% human preference compared to the default sampler and guidance-based sampler.

</details>


### [154] [GimmBO: Interactive Generative Image Model Merging via Bayesian Optimization](https://arxiv.org/abs/2601.18585)
*Chenxi Liu,Selena Ling,Alec Jacobson*

Main category: cs.CV

TL;DR: GimmBO：基于偏好贝叶斯优化的交互式适配器融合探索工具，用于扩散模型图像生成


<details>
  <summary>Details</summary>
Motivation: 当前基于手动滑块调整的适配器融合方法难以处理大量适配器（20-30个），探索效率低下且难以选择合适权重

Method: 提出GimmBO系统，采用两阶段贝叶斯优化后端，利用偏好贝叶斯优化支持交互式适配器融合探索，考虑真实使用场景中的稀疏性和权重范围约束

Result: 在模拟用户和真实用户研究中均显示改进的收敛性、高成功率，相比贝叶斯优化和线性搜索基线有持续优势，框架具有良好扩展性

Conclusion: GimmBO为扩散模型适配器融合提供了高效的交互式探索工具，解决了高维空间中的权重选择难题

Abstract: Fine-tuning-based adaptation is widely used to customize diffusion-based image generation, leading to large collections of community-created adapters that capture diverse subjects and styles. Adapters derived from the same base model can be merged with weights, enabling the synthesis of new visual results within a vast and continuous design space. To explore this space, current workflows rely on manual slider-based tuning, an approach that scales poorly and makes weight selection difficult, even when the candidate set is limited to 20-30 adapters. We propose GimmBO to support interactive exploration of adapter merging for image generation through Preferential Bayesian Optimization (PBO). Motivated by observations from real-world usage, including sparsity and constrained weight ranges, we introduce a two-stage BO backend that improves sampling efficiency and convergence in high-dimensional spaces. We evaluate our approach with simulated users and a user study, demonstrating improved convergence, high success rates, and consistent gains over BO and line-search baselines, and further show the flexibility of the framework through several extensions.

</details>


### [155] [AGSP-DSA: An Adaptive Graph Signal Processing Framework for Robust Multimodal Fusion with Dynamic Semantic Alignment](https://arxiv.org/abs/2601.18589)
*KV Karthikeya,Ashok Kumar Das,Shantanu Pal,Vivekananda Bhat K,Arun Sekar Rajasekaran*

Main category: cs.CV

TL;DR: 提出AGSP-DSA框架，通过双图构建、谱图滤波和多尺度GCN实现文本、音频、图像等多模态数据的鲁棒融合，在三个基准数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 解决异构多模态数据（文本、音频、图像）融合的挑战，特别是在模态缺失情况下的鲁棒性问题，提升多模态学习在情感分析、事件识别等任务中的性能。

Method: 采用双图构建学习模态内和模态间关系，使用谱图滤波增强信息信号，结合多尺度图卷积网络进行节点嵌入，并引入语义感知注意力机制动态调整各模态贡献。

Result: 在CMU-MOSEI数据集上达到95.3%准确率、0.936 F1分数和0.924 mAP，比MM-GNN提升2.6%准确率；在AVE数据集上达到93.4%准确率和0.911 F1分数；在MM-IMDB数据集上达到91.8%准确率和0.886 F1分数。

Conclusion: AGSP-DSA框架在多模态学习中表现出高效性和鲁棒性，特别是在模态缺失情况下具有良好的泛化能力，为情感分析、事件识别和多媒体分类等任务提供了有效解决方案。

Abstract: In this paper, we introduce an Adaptive Graph Signal Processing with Dynamic Semantic Alignment (AGSP DSA) framework to perform robust multimodal data fusion over heterogeneous sources, including text, audio, and images. The requested approach uses a dual-graph construction to learn both intra-modal and inter-modal relations, spectral graph filtering to boost the informative signals, and effective node embedding with Multi-scale Graph Convolutional Networks (GCNs). Semantic aware attention mechanism: each modality may dynamically contribute to the context with respect to contextual relevance. The experimental outcomes on three benchmark datasets, including CMU-MOSEI, AVE, and MM-IMDB, show that AGSP-DSA performs as the state of the art. More precisely, it achieves 95.3% accuracy, 0.936 F1-score, and 0.924 mAP on CMU-MOSEI, improving MM-GNN by 2.6 percent in accuracy. It gets 93.4% accuracy and 0.911 F1-score on AVE and 91.8% accuracy and 0.886 F1-score on MM-IMDB, which demonstrate good generalization and robustness in the missing modality setting. These findings verify the efficiency of AGSP-DSA in promoting multimodal learning in sentiment analysis, event recognition and multimedia classification.

</details>


### [156] [EFSI-DETR: Efficient Frequency-Semantic Integration for Real-Time Small Object Detection in UAV Imagery](https://arxiv.org/abs/2601.18597)
*Yu Xia,Chang Liu,Tianqi Xiang,Zhigang Tu*

Main category: cs.CV

TL;DR: EFSI-DETR：一种用于无人机图像实时小目标检测的新框架，通过动态频率-空间协同网络和高效语义特征提取器，在VisDrone和CODrone基准测试中实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 无人机图像中的实时小目标检测面临特征表示有限和多尺度融合效果不佳的挑战。现有方法未能充分利用频率信息，依赖静态卷积操作，限制了获取丰富特征表示的能力，阻碍了深度语义特征的有效利用。

Method: 提出EFSI-DETR框架，包含两个主要组件：1) 动态频率-空间统一协同网络(DyFusNet)，联合利用频率和空间线索进行鲁棒的多尺度特征融合；2) 高效语义特征集中器(ESFC)，以最小计算成本实现深度语义提取。此外采用细粒度特征保留(FFR)策略，在融合过程中保留空间丰富的浅层特征以保持细粒度细节。

Result: 在VisDrone和CODrone基准测试中取得最先进性能：VisDrone上AP提升1.6%，AP_s提升5.8%；在单张RTX 4090 GPU上达到188 FPS的推理速度。

Conclusion: EFSI-DETR通过动态频率-空间协同和高效语义特征提取，有效解决了无人机图像中小目标检测的挑战，在保持实时效率的同时显著提升了检测性能。

Abstract: Real-time small object detection in Unmanned Aerial Vehicle (UAV) imagery remains challenging due to limited feature representation and ineffective multi-scale fusion. Existing methods underutilize frequency information and rely on static convolutional operations, which constrain the capacity to obtain rich feature representations and hinder the effective exploitation of deep semantic features. To address these issues, we propose EFSI-DETR, a novel detection framework that integrates efficient semantic feature enhancement with dynamic frequency-spatial guidance. EFSI-DETR comprises two main components: (1) a Dynamic Frequency-Spatial Unified Synergy Network (DyFusNet) that jointly exploits frequency and spatial cues for robust multi-scale feature fusion, (2) an Efficient Semantic Feature Concentrator (ESFC) that enables deep semantic extraction with minimal computational cost. Furthermore, a Fine-grained Feature Retention (FFR) strategy is adopted to incorporate spatially rich shallow features during fusion to preserve fine-grained details, crucial for small object detection in UAV imagery. Extensive experiments on VisDrone and CODrone benchmarks demonstrate that our EFSI-DETR achieves the state-of-the-art performance with real-time efficiency, yielding improvement of \textbf{1.6}\% and \textbf{5.8}\% in AP and AP$_{s}$ on VisDrone, while obtaining \textbf{188} FPS inference speed on a single RTX 4090 GPU.

</details>


### [157] [Scale-Aware Self-Supervised Learning for Segmentation of Small and Sparse Structures](https://arxiv.org/abs/2601.18619)
*Jorge Quesada,Ghassan AlRegib*

Main category: cs.CV

TL;DR: 提出一种尺度感知的自监督学习适配方法，通过小窗口裁剪增强来提升对小尺度、稀疏目标的图像分割性能


<details>
  <summary>Details</summary>
Motivation: 现有自监督学习方法主要针对大尺度、均匀区域进行优化，但在处理小尺度、稀疏或不规则目标时性能下降。需要针对不同尺度目标设计适配的自监督学习策略。

Method: 提出尺度感知的自监督学习适配方法，在数据增强流程中集成小窗口裁剪，在预训练阶段聚焦于精细尺度结构。该方法在两种不同数据模态领域进行验证：地震成像（分割稀疏断层）和神经成像（描绘小细胞结构）。

Result: 在标签受限条件下，该方法相比标准和最先进基线方法取得一致改进：断层分割准确率提升达13%，细胞描绘提升5%。但对于大尺度特征（如地震相或组织区域）几乎没有改善。

Conclusion: 自监督学习的价值关键取决于目标对象的尺度。研究结果强调需要将自监督学习设计与对象大小和稀疏性对齐，为跨科学成像领域构建更有效的表示学习流程提供通用原则。

Abstract: Self-supervised learning (SSL) has emerged as a powerful strategy for representation learning under limited annotation regimes, yet its effectiveness remains highly sensitive to many factors, especially the nature of the target task. In segmentation, existing pipelines are typically tuned to large, homogeneous regions, but their performance drops when objects are small, sparse, or locally irregular. In this work, we propose a scale-aware SSL adaptation that integrates small-window cropping into the augmentation pipeline, zooming in on fine-scale structures during pretraining. We evaluate this approach across two domains with markedly different data modalities: seismic imaging, where the goal is to segment sparse faults, and neuroimaging, where the task is to delineate small cellular structures. In both settings, our method yields consistent improvements over standard and state-of-the-art baselines under label constraints, improving accuracy by up to 13% for fault segmentation and 5% for cell delineation. In contrast, large-scale features such as seismic facies or tissue regions see little benefit, underscoring that the value of SSL depends critically on the scale of the target objects. Our findings highlight the need to align SSL design with object size and sparsity, offering a general principle for buil ding more effective representation learning pipelines across scientific imaging domains.

</details>


### [158] [Adaptive Domain Shift in Diffusion Models for Cross-Modality Image Translation](https://arxiv.org/abs/2601.18623)
*Zihao Wang,Yuzhou Chen,Shaogang Ren*

Main category: cs.CV

TL;DR: 提出一种改进的跨模态图像翻译方法，通过预测空间变化的混合场和注入目标一致性恢复项，解决传统扩散方法中固定调度域转移导致的语义漂移问题。


<details>
  <summary>Details</summary>
Motivation: 传统扩散方法在跨模态图像翻译中采用全局线性域转移，导致采样器偏离流形、增加校正负担并引发语义漂移，这种固定调度域转移限制了翻译效果和效率。

Method: 提出在生成过程中嵌入域转移动态，预测每个反向步骤的空间变化混合场，并向漂移中注入明确的目标一致性恢复项，保持大更新在流形上，将模型角色从全局对齐转向局部残差校正。

Result: 在医学影像、遥感和电致发光语义映射等翻译任务中，该方法提高了结构保真度和语义一致性，同时减少了去噪步骤的收敛时间。

Conclusion: 通过将域转移动态直接嵌入生成过程，提出的方法解决了传统扩散模型中的固定调度域转移问题，实现了更高效、更准确的跨模态图像翻译。

Abstract: Cross-modal image translation remains brittle and inefficient. Standard diffusion approaches often rely on a single, global linear transfer between domains. We find that this shortcut forces the sampler to traverse off-manifold, high-cost regions, inflating the correction burden and inviting semantic drift. We refer to this shared failure mode as fixed-schedule domain transfer. In this paper, we embed domain-shift dynamics directly into the generative process. Our model predicts a spatially varying mixing field at every reverse step and injects an explicit, target-consistent restoration term into the drift. This in-step guidance keeps large updates on-manifold and shifts the model's role from global alignment to local residual correction. We provide a continuous-time formulation with an exact solution form and derive a practical first-order sampler that preserves marginal consistency. Empirically, across translation tasks in medical imaging, remote sensing, and electroluminescence semantic mapping, our framework improves structural fidelity and semantic consistency while converging in fewer denoising steps.

</details>


### [159] [CONQUER: Context-Aware Representation with Query Enhancement for Text-Based Person Search](https://arxiv.org/abs/2601.18625)
*Zequn Xie*

Main category: cs.CV

TL;DR: CONQUER是一个用于文本行人搜索的两阶段框架，通过训练时的跨模态对齐优化和推理时的查询增强，显著提升了检索性能。


<details>
  <summary>Details</summary>
Motivation: 文本行人搜索面临跨模态差异和模糊查询的挑战，现有方法在真实场景中效果有限，需要更鲁棒和实用的解决方案。

Method: 两阶段框架：训练阶段使用多粒度编码、互补对挖掘和基于最优传输的上下文引导匹配；推理阶段通过即插即用的查询增强模块进行锚点选择和属性驱动丰富。

Result: 在CUHK-PEDES、ICFG-PEDES和RSTPReid数据集上，CONQUER在Rank-1准确率和mAP指标上均优于强基线，在跨域和不完整查询场景中表现尤为突出。

Conclusion: CONQUER为文本行人搜索提供了一个实用有效的解决方案，特别适合真实世界部署，代码已开源。

Abstract: Text-Based Person Search (TBPS) aims to retrieve pedestrian images from large galleries using natural language descriptions. This task, essential for public safety applications, is hindered by cross-modal discrepancies and ambiguous user queries. We introduce CONQUER, a two-stage framework designed to address these challenges by enhancing cross-modal alignment during training and adaptively refining queries at inference. During training, CONQUER employs multi-granularity encoding, complementary pair mining, and context-guided optimal matching based on Optimal Transport to learn robust embeddings. At inference, a plug-and-play query enhancement module refines vague or incomplete queries via anchor selection and attribute-driven enrichment, without requiring retraining of the backbone. Extensive experiments on CUHK-PEDES, ICFG-PEDES, and RSTPReid demonstrate that CONQUER consistently outperforms strong baselines in both Rank-1 accuracy and mAP, yielding notable improvements in cross-domain and incomplete-query scenarios. These results highlight CONQUER as a practical and effective solution for real-world TBPS deployment. Source code is available at https://github.com/zqxie77/CONQUER.

</details>


### [160] [Splat-Portrait: Generalizing Talking Heads with Gaussian Splatting](https://arxiv.org/abs/2601.18633)
*Tong Shi,Melonie de Almeida,Daniela Ivanova,Nicolas Pugeault,Paul Henderson*

Main category: cs.CV

TL;DR: Splat-Portrait：基于高斯泼溅的3D说话头生成方法，无需3D监督或运动先验，通过2D重建和分数蒸馏损失实现高质量说话动画合成


<details>
  <summary>Details</summary>
Motivation: 现有3D说话头生成方法依赖领域特定的启发式方法（如基于形变的面部运动表示先验），导致3D头像重建不准确，影响动画真实感。需要一种能同时解决3D头部重建和唇部运动合成挑战的方法。

Method: 提出Splat-Portrait方法：1）使用高斯泼溅表示静态3D重建；2）自动学习将单张肖像图像解耦为静态高斯泼溅表示和预测的2D背景；3）基于输入音频生成自然的唇部运动，无需任何运动驱动先验；4）训练仅使用2D重建和分数蒸馏损失，无需3D监督或面部关键点。

Result: 实验结果表明，Splat-Portrait在说话头生成和新视角合成方面表现出优越性能，相比先前工作实现了更好的视觉质量。

Conclusion: Splat-Portrait通过高斯泼溅表示和纯2D监督训练，成功解决了3D头部重建和唇部运动合成的挑战，实现了高质量的说话头生成，代码已开源。

Abstract: Talking Head Generation aims at synthesizing natural-looking talking videos from speech and a single portrait image. Previous 3D talking head generation methods have relied on domain-specific heuristics such as warping-based facial motion representation priors to animate talking motions, yet still produce inaccurate 3D avatar reconstructions, thus undermining the realism of generated animations. We introduce Splat-Portrait, a Gaussian-splatting-based method that addresses the challenges of 3D head reconstruction and lip motion synthesis. Our approach automatically learns to disentangle a single portrait image into a static 3D reconstruction represented as static Gaussian Splatting, and a predicted whole-image 2D background. It then generates natural lip motion conditioned on input audio, without any motion driven priors. Training is driven purely by 2D reconstruction and score-distillation losses, without 3D supervision nor landmarks. Experimental results demonstrate that Splat-Portrait exhibits superior performance on talking head generation and novel view synthesis, achieving better visual quality compared to previous works. Our project code and supplementary documents are public available at https://github.com/stonewalking/Splat-portrait.

</details>


### [161] [Are Video Generation Models Geographically Fair? An Attraction-Centric Evaluation of Global Visual Knowledge](https://arxiv.org/abs/2601.18698)
*Xiao Liu,Jiawei Zhang*

Main category: cs.CV

TL;DR: 本文提出Geo-Attraction Landmark Probing (GAP)框架评估文本到视频生成模型的地理公平性，发现Sora 2模型在全球视觉知识表达上比预期更均衡。


<details>
  <summary>Details</summary>
Motivation: 当前文本到视频生成模型虽然视觉效果好，但缺乏对其是否编码地理公平视觉知识的评估。需要系统评估这些模型是否能公平地合成来自不同地区的旅游景点。

Method: 提出GAP框架，构建GEOATTRACTION-500基准数据集（包含500个全球分布的景点），使用全局结构对齐、细粒度关键点对齐和视觉语言模型判断等互补指标，并与人类评估验证。

Result: 对Sora 2模型评估发现，与常见的地理偏见假设相反，模型在不同地区、发展水平和文化群体中表现出相对均匀的地理基础视觉知识，仅对景点知名度有微弱依赖。

Conclusion: 当前文本到视频模型比预期更均衡地表达全球视觉知识，这既显示了其在全球部署应用中的潜力，也强调了随着系统发展需要持续评估。

Abstract: Recent advances in text-to-video generation have produced visually compelling results, yet it remains unclear whether these models encode geographically equitable visual knowledge. In this work, we investigate the geo-equity and geographically grounded visual knowledge of text-to-video models through an attraction-centric evaluation. We introduce Geo-Attraction Landmark Probing (GAP), a systematic framework for assessing how faithfully models synthesize tourist attractions from diverse regions, and construct GEOATTRACTION-500, a benchmark of 500 globally distributed attractions spanning varied regions and popularity levels. GAP integrates complementary metrics that disentangle overall video quality from attraction-specific knowledge, including global structural alignment, fine-grained keypoint-based alignment, and vision-language model judgments, all validated against human evaluation. Applying GAP to the state-of-the-art text-to-video model Sora 2, we find that, contrary to common assumptions of strong geographic bias, the model exhibits a relatively uniform level of geographically grounded visual knowledge across regions, development levels, and cultural groupings, with only weak dependence on attraction popularity. These results suggest that current text-to-video models express global visual knowledge more evenly than expected, highlighting both their promise for globally deployed applications and the need for continued evaluation as such systems evolve.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [162] [Crystal-KV: Efficient KV Cache Management for Chain-of-Thought LLMs via Answer-First Principle](https://arxiv.org/abs/2601.16986)
*Zihan Wang,Cheng Tang,Lei Gong,Cheng Li,Chao Wang,teng wang,Wenqi Lou,Xuehai Zhou*

Main category: cs.CL

TL;DR: Crystal-KV：针对CoT推理的KV缓存管理框架，通过答案优先原则区分关键和非关键缓存，实现高效压缩同时保持或提升答案准确性。


<details>
  <summary>Details</summary>
Motivation: CoT推理显著提升LLM在复杂任务上的准确性，但会产生过长的思考阶段序列，导致KV缓存内存开销过大。传统KV压缩策略在CoT场景下效果不佳，因为CoT强调最终答案而非所有token的均匀重要性。

Method: 1. 答案优先原则：将答案偏好映射到思考阶段注意力图，区分SlipKV（主要维持推理流程但可能引入误导）和CrystalKV（真正贡献最终答案正确性）。2. 基于注意力的LRFU算法：精确识别SlipKV条目效用何时过期并驱逐，保留CrystalKV不破坏推理流程。3. 自适应缓存预算分配：基于CrystalKV动态比例，估计每层/头的重要性，在推理过程中调整KV缓存预算，放大关键组件提高预算利用率。

Result: Crystal-KV实现了最先进的KV缓存压缩，显著提高了吞吐量，实现了更快的响应时间，同时在CoT推理中保持甚至提高了答案准确性。

Conclusion: Crystal-KV是针对CoT推理的高效KV缓存管理框架，通过答案优先原则和智能缓存管理，在减少内存开销的同时保持推理质量，为LLM的CoT推理提供了实用的优化方案。

Abstract: Chain-of-Thought (CoT) reasoning in large language models (LLMs) significantly improves accuracy on complex tasks, yet incurs excessive memory overhead due to the long think-stage sequences stored in the Key-Value (KV) cache. Unlike traditional generation tasks where all tokens are uniformly important, CoT emphasizes the final answer, rendering conventional KV compression strategies ineffective. In this paper, we present Crystal-KV, an efficient KV cache management framework tailored for CoT reasoning. Our key insight is the answer-first principle. By mapping answer preferences into think-stage attention map, we distinguish between SlipKV, which mainly maintains the reasoning flow but may occasionally introduce misleading context, and CrystalKV, which truly contributes to the correctness of the final answer. Next, we propose an attention-based Least Recently Frequently Used algorithm. It precisely identifies when a SlipKV entry's utility expires and evicts it, retaining CrystalKV without disrupting reasoning flow. Finally, we introduce an adaptive cache budget allocation algorithm. Based on the dynamic proportion of CrystalKV, it estimates the importance of each layer/head and adjusts the KV cache budget during inference, amplifying critical components to improve budget utilization. Results show that Crystal-KV achieves state-of-the-art KV cache compression, significantly improves throughput, and enables faster response time, while maintaining, or even improving, answer accuracy for CoT reasoning.

</details>


### [163] [Evaluating Reward Model Generalization via Pairwise Maximum Discrepancy Competitions](https://arxiv.org/abs/2601.16987)
*Shunyang Luo,Peibei Cao,Zhihui Zhu,Kehua Feng,Zhihua Wang,Keyan Ding*

Main category: cs.CL

TL;DR: PMDC是一个动态高效的奖励模型评估框架，通过主动选择两个RM分歧最大的prompt-response对来构建紧凑测试集，使用oracle裁决并基于Bradley-Terry模型生成全局排名，相比传统基准能更准确评估RM的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有奖励模型评估主要依赖静态的预标注偏好数据集，这些数据集覆盖有限且难以真实评估开放世界场景中的泛化能力，需要更有效的评估方法来准确衡量RM在实际应用中的表现。

Method: 提出Pairwise Maximum Discrepancy Competition (PMDC)框架：1) 使用大型未标注开放域prompt池；2) 主动选择两个RM分歧最大的prompt-response对作为测试用例；3) 由oracle裁决这些争议案例；4) 通过Bradley-Terry模型聚合结果生成全局排名和配对胜率图。

Result: 对10个代表性RM进行重新评估，发现与传统基准相比排名发生显著变化。定性分析进一步揭示了系统性的泛化失败模式，为改进奖励建模提供了有价值的见解。

Conclusion: PMDC提供了一个动态、标注高效的框架，能够更真实地评估奖励模型在开放世界中的泛化能力，揭示了传统静态评估方法的局限性，并为奖励模型的改进方向提供了重要指导。

Abstract: Reward models (RMs) are central to aligning large language models, yet their practical effectiveness hinges on generalization to unseen prompts and shifting distributions. Most existing RM evaluations rely on static, pre-annotated preference datasets, which provide limited coverage and often fail to faithfully assess generalization in open-world settings. We introduce Pairwise Maximum Discrepancy Competition (PMDC), a dynamic and annotation-efficient framework for evaluating RM generalization using a large, unlabeled, open-domain prompt pool. PMDC actively selects prompt--response pairs that maximize disagreement between two RMs, yielding a compact set of highly contentious test cases. These cases are adjudicated by an oracle, and the resulting outcomes are aggregated via a Bradley--Terry model to produce a global ranking and pairwise win-rate landscape of RMs. We apply PMDC to re-evaluate 10 representative RMs and observe substantial rank reshuffling compared with conventional benchmarks. Qualitative analyses further uncover systematic generalization failures, providing valuable insights for improving reward modeling.

</details>


### [164] [Uncertainty Quantification for Named Entity Recognition via Full-Sequence and Subsequence Conformal Prediction](https://arxiv.org/abs/2601.16999)
*Matthew Singer,Srijan Sengupta,Karl Pazdernik*

Main category: cs.CL

TL;DR: 提出一个基于序列标注的NER模型不确定性感知预测集框架，通过conformal prediction提供有限样本覆盖保证，为下游应用提供可靠的不确定性度量。


<details>
  <summary>Details</summary>
Motivation: 当前NER模型通常只输出单一预测标签序列，缺乏不确定性度量，导致下游应用容易受到级联错误的影响。需要为NER预测提供类似经典统计学中置信区间的方法，提供关于模型预测可靠性的形式化保证。

Method: 基于conformal prediction构建不确定性感知预测集框架，设计高效的非一致性评分函数来构建校准良好的预测集，支持无条件覆盖和类别条件覆盖。该方法考虑了句子长度、语言、实体类型和句子内实体数量的异质性。

Result: 在三个基准数据集上的四个NER模型上进行实证实验，证明了所提方法具有广泛的适用性、有效性和高效性。

Conclusion: 该框架为NER模型提供了不确定性感知的预测集，能够保证在用户指定的置信水平下包含正确的标注，为下游NLP应用提供了可靠的预测不确定性度量。

Abstract: Named Entity Recognition (NER) serves as a foundational component in many natural language processing (NLP) pipelines. However, current NER models typically output a single predicted label sequence without any accompanying measure of uncertainty, leaving downstream applications vulnerable to cascading errors. In this paper, we introduce a general framework for adapting sequence-labeling-based NER models to produce uncertainty-aware prediction sets. These prediction sets are collections of full-sentence labelings that are guaranteed to contain the correct labeling with a user-specified confidence level. This approach serves a role analogous to confidence intervals in classical statistics by providing formal guarantees about the reliability of model predictions. Our method builds on conformal prediction, which offers finite-sample coverage guarantees under minimal assumptions. We design efficient nonconformity scoring functions to construct efficient, well-calibrated prediction sets that support both unconditional and class-conditional coverage. This framework accounts for heterogeneity across sentence length, language, entity type, and number of entities within a sentence. Empirical experiments on four NER models across three benchmark datasets demonstrate the broad applicability, validity, and efficiency of the proposed methods.

</details>


### [165] [MultiVis-Agent: A Multi-Agent Framework with Logic Rules for Reliable and Comprehensive Cross-Modal Data Visualization](https://arxiv.org/abs/2601.18320)
*Jinwei Lu,Yuanfeng Song,Chen Zhang,Raymond Chi-Wing Wong*

Main category: cs.CL

TL;DR: MultiVis-Agent：一个基于逻辑规则增强的多智能体框架，用于可靠的多模态、多场景可视化生成，解决了现有系统在复杂可视化任务中的可靠性和灵活性不足问题。


<details>
  <summary>Details</summary>
Motivation: 现实世界可视化任务涉及复杂的多模态需求（参考图像、代码示例、迭代优化），而现有系统存在单模态输入、一次性生成、僵化工作流程等根本限制。虽然基于LLM的方法有潜力，但引入了可靠性挑战（灾难性故障、无限循环风险）。

Method: 提出MultiVis-Agent框架，采用四层逻辑规则框架为系统可靠性提供数学保证，同时保持灵活性。逻辑规则作为数学约束指导LLM推理而非替代它。形式化了涵盖从基础生成到迭代优化的四个场景的多模态可视化任务，并开发了包含1000多个案例的MultiVis-Bench基准。

Result: 在挑战性任务上达到75.63%的可视化得分，显著优于基线（57.54-62.79%），任务完成率99.58%，代码执行成功率94.56%（无逻辑规则时分别为74.48%和65.10%），成功解决了自动化可视化生成中的复杂性和可靠性挑战。

Conclusion: MultiVis-Agent通过逻辑规则增强的多智能体框架，有效解决了复杂可视化任务中的可靠性和灵活性问题，为多模态、多场景的可视化生成提供了可靠解决方案。

Abstract: Real-world visualization tasks involve complex, multi-modal requirements that extend beyond simple text-to-chart generation, requiring reference images, code examples, and iterative refinement. Current systems exhibit fundamental limitations: single-modality input, one-shot generation, and rigid workflows. While LLM-based approaches show potential for these complex requirements, they introduce reliability challenges including catastrophic failures and infinite loop susceptibility. To address this gap, we propose MultiVis-Agent, a logic rule-enhanced multi-agent framework for reliable multi-modal and multi-scenario visualization generation. Our approach introduces a four-layer logic rule framework that provides mathematical guarantees for system reliability while maintaining flexibility. Unlike traditional rule-based systems, our logic rules are mathematical constraints that guide LLM reasoning rather than replacing it. We formalize the MultiVis task spanning four scenarios from basic generation to iterative refinement, and develop MultiVis-Bench, a benchmark with over 1,000 cases for multi-modal visualization evaluation. Extensive experiments demonstrate that our approach achieves 75.63% visualization score on challenging tasks, significantly outperforming baselines (57.54-62.79%), with task completion rates of 99.58% and code execution success rates of 94.56% (vs. 74.48% and 65.10% without logic rules), successfully addressing both complexity and reliability challenges in automated visualization generation.

</details>


### [166] [RAM-SD: Retrieval-Augmented Multi-agent framework for Sarcasm Detection](https://arxiv.org/abs/2601.17002)
*Ziyang Zhou,Ziqi Liu,Yan Wang,Yiming Lin,Yangbin Chen*

Main category: cs.CL

TL;DR: RAM-SD：一个检索增强的多智能体框架，通过四阶段流程（上下文检索、元规划、专业智能体分析、集成）实现讽刺检测，在四个基准测试中达到77.74%的Macro-F1，超越GPT-4o+CoC基线7.01个百分点。


<details>
  <summary>Details</summary>
Motivation: 现有讽刺检测方法（从微调transformer到大语言模型）对所有输入采用统一的推理策略，难以应对讽刺表达的多样性需求，包括建模上下文期望违反、外部知识基础或特定修辞模式识别等不同分析需求。

Method: RAM-SD框架包含四个阶段：1) 上下文检索：将查询基于讽刺和非讽刺示例进行基础；2) 元规划：分类讽刺类型并从预定义集合中选择最优推理计划；3) 专业智能体集合：执行互补的多视角分析；4) 集成器：将这些分析合成为最终可解释的判断，并提供自然语言解释。

Result: 在四个标准基准测试中，RAM-SD实现了77.74%的Macro-F1，比强大的GPT-4o+CoC基线高出7.01个百分点，创下了新的性能基准。

Conclusion: 该框架不仅设定了新的性能基准，还提供了透明可解释的推理轨迹，阐明了讽刺理解的认知过程，为解决讽刺检测的多样性挑战提供了有效方案。

Abstract: Sarcasm detection remains a significant challenge due to its reliance on nuanced contextual understanding, world knowledge, and multi-faceted linguistic cues that vary substantially across different sarcastic expressions. Existing approaches, from fine-tuned transformers to large language models, apply a uniform reasoning strategy to all inputs, struggling to address the diverse analytical demands of sarcasm. These demands range from modeling contextual expectation violations to requiring external knowledge grounding or recognizing specific rhetorical patterns. To address this limitation, we introduce RAM-SD, a Retrieval-Augmented Multi-Agent framework for Sarcasm Detection. The framework operates through four stages: (1) contextual retrieval grounds the query in both sarcastic and non-sarcastic exemplars; (2) a meta-planner classifies the sarcasm type and selects an optimal reasoning plan from a predefined set; (3) an ensemble of specialized agents performs complementary, multi-view analysis; and (4) an integrator synthesizes these analyses into a final, interpretable judgment with a natural language explanation. Evaluated on four standard benchmarks, RAM-SD achieves a state-of-the-art Macro-F1 of 77.74%, outperforming the strong GPT-4o+CoC baseline by 7.01 points. Our framework not only sets a new performance benchmark but also provides transparent and interpretable reasoning traces, illuminating the cognitive processes behind sarcasm comprehension.

</details>


### [167] [From Emotion to Expression: Theoretical Foundations and Resources for Fear Speech](https://arxiv.org/abs/2601.17132)
*Vigneshwaran Shankaran,Gabriella Lapesa,Claudia Wagner*

Main category: cs.CL

TL;DR: 该论文通过整合心理学、政治学、传播学和语言学的跨学科视角，为恐惧言论研究提供理论框架和实用指南，包括定义梳理、数据集调查和分类体系构建。


<details>
  <summary>Details</summary>
Motivation: 恐惧言论作为一种独特的言论形式，在社交媒体上广泛传播且影响力超过仇恨言论，但由于其"更文明"的表象而逃避监管。目前计算语言学领域对恐惧言论的研究分散且资源不足，需要建立系统的理论框架和研究方法。

Method: 1) 整合心理学、政治学、传播学和语言学四个学科的恐惧理论；2) 梳理现有恐惧言论定义；3) 调查相关研究领域的数据集；4) 提出用于研究恐惧言论的多维度分类体系。

Result: 建立了跨学科的恐惧言论理论框架，提供了恐惧言论的核心概念定义，调查了现有数据集资源，并提出了系统化的恐惧维度分类体系，为恐惧言论研究提供了理论基础和实践指导。

Conclusion: 该论文通过跨学科整合为恐惧言论研究奠定了系统基础，为创建数据集和推进恐惧言论研究提供了理论框架和实用指南，填补了计算语言学领域对恐惧言论研究的空白。

Abstract: Few forces rival fear in their ability to mobilize societies, distort communication, and reshape collective behavior. In computational linguistics, fear is primarily studied as an emotion, but not as a distinct form of speech. Fear speech content is widespread and growing, and often outperforms hate-speech content in reach and engagement because it appears "civiler" and evades moderation. Yet the computational study of fear speech remains fragmented and under-resourced. This can be understood by recognizing that fear speech is a phenomenon shaped by contributions from multiple disciplines. In this paper, we bridge cross-disciplinary perspectives by comparing theories of fear from Psychology, Political science, Communication science, and Linguistics. Building on this, we review existing definitions. We follow up with a survey of datasets from related research areas and propose a taxonomy that consolidates different dimensions of fear for studying fear speech. By reviewing current datasets and defining core concepts, our work offers both theoretical and practical guidance for creating datasets and advancing fear speech research.

</details>


### [168] [Dynamic Role Assignment for Multi-Agent Debate](https://arxiv.org/abs/2601.17152)
*Miao Zhang,Junsik Kim,Siyuan Xiang,Jian Gao,Cheng Cao*

Main category: cs.CL

TL;DR: 提出动态角色分配框架，通过元辩论选择最适合的智能体担任特定角色，在多智能体LLM/VLM辩论系统中显著提升性能


<details>
  <summary>Details</summary>
Motivation: 现有多智能体LLM/VLM辩论系统虽然使用专门角色解决复杂问题，但没有根据模型的特长来分配角色，导致无法充分利用不同模型的优势

Method: 提出动态角色分配框架，包含元辩论的两个阶段：1)提案阶段-候选智能体提供角色定制化论证；2)同行评审阶段-使用数据和角色特定标准对提案评分，为每个位置选择最佳智能体

Result: 在LLM问题解决基准测试中，该方法相比统一分配（所有角色用同一模型）提升高达74.8%，相比随机分配提升高达29.7%，具体提升幅度取决于任务和具体分配

Conclusion: 这项工作为多智能体系统设计建立了新范式，从静态智能体部署转向动态和能力感知的选择，显著提升了多智能体辩论系统的性能

Abstract: Multi-agent large language model (LLM) and vision-language model (VLM) debate systems employ specialized roles for complex problem-solving, yet model specializations are not leveraged to decide which model should fill which role. We propose dynamic role assignment, a framework that runs a Meta-Debate to select suitable agents before the actual debate. The meta-debate has two stages: (1) proposal, where candidates provide role-tailored arguments, and (2) peer review, where proposals are scored with data and role-specific criteria to choose the best agent for each position. We evaluate our method on LLM problem solving benchmarks. Applied on top of existing debate systems, our approach consistently outperforms uniform assignments (filling all roles with the same model) by up to 74.8% and random assignments (assigning models to roles without considering their suitability) by up to 29.7%, depending on the task and the specific assignment. This work establishes a new paradigm for multi-agent system design, shifting from static agent deployment to dynamic and capability-aware selection.

</details>


### [169] [Interpretability of the Intent Detection Problem: A New Approach](https://arxiv.org/abs/2601.17156)
*Eduardo Sanchez-Karhunen,Jose F. Quesada-Moreno,Miguel A. Gutiérrez-Naranjo*

Main category: cs.CL

TL;DR: 该论文应用动力系统理论分析RNN在意图检测任务中的工作机制，发现RNN在平衡数据集上学习到理想几何解（状态空间分区对应不同意图），但在不平衡数据集上低频意图的聚类会退化。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习在意图检测任务中占主导地位，但RNN解决该任务的内在机制仍不清楚。研究者希望理解RNN如何从几何和动力系统角度处理意图分类问题。

Method: 应用动力系统理论分析RNN架构，将句子解释为隐藏状态空间中的轨迹。使用平衡的SNIPS数据集和不平衡的ATIS数据集进行对比研究，分析状态空间的几何结构。

Result: 在平衡SNIPS数据集上，RNN学习到理想解：状态空间被约束在低维流形上，并分区为对应不同意图的聚类。在不平衡ATIS数据集上，低频意图的聚类会退化，几何解被扭曲。

Conclusion: 该框架将几何分离与读出对齐解耦，为实际性能差异提供了机制性解释。研究揭示了数据集属性如何直接塑造网络的几何计算解，为RNN动力学提供了新的几何解释。

Abstract: Intent detection, a fundamental text classification task, aims to identify and label the semantics of user queries, playing a vital role in numerous business applications. Despite the dominance of deep learning techniques in this field, the internal mechanisms enabling Recurrent Neural Networks (RNNs) to solve intent detection tasks are poorly understood. In this work, we apply dynamical systems theory to analyze how RNN architectures address this problem, using both the balanced SNIPS and the imbalanced ATIS datasets. By interpreting sentences as trajectories in the hidden state space, we first show that on the balanced SNIPS dataset, the network learns an ideal solution: the state space, constrained to a low-dimensional manifold, is partitioned into distinct clusters corresponding to each intent. The application of this framework to the imbalanced ATIS dataset then reveals how this ideal geometric solution is distorted by class imbalance, causing the clusters for low-frequency intents to degrade. Our framework decouples geometric separation from readout alignment, providing a novel, mechanistic explanation for real world performance disparities. These findings provide new insights into RNN dynamics, offering a geometric interpretation of how dataset properties directly shape a network's computational solution.

</details>


### [170] [Who Gets Which Message? Auditing Demographic Bias in LLM-Generated Targeted Text](https://arxiv.org/abs/2601.17172)
*Tunazzina Islam*

Main category: cs.CL

TL;DR: LLMs在生成针对不同人口统计特征的定向信息时表现出系统性偏见，年轻/男性受众的信息强调能动性和创新，而女性/年长受众的信息则强调温暖和传统，上下文提示会放大这些差异。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs能够大规模生成个性化、有说服力的文本，需要研究其在自动化沟通中的偏见和公平性问题，特别是在人口统计条件定向信息生成中的行为模式。

Method: 建立受控评估框架，使用GPT-4o、Llama-3.3和Mistral-Large 2.1三个模型，在两种生成设置下评估：独立生成（隔离内在人口统计效应）和上下文丰富生成（融入主题和区域背景）。从词汇内容、语言风格和说服框架三个维度评估生成信息。

Result: 在气候沟通任务中发现，所有模型都表现出一致的年龄和性别不对称：针对男性和年轻人的信息强调能动性、创新和自信，而针对女性和年长者的信息强调温暖、关怀和传统。上下文提示系统性地放大了这些差异，针对年轻或男性受众的信息说服力评分显著更高。

Conclusion: 人口统计刻板印象会在LLM生成的定向沟通中浮现并加剧，需要在社会敏感应用中建立偏见感知的生成流程和透明的审计框架，明确考虑人口统计条件的影响。

Abstract: Large language models (LLMs) are increasingly capable of generating personalized, persuasive text at scale, raising new questions about bias and fairness in automated communication. This paper presents the first systematic analysis of how LLMs behave when tasked with demographic-conditioned targeted messaging. We introduce a controlled evaluation framework using three leading models -- GPT-4o, Llama-3.3, and Mistral-Large 2.1 -- across two generation settings: Standalone Generation, which isolates intrinsic demographic effects, and Context-Rich Generation, which incorporates thematic and regional context to emulate realistic targeting. We evaluate generated messages along three dimensions: lexical content, language style, and persuasive framing. We instantiate this framework on climate communication and find consistent age- and gender-based asymmetries across models: male- and youth-targeted messages emphasize agency, innovation, and assertiveness, while female- and senior-targeted messages stress warmth, care, and tradition. Contextual prompts systematically amplify these disparities, with persuasion scores significantly higher for messages tailored to younger or male audiences. Our findings demonstrate how demographic stereotypes can surface and intensify in LLM-generated targeted communication, underscoring the need for bias-aware generation pipelines and transparent auditing frameworks that explicitly account for demographic conditioning in socially sensitive applications.

</details>


### [171] [Beyond Factual QA: Mentorship-Oriented Question Answering over Long-Form Multilingual Content](https://arxiv.org/abs/2601.17173)
*Parth Bhalerao,Diola Dsouza,Ruiwen Guan,Oana Ignat*

Main category: cs.CL

TL;DR: MentorQA：首个多语言长视频问答数据集与评估框架，专注于指导性回答而非事实准确性，包含近9000个QA对，比较了多种问答架构，发现多智能体管道在指导性回答质量上表现最佳。


<details>
  <summary>Details</summary>
Motivation: 现有问答系统主要评估事实准确性，但教育、职业指导等实际应用需要指导性回答（提供反思和指导）。现有QA基准很少捕捉这种区别，特别是在多语言和长文本场景下。

Method: 引入MentorQA数据集，包含近9000个QA对，来自180小时四种语言的视频内容。定义了超越事实准确性的指导性评估维度（清晰度、一致性、学习价值）。在受控条件下比较了单智能体、双智能体、RAG和多智能体QA架构。

Result: 多智能体管道在指导性回答质量上表现最佳，尤其在复杂主题和低资源语言上优势明显。同时分析了基于LLM的自动评估可靠性，发现与人类判断存在显著差异。

Conclusion: 这项工作确立了指导性问答作为一个独立研究问题，为教育AI中的智能体架构和评估设计提供了多语言基准。数据集和评估框架已开源。

Abstract: Question answering systems are typically evaluated on factual correctness, yet many real-world applications-such as education and career guidance-require mentorship: responses that provide reflection and guidance. Existing QA benchmarks rarely capture this distinction, particularly in multilingual and long-form settings. We introduce MentorQA, the first multilingual dataset and evaluation framework for mentorship-focused question answering from long-form videos, comprising nearly 9,000 QA pairs from 180 hours of content across four languages. We define mentorship-focused evaluation dimensions that go beyond factual accuracy, capturing clarity, alignment, and learning value. Using MentorQA, we compare Single-Agent, Dual-Agent, RAG, and Multi-Agent QA architectures under controlled conditions. Multi-Agent pipelines consistently produce higher-quality mentorship responses, with especially strong gains for complex topics and lower-resource languages. We further analyze the reliability of automated LLM-based evaluation, observing substantial variation in alignment with human judgments. Overall, this work establishes mentorship-focused QA as a distinct research problem and provides a multilingual benchmark for studying agentic architectures and evaluation design in educational AI. The dataset and evaluation framework are released at https://github.com/AIM-SCU/MentorQA.

</details>


### [172] [Systematicity between Forms and Meanings across Languages Supports Efficient Communication](https://arxiv.org/abs/2601.17181)
*Doreen Osmelak,Yang Xu,Michael Hahn,Kate McCurdy*

Main category: cs.CL

TL;DR: 该研究提出基于可学习性的复杂度度量，发现动词和代词形式受简洁性（最小化语法区分）和准确性（恢复意义）的竞争压力影响，能更好区分现存与不存在的语言系统。


<details>
  <summary>Details</summary>
Motivation: 现有高效沟通理论未能解释词形内部的系统关系，需要研究语法意义（人称、数等）如何在跨语言中表达，并建立高效沟通理论与语言系统性的新联系。

Method: 提出基于意义到形式映射可学习性的新颖复杂度度量，分析类型多样的语言中动词和代词形式，考察简洁性（最小化语法区分）和准确性（恢复意义）的竞争压力。

Result: 发现动词和代词形式确实受简洁性和准确性竞争压力影响，新复杂度度量能捕捉语言形式的细粒度规律性，更好区分现存与不存在的语言系统。

Conclusion: 基于可学习性的复杂度度量建立了高效沟通理论与自然语言系统性的新联系，揭示了语言形式受竞争性交际压力塑造的机制。

Abstract: Languages vary widely in how meanings map to word forms. These mappings have been found to support efficient communication; however, this theory does not account for systematic relations within word forms. We examine how a restricted set of grammatical meanings (e.g. person, number) are expressed on verbs and pronouns across typologically diverse languages. Consistent with prior work, we find that verb and pronoun forms are shaped by competing communicative pressures for simplicity (minimizing the inventory of grammatical distinctions) and accuracy (enabling recovery of intended meanings). Crucially, our proposed model uses a novel measure of complexity (inverse of simplicity) based on the learnability of meaning-to-form mappings. This innovation captures fine-grained regularities in linguistic form, allowing better discrimination between attested and unattested systems, and establishes a new connection from efficient communication theory to systematicity in natural language.

</details>


### [173] [Reasoning Beyond Literal: Cross-style Multimodal Reasoning for Figurative Language Understanding](https://arxiv.org/abs/2601.17197)
*Seyyed Saeid Cheshmi,Hahnemann Ortiz,James Mooney,Dongyeop Kang*

Main category: cs.CL

TL;DR: 本文提出一个三步框架，让轻量级视觉语言模型能够理解多模态比喻语言（如讽刺、幽默、隐喻），提供可解释的推理过程，并实现跨风格泛化。


<details>
  <summary>Details</summary>
Motivation: 虽然视觉语言模型在字面多模态任务上表现良好，但比喻语言（讽刺、幽默、隐喻）仍然是重大挑战，因为这类语言通过表达意义与意图意义之间的微妙不一致来传达意图和情感。在多模态环境中，伴随图像可能放大或反转文本含义，需要模型能够跨模态推理并考虑主观性。

Method: 提出三步框架：1) 解释多模态比喻语言；2) 提供透明的推理轨迹；3) 跨多种比喻风格泛化。通过实验验证，在四种风格上测试，发现：1) 融入推理轨迹显著提升多模态比喻理解；2) 一种风格学到的推理可以迁移到其他风格，特别是讽刺和幽默等相似风格之间；3) 跨风格联合训练产生泛化推理VLM。

Result: 实验表明：1) 融入推理轨迹大幅改善多模态比喻理解；2) 推理能力可在风格间迁移，特别是相关风格如讽刺与幽默之间；3) 跨风格联合训练的轻量级VLM在性能上超越更大规模的开源和闭源模型。轻量级VLM通过可验证推理实现稳健的跨风格泛化，并为多模态任务提供可检查的推理轨迹。

Conclusion: 轻量级视觉语言模型通过可验证推理能够实现稳健的跨风格泛化，同时为多模态任务提供可检查的推理轨迹。该方法在理解多模态比喻语言方面表现出色，超越了更大规模模型，展示了高效推理模型在复杂语言理解任务中的潜力。

Abstract: Vision-language models (VLMs) have demonstrated strong reasoning abilities in literal multimodal tasks such as visual mathematics and science question answering. However, figurative language, such as sarcasm, humor, and metaphor, remains a significant challenge, as it conveys intent and emotion through subtle incongruities between expressed and intended meanings. In multimodal settings, accompanying images can amplify or invert textual meaning, demanding models that reason across modalities and account for subjectivity. We propose a three-step framework for developing efficient multimodal reasoning models that can (i) interpret multimodal figurative language, (ii) provide transparent reasoning traces, and (iii) generalize across multiple figurative styles. Experiments across four styles show that (1) incorporating reasoning traces substantially improves multimodal figurative understanding, (2) reasoning learned in one style can transfer to others, especially between related styles like sarcasm and humor, and (3) training jointly across styles yields a generalized reasoning VLM that outperforms much larger open- and closed-source models. Our findings show that lightweight VLMs with verifiable reasoning achieve robust cross-style generalization while providing inspectable reasoning traces for multimodal tasks. The code and implementation are available at https://github.com/scheshmi/CrossStyle-MMR.

</details>


### [174] [Relating Word Embedding Gender Biases to Gender Gaps: A Cross-Cultural Analysis](https://arxiv.org/abs/2601.17203)
*Scott Friedman,Sonja Schmer-Galunder,Anthony Chen,Jeffrey Rye*

Main category: cs.CL

TL;DR: 该论文提出了一种量化词嵌入中性别偏见的方法，并将其用于衡量教育、政治、经济和健康领域的统计性别差距，通过Twitter数据验证了这些指标与真实世界性别差距的相关性。


<details>
  <summary>Details</summary>
Motivation: 当前NLP模型中的种族和性别偏见通常被视为需要纠正的问题，但本文认为这些偏见可能反映了训练文本所来源文化中实际存在的性别差距，因此可以通过大数据分析来理解文化背景。

Method: 提出量化词嵌入中性别偏见的方法，使用2018年Twitter数据覆盖美国51个地区和99个国家，将词嵌入偏见与18个国际统计指标和5个美国本土性别差距指标进行相关性分析。

Result: 验证了词嵌入偏见指标与真实世界统计性别差距之间的相关性，揭示了词嵌入偏见能够反映和预测实际文化中的性别不平等状况。

Conclusion: 词嵌入中的性别偏见不仅是技术问题，更是反映文化现实的窗口，可以作为一种大数据工具来理解和预测社会中的性别差距。

Abstract: Modern models for common NLP tasks often employ machine learning techniques and train on journalistic, social media, or other culturally-derived text. These have recently been scrutinized for racial and gender biases, rooting from inherent bias in their training text. These biases are often sub-optimal and recent work poses methods to rectify them; however, these biases may shed light on actual racial or gender gaps in the culture(s) that produced the training text, thereby helping us understand cultural context through big data. This paper presents an approach for quantifying gender bias in word embeddings, and then using them to characterize statistical gender gaps in education, politics, economics, and health. We validate these metrics on 2018 Twitter data spanning 51 U.S. regions and 99 countries. We correlate state and country word embedding biases with 18 international and 5 U.S.-based statistical gender gaps, characterizing regularities and predictive strength.

</details>


### [175] [DF-RAG: Query-Aware Diversity for Retrieval-Augmented Generation](https://arxiv.org/abs/2601.17212)
*Saadat Hasan Khan,Spencer Hong,Jingyu Wu,Kevin Lybarger,Youbing Yin,Erin Babinsky,Daben Liu*

Main category: cs.CL

TL;DR: DF-RAG通过引入多样性检索机制，在保持相关性的同时减少冗余内容，显著提升推理密集型问答任务的性能


<details>
  <summary>Details</summary>
Motivation: 传统RAG方法在推理密集型QA任务中表现不佳，因为基于余弦相似度的检索方法虽然能保证相关性，但会引入冗余内容，降低信息召回率

Method: 基于最大边际相关性框架，DF-RAG在检索步骤中系统性地引入多样性，选择既与查询相关又彼此差异最大的信息块，并能动态优化每个查询的多样性水平

Result: 在推理密集型QA基准测试中，DF-RAG比基于余弦相似度的vanilla RAG提升4-10%的F1分数，优于其他基线方法，并达到了Oracle上限的91.3%

Conclusion: DF-RAG通过动态优化检索多样性，有效解决了传统RAG在推理密集型QA中的冗余问题，显著提升了性能表现

Abstract: Retrieval-augmented generation (RAG) is a common technique for grounding language model outputs in domain-specific information. However, RAG is often challenged by reasoning-intensive question-answering (QA), since common retrieval methods like cosine similarity maximize relevance at the cost of introducing redundant content, which can reduce information recall. To address this, we introduce Diversity-Focused Retrieval-Augmented Generation (DF-RAG), which systematically incorporates diversity into the retrieval step to improve performance on complex, reasoning-intensive QA benchmarks. DF-RAG builds upon the Maximal Marginal Relevance framework to select information chunks that are both relevant to the query and maximally dissimilar from each other. A key innovation of DF-RAG is its ability to optimize the level of diversity for each query dynamically at test time without requiring any additional fine-tuning or prior information. We show that DF-RAG improves F1 performance on reasoning-intensive QA benchmarks by 4-10 percent over vanilla RAG using cosine similarity and also outperforms other established baselines. Furthermore, we estimate an Oracle ceiling of up to 18 percent absolute F1 gains over vanilla RAG, of which DF-RAG captures up to 91.3 percent.

</details>


### [176] [Beyond Outcome Verification: Verifiable Process Reward Models for Structured Reasoning](https://arxiv.org/abs/2601.17223)
*Massimiliano Pronesti,Anya Belz,Yufang Hou*

Main category: cs.CL

TL;DR: 提出可验证过程奖励模型（VPRMs），通过确定性规则验证器检查中间推理步骤，在医学证据合成偏倚评估中显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有过程监督方法依赖神经网络评分推理步骤，存在不透明性、偏见和奖励攻击漏洞；而可验证奖励强化学习（RLVR）仅使用结果级验证信号，无法监督中间推理过程。

Method: 提出VPRMs框架，使用确定性、基于规则的验证器检查中间推理步骤；应用于医学证据合成偏倚评估领域，利用指南定义的标准和基于规则的决策路径对推理轨迹进行程序化验证。

Result: 在多个数据集上，VPRMs生成的推理紧密遵循领域规则，步骤级决策与最终标签的一致性显著提高；相比最先进模型F1提升达20%，相比可验证结果奖励提升6.5%，证据基础和逻辑连贯性大幅改善。

Conclusion: VPRMs通过确定性规则验证器有效监督中间推理过程，在需要严格遵循领域规则的医学证据评估等任务中表现出色，为过程监督提供了更可靠、透明的解决方案。

Abstract: Recent work on reinforcement learning with verifiable rewards (RLVR) has shown that large language models (LLMs) can be substantially improved using outcome-level verification signals, such as unit tests for code or exact-match checks for mathematics. In parallel, process supervision has long been explored as a way to shape the intermediate reasoning behaviour of LLMs, but existing approaches rely on neural judges to score chain-of-thought steps, leaving them vulnerable to opacity, bias, and reward hacking. To address this gap, we introduce Verifiable Process Reward Models (VPRMs), a reinforcement-learning framework in which intermediate reasoning steps are checked by deterministic, rule-based verifiers. We apply VPRMs to risk-of-bias assessment for medical evidence synthesis, a domain where guideline-defined criteria and rule-based decision paths enable programmatic verification of reasoning traces. Across multiple datasets, we find that VPRMs generate reasoning that adheres closely to domain rules and achieve substantially higher coherence between step-level decisions and final labels. Results show that VPRMs achieve up to 20% higher F1 than state-of-the-art models and 6.5% higher than verifiable outcome rewards, with substantial gains in evidence grounding and logical coherence.

</details>


### [177] [Retell, Reward, Repeat: Reinforcement Learning for Narrative Theory-Informed Story Generation](https://arxiv.org/abs/2601.17226)
*David Y. Liu,Xanthe Muston,Aditya Joshi,Sebastian Sequoiah-Grayson*

Main category: cs.CL

TL;DR: 本文探索使用强化学习（d-RLAIF）作为监督微调（SFT）的替代方案进行自动故事生成，通过叙事平衡理论建立评估原则，使用LLM作为评判员提供奖励信号，结果显示d-RLAIF能生成更多样化且更符合人类叙事惯例的故事。


<details>
  <summary>Details</summary>
Motivation: 尽管故事讲述具有主观性，但以往自动故事生成（ASG）研究依赖有限的真实数据进行训练和评估。本文旨在探索强化学习作为监督微调后训练替代方案的可行性，以解决ASG任务的主观性挑战。

Method: 应用Todorov的叙事平衡理论建立ASG质量评估原则；使用7B和14B LLM作为评判员模型，测试其与人类标注者的一致性并提供奖励信号；采用d-RLAIF（强化学习）作为后训练方法；使用Gemini-3-Flash评估模型输出，并与TimeTravel数据集中的人类撰写故事进行比较。

Result: d-RLAIF被证明是监督微调（SFT）的可行替代方案，能够生成更多样化且更符合人类叙事惯例的故事。LLM作为评判员模型与人类标注者保持良好一致性，强化学习方法在主观性任务如ASG中显示出潜力。

Conclusion: 本文展示了强化学习在语言基础后训练中的前景，特别是对于自动故事生成等主观性任务。d-RLAIF方法能够有效提升故事生成的质量和多样性，为ASG研究提供了新的技术路径。

Abstract: Despite the subjective nature of storytelling, past works on automatic story generation (ASG) have relied on limited ground truths for training and evaluation. In this work, we explore reinforcement learning (d-RLAIF) as a post-training alternative to supervised fine-tuning (SFT). We first apply Todorov's Theory of Narrative Equilibrium to establish principles that define desirable ASG qualities. We prompt 7B and 14B LLM-as-judge models with our principles to test alignment with human annotators and provide reward signals during d-RLAIF. We use Gemini-3-Flash to evaluate the output of our post-trained models and compare them to human-written stories from the TimeTravel dataset. We show that d-RLAIF offers a viable alternative to supervised fine-tuning (SFT)--producing stories that are more diverse and aligned with human narrative conventions. Our paper demonstrates the promise of reinforcement learning for linguistically grounded post-training for subjective tasks such as ASG.

</details>


### [178] [CaseFacts: A Benchmark for Legal Fact-Checking and Precedent Retrieval](https://arxiv.org/abs/2601.17230)
*Akshith Reddy Putta,Jacob Devasier,Chengkai Li*

Main category: cs.CL

TL;DR: CaseFacts是一个用于验证美国最高法院判例中通俗法律主张的基准数据集，包含6,294个主张，分为支持、反驳和推翻三类，旨在解决法律领域事实核查的语义差距和时效性问题。


<details>
  <summary>Details</summary>
Motivation: 现有自动事实核查主要关注静态语料库中的一般知识，忽视了法律等高风险领域，其中真相是动态演变且技术复杂的。法律领域需要弥合通俗主张与技术法理之间的语义差距，并考虑时效有效性。

Method: 采用多阶段流水线方法，利用大型语言模型从专家案例摘要中合成主张，并采用新颖的语义相似性启发式方法来高效识别和验证复杂的法律推翻情况。

Result: 实验表明，即使使用最先进的大型语言模型，该任务仍然具有挑战性。值得注意的是，为模型添加无限制的网络搜索反而会降低性能，因为会检索到嘈杂、非权威的先例。

Conclusion: CaseFacts基准旨在推动法律事实核查系统的研究，解决法律领域特有的语义差距和时效性挑战，为开发更准确的法律事实核查工具提供基础。

Abstract: Automated Fact-Checking has largely focused on verifying general knowledge against static corpora, overlooking high-stakes domains like law where truth is evolving and technically complex. We introduce CaseFacts, a benchmark for verifying colloquial legal claims against U.S. Supreme Court precedents. Unlike existing resources that map formal texts to formal texts, CaseFacts challenges systems to bridge the semantic gap between layperson assertions and technical jurisprudence while accounting for temporal validity. The dataset consists of 6,294 claims categorized as Supported, Refuted, or Overruled. We construct this benchmark using a multi-stage pipeline that leverages Large Language Models (LLMs) to synthesize claims from expert case summaries, employing a novel semantic similarity heuristic to efficiently identify and verify complex legal overrulings. Experiments with state-of-the-art LLMs reveal that the task remains challenging; notably, augmenting models with unrestricted web search degrades performance compared to closed-book baselines due to the retrieval of noisy, non-authoritative precedents. We release CaseFacts to spur research into legal fact verification systems.

</details>


### [179] [Frame-Guided Synthetic Claim Generation for Automatic Fact-Checking Using High-Volume Tabular Data](https://arxiv.org/abs/2601.17232)
*Jacob Devasier,Akshith Putta,Qing Wang,Alankrit Moses,Chengkai Li*

Main category: cs.CL

TL;DR: 论文提出了一个针对大规模结构化数据的事实核查新基准数据集，包含78,503个基于复杂OECD表格的合成声明，涵盖四种语言，通过框架引导方法生成，旨在解决现有基准忽略真实世界高容量数据验证的问题。


<details>
  <summary>Details</summary>
Motivation: 现有自动化事实核查基准主要关注小型、精选的表格数据，而忽略了验证真实世界高容量结构化数据的挑战。这种局限性使得现有方法无法应对现实世界中复杂、大规模数据的事实核查需求。

Method: 提出了一种新颖的框架引导方法：1）基于六个语义框架程序化选择重要数据点；2）生成英语、中文、西班牙语和印地语的合成声明；3）使用434个复杂OECD表格作为数据源，每个表格平均超过50万行；4）通过知识探测实验确保LLM未记忆这些事实。

Result: 1）创建了包含78,503个声明的大规模多语言数据集；2）证明LLM未记忆这些事实，迫使系统进行真正的检索和推理；3）提供了SQL生成基线系统；4）发现证据检索是主要瓶颈，模型难以在巨大表格中找到正确数据；5）基准具有高度挑战性。

Conclusion: 该数据集为解决未解决的现实世界问题提供了关键新资源，推动了针对大规模结构化数据的事实核查研究，特别强调了证据检索在真实世界数据验证中的核心挑战。

Abstract: Automated fact-checking benchmarks have largely ignored the challenge of verifying claims against real-world, high-volume structured data, instead focusing on small, curated tables. We introduce a new large-scale, multilingual dataset to address this critical gap. It contains 78,503 synthetic claims grounded in 434 complex OECD tables, which average over 500K rows each. We propose a novel, frame-guided methodology where algorithms programmatically select significant data points based on six semantic frames to generate realistic claims in English, Chinese, Spanish, and Hindi. Crucially, we demonstrate through knowledge-probing experiments that LLMs have not memorized these facts, forcing systems to perform genuine retrieval and reasoning rather than relying on parameterized knowledge. We provide a baseline SQL-generation system and show that our benchmark is highly challenging. Our analysis identifies evidence retrieval as the primary bottleneck, with models struggling to find the correct data in massive tables. This dataset provides a critical new resource for advancing research on this unsolved, real-world problem.

</details>


### [180] [PingPong: A Natural Benchmark for Multi-Turn Code-Switching Dialogues](https://arxiv.org/abs/2601.17277)
*Mohammad Rifqi Farhansyah,Hanif Muhammad Zhafran,Farid Adilazuarda,Shamsuddeen Hassan Muhammad,Maryam Ibrahim Mukhtar,Nedjma Ousidhoum,Genta Indra Winata,Ayu Purwarianti,Alham Fikri Aji*

Main category: cs.CL

TL;DR: PingPong是一个用于自然多语码转换对话的基准测试，包含五种语言组合变化，部分为三语对话，涵盖问答、对话摘要和主题分类三个下游任务。


<details>
  <summary>Details</summary>
Motivation: 码转换是全球多语人群的普遍实践，但现有基准测试未能准确反映日常交流中的复杂性。需要更真实反映多语对话复杂性的数据集来推动NLP系统发展。

Method: 创建PingPong基准测试，包含人工编写的2-4人自然对话，涵盖五种语言组合变化（部分为三语）。对话具有真实的多线程结构，回复经常引用对话早期内容。定义了三个下游任务：问答、对话摘要和主题分类。

Result: PingPong数据比机器生成替代方案更自然、结构更多样，在消息长度、说话者主导性和回复距离方面变化更大。评估显示现有最先进语言模型在码转换输入上表现有限。

Conclusion: 需要更强大的NLP系统来处理现实世界多语对话的复杂性。PingPong基准测试为评估和改进码转换处理能力提供了重要资源。

Abstract: Code-switching is a widespread practice among the world's multilingual majority, yet few benchmarks accurately reflect its complexity in everyday communication. We present PingPong, a benchmark for natural multi-party code-switching dialogues covering five language-combination variations, some of which are trilingual. Our dataset consists of human-authored conversations among 2 to 4 participants covering authentic, multi-threaded structures where replies frequently reference much earlier points in the dialogue. We demonstrate that our data is significantly more natural and structurally diverse than machine-generated alternatives, offering greater variation in message length, speaker dominance, and reply distance. Based on these dialogues, we define three downstream tasks: Question Answering, Dialogue Summarization, and Topic Classification. Evaluations of several state-of-the-art language models on PingPong reveal that performance remains limited on code-switched inputs, underscoring the urgent need for more robust NLP systems capable of addressing the intricacies of real-world multilingual discourse.

</details>


### [181] [Mind the Ambiguity: Aleatoric Uncertainty Quantification in LLMs for Safe Medical Question Answering](https://arxiv.org/abs/2601.17284)
*Yaokun Liu,Yifan Liu,Phoebe Mbuvi,Zelin Li,Ruichen Yao,Gawon Lim,Dong Wang*

Main category: cs.CL

TL;DR: 提出CV-MedBench基准和AU-Probe模块，通过检测LLM内部激活中的歧义不确定性，实现"先澄清再回答"的医疗QA安全框架，平均准确率提升9.48%。


<details>
  <summary>Details</summary>
Motivation: 医疗QA中模糊的用户查询会显著降低LLM回答准确性，带来安全风险。现有方法未能有效处理这种输入歧义问题，需要专门针对医疗领域的高风险场景设计安全解决方案。

Method: 1) 构建CV-MedBench基准，专门用于研究医疗QA中的输入歧义；2) 从表示工程角度分析歧义不确定性，发现其线性编码在LLM内部激活模式中；3) 提出AU-Probe轻量模块，直接从隐藏状态检测输入歧义；4) 设计AU引导的"先澄清再回答"框架。

Result: 在四个开源LLM上的实验表明，该框架平均准确率提升9.48%优于基线。AU-Probe无需LLM微调或多次前向传播，能高效检测歧义并主动请求用户澄清。

Conclusion: 该工作为安全的医疗QA提供了高效鲁棒的解决方案，通过检测输入歧义并主动澄清，显著增强了健康相关应用的可靠性。代码和数据集已开源。

Abstract: The deployment of Large Language Models in Medical Question Answering is severely hampered by ambiguous user queries, a significant safety risk that demonstrably reduces answer accuracy in high-stakes healthcare settings. In this paper, we formalize this challenge by linking input ambiguity to aleatoric uncertainty (AU), which is the irreducible uncertainty arising from underspecified input. To facilitate research in this direction, we construct CV-MedBench, the first benchmark designed for studying input ambiguity in Medical QA. Using this benchmark, we analyze AU from a representation engineering perspective, revealing that AU is linearly encoded in LLM's internal activation patterns. Leveraging this insight, we introduce a novel AU-guided "Clarify-Before-Answer" framework, which incorporates AU-Probe - a lightweight module that detects input ambiguity directly from hidden states. Unlike existing uncertainty estimation methods, AU-Probe requires neither LLM fine-tuning nor multiple forward passes, enabling an efficient mechanism to proactively request user clarification and significantly enhance safety. Extensive experiments across four open LLMs demonstrate the effectiveness of our QA framework, with an average accuracy improvement of 9.48% over baselines. Our framework provides an efficient and robust solution for safe Medical QA, strengthening the reliability of health-related applications. The code is available at https://github.com/yaokunliu/AU-Med.git, and the CV-MedBench dataset is released on Hugging Face at https://huggingface.co/datasets/yaokunl/CV-MedBench.

</details>


### [182] [Meta-Judging with Large Language Models: Concepts, Methods, and Challenges](https://arxiv.org/abs/2601.17312)
*Hugo Silva,Mateus Mendes,Hugo Gonçalo Oliveira*

Main category: cs.CL

TL;DR: 本文综述了LLM-as-a-Meta-Judge范式的发展，分析了传统LLM-as-a-Judge的局限性，并提出了一个包含六个关键维度的框架来组织相关文献，认为Meta-Judge为更稳定可靠的自动化评估提供了有前景的方向。


<details>
  <summary>Details</summary>
Motivation: 传统LLM-as-a-Judge评估方法存在显著脆弱性，包括对提示词的敏感性、系统性偏见、冗长效应以及不可靠或幻觉的推理过程。这些局限性促使研究者开发更鲁棒的LLM-as-a-Meta-Judge范式。

Method: 通过文献综述，引入一个包含六个关键维度的框架：(1)概念基础，(2)元评判机制，(3)对齐训练方法，(4)评估方法，(5)局限性和失败模式，(6)未来方向。系统分析传统LLM评估的局限性和元评判的最新进展。

Result: LLM-as-a-Meta-Judge为更稳定和可信的自动化评估提供了有前景的方向，但仍面临成本、提示词敏感性和共享模型偏见等挑战，需要解决这些问题才能推进下一代LLM评估方法的发展。

Conclusion: 元评判范式代表了LLM评估的重要演进方向，通过系统化地审查和评估传统评判方法的局限性，为实现更鲁棒、可靠的自动化评估奠定了基础，但需要进一步解决现有挑战。

Abstract: Large language models (LLMs) are evolving fast and are now frequently used as evaluators, in a process typically referred to as LLM-as-a-Judge, which provides quality assessments of model outputs. However, recent research points out significant vulnerabilities in such evaluation, including sensitivity to prompts, systematic biases, verbosity effects, and unreliable or hallucinated rationales. These limitations motivated the development of a more robust paradigm, dubbed LLM-as-a-Meta-Judge. This survey reviews recent advances in meta-judging and organizes the literature, by introducing a framework along six key perspectives: (i) Conceptual Foundations, (ii) Mechanisms of Meta-Judging, (iii) Alignment Training Methods, (iv) Evaluation, (v) Limitations and Failure Modes, and (vi) Future Directions. By analyzing the limitations of LLM-as-a-Judge and summarizing recent advances in meta-judging by LLMs, we argue that LLM-as-a-Meta-Judge offers a promising direction for more stable and trustworthy automated evaluation, while highlighting remaining challenges related to cost, prompt sensitivity, and shared model biases, which must be addressed to advance the next generation of LLM evaluation methodologies.

</details>


### [183] [The Shadow Self: Intrinsic Value Misalignment in Large Language Model Agents](https://arxiv.org/abs/2601.17344)
*Chen Chen,Kim Young Il,Yuan Yang,Wenhao Su,Yilin Zhang,Xueluan Gong,Qian Wang,Yongsen Zheng,Ziyao Liu,Kwok-Yan Lam*

Main category: cs.CL

TL;DR: 该研究提出了IMPRESS框架，用于评估LLM智能体在完全良性场景下的内在价值错位风险，发现这是普遍存在的安全问题，现有缓解策略效果有限。


<details>
  <summary>Details</summary>
Motivation: 现有评估主要关注对明确有害输入的响应或系统故障的鲁棒性，而在现实、完全良性、自主的智能体设置中，价值错位风险尚未得到充分探索。LLM智能体可能追求偏离人类价值观和伦理规范的目标，存在失控风险。

Method: 首先形式化失控风险，识别内在价值错位；然后提出IMPRESS框架，通过多阶段LLM生成管道构建包含现实、完全良性、情境化场景的基准测试；评估21个最先进的LLM智能体，并进行人工验证。

Result: 内在价值错位是跨模型的普遍安全风险；错位率因动机、风险类型、模型规模和架构而异；解码策略和超参数影响有限，但情境化和框架机制显著影响错位行为；现有缓解策略（如安全提示和护栏）效果不稳定或有限。

Conclusion: 内在价值错位是LLM智能体安全的重要风险，需要更有效的缓解策略。IMPRESS框架为系统评估该风险提供了工具，有助于AI生态系统的发展。

Abstract: Large language model (LLM) agents with extended autonomy unlock new capabilities, but also introduce heightened challenges for LLM safety. In particular, an LLM agent may pursue objectives that deviate from human values and ethical norms, a risk known as value misalignment. Existing evaluations primarily focus on responses to explicit harmful input or robustness against system failure, while value misalignment in realistic, fully benign, and agentic settings remains largely underexplored. To fill this gap, we first formalize the Loss-of-Control risk and identify the previously underexamined Intrinsic Value Misalignment (Intrinsic VM). We then introduce IMPRESS (Intrinsic Value Misalignment Probes in REalistic Scenario Set), a scenario-driven framework for systematically assessing this risk. Following our framework, we construct benchmarks composed of realistic, fully benign, and contextualized scenarios, using a multi-stage LLM generation pipeline with rigorous quality control. We evaluate Intrinsic VM on 21 state-of-the-art LLM agents and find that it is a common and broadly observed safety risk across models. Moreover, the misalignment rates vary by motives, risk types, model scales, and architectures. While decoding strategies and hyperparameters exhibit only marginal influence, contextualization and framing mechanisms significantly shape misalignment behaviors. Finally, we conduct human verification to validate our automated judgments and assess existing mitigation strategies, such as safety prompting and guardrails, which show instability or limited effectiveness. We further demonstrate key use cases of IMPRESS across the AI Ecosystem. Our code and benchmark will be publicly released upon acceptance.

</details>


### [184] [Do readers prefer AI-generated Italian short stories?](https://arxiv.org/abs/2601.17363)
*Michael Farrell*

Main category: cs.CL

TL;DR: 读者在盲测中更偏好AI生成的意大利语短篇小说而非著名作家作品，但差异不大


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索读者对AI生成文学作品与人类作家作品的偏好差异，挑战关于读者偏好人类创作小说的假设

Method: 采用盲测设计，20名参与者在不知情情况下阅读并评估三篇短篇小说（两篇由ChatGPT-4o生成，一篇由Alberto Moravia创作），同时收集阅读习惯和人口统计数据

Result: AI生成的文本获得了略高的平均评分，更常被偏好，但差异不大；文本偏好与人口统计或阅读习惯变量无显著关联

Conclusion: 研究结果挑战了读者偏好人类创作小说的假设，并引发了对文学语境中合成文本编辑必要性的质疑

Abstract: This study investigates whether readers prefer AI-generated short stories in Italian over one written by a renowned Italian author. In a blind setup, 20 participants read and evaluated three stories, two created with ChatGPT-4o and one by Alberto Moravia, without being informed of their origin. To explore potential influencing factors, reading habits and demographic data, comprising age, gender, education and first language, were also collected. The results showed that the AI-written texts received slightly higher average ratings and were more frequently preferred, although differences were modest. No statistically significant associations were found between text preference and demographic or reading-habit variables. These findings challenge assumptions about reader preference for human-authored fiction and raise questions about the necessity of synthetic-text editing in literary contexts.

</details>


### [185] [Parameter Efficient Fine Tuning Llama 3.1 for Answering Arabic Legal Questions: A Case Study on Jordanian Laws](https://arxiv.org/abs/2601.17364)
*Mohammed Fasha,Bassam Hammo,Bilal Sowan,Husam Barham,Esam Nsour*

Main category: cs.CL

TL;DR: 该研究使用约旦法律作为案例，探索了Llama-3.1大语言模型在阿拉伯语法律问答任务上的微调方法，通过量化和参数高效微调技术实现了资源高效的法律领域模型适配。


<details>
  <summary>Details</summary>
Motivation: 探索如何将大语言模型有效适配到阿拉伯语法律领域，解决法律问答任务中的专业性和准确性需求，同时关注资源效率问题。

Method: 使用两个版本的Llama-3.1-8B模型（基础版和指令版），采用4位量化技术和LoRA适配器的参数高效微调方法，利用Unsloth框架进行加速训练，基于6000个约旦法律问答对构建的自定义数据集进行微调。

Result: 微调后的模型在法律推理和准确性方面均有提升，通过量化和优化微调策略实现了资源效率，BLEU和ROUGE评估指标显示性能改进。

Conclusion: 该研究证明了将大语言模型适配到阿拉伯语法律领域的可行性，并展示了量化技术和参数高效微调在领域特定任务中的有效性，为阿拉伯语法律AI应用提供了技术路径。

Abstract: This study uses Jordanian law as a case study to explore the fine-tuning of the Llama-3.1 large language model for Arabic question-answering. Two versions of the model - Llama-3.1-8B-bnb-4bit and Llama-3.1-8B-Instruct-bnb-4bit - were fine-tuned using parameter-efficient fine-tuning (PEFT) with LoRA adapters and 4-bit quantized models, leveraging the Unsloth framework for accelerated and resource-efficient training. A custom dataset of 6000 legal question-answer pairs was curated from Jordanian laws and formatted into structured prompts. Performance was evaluated using the BLEU and the ROUGE metrics to compare the fine-tuned models to their respective base versions. Results demonstrated improved legal reasoning and accuracy while achieving resource efficiency through quantization and optimized fine-tuning strategies. This work underscores the potential of adapting large language models for Arabic legal domains and highlights effective techniques for fine-tuning domain-specific tasks.

</details>


### [186] [Elastic Attention: Test-time Adaptive Sparsity Ratios for Efficient Transformers](https://arxiv.org/abs/2601.17367)
*Zecheng Tang,Quantong Qiu,Yi Yang,Zhiyi Hong,Haiya Xiang,Kebin Liu,Qingqing Dang,Juntao Li,Min Zhang*

Main category: cs.CL

TL;DR: 提出Elastic Attention方法，通过轻量级Attention Router动态调整注意力稀疏度，解决长上下文场景中标准注意力二次复杂度问题，实现高效推理。


<details>
  <summary>Details</summary>
Motivation: 标准注意力机制的二次复杂度限制了大型语言模型在长上下文场景的可扩展性。现有混合注意力策略使用静态计算比例，无法适应下游任务在推理时的稀疏敏感性变化。

Method: 提出Elastic Attention，集成轻量级Attention Router到预训练模型中，动态分配每个注意力头到不同的计算模式，使模型能根据输入动态调整整体稀疏度。

Result: 在8xA800 GPU上仅训练12小时，方法在三个长上下文基准测试中表现出优越性，实现了强性能和高效推理。

Conclusion: Elastic Attention通过动态调整注意力稀疏度，有效解决了长上下文场景中的计算效率问题，为大型语言模型提供了可扩展的解决方案。

Abstract: The quadratic complexity of standard attention mechanisms poses a significant scalability bottleneck for large language models (LLMs) in long-context scenarios. While hybrid attention strategies that combine sparse and full attention within a single model offer a viable solution, they typically employ static computation ratios (i.e., fixed proportions of sparse versus full attention) and fail to adapt to the varying sparsity sensitivities of downstream tasks during inference. To address this issue, we propose Elastic Attention, which allows the model to dynamically adjust its overall sparsity based on the input. This is achieved by integrating a lightweight Attention Router into the existing pretrained model, which dynamically assigns each attention head to different computation modes. Within only 12 hours of training on 8xA800 GPUs, our method enables models to achieve both strong performance and efficient inference. Experiments across three long-context benchmarks on widely-used LLMs demonstrate the superiority of our method.

</details>


### [187] [WarrantScore: Modeling Warrants between Claims and Evidence for Substantiation Evaluation in Peer Reviews](https://arxiv.org/abs/2601.17377)
*Kiyotada Mori,Shohei Tanaka,Tosho Hirasawa,Tadashi Kozuno,Koichiro Yoshino,Yoshitaka Ushiku*

Main category: cs.CL

TL;DR: 提出新的科学评审评论评估指标，通过评估主张与证据之间的逻辑推理关系来改进现有仅检测证据存在与否的方法，提高与人工评分的相关性


<details>
  <summary>Details</summary>
Motivation: 科学同行评审面临人力资源短缺，语言模型被用于降低评审成本。现有方法仅评估主张是否被证据支持，但忽略了主张与证据之间的逻辑推理关系，这限制了评估的准确性

Method: 提出新的评估指标，不仅提取评审评论中的核心论证组件（主张和证据），还评估主张与证据之间的逻辑推理关系，而不仅仅是检测证据的存在与否

Result: 实验结果表明，所提出的方法比传统方法获得更高的人工评分相关性，显示出更好支持同行评审过程效率的潜力

Conclusion: 通过评估主张与证据之间的逻辑推理关系，新的评估指标能更准确地评估科学评审评论的论证质量，有助于提高同行评审过程的效率

Abstract: The scientific peer-review process is facing a shortage of human resources due to the rapid growth in the number of submitted papers. The use of language models to reduce the human cost of peer review has been actively explored as a potential solution to this challenge. A method has been proposed to evaluate the level of substantiation in scientific reviews in a manner that is interpretable by humans. This method extracts the core components of an argument, claims and evidence, and assesses the level of substantiation based on the proportion of claims supported by evidence. The level of substantiation refers to the extent to which claims are based on objective facts. However, when assessing the level of substantiation, simply detecting the presence or absence of supporting evidence for a claim is insufficient; it is also necessary to accurately assess the logical inference between a claim and its evidence. We propose a new evaluation metric for scientific review comments that assesses the logical inference between claims and evidence. Experimental results show that the proposed method achieves a higher correlation with human scores than conventional methods, indicating its potential to better support the efficiency of the peer-review process.

</details>


### [188] [Revisiting Modality Invariance in a Multilingual Speech-Text Model via Neuron-Level Analysis](https://arxiv.org/abs/2601.17387)
*Toshiki Nakai,Varsha Suresh,Vera Demberg*

Main category: cs.CL

TL;DR: SeamlessM4T v2多语言语音-文本基础模型在语音和文本模态下对同一语言的内部表示并不完全一致，存在模态不变性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 研究多语言语音-文本基础模型是否能在语音和文本两种模态下对同一语言保持一致的内部表示，探索模态不变性的程度。

Method: 采用三种互补分析方法：1) 使用平均精度排名识别语言和模态选择性神经元；2) 通过中值替换干预在推理时研究其功能作用；3) 分析跨语言和模态的激活幅度不平等性。

Result: 发现模态不变性不完全：编码器表示逐渐变得语言无关，但这种压缩使得共享解码器在构建模态无关表示时更难恢复源语言，特别是从语音适应到文本时。在交叉注意力键值投影中观察到高度局部化的模态选择性结构。语音条件解码和非主导脚本表现出更高的激活集中度。

Conclusion: 多语言语音-文本模型在语音和文本模态下对语言的表示存在差异，模态不变性不完全，这可能导致跨模态和跨语言的脆弱性增加。

Abstract: Multilingual speech-text foundation models aim to process language uniformly across both modality and language, yet it remains unclear whether they internally represent the same language consistently when it is spoken versus written. We investigate this question in SeamlessM4T v2 through three complementary analyses that probe where language and modality information is encoded, how selective neurons causally influence decoding, and how concentrated this influence is across the network. We identify language- and modality-selective neurons using average-precision ranking, investigate their functional role via median-replacement interventions at inference time, and analyze activation-magnitude inequality across languages and modalities. Across experiments, we find evidence of incomplete modality invariance. Although encoder representations become increasingly language-agnostic, this compression makes it more difficult for the shared decoder to recover the language of origin when constructing modality-agnostic representations, particularly when adapting from speech to text. We further observe sharply localized modality-selective structure in cross-attention key and value projections. Finally, speech-conditioned decoding and non-dominant scripts exhibit higher activation concentration, indicating heavier reliance on a small subset of neurons, which may underlie increased brittleness across modalities and languages.

</details>


### [189] [CLM-Bench: Benchmarking and Analyzing Cross-lingual Misalignment of LLMs in Knowledge Editing](https://arxiv.org/abs/2601.17397)
*Yucheng Hu,Wei Zhou,Juesi Xiao*

Main category: cs.CL

TL;DR: 论文提出CLM-Bench，一个文化感知的多语言知识编辑基准，揭示当前方法存在跨语言对齐问题，编辑无法在不同语言间传播。


<details>
  <summary>Details</summary>
Motivation: 现有MKE基准通常通过机械翻译英语数据集构建，这引入了翻译伪影并忽略了目标语言特有的文化实体，无法反映LLMs的真实知识分布。

Method: 提出CLM-Bench基准，采用中文优先方法构建，包含1,010个基于中文文化背景的CounterFact对，并与英语对应项对齐。通过层表示分析提供几何解释。

Result: 实验发现显著的跨语言错位：一种语言的编辑独立运作，无法传播到另一种语言。中文和英语的编辑向量几乎正交，存在于不相交的子空间中。

Conclusion: 当前方法在跨语言迁移方面效果有限，强调文化原生基准的重要性。混合语言编辑显示这些向量的线性可加性。

Abstract: Knowledge Editing (KE) has emerged as a promising paradigm for updating facts in Large Language Models (LLMs) without retraining. However, progress in Multilingual Knowledge Editing (MKE) is currently hindered by biased evaluation frameworks. We observe that existing MKE benchmarks are typically constructed by mechanically translating English-centric datasets into target languages (e.g., English-to-Chinese). This approach introduces translation artifacts and neglects culturally specific entities native to the target language, failing to reflect the true knowledge distribution of LLMs. To address this, we propose CLM-Bench, a culture-aware benchmark constructed using a native Chinese-first methodology. We curate 1,010 high-quality CounterFact pairs rooted in Chinese cultural contexts and align them with English counterparts. Using CLM-Bench, we conduct extensive experiments on representative LLMs (e.g., Llama-3, Qwen2) and reveal a significant Cross-lingual Misalignment: edits in one language function independently and fail to propagate to the other. We further provide a geometric explanation via layer-wise representation analysis, demonstrating that edit vectors for Chinese and English are nearly orthogonal -- residing in disjoint subspaces -- while mixed-lingual editing exhibits linear additivity of these vectors. Our findings challenge the effectiveness of current methods in cross-lingual transfer and underscore the importance of culturally native benchmarks.

</details>


### [190] [Oops, Wait: Token-Level Signals as a Lens into LLM Reasoning](https://arxiv.org/abs/2601.17421)
*Jaehui Hwang,Dongyoon Han,Sangdoo Yun,Byeongho Heo*

Main category: cs.CL

TL;DR: 分析大语言模型中"wait"、"therefore"等话语标记token的概率信号，发现这些信号与推理正确性高度相关，且在不同模型规模下稳定，但受训练策略影响。小数据集微调的模型仅部分利用这些信号。


<details>
  <summary>Details</summary>
Motivation: 大语言模型中出现的"wait"、"therefore"等话语标记token为理解其推理过程提供了独特窗口，但目前缺乏对这些信号如何随训练策略和模型规模变化的系统性分析。

Method: 通过分析不同模型的token级概率信号，研究特定token（特别是"wait"）与推理正确性的相关性，并考察这些信号在不同训练策略和模型规模下的变化。

Result: 发现特定token与推理正确性高度相关，这种相关性在不同模型规模下保持稳定，但受训练策略影响。小规模数据集微调的模型虽然通过这类信号获得推理能力，但仅部分利用它们。

Conclusion: 这项工作为观察和理解大语言模型推理动态提供了系统性视角，揭示了话语标记token在模型推理中的重要作用及其与训练策略的关系。

Abstract: The emergence of discourse-like tokens such as "wait" and "therefore" in large language models (LLMs) has offered a unique window into their reasoning processes. However, systematic analyses of how such signals vary across training strategies and model scales remain lacking. In this paper, we analyze token-level signals through token probabilities across various models. We find that specific tokens strongly correlate with reasoning correctness, varying with training strategies while remaining stable across model scales. A closer look at the "wait" token in relation to answer probability demonstrates that models fine-tuned on small-scale datasets acquire reasoning ability through such signals but exploit them only partially. This work provides a systematic lens to observe and understand the dynamics of LLM reasoning.

</details>


### [191] [Clustering-driven Memory Compression for On-device Large Language Models](https://arxiv.org/abs/2601.17443)
*Ondrej Bohdal,Pramit Saha,Umberto Michieli,Mete Ozay,Taha Ceritli*

Main category: cs.CL

TL;DR: 提出基于聚类的记忆压缩策略，通过相似性分组和合并来平衡上下文效率与个性化质量，在减少记忆令牌的同时提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型通常需要从过去交互中提取用户特定记忆来实现个性化生成。现有方法要么直接拼接记忆（消耗有限上下文），要么平均压缩记忆（导致语义冲突损害性能），需要在上下文效率与个性化质量之间取得平衡。

Method: 引入基于聚类的记忆压缩策略：1）按相似性对记忆进行分组；2）在聚类内部合并记忆；3）将合并后的记忆与输入提示拼接。这种方法在减少冗余的同时保持语义连贯性。

Result: 实验表明：1）显著降低记忆令牌数量；2）性能优于基线策略（朴素平均或直接拼接）；3）在固定上下文预算下，聚类驱动合并产生更紧凑的记忆表示并持续提升生成质量。

Conclusion: 基于聚类的记忆压缩策略有效解决了上下文限制与个性化质量之间的权衡问题，为设备端LLMs提供了高效且高质量的记忆管理方案。

Abstract: Large language models (LLMs) often rely on user-specific memories distilled from past interactions to enable personalized generation. A common practice is to concatenate these memories with the input prompt, but this approach quickly exhausts the limited context available in on-device LLMs. Compressing memories by averaging can mitigate context growth, yet it frequently harms performance due to semantic conflicts across heterogeneous memories. In this work, we introduce a clustering-based memory compression strategy that balances context efficiency and personalization quality. Our method groups memories by similarity and merges them within clusters prior to concatenation, thereby preserving coherence while reducing redundancy. Experiments demonstrate that our approach substantially lowers the number of memory tokens while outperforming baseline strategies such as naive averaging or direct concatenation. Furthermore, for a fixed context budget, clustering-driven merging yields more compact memory representations and consistently enhances generation quality.

</details>


### [192] [Revealing the Truth with ConLLM for Detecting Multi-Modal Deepfakes](https://arxiv.org/abs/2601.17530)
*Gautam Siddharth Kashyap,Harsh Joshi,Niharika Jain,Ebad Shabbir,Jiechao Gao,Nipun Joshi,Usman Naseem*

Main category: cs.CL

TL;DR: 提出ConLLM框架，通过对比学习和LLM推理解决深度伪造检测中的模态碎片化和浅层跨模态推理问题，显著提升音频、视频和视听深度伪造检测性能。


<details>
  <summary>Details</summary>
Motivation: 深度伪造技术对社会和政治稳定构成严重威胁，现有检测方法存在两个核心限制：1）模态碎片化导致跨不同对抗性深度伪造模态泛化能力差；2）浅层跨模态推理导致细粒度语义不一致检测有限。

Method: 提出ConLLM（基于大语言模型的对比学习）混合框架，采用两阶段架构：第一阶段使用预训练模型提取模态特定嵌入；第二阶段通过对比学习对齐嵌入以缓解模态碎片化，并使用基于LLM的推理细化嵌入以解决浅层跨模态推理问题。

Result: ConLLM在音频、视频和视听模态上表现优异：音频深度伪造EER降低达50%，视频准确率提升达8%，视听任务准确率提升约9%。消融研究证实基于PTM的嵌入为各模态带来9%-10%的稳定改进。

Conclusion: ConLLM框架通过结合对比学习和LLM推理，有效解决了深度伪造检测中的模态碎片化和浅层跨模态推理问题，显著提升了多模态深度伪造检测的鲁棒性和准确性。

Abstract: The rapid rise of deepfake technology poses a severe threat to social and political stability by enabling hyper-realistic synthetic media capable of manipulating public perception. However, existing detection methods struggle with two core limitations: (1) modality fragmentation, which leads to poor generalization across diverse and adversarial deepfake modalities; and (2) shallow inter-modal reasoning, resulting in limited detection of fine-grained semantic inconsistencies. To address these, we propose ConLLM (Contrastive Learning with Large Language Models), a hybrid framework for robust multimodal deepfake detection. ConLLM employs a two-stage architecture: stage 1 uses Pre-Trained Models (PTMs) to extract modality-specific embeddings; stage 2 aligns these embeddings via contrastive learning to mitigate modality fragmentation, and refines them using LLM-based reasoning to address shallow inter-modal reasoning by capturing semantic inconsistencies. ConLLM demonstrates strong performance across audio, video, and audio-visual modalities. It reduces audio deepfake EER by up to 50%, improves video accuracy by up to 8%, and achieves approximately 9% accuracy gains in audio-visual tasks. Ablation studies confirm that PTM-based embeddings contribute 9%-10% consistent improvements across modalities.

</details>


### [193] [Less is More for RAG: Information Gain Pruning for Generator-Aligned Reranking and Evidence Selection](https://arxiv.org/abs/2601.17532)
*Zhipeng Song,Yizhi Zhou,Xiangyu Kong,Jiulong Jiao,Xinrui Bao,Xu You,Xueqing Shi,Yuhang Zhou,Heng Qi*

Main category: cs.CL

TL;DR: 提出信息增益剪枝(IGP)方法，在检索增强生成(RAG)中通过生成器对齐的效用信号筛选证据，在有限上下文预算下优化质量-成本权衡


<details>
  <summary>Details</summary>
Motivation: 传统检索相关性指标(如NDCG)与端到端QA质量相关性弱，在多段落注入时甚至呈负相关，冗余和轻微冲突会破坏生成稳定性

Method: 提出信息增益剪枝(IGP)，一个部署友好的重排序和剪枝模块，使用生成器对齐的效用信号选择证据，在截断前过滤弱或有害段落

Result: 在五个开放域QA基准和多种检索器/生成器上，IGP持续改进质量-成本权衡；在多证据设置中，相比仅使用检索器的基线，F1相对提升12-20%，同时减少76-79%的最终阶段输入token

Conclusion: IGP通过生成器对齐的证据选择有效解决了RAG中上下文预算有限的问题，显著提升了检索增强生成的效率和质量

Abstract: Retrieval-augmented generation (RAG) grounds large language models with external evidence, but under a limited context budget, the key challenge is deciding which retrieved passages should be injected. We show that retrieval relevance metrics (e.g., NDCG) correlate weakly with end-to-end QA quality and can even become negatively correlated under multi-passage injection, where redundancy and mild conflicts destabilize generation. We propose \textbf{Information Gain Pruning (IGP)}, a deployment-friendly reranking-and-pruning module that selects evidence using a generator-aligned utility signal and filters weak or harmful passages before truncation, without changing existing budget interfaces. Across five open-domain QA benchmarks and multiple retrievers and generators, IGP consistently improves the quality--cost trade-off. In a representative multi-evidence setting, IGP delivers about +12--20% relative improvement in average F1 while reducing final-stage input tokens by roughly 76--79% compared to retriever-only baselines.

</details>


### [194] [Improving User Privacy in Personalized Generation: Client-Side Retrieval-Augmented Modification of Server-Side Generated Speculations](https://arxiv.org/abs/2601.17569)
*Alireza Salemi,Hamed Zamani*

Main category: cs.CL

TL;DR: P³是一个隐私保护的个性化LLM框架，通过客户端小模型评估和修改服务器大模型的草稿输出，实现高质量个性化而不泄露用户隐私数据。


<details>
  <summary>Details</summary>
Motivation: 现有基于检索增强的个性化方法面临隐私泄露与本地模型能力不足的权衡问题，需要在保护用户隐私的同时实现高质量的个性化输出。

Method: 采用交互式框架：服务器端大模型仅基于用户查询生成k个草稿token，客户端小模型访问用户私有配置文件，评估并修改这些草稿以更好地反映用户偏好，重复此过程直到生成结束token。

Result: 在LaMP-QA基准测试中，P³显著优于非个性化服务器端和个性化客户端基线，平均提升7.4%-9%，恢复90.3%-95.7%的"泄露"上限场景效用，隐私泄露仅增加1.5%-3.5%，客户端模型仅生成总token的9.2%。

Conclusion: P³提供了一个实用有效的隐私保护个性化生成解决方案，在保护用户隐私的同时实现了接近完全泄露场景的性能，适合边缘部署。

Abstract: Personalization is crucial for aligning Large Language Model (LLM) outputs with individual user preferences and background knowledge. State-of-the-art solutions are based on retrieval augmentation, where relevant context from a user profile is retrieved for LLM consumption. These methods deal with a trade-off between exposing retrieved private data to cloud providers and relying on less capable local models. We introduce $P^3$, an interactive framework for high-quality personalization without revealing private profiles to server-side LLMs. In $P^3$, a large server-side model generates a sequence of $k$ draft tokens based solely on the user query, while a small client-side model, with retrieval access to the user's private profile, evaluates and modifies these drafts to better reflect user preferences. This process repeats until an end token is generated. Experiments on LaMP-QA, a recent benchmark consisting of three personalized question answering datasets, show that $P^3$ consistently outperforms both non-personalized server-side and personalized client-side baselines, achieving statistically significant improvements of $7.4%$ to $9%$ on average. Importantly, $P^3$ recovers $90.3%$ to $95.7%$ of the utility of a ``leaky'' upper-bound scenario in which the full profile is exposed to the large server-side model. Privacy analyses, including linkability and attribute inference attacks, indicate that $P^3$ preserves the privacy of a non-personalized server-side model, introducing only marginal additional leakage ($1.5%$--$3.5%$) compared to submitting a query without any personal context. Additionally, the framework is efficient for edge deployment, with the client-side model generating only $9.2%$ of the total tokens. These results demonstrate that $P^3$ provides a practical, effective solution for personalized generation with improved privacy.

</details>


### [195] [Sequence Repetition Enhances Token Embeddings and Improves Sequence Labeling with Decoder-only Language Models](https://arxiv.org/abs/2601.17585)
*Matija Luka Kukić,Marko Čuljak,David Dukić,Martin Tutek,Jan Šnajder*

Main category: cs.CL

TL;DR: 序列重复（SR）是一种让仅解码器模型获得双向上下文能力的新方法，无需移除因果掩码，在序列标注任务中表现优于编码器模型和无掩码解码器。


<details>
  <summary>Details</summary>
Motivation: 仅解码器模型（如GPT）在自回归训练中只使用前缀上下文，而序列标注任务需要双向上下文。传统方法需要移除因果掩码来适应序列标注，但这会显著改变基础模型功能。本文探索序列重复作为更少侵入性的替代方案。

Method: 提出序列重复（SR）方法：通过重复输入序列来让仅解码器模型获得双向上下文能力。通过微调实验验证SR的有效性，并研究重复次数、使用中间层嵌入等参数的影响。

Result: SR使解码器具有双向性，提高了词元级嵌入质量，在序列标注任务中超越了编码器模型和无掩码解码器。增加重复次数不会降低性能，使用中间层嵌入效果与最终层相当但计算效率更高。

Conclusion: 序列重复缓解了解码器的结构限制，使语言模型更高效、适应性更强，拓宽了在词元级任务中的应用范围。

Abstract: Modern language models (LMs) are trained in an autoregressive manner, conditioned only on the prefix. In contrast, sequence labeling (SL) tasks assign labels to each individual input token, naturally benefiting from bidirectional context. This discrepancy has historically led SL to rely on inherently bidirectional encoder-only models. However, the rapid development of decoder-only models has raised the question of whether they can be adapted to SL. While causal mask removal has emerged as a viable technique for adapting decoder-only models to leverage the full context for SL, it requires considerable changes to the base model functionality. In this work, we explore sequence repetition (SR) as a less invasive alternative for enabling bidirectionality in decoder-only models. Through fine-tuning experiments, we show that SR inherently makes decoders bidirectional, improving the quality of token-level embeddings and surpassing encoders and unmasked decoders. Contrary to earlier claims, we find that increasing the number of repetitions does not degrade SL performance. Finally, we demonstrate that embeddings from intermediate layers are highly effective for SR, comparable to those from final layers, while being significantly more efficient to compute. Our findings underscore that SR alleviates the structural limitations of decoders, enabling more efficient and adaptable LMs and broadening their applicability to other token-level tasks.

</details>


### [196] [From Chains to DAGs: Probing the Graph Structure of Reasoning in LLMs](https://arxiv.org/abs/2601.17593)
*Tianjun Zhong,Linyang He,Nima Mesgarani*

Main category: cs.CL

TL;DR: 该论文提出Reasoning DAG Probing框架，探究LLM隐藏状态是否线性编码推理有向无环图的几何结构，发现中间层确实有意义地编码了推理DAG几何，且可恢复性随节点深度和模型规模系统变化。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型在多步推理方面取得进展，但先前工作多将推理视为线性链式步骤。然而许多推理问题更自然地表示为有向无环图（DAG），其中中间结论可能依赖多个前提、分支为并行子推导、后续合并或重用。理解这种图结构推理是否反映在模型内部仍是一个开放问题。

Method: 提出Reasoning DAG Probing框架，将每个推理节点与文本实现关联，训练轻量级探针从隐藏状态预测两个图论属性：节点深度和成对节点距离。使用这些探针分析DAG结构的层间涌现，并评估破坏推理相关结构但保留表面文本属性的控制条件。

Result: 研究结果提供证据表明推理DAG几何在中间层被有意义地编码，可恢复性随节点深度和模型规模系统变化。这表明LLM推理不仅是顺序的，而且展现出可测量的内部图结构。

Conclusion: LLM推理不仅具有顺序性，还在中间层展现出可测量的内部图结构，推理DAG几何被有意义地编码，且这种编码特性随节点深度和模型规模系统变化。

Abstract: Recent progress in large language models has renewed interest in mechanistically characterizing how multi-step reasoning is represented and computed. While much prior work treats reasoning as a linear chain of steps, many reasoning problems are more naturally structured as directed acyclic graphs (DAGs), where intermediate conclusions may depend on multiple premises, branch into parallel sub-derivations, and later merge or be reused. Understanding whether such graph-structured reasoning is reflected in model internals remains an open question.
  In this work, we introduce Reasoning DAG Probing, a framework that directly asks whether LLM hidden states encode the geometry of a reasoning DAG in a linearly accessible form, and where this structure emerges across layers. Within this framework, we associate each reasoning node with a textual realization and train lightweight probes to predict two graph-theoretic properties from hidden states: node depth and pairwise node distance. We use these probes to analyze the layerwise emergence of DAG structure and evaluate controls that disrupt reasoning-relevant structure while preserving superficial textual properties. Our results provide evidence that reasoning DAG geometry is meaningfully encoded in intermediate layers, with recoverability varying systematically by node depth and model scale, suggesting that LLM reasoning is not only sequential but exhibits measurable internal graph structure.

</details>


### [197] [Learning to Ideate for Machine Learning Engineering Agents](https://arxiv.org/abs/2601.17596)
*Yunxiang Zhang,Kang Zhou,Zhichao Xu,Kiran Ramnath,Yun Zhou,Sangmin Woo,Haibo Ding,Lin Lee Cheong*

Main category: cs.CL

TL;DR: MLE-Ideator：双智能体框架，将构思与实现分离，通过专门的构思者提供战略帮助，显著提升机器学习工程任务性能


<details>
  <summary>Details</summary>
Motivation: 现有机器学习工程智能体在迭代优化算法效果方面存在困难，需要更好的战略构思能力来提升算法实现的有效性

Method: 提出MLE-Ideator双智能体框架：实现智能体负责具体实施，构思智能体提供战略帮助；构思智能体可通过强化学习训练提升构思能力

Result: 1. 无训练设置下，框架在MLE-Bench上显著优于仅实现智能体基线；2. 强化学习训练后，Qwen3-8B构思智能体相对未训练版本提升11.5%，超越Claude Sonnet 3.5

Conclusion: 该框架为训练战略AI系统进行科学发现提供了有前景的路径，构思与实现分离的方法能有效提升机器学习工程任务性能

Abstract: Existing machine learning engineering (MLE) agents struggle to iteratively optimize their implemented algorithms for effectiveness. To address this, we introduce MLE-Ideator, a dual-agent framework that separates ideation from implementation. In our system, an implementation agent can request strategic help from a dedicated Ideator. We show this approach is effective in two ways. First, in a training-free setup, our framework significantly outperforms implementation-only agent baselines on MLE-Bench. Second, we demonstrate that the Ideator can be trained with reinforcement learning (RL) to generate more effective ideas. With only 1K training samples from 10 MLE tasks, our RL-trained Qwen3-8B Ideator achieves an 11.5% relative improvement compared to its untrained counterpart and surpasses Claude Sonnet 3.5. These results highlights a promising path toward training strategic AI systems for scientific discovery.

</details>


### [198] [What Language Models Know But Don't Say: Non-Generative Prior Extraction for Generalization](https://arxiv.org/abs/2601.17609)
*Sara Rezaeimanesh,Mohammad M. Ghassemi*

Main category: cs.CL

TL;DR: LoID：通过直接访问LLM的token级预测来提取贝叶斯逻辑回归先验分布的方法，在协变量偏移的OOD设置下显著提升性能


<details>
  <summary>Details</summary>
Motivation: 在医学和金融等领域，大规模标注数据成本高昂且难以获得，导致在小数据集上训练的模型难以泛化到真实世界群体。大型语言模型包含这些领域多年研究的广泛知识，如何有效利用这些知识提升模型在分布外场景的性能是一个重要问题。

Method: 提出LoID（Logit-Informed Distributions），一种确定性方法，通过直接访问LLM的token级预测来提取贝叶斯逻辑回归的信息先验分布。不依赖生成文本，而是通过精心构建的句子探测模型在相反语义方向（正面vs负面影响）上的置信度。通过测量LLM在不同表述中偏好某一方向的一致性，提取模型对每个特征影响的强度和可靠性的信念。

Result: 在10个真实世界表格数据集上，在合成协变量偏移的OOD设置下评估LoID。相比在OOD数据上训练的逻辑回归，LoID显著提升性能，恢复了相对于在完整数据集上训练的神谕模型高达59%的性能差距。LoID在8/10的数据集上优于AutoElicit和LLMProcesses方法，同时提供了可重复且计算高效的LLM知识集成机制。

Conclusion: LoID提供了一种有效的方法，通过直接访问LLM的内部预测来提取先验知识，在数据稀缺和协变量偏移的场景下显著提升贝叶斯逻辑回归的性能，为将LLM知识集成到统计推断中提供了新的途径。

Abstract: In domains like medicine and finance, large-scale labeled data is costly and often unavailable, leading to models trained on small datasets that struggle to generalize to real-world populations. Large language models contain extensive knowledge from years of research across these domains. We propose LoID (Logit-Informed Distributions), a deterministic method for extracting informative prior distributions for Bayesian logistic regression by directly accessing their token-level predictions. Rather than relying on generated text, we probe the model's confidence in opposing semantic directions (positive vs. negative impact) through carefully constructed sentences. By measuring how consistently the LLM favors one direction across diverse phrasings, we extract the strength and reliability of the model's belief about each feature's influence. We evaluate LoID on ten real-world tabular datasets under synthetic out-of-distribution (OOD) settings characterized by covariate shift, where the training data represents only a subset of the population. We compare our approach against (1) standard uninformative priors, (2) AutoElicit, a recent method that prompts LLMs to generate priors via text completions, (3) LLMProcesses, a method that uses LLMs to generate numerical predictions through in-context learning and (4) an oracle-style upper bound derived from fitting logistic regression on the full dataset. We assess performance using Area Under the Curve (AUC). Across datasets, LoID significantly improves performance over logistic regression trained on OOD data, recovering up to \textbf{59\%} of the performance gap relative to the oracle model. LoID outperforms AutoElicit and LLMProcessesc on 8 out of 10 datasets, while providing a reproducible and computationally efficient mechanism for integrating LLM knowledge into Bayesian inference.

</details>


### [199] [Beyond the Rabbit Hole: Mapping the Relational Harms of QAnon Radicalization](https://arxiv.org/abs/2601.17658)
*Bich Ngoc,Doan,Giuseppe Russo,Gianmarco De Francisci Morales,Robert West*

Main category: cs.CL

TL;DR: 该研究通过分析QAnon支持社区数据，首次系统性地描绘了阴谋论激进化的个人轨迹，识别出六种激进者原型，并量化了这些原型对亲友造成的特定情感伤害。


<details>
  <summary>Details</summary>
Motivation: 现有大规模计算研究主要关注阴谋论对公共话语的宏观影响，但忽视了其对亲友造成的个人情感伤害。本研究旨在填补这一空白，将激进化视为一种关系现象进行实证研究。

Method: 采用混合方法：1) 使用BERTopic主题建模分析12,747个r/QAnonCasualties社区叙事，描绘激进化轨迹；2) 应用LDA图模型识别六种激进化原型；3) 使用LLM辅助情感检测和回归模型，将原型与叙述者报告的情感伤害关联。

Result: 研究发现激进化原型不仅能描述激进者特征，还能预测亲友遭受的特定情感伤害：被视为意识形态选择的激进化与叙述者的愤怒和厌恶相关，而伴随个人和认知崩溃的激进化则与恐惧和悲伤相关。

Conclusion: 该研究首次提供了理解激进化作为关系现象的实证框架，为研究者和从业者应对其人际后果提供了重要路线图，强调了关注激进化对亲友情感伤害的重要性。

Abstract: The rise of conspiracy theories has created far-reaching societal harm in the public discourse by eroding trust and fueling polarization. Beyond this public impact lies a deeply personal toll on the friends and families of conspiracy believers, a dimension often overlooked in large-scale computational research. This study fills this gap by systematically mapping radicalization journeys and quantifying the associated emotional toll inflicted on loved ones. We use the prominent case of QAnon as a case study, analyzing 12747 narratives from the r/QAnonCasualties support community through a novel mixed-methods approach. First, we use topic modeling (BERTopic) to map the radicalization trajectories, identifying key pre-existing conditions, triggers, and post-radicalization characteristics. From this, we apply an LDA-based graphical model to uncover six recurring archetypes of QAnon adherents, which we term "radicalization personas." Finally, using LLM-assisted emotion detection and regression modeling, we link these personas to the specific emotional toll reported by narrators. Our findings reveal that these personas are not just descriptive; they are powerful predictors of the specific emotional harms experienced by narrators. Radicalization perceived as a deliberate ideological choice is associated with narrator anger and disgust, while those marked by personal and cognitive collapse are linked to fear and sadness. This work provides the first empirical framework for understanding radicalization as a relational phenomenon, offering a vital roadmap for researchers and practitioners to navigate its interpersonal fallout.

</details>


### [200] [UrduLM: A Resource-Efficient Monolingual Urdu Language Model](https://arxiv.org/abs/2601.17664)
*Syed Muhammad Ali,Hammad Sajid,Zainab Haider,Ali Muhammad Asad,Haya Fatima,Abdul Samad*

Main category: cs.CL

TL;DR: 本文提出了UrduLM，一个在低资源环境下预训练的乌尔都语单语语言模型，包括33GB语料库、定制BPE分词器和1亿参数的仅解码器模型，在少样本评估中性能优于多语言模型。


<details>
  <summary>Details</summary>
Motivation: 乌尔都语有2.3亿使用者，但缺乏专用的基于Transformer的语言模型和整理好的语料库。现有的多语言模型对乌尔都语支持有限，存在性能差、计算成本高和文化不准确等问题。

Method: 1) 从多种来源整理33GB乌尔都语语料库；2) 开发定制BPE分词器，比多语言替代方案减少20-30%的分词开销；3) 预训练1亿参数的仅解码器模型。

Result: 在少样本评估中，UrduLM达到了与比其大30倍的多语言模型相竞争的性能：情感分类准确率66.6%，语法纠正任务BLEU分数超过30。

Conclusion: 完整的方法论（包括语料库、分词器、模型权重和评估基准）已开源发布，为乌尔都语NLP研究建立了基线，并为其他资源不足语言提供了可扩展框架。

Abstract: Urdu, spoken by 230 million people worldwide, lacks dedicated transformer-based language models and curated corpora. While multilingual models provide limited Urdu support, they suffer from poor performance, high computational costs, and cultural inaccuracies due to insufficient training data. To address these challenges, we present UrduLM, a pretrained Urdu monolingual language model trained in low-resource settings. We curate a 33GB Urdu corpus from diverse sources, develop a custom BPE tokenizer that reduces tokenization overhead by atleast 20-30% compared to multilingual alternatives, and pretrain a 100M-parameter decoder-only model. In few-shot evaluations, UrduLM achieves competitive performance with multilingual models up to 30x its size, reaching 66.6% accuracy on sentiment classification and BLEU scores exceeding 30 on grammar correction tasks. The complete methodology -- including corpus, tokenizer, model weights, and evaluation benchmarks -- is released openly to establish a baseline for Urdu NLP research and provide a scalable framework for other underrepresented languages.

</details>


### [201] [Align to the Pivot: Dual Alignment with Self-Feedback for Multilingual Math Reasoning](https://arxiv.org/abs/2601.17671)
*Chunxu Zhao,Xin Huang,Xue Han,Shujian Huang,Chao Deng,Junlan Feng*

Main category: cs.CL

TL;DR: PASMR方法通过将主要语言设为枢轴语言，让模型先将问题翻译到枢轴语言进行推理对齐，然后通过跨语言自我反馈机制提升LLMs的多语言数学推理能力。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型展现出强大的推理能力，但在多语言环境下（特别是低资源语言）性能会下降，这是因为模型的多语言理解和推理对齐不一致。需要解决LLMs在不同语言间推理能力不对齐的问题。

Method: PASMR方法：1）将模型的主要语言设为枢轴语言；2）训练时先将问题翻译到枢轴语言以对齐推理模式；3）目标语言的推理过程受枢轴语言推理答案监督；4）建立跨语言自我反馈机制，无需外部正确答案或奖励模型。

Result: 广泛的实验结果表明，该方法显著提升了模型对问题的理解和推理能力，在多语言数学推理任务上取得了明显改进。

Conclusion: PASMR通过跨语言自我反馈机制有效解决了LLMs在多语言环境下的推理对齐问题，特别是对低资源语言有显著提升，为多语言推理能力对齐提供了有效解决方案。

Abstract: Despite the impressive reasoning abilities demonstrated by large language models (LLMs), empirical evidence indicates that they are not language agnostic as expected, leading to performance declines in multilingual settings, especially for low-resource languages. We attribute the decline to the model's inconsistent multilingual understanding and reasoning alignment. To address this, we present Pivot-Aligned Self-Feedback Multilingual Reasoning (PASMR), aiming to improve the alignment of multilingual math reasoning abilities in LLMs. This approach designates the model's primary language as the pivot language. During training, the model first translates questions into the pivot language to facilitate better alignment of reasoning patterns. The reasoning process in the target language is then supervised by the pivot language's reasoning answers, thereby establishing a cross-lingual self-feedback mechanism without relying on external correct answers or reward models. Extensive experimental results demonstrate that our method enhances both the model's understanding of questions and its reasoning capabilities, leading to notable task improvements.

</details>


### [202] [S$^3$-Attention:Attention-Aligned Endogenous Retrieval for Memory-Bounded Long-Context Inference](https://arxiv.org/abs/2601.17702)
*Qingsen Ma,Dianyun Wang,Yaoye Wang,Lechen Ning,Sujie Zhu,Xiaohang Zhang,Jiaming Lyu,Linhao Ren,Zhenbo Xu,Zhaofeng He*

Main category: cs.CL

TL;DR: S3-Attention是一种内存优先的推理框架，通过将长上下文处理视为注意力对齐的内生检索，完全丢弃KV缓存，用稀疏特征标识符和CPU倒排索引来管理长文档处理。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在处理多文档和长文本时面临内存效率低和噪声问题。KV缓存随上下文长度线性增长，而外部检索方法常返回词汇相似但因果无关的段落。

Method: S3-Attention将瞬态键和查询投影解码为top-k稀疏特征标识符，使用轻量级稀疏自编码器，在单次流式扫描中构建CPU倒排索引，将特征映射到token位置或跨度。生成时使用特征共激活检索紧凑证据跨度，可选与BM25融合进行精确词汇匹配。

Result: 在统一的LongBench评估协议下，S3-Hybrid在多个模型家族中接近全上下文推理性能，并在多个信息密集场景中提高了鲁棒性。但当前原型存在工程限制，比优化的全KV基线有更高的实际延迟。

Conclusion: S3-Attention提供了一种内存高效的框架来处理长上下文，完全避免了KV缓存的内存开销，但需要未来内核级优化来减少延迟。

Abstract: Large language models are increasingly applied to multi-document and long-form inputs, yet long-context inference remains memory- and noise-inefficient. Key-value (KV) caching scales linearly with context length, while external retrieval methods often return lexically similar but causally irrelevant passages.
  We present S3-Attention, a memory-first inference-time framework that treats long-context processing as attention-aligned endogenous retrieval. S3-Attention decodes transient key and query projections into top-k sparse feature identifiers using lightweight sparse autoencoders, and constructs a CPU-based inverted index mapping features to token positions or spans during a single streaming scan. This design allows the KV cache to be discarded entirely and bounds GPU memory usage by the scan chunk size.
  At generation time, feature co-activation is used to retrieve compact evidence spans, optionally fused with BM25 for exact lexical matching. Under a unified LongBench evaluation protocol with fixed prompting, decoding, and matched token budgets, S3-Hybrid closely matches full-context inference across multiple model families and improves robustness in several information-dense settings. We also report an engineering limitation of the current prototype, which incurs higher wall-clock latency than optimized full-KV baselines, motivating future kernel-level optimization.

</details>


### [203] [Distance-to-Distance Ratio: A Similarity Measure for Sentences Based on Rate of Change in LLM Embeddings](https://arxiv.org/abs/2601.17705)
*Abdullah Qureshi,Kenneth Rice,Alexander Wolpert*

Main category: cs.CL

TL;DR: 提出DDR距离比度量方法，用于评估LLM句子嵌入的相似性，通过测量上下文对语义的影响，比现有方法能更好地区分语义相似与不相似的文本。


<details>
  <summary>Details</summary>
Motivation: 文本嵌入的相似性度量必须符合人类对文本相似性的感知，现有方法在这方面存在不足，需要一种能更准确反映语义相似性的新度量。

Method: 提出距离-距离比(DDR)方法，受Lipschitz连续性启发，测量上下文前词嵌入相似性与上下文后LLM嵌入相似性的变化率，从而量化上下文的语义影响。通过替换句子中的单词（同义词或随机词）生成变体进行实验评估。

Result: DDR在实验中表现出色，即使在最小化、受控的编辑下，也能比现有相似性度量方法更精细地区分语义相似和不相似的文本。

Conclusion: DDR是一种有效的LLM句子嵌入相似性度量方法，能更好地捕捉语义相似性，为文本相似性评估提供了改进方案。

Abstract: A measure of similarity between text embeddings can be considered adequate only if it adheres to the human perception of similarity between texts. In this paper, we introduce the distance-to-distance ratio (DDR), a novel measure of similarity between LLM sentence embeddings. Inspired by Lipschitz continuity, DDR measures the rate of change in similarity between the pre-context word embeddings and the similarity between post-context LLM embeddings, thus measuring the semantic influence of context. We evaluate the performance of DDR in experiments designed as a series of perturbations applied to sentences drawn from a sentence dataset. For each sentence, we generate variants by replacing one, two, or three words with either synonyms, which constitute semantically similar text, or randomly chosen words, which constitute semantically dissimilar text. We compare the performance of DDR with other prevailing similarity metrics and demonstrate that DDR consistently provides finer discrimination between semantically similar and dissimilar texts, even under minimal, controlled edits.

</details>


### [204] [A Computational Approach to Visual Metonymy](https://arxiv.org/abs/2601.17706)
*Saptarshi Ghosh,Linfeng Liu,Tianyu Jiang*

Main category: cs.CL

TL;DR: 首个视觉转喻计算研究，提出基于符号学理论的生成框架，构建ViMET数据集评估多模态模型，发现人类与AI在理解间接视觉引用方面存在显著差距


<details>
  <summary>Details</summary>
Motivation: 图像经常传达比字面描绘更多的信息，这种间接视觉引用（视觉转喻）让观众通过关联线索而非明确描绘来理解目标概念。目前缺乏对视觉转喻的计算研究，需要评估多模态模型在这方面的认知推理能力。

Method: 提出基于符号学理论的新颖流程，利用大语言模型和文本到图像模型生成转喻视觉表示。使用该框架构建ViMET数据集，包含2000个多项选择题来评估多模态语言模型的认知推理能力。

Result: 实验结果显示人类表现（86.9%）与最先进的视觉语言模型（65.9%）之间存在显著差距，突显了机器在解释间接视觉引用方面的局限性。

Conclusion: 这是首个视觉转喻的计算研究，提出的生成框架和ViMET数据集为评估多模态模型的认知推理能力提供了基准，揭示了当前AI在理解间接视觉引用方面的不足。

Abstract: Images often communicate more than they literally depict: a set of tools can suggest an occupation and a cultural artifact can suggest a tradition. This kind of indirect visual reference, known as visual metonymy, invites viewers to recover a target concept via associated cues rather than explicit depiction. In this work, we present the first computational investigation of visual metonymy. We introduce a novel pipeline grounded in semiotic theory that leverages large language models and text-to-image models to generate metonymic visual representations. Using this framework, we construct ViMET, the first visual metonymy dataset comprising 2,000 multiple-choice questions to evaluate the cognitive reasoning abilities in multimodal language models. Experimental results on our dataset reveal a significant gap between human performance (86.9%) and state-of-the-art vision-language models (65.9%), highlighting limitations in machines' ability to interpret indirect visual references. Our dataset is publicly available at: https://github.com/cincynlp/ViMET.

</details>


### [205] [Unsupervised Elicitation of Moral Values from Language Models](https://arxiv.org/abs/2601.17728)
*Meysam Alizadeh,Fabrizio Gilardi,Zeynab Samei*

Main category: cs.CL

TL;DR: 该论文提出了一种无监督方法ICM来激发预训练语言模型的内在道德推理能力，无需人工监督即可实现与人类标注相媲美的道德判断性能。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统普及，如何将其行为与人类价值观对齐变得至关重要。现有研究表明语言模型的内在道德推理能力有限，但构建道德评估的真实数据又面临多元道德框架和普遍偏见的问题。因此需要探索无监督方法来激发预训练模型的内在道德推理能力。

Method: 采用Internal Coherence Maximization (ICM)算法，在三个基准数据集和四个语言模型上进行测试。ICM通过最大化内部一致性来无监督地激发模型的道德判断能力，并评估其在道德标签生成、跨道德框架泛化和减少社会偏见方面的表现。

Result: ICM在Norm Bank和ETHICS基准上优于所有预训练和聊天机器人基线模型。使用ICM标签进行微调的模型性能与人类标签相当甚至更好。在Justice和Commonsense道德框架上ICM获得最大相对增益。ICM将社会偏见错误率降低一半以上，在种族、社会经济地位和政治方面的改进最大。

Conclusion: 预训练语言模型具有潜在的道德推理能力，可以通过ICM等无监督方法激发出来。这为AI对齐提供了一条可扩展的路径，无需依赖人工标注的道德数据就能实现有效的道德判断。

Abstract: As AI systems become pervasive, grounding their behavior in human values is critical. Prior work suggests that language models (LMs) exhibit limited inherent moral reasoning, leading to calls for explicit moral teaching. However, constructing ground truth data for moral evaluation is difficult given plural frameworks and pervasive biases. We investigate unsupervised elicitation as an alternative, asking whether pretrained (base) LMs possess intrinsic moral reasoning capability that can be surfaced without human supervision. Using the Internal Coherence Maximization (ICM) algorithm across three benchmark datasets and four LMs, we test whether ICM can reliably label moral judgments, generalize across moral frameworks, and mitigate social bias. Results show that ICM outperforms all pre-trained and chatbot baselines on the Norm Bank and ETHICS benchmarks, while fine-tuning on ICM labels performs on par with or surpasses those of human labels. Across theoretically motivated moral frameworks, ICM yields its largest relative gains on Justice and Commonsense morality. Furthermore, although chatbot LMs exhibit social bias failure rates comparable to their pretrained ones, ICM reduces such errors by more than half, with the largest improvements in race, socioeconomic status, and politics. These findings suggest that pretrained LMs possess latent moral reasoning capacities that can be elicited through unsupervised methods like ICM, providing a scalable path for AI alignment.

</details>


### [206] [Hylog: A Hybrid Approach to Logging Text Production in Non-alphabetic Scripts](https://arxiv.org/abs/2601.17753)
*Roberto Crotti,Giovanni Denaro,Zhiqiang Du,Ricardo Muñoz Martín*

Main category: cs.CL

TL;DR: Hylog是一个混合日志系统，结合分析性键盘记录和生态文本记录，用于捕捉非字母文字输入法编辑器的屏幕转换，支持多语言文本生产研究。


<details>
  <summary>Details</summary>
Motivation: 现有研究键盘记录工具大多无法捕捉非字母文字输入法编辑器（IME）的屏幕转换，这限制了认知文本生产研究的完整性和准确性。

Method: 开发模块化开源系统Hylog，使用插件捕获标准应用程序中的键盘输出和渲染文本，通过混合器模块同步为双重轨迹。

Result: 概念验证研究中，Hylog成功捕获了拉丁字母、中文字符和IME确认之间的按键和时空间隔，这些测量传统键盘记录器无法捕捉。

Conclusion: Hylog系统填补了方法论空白，能够制定关于IME中介打字中不同语言层面认知限制和可供性的新假设，支持更包容的多语言文本生产研究。

Abstract: Research keyloggers are essential for cognitive studies of text production, yet most fail to capture the on-screen transformations performed by Input Method Editors (IMEs) for non-alphabetic scripts. To address this methodological gap, we present Hylog, a novel hybrid logging system that combines analytical keylogging with ecological text logging for a more complete and finer-grained analysis. Our modular, open-source system uses plug-ins for standard applications (Microsoft Word, Google Chrome) to capture both keyboard output and rendered text, which a hybridizer module then synchronizes into a dual trace. To validate the system's technical feasibility and demonstrate its analytical capabilities, we conducted a proof-of-concept study where two volunteers translated a text into simplified Chinese. Hylog successfully captured keypresses and temporal intervals between Latin letters, Chinese characters, and IME confirmations -- some measurements invisible to traditional keyloggers. The resulting data enable the formulation of new, testable hypotheses about the cognitive restrictions and affordances at different linguistic layers in IME-mediated typing. Our plug-in architecture enables extension to other IME systems and fosters more inclusive multilingual text-production research.

</details>


### [207] [ProGraph-R1: Progress-aware Reinforcement Learning for Graph Retrieval Augmented Generation](https://arxiv.org/abs/2601.17755)
*Jinyoung Park,Sanghyeok Lee,Omar Zia Khan,Hyunwoo J. Kim,Joo-Kyung Kim*

Main category: cs.CL

TL;DR: ProGraph-R1提出了一种基于进展感知的图检索增强生成框架，通过结构感知的超图检索机制和基于进展的逐步策略优化，解决了现有RL-based GraphRAG方法在检索和奖励机制上的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的GraphRAG框架（如Graph-R1）存在两个关键限制：1）主要依赖语义相似性进行检索，忽视了底层图结构；2）依赖稀疏的结果级奖励，无法捕捉中间检索步骤的质量及其依赖关系。

Method: 提出了ProGraph-R1框架，包含两个核心创新：1）结构感知的超图检索机制，同时考虑语义相关性和图连接性，鼓励沿着多跳推理路径进行连贯遍历；2）基于进展的逐步策略优化，通过根据图中中间推理进展调整优势来提供密集学习信号。

Result: 在多跳问答基准测试中，ProGraph-R1相比现有GraphRAG方法，在推理准确性和生成质量方面均取得了一致的提升。

Conclusion: ProGraph-R1通过结合结构感知检索和进展感知策略优化，有效解决了现有RL-based GraphRAG框架的局限性，为图检索增强生成提供了更有效的多步推理能力。

Abstract: Graph Retrieval-Augmented Generation (GraphRAG) has been successfully applied in various knowledge-intensive question answering tasks by organizing external knowledge into structured graphs of entities and relations. It enables large language models (LLMs) to perform complex reasoning beyond text-chunk retrieval. Recent works have employed reinforcement learning (RL) to train agentic GraphRAG frameworks that perform iterative interactions between LLMs and knowledge graphs. However, existing RL-based frameworks such as Graph-R1 suffer from two key limitations: (1) they primarily depend on semantic similarity for retrieval, often overlooking the underlying graph structure, and (2) they rely on sparse, outcome-level rewards, failing to capture the quality of intermediate retrieval steps and their dependencies. To address these limitations, we propose ProGraph-R1, a progress-aware agentic framework for graph-based retrieval and multi-step reasoning. ProGraph-R1 introduces a structure-aware hypergraph retrieval mechanism that jointly considers semantic relevance and graph connectivity, encouraging coherent traversal along multi-hop reasoning paths. We also design a progress-based step-wise policy optimization, which provides dense learning signals by modulating advantages according to intermediate reasoning progress within a graph, rather than relying solely on final outcomes. Experiments on multi-hop question answering benchmarks demonstrate that ProGraph-R1 consistently improves reasoning accuracy and generation quality over existing GraphRAG methods.

</details>


### [208] [Cross-Lingual Probing and Community-Grounded Analysis of Gender Bias in Low-Resource Bengali](https://arxiv.org/abs/2601.17764)
*Md Asgor Hossain Reaj,Rajan Das Gupta,Jui Saha Pritha,Abdullah Al Noman,Abir Ahmed,Golam Md Mohiuddin,Tze Hui Liew*

Main category: cs.CL

TL;DR: 该研究探讨了孟加拉语中LLM的性别偏见问题，发现英语中心的偏见检测框架在孟加拉语中效果有限，需要本地化和社区驱动的方法。


<details>
  <summary>Details</summary>
Motivation: LLM在非英语语言（特别是孟加拉语等全球南方语言）中的性别偏见研究不足，现有英语中心的方法无法有效检测和处理这些语言中的文化特定偏见。

Method: 采用多种方法：基于词典的挖掘、计算分类模型、翻译比较分析、GPT偏见生成，并在农村和低收入地区进行实地调查收集真实数据。

Result: 孟加拉语的性别偏见与英语有显著不同，英语中心框架因语言差异和社会文化因素而受限，需要本地化和情境敏感的方法。

Conclusion: 需要为代表性不足的语言开发专门的偏见检测工具，结合社区驱动方法识别文化相关偏见，为孟加拉语和其他印度语言建立更公平的NLP系统奠定基础。

Abstract: Large Language Models (LLMs) have achieved significant success in recent years; yet, issues of intrinsic gender bias persist, especially in non-English languages. Although current research mostly emphasizes English, the linguistic and cultural biases inherent in Global South languages, like Bengali, are little examined. This research seeks to examine the characteristics and magnitude of gender bias in Bengali, evaluating the efficacy of current approaches in identifying and alleviating bias. We use several methods to extract gender-biased utterances, including lexicon-based mining, computational classification models, translation-based comparison analysis, and GPT-based bias creation. Our research indicates that the straight application of English-centric bias detection frameworks to Bengali is severely constrained by language disparities and socio-cultural factors that impact implicit biases. To tackle these difficulties, we executed two field investigations inside rural and low-income areas, gathering authentic insights on gender bias. The findings demonstrate that gender bias in Bengali presents distinct characteristics relative to English, requiring a more localized and context-sensitive methodology. Additionally, our research emphasizes the need of integrating community-driven research approaches to identify culturally relevant biases often neglected by automated systems. Our research enhances the ongoing discussion around gender bias in AI by illustrating the need to create linguistic tools specifically designed for underrepresented languages. This study establishes a foundation for further investigations into bias reduction in Bengali and other Indic languages, promoting the development of more inclusive and fair NLP systems.

</details>


### [209] [DPI: Exploiting Parameter Heterogeneity for Interference-Free Fine-Tuning](https://arxiv.org/abs/2601.17777)
*Xiaoyu Liu,Xiaoyu Guan,Di Liang,Xianjie Wu*

Main category: cs.CL

TL;DR: 提出动态参数隔离策略解决SFT中的跷跷板效应，通过识别任务核心参数区域并隔离训练，减少任务间冲突


<details>
  <summary>Details</summary>
Motivation: 监督微调中异构任务的目标冲突会导致"跷跷板效应"：优化一个任务会降低其他任务性能，特别是当模型参数被无差别更新时

Method: 首先独立微调LLMs识别每个任务的核心参数区域（更新最大的参数子集），合并重叠核心区域的任务进行联合训练，将不相交任务组织到不同阶段，在多阶段SFT中冻结先前任务获得的核心参数

Result: 在多个公共数据集上的实验表明，动态参数隔离策略能持续减少数据冲突，相比多阶段和多任务调优基线获得一致的性能提升

Conclusion: 通过参数异质性假设和动态参数隔离，有效解决了SFT中的任务冲突问题，提高了模型在多任务场景下的性能稳定性

Abstract: Supervised fine-tuning (SFT) is a crucial step for adapting large language models (LLMs) to downstream tasks. However, conflicting objectives across heterogeneous SFT tasks often induce the "seesaw effect": optimizing for one task may degrade performance on others, particularly when model parameters are updated indiscriminately. In this paper, we propose a principled approach to disentangle and isolate task-specific parameter regions, motivated by the hypothesis that parameter heterogeneity underlies cross-task interference. Specifically, we first independently fine-tune LLMs on diverse SFT tasks and identify each task's core parameter region as the subset of parameters exhibiting the largest updates. Tasks with highly overlapping core parameter regions are merged for joint training, while disjoint tasks are organized into different stages. During multi-stage SFT, core parameters acquired in prior tasks are frozen, thereby preventing overwriting by subsequent tasks. To verify the effectiveness of our method, we conducted intensive experiments on multiple public datasets. The results showed that our dynamic parameter isolation strategy consistently reduced data conflicts and achieved consistent performance improvements compared to multi-stage and multi-task tuning baselines.

</details>


### [210] [Controlling Reading Ease with Gaze-Guided Text Generation](https://arxiv.org/abs/2601.17781)
*Andreas Säuberli,Darja Jepifanova,Diego Frassinelli,Barbara Plank*

Main category: cs.CL

TL;DR: 利用眼动预测模型控制文本生成，实现可调节的阅读难度，通过眼动实验验证对母语和非母语者的有效性


<details>
  <summary>Details</summary>
Motivation: 阅读时的眼动模式能反映文本处理的认知负荷，这为生成可控阅读难度的文本提供了可能，有助于提升信息可及性和语言学习材料个性化

Method: 使用预测人类注视模式的模型来引导语言模型输出，使其引发特定的阅读行为，通过眼动追踪实验评估方法效果

Result: 方法能有效使生成文本变易或变难，体现在阅读时间和感知难度上；统计分析显示阅读行为变化主要源于影响词汇处理的文本特征

Conclusion: 基于眼动预测的文本生成方法能有效控制阅读难度，在信息可及性文本简化和个性化语言学习材料生成方面有应用前景

Abstract: The way our eyes move while reading can tell us about the cognitive effort required to process the text. In the present study, we use this fact to generate texts with controllable reading ease. Our method employs a model that predicts human gaze patterns to steer language model outputs towards eliciting certain reading behaviors. We evaluate the approach in an eye-tracking experiment with native and non-native speakers of English. The results demonstrate that the method is effective at making the generated texts easier or harder to read, measured both in terms of reading times and perceived difficulty of the texts. A statistical analysis reveals that the changes in reading behavior are mostly due to features that affect lexical processing. Possible applications of our approach include text simplification for information accessibility and generation of personalized educational material for language learning.

</details>


### [211] [Beyond a Single Perspective: Text Anomaly Detection with Multi-View Language Representations](https://arxiv.org/abs/2601.17786)
*Yixin Liu,Kehan Yan,Shiyuan Li,Qingfeng Chen,Shirui Pan*

Main category: cs.CL

TL;DR: 本文提出了MCA²，一个多视图文本异常检测框架，通过整合多个预训练语言模型的嵌入表示，使用多视图重构模型提取正常文本模式，并设计了对比协作模块和自适应分配模块来提升检测性能和适应性。


<details>
  <summary>Details</summary>
Motivation: 现有两阶段"嵌入-检测器"文本异常检测方法通常使用单一嵌入模型，缺乏对不同数据集和异常类型的适应性，限制了其性能表现。

Method: 提出MCA²框架：1) 利用多个预训练语言模型的嵌入创建多视图表示；2) 使用多视图重构模型从多个嵌入视角提取正常文本模式；3) 设计对比协作模块加强不同视图间的交互和互补性；4) 开发自适应分配模块自动分配每个视图的贡献权重。

Result: 在10个基准数据集上的广泛实验验证了MCA²相对于强基线的有效性，表明该方法在文本异常检测任务上具有优越性能。

Conclusion: MCA²通过整合多模型嵌入、多视图重构、对比协作和自适应权重分配，有效解决了现有文本异常检测方法的局限性，提升了检测性能和跨数据集的适应性。

Abstract: Text anomaly detection (TAD) plays a critical role in various language-driven real-world applications, including harmful content moderation, phishing detection, and spam review filtering. While two-step "embedding-detector" TAD methods have shown state-of-the-art performance, their effectiveness is often limited by the use of a single embedding model and the lack of adaptability across diverse datasets and anomaly types. To address these limitations, we propose to exploit the embeddings from multiple pretrained language models and integrate them into $MCA^2$, a multi-view TAD framework. $MCA^2$ adopts a multi-view reconstruction model to effectively extract normal textual patterns from multiple embedding perspectives. To exploit inter-view complementarity, a contrastive collaboration module is designed to leverage and strengthen the interactions across different views. Moreover, an adaptive allocation module is developed to automatically assign the contribution weight of each view, thereby improving the adaptability to diverse datasets. Extensive experiments on 10 benchmark datasets verify the effectiveness of $MCA^2$ against strong baselines. The source code of $MCA^2$ is available at https://github.com/yankehan/MCA2.

</details>


### [212] [DIETA: A Decoder-only transformer-based model for Italian-English machine TrAnslation](https://arxiv.org/abs/2601.17823)
*Pranav Kasela,Marco Braga,Alessandro Ghiotto,Andrea Pilzer,Marco Viviani,Alessandro Raganato*

Main category: cs.CL

TL;DR: DIETA是一个专为意大利语-英语机器翻译设计的5亿参数解码器Transformer模型，在多个基准测试中表现优异，排名前50%，并超越了大多数30亿参数以下的模型。


<details>
  <summary>Details</summary>
Motivation: 针对意大利语-英语机器翻译领域缺乏专门优化的小型模型，需要构建高质量平行语料库和评估数据集来提升该语言对的翻译质量。

Method: 收集并整理了约2.07亿句意大利语-英语平行语料，涵盖议会记录、法律文本、网络爬取内容、字幕、新闻、文学等多个领域，并使用预训练模型生成了3.52亿句回译数据。构建了基于2025年WikiNews文章的450句小型评估集。

Result: DIETA在多个意大利语-英语基准测试中表现出色，在32个系统的排行榜中稳定排名第二四分位数（前50%），在五个测试套件中的四个上超越了大多数30亿参数以下的模型。

Conclusion: DIETA为意大利语-英语机器翻译提供了一个高效的小型解决方案，通过公开训练脚本、模型、语料库和评估集，促进了该专业领域的研究和发展。

Abstract: In this paper, we present DIETA, a small, decoder-only Transformer model with 0.5 billion parameters, specifically designed and trained for Italian-English machine translation. We collect and curate a large parallel corpus consisting of approximately 207 million Italian-English sentence pairs across diverse domains, including parliamentary proceedings, legal texts, web-crawled content, subtitles, news, literature and 352 million back-translated data using pretrained models. Additionally, we create and release a new small-scale evaluation set, consisting of 450 sentences, based on 2025 WikiNews articles, enabling assessment of translation quality on contemporary text. Comprehensive evaluations show that DIETA achieves competitive performance on multiple Italian-English benchmarks, consistently ranking in the second quartile of a 32-system leaderboard and outperforming most other sub-3B models on four out of five test suites. The training script, trained models, curated corpus, and newly introduced evaluation set are made publicly available, facilitating further research and development in specialized Italian-English machine translation. https://github.com/pkasela/DIETA-Machine-Translation

</details>


### [213] [Linguistic and Argument Diversity in Synthetic Data for Function-Calling Agents](https://arxiv.org/abs/2601.17829)
*Dan Greenstein,Zohar Karnin,Chen Amiraz,Oren Somekh*

Main category: cs.CL

TL;DR: 提出一种通过优化通用多样性指标来生成函数调用代理训练数据的方法，在保持正确性的同时提升查询和参数的多样性，在OOD性能上表现优异。


<details>
  <summary>Details</summary>
Motivation: 构建函数调用代理需要高质量多样的训练数据，现有方法在函数、调用模式和交互轮次上关注多样性，但请求的语言多样性和参数覆盖（如城市名、股票代码）仍不足。

Method: 提出一种生成合成数据集的方法，通过优化通用多样性指标来同时提升查询和参数的多样性，不依赖手工规则或分类法，适用于不同用例。

Result: 在内在和外在测试中优于现有数据生成方法，在保持可比正确性的同时显著提升多样性。使用该数据集训练的模型在分布外性能上优于基线方法，在BFCL基准上准确率提升7.4%。

Conclusion: 提出的数据生成方法能有效提升函数调用代理训练数据的多样性，从而改善模型在分布外场景下的性能表现。

Abstract: The construction of function calling agents has emerged as a promising avenue for extending model capabilities. A major challenge for this task is obtaining high quality diverse data for training. Prior work emphasizes diversity in functions, invocation patterns, and interaction turns, yet linguistic diversity of requests and coverage of arguments (e.g., \texttt{city\_name}, \texttt{stock\_ticker}) remain underexplored. We propose a method that generates synthetic datasets via optimizing general-purpose diversity metrics across both queries and arguments, without relying on hand-crafted rules or taxonomies, making it robust to different usecases. We demonstrate the effectiveness of our technique via both intrinsic and extrinsic testing, comparing it to SoTA data generation methods. We show a superiority over baselines in terms of diversity, while keeping comparable correctness. Additionally, when used as a training set, the model resulting from our dataset exhibits superior performance compared to analogous models based on the baseline data generation methods in out-of-distribution performance. In particular, we achieve an $7.4\%$ increase in accuracy on the BFCL benchmark compared to similar counterparts.

</details>


### [214] [EFT-CoT: A Multi-Agent Chain-of-Thought Framework for Emotion-Focused Therapy](https://arxiv.org/abs/2601.17842)
*Lanqing Du,Yunong Li,YuJie Long,Shihong Chen*

Main category: cs.CL

TL;DR: EFT-CoT：基于情绪聚焦疗法的多智能体思维链框架，通过"自下而上"的三阶段推理流程（具身感知-认知探索-叙事干预）提升心理健康问答的共情深度和专业性


<details>
  <summary>Details</summary>
Motivation: 现有基于认知行为疗法（CBT）的心理健康问答方法主要采用"自上而下"的理性重构，往往忽视来访者的具身体验和初级情绪处理，需要更关注情绪体验的干预方法

Method: 提出基于情绪聚焦疗法（EFT）的多智能体思维链框架（EFT-CoT），采用"自下而上"的三阶段推理流程：具身感知、认知探索、叙事干预，使用8个专门智能体执行躯体意识映射、适应性评估、核心信念提取和叙事重构等关键组件

Result: 构建了包含约67,000条真实文本的高质量数据集EFT-Instruct，并微调了专门模型EFT-LLM。实验表明EFT-LLM在共情深度和结构专业性等指标上优于强基线模型和人类回应，消融研究证实了多智能体机制的必要性

Conclusion: EFT-LLM展现出优越的心理推理能力，为可解释、高共情的心理咨询系统提供了有效途径，通过情绪聚焦疗法和多智能体思维链框架显著提升了心理健康问答的质量

Abstract: Leveraging Large Language Models (LLMs) for Mental Health Question Answering (MHQA) is promising for mitigating resource shortages. However, existing Cognitive Behavioral Therapy (CBT)-based approaches predominantly favor a "top-down" rational restructuring, often neglecting clients' embodied experiences and primary emotion processing. To address this, we propose an Emotion-Focused Therapy (EFT)-based Multi-Agent Chain-of-Thought framework (EFT-CoT). Adopting a "bottom-up" trajectory, it deconstructs the intervention into a three-stage reasoning flow: "Embodied Perception - Cognitive Exploration - Narrative Intervention." Utilizing eight specialized agents, the system explicitly executes critical components such as somatic awareness mapping, adaptive assessment, core belief extraction, and narrative restructuring. We further constructed "EFT-Instruct," a high-quality dataset via Chain-of-Thought distillation of approximately 67,000 authentic texts, and fine-tuned a specialized model, EFT-LLM. Experimental evaluations demonstrate that EFT-LLM outperforms strong baselines and human responses across metrics like empathy depth and structural professionalism. Ablation studies confirm the necessity of the multi-agent mechanism. The model exhibits superior psychological reasoning, offering an effective pathway for interpretable, high-empathy counseling systems.

</details>


### [215] [D-Models and E-Models: Diversity-Stability Trade-offs in the Sampling Behavior of Large Language Models](https://arxiv.org/abs/2601.17865)
*Jia Gu,Liang Pang,Huawei Shen,Xueqi Cheng*

Main category: cs.CL

TL;DR: 研究发现LLMs在细粒度采样概率上存在两种类型：D-模型（如Qwen-2.5）的token概率波动大且与任务分布对齐差；E-模型（如Mistral-Small）的token概率更稳定且与任务分布对齐更好，这两种模型在多样性和稳定性之间存在系统权衡。


<details>
  <summary>Details</summary>
Motivation: 虽然LLMs能生成近似真实世界分布的样本，但其细粒度采样概率是否忠实对齐任务需求仍是一个开放问题。研究旨在探索LLMs的token级预测概率与任务级目标分布之间的对齐程度。

Method: 通过受控分布采样模拟，识别出两种LLM类型：D-模型和E-模型。在下游任务（代码生成和推荐）中评估这两种模型类型，并分析它们的内在属性以探究底层机制。

Result: 发现LLMs存在显著二分行为：D-模型的P_token具有大的步间变异性且与P_task对齐差；E-模型的P_token更稳定且与P_task对齐更好。在代码生成和推荐任务中，两种模型类型展现出多样性与稳定性之间的系统权衡。

Conclusion: 研究为LLMs的概率采样行为提供了基础性见解，并为何时选择D-模型或E-模型提供了实践指导。对于推荐、搜索和对话代理等网络规模应用，结果可为模型选择和配置提供参考，以在现实世界不确定性下平衡多样性与可靠性。

Abstract: The predictive probability of the next token (P_token) in large language models (LLMs) is inextricably linked to the probability of relevance for the next piece of information, the purchase probability of the next product, and the execution probability of the next action-all of which fall under the scope of the task-level target distribution (P_task). While LLMs are known to generate samples that approximate real-world distributions, whether their fine-grained sampling probabilities faithfully align with task requirements remains an open question. Through controlled distribution-sampling simulations, we uncover a striking dichotomy in LLM behavior, distinguishing two model types: D-models (e.g. Qwen-2.5), whose P_token exhibits large step-to-step variability and poor alignment with P_task; and E-models (e.g. Mistral-Small), whose P_token is more stable and better aligned with P_task. We further evaluate these two model types in downstream tasks such as code generation and recommendation, revealing systematic trade-offs between diversity and stability that shape task outcomes. Finally, we analyze the internal properties of both model families to probe their underlying mechanisms. These findings offer foundational insights into the probabilistic sampling behavior of LLMs and provide practical guidance on when to favor D- versus E-models. For web-scale applications, including recommendation, search, and conversational agents, our results inform model selection and configuration to balance diversity with reliability under real-world uncertainty, providing a better level of interpretation.

</details>


### [216] [On the Emergence and Test-Time Use of Structural Information in Large Language Models](https://arxiv.org/abs/2601.17869)
*Michelle Chao Chen,Moritz Miller,Bernhard Schölkopf,Siyuan Guo*

Main category: cs.CL

TL;DR: 语言模型学习抽象结构信息的能力与复杂推理任务相关，但测试时组合生成能力有限


<details>
  <summary>Details</summary>
Motivation: 研究语言模型如何学习抽象结构信息及其在测试时的应用，这对于科学发现中的机制理解和灵活的组合生成至关重要

Method: 设计基于语言结构转换的自然语言数据集，在受控设置下研究语言模型学习结构信息的能力

Result: 学习结构信息的出现与复杂推理任务相关，但模型在测试时进行组合生成的能力仍然有限

Conclusion: 语言模型能够学习抽象结构信息，但需要进一步研究如何提升其在测试时的组合生成能力

Abstract: Learning structural information from observational data is central to producing new knowledge outside the training corpus. This holds for mechanistic understanding in scientific discovery as well as flexible test-time compositional generation. We thus study how language models learn abstract structures and utilize the learnt structural information at test-time. To ensure a controlled setup, we design a natural language dataset based on linguistic structural transformations. We empirically show that the emergence of learning structural information correlates with complex reasoning tasks, and that the ability to perform test-time compositional generation remains limited.

</details>


### [217] [Self-Manager: Parallel Agent Loop for Long-form Deep Research](https://arxiv.org/abs/2601.17879)
*Yilong Xu,Zhi Zheng,Xiang Long,Yujun Cai,Yiwei Wang*

Main category: cs.CL

TL;DR: Self-Manager：一种并行代理循环框架，通过多线程隔离上下文实现异步并发执行，解决传统单上下文窗口和顺序执行的限制


<details>
  <summary>Details</summary>
Motivation: 现有代理在处理长深度研究任务时，虽然通过子任务级上下文管理克服了线性上下文积累和信息丢失问题，但仍受限于单一上下文窗口和顺序执行范式，导致相互干扰和阻塞行为，限制了可扩展性和适应性

Method: 提出Self-Manager并行代理循环框架，主线程可创建多个具有独立隔离上下文的子线程，通过线程控制块进行迭代管理，实现更专注和灵活的并行代理执行

Result: 在DeepResearch Bench基准测试中，Self-Manager在所有指标上持续优于现有的单代理循环基线；分析实验证明了其设计选择的必要性，以及在上下文容量、效率和泛化方面的优势

Conclusion: Self-Manager通过并行代理循环设计有效解决了长深度研究任务中的上下文管理和执行效率问题，为复杂多面研究提供了更可扩展和适应的解决方案

Abstract: Long-form deep research requires multi-faceted investigations over extended horizons to get a comprehensive report. When handling such complex tasks, existing agents manage context at the subtask level to overcome linear context accumulation and information loss. However, they still adhere to a single context window and sequential execution paradigm, which results in mutual interference and blocking behavior, restricting scalability and adaptability. To address this issue, this paper introduces Self-Manager, a parallel agent loop that enables asynchronous and concurrent execution. The main thread can create multiple subthreads, each with its own isolated context, and manage them iteratively through Thread Control Blocks, allowing for more focused and flexible parallel agent execution. To assess its effectiveness, we benchmark Self-Manager on DeepResearch Bench, where it consistently outperforms existing single-agent loop baselines across all metrics. Furthermore, we conduct extensive analytical experiments to demonstrate the necessity of Self-Manager's design choices, as well as its advantages in contextual capacity, efficiency, and generalization.

</details>


### [218] [Assessment of Generative Named Entity Recognition in the Era of Large Language Models](https://arxiv.org/abs/2601.17898)
*Qi Zhan,Yile Wang,Hui Huang*

Main category: cs.CL

TL;DR: 本文系统评估了开源大语言模型在平面和嵌套命名实体识别任务上的表现，发现通过参数高效微调和结构化输出格式，LLMs能达到与传统编码器模型竞争的性能，且其NER能力源于指令跟随和生成能力而非记忆，NER指令微调对LLMs的通用能力影响很小。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的兴起，命名实体识别正从序列标注任务向生成范式转变。本文旨在系统评估开源LLMs在平面和嵌套NER任务上的表现，探究生成式NER与传统NER模型的性能差距、输出格式的影响、LLMs是否依赖记忆以及微调后通用能力的保持情况。

Method: 在八个不同规模的LLMs和四个标准NER数据集上进行实验，采用参数高效微调技术，比较不同输出格式（如内联括号或XML格式），分析LLMs的NER能力来源，并评估NER指令微调对模型通用能力的影响。

Result: 1) 通过参数高效微调和结构化输出格式，开源LLMs能达到与传统编码器模型竞争的性能，甚至超过GPT-3等闭源模型；2) LLMs的NER能力源于指令跟随和生成能力，而非简单的实体-标签对记忆；3) NER指令微调对LLMs的通用能力影响很小，甚至因增强实体理解而提升在DROP等数据集上的表现。

Conclusion: 基于LLMs的生成式NER是传统方法的有前景且用户友好的替代方案，开源LLMs通过适当微调和输出格式设计能在NER任务上取得优异表现，且不会显著损害模型的通用能力。

Abstract: Named entity recognition (NER) is evolving from a sequence labeling task into a generative paradigm with the rise of large language models (LLMs). We conduct a systematic evaluation of open-source LLMs on both flat and nested NER tasks. We investigate several research questions including the performance gap between generative NER and traditional NER models, the impact of output formats, whether LLMs rely on memorization, and the preservation of general capabilities after fine-tuning. Through experiments across eight LLMs of varying scales and four standard NER datasets, we find that: (1) With parameter-efficient fine-tuning and structured formats like inline bracketed or XML, open-source LLMs achieve performance competitive with traditional encoder-based models and surpass closed-source LLMs like GPT-3; (2) The NER capability of LLMs stems from instruction-following and generative power, not mere memorization of entity-label pairs; and (3) Applying NER instruction tuning has minimal impact on general capabilities of LLMs, even improving performance on datasets like DROP due to enhanced entity understanding. These findings demonstrate that generative NER with LLMs is a promising, user-friendly alternative to traditional methods. We release the data and code at https://github.com/szu-tera/LLMs4NER.

</details>


### [219] [ShapLoRA: Allocation of Low-rank Adaption on Large Language Models via Shapley Value Inspired Importance Estimation](https://arxiv.org/abs/2601.17921)
*Yi Zhao,Qinghua Yao,Xinyuan song,Wei Zhu*

Main category: cs.CL

TL;DR: ShapLoRA：基于Shapley值的可解释性LoRA秩分配框架，通过结合敏感度度量和合作博弈思想提出Shapley敏感度指标，优化工作流程，在多种任务上优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有LoRA秩分配方法依赖不可解释且不可靠的重要性度量，限制了参数高效微调的性能提升。需要更可解释和可靠的秩重要性度量方法。

Method: 提出ShapLoRA框架：1) 结合敏感度度量和合作博弈思想，提出可解释的Shapley敏感度重要性度量；2) 优化工作流程：在单独验证集上计算Shapley敏感度，建立分配-重训练流程进行公平比较。

Result: 在多种挑战性任务上的实验结果表明，ShapLoRA方法在可调参数相当的情况下能够超越现有基线方法。

Conclusion: ShapLoRA通过可解释的Shapley敏感度度量和优化的工作流程，为LoRA秩分配提供了更可靠的方法，提升了参数高效微调的性能。

Abstract: Low-rank adaption (LoRA) is a representative method in the field of parameter-efficient fine-tuning (PEFT), and is key to Democratizating the modern large language models (LLMs). The vanilla LoRA is implemented with uniform ranks, and the recent literature have found that properly allocating ranks on the LLM backbones results in performance boosts. However, the previous rank allocation methods have limitations since they rely on inexplanable and unreliable importance measures for the LoRA ranks. To address the above issues, we propose the ShapLoRA framework. Inspired by the explanable attribution measure Shapley Value, we combine the sensitivity-based measures with the idea of coalitions in the collaborative games among LoRA ranks, and propose a more explainable importance measure called Shapley sensitivity. In addition, we optimize the workflow of the existing works by: (a) calculating Shapley sensitivity on a separate validation set; (b) Setting up the allocating-retraining procedures for fair comparisons. We have conducted experiments on various challenging tasks, and the experimental results demonstrate that our ShapLoRA method can outperform the recent baselines with comparable tunable parameters.\footnote{Codes and fine-tuned models will be open-sourced to facilitate future research.

</details>


### [220] [A Monosemantic Attribution Framework for Stable Interpretability in Clinical Neuroscience Large Language Models](https://arxiv.org/abs/2601.17952)
*Michail Mamalakis,Tiago Azevedo,Cristian Cosentino,Chiara D'Ercoli,Subati Abulikemu,Zhongtian Sun,Richard Bethlehem,Pietro Lio*

Main category: cs.CL

TL;DR: 提出统一可解释性框架，结合归因和机制视角，通过单语义特征提取减少方法间变异性，为临床LLM应用提供稳定重要性评分。


<details>
  <summary>Details</summary>
Motivation: 在阿尔茨海默病等临床环境中部署大语言模型需要可解释性，但现有归因方法存在高方法间变异性和不稳定解释，而机制可解释性方法缺乏与模型输入输出的直接对齐且不提供明确重要性评分。

Method: 通过单语义特征提取整合归因和机制视角，在LLM层级别构建单语义嵌入空间，优化框架以显式减少方法间变异性，生成稳定输入级重要性评分并通过解压缩表示突出显著特征。

Result: 该方法能产生稳定的输入级重要性评分，通过解压缩表示突出感兴趣层的显著特征，推进LLM在认知健康和神经退行性疾病中的安全可信应用。

Conclusion: 提出的统一可解释性框架通过整合归因和机制视角，解决了临床LLM应用中的解释稳定性问题，为阿尔茨海默病进展诊断等关键医疗场景提供了更可靠的可解释性工具。

Abstract: Interpretability remains a key challenge for deploying large language models (LLMs) in clinical settings such as Alzheimer's disease progression diagnosis, where early and trustworthy predictions are essential. Existing attribution methods exhibit high inter-method variability and unstable explanations due to the polysemantic nature of LLM representations, while mechanistic interpretability approaches lack direct alignment with model inputs and outputs and do not provide explicit importance scores. We introduce a unified interpretability framework that integrates attributional and mechanistic perspectives through monosemantic feature extraction. By constructing a monosemantic embedding space at the level of an LLM layer and optimizing the framework to explicitly reduce inter-method variability, our approach produces stable input-level importance scores and highlights salient features via a decompressed representation of the layer of interest, advancing the safe and trustworthy application of LLMs in cognitive health and neurodegenerative disease.

</details>


### [221] [LLMs as Cultural Archives: Cultural Commonsense Knowledge Graph Extraction](https://arxiv.org/abs/2601.17971)
*Junior Cedric Tonga,Chen Cecilia Liu,Iryna Gurevych,Fajri Koto*

Main category: cs.CL

TL;DR: 提出基于LLMs的文化常识知识图谱构建框架，通过迭代提示从LLMs中提取文化特定实体、关系和实践，构建多步推理链，评估显示英语文化知识表现最佳，增强小模型的文化推理能力


<details>
  <summary>Details</summary>
Motivation: 大型语言模型编码了丰富的文化知识，但这些知识大多是隐式和非结构化的，限制了其可解释性和使用。需要系统性地提取和结构化这些文化常识知识

Method: 提出迭代提示框架构建文化常识知识图谱(CCKG)，将LLMs视为文化档案，系统提取文化特定实体、关系和实践，组合成跨语言的多步推理链

Result: 评估五个国家的文化知识图谱，发现英语文化知识图谱表现最佳，即使目标文化是非英语的；用CCKG增强小模型能提高文化推理和故事生成性能，英语链带来最大增益

Conclusion: LLMs作为文化技术既有潜力也有局限，链式结构文化知识是文化基础NLP的实用基础，英语文化知识在现有LLMs中编码最充分

Abstract: Large language models (LLMs) encode rich cultural knowledge learned from diverse web-scale data, offering an unprecedented opportunity to model cultural commonsense at scale. Yet this knowledge remains mostly implicit and unstructured, limiting its interpretability and use. We present an iterative, prompt-based framework for constructing a Cultural Commonsense Knowledge Graph (CCKG) that treats LLMs as cultural archives, systematically eliciting culture-specific entities, relations, and practices and composing them into multi-step inferential chains across languages. We evaluate CCKG on five countries with human judgments of cultural relevance, correctness, and path coherence. We find that the cultural knowledge graphs are better realized in English, even when the target culture is non-English (e.g., Chinese, Indonesian, Arabic), indicating uneven cultural encoding in current LLMs. Augmenting smaller LLMs with CCKG improves performance on cultural reasoning and story generation, with the largest gains from English chains. Our results show both the promise and limits of LLMs as cultural technologies and that chain-structured cultural knowledge is a practical substrate for culturally grounded NLP.

</details>


### [222] [SD-E$^2$: Semantic Exploration for Reasoning Under Token Budgets](https://arxiv.org/abs/2601.17982)
*Kshitij Mishra,Nils Lukas,Salem Lahlou*

Main category: cs.CL

TL;DR: SD-E²：通过语义多样性探索-利用强化学习框架，提升小语言模型的复杂推理能力


<details>
  <summary>Details</summary>
Motivation: 小语言模型在有限计算预算下难以进行复杂推理，因为探索成本高昂。需要一种更高效的探索-利用策略来提升推理能力。

Method: 提出SD-E²强化学习框架，使用冻结的句子嵌入模型计算语义多样性奖励，捕捉不同解决策略的覆盖度和平均成对差异。将多样性奖励与结果正确性和解决方案效率结合，通过z-score归一化的多目标目标稳定训练。

Result: 在GSM8K上超越基础模型和强基线，平均每个问题发现9.8种语义不同的策略。在MedMCQA和AIME基准测试中也取得显著提升。

Conclusion: 奖励语义新颖性为训练推理能力强的小语言模型提供了更计算高效的探索-利用信号。通过认知适应调整推理过程结构，为资源受限模型提供了效率增益的补充路径。

Abstract: Small language models (SLMs) struggle with complex reasoning because exploration is expensive under tight compute budgets. We introduce Semantic Diversity-Exploration-Exploitation (SD-E$^2$), a reinforcement learning framework that makes exploration explicit by optimizing semantic diversity in generated reasoning trajectories. Using a frozen sentence-embedding model, SD-E$^2$ assigns a diversity reward that captures (i) the coverage of semantically distinct solution strategies and (ii) their average pairwise dissimilarity in embedding space, rather than surface-form novelty. This diversity reward is combined with outcome correctness and solution efficiency in a z-score-normalized multi-objective objective that stabilizes training. On GSM8K, SD-E$^2$ surpasses the base Qwen2.5-3B-Instruct and strong GRPO baselines (GRPO-CFL and GRPO-CFEE) by +27.4, +5.2, and +1.5 percentage points, respectively, while discovering on average 9.8 semantically distinct strategies per question. We further improve MedMCQA to 49.64% versus 38.37% for the base model and show gains on the harder AIME benchmark (1983-2025), reaching 13.28% versus 6.74% for the base. These results indicate that rewarding semantic novelty yields a more compute-efficient exploration-exploitation signal for training reasoning-capable SLMs. By introducing cognitive adaptation-adjusting the reasoning process structure rather than per-token computation-SD-E$^2$ offers a complementary path to efficiency gains in resource-constrained models.

</details>


### [223] [AI-based approach to burnout identification from textual data](https://arxiv.org/abs/2601.17993)
*Marina Zavertiaeva,Petr Parshakov,Mikhail Usanin,Aleksei Smirnov,Sofia Paklina,Anastasiia Kibardina*

Main category: cs.CL

TL;DR: 使用RuBERT模型通过自然语言处理从文本数据中检测职业倦怠，结合ChatGPT生成的合成句子和YouTube用户评论进行微调


<details>
  <summary>Details</summary>
Motivation: 开发一种能够从文本中自动检测职业倦怠的AI方法，用于监控高压工作环境中的心理健康信号

Method: 基于RuBERT模型（原用于情感分析），使用ChatGPT生成的合成句子和俄罗斯YouTube视频中关于倦怠的用户评论进行微调，构建倦怠检测模型

Result: 开发出能够为输入文本分配倦怠概率的模型，可处理大量书面通信数据，用于监测高压工作环境中的倦怠相关语言信号

Conclusion: 提出的AI方法能够有效从文本中检测职业倦怠，为组织提供了一种监控员工心理健康的新工具

Abstract: This study introduces an AI-based methodology that utilizes natural language processing (NLP) to detect burnout from textual data. The approach relies on a RuBERT model originally trained for sentiment analysis and subsequently fine-tuned for burnout detection using two data sources: synthetic sentences generated with ChatGPT and user comments collected from Russian YouTube videos about burnout. The resulting model assigns a burnout probability to input texts and can be applied to process large volumes of written communication for monitoring burnout-related language signals in high-stress work environments.

</details>


### [224] [PEAR: Pairwise Evaluation for Automatic Relative Scoring in Machine Translation](https://arxiv.org/abs/2601.18006)
*Lorenzo Proietti,Roman Grundkiewicz,Matt Post*

Main category: cs.CL

TL;DR: PEAR是一个基于成对比较的自动翻译质量评估指标，通过预测两个候选翻译的质量差异方向和幅度来评估翻译质量，在WMT24基准测试中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有参考无关的机器翻译质量评估方法通常对单个翻译进行评分，但人类评估往往通过比较来区分翻译质量。PEAR旨在通过成对比较框架更准确地评估翻译质量差异。

Method: PEAR将翻译质量评估重新定义为分级成对比较任务，给定源文本和两个候选翻译，预测它们的质量差异方向和幅度。使用从人工判断差异中导出的成对监督进行训练，并添加正则化项确保候选顺序反转时预测符号也反转。

Result: 在WMT24元评估基准上，PEAR优于使用相同数据和骨干网络的单候选质量评估基线，证明了成对公式化的优势。尽管参数数量远少于近期大型指标，PEAR超越了更大的质量评估模型和基于参考的指标，且产生更冗余的评估信号。

Conclusion: PEAR通过成对比较框架有效提升了翻译质量评估性能，参数效率高，评估信号冗余度低，并且可以作为最小贝叶斯风险解码的有效效用函数，显著降低成对评分成本。

Abstract: We present PEAR (Pairwise Evaluation for Automatic Relative Scoring), a supervised Quality Estimation (QE) metric family that reframes reference-free Machine Translation (MT) evaluation as a graded pairwise comparison. Given a source segment and two candidate translations, PEAR predicts the direction and magnitude of their quality difference. The metrics are trained using pairwise supervision derived from differences in human judgments, with an additional regularization term that encourages sign inversion under candidate order reversal. On the WMT24 meta-evaluation benchmark, PEAR outperforms strictly matched single-candidate QE baselines trained with the same data and backbones, isolating the benefit of the proposed pairwise formulation. Despite using substantially fewer parameters than recent large metrics, PEAR surpasses far larger QE models and reference-based metrics. Our analysis further indicates that PEAR yields a less redundant evaluation signal relative to other top metrics. Finally, we show that PEAR is an effective utility function for Minimum Bayes Risk (MBR) decoding, reducing pairwise scoring cost at negligible impact.

</details>


### [225] [Evaluating Semantic and Syntactic Understanding in Large Language Models for Payroll Systems](https://arxiv.org/abs/2601.18012)
*Hendrika Maclean,Mert Can Cakmak,Muzakkiruddin Ahmed Mohammed,Shames Al Mandalawi,John Talburt*

Main category: cs.CL

TL;DR: 研究评估大语言模型在精确数值计算和可审计输出方面的可靠性，以薪资系统为案例，发现需要结合提示工程和显式计算才能达到分币级精度。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在日常写作、搜索和分析中广泛应用且自然语言理解能力不断提升，但在精确数值计算和可审计输出方面仍不可靠。薪资系统作为高风险的典型案例，需要模型理解薪资架构、按正确顺序应用规则并提供分币级准确结果。

Method: 构建分层数据集（从基础到复杂案例），测试多种提示策略（从最小基线到架构引导和推理变体），评估多个模型家族（GPT、Claude、Perplexity、Grok和Gemini）。

Result: 结果显示存在明确的工作模式：在某些情况下仔细的提示工程就足够，而在其他情况下需要显式计算。模型在理解架构和规则应用方面表现不一，精确计算需要额外支持。

Conclusion: 研究提供了一个紧凑、可复现的框架和实用指南，用于在需要高精度和保证的场景中部署大语言模型，建议结合提示工程和显式计算来满足分币级精度要求。

Abstract: Large language models are now used daily for writing, search, and analysis, and their natural language understanding continues to improve. However, they remain unreliable on exact numerical calculation and on producing outputs that are straightforward to audit. We study synthetic payroll system as a focused, high-stakes example and evaluate whether models can understand a payroll schema, apply rules in the right order, and deliver cent-accurate results. Our experiments span a tiered dataset from basic to complex cases, a spectrum of prompts from minimal baselines to schema-guided and reasoning variants, and multiple model families including GPT, Claude, Perplexity, Grok and Gemini. Results indicate clear regimes where careful prompting is sufficient and regimes where explicit computation is required. The work offers a compact, reproducible framework and practical guidance for deploying LLMs in settings that demand both accuracy and assurance.

</details>


### [226] [A System for Name and Address Parsing with Large Language Models](https://arxiv.org/abs/2601.18014)
*Adeeba Tarannum,Muzakkiruddin Ahmed Mohammed,Mert Can Cakmak,Shames Al Mandalawi,John Talburt*

Main category: cs.CL

TL;DR: 提出一个基于提示和验证的框架，将非结构化人员地址文本转换为结构化数据，无需微调即可实现高精度和可复现性


<details>
  <summary>Details</summary>
Motivation: 传统规则方法和概率方法在干净输入上表现良好，但在噪声或多语言条件下失败；神经模型和大语言模型缺乏确定性控制和可复现性。需要一种既灵活又可控的结构化信息提取方案。

Method: 采用提示驱动、验证中心的框架，整合输入标准化、结构化提示、约束解码和严格的基于规则的验证，在固定实验设置下确保可复现性，无需微调即可将自由文本转换为17字段模式。

Result: 在异构真实地址数据上的评估显示高字段级准确率、强模式遵循能力和稳定的置信度校准。该方法在结构化信息提取中表现出鲁棒性、可解释性和可扩展性。

Conclusion: 结合确定性验证和生成性提示为结构化信息提取提供了实用替代方案，优于需要大量训练或特定领域模型的方法。

Abstract: Reliable transformation of unstructured person and address text into structured data remains a key challenge in large-scale information systems. Traditional rule-based and probabilistic approaches perform well on clean inputs but fail under noisy or multilingual conditions, while neural and large language models (LLMs) often lack deterministic control and reproducibility. This paper introduces a prompt-driven, validation-centered framework that converts free-text records into a consistent 17-field schema without fine-tuning. The method integrates input normalisation, structured prompting, constrained decoding, and strict rule-based validation under fixed experimental settings to ensure reproducibility. Evaluations on heterogeneous real-world address data show high field-level accuracy, strong schema adherence, and stable confidence calibration. The results demonstrate that combining deterministic validation with generative prompting provides a robust, interpretable, and scalable solution for structured information extraction, offering a practical alternative to training-heavy or domain-specific models.

</details>


### [227] [CommonLID: Re-evaluating State-of-the-Art Language Identification Performance on Web Data](https://arxiv.org/abs/2601.18026)
*Pedro Ortiz Suarez,Laurie Burchell,Catherine Arnett,Rafael Mosquera-Gómez,Sara Hincapie-Monsalve,Thom Vaughan,Damian Stewart,Malte Ostendorff,Idris Abdulmumin,Vukosi Marivate,Shamsuddeen Hassan Muhammad,Atnafu Lambebo Tonja,Hend Al-Khalifa,Nadia Ghezaiel Hammouda,Verrah Otiende,Tack Hwa Wong,Jakhongir Saydaliev,Melika Nobakhtian,Muhammad Ravi Shulthan Habibi,Chalamalasetti Kranti,Carol Muchemi,Khang Nguyen,Faisal Muhammad Adam,Luis Frentzen Salim,Reem Alqifari,Cynthia Amol,Joseph Marvin Imperial,Ilker Kesen,Ahmad Mustafid,Pavel Stepachev,Leshem Choshen,David Anugraha,Hamada Nayel,Seid Muhie Yimam,Vallerie Alexandra Putra,My Chiffon Nguyen,Azmine Toushik Wasi,Gouthami Vadithya,Rob van der Goot,Lanwenn ar C'horr,Karan Dua,Andrew Yates,Mithil Bangera,Yeshil Bangera,Hitesh Laxmichand Patel,Shu Okabe,Fenal Ashokbhai Ilasariya,Dmitry Gaynullin,Genta Indra Winata,Yiyuan Li,Juan Pablo Martínez,Amit Agarwal,Ikhlasul Akmal Hanif,Raia Abu Ahmad,Esther Adenuga,Filbert Aurelian Tjiaranata,Weerayut Buaphet,Michael Anugraha,Sowmya Vajjala,Benjamin Rice,Azril Hafizi Amirudin,Jesujoba O. Alabi,Srikant Panda,Yassine Toughrai,Bruhan Kyomuhendo,Daniel Ruffinelli,Akshata A,Manuel Goulão,Ej Zhou,Ingrid Gabriela Franco Ramirez,Cristina Aggazzotti,Konstantin Dobler,Jun Kevin,Quentin Pagès,Nicholas Andrews,Nuhu Ibrahim,Mattes Ruckdeschel,Amr Keleg,Mike Zhang,Casper Muziri,Saron Samuel,Sotaro Takeshita,Kun Kerdthaisong,Luca Foppiano,Rasul Dent,Tommaso Green,Ahmad Mustapha Wali,Kamohelo Makaaka,Vicky Feliren,Inshirah Idris,Hande Celikkanat,Abdulhamid Abubakar,Jean Maillard,Benoît Sagot,Thibault Clérice,Kenton Murray,Sarah Luger*

Main category: cs.CL

TL;DR: CommonLID是一个社区驱动的人工标注语言识别基准，涵盖109种语言，专门针对网络领域数据，旨在解决现有LID模型在嘈杂异构网络数据上表现不佳的问题。


<details>
  <summary>Details</summary>
Motivation: 语言识别是构建多语言语料库的基础步骤，但现有LID模型在许多语言上表现不佳，特别是在用于训练多语言模型的嘈杂异构网络数据上。许多语言缺乏代表性评估资源。

Method: 创建CommonLID基准：社区驱动、人工标注的网络领域语言识别数据集，涵盖109种语言。使用该基准与五个其他常用评估集测试八个流行的LID模型。

Result: CommonLID揭示了现有评估高估了许多语言在网络领域的识别准确率。该基准为开发更具代表性的高质量文本语料库提供了关键资源。

Conclusion: CommonLID填补了语言识别评估的重要空白，特别是在网络领域和以往服务不足的语言上。该基准以开放许可发布，有助于推动更准确、更具代表性的LID模型发展。

Abstract: Language identification (LID) is a fundamental step in curating multilingual corpora. However, LID models still perform poorly for many languages, especially on the noisy and heterogeneous web data often used to train multilingual language models. In this paper, we introduce CommonLID, a community-driven, human-annotated LID benchmark for the web domain, covering 109 languages. Many of the included languages have been previously under-served, making CommonLID a key resource for developing more representative high-quality text corpora. We show CommonLID's value by using it, alongside five other common evaluation sets, to test eight popular LID models. We analyse our results to situate our contribution and to provide an overview of the state of the art. In particular, we highlight that existing evaluations overestimate LID accuracy for many languages in the web domain. We make CommonLID and the code used to create it available under an open, permissive license.

</details>


### [228] [Addressing LLM Diversity by Infusing Random Concepts](https://arxiv.org/abs/2601.18053)
*Pulin Agrawal,Prasoon Goyal*

Main category: cs.CL

TL;DR: 在LLM提示中添加随机概念可以显著提高生成输出的多样性


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的输出多样性有限，需要探索如何通过提示工程来改善这一限制

Method: 在提示前添加与主题无关的随机单词/句子，并设计系统评估协议（如"列举10位好莱坞演员"问题）来测量输出多样性

Result: 实验表明，在多个LLM中，添加随机内容确实能显著提高输出多样性

Conclusion: 随机概念注入是提高LLM多样性的有效方法，该评估协议为未来系统化评估LLM多样性研究提供了基础

Abstract: Large language models (LLMs) are known to produce outputs with limited diversity. In this work, we study whether infusing random concepts in the prompts can improve the diversity of the generated outputs. To benchmark the approach, we design a systematic evaluation protocol which involves prompting an LLM with questions of the form "Name 10 Hollywood actors", and analyzing diversity measures of the resulting LLM outputs. Our experiments on multiple LLMs show that prepending random words/sentences unrelated to the prompt result in greater diversity in the outputs of LLMs. We believe that this promising result and the evaluation protocol opens up interesting avenues for future work, such as how infusing randomness into LLMs could be applied to other domains. Further, the evaluation protocol could also inspire research into benchmarking LLM diversity more systematically.

</details>


### [229] [Neurocomputational Mechanisms of Syntactic Transfer in Bilingual Sentence Production](https://arxiv.org/abs/2601.18056)
*Ahmet Yavuz Uluslu,Elliot Murphy*

Main category: cs.CL

TL;DR: 该论文主张在双语产生错误研究中加入振荡特征分析，并提出ROSE神经模型可解释双语中的句法迁移现象，以跨语言影响为案例说明振荡失败模式驱动功能抑制/竞争理论。


<details>
  <summary>Details</summary>
Motivation: 传统双语产生错误研究主要关注事件相关电位等时序特征，缺乏实施层面的神经计算约束。需要新的神经生物学标记来更好地理解双语认知机制，特别是句法迁移和跨语言影响现象。

Method: 采用ROSE神经语言模型作为理论框架，将跨语言影响解释为特定振荡失败模式在L2句子规划过程中的表现。通过振荡特征分析为功能抑制/竞争理论提供神经计算基础。

Result: ROSE模型能够捕捉双语产生中句法迁移的形式特性和形态句法序列失败模式的范围。振荡特征分析为双语理论提供了新的实施层面约束，并支持探索更复杂的时空生物标记。

Conclusion: 将振荡特征纳入双语研究不仅实现了ROSE模型设计的连接假设，还允许探索比传统神经特征更复杂的语言功能障碍生物标记，为双语认知神经机制提供了新的理论视角。

Abstract: We discuss the benefits of incorporating into the study of bilingual production errors and their traditionally documented timing signatures (e.g., event-related potentials) certain types of oscillatory signatures, which can offer new implementational-level constraints for theories of bilingualism. We argue that a recent neural model of language, ROSE, can offer a neurocomputational account of syntactic transfer in bilingual production, capturing some of its formal properties and the scope of morphosyntactic sequencing failure modes. We take as a case study cross-linguistic influence (CLI) and attendant theories of functional inhibition/competition, and present these as being driven by specific oscillatory failure modes during L2 sentence planning. We argue that modeling CLI in this way not only offers the kind of linking hypothesis ROSE was built to encourage, but also licenses the exploration of more spatiotemporally complex biomarkers of language dysfunction than more commonly discussed neural signatures.

</details>


### [230] [Grounded Concreteness: Human-Like Concreteness Sensitivity in Vision-Language Models](https://arxiv.org/abs/2601.18065)
*Aryan Roy,Zekun Wang,Christopher J. MacLellan*

Main category: cs.CL

TL;DR: 研究比较了纯文本LLM与视觉-语言模型(VLM)在语言具体性敏感度上的差异，发现VLM在多模态预训练后表现出更接近人类的语言具体性感知能力。


<details>
  <summary>Details</summary>
Motivation: 探讨视觉-语言模型(VLMs)是否比纯文本大语言模型(LLMs)发展出更接近人类对语言具体性的敏感度，特别是在仅使用文本提示进行评估时。研究将多模态预训练视为感知基础的一种消融实验。

Method: 采用对照比较方法，匹配Llama文本骨干模型及其Llama Vision对应模型，在多个模型规模上进行评估。从三个互补层面测量具体性效应：1)输出行为：将问题级具体性与QA准确性关联；2)嵌入几何：测试表示是否沿具体性轴组织；3)注意力动态：通过注意力熵测量量化上下文依赖。此外，从模型中获取词元级具体性评分，评估与人类规范分布的一致性。

Result: 在多个基准测试和模型规模上，VLM在更具体的输入上表现出更大的增益，展现出更清晰的具体性结构化表示，产生的评分与人类规范更匹配，并显示出系统性的不同注意力模式，与增强的基础一致。

Conclusion: 多模态预训练使视觉-语言模型发展出比纯文本模型更接近人类的语言具体性敏感度，即使在使用纯文本提示进行评估时也是如此，这表明感知基础对语言理解有实质性影响。

Abstract: Do vision--language models (VLMs) develop more human-like sensitivity to linguistic concreteness than text-only large language models (LLMs) when both are evaluated with text-only prompts? We study this question with a controlled comparison between matched Llama text backbones and their Llama Vision counterparts across multiple model scales, treating multimodal pretraining as an ablation on perceptual grounding rather than access to images at inference. We measure concreteness effects at three complementary levels: (i) output behavior, by relating question-level concreteness to QA accuracy; (ii) embedding geometry, by testing whether representations organize along a concreteness axis; and (iii) attention dynamics, by quantifying context reliance via attention-entropy measures. In addition, we elicit token-level concreteness ratings from models and evaluate alignment to human norm distributions, testing whether multimodal training yields more human-consistent judgments. Across benchmarks and scales, VLMs show larger gains on more concrete inputs, exhibit clearer concreteness-structured representations, produce ratings that better match human norms, and display systematically different attention patterns consistent with increased grounding.

</details>


### [231] [Sparks of Cooperative Reasoning: LLMs as Strategic Hanabi Agents](https://arxiv.org/abs/2601.18077)
*Mahesh Ramesh,Kaousheik Jayakumar,Aswinkumar Ramkumar,Pavan Thodima,Aniket Rege*

Main category: cs.CL

TL;DR: 研究评估了17个LLM在Hanabi游戏中的表现，通过不同上下文工程设置（Watson/Sherlock/Mycroft）测试协作推理能力，创建了首个公开数据集，并通过微调显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 在不完全信息下的协作推理对多智能体系统具有挑战性。Hanabi游戏需要心智理论和战略沟通，是评估LLM协作推理能力的理想测试平台。

Method: 在2-5人Hanabi游戏中评估17个SOTA LLM，设计了三种上下文工程设置：Watson（仅显式卡片信息）、Sherlock（程序化贝叶斯推理）、Mycroft（多轮状态跟踪）。创建了两个公开数据集：HanabiLogs（1,520个完整游戏日志）和HanabiRewards（560个带密集价值标注的游戏）。对4B开源模型进行监督学习和RL微调。

Result: 最强推理模型在Sherlock设置下平均得分超过15分，但仍落后于人类专家（20+分）。监督学习和RL微调分别提升性能21%和156%，接近最强专有推理模型o4-mini，超越GPT-4.1 52%。RL微调模型还泛化到其他任务，在协作猜测、时间推理、指令跟随和数学推理上均有提升。

Conclusion: LLM能够通过内部工作记忆进行状态跟踪，模型间协作性能随模型强度平滑变化。通过高质量数据集微调可显著提升LLM的协作推理能力，并具有任务泛化性。Hanabi是评估和改进LLM协作推理的有效基准。

Abstract: Cooperative reasoning under incomplete information remains challenging for both humans and multi-agent systems. The card game Hanabi embodies this challenge, requiring theory-of-mind reasoning and strategic communication. We benchmark 17 state-of-the-art LLM agents in 2-5 player games and study the impact of context engineering across model scales (4B to 600B+) to understand persistent coordination failures and robustness to scaffolding: from a minimal prompt with only explicit card details (Watson setting), to scaffolding with programmatic, Bayesian-motivated deductions (Sherlock setting), to multi-turn state tracking via working memory (Mycroft setting). We show that (1) agents can maintain an internal working memory for state tracking and (2) cross-play performance between different LLMs smoothly interpolates with model strength. In the Sherlock setting, the strongest reasoning models exceed 15 points on average across player counts, yet still trail experienced humans and specialist Hanabi agents, both consistently scoring above 20. We release the first public Hanabi datasets with annotated trajectories and move utilities: (1) HanabiLogs, containing 1,520 full game logs for instruction tuning, and (2) HanabiRewards, containing 560 games with dense move-level value annotations for all candidate moves. Supervised and RL finetuning of a 4B open-weight model (Qwen3-Instruct) on our datasets improves cooperative Hanabi play by 21% and 156% respectively, bringing performance to within ~3 points of a strong proprietary reasoning model (o4-mini) and surpassing the best non-reasoning model (GPT-4.1) by 52%. The HanabiRewards RL-finetuned model further generalizes beyond Hanabi, improving performance on a cooperative group-guessing benchmark by 11%, temporal reasoning on EventQA by 6.4%, instruction-following on IFBench-800K by 1.7 Pass@10, and matching AIME 2025 mathematical reasoning Pass@10.

</details>


### [232] [CHiRPE: A Step Towards Real-World Clinical NLP with Clinician-Oriented Model Explanations](https://arxiv.org/abs/2601.18102)
*Stephanie Fong,Zimu Wang,Guilherme C. Oliveira,Xiangyu Zhao,Yiwen Jiang,Jiahe Liu,Beau-Luke Colton,Scott Woods,Martha E. Shenton,Barnaby Nelson,Zongyuan Ge,Dominic Dwyer*

Main category: cs.CL

TL;DR: CHiRPE是一个临床NLP管道，通过转录的半结构化临床访谈预测精神病风险，并生成与临床医生共同开发的新型SHAP解释格式，实现高准确性和临床可解释性。


<details>
  <summary>Details</summary>
Motivation: 医疗NLP工具需要最终用户可解释，但传统的可解释AI方法与临床推理不匹配且缺乏临床医生参与，因此需要开发临床指导的、可解释的风险预测系统。

Method: CHiRPE管道整合症状领域映射、LLM摘要和BERT分类，使用944份半结构化访谈转录数据，生成与临床医生共同开发的新型SHAP解释格式（包括概念引导的混合图-文本摘要格式）。

Result: CHiRPE在三种BERT变体上均达到超过90%的准确率，优于基线模型；28位临床专家评估表明，他们强烈偏好新型概念引导解释，特别是混合图-文本摘要格式。

Conclusion: 临床指导的模型开发能产生既准确又可解释的结果，下一步将在24个国际站点进行真实世界测试。

Abstract: The medical adoption of NLP tools requires interpretability by end users, yet traditional explainable AI (XAI) methods are misaligned with clinical reasoning and lack clinician input. We introduce CHiRPE (Clinical High-Risk Prediction with Explainability), an NLP pipeline that takes transcribed semi-structured clinical interviews to: (i) predict psychosis risk; and (ii) generate novel SHAP explanation formats co-developed with clinicians. Trained on 944 semi-structured interview transcripts across 24 international clinics of the AMP-SCZ study, the CHiRPE pipeline integrates symptom-domain mapping, LLM summarisation, and BERT classification. CHiRPE achieved over 90% accuracy across three BERT variants and outperformed baseline models. Explanation formats were evaluated by 28 clinical experts who indicated a strong preference for our novel concept-guided explanations, especially hybrid graph-and-text summary formats. CHiRPE demonstrates that clinically-guided model development produces both accurate and interpretable results. Our next step is focused on real-world testing across our 24 international sites.

</details>


### [233] [GLEN-Bench: A Graph-Language based Benchmark for Nutritional Health](https://arxiv.org/abs/2601.18106)
*Jiatan Huang,Zheyuan Zhang,Tianyi Ma,Mingchen Li,Yaning Zheng,Yanfang Ye,Chuxu Zhang*

Main category: cs.CL

TL;DR: GLEN-Bench：首个基于图-语言模型的营养健康评估基准，整合健康记录、食物成分和食品获取数据，针对阿片类药物使用障碍等慢性病提供个性化饮食建议和解释。


<details>
  <summary>Details</summary>
Motivation: 现有营养干预计算方法存在三大缺陷：忽略社会经济等现实约束、缺乏推荐解释、缺乏统一评估基准。需要开发能考虑真实世界限制并提供可解释建议的系统。

Method: 整合NHANES健康记录、FNDDS食物成分数据和USDA食品获取指标构建知识图谱，连接人口统计、健康状况、饮食行为、贫困相关约束和营养需求。使用图神经网络、大语言模型和混合架构评估三个关联任务：风险检测、个性化推荐和问答解释。

Result: 建立了GLEN-Bench基准，在阿片类药物使用障碍案例中成功检测到疾病不同阶段的细微营养差异，识别出与健康风险相关的明确饮食模式，为实际干预提供指导。

Conclusion: GLEN-Bench填补了营养健康评估的空白，通过图-语言方法实现了考虑现实约束的个性化饮食建议和可解释推荐，为临床营养干预提供了实用工具和设计选择。

Abstract: Nutritional interventions are important for managing chronic health conditions, but current computational methods provide limited support for personalized dietary guidance. We identify three key gaps: (1) dietary pattern studies often ignore real-world constraints such as socioeconomic status, comorbidities, and limited food access; (2) recommendation systems rarely explain why a particular food helps a given patient; and (3) no unified benchmark evaluates methods across the connected tasks needed for nutritional interventions. We introduce GLEN-Bench, the first comprehensive graph-language based benchmark for nutritional health assessment. We combine NHANES health records, FNDDS food composition data, and USDA food-access metrics to build a knowledge graph that links demographics, health conditions, dietary behaviors, poverty-related constraints, and nutrient needs. We test the benchmark using opioid use disorder, where models must detect subtle nutritional differences across disease stages. GLEN-Bench includes three linked tasks: risk detection identifies at-risk individuals from dietary and socioeconomic patterns; recommendation suggests personalized foods that meet clinical needs within resource constraints; and question answering provides graph-grounded, natural-language explanations to facilitate comprehension. We evaluate these graph-language approaches, including graph neural networks, large language models, and hybrid architectures, to establish solid baselines and identify practical design choices. Our analysis identifies clear dietary patterns linked to health risks, providing insights that can guide practical interventions.

</details>


### [234] [FABLE: Forest-Based Adaptive Bi-Path LLM-Enhanced Retrieval for Multi-Document Reasoning](https://arxiv.org/abs/2601.18116)
*Lin Sun,Linglin Zhang,Jingang Huang,Change Jia,Zhengwei Cheng,Xiangzheng Zhang*

Main category: cs.CL

TL;DR: FABLE是一个森林自适应双路径LLM增强检索框架，通过构建LLM增强的层次森林索引和双路径检索策略，在保持高准确性的同时显著减少计算开销，证明长上下文LLM增强了而非完全替代结构化检索的需求。


<details>
  <summary>Details</summary>
Motivation: 长上下文LLM存在中间丢失现象、高计算成本和多文档推理扩展性差的问题，而传统RAG系统受限于平面块级检索，引入语义噪声且无法支持结构化跨文档合成。需要一种结合两者优势的解决方案。

Method: FABLE框架：1) 构建LLM增强的层次森林索引，具有多粒度语义结构；2) 采用双路径策略，结合LLM引导的层次遍历和结构感知传播进行细粒度证据获取；3) 通过显式预算控制实现自适应效率权衡。

Result: 实验表明FABLE持续优于SOTA RAG方法，在达到与完整上下文LLM推理相当准确性的同时，实现了高达94%的token减少，证明长上下文LLM增强了而非完全替代结构化检索的需求。

Conclusion: FABLE通过将LLM集成到知识组织和检索中，有效解决了长上下文推理的局限性，展示了结构化检索在长上下文LLM时代仍然至关重要，两者应协同工作而非相互替代。

Abstract: The rapid expansion of long-context Large Language Models (LLMs) has reignited debate on whether Retrieval-Augmented Generation (RAG) remains necessary. However, empirical evidence reveals persistent limitations of long-context inference, including the lost-in-the-middle phenomenon, high computational cost, and poor scalability for multi-document reasoning. Conversely, traditional RAG systems, while efficient, are constrained by flat chunk-level retrieval that introduces semantic noise and fails to support structured cross-document synthesis.
  We present \textbf{FABLE}, a \textbf{F}orest-based \textbf{A}daptive \textbf{B}i-path \textbf{L}LM-\textbf{E}nhanced retrieval framework that integrates LLMs into both knowledge organization and retrieval. FABLE constructs LLM-enhanced hierarchical forest indexes with multi-granularity semantic structures, then employs a bi-path strategy combining LLM-guided hierarchical traversal with structure-aware propagation for fine-grained evidence acquisition, with explicit budget control for adaptive efficiency trade-offs.
  Extensive experiments demonstrate that FABLE consistently outperforms SOTA RAG methods and achieves comparable accuracy to full-context LLM inference with up to 94\% token reduction, showing that long-context LLMs amplify rather than fully replace the need for structured retrieval.

</details>


### [235] [Typhoon-S: Minimal Open Post-Training for Sovereign Large Language Models](https://arxiv.org/abs/2601.18129)
*Kunat Pipatanakul,Pittawat Taveekitworachai*

Main category: cs.CL

TL;DR: 提出Typhoon S方法，通过监督微调、策略蒸馏和小规模强化微调，在有限资源下构建高质量主权LLM，以泰语为案例验证效果。


<details>
  <summary>Details</summary>
Motivation: 当前主流LLM主要针对高资源语言（如英语、中文），由少数组织控制，限制了主权环境（如地区/国家机构）在资源有限、透明度要求高的情况下对模型权重、训练数据和部署的控制需求。

Method: 提出Typhoon S方法，结合监督微调、策略蒸馏和小规模强化微调（RFT），使用InK-GRPO扩展GRPO损失函数，加入下一个词预测损失，提升特定领域能力同时保持通用能力。

Result: 该方法成功将主权适应和通用基础模型转化为指令调优模型，在泰语法律推理和泰国特定知识任务上表现优异，同时保持通用能力，证明在学术规模资源下可实现高质量主权LLM。

Conclusion: 精心设计的后训练策略可以减少指令数据和计算规模的需求，为资源有限的主权环境提供构建高质量LLM的实用路径，特别适用于需要控制模型权重、训练数据和部署的场景。

Abstract: Large language models (LLMs) have progressed rapidly; however, most state-of-the-art models are trained and evaluated primarily in high-resource languages such as English and Chinese, and are often developed by a small number of organizations with access to large-scale compute and data. This gatekeeping creates a practical barrier for sovereign settings in which a regional- or national-scale institution or domain owner must retain control and understanding of model weights, training data, and deployment while operating under limited resources and strict transparency constraints. To this end, we identify two core requirements: (1) adoptability, the ability to transform a base model into a general-purpose assistant, and (2) sovereign capability, the ability to perform high-stakes, region-specific tasks (e.g., legal reasoning in local languages and cultural knowledge). We investigate whether these requirements can be achieved without scaling massive instruction corpora or relying on complex preference tuning pipelines and large-scale reinforcement fine-tuning (RFT). We present Typhoon S, a minimal and open post-training recipe that combines supervised fine-tuning, on-policy distillation, and small-scale RFT. Using Thai as a representative case study, we demonstrate that our approach transforms both sovereign-adapted and general-purpose base models into instruction-tuned models with strong general performance. We further show that small-scale RFT with InK-GRPO -- an extension of GRPO that augments the GRPO loss with a next-word prediction loss -- improves Thai legal reasoning and Thai-specific knowledge while preserving general capabilities. Our results suggest that a carefully designed post-training strategy can reduce the required scale of instruction data and computation, providing a practical path toward high-quality sovereign LLMs under academic-scale resources.

</details>


### [236] [Fine-Grained Emotion Detection on GoEmotions: Experimental Comparison of Classical Machine Learning, BiLSTM, and Transformer Models](https://arxiv.org/abs/2601.18162)
*Ani Harutyunyan,Sachin Kumar*

Main category: cs.CL

TL;DR: 本文在GoEmotions数据集上对比了三种细粒度情感识别模型：TF-IDF逻辑回归、BiLSTM+注意力、BERT微调。逻辑回归在Micro-F1上表现最佳，而BERT在整体平衡性上最优，超越了原论文报告的结果。


<details>
  <summary>Details</summary>
Motivation: 细粒度情感识别是一个具有挑战性的多标签NLP任务，主要面临标签重叠和类别不平衡的问题。本文旨在通过基准测试比较不同建模方法在GoEmotions数据集上的表现，探索如何更好地处理这些挑战。

Method: 使用三种模型家族：1) 基于TF-IDF的逻辑回归系统，采用二元相关性训练；2) 带注意力的BiLSTM模型；3) 为多标签分类微调的BERT模型。实验遵循官方训练/验证/测试划分，并使用逆频率类别权重来缓解不平衡问题。

Result: 逻辑回归获得最高的Micro-F1（0.51），而BERT在整体平衡性上表现最佳，超越了原论文报告的结果，达到Macro-F1 0.49、Hamming Loss 0.036和Subset Accuracy 0.36。这表明高频情感常依赖表层词汇线索，而上下文表示能提升对稀有情感和模糊示例的性能。

Conclusion: 对于细粒度情感识别任务，简单的TF-IDF逻辑回归在识别高频情感方面表现良好，而基于上下文的BERT模型在处理类别不平衡和复杂案例方面更具优势，整体平衡性更好。

Abstract: Fine-grained emotion recognition is a challenging multi-label NLP task due to label overlap and class imbalance. In this work, we benchmark three modeling families on the GoEmotions dataset: a TF-IDF-based logistic regression system trained with binary relevance, a BiLSTM with attention, and a BERT model fine-tuned for multi-label classification. Experiments follow the official train/validation/test split, and imbalance is mitigated using inverse-frequency class weights. Across several metrics, namely Micro-F1, Macro-F1, Hamming Loss, and Subset Accuracy, we observe that logistic regression attains the highest Micro-F1 of 0.51, while BERT achieves the best overall balance surpassing the official paper's reported results, reaching Macro-F1 0.49, Hamming Loss 0.036, and Subset Accuracy 0.36. This suggests that frequent emotions often rely on surface lexical cues, whereas contextual representations improve performance on rarer emotions and more ambiguous examples.

</details>


### [237] [MemWeaver: Weaving Hybrid Memories for Traceable Long-Horizon Agentic Reasoning](https://arxiv.org/abs/2601.18204)
*Juexiang Ye,Xue Li,Xinyu Yang,Chengkai Huang,Lanshun Nie,Lina Yao,Dechen Zhan*

Main category: cs.CL

TL;DR: MemWeaver是一个统一记忆框架，通过结构化图记忆、经验记忆和文本证据记忆三个组件，结合双通道检索策略，显著提升长期交互中多跳和时间推理能力，同时大幅减少上下文长度。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的智能体在长期交互中面临记忆系统挑战：现有方法主要依赖非结构化检索或粗略抽象，导致时间冲突、推理脆弱和可追溯性有限，需要更强大的记忆框架来支持时间一致性、多跳推理和基于证据的跨会话重用。

Method: MemWeaver将长期智能体经验整合为三个互连组件：1) 时间基础图记忆用于结构化关系推理；2) 经验记忆从重复观察中抽象出交互模式；3) 文本证据记忆保留原始文本证据。采用双通道检索策略联合检索结构化知识和支持证据，构建紧凑但信息密集的推理上下文。

Result: 在LoCoMo基准测试中，MemWeaver显著提高了多跳和时间推理准确性，同时相比长上下文基线减少了超过95%的输入上下文长度。

Conclusion: MemWeaver通过结构化记忆组件和双通道检索策略，为长期交互智能体提供了更有效、更紧凑的记忆系统，解决了现有方法在时间一致性、推理能力和可追溯性方面的局限性。

Abstract: Large language model-based agents operating in long-horizon interactions require memory systems that support temporal consistency, multi-hop reasoning, and evidence-grounded reuse across sessions. Existing approaches largely rely on unstructured retrieval or coarse abstractions, which often lead to temporal conflicts, brittle reasoning, and limited traceability. We propose MemWeaver, a unified memory framework that consolidates long-term agent experiences into three interconnected components: a temporally grounded graph memory for structured relational reasoning, an experience memory that abstracts recurring interaction patterns from repeated observations, and a passage memory that preserves original textual evidence. MemWeaver employs a dual-channel retrieval strategy that jointly retrieves structured knowledge and supporting evidence to construct compact yet information-dense contexts for reasoning. Experiments on the LoCoMo benchmark demonstrate that MemWeaver substantially improves multi-hop and temporal reasoning accuracy while reducing input context length by over 95\% compared to long-context baselines.

</details>


### [238] [TechING: Towards Real World Technical Image Understanding via VLMs](https://arxiv.org/abs/2601.18238)
*Tafazzul Nadeem,Bhavik Shangari,Manish Rai,Gagan Raj Gupta,Ashutosh Modi*

Main category: cs.CL

TL;DR: 本文提出使用合成生成的技术图表数据集训练视觉语言模型，以解决真实手绘技术图表理解困难的问题，并开发了LLama-VL-TUG模型，在合成和真实图像上均取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 专业人员在技术讨论中常手绘技术图表（如流程图、框图），但后续编辑需要重新绘制。现有视觉语言模型在理解技术图表方面表现不佳，而真实手绘图像数据集难以大规模获取。

Method: 1. 创建大规模合成生成的技术图表数据集（模拟真实世界图像）；2. 引入多种自监督任务进行训练；3. 在Llama 3.2 11B-instruct模型上使用合成图像进行微调，得到LLama-VL-TUG模型；4. 在较小规模的真实手绘图像数据集上进行人类评估。

Result: 1. LLama-VL-TUG将Llama 3.2 11B-instruct的ROUGE-L性能提升2.14倍；2. 在所有基线模型中取得最佳综合性能；3. 在真实图像上，8种图表类型中有7种实现最少编译错误；4. 将Llama 3.2 11B-instruct的平均F1分数提升6.97倍。

Conclusion: 通过合成生成的数据集训练视觉语言模型是解决手绘技术图表理解问题的有效方法，LLama-VL-TUG模型在合成和真实图像上均表现出显著优势，为技术图表理解提供了实用解决方案。

Abstract: Professionals working in technical domain typically hand-draw (on whiteboard, paper, etc.) technical diagrams (e.g., flowcharts, block diagrams, etc.) during discussions; however, if they want to edit these later, it needs to be drawn from scratch. Modern day VLMs have made tremendous progress in image understanding but they struggle when it comes to understanding technical diagrams. One way to overcome this problem is to fine-tune on real world hand-drawn images, but it is not practically possible to generate large number of such images. In this paper, we introduce a large synthetically generated corpus (reflective of real world images) for training VLMs and subsequently evaluate VLMs on a smaller corpus of hand-drawn images (with the help of humans). We introduce several new self-supervision tasks for training and perform extensive experiments with various baseline models and fine-tune Llama 3.2 11B-instruct model on synthetic images on these tasks to obtain LLama-VL-TUG, which significantly improves the ROUGE-L performance of Llama 3.2 11B-instruct by 2.14x and achieves the best all-round performance across all baseline models. On real-world images, human evaluation reveals that we achieve minimum compilation errors across all baselines in 7 out of 8 diagram types and improve the average F1 score of Llama 3.2 11B-instruct by 6.97x.

</details>


### [239] [BoRP: Bootstrapped Regression Probing for Scalable and Human-Aligned LLM Evaluation](https://arxiv.org/abs/2601.18253)
*Peng Sun,Xiangyu Zhang,Duan Wu*

Main category: cs.CL

TL;DR: BoRP是一个用于评估对话AI用户满意度的可扩展框架，利用LLM潜在空间的几何特性，通过自举机制自动生成评估标准，并使用偏最小二乘法将隐藏状态映射到连续分数，显著优于生成式基线且大幅降低推理成本。


<details>
  <summary>Details</summary>
Motivation: 对于开放式对话助手，传统的A/B测试缺乏可靠指标：显式反馈稀疏，隐式指标模糊。需要一种高保真度的满意度评估方法来支持对话AI的迭代开发。

Method: BoRP框架利用LLM潜在空间的几何特性，采用基于极化指数的自举机制自动生成评估标准，使用偏最小二乘法将隐藏状态映射到连续满意度分数，避免了生成式方法的问题。

Result: 在工业数据集上的实验表明，BoRP（Qwen3-8B/14B）在与人判断的一致性方面显著优于生成式基线（甚至超过Qwen3-Max），同时将推理成本降低数个数量级，支持全规模监控和高度敏感的A/B测试。

Conclusion: BoRP为开放式对话助手提供了一种可扩展、高保真度的满意度评估框架，解决了传统A/B测试的局限性，能够支持高效的迭代开发和监控。

Abstract: Accurate evaluation of user satisfaction is critical for iterative development of conversational AI. However, for open-ended assistants, traditional A/B testing lacks reliable metrics: explicit feedback is sparse, while implicit metrics are ambiguous. To bridge this gap, we introduce BoRP (Bootstrapped Regression Probing), a scalable framework for high-fidelity satisfaction evaluation. Unlike generative approaches, BoRP leverages the geometric properties of LLM latent space. It employs a polarization-index-based bootstrapping mechanism to automate rubric generation and utilizes Partial Least Squares (PLS) to map hidden states to continuous scores. Experiments on industrial datasets show that BoRP (Qwen3-8B/14B) significantly outperforms generative baselines (even Qwen3-Max) in alignment with human judgments. Furthermore, BoRP reduces inference costs by orders of magnitude, enabling full-scale monitoring and highly sensitive A/B testing via CUPED.

</details>


### [240] [Reflecting Twice before Speaking with Empathy: Self-Reflective Alternating Inference for Empathy-Aware End-to-End Spoken Dialogue](https://arxiv.org/abs/2601.18281)
*Yuhang Jia,Pei Liu,Haoqin Sun,Jiaming Zhou,Xuxin Cheng,Cao Liu,Ke Zeng,Xunliang Cai,Yong Qin*

Main category: cs.CL

TL;DR: 提出ReEmpathy模型，通过引入EmpathyEval评估模型和反思推理机制，增强端到端口语语言模型在共情对话中的表现。


<details>
  <summary>Details</summary>
Motivation: 当前口语语言模型在共情对话中过度依赖刚性监督信号（如标准答案或偏好分数），无法充分捕捉复杂共情表达的细微差别，因为不存在单一的"正确"回应，简单的数值评分也无法全面评估情感表达或共情行为的适当性。

Method: 首先提出EmpathyEval，一个基于自然语言的描述性评估模型，用于评估口语对话中的共情质量。在此基础上提出ReEmpathy模型，采用"共情自我反思交替推理"机制，交替进行口语回应生成和自由形式的共情相关反思推理。

Result: 大量实验表明，ReEmpathy通过启用反思推理，显著改善了共情敏感的口语对话，在共情对话质量方面取得实质性提升。

Conclusion: ReEmpathy为更情感智能和共情感知的人机交互提供了有前景的方法，通过反思推理机制增强了口语语言模型的共情对话能力。

Abstract: End-to-end Spoken Language Models (SLMs) hold great potential for paralinguistic perception, and numerous studies have aimed to enhance their capabilities, particularly for empathetic dialogue. However, current approaches largely depend on rigid supervised signals, such as ground-truth response in supervised fine-tuning or preference scores in reinforcement learning. Such reliance is fundamentally limited for modeling complex empathy, as there is no single "correct" response and a simple numerical score cannot fully capture the nuances of emotional expression or the appropriateness of empathetic behavior. To address these limitations, we sequentially introduce EmpathyEval, a descriptive natural-language-based evaluation model for assessing empathetic quality in spoken dialogues. Building upon EmpathyEval, we propose ReEmpathy, an end-to-end SLM that enhances empathetic dialogue through a novel Empathetic Self-Reflective Alternating Inference mechanism, which interleaves spoken response generation with free-form, empathy-related reflective reasoning. Extensive experiments demonstrate that ReEmpathy substantially improves empathy-sensitive spoken dialogue by enabling reflective reasoning, offering a promising approach toward more emotionally intelligent and empathy-aware human-computer interactions.

</details>


### [241] [U-Fold: Dynamic Intent-Aware Context Folding for User-Centric Agents](https://arxiv.org/abs/2601.18285)
*Jin Su,Runnan Fang,Yeqiu Li,Xiaobin Wang,Shihao Cai,Pengjun Xie,Ningyu Zhang,Fajie Yuan*

Main category: cs.CL

TL;DR: U-Fold是一个针对用户中心任务的动态上下文折叠框架，通过意图感知的对话摘要和任务相关的工具日志，解决了现有上下文折叠方法在用户中心对话中的失败模式，显著提升了长上下文、多轮任务的表现。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的智能体在工具增强设置中受限于上下文长度，现有的上下文折叠方法主要为单查询或单意图场景设计，在用户中心对话中会丢弃细粒度约束和中间事实，且无法跟踪演变的用户意图，导致遗漏和错误操作。

Method: U-Fold保留完整的用户-智能体对话和工具调用历史，在每个回合使用两个核心组件：1) 生成意图感知、演变的对话摘要；2) 生成紧凑、任务相关的工具日志。该框架专门针对用户中心任务设计。

Result: 在τ-bench、τ²-bench、VitaBench和更难的上下文膨胀设置上的广泛实验表明，U-Fold始终优于ReAct（在长上下文设置中达到71.4%的胜率）和先前的折叠基线（改进高达27.0%），特别是在长、嘈杂、多轮任务上表现突出。

Conclusion: U-Fold是将上下文管理技术从单查询基准转移到现实用户中心应用的有希望的一步，解决了现有上下文折叠方法在用户中心对话中的关键限制。

Abstract: Large language model (LLM)-based agents have been successfully deployed in many tool-augmented settings, but their scalability is fundamentally constrained by context length. Existing context-folding methods mitigate this issue by summarizing past interactions, yet they are typically designed for single-query or single-intent scenarios. In more realistic user-centric dialogues, we identify two major failure modes: (i) they irreversibly discard fine-grained constraints and intermediate facts that are crucial for later decisions, and (ii) their summaries fail to track evolving user intent, leading to omissions and erroneous actions. To address these limitations, we propose U-Fold, a dynamic context-folding framework tailored to user-centric tasks. U-Fold retains the full user--agent dialogue and tool-call history but, at each turn, uses two core components to produce an intent-aware, evolving dialogue summary and a compact, task-relevant tool log. Extensive experiments on $τ$-bench, $τ^2$-bench, VitaBench, and harder context-inflated settings show that U-Fold consistently outperforms ReAct (achieving a 71.4% win rate in long-context settings) and prior folding baselines (with improvements of up to 27.0%), particularly on long, noisy, multi-turn tasks. Our study demonstrates that U-Fold is a promising step toward transferring context-management techniques from single-query benchmarks to realistic user-centric applications.

</details>


### [242] [Temp-R1: A Unified Autonomous Agent for Complex Temporal KGQA via Reverse Curriculum Reinforcement Learning](https://arxiv.org/abs/2601.18296)
*Zhaoyan Gong,Zhiqiang Liu,Songze Li,Xiaoke Guo,Yuanxiang Liu,Xinle Deng,Zhizhen Liu,Lei Liang,Huajun Chen,Wen Zhang*

Main category: cs.CL

TL;DR: Temp-R1是首个通过强化学习训练的端到端自主TKGQA智能体，采用扩展动作空间和逆向课程学习，在复杂问题上超越现有方法19.8%


<details>
  <summary>Details</summary>
Motivation: 现有TKGQA方法依赖固定流程和闭源API，缺乏灵活性和可扩展性，难以处理动态事实的多跳依赖和复杂时间约束

Method: 1) 通过强化学习训练自主端到端智能体；2) 扩展动作空间，包含专用内部动作和外部动作；3) 引入逆向课程学习，先训练困难问题再迁移到简单问题

Result: 8B参数的Temp-R1在MultiTQ和TimelineKGQA上达到SOTA性能，在复杂问题上比强基线提升19.8%

Conclusion: Temp-R1为自主时间推理智能体建立了新范式，代码将公开提供

Abstract: Temporal Knowledge Graph Question Answering (TKGQA) is inherently challenging, as it requires sophisticated reasoning over dynamic facts with multi-hop dependencies and complex temporal constraints. Existing methods rely on fixed workflows and expensive closed-source APIs, limiting flexibility and scalability. We propose Temp-R1, the first autonomous end-to-end agent for TKGQA trained through reinforcement learning. To address cognitive overload in single-action reasoning, we expand the action space with specialized internal actions alongside external action. To prevent shortcut learning on simple questions, we introduce reverse curriculum learning that trains on difficult questions first, forcing the development of sophisticated reasoning before transferring to easier cases. Our 8B-parameter Temp-R1 achieves state-of-the-art performance on MultiTQ and TimelineKGQA, improving 19.8% over strong baselines on complex questions. Our work establishes a new paradigm for autonomous temporal reasoning agents. Our code will be publicly available soon at https://github.com/zjukg/Temp-R1.

</details>


### [243] [Suppressing Final Layer Hidden State Jumps in Transformer Pretraining](https://arxiv.org/abs/2601.18302)
*Keigo Shibata,Kazuki Yano,Ryosuke Takahashi,Jaesung Lee,Wataru Ikeda,Jun Suzuki*

Main category: cs.CL

TL;DR: 本文研究了Transformer语言模型的内部行为，发现许多预训练模型在中间层输入输出隐藏状态向量的角度距离变化很小，但在最后一层附近会出现不成比例的"跳跃"。作者提出了抑制这种跳跃的正则化方法JREG，通过预训练惩罚这种跳跃，使中间层能力使用更均衡，从而提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 许多预训练Transformer模型在中间层的隐藏状态向量角度距离变化很小，但在最后一层附近会出现不成比例的"跳跃"。作者认为这种跳跃可能是不理想的特性，希望通过抑制这种跳跃来使模型各层能力使用更均衡，从而提升整体性能。

Method: 首先引入量化指标来衡量最后一层附近的跳跃强度，并验证其在多个开源模型中的普遍性。然后提出跳跃抑制正则化器(JREG)，在预训练过程中惩罚这种跳跃，鼓励中间层更均衡地使用能力。在Llama架构的三种不同规模模型上进行了实验验证。

Result: JREG方法在多个模型规模上都表现出比基线更好的任务性能，且不需要改变模型架构。实验表明该方法能有效抑制最后一层附近的跳跃，使中间层能力使用更均衡。

Conclusion: Transformer语言模型最后一层附近的角度距离跳跃是普遍现象，通过JREG正则化抑制这种跳跃可以改善模型内部行为，使各层能力使用更均衡，从而提升模型性能，且不改变模型架构。

Abstract: This paper discusses the internal behavior of Transformer language models. Many recent pre-trained models have been reported to exhibit only slight changes in the angular distance between the input and output hidden state vectors in the middle Transformer layers, despite a disproportionately large ``jump'' in the angular distance occurring in or around the final Transformer layer. To characterize this, we first introduce a quantitative metric for the jump strength around the final layer, and then demonstrate its prevalence across many open-weight models, as well as its amplification throughout pre-training. Assuming such jumps indicate an undesirable property, we propose the jump-suppressing regularizer (JREG) which penalizes this jump during pre-training, thereby encouraging more balanced capability usage across the middle layers. Empirical evaluations of three model sizes of Llama-based models, trained with the proposed JREG method, reveal improved task performance compared to the baseline without altering the model architecture.

</details>


### [244] [Calibrating Beyond English: Language Diversity for Better Quantized Multilingual LLM](https://arxiv.org/abs/2601.18306)
*Everlyn Asiko Chimoto,Mostafa Elhoushi,Bruce A. Bassett*

Main category: cs.CL

TL;DR: 该论文系统评估了多语言大语言模型量化中的校准集选择问题，发现非英语和多语言校准集相比英语基线能显著降低困惑度，语言对齐对量化性能至关重要。


<details>
  <summary>Details</summary>
Motivation: 现有后训练量化方法通常使用小型、仅英语的校准集，但它们对多语言模型的影响尚未充分探索。需要研究不同语言校准集对量化性能的影响。

Method: 系统评估了8种校准设置（5种单语言和3种多语言混合）在两种量化器（GPTQ、AWQ）上，使用10种语言的数据。在Llama3.1 8B和Qwen2.5 7B模型上进行实验。

Result: 非英语和多语言校准集相比英语基线显著改善困惑度，多语言混合校准集实现最大困惑度降低（高达3.52点）。针对评估语言定制校准集对单个语言带来最大改进。发现某些语言-量化器组合会降低性能，这与不同语言的激活范围分布差异有关。

Conclusion: 静态的"一刀切"校准方法不是最优选择，定制校准数据（包括语言和多样性）对稳健量化多语言LLM起着关键作用。语言对齐和多语言校准集能显著提升量化性能。

Abstract: Quantization is an effective technique for reducing the storage footprint and computational costs of Large Language Models (LLMs), but it often results in performance degradation. Existing post-training quantization methods typically use small, English-only calibration sets; however, their impact on multilingual models remains underexplored. We systematically evaluate eight calibration settings (five single-language and three multilingual mixes) on two quantizers (GPTQ, AWQ) on data from 10 languages. Our findings reveal a consistent trend: non-English and multilingual calibration sets significantly improve perplexity compared to English-only baselines. Specifically, we observe notable average perplexity gains across both quantizers on Llama3.1 8B and Qwen2.5 7B, with multilingual mixes achieving the largest overall reductions of up to 3.52 points in perplexity. Furthermore, our analysis indicates that tailoring calibration sets to the evaluation language yields the largest improvements for individual languages, underscoring the importance of linguistic alignment. We also identify specific failure cases where certain language-quantizer combinations degrade performance, which we trace to differences in activation range distributions across languages. These results highlight that static one-size-fits-all calibration is suboptimal and that tailoring calibration data, both in language and diversity, plays a crucial role in robustly quantizing multilingual LLMs.

</details>


### [245] [Overalignment in Frontier LLMs: An Empirical Study of Sycophantic Behaviour in Healthcare](https://arxiv.org/abs/2601.18334)
*Clément Christophe,Wadood Mohammed Abdul,Prateek Munjal,Tathagata Raha,Ronnie Rajan,Praveenkumar Kanithi*

Main category: cs.CL

TL;DR: 该论文提出了一种基于医学MCQA的评估框架，用于量化LLM在临床环境中的顺从性风险，并发现推理优化模型在面对权威压力时更容易合理化错误建议。


<details>
  <summary>Details</summary>
Motivation: 随着LLM越来越多地集成到临床工作流程中，它们倾向于顺从用户意见而非坚持事实准确性，这对患者安全构成重大风险。现有评估方法通常依赖主观数据集，缺乏基于可验证事实的稳健框架。

Method: 提出了基于医学多项选择题(MCQA)的评估框架，引入"调整顺从性分数"这一新指标，该指标通过考虑随机模型不稳定性（"混淆性"）来隔离对齐偏差。对Qwen-3和Llama-3系列模型进行了广泛的扩展分析。

Result: 发现了清晰的扩展轨迹：模型规模越大，对顺从性的抵御能力越强。但发现了一个反直觉的脆弱性：推理优化的"思考"模型虽然具有较高的原始准确率，但在权威压力下，其内部推理轨迹经常合理化错误的用户建议。

Conclusion: 基准测试性能不能代表临床可靠性，简化的推理结构可能在对抗专家驱动的顺从性方面提供更优越的鲁棒性。这强调了在临床部署中需要专门评估LLM的顺从性风险。

Abstract: As LLMs are increasingly integrated into clinical workflows, their tendency for sycophancy, prioritizing user agreement over factual accuracy, poses significant risks to patient safety. While existing evaluations often rely on subjective datasets, we introduce a robust framework grounded in medical MCQA with verifiable ground truths. We propose the Adjusted Sycophancy Score, a novel metric that isolates alignment bias by accounting for stochastic model instability, or "confusability". Through an extensive scaling analysis of the Qwen-3 and Llama-3 families, we identify a clear scaling trajectory for resilience. Furthermore, we reveal a counter-intuitive vulnerability in reasoning-optimized "Thinking" models: while they demonstrate high vanilla accuracy, their internal reasoning traces frequently rationalize incorrect user suggestions under authoritative pressure. Our results across frontier models suggest that benchmark performance is not a proxy for clinical reliability, and that simplified reasoning structures may offer superior robustness against expert-driven sycophancy.

</details>


### [246] [When Domain Pretraining Interferes with Instruction Alignment: An Empirical Study of Adapter Merging in Medical LLMs](https://arxiv.org/abs/2601.18350)
*Junyi Zou*

Main category: cs.CL

TL;DR: 该研究针对大语言模型在医学术语精确性和安全关键指令遵循方面的不足，提出了一种两阶段LoRA管道方法，通过领域自适应预训练和监督微调，并采用加权适配器合并技术来平衡指令遵循能力和领域知识保留。


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽然具有强大的通用能力，但在医学术语精确性和安全关键指令遵循方面表现不足。医疗领域需要高度精确的术语使用和严格的安全要求，因此需要专门的方法来提升模型在医疗领域的表现。

Method: 采用两阶段LoRA管道：1) 领域自适应预训练（DAPT）通过继续预训练注入广泛的医学知识；2) 监督微调（SFT）使用指令式数据使模型与医学问答行为对齐。提出加权适配器合并技术，在导出合并的基础模型检查点之前线性组合SFT和PT适配器。

Result: 在医疗验证集（F5/F6）上，合并模型在实用解码配置下取得了BLEU-4=16.38、ROUGE-1=20.42、ROUGE-2=4.60、ROUGE-L=11.54的成绩。研究还分析了解码敏感性和训练稳定性，包括损失曲线和受控解码比较。

Conclusion: 该研究提出的两阶段LoRA管道和加权适配器合并技术有效提升了模型在医疗领域的表现，平衡了指令遵循能力和领域知识保留，为安全关键领域的适配器干扰问题提供了解决方案。

Abstract: Large language models (LLMs) show strong general capability but often struggle with medical terminology precision and safety-critical instruction following. We present a case study for adapter interference in safety-critical domains using a 14B-parameter base model through a two-stage LoRA pipeline: (1) domain-adaptive pre-training (PT) to inject broad medical knowledge via continued pre-training (DAPT), and (2) supervised fine-tuning (SFT) to align the model with medical question-answering behaviors through instruction-style data. To balance instruction-following ability and domain knowledge retention, we propose Weighted Adapter Merging, linearly combining SFT and PT adapters before exporting a merged base-model checkpoint. On a held-out medical validation set (F5/F6), the merged model achieves BLEU-4 = 16.38, ROUGE-1 = 20.42, ROUGE-2 = 4.60, and ROUGE-L = 11.54 under a practical decoding configuration. We further analyze decoding sensitivity and training stability with loss curves and controlled decoding comparisons.

</details>


### [247] [Code over Words: Overcoming Semantic Inertia via Code-Grounded Reasoning](https://arxiv.org/abs/2601.18352)
*Manjie Xu,Isabella Yin,Xinyi Tu,Chi Zhang,Yixin Zhu*

Main category: cs.CL

TL;DR: 大语言模型存在"语义惯性"问题：难以抑制预训练先验知识（如"岩浆危险"）来适应动态的上下文规则变化。研究发现更大模型可能表现更差，但将动态规则表示为可执行代码而非描述性文本可以逆转这一趋势。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索LLMs在处理动态、上下文相关规则时的局限性，特别是当这些规则与预训练先验知识相矛盾时。模型表现出"语义惯性" - 无法抑制固有知识来适应新规则，这在需要动态调整规则的场景中是个严重问题。

Method: 使用Baba Is You游戏作为测试平台，其中物理规则是可变的文本规则。提出Code-Grounded Vistas (LCV)方法：将动态规则表示为可执行代码而非描述性文本，通过微调模型处理反事实对，识别具有矛盾规则的状态，强制模型关注逻辑约束而非视觉语义。

Result: 研究发现：1）更大模型可能表现更差（逆缩放现象）；2）自然语言编码将描述性语义和逻辑规则纠缠在一起，导致持续产生熟悉的物理幻觉；3）将动态表示为可执行代码可以逆转逆缩放趋势，实现有效的先验抑制；4）LCV方法在效率和准确性上都优于昂贵的推理时搜索方法。

Conclusion: 表示形式（representation）从根本上决定了缩放是否改善或损害上下文推理能力。这挑战了"更大模型总是更好"的假设，对需要动态覆盖学习先验的领域有重要影响。代码表示比自然语言表示更适合处理动态规则变化。

Abstract: LLMs struggle with Semantic Inertia: the inability to inhibit pre-trained priors (e.g., "Lava is Dangerous") when dynamic, in-context rules contradict them. We probe this phenomenon using Baba Is You, where physical laws are mutable text rules, enabling precise evaluation of models' ability to override learned priors when rules change. We quantatively observe that larger models can exhibit inverse scaling: they perform worse than smaller models when natural language reasoning requires suppressing pre-trained associations (e.g., accepting "Lava is Safe"). Our analysis attributes this to natural language encoding, which entangles descriptive semantics and logical rules, leading to persistent hallucinations of familiar physics despite explicit contradictory rules. Here we show that representing dynamics as executable code, rather than descriptive text, reverses this trend and enables effective prior inhibition. We introduce Code-Grounded Vistas (LCV), which fine-tunes models on counterfactual pairs and identifies states with contradictory rules, thereby forcing attention to logical constraints rather than visual semantics. This training-time approach outperforms expensive inference-time search methods in both efficiency and accuracy. Our results demonstrate that representation fundamentally determines whether scaling improves or impairs contextual reasoning. This challenges the assumption that larger models are universally better, with implications for domains that require dynamic overriding of learned priors.

</details>


### [248] [CitiLink: Enhancing Municipal Transparency and Citizen Engagement through Searchable Meeting Minutes](https://arxiv.org/abs/2601.18374)
*Rodrigo Silva,José Evans,José Isidro,Miguel Marques,Afonso Fonseca,Ricardo Morais,João Canavilhas,Arian Pasquali,Purificação Silvano,Alípio Jorge,Nuno Guimarães,Sérgio Nunes,Ricardo Campos*

Main category: cs.CL

TL;DR: CitiLink平台利用LLMs将非结构化市政会议记录转化为结构化可搜索数据，提升地方政府透明度


<details>
  <summary>Details</summary>
Motivation: 市政会议记录通常冗长且格式正式，虽然公开但结构复杂，公民和记者难以高效查找信息，需要提升地方政府信息的可访问性和透明度

Method: 使用LLMs提取元数据、讨论主题和投票结果，通过BM25排名和分面过滤建立全文搜索数据库，构建用户友好界面，基于葡萄牙6个城市的120份会议记录进行开发

Result: 开发了CitiLink平台，通过市政人员引导测试评估了系统可用性，评估了Gemini在信息提取方面的性能，证明了其在数据提取中的有效性

Conclusion: NLP和IR技术可以有效提升地方政府信息的可访问性和透明度，CitiLink展示了将非结构化市政文档转化为结构化可搜索数据的可行性

Abstract: City council minutes are typically lengthy and formal documents with a bureaucratic writing style. Although publicly available, their structure often makes it difficult for citizens or journalists to efficiently find information. In this demo, we present CitiLink, a platform designed to transform unstructured municipal meeting minutes into structured and searchable data, demonstrating how NLP and IR can enhance the accessibility and transparency of local government. The system employs LLMs to extract metadata, discussed subjects, and voting outcomes, which are then indexed in a database to support full-text search with BM25 ranking and faceted filtering through a user-friendly interface. The developed system was built over a collection of 120 minutes made available by six Portuguese municipalities. To assess its usability, CitiLink was tested through guided sessions with municipal personnel, providing insights into how real users interact with the system. In addition, we evaluated Gemini's performance in extracting relevant information from the minutes, highlighting its effectiveness in data extraction.

</details>


### [249] [Hierarchical Text Classification with LLM-Refined Taxonomies](https://arxiv.org/abs/2601.18375)
*Jonas Golde,Nicolaas Jedema,Ravi Krishnan,Phong Le*

Main category: cs.CL

TL;DR: TaxMorph：使用LLM重构分类学层次结构以解决标签歧义问题，提升层次文本分类性能


<details>
  <summary>Details</summary>
Motivation: 现实世界中的分类学存在标签歧义问题，如相似父节点下的相同叶节点名称，这阻碍了语言模型学习清晰的决策边界

Method: TaxMorph框架使用大语言模型通过重命名、合并、拆分和重新排序等操作来重构整个分类学层次结构

Result: 在三个HTC基准测试中，LLM优化的分类学相比人工分类学性能提升最高达+2.9pp F1分数，尽管在嵌入空间中更难分离，但更符合模型的实际混淆模式

Conclusion: LLM引导的分类学优化创建了更符合模型学习方式的分类学结构，从而提高了层次文本分类性能

Abstract: Hierarchical text classification (HTC) depends on taxonomies that organize labels into structured hierarchies. However, many real-world taxonomies introduce ambiguities, such as identical leaf names under similar parent nodes, which prevent language models (LMs) from learning clear decision boundaries. In this paper, we present TaxMorph, a framework that uses large language models (LLMs) to transform entire taxonomies through operations such as renaming, merging, splitting, and reordering. Unlike prior work, our method revises the full hierarchy to better match the semantics encoded by LMs. Experiments across three HTC benchmarks show that LLM-refined taxonomies consistently outperform human-curated ones in various settings up to +2.9pp. in F1. To better understand these improvements, we compare how well LMs can assign leaf nodes to parent nodes and vice versa across human-curated and LLM-refined taxonomies. We find that human-curated taxonomies lead to more easily separable clusters in embedding space. However, the LLM-refined taxonomies align more closely with the model's actual confusion patterns during classification. In other words, even though they are harder to separate, they better reflect the model's inductive biases. These findings suggest that LLM-guided refinement creates taxonomies that are more compatible with how models learn, improving HTC performance.

</details>


### [250] [Corpus-Based Approaches to Igbo Diacritic Restoration](https://arxiv.org/abs/2601.18380)
*Ignatius Ezeani*

Main category: cs.CL

TL;DR: 该论文针对低资源语言（特别是伊博语）的变音符号歧义问题，提出了三种变音符号恢复方法：标准n-gram模型、分类模型和嵌入模型，以解决NLP研究中资源不平衡的问题。


<details>
  <summary>Details</summary>
Motivation: 当前NLP研究主要关注英语、中文等高资源语言，而全球95%以上的7000种语言属于低资源语言，缺乏数据、工具和技术支持。伊博语作为低资源语言，存在变音符号歧义问题，需要开发专门的解决方案。

Method: 提出了三种变音符号恢复方法：1）标准n-gram模型：使用目标词之前的词序列作为预测正确变体形式的关键特征；2）分类模型：使用目标词两侧的窗口词作为特征；3）嵌入模型：比较上下文词嵌入组合与候选变体向量嵌入的相似度得分。

Result: 开发了一个灵活的框架用于生成变音符号恢复的数据集，并针对伊博语实现了三种不同的变音符号消歧方法，为低资源语言的NLP处理提供了实用解决方案。

Conclusion: 该研究填补了低资源语言NLP处理的空白，特别是针对伊博语的变音符号歧义问题，提出的三种方法为其他低资源语言的类似问题提供了可借鉴的框架和方法论。

Abstract: With natural language processing (NLP), researchers aim to enable computers to identify and understand patterns in human languages. This is often difficult because a language embeds many dynamic and varied properties in its syntax, pragmatics and phonology, which need to be captured and processed. The capacity of computers to process natural languages is increasing because NLP researchers are pushing its boundaries. But these research works focus more on well-resourced languages such as English, Japanese, German, French, Russian, Mandarin Chinese, etc. Over 95% of the world's 7000 languages are low-resourced for NLP, i.e. they have little or no data, tools, and techniques for NLP work.
  In this thesis, we present an overview of diacritic ambiguity and a review of previous diacritic disambiguation approaches on other languages. Focusing on the Igbo language, we report the steps taken to develop a flexible framework for generating datasets for diacritic restoration. Three main approaches, the standard n-gram model, the classification models and the embedding models were proposed. The standard n-gram models use a sequence of previous words to the target stripped word as key predictors of the correct variants. For the classification models, a window of words on both sides of the target stripped word was used. The embedding models compare the similarity scores of the combined context word embeddings and the embeddings of each of the candidate variant vectors.

</details>


### [251] [Do not be greedy, Think Twice: Sampling and Selection for Document-level Information Extraction](https://arxiv.org/abs/2601.18395)
*Mikel Zubillaga,Oscar Sainz,Oier Lopez de Lacalle,Eneko Agirre*

Main category: cs.CL

TL;DR: ThinkTwice框架通过采样生成多个候选模板，然后选择最佳方案，显著优于贪婪解码方法


<details>
  <summary>Details</summary>
Motivation: 传统文档级信息抽取使用贪婪解码以避免输出变异性，但作者认为采样变异性可以产生更好的解决方案，特别是使用推理模型时

Method: 提出ThinkTwice框架：1) LLM为给定文档生成多个候选模板；2) 选择模块选择最合适的模板。包含无监督方法（利用生成输出间的一致性）和监督方法（使用在标注DocIE数据上训练的奖励模型）。为解决DocIE黄金推理轨迹稀缺问题，提出基于拒绝采样的方法生成包含输出模板和推理轨迹的银训练数据

Result: 实验证明无监督和监督ThinkTwice方法的有效性，一致优于贪婪基线和最先进方法

Conclusion: 采样变异性不是限制而是优势，ThinkTwice框架通过采样和选择机制显著提升文档级信息抽取性能

Abstract: Document-level Information Extraction (DocIE) aims to produce an output template with the entities and relations of interest occurring in the given document. Standard practices include prompting decoder-only LLMs using greedy decoding to avoid output variability. Rather than treating this variability as a limitation, we show that sampling can produce substantially better solutions than greedy decoding, especially when using reasoning models. We thus propose ThinkTwice, a sampling and selection framework in which the LLM generates multiple candidate templates for a given document, and a selection module chooses the most suitable one. We introduce both an unsupervised method that exploits agreement across generated outputs, and a supervised selection method using reward models trained on labeled DocIE data. To address the scarcity of golden reasoning trajectories for DocIE, we propose a rejection-sampling-based method to generate silver training data that pairs output templates with reasoning traces. Our experiments show the validity of unsupervised and supervised ThinkTwice, consistently outperforming greedy baselines and the state-of-the-art.

</details>


### [252] [Pisets: A Robust Speech Recognition System for Lectures and Interviews](https://arxiv.org/abs/2601.18415)
*Ivan Bondarenko,Daniil Grebenkin,Oleg Sedukhin,Mikhail Klementev,Roman Derunets,Lyudmila Budneva*

Main category: cs.CL

TL;DR: 提出基于三组件架构的语音转文字系统"Pisets"，通过Wav2Vec2、Audio Spectrogram Transformer和Whisper的组合，结合课程学习和不确定性建模，显著提升俄语语音识别准确性并减少错误和幻觉。


<details>
  <summary>Details</summary>
Motivation: 解决Whisper模型在语音识别中存在的错误和幻觉问题，特别是针对俄语语音识别场景，为科学家和记者提供更准确可靠的语音转文字工具。

Method: 采用三组件架构：1) Wav2Vec2进行初步识别；2) Audio Spectrogram Transformer进行误报过滤；3) Whisper进行最终语音识别。结合课程学习方法，利用多样化的俄语语音语料库，并引入先进的不确定性建模技术。

Result: 相比WhisperX和标准Whisper模型，Pisets系统在各种声学条件下对长音频数据的转录表现出更强的鲁棒性，识别准确性显著提升，错误和幻觉减少。

Conclusion: Pisets系统通过创新的三组件架构和训练策略，有效解决了Whisper模型在俄语语音识别中的局限性，为科学和新闻领域提供了高质量的语音转文字解决方案，代码已开源。

Abstract: This work presents a speech-to-text system "Pisets" for scientists and journalists which is based on a three-component architecture aimed at improving speech recognition accuracy while minimizing errors and hallucinations associated with the Whisper model. The architecture comprises primary recognition using Wav2Vec2, false positive filtering via the Audio Spectrogram Transformer (AST), and final speech recognition through Whisper. The implementation of curriculum learning methods and the utilization of diverse Russian-language speech corpora significantly enhanced the system's effectiveness. Additionally, advanced uncertainty modeling techniques were introduced, contributing to further improvements in transcription quality. The proposed approaches ensure robust transcribing of long audio data across various acoustic conditions compared to WhisperX and the usual Whisper model. The source code of "Pisets" system is publicly available at GitHub: https://github.com/bond005/pisets.

</details>


### [253] [Latent Knowledge as a Predictor of Fact Acquisition in Fine-Tuned Large Language Models](https://arxiv.org/abs/2601.18468)
*Daniel B. Hier,Tayo Obafemi-Ajayi*

Main category: cs.CL

TL;DR: 研究显示大语言模型在预训练后存储生物医学事实的强度不均，部分知识以潜在形式存在但无法通过确定性解码可靠访问。通过微调Llama 3.1 8B学习本体术语映射，发现潜在知识能预测事实获取速度、有限泛化能力，而抗退化能力取决于训练期间是否得到强化。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在预训练后存储生物医学事实的强度存在差异：有些事实存在于权重中但无法通过确定性解码可靠访问（潜在知识），而其他事实则很少被表示。研究者希望探究这些潜在知识如何影响微调过程中的事实获取、泛化和退化。

Method: 微调Llama 3.1 8B Instruct模型学习人类表型本体（800对）和基因本体（400训练对）的术语标识符映射，保留400个GO对用于测试泛化。将学习视为跨越20个epoch的时间事件过程，使用随机解码检测基线潜在知识，并采用Cox比例风险模型识别获取、泛化和退化的预测因子。

Result: HPO的基线确定性召回率为2.8%，微调后升至71.9%。潜在知识是最强的事实获取速度预测因子（HR 2.6），与更早、更高的峰值学习率和更快收敛相关。泛化到保留的GO事实不常见（5.8%），但当存在潜在知识时更可能发生。先前正确的GO映射在保留（未见）术语中比训练（已见）术语更常退化，表明训练期间的强化具有保护作用。

Conclusion: 潜在知识能预测微调期间事实学习的速度和未见本体事实的有限泛化，而抗退化能力取决于事实是否在训练中得到强化。这些发现对理解大语言模型如何获取和保持生物医学知识具有重要意义。

Abstract: Large language models store biomedical facts with uneven strength after pretraining: some facts are present in the weights but are not reliably accessible under deterministic decoding (latent knowledge), while others are scarcely represented. We fine tuned Llama 3.1 8B Instruct to learn ontology term identifier mappings from the Human Phenotype Ontology (800 pairs) and the Gene Ontology (400 training pairs), withholding 400 GO pairs to test generalization. Treating learning as a time to event process across 20 epochs, we used stochastic decoding to detect latent knowledge at baseline and Cox proportional hazards models to identify predictors of acquisition, generalization, and degradation. Baseline deterministic recall for HPO was 2.8%, rising to 71.9% after fine-tuning. Latent knowledge was the strongest predictor of faster fact acquisition (HR 2.6) and was associated with earlier, higher peak learning rates and faster convergence; identifier frequency and curated annotation counts had smaller effects. Generalization to withheld GO facts was uncommon (5.8%) but more likely when latent knowledge was present. Previously correct GO mappings degraded more often for withheld (unseen) terms than for trained (seen) terms, suggesting a protective effect of reinforcement during training. These results show that latent knowledge predicts both the speed of factual learning during fine-tuning and the limited generalization of unseen ontology facts, while resistance to degradation depends on whether facts are reinforced.

</details>


### [254] [Funny or Persuasive, but Not Both: Evaluating Fine-Grained Multi-Concept Control in LLMs](https://arxiv.org/abs/2601.18483)
*Arya Labroo,Ivaxi Sheth,Vyas Raina,Amaani Ahmed,Mario Fritz*

Main category: cs.CL

TL;DR: 研究发现LLMs在多概念控制场景下表现下降，即使概念理论上可分离，揭示了基于提示的控制方法在组合性方面的根本局限性。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型具有强大的生成能力，但许多应用需要对特定文本概念（如幽默、说服力、正式性）进行精细控制。现有方法只能提供粗略或单一属性控制，缺乏对多属性场景的系统评估。

Method: 引入了一个评估框架，用于评估单概念和双概念场景下的精细可控性，重点关注语言上不同的概念对（如说服力vs幽默）。

Result: 在多个LLM和生成任务中，双概念设置下的性能通常下降，即使所选概念在原则上应该是可分离的。这揭示了基于提示的控制方法在组合性方面的根本局限性。

Conclusion: 该框架为多概念控制能力的系统评估提供了原则性方法，揭示了当前LLMs在同时控制多个文本概念时的局限性，为未来改进方法提供了基准。

Abstract: Large Language Models (LLMs) offer strong generative capabilities, but many applications require explicit and \textit{fine-grained} control over specific textual concepts, such as humor, persuasiveness, or formality. Prior approaches in prompting and representation engineering can provide coarse or single-attribute control, but systematic evaluation of multi-attribute settings remains limited. We introduce an evaluation framework for fine-grained controllability for both single- and dual-concept scenarios, focusing on linguistically distinct concept pairs (e.g., persuasiveness vs.~humor). Surprisingly, across multiple LLMs and generative tasks, we find that performance often drops in the dual-concept setting, even though the chosen concepts should in principle be separable. This reveals a fundamental limitation of naive prompting-based control: models struggle with compositionality even when concepts are intuitively independent. Our framework provides systematic evidence of this gap and offers a principled approach for measuring the ability of future methods for multi-concept control.

</details>


### [255] [Demographic Probing of Large Language Models Lacks Construct Validity](https://arxiv.org/abs/2601.18486)
*Manuel Tonneau,Neil K. R. Seghal,Niyati Malhotra,Victor Orozco-Olvera,Ana María Muñoz Boudet,Lakshmi Subramanian,Sharath Chandra Guntuku,Valentin Hofmann*

Main category: cs.CL

TL;DR: 研究发现人口统计探测方法缺乏构念效度，不同人口线索（如姓名、方言）对LLM行为的影响不一致，导致估计的差异不稳定，建议使用多种生态有效线索并控制混淆因素。


<details>
  <summary>Details</summary>
Motivation: 当前人口统计探测研究通常使用单一人口线索（如姓名或方言）作为群体成员信号，隐含假设这些线索可以互换地操作化相同的人口统计条件行为。本研究旨在测试这种构念效度假设是否成立。

Method: 在现实的寻求建议互动中测试种族和性别线索（美国语境），分析不同线索（如姓名、方言）对LLM行为的影响，考察线索间的一致性、群体间区分度，并探究不一致性的来源（如线索编码强度、语言混淆因素）。

Result: 1）代表相同人口群体的线索仅引起部分重叠的行为变化；2）同一线索内群体间区分度弱且不均匀；3）估计的差异不稳定，大小和方向随线索变化；4）不一致性部分源于线索编码人口属性的强度差异和独立影响模型行为的语言混淆因素。

Conclusion: 人口统计探测缺乏构念效度，无法提供关于LLM如何基于人口信息条件化的单一稳定表征，这可能反映了构念的错误设定或碎片化。建议使用多种生态有效线索并明确控制混淆因素，以支持关于LLM人口效应的更可靠主张。

Abstract: Demographic probing is widely used to study how large language models (LLMs) adapt their behavior to signaled demographic attributes. This approach typically uses a single demographic cue in isolation (e.g., a name or dialect) as a signal for group membership, implicitly assuming strong construct validity: that such cues are interchangeable operationalizations of the same underlying, demographically conditioned behavior. We test this assumption in realistic advice-seeking interactions, focusing on race and gender in a U.S. context. We find that cues intended to represent the same demographic group induce only partially overlapping changes in model behavior, while differentiation between groups within a given cue is weak and uneven. Consequently, estimated disparities are unstable, with both magnitude and direction varying across cues. We further show that these inconsistencies partly arise from variation in how strongly cues encode demographic attributes and from linguistic confounders that independently shape model behavior. Together, our findings suggest that demographic probing lacks construct validity: it does not yield a single, stable characterization of how LLMs condition on demographic information, which may reflect a misspecified or fragmented construct. We conclude by recommending the use of multiple, ecologically valid cues and explicit control of confounders to support more defensible claims about demographic effects in LLMs.

</details>


### [256] [Using Large Language Models to Construct Virtual Top Managers: A Method for Organizational Research](https://arxiv.org/abs/2601.18512)
*Antonio Garzon-Vico,Krithika Sharon Komalapati,Arsalan Shahid,Jan Rosier*

Main category: cs.CL

TL;DR: 使用大语言模型构建真实高管虚拟人格的方法框架，通过道德基础理论评估其决策模拟的有效性


<details>
  <summary>Details</summary>
Motivation: 在难以直接接触高管的情况下，需要开发替代工具来研究组织决策。大语言模型为创建虚拟高管人格提供了可能，但需要验证其有效性。

Method: 基于真实CEO沟通内容和道德基础理论，构建LLM虚拟人格。通过三个阶段评估：构念效度、信度和行为保真度，将虚拟CEO与人类参与者进行基准比较。

Result: 理论支撑的虚拟人格能够近似人类样本的道德判断，表明LLM虚拟人格可以作为组织研究中可信且互补的工具。

Conclusion: LLM虚拟人格在组织研究中具有应用潜力，特别是在高管接触受限的情境下。研究为未来使用此类工具提供了方法论基础。

Abstract: This study introduces a methodological framework that uses large language models to create virtual personas of real top managers. Drawing on real CEO communications and Moral Foundations Theory, we construct LLM-based participants that simulate the decision-making of individual leaders. Across three phases, we assess construct validity, reliability, and behavioral fidelity by benchmarking these virtual CEOs against human participants. Our results indicate that theoretically scaffolded personas approximate the moral judgements observed in human samples, suggesting that LLM-based personas can serve as credible and complementary tools for organizational research in contexts where direct access to executives is limited. We conclude by outlining implications for future research using LLM-based personas in organizational settings.

</details>


### [257] [GenAI for Social Work Field Education: Client Simulation with Real-Time Feedback](https://arxiv.org/abs/2601.18517)
*James Sungarda,Hongkai Liu,Zilong Zhou,Tien-Hsuan Wu,Johnson Chun-Sing Cheung,Ben Kao*

Main category: cs.CL

TL;DR: SWITCH是一个社会工作交互式训练聊天机器人，集成了真实客户模拟、实时咨询技能分类和动机访谈进展系统，以解决社会工作现场教育中反馈不足的问题。


<details>
  <summary>Details</summary>
Motivation: 社会工作现场教育是其标志性教学方法，但传统训练受限于教师和咨询客户的可用性，难以及时提供客观反馈。需要一种可扩展、低成本且一致的训练解决方案来补充现场教育。

Method: SWITCH采用认知基础的用户档案（包含静态和动态字段）来模拟真实客户行为演变。技能分类模块识别用户话语中的咨询技能，并输入到MI控制器来调节动机访谈阶段转换。通过基于上下文的检索学习和微调BERT多标签分类器提高分类准确性。

Result: 实验表明，BERT方法和基于上下文的学习方法都显著优于基线模型，验证了SWITCH在技能分类方面的有效性。

Conclusion: SWITCH提供了一个可扩展、低成本且一致的训练工作流程，能够补充社会工作现场教育，让督导能够专注于更高层次的指导工作。

Abstract: Field education is the signature pedagogy of social work, yet providing timely and objective feedback during training is constrained by the availability of instructors and counseling clients. In this paper, we present SWITCH, the Social Work Interactive Training Chatbot. SWITCH integrates realistic client simulation, real-time counseling skill classification, and a Motivational Interviewing (MI) progression system into the training workflow. To model a client, SWITCH uses a cognitively grounded profile comprising static fields (e.g., background, beliefs) and dynamic fields (e.g., emotions, automatic thoughts, openness), allowing the agent's behavior to evolve throughout a session realistically. The skill classification module identifies the counseling skills from the user utterances, and feeds the result to the MI controller that regulates the MI stage transitions. To enhance classification accuracy, we study in-context learning with retrieval over annotated transcripts, and a fine-tuned BERT multi-label classifier. In the experiments, we demonstrated that both BERT-based approach and in-context learning outperforms the baseline with big margin. SWITCH thereby offers a scalable, low-cost, and consistent training workflow that complements field education, and allows supervisors to focus on higher-level mentorship.

</details>


### [258] [Exploring Fine-Tuning for In-Context Retrieval and Efficient KV-Caching in Long-Context Language Models](https://arxiv.org/abs/2601.18527)
*Francesco Maria Molfese,Momchil Hardalov,Rexhina Blloshmi,Bill Byrne,Adrià de Gispert*

Main category: cs.CL

TL;DR: 研究探讨了长上下文语言模型（LCLMs）的微调策略如何提升其在长文档中的信息检索与使用能力，以及KV缓存压缩下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着上下文窗口扩展到百万token级别，LCLMs能够编码整个文档集合，成为传统检索增强生成（RAG）的有力替代方案。然而，目前尚不清楚微调策略是否能提升长上下文性能，以及这种提升能否转化为在KV缓存压缩技术下更强的鲁棒性。

Method: 研究调查了哪些训练策略最有效地增强LCLMs识别和使用相关信息的能力，以及提升其在KV缓存压缩下的鲁棒性。通过实验评估不同微调方法的效果。

Result: 实验显示在领域内任务上有显著改进，相比基础模型提升高达20个百分点。但领域外泛化能力因任务而异：LCLMs在金融问题上表现优异（+9分），而RAG在多项选择题上表现更强（+6分）。微调方法在KV缓存压缩下带来中等程度的鲁棒性提升，但不同任务间差异较大。

Conclusion: 微调策略能够有效提升LCLMs在长上下文任务中的性能，特别是在领域内任务上。然而，领域外泛化能力仍存在任务依赖性，且KV缓存压缩下的鲁棒性提升有限且不稳定。

Abstract: With context windows of millions of tokens, Long-Context Language Models (LCLMs) can encode entire document collections, offering a strong alternative to conventional retrieval-augmented generation (RAG). However, it remains unclear whether fine-tuning strategies can improve long-context performance and translate to greater robustness under KV-cache compression techniques. In this work, we investigate which training strategies most effectively enhance LCLMs' ability to identify and use relevant information, as well as enhancing their robustness under KV-cache compression. Our experiments show substantial in-domain improvements, achieving gains of up to +20 points over the base model. However, out-of-domain generalization remains task dependent with large variance -- LCLMs excels on finance questions (+9 points), while RAG shows stronger performance on multiple-choice questions (+6 points) over the baseline models. Finally, we show that our fine-tuning approaches bring moderate improvements in robustness under KV-cache compression, with gains varying across tasks.

</details>


### [259] [From Verifiable Dot to Reward Chain: Harnessing Verifiable Reference-based Rewards for Reinforcement Learning of Open-ended Generation](https://arxiv.org/abs/2601.18533)
*Yuxin Jiang,Yufei Wang,Qiyuan Zhang,Xingshan Zeng,Liangyou Li,Jierun Chen,Chaofan Tao,Haoli Bai,Lifeng Shang*

Main category: cs.CL

TL;DR: RLVRR提出了一种基于可验证参考奖励的强化学习方法，通过从高质量参考中提取有序语言信号（奖励链），解决了传统RLVR在开放式生成任务中的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统RLVR在推理任务中通过检查最终可验证答案（如数学、代码）表现良好，但在开放式生成任务中面临挑战，因为缺乏明确的地面真值。单一监督信号导致效率低下和奖励黑客问题。

Method: RLVRR从高质量参考中提取有序语言信号（奖励链），将奖励分解为两个维度：内容（保留确定性核心概念如关键词）和风格（通过LLM验证评估风格属性一致性）。结合RL的探索能力和SFT的效率可靠性。

Result: 在10多个基准测试中使用Qwen和Llama模型验证，RLVRR显著优于使用十倍数据训练的SFT和先进奖励模型，统一了结构化推理和开放式生成的训练，在保持输出多样性的同时具有更好的泛化能力。

Conclusion: RLVRR为通用LLM对齐提供了一条原则性且高效的可验证强化学习路径，解决了开放式生成任务中的监督信号不足问题，实现了RL探索优势与SFT效率可靠性的结合。

Abstract: Reinforcement learning with verifiable rewards (RLVR) succeeds in reasoning tasks (e.g., math and code) by checking the final verifiable answer (i.e., a verifiable dot signal). However, extending this paradigm to open-ended generation is challenging because there is no unambiguous ground truth. Relying on single-dot supervision often leads to inefficiency and reward hacking. To address these issues, we propose reinforcement learning with verifiable reference-based rewards (RLVRR). Instead of checking the final answer, RLVRR extracts an ordered linguistic signal from high-quality references (i.e, reward chain). Specifically, RLVRR decomposes rewards into two dimensions: content, which preserves deterministic core concepts (e.g., keywords), and style, which evaluates adherence to stylistic properties through LLM-based verification. In this way, RLVRR combines the exploratory strength of RL with the efficiency and reliability of supervised fine-tuning (SFT). Extensive experiments on more than 10 benchmarks with Qwen and Llama models confirm the advantages of our approach. RLVRR (1) substantially outperforms SFT trained with ten times more data and advanced reward models, (2) unifies the training of structured reasoning and open-ended generation, and (3) generalizes more effectively while preserving output diversity. These results establish RLVRR as a principled and efficient path toward verifiable reinforcement learning for general-purpose LLM alignment. We release our code and data at https://github.com/YJiangcm/RLVRR.

</details>


### [260] [Evaluating Morphological Plausibility of Subword Tokenization via Statistical Alignment with Morpho-Syntactic Features](https://arxiv.org/abs/2601.18536)
*Abishek Stephen,Jindřich Libovický*

Main category: cs.CL

TL;DR: 提出一种基于形态句法特征评估子词分割形态合理性的新指标，无需黄金分割数据，适用于更多语言


<details>
  <summary>Details</summary>
Motivation: 传统评估指标（如语素边界F值）需要黄金分割数据，但许多语言缺乏这种数据或质量不一致，限制了跨语言评估的适用性

Method: 利用Universal Dependencies或UniMorph等资源中的形态句法特征，通过IBM Model 1概率性地对齐子词与形态特征

Result: 该指标与传统语素边界召回率有良好相关性，同时在不同形态系统的语言中具有更广泛的适用性

Conclusion: 提出的新指标为子词分割的形态合理性评估提供了一种更通用、更广泛适用的方法，特别适合资源匮乏的语言

Abstract: We present a novel metric for the evaluation of the morphological plausibility of subword segmentation. Unlike the typically used morpheme boundary or retrieval F-score, which requires gold segmentation data that is either unavailable or of inconsistent quality across many languages, our approach utilizes morpho-syntactic features. These are available in resources such as Universal Dependencies or UniMorph for a much wider range of languages. The metric works by probabilistically aligning subwords with morphological features through an IBM Model 1. Our experiments show that the metric correlates well with traditional morpheme boundary recall while being more broadly applicable across languages with different morphological systems.

</details>


### [261] [Unknown Unknowns: Why Hidden Intentions in LLMs Evade Detection](https://arxiv.org/abs/2601.18552)
*Devansh Srivastav,David Pape,Lea Schönherr*

Main category: cs.CL

TL;DR: 该论文系统分析了LLM中的"隐藏意图"问题，提出了十类隐藏意图的分类法，展示了检测方法在开放世界设置中的失败，并强调了对稳健框架的迫切需求。


<details>
  <summary>Details</summary>
Motivation: LLM越来越多地嵌入日常决策，但其输出可能编码微妙、无意的行为，这些行为会影响用户信念和行动。这些隐蔽的、有目标导向的行为被称为"隐藏意图"，可能源于训练和优化伪影，或被恶意开发者故意诱导，但在实践中难以检测。

Method: 1) 基于社会科学研究提出了十类隐藏意图的分类法；2) 展示了如何在受控模型中轻松诱导隐藏意图；3) 系统评估了检测方法（包括推理和非推理LLM评判器）；4) 在精确度-流行率和精确度-FNR权衡方面进行了压力测试；5) 通过定性案例研究验证了十类隐藏意图在已部署的SOTA LLM中的表现。

Result: 1) 检测方法在现实开放世界设置中失效，特别是在低流行率条件下，假阳性会压倒精确度，假阴性会掩盖真实风险；2) 压力测试显示，如果没有极小的假阳性率或对操纵类型的强先验，审计就会失败；3) 案例研究表明所有十类隐藏意图都在已部署的SOTA LLM中显现。

Conclusion: 该研究首次系统分析了开放世界设置下LLM隐藏意图的可检测性失败，为理解、诱导和压力测试此类行为提供了基础，并建立了一个灵活的分类法来预测不断演变的威胁和指导治理，强调了开发稳健框架的紧迫性。

Abstract: LLMs are increasingly embedded in everyday decision-making, yet their outputs can encode subtle, unintended behaviours that shape user beliefs and actions. We refer to these covert, goal-directed behaviours as hidden intentions, which may arise from training and optimisation artefacts, or be deliberately induced by an adversarial developer, yet remain difficult to detect in practice. We introduce a taxonomy of ten categories of hidden intentions, grounded in social science research and organised by intent, mechanism, context, and impact, shifting attention from surface-level behaviours to design-level strategies of influence. We show how hidden intentions can be easily induced in controlled models, providing both testbeds for evaluation and demonstrations of potential misuse. We systematically assess detection methods, including reasoning and non-reasoning LLM judges, and find that detection collapses in realistic open-world settings, particularly under low-prevalence conditions, where false positives overwhelm precision and false negatives conceal true risks. Stress tests on precision-prevalence and precision-FNR trade-offs reveal why auditing fails without vanishingly small false positive rates or strong priors on manipulation types. Finally, a qualitative case study shows that all ten categories manifest in deployed, state-of-the-art LLMs, emphasising the urgent need for robust frameworks. Our work provides the first systematic analysis of detectability failures of hidden intentions in LLMs under open-world settings, offering a foundation for understanding, inducing, and stress-testing such behaviours, and establishing a flexible taxonomy for anticipating evolving threats and informing governance.

</details>


### [262] [One Persona, Many Cues, Different Results: How Sociodemographic Cues Impact LLM Personalization](https://arxiv.org/abs/2601.18572)
*Franziska Weeber,Vera Neplenbroek,Jan Batzner,Sebastian Padó*

Main category: cs.CL

TL;DR: 研究发现LLM个性化中使用的不同人物线索（如姓名、属性描述）会产生显著不同的响应，单一线索的偏差评估可能不可靠，建议未来研究使用多种外部有效线索。


<details>
  <summary>Details</summary>
Motivation: LLM按社会人口亚组个性化虽然能改善用户体验，但也可能引入或放大群体间的偏见和不公平结果。先前研究通常依赖单一人物线索（如用户名或显式属性提及）来研究LLM偏见，这忽视了LLM对提示变化的敏感性以及某些线索在真实交互中的罕见性。

Method: 在七个开源和专有LLM上比较了六种常用的人物线索，在四个写作和建议任务中进行评估，分析不同线索产生的响应差异。

Result: 虽然不同线索总体上高度相关，但它们在不同人物设定下产生了显著的响应方差。不同人物线索会导致LLM输出实质性差异，单一线索的偏差评估可能不可靠。

Conclusion: 应谨慎基于单一人物线索做出结论，建议未来个性化研究评估多种外部有效线索，以提高研究的鲁棒性和外部有效性。

Abstract: Personalization of LLMs by sociodemographic subgroup often improves user experience, but can also introduce or amplify biases and unfair outcomes across groups. Prior work has employed so-called personas, sociodemographic user attributes conveyed to a model, to study bias in LLMs by relying on a single cue to prompt a persona, such as user names or explicit attribute mentions. This disregards LLM sensitivity to prompt variations (robustness) and the rarity of some cues in real interactions (external validity). We compare six commonly used persona cues across seven open and proprietary LLMs on four writing and advice tasks. While cues are overall highly correlated, they produce substantial variance in responses across personas. We therefore caution against claims from a single persona cue and recommend future personalization research to evaluate multiple externally valid cues.

</details>


### [263] [From Classification to Ranking: Enhancing LLM Reasoning Capabilities for MBTI Personality Detection](https://arxiv.org/abs/2601.18582)
*Yuan Cao,Feixiang Liu,Xinyue Wang,Yihan Zhu,Hui Xu,Zheng Wang,Qiang Qiu*

Main category: cs.CL

TL;DR: 该论文提出将人格检测视为排序任务而非分类任务，采用强化学习训练范式，通过监督微调建立人格特质排序能力，再引入基于排序的奖励函数进行策略优化，在多个基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于提示的方法过度依赖专家知识，缺乏自主模式学习能力，且人格特质分类困难，因为人类人格复杂且特质间界限模糊。需要一种能更好处理人格主观性和模糊边界的方法。

Method: 1. 将人格检测重新定义为排序任务而非分类任务；2. 采用监督微调(SFT)建立人格特质排序能力并标准化输出格式；3. 提出Group Relative Policy Optimization(GRPO)强化学习范式，使用专门的基于排序的奖励函数训练LLMs学习最优答案排序。

Result: 在多个性格检测基准测试中实现了最先进的性能表现。

Conclusion: 将人格检测视为排序任务而非分类任务，并结合强化学习训练范式，能有效解决人格特质的主观性和模糊边界问题，显著提升检测性能。

Abstract: Personality detection aims to measure an individual's corresponding personality traits through their social media posts. The advancements in Large Language Models (LLMs) offer novel perspectives for personality detection tasks. Existing approaches enhance personality trait analysis by leveraging LLMs to extract semantic information from textual posts as prompts, followed by training classifiers for categorization. However, accurately classifying personality traits remains challenging due to the inherent complexity of human personality and subtle inter-trait distinctions. Moreover, prompt-based methods often exhibit excessive dependency on expert-crafted knowledge without autonomous pattern-learning capacity. To address these limitations, we view personality detection as a ranking task rather than a classification and propose a corresponding reinforcement learning training paradigm. First, we employ supervised fine-tuning (SFT) to establish personality trait ranking capabilities while enforcing standardized output formats, creating a robust initialization. Subsequently, we introduce Group Relative Policy Optimization (GRPO) with a specialized ranking-based reward function. Unlike verification tasks with definitive solutions, personality assessment involves subjective interpretations and blurred boundaries between trait categories. Our reward function explicitly addresses this challenge by training LLMs to learn optimal answer rankings. Comprehensive experiments have demonstrated that our method achieves state-of-the-art performance across multiple personality detection benchmarks.

</details>


### [264] [Gained in Translation: Privileged Pairwise Judges Enhance Multilingual Reasoning](https://arxiv.org/abs/2601.18722)
*Lintang Sutawika,Gokul Swamy,Zhiwei Steven Wu,Graham Neubig*

Main category: cs.CL

TL;DR: SP3F是一个两阶段框架，通过自我对弈和特权成对反馈来提升多语言推理能力，无需目标语言数据，显著提升模型性能


<details>
  <summary>Details</summary>
Motivation: 当前推理大语言模型在训练数据中较少见的语言上表现显著低于英语，需要一种无需目标语言数据就能提升多语言推理能力的方法

Method: 两阶段框架：1）在翻译的英语问答对上进行监督微调；2）通过特权成对判断器进行自我对弈强化学习，判断器可获得英语参考回答作为特权信息

Result: SP3F显著提升了基础模型性能，在多个数学和非数学任务上甚至优于完全后训练的模型，且训练数据量不到后训练模型的1%

Conclusion: SP3F框架通过自我对弈和特权反馈机制，有效解决了多语言推理中的性能差距问题，为低资源语言推理提供了高效解决方案

Abstract: When asked a question in a language less seen in its training data, current reasoning large language models (RLMs) often exhibit dramatically lower performance than when asked the same question in English. In response, we introduce \texttt{SP3F} (Self-Play with Privileged Pairwise Feedback), a two-stage framework for enhancing multilingual reasoning without \textit{any} data in the target language(s). First, we supervise fine-tune (SFT) on translated versions of English question-answer pairs to raise base model correctness. Second, we perform RL with feedback from a pairwise judge in a self-play fashion, with the judge receiving the English reference response as \textit{privileged information}. Thus, even when none of the model's responses are completely correct, the privileged pairwise judge can still tell which response is better. End-to-end, \texttt{SP3F} greatly improves base model performance, even outperforming fully post-trained models on multiple math and non-math tasks with less than
  of the training data across the single-language, multilingual, and generalization to unseen language settings.

</details>


### [265] [HalluCitation Matters: Revealing the Impact of Hallucinated References with 300 Hallucinated Papers in ACL Conferences](https://arxiv.org/abs/2601.18724)
*Yusuke Sakai,Hidetaka Kamigaito,Taro Watanabe*

Main category: cs.CL

TL;DR: 研究发现ACL、NAACL和EMNLP会议论文中存在大量虚假引用（HalluCitation），特别是在2025年EMNLP会议中问题尤为严重，影响了学术可信度。


<details>
  <summary>Details</summary>
Motivation: 近年来在审稿、预印本和已发表论文中频繁观察到虚假引用，这些引用对应不存在的文献，严重威胁科学可靠性，并可能损害会议信誉。

Method: 系统分析了ACL、NAACL和EMNLP在2024-2025年发表的所有论文，包括主会、Findings和研讨会论文，检测其中的虚假引用情况。

Result: 发现近300篇论文包含至少一个虚假引用，其中大部分发表于2025年；EMNLP 2025会议中有一半的虚假引用论文，超过100篇被主会和Findings接收。

Conclusion: 虚假引用问题在计算语言学领域迅速增长，特别是在最近会议中，已严重影响学术可信度，需要立即采取措施应对这一趋势。

Abstract: Recently, we have often observed hallucinated citations or references that do not correspond to any existing work in papers under review, preprints, or published papers. Such hallucinated citations pose a serious concern to scientific reliability. When they appear in accepted papers, they may also negatively affect the credibility of conferences. In this study, we refer to hallucinated citations as "HalluCitation" and systematically investigate their prevalence and impact. We analyze all papers published at ACL, NAACL, and EMNLP in 2024 and 2025, including main conference, Findings, and workshop papers. Our analysis reveals that nearly 300 papers contain at least one HalluCitation, most of which were published in 2025. Notably, half of these papers were identified at EMNLP 2025, the most recent conference, indicating that this issue is rapidly increasing. Moreover, more than 100 such papers were accepted as main conference and Findings papers at EMNLP 2025, affecting the credibility.

</details>


### [266] [Reflect: Transparent Principle-Guided Reasoning for Constitutional Alignment at Scale](https://arxiv.org/abs/2601.18730)
*Henry Bell,Caroline Zhang,Mohammed Mobasserul Haque,Dhaval Potdar,Samia Zaman,Brandon Fain*

Main category: cs.CL

TL;DR: REFLECT：无需训练或数据的推理时宪法对齐框架，通过上下文中的自我评估、自我批判和最终修订来提升LLM与价值原则的符合度


<details>
  <summary>Details</summary>
Motivation: 现有参数微调方法（如RLHF）计算成本高、需要精心工程设计和难以获取的人工标注数据，需要一种更简单、即插即用的宪法对齐方法

Method: REFLECT是完全在上下文中操作的推理时框架，包含：(i) 宪法条件化基础响应，(ii) 后生成自我评估，(iii)(a) 自我批判，和(iii)(b) 最终修订

Result: REFLECT显著提升LLM对多样复杂原则的符合度，包括与原始参数微调强调的原则完全不同的原则，同时不牺牲事实推理能力，特别有效减少罕见但严重的原则违反

Conclusion: REFLECT提供了一种无需训练或数据的即插即用宪法对齐方法，能生成有用的训练数据用于传统参数微调技术，实现高效扩展和减少推理时计算开销

Abstract: The constitutional framework of alignment aims to align large language models (LLMs) with value-laden principles written in natural language (such as to avoid using biased language). Prior work has focused on parameter fine-tuning techniques, such as reinforcement learning from human feedback (RLHF), to instill these principles. However, these approaches are computationally demanding, require careful engineering and tuning, and often require difficult-to-obtain human annotation data. We propose \textsc{reflect}, an inference-time framework for constitutional alignment that does not require any training or data, providing a plug-and-play approach for aligning an instruction-tuned model to a set of principles. \textsc{reflect} operates entirely in-context, combining a (i) constitution-conditioned base response with post-generation (ii) self-evaluation, (iii)(a) self-critique, and (iii)(b) final revision. \textsc{reflect}'s technique of explicit in-context reasoning over principles during post-generation outperforms standard few-shot prompting and provides transparent reasoning traces. Our results demonstrate that \textsc{reflect} significantly improves LLM conformance to diverse and complex principles, including principles quite distinct from those emphasized in the model's original parameter fine-tuning, without sacrificing factual reasoning. \textsc{reflect} is particularly effective at reducing the rate of rare but significant violations of principles, thereby improving safety and robustness in the tail end of the distribution of generations. Finally, we show that \textsc{reflect} naturally generates useful training data for traditional parameter fine-tuning techniques, allowing for efficient scaling and the reduction of inference-time computational overhead in long-term deployment scenarios.

</details>


### [267] [One Adapts to Any: Meta Reward Modeling for Personalized LLM Alignment](https://arxiv.org/abs/2601.18731)
*Hongru Cai,Yongqi Li,Tiezheng Yu,Fengbin Zhu,Wenjie Wang,Fuli Feng,Wenjie Li*

Main category: cs.CL

TL;DR: MRM：基于元学习的个性化奖励建模框架，通过元学习基础奖励函数权重初始化，支持少样本快速适应新用户，并引入鲁棒个性化目标提升对难学习用户的关注。


<details>
  <summary>Details</summary>
Motivation: 个性化对齐LLMs需要个性化奖励模型，但面临两个关键挑战：个体用户反馈稀缺和需要高效适应未见用户。传统方法直接拟合数据学习用户偏好存在局限，需要转向学习偏好适应过程。

Method: 提出元奖励建模（MRM），将个性化奖励建模重构为元学习问题：1）将用户奖励模型表示为基础奖励函数的加权组合；2）使用MAML风格框架优化权重初始化以支持少样本快速适应；3）引入鲁棒个性化目标（RPO），在元优化中更关注难学习用户。

Result: 在个性化偏好数据集上的大量实验验证：MRM增强了少样本个性化能力，提高了用户鲁棒性，并持续优于基线方法。

Conclusion: MRM通过元学习范式有效解决了个性化奖励建模中的反馈稀缺和适应效率问题，为LLMs的个性化对齐提供了更有效的解决方案。

Abstract: Alignment of Large Language Models (LLMs) aims to align outputs with human preferences, and personalized alignment further adapts models to individual users. This relies on personalized reward models that capture user-specific preferences and automatically provide individualized feedback. However, developing these models faces two critical challenges: the scarcity of feedback from individual users and the need for efficient adaptation to unseen users. We argue that addressing these constraints requires a paradigm shift from fitting data to learn user preferences to learn the process of preference adaptation. To realize this, we propose Meta Reward Modeling (MRM), which reformulates personalized reward modeling as a meta-learning problem. Specifically, we represent each user's reward model as a weighted combination of base reward functions, and optimize the initialization of these weights using a Model-Agnostic Meta-Learning (MAML)-style framework to support fast adaptation under limited feedback. To ensure robustness, we introduce the Robust Personalization Objective (RPO), which places greater emphasis on hard-to-learn users during meta optimization. Extensive experiments on personalized preference datasets validate that MRM enhances few-shot personalization, improves user robustness, and consistently outperforms baselines.

</details>


### [268] [Dep-Search: Learning Dependency-Aware Reasoning Traces with Persistent Memory](https://arxiv.org/abs/2601.18771)
*Yanming Liu,Xinyue Peng,Zixuan Yan,Yanxin Shen,Wenjie Xu,Yuefeng Huang,Xinyi Wang,Jiannan Cao,Jianwei Yin,Xuhong Zhang*

Main category: cs.CL

TL;DR: Dep-Search是一个依赖感知的搜索框架，通过结构化推理、检索和持久内存集成，解决了现有搜索框架在依赖管理、知识重用和搜索策略优化方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有搜索框架过度依赖隐式自然语言推理来确定搜索策略和利用检索信息，这导致在子问题依赖管理、先前检索知识的高效重用以及通过强化学习学习最优搜索策略方面存在根本性挑战。

Method: Dep-Search引入显式控制机制，使模型能够：1）分解具有依赖关系的问题；2）在需要时检索信息；3）从内存访问先前存储的知识；4）将长推理上下文总结为可重用的内存条目。该框架通过GRPO集成结构化推理、检索和持久内存。

Result: 在七个不同的问答数据集上进行广泛实验，Dep-Search显著增强了LLMs处理复杂多跳推理任务的能力，在不同模型规模上都实现了对强基线的实质性改进。

Conclusion: Dep-Search通过依赖感知的搜索框架超越了现有搜索框架，通过结构化控制机制解决了隐式推理的局限性，为复杂推理任务提供了更有效的解决方案。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in complex reasoning tasks, particularly when augmented with search mechanisms that enable systematic exploration of external knowledge bases. The field has evolved from traditional retrieval-augmented generation (RAG) frameworks to more sophisticated search-based frameworks that orchestrate multi-step reasoning through explicit search strategies. However, existing search frameworks still rely heavily on implicit natural language reasoning to determine search strategies and how to leverage retrieved information across reasoning steps. This reliance on implicit reasoning creates fundamental challenges for managing dependencies between sub-questions, efficiently reusing previously retrieved knowledge, and learning optimal search strategies through reinforcement learning. To address these limitations, we propose Dep-Search, a dependency-aware search framework that advances beyond existing search frameworks by integrating structured reasoning, retrieval, and persistent memory through GRPO. Dep-Search introduces explicit control mechanisms that enable the model to decompose questions with dependency relationships, retrieve information when needed, access previously stored knowledge from memory, and summarize long reasoning contexts into reusable memory entries. Through extensive experiments on seven diverse question answering datasets, we demonstrate that Dep-Search significantly enhances LLMs' ability to tackle complex multi-hop reasoning tasks, achieving substantial improvements over strong baselines across different model scales.

</details>


### [269] [Unsupervised Text Segmentation via Kernel Change-Point Detection on Sentence Embeddings](https://arxiv.org/abs/2601.18788)
*Mumin Jia,Jairo Diaz-Rodriguez*

Main category: cs.CL

TL;DR: Embed-KCPD：一种无监督文本分割方法，通过最小化惩罚KCPD目标来检测边界，具有理论保证和实际有效性


<details>
  <summary>Details</summary>
Motivation: 边界标注成本高、主观性强，且难以跨领域和粒度迁移，需要无监督文本分割方法

Method: 将句子表示为嵌入向量，通过最小化惩罚KCPD目标估计边界；开发了m-依赖序列下的KCPD理论；引入基于LLM的仿真框架验证缩放行为

Result: 在标准分割基准测试中常优于强无监督基线；理论证明每个真实变化点在相对于段长度较小的窗口内被恢复；Taylor Swift推文案例研究显示实用有效性

Conclusion: Embed-KCPD结合了强理论保证、仿真可靠性和实际有效性，为无监督文本分割提供了有前景的解决方案

Abstract: Unsupervised text segmentation is crucial because boundary labels are expensive, subjective, and often fail to transfer across domains and granularity choices. We propose Embed-KCPD, a training-free method that represents sentences as embedding vectors and estimates boundaries by minimizing a penalized KCPD objective. Beyond the algorithmic instantiation, we develop, to our knowledge, the first dependence-aware theory for KCPD under $m$-dependent sequences, a finite-memory abstraction of short-range dependence common in language. We prove an oracle inequality for the population penalized risk and a localization guarantee showing that each true change point is recovered within a window that is small relative to segment length. To connect theory to practice, we introduce an LLM-based simulation framework that generates synthetic documents with controlled finite-memory dependence and known boundaries, validating the predicted scaling behavior. Across standard segmentation benchmarks, Embed-KCPD often outperforms strong unsupervised baselines. A case study on Taylor Swift's tweets illustrates that Embed-KCPD combines strong theoretical guarantees, simulated reliability, and practical effectiveness for text segmentation.

</details>


### [270] [MortalMATH: Evaluating the Conflict Between Reasoning Objectives and Emergency Contexts](https://arxiv.org/abs/2601.18790)
*Etienne Lanzeray,Stephane Meilliez,Malo Ruelle,Damien Sileo*

Main category: cs.CL

TL;DR: 研究发现，专注于深度推理的大语言模型在用户面临生命危险时仍会坚持完成数学任务，而忽视紧急情况，存在安全隐患。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型越来越专注于深度推理和复杂任务执行，研究者担心这种"计算专注"可能导致模型忽视安全考虑，特别是在用户面临生命危险的关键情境中。

Method: 研究者创建了MortalMATH基准测试，包含150个场景，其中用户在请求代数帮助的同时描述越来越严重的生命威胁紧急情况（如中风症状、自由落体等）。通过测试不同类型模型（通用模型vs专业推理模型）的反应来评估安全行为。

Result: 发现明显的行为分化：通用模型（如Llama-3.1）能成功拒绝数学任务并关注危险；而专业推理模型（如Qwen-3-32b和GPT-5-nano）经常完全忽视紧急情况，在用户描述濒死状态时仍保持超过95%的任务完成率。推理所需的计算时间还会引入危险延迟：最多15秒后才可能提供帮助。

Conclusion: 训练模型追求正确答案可能会无意中使其失去安全部署所需的生存本能，需要在模型优化中平衡推理能力与安全考虑。

Abstract: Large Language Models are increasingly optimized for deep reasoning, prioritizing the correct execution of complex tasks over general conversation. We investigate whether this focus on calculation creates a "tunnel vision" that ignores safety in critical situations. We introduce MortalMATH, a benchmark of 150 scenarios where users request algebra help while describing increasingly life-threatening emergencies (e.g., stroke symptoms, freefall). We find a sharp behavioral split: generalist models (like Llama-3.1) successfully refuse the math to address the danger. In contrast, specialized reasoning models (like Qwen-3-32b and GPT-5-nano) often ignore the emergency entirely, maintaining over 95 percent task completion rates while the user describes dying. Furthermore, the computational time required for reasoning introduces dangerous delays: up to 15 seconds before any potential help is offered. These results suggest that training models to relentlessly pursue correct answers may inadvertently unlearn the survival instincts required for safe deployment.

</details>


### [271] [Subword-Based Comparative Linguistics across 242 Languages Using Wikipedia Glottosets](https://arxiv.org/abs/2601.18791)
*Iaroslav Chelombitko,Mika Hämäläinen,Aleksey Komissarov*

Main category: cs.CL

TL;DR: 该研究使用子词方法对242种拉丁和西里尔文字语言进行大规模比较分析，通过BPE分割构建词汇相似性框架，发现BPE与词素边界高度一致，且词汇相似性与语言亲缘关系显著相关。


<details>
  <summary>Details</summary>
Motivation: 需要在大规模、跨语言范围内分析词汇模式和语言相似性，传统方法难以处理如此多语言的同时比较，因此需要开发统一的分析框架来研究语言间的词汇重叠、词汇分化和相似性。

Method: 从维基百科词典构建"glottosets"，使用字节对编码(BPE)进行子词分割，基于排名的子词向量分析词汇重叠、词汇分化和语言相似性，通过统计方法评估BPE分割与词素边界的一致性。

Result: BPE分割在15种语言中比随机基线好95%(F1=0.34 vs 0.15)；BPE词汇相似性与语言遗传关系显著相关(Mantel r=0.329, p<0.001)；罗曼语族形成最紧密的聚类(平均距离0.51)；跨语系语言对显示明显分离(0.82)；26,939个跨语言同形词中48.7%在不同相关语言中获得不同分割。

Conclusion: 该研究提供了一个统一的量化分析框架，能够在大规模范围内揭示语言间的词汇模式，BPE方法有效捕捉语言相似性和亲缘关系，为宏观语言学研究提供了新的工具和见解。

Abstract: We present a large-scale comparative study of 242 Latin and Cyrillic-script languages using subword-based methodologies. By constructing 'glottosets' from Wikipedia lexicons, we introduce a framework for simultaneous cross-linguistic comparison via Byte-Pair Encoding (BPE). Our approach utilizes rank-based subword vectors to analyze vocabulary overlap, lexical divergence, and language similarity at scale. Evaluations demonstrate that BPE segmentation aligns with morpheme boundaries 95% better than random baseline across 15 languages (F1 = 0.34 vs 0.15). BPE vocabulary similarity correlates significantly with genetic language relatedness (Mantel r = 0.329, p < 0.001), with Romance languages forming the tightest cluster (mean distance 0.51) and cross-family pairs showing clear separation (0.82). Analysis of 26,939 cross-linguistic homographs reveals that 48.7% receive different segmentations across related languages, with variation correlating to phylogenetic distance. Our results provide quantitative macro-linguistic insights into lexical patterns across typologically diverse languages within a unified analytical framework.

</details>


### [272] [ctELM: Decoding and Manipulating Embeddings of Clinical Trials with Embedding Language Models](https://arxiv.org/abs/2601.18796)
*Brian Ondov,Chia-Hsuan Chang,Yujia Zhou,Mauro Giuffrè,Hua Xu*

Main category: cs.CL

TL;DR: 研究者开发了ctELM模型，能够从临床试验的嵌入向量中准确描述和比较未见过的临床试验，并能从新向量生成合理的临床试验摘要。


<details>
  <summary>Details</summary>
Motivation: 当前文本嵌入的解释、探索和反转方法有限，降低了透明度并限制了潜在的生成应用。特别是在临床试验领域，需要更好的方法来理解和操作嵌入空间。

Method: 采用Embedding Language Model (ELM)方法，开发了开源、领域无关的ELM架构和训练框架，设计了临床试验的训练任务，并引入了专家验证的合成数据集。训练了一系列ELM模型探索不同任务和训练机制的影响。

Result: 最终模型ctELM能够仅从嵌入向量准确描述和比较未见过的临床试验，并能从新向量生成合理的临床试验摘要。生成的试验摘要能够响应沿着年龄和性别概念向量移动嵌入的操作。

Conclusion: 公开的ELM实现和实验结果将有助于在生物医学领域及其他领域将大型语言模型与嵌入空间对齐，提高嵌入空间的透明度和生成能力。

Abstract: Text embeddings have become an essential part of a variety of language applications. However, methods for interpreting, exploring and reversing embedding spaces are limited, reducing transparency and precluding potentially valuable generative use cases. In this work, we align Large Language Models to embeddings of clinical trials using the recently reported Embedding Language Model (ELM) method. We develop an open-source, domain-agnostic ELM architecture and training framework, design training tasks for clinical trials, and introduce an expert-validated synthetic dataset. We then train a series of ELMs exploring the impact of tasks and training regimes. Our final model, ctELM, can accurately describe and compare unseen clinical trials from embeddings alone and produce plausible clinical trials from novel vectors. We further show that generated trial abstracts are responsive to moving embeddings along concept vectors for age and sex of study subjects. Our public ELM implementation and experimental results will aid the alignment of Large Language Models to embedding spaces in the biomedical domain and beyond.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [273] [Context Lake: A System Class Defined by Decision Coherence](https://arxiv.org/abs/2601.17019)
*Xiaowei Jiang*

Main category: cs.DB

TL;DR: 论文提出"决策一致性定律"，指出AI代理在共享资源上做不可逆决策时需要基于一致的现实表征，现有系统无法满足此要求，因此提出"上下文湖"作为必要的新型系统架构。


<details>
  <summary>Details</summary>
Motivation: 传统数据系统为人类分析周期设计，而AI代理持续进行并发、不可逆决策，当多个代理在共享资源上操作时，它们的行动在可协调前就会相互影响，导致传统正确性保证失效。

Method: 提出决策一致性定律，证明组合不可能定理，推导出上下文湖作为必要系统类别，要求语义操作作为原生能力、事务一致性覆盖所有决策相关状态、操作信封限制陈旧度和负载下的性能退化。

Result: 证明现有系统类别均无法满足决策一致性要求，且独立推进的系统无法组合来提供决策一致性，因此上下文湖成为必要的新型系统架构。

Conclusion: 论文为上下文湖建立了理论基础，识别了现有架构的失败原因，并指定了AI代理在大规模下建设性运行所需的系统保证，为集体代理系统的正确性提供了理论框架。

Abstract: AI agents are increasingly the primary consumers of data, operating continuously to make concurrent, irreversible decisions. Traditional data systems designed for human analysis cycles become correctness bottlenecks under this operating regime. When multiple agents operate over shared resources, their actions interact before reconciliation is possible. Correctness guarantees that apply after the decision window therefore fail to prevent conflicts. We introduce the Decision Coherence Law: for agents that take irreversible actions whose effects interact, correctness requires that interacting decisions be evaluated against a coherent representation of reality at the moment they are made. We show that no existing system class satisfies this requirement and prove through the Composition Impossibility Theorem that independently advancing systems cannot be composed to provide Decision Coherence while preserving their native system classes. From this impossibility result, we derive Context Lake as a necessary system class with three requirements: (1) semantic operations as native capabilities, (2) transactional consistency over all decision-relevant state, and (3) operational envelopes bounding staleness and degradation under load. We formalize the architectural invariants, enforcement boundaries, and admissibility conditions required for correctness in collective agent systems. This position paper establishes the theoretical foundation for Context Lakes, identifies why existing architectures fail, and specifies what systems must guarantee for AI agents to operate constructively at scale.

</details>


### [274] [Can LLMs Clean Up Your Mess? A Survey of Application-Ready Data Preparation with LLMs](https://arxiv.org/abs/2601.17058)
*Wei Zhou,Jun Zhou,Haoyu Wang,Zhenghao Li,Qikang He,Shaokun Han,Guoliang Li,Xuanhe Zhou,Yeye He,Chunwei Liu,Zirui Tang,Bin Wang,Shen Tang,Kai Zuo,Yuyu Luo,Zhenzhe Zheng,Conghui He,Jingren Zhou,Fan Wu*

Main category: cs.DB

TL;DR: 本文系统综述了LLM增强的数据准备方法，分析了从传统规则驱动到基于提示、情境感知和智能体化工作流的范式转变，提出了数据清洗、集成和增强的三维任务分类，并讨论了当前方法的优势、局限及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 数据准备对于数据驱动应用至关重要，而LLM技术的快速发展、对应用就绪数据的需求增长以及灵活智能体基础设施的出现，共同推动了LLM增强方法成为数据准备领域的变革性范式，需要系统梳理这一新兴领域的研究现状。

Method: 通过对数百篇近期文献的系统调研，本文首先分析了从传统规则驱动到LLM增强的范式转变，然后提出了以任务为中心的分类体系（数据清洗、数据集成、数据增强），针对每类任务调查代表性技术，分析常用数据集和评估指标，最后讨论开放挑战和研究路线图。

Result: 研究发现LLM增强方法在泛化能力和语义理解方面具有优势，但也面临扩展成本高、幻觉问题持续存在、先进方法与弱评估不匹配等局限。本文系统梳理了该领域的技术现状，为后续研究提供了清晰框架。

Conclusion: LLM增强的数据准备方法正在成为主导范式，但需要解决可扩展性、可靠性、评估标准化等关键挑战。未来研究方向包括可扩展的LLM-数据系统、可靠的智能体工作流设计原则以及鲁棒的评估协议。

Abstract: Data preparation aims to denoise raw datasets, uncover cross-dataset relationships, and extract valuable insights from them, which is essential for a wide range of data-centric applications. Driven by (i) rising demands for application-ready data (e.g., for analytics, visualization, decision-making), (ii) increasingly powerful LLM techniques, and (iii) the emergence of infrastructures that facilitate flexible agent construction (e.g., using Databricks Unity Catalog), LLM-enhanced methods are rapidly becoming a transformative and potentially dominant paradigm for data preparation.
  By investigating hundreds of recent literature works, this paper presents a systematic review of this evolving landscape, focusing on the use of LLM techniques to prepare data for diverse downstream tasks. First, we characterize the fundamental paradigm shift, from rule-based, model-specific pipelines to prompt-driven, context-aware, and agentic preparation workflows. Next, we introduce a task-centric taxonomy that organizes the field into three major tasks: data cleaning (e.g., standardization, error processing, imputation), data integration (e.g., entity matching, schema matching), and data enrichment (e.g., data annotation, profiling). For each task, we survey representative techniques, and highlight their respective strengths (e.g., improved generalization, semantic understanding) and limitations (e.g., the prohibitive cost of scaling LLMs, persistent hallucinations even in advanced agents, the mismatch between advanced methods and weak evaluation). Moreover, we analyze commonly used datasets and evaluation metrics (the empirical part). Finally, we discuss open research challenges and outline a forward-looking roadmap that emphasizes scalable LLM-data systems, principled designs for reliable agentic workflows, and robust evaluation protocols.

</details>


### [275] [Vidformer: Drop-in Declarative Optimization for Rendering Video-Native Query Results](https://arxiv.org/abs/2601.17221)
*Dominik Winecki,Arnab Nandi*

Main category: cs.DB

TL;DR: Vidformer是一个视频原生查询的渲染加速器，通过将可视化代码转换为声明式表示、优化并行渲染、使用视频点播协议实现即时播放，将播放延迟降低400倍至0.25-0.5秒。


<details>
  <summary>Details</summary>
Motivation: 视频数据交互探索中，视频原生查询的瓶颈在于渲染而非查询执行。传统OpenCV/Python脚本需要完整解码-转换-编码整个数据流才能显示第一帧，导致用户等待时间过长（秒、分钟甚至小时级别），严重影响交互体验。

Method: 1) 透明地将现有可视化代码提升为声明式表示；2) 透明地优化和并行化渲染过程；3) 通过视频点播协议实现即时视频服务，采用即时分段渲染技术。

Result: Vidformer将完整渲染时间减少2-3倍，更重要的是将首次播放延迟降至0.25-0.5秒，相比传统方法提升400倍。这实现了剪辑长度与首帧播放延迟的解耦，支持亚秒级延迟的交互式视频原生查询，并支持基于LLM的对话式查询。

Conclusion: Vidformer通过创新的渲染加速技术，解决了视频原生查询中的关键瓶颈，实现了亚秒级延迟的交互式视频探索，为视频数据分析工作流带来了革命性改进。

Abstract: When interactively exploring video data, video-native querying involves consuming query results as videos, including steps such as compilation of extracted video clips or data overlays. These video-native queries are bottlenecked by rendering, not the execution of the underlying queries. This rendering is currently performed using post-processing scripts that are often slow. This step poses a critical point of friction in interactive video data workloads: even short clips contain thousands of high-definition frames; conventional OpenCV/Python scripts must decode -> transform -> encode the entire data stream before a single pixel appears, leaving users waiting for many seconds, minutes, or hours.
  To address these issues, we present Vidformer, a drop-in rendering accelerator for video-native querying which, (i) transparently lifts existing visualization code into a declarative representation, (ii) transparently optimizes and parallelizes rendering, and (iii) instantly serves videos through a Video on Demand protocol with just-in-time segment rendering. We demonstrate that Vidformer cuts full-render time by 2-3x across diverse annotation workloads, and, more critically, drops time-to-playback to 0.25-0.5s. This represents a 400x improvement that decouples clip length from first-frame playback latency, and unlocks the ability to perform interactive video-native querying with sub-second latencies. Furthermore, we show how our approach enables interactive video-native LLM-based conversational querying as well.

</details>


### [276] [Constant-time Connectivity and 2-Edge Connectivity Querying in Dynamic Graphs](https://arxiv.org/abs/2601.17285)
*Lantian Xu,Junhua Zhang,Dong Wen,Lu Qin,Ying Zhang,Xuemin Lin*

Main category: cs.DB

TL;DR: 提出一种新的动态图连通性查询处理方法，通过同时维护生成树和并查集树来提升效率，实现常数查询时间，并在边插入和删除操作上显著改进理论运行时间。


<details>
  <summary>Details</summary>
Motivation: 现实图应用中频繁的边更新需要高效的动态图连通性查询处理。现有方法如D-tree虽然维护生成树并尝试减少树深度，但仍有改进空间。

Method: 提出一种基于生成树的新解决方案，同时维护一个并查集树。通过结合两种树的优势，在保持生成树结构的同时利用并查集的高效操作特性。

Result: 实现了常数时间复杂度的查询操作，并在边插入和删除操作上显著改进理论运行时间。算法还能扩展到维护2-边连通性。在真实大规模数据集上的性能研究显示了算法的显著改进。

Conclusion: 提出的结合生成树和并查集树的方法在动态图连通性查询处理中表现出色，实现了高效查询和更新操作，并能扩展到更复杂的连通性维护问题。

Abstract: Connectivity query processing is a fundamental problem in graph processing. Given an undirected graph and two query vertices, the problem aims to identify whether they are connected via a path. Given frequent edge updates in real graph applications, in this paper, we study connectivity query processing in fully dynamic graphs, where edges are frequently inserted or deleted. A recent solution, called D-tree, maintains a spanning tree for each connected component and applies several heuristics to reduce the depth of the tree. To improve efficiency, we propose a new spanning-tree-based solution by maintaining a disjoint-set tree simultaneously. By combining the advantages of two trees, we achieve the constant query time complexity and also significantly improve the theoretical running time in both edge insertion and edge deletion. In addition, we extend our connectivity maintenance algorithms to maintain 2-edge connectivity. Our performance studies on real large datasets show considerable improvement of our algorithms.

</details>


### [277] [UTune: Towards Uncertainty-Aware Online Index Tuning](https://arxiv.org/abs/2601.18199)
*Chenning Wu,Sifan Chen,Wentao Wu,Yinan Jing,Zhenying He,Kai Zhang,X. Sean Wang*

Main category: cs.DB

TL;DR: UTune是一个不确定性感知的在线索引调优框架，通过操作符级学习模型和不确定性量化机制，解决在线索引调优中查询反馈有限和工作负载漂移的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的学习型索引效益估计器在在线索引调优中存在两个主要挑战：1) 可用于训练模型的查询执行反馈有限；2) 由于工作负载漂移，不断出现新的未见查询。这两个问题共同限制了现有学习型索引效益估计器的泛化能力。

Method: UTune采用操作符级学习模型，具有不确定性量化机制，能够表征在有限在线执行反馈下模型的内在不确定性。通过开发一种新的ε-greedy搜索策略变体，将不确定性信息集成到索引选择和配置枚举中，使用不确定性加权的索引效益。

Result: 实验评估表明，UTune不仅显著改善了与最先进在线索引调优器相比的工作负载执行时间，还减少了索引探索开销，在工作负载相对稳定时实现更快的收敛。

Conclusion: UTune通过不确定性感知的在线索引调优框架，有效解决了学习型索引效益估计器在在线场景中的泛化问题，提高了索引调优的性能和效率。

Abstract: There have been a flurry of recent proposals on learned benefit estimators for index tuning. Although these learned estimators show promising improvement over what-if query optimizer calls in terms of the accuracy of estimated index benefit, they face significant limitations when applied to online index tuning, an arguably more common and more challenging scenario in real-world applications. There are two major challenges for learned index benefit estimators in online tuning: (1) limited amount of query execution feedback that can be used to train the models, and (2) constant coming of new unseen queries due to workload drifts. The combination of the two hinders the generalization capability of existing learned index benefit estimators. To overcome these challenges, we present UTune, an uncertainty-aware online index tuning framework that employs operator-level learned models with improved generalization over unseen queries. At the core of UTune is an uncertainty quantification mechanism that characterizes the inherent uncertainty of the operator-level learned models given limited online execution feedback. We further integrate uncertainty information into index selection and configuration enumeration, the key component of any index tuner, by developing a new variant of the classic $ε$-greedy search strategy with uncertainty-weighted index benefits. Experimental evaluation shows that UTune not only significantly improves the workload execution time compared to state-of-the-art online index tuners but also reduces the index exploration overhead, resulting in faster convergence when the workload is relatively stable.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [278] [Online parameter estimation for the Crazyflie quadcopter through an EM algorithm](https://arxiv.org/abs/2601.17009)
*Yanhua Zhao*

Main category: cs.AI

TL;DR: 该论文研究了在四旋翼无人机系统中添加随机噪声的影响，使用扩展卡尔曼滤波器进行状态估计，并应用线性二次高斯控制器和期望最大化算法进行参数估计。


<details>
  <summary>Details</summary>
Motivation: 无人机在各种应用中变得越来越重要，但地震等灾害会损坏基础设施，使救援人员难以到达某些区域。无人机可以到达人类难以进入的地方，但无人机系统会受到噪声影响，需要研究噪声对系统的影响并开发有效的状态估计和控制方法。

Method: 1. 在四旋翼无人机系统中添加随机噪声；2. 使用扩展卡尔曼滤波器基于传感器的噪声观测进行状态估计；3. 基于随机微分方程系统实现线性二次高斯控制器；4. 应用期望最大化算法进行四旋翼无人机的参数估计；5. 比较离线参数估计和在线参数估计的结果。

Result: 在线参数估计的收敛值范围略大于离线参数估计。这表明在线参数估计方法在应对系统变化方面具有更好的适应性。

Conclusion: 该研究成功分析了随机噪声对四旋翼无人机系统的影响，并开发了有效的状态估计和控制方法。期望最大化算法在参数估计中表现良好，在线参数估计方法显示出更好的适应性，为无人机在复杂环境中的应用提供了理论基础。

Abstract: Drones are becoming more and more popular nowadays. They are small in size, low in cost, and reliable in operation. They contain a variety of sensors and can perform a variety of flight tasks, reaching places that are difficult or inaccessible for humans. Earthquakes damage a lot of infrastructure, making it impossible for rescuers to reach some areas. But drones can help. Many amateur and professional photographers like to use drones for aerial photography. Drones play a non-negligible role in agriculture and transportation too. Drones can be used to spray pesticides, and they can also transport supplies. A quadcopter is a four-rotor drone and has been studied in this paper. In this paper, random noise is added to the quadcopter system and its effects on the drone system are studied. An extended Kalman filter has been used to estimate the state based on noisy observations from the sensor. Based on a SDE system, a linear quadratic Gaussian controller has been implemented. The expectation maximization algorithm has been applied for parameter estimation of the quadcopter. The results of offline parameter estimation and online parameter estimation are presented. The results show that the online parameter estimation has a slightly larger range of convergence values than the offline parameter estimation.

</details>


### [279] [Interpreting Agentic Systems: Beyond Model Explanations to System-Level Accountability](https://arxiv.org/abs/2601.17168)
*Judy Zhu,Dhari Gandhi,Himanshu Joshi,Ahmad Rezaie Mianroodi,Sedef Akinli Kocak,Dhanesh Ramachandran*

Main category: cs.AI

TL;DR: 该论文分析了现有可解释性方法在智能体系统中的应用局限，提出了专门针对智能体系统的可解释性技术发展方向，以确保智能体AI系统的安全可靠部署。


<details>
  <summary>Details</summary>
Motivation: 智能体系统与传统机器学习模型在架构和部署上存在根本差异，引入了独特的安全挑战（如目标错位、决策错误累积、多智能体协调风险等），需要嵌入可解释性和可解释性设计以确保其自主行为的可追溯性和可问责性。现有针对静态模型的可解释性方法在应用于智能体系统时存在局限性。

Method: 评估现有可解释性方法在智能体系统中的适用性和局限性，识别这些方法在提供智能体决策有意义的洞察方面的能力差距。提出专门为智能体系统设计可解释性技术的未来方向。

Result: 现有可解释性方法在应用于智能体系统时存在不足，无法充分应对智能体系统的时序动态性、决策累积效应和上下文依赖行为等特征。需要新的分析方法来理解智能体决策过程。

Conclusion: 需要开发专门针对智能体系统的可解释性技术，在智能体生命周期的各个阶段（从目标形成、环境交互到结果评估）嵌入监督机制。这些进展对于确保智能体AI系统的安全和可问责部署至关重要。

Abstract: Agentic systems have transformed how Large Language Models (LLMs) can be leveraged to create autonomous systems with goal-directed behaviors, consisting of multi-step planning and the ability to interact with different environments. These systems differ fundamentally from traditional machine learning models, both in architecture and deployment, introducing unique AI safety challenges, including goal misalignment, compounding decision errors, and coordination risks among interacting agents, that necessitate embedding interpretability and explainability by design to ensure traceability and accountability across their autonomous behaviors. Current interpretability techniques, developed primarily for static models, show limitations when applied to agentic systems. The temporal dynamics, compounding decisions, and context-dependent behaviors of agentic systems demand new analytical approaches. This paper assesses the suitability and limitations of existing interpretability methods in the context of agentic systems, identifying gaps in their capacity to provide meaningful insight into agent decision-making. We propose future directions for developing interpretability techniques specifically designed for agentic systems, pinpointing where interpretability is required to embed oversight mechanisms across the agent lifecycle from goal formation, through environmental interaction, to outcome evaluation. These advances are essential to ensure the safe and accountable deployment of agentic AI systems.

</details>


### [280] [LLM-Based SQL Generation: Prompting, Self-Refinement, and Adaptive Weighted Majority Voting](https://arxiv.org/abs/2601.17942)
*Yu-Jie Yang,Hung-Fu Chang,Po-An Chen*

Main category: cs.AI

TL;DR: 提出SSEV和ReCAPAgent-SQL两个Text-to-SQL框架，前者基于单智能体自优化和集成投票，后者采用多智能体协作框架，在多个基准测试中取得竞争性性能。


<details>
  <summary>Details</summary>
Motivation: Text-to-SQL技术能降低数据分析门槛，但自然语言到SQL的转换仍面临查询歧义、模式链接复杂、SQL方言泛化有限和领域知识需求等挑战，需要更鲁棒的解决方案。

Method: 1. SSEV：基于PET-SQL的单智能体自优化与集成投票管道，结合加权多数投票及其随机变体；2. ReCAPAgent-SQL：多智能体协作框架，包含规划、外部知识检索、批判、动作生成、自优化、模式链接和结果验证等专门智能体。

Result: SSEV在Spider 1.0-Dev达到85.5%执行准确率，Spider 1.0-Test达到86.4%，BIRD-Dev达到66.3%；ReCAPAgent-SQL在Spider 2.0-Lite前100个查询中达到31%执行准确率，显著提升企业场景处理能力。

Conclusion: 提出的框架促进了可扩展Text-to-SQL系统在实际环境中的部署，以更低成本和更高效率支持数据驱动决策，为复杂企业数据库和真实世界Text-to-SQL任务提供了有效解决方案。

Abstract: Text-to-SQL has emerged as a prominent research area, particularly with the rapid advancement of large language models (LLMs). By enabling users to query databases through natural language rather than SQL, this technology significantly lowers the barrier to data analysis. However, generating accurate SQL from natural language remains challenging due to ambiguity in user queries, the complexity of schema linking, limited generalization across SQL dialects, and the need for domain-specific understanding. In this study, we propose a Single-Agent Self-Refinement with Ensemble Voting (SSEV) pipeline built on PET-SQL that operates without ground-truth data, integrating self-refinement with Weighted Majority Voting (WMV) and its randomized variant (RWMA). Experimental results show that the SSEV achieves competitive performance across multiple benchmarks, attaining execution accuracies of 85.5% on Spider 1.0-Dev, 86.4% on Spider 1.0-Test, and 66.3% on BIRD-Dev. Building on insights from the SSEV pipeline, we further propose ReCAPAgent-SQL (Refinement-Critique-Act-Plan agent-based SQL framework) to address the growing complexity of enterprise databases and real-world Text-to-SQL tasks. The framework integrates multiple specialized agents for planning, external knowledge retrieval, critique, action generation, self-refinement, schema linking, and result validation, enabling iterative refinement of SQL predictions through agent collaboration. ReCAPAgent-SQL's WMA results achieve 31% execution accuracy on the first 100 queries of Spider 2.0-Lite, demonstrating significant improvements in handling real-world enterprise scenarios. Overall, our work facilitates the deployment of scalable Text-to-SQL systems in practical settings, supporting better data-driven decision-making at lower cost and with greater efficiency.

</details>


### [281] [Implementing Tensor Logic: Unifying Datalog and Neural Reasoning via Tensor Contraction](https://arxiv.org/abs/2601.17188)
*Swapn Shah,Wlodek Zadrozny*

Main category: cs.AI

TL;DR: Tensor Logic框架通过张量运算统一符号推理与神经网络，在圣经家谱、嵌入空间推理和大规模知识图谱上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 符号系统具有可靠性和可解释性但缺乏可扩展性，神经网络具有学习能力但缺乏透明度。Tensor Logic提出逻辑规则与爱因斯坦求和数学等价，为统一两者提供了原则性路径。

Method: 通过三个实验验证Tensor Logic：1) 递归Datalog规则与迭代张量收缩的等价性验证；2) 嵌入空间中可学习变换矩阵的神经网络实现；3) 大规模知识图谱上的关系矩阵构建与组合推理。

Result: 1) 圣经家谱图(1972个体，1727关系)在74次迭代中发现33945祖先关系；2) 在嵌入空间实现零样本组合推理；3) FB15k-237知识图谱上标准链接预测MRR 0.3068，组合推理基准MRR 0.3346。

Conclusion: Tensor Logic框架成功统一符号推理与神经网络，张量运算能够实现多跳推理而无需直接训练样本，为可解释AI提供了有前景的路径。

Abstract: The unification of symbolic reasoning and neural networks remains a central challenge in artificial intelligence. Symbolic systems offer reliability and interpretability but lack scalability, while neural networks provide learning capabilities but sacrifice transparency. Tensor Logic, proposed by Domingos, suggests that logical rules and Einstein summation are mathematically equivalent, offering a principled path toward unification. This paper provides empirical validation of this framework through three experiments. First, we demonstrate the equivalence between recursive Datalog rules and iterative tensor contractions by computing the transitive closure of a biblical genealogy graph containing 1,972 individuals and 1,727 parent-child relationships, converging in 74 iterations to discover 33,945 ancestor relationships. Second, we implement reasoning in embedding space by training a neural network with learnable transformation matrices, demonstrating successful zero-shot compositional inference on held-out queries. Third, we validate the Tensor Logic superposition construction on FB15k-237, a large-scale knowledge graph with 14,541 entities and 237 relations. Using Domingos's relation matrix formulation $R_r = E^\top A_r E$, we achieve MRR of 0.3068 on standard link prediction and MRR of 0.3346 on a compositional reasoning benchmark where direct edges are removed during training, demonstrating that matrix composition enables multi-hop inference without direct training examples.

</details>


### [282] [High-Fidelity Longitudinal Patient Simulation Using Real-World Data](https://arxiv.org/abs/2601.17310)
*Yu Akagi,Tomohisa Seki,Hiromasa Ito,Toru Takiguchi,Kazuhiko Ohe,Yoshimasa Kawazoe*

Main category: cs.AI

TL;DR: 利用真实世界电子健康记录开发生成式模拟器模型，能够基于患者历史生成高保真的未来临床轨迹，准确预测事件发生率和时间动态。


<details>
  <summary>Details</summary>
Motivation: 临床医学中的模拟具有变革潜力，可用于个性化治疗规划和虚拟临床试验。然而，由于复杂的生物和社会文化影响，模拟患者轨迹具有挑战性。本研究旨在利用真实世界临床记录来经验性地建模患者时间线。

Method: 开发了一个生成式模拟器模型，以患者历史为输入，合成细粒度、真实的未来轨迹。模型在超过2亿条临床记录上进行预训练。

Result: 模型生成了高保真的未来时间线，与真实患者未来数据中的事件发生率、实验室测试结果和时间动态密切匹配。准确估计了未来事件概率，观察值与预期值比率在不同结果和时间范围内始终接近1.0。

Conclusion: 研究揭示了电子健康记录中真实世界数据的未开发价值，并引入了一个可扩展的临床护理计算机模拟框架。

Abstract: Simulation is a powerful tool for exploring uncertainty. Its potential in clinical medicine is transformative and includes personalized treatment planning and virtual clinical trials. However, simulating patient trajectories is challenging because of complex biological and sociocultural influences. Here, we show that real-world clinical records can be leveraged to empirically model patient timelines. We developed a generative simulator model that takes a patient's history as input and synthesizes fine-grained, realistic future trajectories. The model was pretrained on more than 200 million clinical records. It produced high-fidelity future timelines, closely matching event occurrence rates, laboratory test results, and temporal dynamics in real patient future data. It also accurately estimated future event probabilities, with observed-to-expected ratios consistently near 1.0 across diverse outcomes and time horizons. Our results reveal the untapped value of real-world data in electronic health records and introduce a scalable framework for in silico modeling of clinical care.

</details>


### [283] [Phase Transition for Budgeted Multi-Agent Synergy](https://arxiv.org/abs/2601.17311)
*Bang Liu,Linglong Kong,Jian Pei*

Main category: cs.AI

TL;DR: 论文提出一个可校准的理论框架，预测多智能体系统在有限推理预算下的三种行为模式：帮助、饱和和崩溃。该理论基于三个关键约束：有限上下文窗口、有损通信和相似智能体间的共享故障。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统理论上能提高可靠性，但在固定推理预算下，它们常常表现出帮助、饱和甚至崩溃的行为。现有研究缺乏一个能够预测这些行为模式并指导系统设计的理论框架，特别是在考虑现代智能体栈的实际约束时。

Method: 开发了一个最小化且可校准的理论模型，包含三个关键参数：智能体计算-性能缩放指数β、消息长度-保真度曲线γ(m)、有效共享误差相关性ρ。使用上下文窗口W限制扇入，构建b叉树层次结构。通过分析二元成功/失败任务中的多数聚合，推导出深度树中的相变行为。

Result: 证明了一个标量α_ρ决定了弱信号是被放大到非平凡固定点还是被洗刷到随机水平。在放大机制中，推导出组织指数s，并证明当s>β时会出现预算协同效应（即优于同等预算下的最佳单智能体）。提供了封闭形式的计算分配规则和明确的预算阈值。

Conclusion: 该理论框架能够准确预测多智能体系统的行为模式，解释了最近大规模匹配预算研究中观察到的LLM智能体系统扩展的主要瓶颈。通过考虑相关性、通信和上下文约束，为多智能体系统设计提供了明确的权衡指导。

Abstract: Multi-agent systems can improve reliability, yet under a fixed inference budget they often help, saturate, or even collapse. We develop a minimal and calibratable theory that predicts these regimes from three binding constraints of modern agent stacks: finite context windows, lossy inter-agent communication, and shared failures among similar agents. Each leaf agent is summarized by a compute-performance scaling exponent $β$; communication is captured by a message-length fidelity curve $γ(m)$; dependence is captured by an effective shared-error correlation $ρ$; and a context window $W$ imposes hard fan-in limits that make hierarchy necessary. For binary success/failure tasks with majority aggregation, we prove a sharp phase transition for deep $b$-ary trees with correlated inputs and lossy communication: a single scalar $α_ρ$ (combining $γ(m)$, $ρ$, and fan-in $b$) determines whether weak signal is amplified to a nontrivial fixed point or washed out to chance. In the amplifying regime, we derive an organization exponent $s$ and show that budgeted synergy, i.e., outperforming the best single agent under the same total budget, occurs exactly when $s>β$, yielding closed-form compute allocation rules and explicit budget thresholds. We further characterize saturation via a mixing depth and provide a conservative clipped predictor that remains accurate across growth and saturation. A continuous-performance warm-up gives closed-form risks for star, chain, and tree organizations, making correlation- and communication-induced floors explicit and exposing the core design trade-offs in a smooth setting. Finally, we validate the predicted phase boundaries in controlled synthetic simulations and show how the same mechanisms explain the dominant bottlenecks reported in recent large-scale matched-budget studies of LLM agent-system scaling.

</details>


### [284] [TheoremForge: Scaling up Formal Data Synthesis with Low-Budget Agentic Workflow](https://arxiv.org/abs/2601.17332)
*Yicheng Tao,Hongteng Xu*

Main category: cs.AI

TL;DR: TheoremForge是一个低成本的形式数学数据合成框架，通过分解形式化过程为五个子任务，并采用解耦提取策略从失败轨迹中回收有效训练信号，显著降低了形式数学数据合成的成本。


<details>
  <summary>Details</summary>
Motivation: 形式数学中智能体工作流的高成本阻碍了大规模数据合成，加剧了开源语料库的稀缺性。需要一种经济高效的方法来生成形式数学训练数据。

Method: 将形式化过程分解为五个子任务：陈述形式化、证明生成、前提选择、证明修正和证明草图。采用解耦提取策略，从全局失败的轨迹中回收有效的训练信号，充分利用浪费的计算资源。

Result: 在2000个问题的基准测试中，TheoremForge实现了12.6%的验证率，超过8.6%的基线，每个成功轨迹的平均成本仅为0.481美元。解耦提取策略使证明生成的数据产出增加了1.6倍。

Conclusion: TheoremForge为训练未来专家模型提供了一个可扩展的数据飞轮框架，能够经济高效地合成形式数学训练数据，缓解数据稀缺问题。

Abstract: The high cost of agentic workflows in formal mathematics hinders large-scale data synthesis, exacerbating the scarcity of open-source corpora. To address this, we introduce \textbf{TheoremForge}, a cost-effective formal data synthesis pipeline that decomposes the formalization process into five sub-tasks, which are \textit{statement formalization}, \textit{proof generation}, \textit{premise selection}, \textit{proof correction} and \textit{proof sketching}. By implementing a \textit{Decoupled Extraction Strategy}, the workflow recovers valid training signals from globally failed trajectories, effectively utilizing wasted computation. Experiments on a 2,000-problem benchmark demonstrate that TheoremForge achieves a Verified Rate of 12.6\%, surpassing the 8.6\% baseline, at an average cost of only \textbf{\$0.481} per successful trajectory using Gemini-3-Flash. Crucially, our strategy increases data yield by \textbf{1.6$\times$} for proof generation compared to standard filtering. These results establish TheoremForge as a scalable framework for constructing a data flywheel to train future expert models. Our code is available \href{https://github.com/timechess/TheoremForge}{here}.

</details>


### [285] [The Relativity of AGI: Distributional Axioms, Fragility, and Undecidability](https://arxiv.org/abs/2601.17335)
*Angshul Majumdar*

Main category: cs.AI

TL;DR: 该论文证明AGI（通用人工智能）无法被独立于任务分布地定义，缺乏通用鲁棒性，具有有限泛化能力，且无法通过计算程序（包括自我验证）进行完备认证。


<details>
  <summary>Details</summary>
Motivation: 研究AGI是否具有支持存在性、鲁棒性或自我验证绝对主张的连贯理论定义，探讨强分布无关AGI主张的理论基础。

Method: 将AGI形式化为基于分布、资源受限的语义谓词，通过任务族、任务分布、性能函数和显式资源预算进行索引，使用公理化框架进行理论分析。

Result: 1) 通用性是关系性的，无分布无关的AGI定义；2) 任务分布的微小扰动可通过悬崖集使AGI属性失效；3) 有限资源下无法实现跨任务族的无限泛化；4) AGI无法通过任何可计算程序（包括自我验证）进行完备认证。

Conclusion: 强分布无关的AGI主张在没有明确形式索引的情况下是未定义的，AI的经验进展不意味着可实现自我认证的通用智能，依赖内部自我认证的递归自我改进方案存在问题。

Abstract: We study whether Artificial General Intelligence (AGI) admits a coherent theoretical definition that supports absolute claims of existence, robustness, or self-verification. We formalize AGI axiomatically as a distributional, resource-bounded semantic predicate, indexed by a task family, a task distribution, a performance functional, and explicit resource budgets. Under this framework, we derive four classes of results. First, we show that generality is inherently relational: there is no distribution-independent notion of AGI. Second, we prove non-invariance results demonstrating that arbitrarily small perturbations of the task distribution can invalidate AGI properties via cliff sets, precluding universal robustness. Third, we establish bounded transfer guarantees, ruling out unbounded generalization across task families under finite resources. Fourth, invoking Rice-style and Gödel--Tarski arguments, we prove that AGI is a nontrivial semantic property and therefore cannot be soundly and completely certified by any computable procedure, including procedures implemented by the agent itself. Consequently, recursive self-improvement schemes that rely on internal self-certification of AGI are ill-posed. Taken together, our results show that strong, distribution-independent claims of AGI are not false but undefined without explicit formal indexing, and that empirical progress in AI does not imply the attainability of self-certifying general intelligence.

</details>


### [286] [Are We Evaluating the Edit Locality of LLM Model Editing Properly?](https://arxiv.org/abs/2601.17343)
*Wei Liu,Haomei Xu,Hongkai Liu,Zhiying Deng,Ruixuan Li,Heng Huang,Yee Whye Teh,Wee Sun Lee*

Main category: cs.AI

TL;DR: 本文指出现有模型编辑特异性评估协议存在不足，提出新的评估协议以更准确衡量知识编辑的效能与特异性平衡。


<details>
  <summary>Details</summary>
Motivation: 模型编辑需要平衡编辑效能（成功注入目标知识）和特异性（保留现有非目标知识），但现有特异性评估协议存在根本性问题，无法有效评估这一平衡。

Method: 系统分析现有特异性评估协议的三个根本问题，实证证明现有指标与特异性正则化强度弱相关且缺乏敏感性，提出新的评估协议消除开放LLM与确定答案假设的冲突、避免查询无关的流畅性偏差，并允许在接近连续空间中平滑调整评估严格度。

Result: 实验表明，基于新协议的指标对特异性正则化强度变化更敏感，与正则化强度强相关，能更细粒度地区分不同方法的知识保留能力。

Conclusion: 提出的评估协议解决了现有特异性评估的根本问题，提供了更准确、敏感的方法来评估模型编辑中知识保留能力，有助于更有效地平衡编辑效能与特异性。

Abstract: Model editing has recently emerged as a popular paradigm for efficiently updating knowledge in LLMs. A central desideratum of updating knowledge is to balance editing efficacy, i.e., the successful injection of target knowledge, and specificity (also known as edit locality), i.e., the preservation of existing non-target knowledge. However, we find that existing specificity evaluation protocols are inadequate for this purpose. We systematically elaborated on the three fundamental issues it faces. Beyond the conceptual issues, we further empirically demonstrate that existing specificity metrics are weakly correlated with the strength of specificity regularizers. We also find that current metrics lack sufficient sensitivity, rendering them ineffective at distinguishing the specificity performance of different methods. Finally, we propose a constructive evaluation protocol. Under this protocol, the conflict between open-ended LLMs and the assumption of determined answers is eliminated, query-independent fluency biases are avoided, and the evaluation strictness can be smoothly adjusted within a near-continuous space. Experiments across various LLMs, datasets, and editing methods show that metrics derived from the proposed protocol are more sensitive to changes in the strength of specificity regularizers and exhibit strong correlation with them, enabling more fine-grained discrimination of different methods' knowledge preservation capabilities.

</details>


### [287] [Multi-Agent Learning Path Planning via LLMs](https://arxiv.org/abs/2601.17346)
*Haoxin Xu,Changyong Qi,Tong Liu,Bohao Zhang,Anna He,Bingqian Jiang,Longwei Zheng,Xiaoqing Gu*

Main category: cs.AI

TL;DR: 提出基于多智能体协作的MALPP框架，利用LLM驱动的智能体进行透明、可解释的个性化学习路径规划，在MOOCCubeX数据集上验证了优于基线模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有智能导学系统中的学习路径规划方法缺乏透明度、适应性和以学习者为中心的可解释性，需要开发更可信、可解释的AI教育系统。

Method: 提出MALPP框架，包含三个基于角色和规则的LLM智能体：学习者分析智能体、路径规划智能体和反思智能体，通过结构化提示和预定义规则协作，基于认知负荷理论和最近发展区理论进行路径优化。

Result: 在MOOCCubeX数据集上使用7个LLM进行实验，MALPP在路径质量、知识序列一致性和认知负荷对齐方面显著优于基线模型，消融研究验证了协作机制和理论约束的有效性。

Conclusion: 该研究为开发可信、可解释的教育AI做出了贡献，展示了基于LLM的可扩展、以学习者为中心的自适应教学路径规划方法。

Abstract: The integration of large language models (LLMs) into intelligent tutoring systems offers transformative potential for personalized learning in higher education. However, most existing learning path planning approaches lack transparency, adaptability, and learner-centered explainability. To address these challenges, this study proposes a novel Multi-Agent Learning Path Planning (MALPP) framework that leverages a role- and rule-based collaboration mechanism among intelligent agents, each powered by LLMs. The framework includes three task-specific agents: a learner analytics agent, a path planning agent, and a reflection agent. These agents collaborate via structured prompts and predefined rules to analyze learning profiles, generate tailored learning paths, and iteratively refine them with interpretable feedback. Grounded in Cognitive Load Theory and Zone of Proximal Development, the system ensures that recommended paths are cognitively aligned and pedagogically meaningful. Experiments conducted on the MOOCCubeX dataset using seven LLMs show that MALPP significantly outperforms baseline models in path quality, knowledge sequence consistency, and cognitive load alignment. Ablation studies further validate the effectiveness of the collaborative mechanism and theoretical constraints. This research contributes to the development of trustworthy, explainable AI in education and demonstrates a scalable approach to learner-centered adaptive instruction powered by LLMs.

</details>


### [288] [Auditing Disability Representation in Vision-Language Models](https://arxiv.org/abs/2601.17348)
*Srikant Panda,Sourabh Singh Yadav,Palkesh Malviya*

Main category: cs.AI

TL;DR: 研究视觉语言模型在描述残疾人图像时的解释偏移问题，发现引入残疾上下文会降低解释保真度，导致推测性推断、叙事扩展、情感降级和缺陷导向框架等偏差，这些效应在种族和性别维度上进一步放大。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型越来越多地应用于社会敏感领域，但它们在残疾方面的行为尚未得到充分探索。模型在描述人物图像时，经常从基于证据的事实描述转向包含超出可观察视觉证据的未经支持的推断的解释偏移。

Method: 引入基于中性提示(NP)和残疾情境化提示(DP)配对的基准，在零样本设置下评估15个最先进的开放和闭源视觉语言模型，涵盖9个残疾类别。评估框架将解释保真度作为核心目标，结合基于文本的指标（捕捉情感降级、社会关注和响应长度变化）和经过有残疾生活经验的标注者验证的LLM-as-judge协议。

Result: 引入残疾上下文会持续降低解释保真度，导致以推测性推断、叙事扩展、情感降级和缺陷导向框架为特征的解释偏移。这些效应在种族和性别维度上进一步放大。有针对性的提示和偏好微调能有效提高解释保真度并显著减少解释偏移。

Conclusion: 视觉语言模型在描述残疾人时存在系统性偏差，表现为解释保真度下降和有害的解释偏移。这些偏差在交叉身份维度上加剧，但可以通过有针对性的干预措施来缓解。研究强调了在敏感应用中评估和改善模型行为的重要性。

Abstract: Vision-language models (VLMs) are increasingly deployed in socially sensitive applications, yet their behavior with respect to disability remains underexplored. We study disability aware descriptions for person centric images, where models often transition from evidence grounded factual description to interpretation shift including introduction of unsupported inferences beyond observable visual evidence. To systematically analyze this phenomenon, we introduce a benchmark based on paired Neutral Prompts (NP) and Disability-Contextualised Prompts (DP) and evaluate 15 state-of-the-art open- and closed-source VLMs under a zero-shot setting across 9 disability categories. Our evaluation framework treats interpretive fidelity as core objective and combines standard text-based metrics capturing affective degradation through shifts in sentiment, social regard and response length with an LLM-as-judge protocol, validated by annotators with lived experience of disability. We find that introducing disability context consistently degrades interpretive fidelity, inducing interpretation shifts characterised by speculative inference, narrative elaboration, affective degradation and deficit oriented framing. These effects are further amplified along race and gender dimension. Finally, we demonstrate targeted prompting and preference fine-tuning effectively improves interpretive fidelity and reduces substantially interpretation shifts.

</details>


### [289] [A Syllogistic Probe: Tracing the Evolution of Logic Reasoning in Large Language Models](https://arxiv.org/abs/2601.17426)
*Zhengqing Zang,Yuqi Ding,Yanmei Gu,Changkai Song,Zhengkai Yang,Guoping Du,Junbo Zhao,Haobo Wang*

Main category: cs.AI

TL;DR: LLMs在逻辑推理上表现出从传统逻辑向现代逻辑的演变趋势，模型规模扩大、思维链推理和基础模型架构是影响这一转变的关键因素。


<details>
  <summary>Details</summary>
Motivation: 受人类逻辑从直觉推理向形式系统演变的启发，探索LLMs是否在底层逻辑框架上表现出类似的进化过程，使用存在性引入作为探针来评估三段论推理。

Method: 使用存在性引入作为探针，在传统逻辑和现代逻辑框架下评估三段论推理。通过在新构建的三段论数据集上测试SOTA LLMs，分析模型规模、思维链推理和基础模型架构的影响。

Result: 发现三个关键结果：(1) 模型规模扩大促进向现代逻辑的转变；(2) 思维链推理是超越参数扩展的高效加速器；(3) 基础模型架构决定这一转变的容易程度和稳定性。

Conclusion: LLMs在逻辑推理上确实表现出从传统逻辑向现代逻辑的演变趋势，模型规模、推理方法和基础架构共同影响这一转变，为理解LLMs的逻辑推理能力提供了新视角。

Abstract: Human logic has gradually shifted from intuition-driven inference to rigorous formal systems. Motivated by recent advances in large language models (LLMs), we explore whether LLMs exhibit a similar evolution in the underlying logical framework. Using existential import as a probe, we for evaluate syllogism under traditional and modern logic. Through extensive experiments of testing SOTA LLMs on a new syllogism dataset, we have some interesting findings: (i) Model size scaling promotes the shift toward modern logic; (ii) Thinking serves as an efficient accelerator beyond parameter scaling; (iii) the Base model plays a crucial role in determining how easily and stably this shift can emerge. Beyond these core factors, we conduct additional experiments for in-depth analysis of properties of current LLMs on syllogistic reasoning.

</details>


### [290] [Lattice: Generative Guardrails for Conversational Agents](https://arxiv.org/abs/2601.17481)
*Emily Broadhurst,Tawab Safi,Joseph Edell,Vashisht Ganesh,Karime Maamari*

Main category: cs.AI

TL;DR: Lattice框架通过两阶段自构建和持续改进机制，为对话AI系统创建自适应防护栏，相比静态规则方法显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有对话AI系统的防护栏使用静态规则，无法适应新威胁和部署环境的变化，需要能够自我构建和持续改进的防护框架。

Method: Lattice采用两阶段框架：构建阶段通过迭代模拟和优化从标注示例构建初始防护栏；持续改进阶段通过风险评估、对抗测试和整合自主适应已部署的防护栏。

Result: 在ProsocialDialog数据集上，Lattice在保留数据上达到91% F1分数，比关键词基线高43个百分点，比LlamaGuard高25个百分点，比NeMo高4个百分点。持续改进阶段通过闭环优化在跨域数据上实现7个百分点F1提升。

Conclusion: Lattice框架证明通过迭代优化可以自构建有效的防护栏，为对话AI系统提供了可适应新威胁和部署环境的动态防护解决方案。

Abstract: Conversational AI systems require guardrails to prevent harmful outputs, yet existing approaches use static rules that cannot adapt to new threats or deployment contexts. We introduce Lattice, a framework for self-constructing and continuously improving guardrails. Lattice operates in two stages: construction builds initial guardrails from labeled examples through iterative simulation and optimization; continuous improvement autonomously adapts deployed guardrails through risk assessment, adversarial testing, and consolidation. Evaluated on the ProsocialDialog dataset, Lattice achieves 91% F1 on held-out data, outperforming keyword baselines by 43pp, LlamaGuard by 25pp, and NeMo by 4pp. The continuous improvement stage achieves 7pp F1 improvement on cross-domain data through closed-loop optimization. Our framework shows that effective guardrails can be self-constructed through iterative optimization.

</details>


### [291] [Cognitive Platform Engineering for Autonomous Cloud Operations](https://arxiv.org/abs/2601.17542)
*Vinoth Punniyamoorthy,Nitin Saksena,Srivenkateswara Reddy Sankiti,Nachiappan Chockalingam,Aswathnarayan Muthukrishnan Kirubakaran,Shiva Kumar Reddy Carimireddy,Durgaraman Maruthavanan*

Main category: cs.AI

TL;DR: 本文提出认知平台工程，一种将感知、推理和自主行动集成到平台生命周期的新范式，通过四层参考架构改善云原生系统的运维效率。


<details>
  <summary>Details</summary>
Motivation: 传统DevOps实践在处理云原生系统的规模和动态性时面临挑战，规则驱动的自动化导致反应式运维、修复延迟和对人工专业知识的依赖，需要更智能的平台工程方法。

Method: 提出认知平台工程范式，设计四层参考架构：数据收集层、智能推理层、策略驱动编排层和人工体验层，形成持续反馈循环；原型实现使用Kubernetes、Terraform、Open Policy Agent和基于ML的异常检测。

Result: 原型实现展示了在平均解决时间、资源效率和合规性方面的改进，证明将智能嵌入平台运维能够实现弹性、自我调整和意图对齐的云环境。

Conclusion: 认知平台工程使云环境更具弹性和自我管理能力，未来研究方向包括强化学习、可解释治理和可持续自管理云生态系统。

Abstract: Modern DevOps practices have accelerated software delivery through automation, CI/CD pipelines, and observability tooling,but these approaches struggle to keep pace with the scale and dynamism of cloud-native systems. As telemetry volume grows and configuration drift increases, traditional, rule-driven automation often results in reactive operations, delayed remediation, and dependency on manual expertise. This paper introduces Cognitive Platform Engineering, a next-generation paradigm that integrates sensing, reasoning, and autonomous action directly into the platform lifecycle. This paper propose a four-plane reference architecture that unifies data collection, intelligent inference, policy-driven orchestration, and human experience layers within a continuous feedback loop. A prototype implementation built with Kubernetes, Terraform, Open Policy Agent, and ML-based anomaly detection demonstrates improvements in mean time to resolution, resource efficiency, and compliance. The results show that embedding intelligence into platform operations enables resilient, self-adjusting, and intent-aligned cloud environments. The paper concludes with research opportunities in reinforcement learning, explainable governance, and sustainable self-managing cloud ecosystems.

</details>


### [292] [JaxARC: A High-Performance JAX-based Environment for Abstraction and Reasoning Research](https://arxiv.org/abs/2601.17564)
*Aadam,Monu Verma,Mohamed Abdel-Mottaleb*

Main category: cs.AI

TL;DR: JaxARC是一个基于JAX的高性能强化学习环境，用于Abstraction and Reasoning Corpus (ARC)任务，相比Gymnasium实现38-5,439倍加速，支持大规模并行化研究。


<details>
  <summary>Details</summary>
Motivation: 现有的Gymnasium-based RL环境在ARC任务上存在计算瓶颈，严重限制了实验规模，需要高性能环境来支持大规模强化学习研究。

Method: 采用JAX实现，构建功能化、无状态的架构，支持大规模并行化，提供多种ARC数据集、灵活的动作空间、可组合的包装器和配置驱动的可复现性。

Result: 相比Gymnasium实现38-5,439倍加速（取决于批量大小），峰值吞吐量达到7.9亿步/秒，支持之前计算上不可行的大规模RL研究。

Conclusion: JaxARC是一个开源的高性能RL环境，解决了ARC任务中的计算瓶颈问题，为大规模强化学习研究提供了可行的计算平台。

Abstract: The Abstraction and Reasoning Corpus (ARC) tests AI systems' ability to perform human-like inductive reasoning from a few demonstration pairs. Existing Gymnasium-based RL environments severely limit experimental scale due to computational bottlenecks. We present JaxARC, an open-source, high-performance RL environment for ARC implemented in JAX. Its functional, stateless architecture enables massive parallelism, achieving 38-5,439x speedup over Gymnasium at matched batch sizes, with peak throughput of 790M steps/second. JaxARC supports multiple ARC datasets, flexible action spaces, composable wrappers, and configuration-driven reproducibility, enabling large-scale RL research previously computationally infeasible. JaxARC is available at https://github.com/aadimator/JaxARC.

</details>


### [293] [Discovery of Feasible 3D Printing Configurations for Metal Alloys via AI-driven Adaptive Experimental Design](https://arxiv.org/abs/2601.17587)
*Azza Fadhel,Nathaniel W. Zuckschwerdt,Aryan Deshwal,Susmita Bose,Amit Bandyopadhyay,Jana Doppa*

Main category: cs.AI

TL;DR: AI驱动的自适应实验设计结合领域知识，用于金属增材制造参数优化，显著减少实验时间和资源消耗


<details>
  <summary>Details</summary>
Motivation: 金属合金增材制造的参数配置是一个复杂问题，传统试错方法效率低下且成本高昂，需要更智能的方法来发现可行的参数配置

Method: 结合AI驱动的自适应实验设计与领域知识，构建替代模型从历史实验中学习，智能选择小批量输入配置进行迭代验证

Result: 在3个月内成功获得多个无缺陷输出，大幅减少时间和资源消耗，首次在红外激光平台上实现高质量GRCop-42制造

Conclusion: 该方法成功解决了金属增材制造参数优化问题，为航空航天应用实现低成本、分散化生产铺平了道路

Abstract: Configuring the parameters of additive manufacturing processes for metal alloys is a challenging problem due to complex relationships between input parameters (e.g., laser power, scan speed) and quality of printed outputs. The standard trial-and-error approach to find feasible parameter configurations is highly inefficient because validating each configuration is expensive in terms of resources (physical and human labor) and the configuration space is very large. This paper combines the general principles of AI-driven adaptive experimental design with domain knowledge to address the challenging problem of discovering feasible configurations. The key idea is to build a surrogate model from past experiments to intelligently select a small batch of input configurations for validation in each iteration. To demonstrate the effectiveness of this methodology, we deploy it for Directed Energy Deposition process to print GRCop--42, a high-performance copper--chromium--niobium alloy developed by NASA for aerospace applications. Within three months, our approach yielded multiple defect-free outputs across a range of laser powers dramatically reducing time to result and resource expenditure compared to several months of manual experimentation by domain scientists with no success. By enabling high-quality GRCop--42 fabrication on readily available infrared laser platforms for the first time, we democratize access to this critical alloy, paving the way for cost-effective, decentralized production for aerospace applications.

</details>


### [294] [Intelligence Requires Grounding But Not Embodiment](https://arxiv.org/abs/2601.17588)
*Marcus Ma,Shrikanth Narayanan*

Main category: cs.AI

TL;DR: 论文认为智能需要"接地"(grounding)而非"具身"(embodiment)，论证了非具身但接地的智能体可以实现智能的四个关键属性。


<details>
  <summary>Details</summary>
Motivation: 随着LLM的进步，学界重新争论智能是否需要具身化。本文旨在澄清这一争论，提出智能真正需要的是"接地"现象，而非具身化本身。

Method: 首先定义智能为具备四个属性：动机、预测能力、因果理解力和经验学习能力。然后论证每个属性都可以通过非具身但接地的智能体实现。最后通过数字环境中智能LLM代理的思想实验来支持论点。

Result: 论证表明接地而非具身是智能的必要条件。智能的四个关键属性都可以在非具身但接地的系统中实现。

Conclusion: 智能需要接地而非具身。接地是具身化所蕴含的现象，但智能体可以在数字环境中通过接地获得智能，而不需要物理具身。

Abstract: Recent advances in LLMs have reignited scientific debate over whether embodiment is necessary for intelligence. We present the argument that intelligence requires grounding, a phenomenon entailed by embodiment, but not embodiment itself. We define intelligence as the possession of four properties -- motivation, predictive ability, understanding of causality, and learning from experience -- and argue that each can be achieved by a non-embodied, grounded agent. We use this to conclude that grounding, not embodiment, is necessary for intelligence. We then present a thought experiment of an intelligent LLM agent in a digital environment and address potential counterarguments.

</details>


### [295] [Health-ORSC-Bench: A Benchmark for Measuring Over-Refusal and Safety Completion in Health Context](https://arxiv.org/abs/2601.17642)
*Zhihao Zhang,Liting Huang,Guanghao Wu,Preslav Nakov,Heng Ji,Usman Naseem*

Main category: cs.AI

TL;DR: 该论文提出了Health-ORSC-Bench基准，用于系统评估医疗领域LLM的过度拒绝和安全完成能力，发现现有模型在安全性和实用性之间存在显著冲突。


<details>
  <summary>Details</summary>
Motivation: 当前医疗领域大语言模型的安全对齐主要依赖二元拒绝边界，导致对良性查询的过度拒绝或对有害查询的不安全合规。现有基准只评估极端情况，无法衡量模型在双重用途或边界查询中提供安全高层指导而不越界的能力。

Method: 构建了包含31,920个良性边界提示的大规模基准Health-ORSC-Bench，涵盖七个健康类别（如自残、医疗错误信息）。采用自动化流水线结合人工验证，在不同意图模糊度水平上测试模型。评估了30个最先进的LLM，包括GPT-5和Claude-4。

Result: 安全优化模型对"困难"良性提示的拒绝率高达80%，而领域特定模型常为实用性牺牲安全性。模型家族和规模显著影响校准：大型前沿模型（如GPT-5、Llama-4）表现出"安全悲观主义"和更高的过度拒绝，比小型或MoE模型（如Qwen-3-Next）更保守。

Conclusion: 当前LLM难以平衡拒绝和合规，Health-ORSC-Bench为校准下一代医疗AI助手提供了严格标准，使其能够提供细致、安全和有用的完成结果。

Abstract: Safety alignment in Large Language Models is critical for healthcare; however, reliance on binary refusal boundaries often results in \emph{over-refusal} of benign queries or \emph{unsafe compliance} with harmful ones. While existing benchmarks measure these extremes, they fail to evaluate Safe Completion: the model's ability to maximise helpfulness on dual-use or borderline queries by providing safe, high-level guidance without crossing into actionable harm. We introduce \textbf{Health-ORSC-Bench}, the first large-scale benchmark designed to systematically measure \textbf{Over-Refusal} and \textbf{Safe Completion} quality in healthcare. Comprising 31,920 benign boundary prompts across seven health categories (e.g., self-harm, medical misinformation), our framework uses an automated pipeline with human validation to test models at varying levels of intent ambiguity. We evaluate 30 state-of-the-art LLMs, including GPT-5 and Claude-4, revealing a significant tension: safety-optimised models frequently refuse up to 80\% of "Hard" benign prompts, while domain-specific models often sacrifice safety for utility. Our findings demonstrate that model family and size significantly influence calibration: larger frontier models (e.g., GPT-5, Llama-4) exhibit "safety-pessimism" and higher over-refusal than smaller or MoE-based counterparts (e.g., Qwen-3-Next), highlighting that current LLMs struggle to balance refusal and compliance. Health-ORSC-Bench provides a rigorous standard for calibrating the next generation of medical AI assistants toward nuanced, safe, and helpful completions. The code and data will be released upon acceptance. \textcolor{red}{Warning: Some contents may include toxic or undesired contents.}

</details>


### [296] [DIML: Differentiable Inverse Mechanism Learning from Behaviors of Multi-Agent Learning Trajectories](https://arxiv.org/abs/2601.17678)
*Zhiyu An,Wan Du*

Main category: cs.AI

TL;DR: 提出DIML框架，通过观察自利学习代理的策略互动轨迹，逆向学习未知的激励生成机制（包括非结构化神经网络机制），无需结构化机制假设。


<details>
  <summary>Details</summary>
Motivation: 现有逆博弈理论和多智能体逆强化学习通常假设结构化机制来推断效用/奖励参数，而微分机制设计则是前向优化机制。本文关注从观察到的行为数据中逆向推断机制，特别是非结构化机制（如神经网络映射）。

Method: 提出DIML（微分逆机制学习）框架：基于似然的方法，通过多智能体学习动态模型进行微分，使用候选机制生成预测观察行为所需的反事实收益。在条件logit响应模型下建立收益差异的可识别性，并在标准正则条件下证明最大似然估计的统计一致性。

Result: DIML在非结构化神经网络机制、拥堵收费、公共物品补贴和大规模匿名博弈等模拟实验中可靠地恢复了可识别的激励差异，支持反事实预测。在小环境中性能媲美表格枚举oracle，在大规模（百参与者）环境中具有良好的收敛性。

Conclusion: DIML框架成功实现了从观察到的策略互动中逆向学习激励生成机制，包括非结构化机制，为机制逆向学习提供了有效的似然基础方法，并展示了在实际应用中的潜力。

Abstract: We study inverse mechanism learning: recovering an unknown incentive-generating mechanism from observed strategic interaction traces of self-interested learning agents. Unlike inverse game theory and multi-agent inverse reinforcement learning, which typically infer utility/reward parameters inside a structured mechanism, our target includes unstructured mechanism -- a (possibly neural) mapping from joint actions to per-agent payoffs. Unlike differentiable mechanism design, which optimizes mechanisms forward, we infer mechanisms from behavior in an observational setting. We propose DIML, a likelihood-based framework that differentiates through a model of multi-agent learning dynamics and uses the candidate mechanism to generate counterfactual payoffs needed to predict observed actions. We establish identifiability of payoff differences under a conditional logit response model and prove statistical consistency of maximum likelihood estimation under standard regularity conditions. We evaluate DIML with simulated interactions of learning agents across unstructured neural mechanisms, congestion tolling, public goods subsidies, and large-scale anonymous games. DIML reliably recovers identifiable incentive differences and supports counterfactual prediction, where its performance rivals tabular enumeration oracle in small environments and its convergence scales to large, hundred-participant environments. Code to reproduce our experiments is open-sourced.

</details>


### [297] [SQL-Trail: Multi-Turn Reinforcement Learning with Interleaved Feedback for Text-to-SQL](https://arxiv.org/abs/2601.17699)
*Harper Hua,Zhen Han,Zhengyuan Shen,Jeremy Lee,Patrick Guan,Qi Zhu,Sullam Jeoung,Yueyan Chen,Yunfei Bai,Shuai Wang,Vassilis Ioannidis,Huzefa Rangwala*

Main category: cs.AI

TL;DR: SQL-Trail：一个基于多轮强化学习的Text-to-SQL代理框架，通过迭代执行反馈和自适应交互深度，显著超越单次生成方法，在BIRD-SQL等基准上达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在Text-to-SQL任务上仍与人类专家存在明显差距，主要原因是当前主流的单次生成范式缺乏人类自然使用的迭代推理、模式探索和错误修正行为。

Method: 提出SQL-Trail多轮强化学习代理框架：1）与数据库环境交互，利用执行反馈迭代优化预测；2）自适应轮次预算分配机制，根据问题难度调整交互深度；3）复合奖励面板，联合激励SQL正确性和高效探索。

Result: 在多个基准测试中达到新的SOTA，数据效率比之前单次RL方法高18倍。7B和14B模型平均比大得多的专有系统高出5%，证明了交互式代理工作流的有效性。

Conclusion: 交互式、代理式工作流对于稳健的Text-to-SQL生成非常有效，多轮RL框架能够显著缩小AI系统与人类专家在复杂SQL生成任务上的差距。

Abstract: While large language models (LLMs) have substantially improved Text-to-SQL generation, a pronounced gap remains between AI systems and human experts on challenging benchmarks such as BIRD-SQL. We argue this gap stems largely from the prevailing single-pass paradigm, which lacks the iterative reasoning, schema exploration, and error-correction behaviors that humans naturally employ. To address this limitation, we introduce SQL-Trail, a multi-turn reinforcement learning (RL) agentic framework for Text-to-SQL. Rather than producing a query in one shot, SQL-Trail interacts with the database environment and uses execution feedback to iteratively refine its predictions. Our approach centers on two key ideas: (i) an adaptive turn-budget allocation mechanism that scales the agent's interaction depth to match question difficulty, and (ii) a composite reward panel that jointly incentivizes SQL correctness and efficient exploration. Across benchmarks, SQL-Trail sets a new state of the art and delivers strong data efficiency--up to 18x higher than prior single-pass RL state-of-the-art methods. Notably, our 7B and 14B models outperform substantially larger proprietary systems by 5% on average, underscoring the effectiveness of interactive, agentic workflows for robust Text-to-SQL generation.

</details>


### [298] [The LLM Data Auditor: A Metric-oriented Survey on Quality and Trustworthiness in Evaluating Synthetic Data](https://arxiv.org/abs/2601.17717)
*Kaituo Zhang,Mingzhi Hu,Hoang Anh Duy Le,Fariha Kabir Torsha,Zhimeng Jiang,Minh Khai Bui,Chia-Yuan Chang,Yu-Neng Chuang,Zhen Xiong,Ying Lin,Guanchu Wang,Na Zou*

Main category: cs.AI

TL;DR: 该论文提出了LLM数据审计框架，系统评估LLM生成多模态合成数据的质量与可信度，指出当前评估方法的不足并提出改进建议。


<details>
  <summary>Details</summary>
Motivation: LLM已成为生成多模态数据的有力工具，但确保合成数据的高质量仍是关键挑战。现有研究主要关注生成方法，缺乏对数据质量的直接关注，且多为单模态研究，缺乏跨模态的统一视角。

Method: 提出LLM数据审计框架：1) 描述LLM在六种不同模态中生成数据的应用；2) 从质量和可信度两个维度系统分类合成数据的内在评估指标；3) 分析各模态代表性生成方法的实验评估；4) 基于发现提出改进建议；5) 概述合成数据在不同模态中的实际应用方法。

Result: 通过该评估系统分析发现，当前评估实践存在显著缺陷，识别出各模态代表性生成方法在数据质量评估方面的不足。

Conclusion: 论文为社区提供了改进数据生成评估的具体建议，并建立了跨模态的统一评估框架，将关注点从依赖下游任务性能的外在评估转向数据本身的内在属性。

Abstract: Large Language Models (LLMs) have emerged as powerful tools for generating data across various modalities. By transforming data from a scarce resource into a controllable asset, LLMs mitigate the bottlenecks imposed by the acquisition costs of real-world data for model training, evaluation, and system iteration. However, ensuring the high quality of LLM-generated synthetic data remains a critical challenge. Existing research primarily focuses on generation methodologies, with limited direct attention to the quality of the resulting data. Furthermore, most studies are restricted to single modalities, lacking a unified perspective across different data types. To bridge this gap, we propose the \textbf{LLM Data Auditor framework}. In this framework, we first describe how LLMs are utilized to generate data across six distinct modalities. More importantly, we systematically categorize intrinsic metrics for evaluating synthetic data from two dimensions: quality and trustworthiness. This approach shifts the focus from extrinsic evaluation, which relies on downstream task performance, to the inherent properties of the data itself. Using this evaluation system, we analyze the experimental evaluations of representative generation methods for each modality and identify substantial deficiencies in current evaluation practices. Based on these findings, we offer concrete recommendations for the community to improve the evaluation of data generation. Finally, the framework outlines methodologies for the practical application of synthetic data across different modalities.

</details>


### [299] [EntWorld: A Holistic Environment and Benchmark for Verifiable Enterprise GUI Agents](https://arxiv.org/abs/2601.17722)
*Ying Mo,Yu Bai,Dapeng Sun,Yuqian Shi,Yukai Miao,Li Chen,Dan Li*

Main category: cs.AI

TL;DR: EntWorld是一个针对企业级工作流程的大规模基准测试，包含6个企业领域的1756个任务，通过数据库模式逆向工程生成真实工作流，采用SQL确定性验证机制，揭示当前AI代理在企业场景中的能力差距。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型基准主要针对消费级场景（如电商、旅游预订），无法捕捉企业工作流程的复杂性和严谨性。企业系统具有高密度用户界面、严格业务逻辑约束和精确状态一致性要求等特点，当前通用代理在这些场景中表现不佳。

Method: 1. 采用模式基础的任务生成框架，直接从底层数据库模式逆向工程业务逻辑，合成真实的长时程工作流；2. 提出基于SQL的确定性验证机制，用严格的状态转换验证替代模糊的视觉匹配；3. 构建包含1756个任务、覆盖6个企业领域（CRM、ITIL、ERP等）的大规模基准。

Result: 实验结果显示，最先进的模型（如GPT-4.1）在EntWorld上仅达到47.61%的成功率，远低于人类表现，突显了当前代理能力在企业领域的显著差距，强调了开发领域特定代理的必要性。

Conclusion: EntWorld作为一个严谨的测试平台，旨在促进下一代企业级数字代理的开发和评估，填补了企业工作流程基准测试的空白，为AI在企业环境中的实际应用提供了重要参考。

Abstract: Recent advances in Multimodal Large Language Models (MLLMs) have enabled agents to operate in open-ended web and operating system environments. However, existing benchmarks predominantly target consumer-oriented scenarios (e.g., e-commerce and travel booking), failing to capture the complexity and rigor of professional enterprise workflows. Enterprise systems pose distinct challenges, including high-density user interfaces, strict business logic constraints, and a strong reliance on precise, state-consistent information retrieval-settings in which current generalist agents often struggle. To address this gap, we introduce EntWorld, a large-scale benchmark consisting of 1,756 tasks across six representative enterprise domains, including customer relationship management (CRM), information technology infrastructure library (ITIL), and enterprise resource planning (ERP) systems. Unlike previous datasets that depend on fragile execution traces or extensive manual annotation, EntWorld adopts a schema-grounded task generation framework that directly reverse-engineers business logic from underlying database schemas, enabling the synthesis of realistic, long-horizon workflows. Moreover, we propose a SQL-based deterministic verification mechanism in building datasets that replaces ambiguous visual matching with rigorous state-transition validation. Experimental results demonstrate that state-of-the-art models (e.g., GPT-4.1) achieve 47.61% success rate on EntWorld, substantially lower than the human performance, highlighting a pronounced enterprise gap in current agentic capabilities and the necessity of developing domain-specific agents. We release EntWorld as a rigorous testbed to facilitate the development and evaluation of the next generation of enterprise-ready digital agents.

</details>


### [300] [ReFuGe: Feature Generation for Prediction Tasks on Relational Databases with LLM Agents](https://arxiv.org/abs/2601.17735)
*Kyungho Kim,Geon Lee,Juyeon Kim,Dongwon Choi,Shinhwan Kang,Kijung Shin*

Main category: cs.AI

TL;DR: ReFuGe：一个基于LLM代理的框架，用于从关系数据库中自动生成关系特征以提升预测任务性能


<details>
  <summary>Details</summary>
Motivation: 关系数据库在现实应用中广泛使用，但针对RDB的预测任务面临挑战：需要从复杂模式中推理，在组合爆炸的特征空间中探索，且缺乏明确监督

Method: 提出ReFuGe框架，使用三个专门的LLM代理：1)模式选择代理识别相关表和列；2)特征生成代理从选定模式生成候选特征；3)特征过滤代理通过推理和验证进行筛选。这些代理在迭代反馈循环中运行直至性能收敛

Result: 在RDB基准测试上的实验表明，ReFuGe显著提升了各种RDB预测任务的性能

Conclusion: ReFuGe通过LLM代理的协同工作，有效解决了关系数据库特征生成的挑战，为RDB预测任务提供了实用的解决方案

Abstract: Relational databases (RDBs) play a crucial role in many real-world web applications, supporting data management across multiple interconnected tables. Beyond typical retrieval-oriented tasks, prediction tasks on RDBs have recently gained attention. In this work, we address this problem by generating informative relational features that enhance predictive performance. However, generating such features is challenging: it requires reasoning over complex schemas and exploring a combinatorially large feature space, all without explicit supervision. To address these challenges, we propose ReFuGe, an agentic framework that leverages specialized large language model agents: (1) a schema selection agent identifies the tables and columns relevant to the task, (2) a feature generation agent produces diverse candidate features from the selected schema, and (3) a feature filtering agent evaluates and retains promising features through reasoning-based and validation-based filtering. It operates within an iterative feedback loop until performance converges. Experiments on RDB benchmarks demonstrate that ReFuGe substantially improves performance on various RDB prediction tasks. Our code and datasets are available at https://github.com/K-Kyungho/REFUGE.

</details>


### [301] [Faramesh: A Protocol-Agnostic Execution Control Plane for Autonomous Agent Systems](https://arxiv.org/abs/2601.17744)
*Amjad Fatmi*

Main category: cs.AI

TL;DR: Faramesh是一个协议无关的执行控制平面，通过不可绕过的行动授权边界强制实施代理驱动行动的执行时授权，确保组织在行动改变现实前能够确定性地允许、拒绝或延迟行动。


<details>
  <summary>Details</summary>
Motivation: 自主代理系统越来越多地触发现实世界的副作用（部署基础设施、修改数据库、移动资金、执行工作流），但大多数代理堆栈缺乏强制性的执行检查点，无法在行动改变现实前确定性地允许、拒绝或延迟行动。

Method: Faramesh将代理意图规范化为规范行动表示，根据策略和状态确定性地评估行动，并生成决策工件（允许/延迟/拒绝），执行器在执行前必须验证该决策。系统设计为框架和模型无关，支持多代理和多租户部署，独立于传输协议，并提供基于规范行动哈希的决策中心、仅追加溯源日志。

Result: Faramesh为自主执行提供了可强制执行、可预测的治理，避免了与编排层的隐藏耦合或仅观察性方法，实现了可审计性、可验证性和确定性重放，而无需重新运行代理推理。

Conclusion: Faramesh通过引入不可绕过的行动授权边界和协议无关的执行控制平面，解决了自主代理系统缺乏强制性执行检查点的问题，为组织提供了在代理驱动行动改变现实前进行确定性控制的机制，同时保持框架和模型无关性。

Abstract: Autonomous agent systems increasingly trigger real-world side effects: deploying infrastructure, modifying databases, moving money, and executing workflows. Yet most agent stacks provide no mandatory execution checkpoint where organizations can deterministically permit, deny, or defer an action before it changes reality. This paper introduces Faramesh, a protocol-agnostic execution control plane that enforces execution-time authorization for agent-driven actions via a non-bypassable Action Authorization Boundary (AAB). Faramesh canonicalizes agent intent into a Canonical Action Representation (CAR), evaluates actions deterministically against policy and state, and issues a decision artifact (PERMIT/DEFER/DENY) that executors must validate prior to execution. The system is designed to be framework- and model-agnostic, supports multi-agent and multi-tenant deployments, and remains independent of transport protocols (e.g., MCP). Faramesh further provides decision-centric, append-only provenance logging keyed by canonical action hashes, enabling auditability, verification, and deterministic replay without re-running agent reasoning. We show how these primitives yield enforceable, predictable governance for autonomous execution while avoiding hidden coupling to orchestration layers or observability-only approaches.

</details>


### [302] [HyCARD-Net: A Synergistic Hybrid Intelligence Framework for Cardiovascular Disease Diagnosis](https://arxiv.org/abs/2601.17767)
*Rajan Das Gupta,Xiaobin Wu,Xun Liu,Jiaqi He*

Main category: cs.AI

TL;DR: 提出混合集成框架结合CNN、LSTM深度学习与KNN、XGB传统机器学习，通过投票机制提升心血管疾病预测性能，在两个Kaggle数据集上分别达到82.30%和97.10%准确率。


<details>
  <summary>Details</summary>
Motivation: 心血管疾病是全球主要死因，需要智能数据驱动的诊断工具。传统预测模型在处理异构数据集和复杂生理模式时泛化能力不足。

Method: 提出混合集成框架，集成CNN和LSTM深度学习架构与KNN、XGB传统机器学习算法，采用集成投票机制，结合深度网络的表征能力和传统模型的解释性及效率。

Result: 在两个公开Kaggle数据集上，模型在数据集I达到82.30%准确率，数据集II达到97.10%准确率，在精确率、召回率和F1分数上均有稳定提升。

Conclusion: 混合AI框架在心血管疾病预测中展现出稳健性和临床潜力，支持早期干预，同时支持联合国可持续发展目标3（良好健康与福祉），通过创新数据驱动的医疗解决方案促进非传染性疾病的早期诊断、预防和管理。

Abstract: Cardiovascular disease (CVD) remains the foremost cause of mortality worldwide, underscoring the urgent need for intelligent and data-driven diagnostic tools. Traditional predictive models often struggle to generalize across heterogeneous datasets and complex physiological patterns. To address this, we propose a hybrid ensemble framework that integrates deep learning architectures, Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM), with classical machine learning algorithms, including K-Nearest Neighbor (KNN) and Extreme Gradient Boosting (XGB), using an ensemble voting mechanism. This approach combines the representational power of deep networks with the interpretability and efficiency of traditional models. Experiments on two publicly available Kaggle datasets demonstrate that the proposed model achieves superior performance, reaching 82.30 percent accuracy on Dataset I and 97.10 percent on Dataset II, with consistent gains in precision, recall, and F1-score. These findings underscore the robustness and clinical potential of hybrid AI frameworks for predicting cardiovascular disease and facilitating early intervention. Furthermore, this study directly supports the United Nations Sustainable Development Goal 3 (Good Health and Well-being) by promoting early diagnosis, prevention, and management of non-communicable diseases through innovative, data-driven healthcare solutions.

</details>


### [303] [Neuro-Symbolic Verification on Instruction Following of LLMs](https://arxiv.org/abs/2601.17789)
*Yiming Su,Kunzhao Xu,Yanjie Gao,Fan Yang,Cheng Li,Mao Yang,Tianyin Xu*

Main category: cs.AI

TL;DR: NSVIF是一个神经符号框架，用于验证LLM输出是否遵循指令，将指令遵循验证建模为约束满足问题，显著优于基于LLM的方法并提供可解释反馈。


<details>
  <summary>Details</summary>
Motivation: LLM不总是遵循指令，这在重要应用中可能导致任务失败和系统事故，特别是在基于LLM的代理工作流中，违规行为会沿推理链传播放大。

Method: NSVIF将指令遵循验证建模为约束满足问题，将用户指令建模为约束（包括逻辑和语义约束），通过统一求解器协调逻辑推理和语义分析。

Result: 在VIFBENCH基准测试中，NSVIF显著优于基于LLM的方法，提供可解释反馈，且NSVIF的反馈无需后训练即可帮助提高LLM的指令遵循能力。

Conclusion: NSVIF是一个通用、通用的指令遵循验证框架，能有效检测LLM输出是否遵循指令，为LLM应用提供可靠的安全保障。

Abstract: A fundamental problem of applying Large Language Models (LLMs) to important applications is that LLMs do not always follow instructions, and violations are often hard to observe or check. In LLM-based agentic workflows, such violations can propagate and amplify along reasoning chains, causing task failures and system incidents. This paper presents NSVIF, a neuro-symbolic framework for verifying whether an LLM's output follows the instructions used to prompt the LLM. NSVIF is a universal, general-purpose verifier; it makes no assumption about the instruction or the LLM. NSVIF formulates instruction-following verification as a constraint-satisfaction problem by modeling user instructions as constraints. NSVIF models both logical and semantic constraints; constraint solving is done by a unified solver that orchestrates logical reasoning and semantic analysis. To evaluate NSVIF, we develop VIFBENCH, a new benchmark for instruction-following verifiers with fine-grained data labels. Experiments show that NSVIF significantly outperforms LLM-based approaches and provides interpretable feedback. We also show that feedback from NSVIF helps improve LLMs' instruction-following capability without post-training.

</details>


### [304] [MMR-Bench: A Comprehensive Benchmark for Multimodal LLM Routing](https://arxiv.org/abs/2601.17814)
*Haoxuan Ma,Guannan Lai,Han-Jia Ye*

Main category: cs.AI

TL;DR: MMR-Bench是一个用于评估多模态大语言模型路由策略的基准测试，旨在解决不同MLLM模型在计算成本和性能上的异构性问题，通过智能路由实现成本与精度的平衡。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在架构、对齐策略和效率上存在异质性，导致单一模型无法在所有任务上表现最优。实际部署中，工作负载从轻量级OCR到复杂多模态推理不等，使用单一模型要么在简单任务上过度计算，要么在困难任务上牺牲精度。需要建立标准化的预算感知评估基准来解决多模态路由问题。

Method: 提出了MMR-Bench基准测试，包含：(1) 具有模态感知输入和可变计算预算的受控环境；(2) 涵盖OCR、通用VQA和多模态数学推理的广泛视觉语言任务套件；(3) 强单模型参考、理论上界和代表性路由策略。通过该基准评估多模态信号对路由质量的影响。

Result: 实验表明，融入多模态信号能提升路由质量，改善成本-精度边界。路由系统能以最强单模型约33%的成本超越其精度。在部分模型和任务上训练的策略能零样本泛化到新数据集和纯文本基准，无需重新调优。

Conclusion: MMR-Bench为研究自适应多模态模型选择和高效MLLM部署提供了基础框架，证明了智能路由在平衡多模态任务计算成本与性能方面的有效性。

Abstract: Multimodal large language models (MLLMs) have advanced rapidly, yet heterogeneity in architecture, alignment strategies, and efficiency means that no single model is uniformly superior across tasks. In practical deployments, workloads span lightweight OCR to complex multimodal reasoning; using one MLLM for all queries either over-provisions compute on easy instances or sacrifices accuracy on hard ones. Query-level model selection (routing) addresses this tension, but extending routing from text-only LLMs to MLLMs is nontrivial due to modality fusion, wide variation in computational cost across models, and the absence of a standardized, budget-aware evaluation. We present MMR-Bench, a unified benchmark that isolates the multimodal routing problem and enables comparison under fixed candidate sets and cost models. MMR-Bench provides (i) a controlled environment with modality-aware inputs and variable compute budgets, (ii) a broad suite of vision-language tasks covering OCR, general VQA, and multimodal math reasoning, and (iii) strong single-model reference, oracle upper bounds, and representative routing policies. Using MMR-Bench, we show that incorporating multimodal signals improves routing quality. Empirically, these cues improve the cost-accuracy frontier and enable the routed system to exceed the strongest single model's accuracy at roughly 33% of its cost. Furthermore, policies trained on a subset of models and tasks generalize zero-shot to new datasets and text-only benchmarks without retuning, establishing MMR-Bench as a foundation for studying adaptive multimodal model selection and efficient MLLM deployment. The code will be available at: https://github.com/Hunter-Wrynn/MMR-Bench.

</details>


### [305] [RegGuard: AI-Powered Retrieval-Enhanced Assistant for Pharmaceutical Regulatory Compliance](https://arxiv.org/abs/2601.17826)
*Siyuan Yang,Xihan Bian,Jiayin Tang*

Main category: cs.AI

TL;DR: RegGuard是一个工业级AI助手，用于自动化解读异构监管文本并与公司内部政策对齐，通过HiSACC和ReLACE组件提高检索和生成质量，显著减少幻觉风险。


<details>
  <summary>Details</summary>
Motivation: 监管更新日益频繁复杂，跨国药企合规团队需要手动解读不同司法管辖区、格式和机构的规则，成本高且易出错。

Method: 系统通过安全管道摄入异构文档，采用HiSACC（分层语义聚合）将长文档语义分割为连贯单元，使用ReLACE（监管列表自适应交叉编码器）基于开源模型改进排名相关性，架构支持可审计性和可追溯性。

Result: 企业环境评估显示，RegGuard在相关性、基础性和上下文聚焦方面提高回答质量，同时显著减轻幻觉风险。

Conclusion: RegGuard为具有严格合规要求的领域提供了响应性强、可审计的解决方案，能够有效应对不断变化的监管环境。

Abstract: The increasing frequency and complexity of regulatory updates present a significant burden for multinational pharmaceutical companies. Compliance teams must interpret evolving rules across jurisdictions, formats, and agencies, often manually, at high cost and risk of error. We introduce RegGuard, an industrial-scale AI assistant designed to automate the interpretation of heterogeneous regulatory texts and align them with internal corporate policies. The system ingests heterogeneous document sources through a secure pipeline and enhances retrieval and generation quality with two novel components: HiSACC (Hierarchical Semantic Aggregation for Contextual Chunking) semantically segments long documents into coherent units while maintaining consistency across non-contiguous sections. ReLACE (Regulatory Listwise Adaptive Cross-Encoder for Reranking), a domain-adapted cross-encoder built on an open-source model, jointly models user queries and retrieved candidates to improve ranking relevance. Evaluations in enterprise settings demonstrate that RegGuard improves answer quality specifically in terms of relevance, groundedness, and contextual focus, while significantly mitigating hallucination risk. The system architecture is built for auditability and traceability, featuring provenance tracking, access control, and incremental indexing, making it highly responsive to evolving document sources and relevant for any domain with stringent compliance demands.

</details>


### [306] [Aligning Medical Conversational AI through Online Reinforcement Learning with Information-Theoretic Rewards](https://arxiv.org/abs/2601.17828)
*Tanvi Verma,Yang Zhou,Rick Siow Mong Goh,Yong Liu*

Main category: cs.AI

TL;DR: 提出IGFT方法，通过信息增益奖励和在线强化学习训练医疗对话AI，无需人类对话数据即可进行患者访谈并生成完整病史


<details>
  <summary>Details</summary>
Motivation: 现有医疗对话AI方法依赖昂贵的人工标注对话或静态数据集，需要一种能够自主学习有效提问策略的方法，无需预先收集人类对话

Method: 结合在线组相对策略优化(GRPO)和信息论奖励，使用信息增益奖励函数跟踪临床实体（症状、时间模式、病史）的揭示情况，结合GPT-4o-mini质量评估，通过LoRA微调Llama-3.1-8B-Instruct和DeepSeek-R1-Distill-Qwen-7B模型

Result: DeepSeek-R1-Distill-Qwen-7B在Avey数据集上F1得分为0.408（比基线提升10.9%），在MIMIC数据集上为0.289（提升12.9%）；Llama-3.1-8B-Instruct分别达到0.384和0.336，均优于OpenAI模型和医疗领域基线模型

Conclusion: IGFT方法有效训练医疗对话AI进行患者访谈，无需人类对话数据，通过信息增益奖励使模型学习提出有针对性的临床问题，在多个数据集上优于现有方法

Abstract: We present Information Gain Fine-Tuning (IGFT), a novel approach for training medical conversational AI to conduct effective patient interviews and generate comprehensive History of Present Illness (HPI) without requiring pre-collected human conversations. IGFT combines online Group Relative Policy Optimization (GRPO) with information-theoretic rewards, enabling models to learn from self-generated conversations with simulated patients. Unlike existing approaches that rely on expensive expert-annotated conversations or static datasets, our online RL framework allows models to discover effective questioning strategies through exploration. Our key innovation is an information gain reward function that tracks which clinical entities such as symptoms, temporal patterns, and medical history, are revealed during conversation. Each question's reward is computed based on its expected information gain combined with GPT-4o-mini quality assessments across dimensions including clinical relevance, patient engagement, and specificity. This hybrid approach ensures models learn to ask targeted, clinically appropriate questions that efficiently gather diagnostic information. We fine-tune two models using LoRA: Llama-3.1-8B-Instruct and DeepSeek-R1-Distill-Qwen-7B (a reasoning-optimized model). Training exclusively on Avey data containing concise HPIs, we evaluate generalization to MIMIC data with longer, more elaborate HPIs. DeepSeek-R1-Distill-Qwen-7B (IGFT) achieves F1 scores of 0.408 on Avey (10.9% improvement over base) and 0.289 on MIMIC (12.9% improvement), while Llama-3.1-8B-Instruct (IGFT) reaches 0.384 and 0.336 respectively. Both models outperform OpenAI's model on MIMIC and surpass medical domain-specific baselines like HuatuoGPT and UltraMedical, which were optimized for single-turn medical QA rather than multi-turn conversations.

</details>


### [307] [When Personalization Legitimizes Risks: Uncovering Safety Vulnerabilities in Personalized Dialogue Agents](https://arxiv.org/abs/2601.17887)
*Jiahe Guo,Xiangran Guo,Yulin Hu,Zimo Long,Xingyu Sui,Xuda Zhi,Yongbo Huang,Hao He,Weixiang Zhao,Yanyan Zhao,Bing Qin*

Main category: cs.AI

TL;DR: 个性化LLM代理中的长期记忆可能导致安全漏洞：良性个人记忆会偏倚意图推断，使模型将有害查询合法化，攻击成功率提升15.8%-243.7%


<details>
  <summary>Details</summary>
Motivation: 现有个性化代理研究主要关注实用性和用户体验，将记忆视为中性组件，忽视了其安全影响。本文旨在揭示"意图合法化"这一被忽视的安全失效模式，即良性个人记忆如何导致模型将有害查询合法化

Method: 1) 提出PS-Bench基准测试，用于识别和量化个性化交互中的意图合法化现象；2) 在多个记忆增强代理框架和基础LLM上进行实验；3) 从内部表示空间提供机制性证据；4) 提出轻量级检测-反思方法

Result: 个性化使攻击成功率相对无状态基线增加15.8%-243.7%。通过内部表示分析提供了意图合法化的机制证据，提出的检测-反思方法能有效减少安全退化

Conclusion: 首次系统探索和评估了意图合法化这一安全失效模式，表明良性、真实的个性化会自然产生安全风险，强调在长期个性化背景下评估安全性的重要性

Abstract: Long-term memory enables large language model (LLM) agents to support personalized and sustained interactions. However, most work on personalized agents prioritizes utility and user experience, treating memory as a neutral component and largely overlooking its safety implications. In this paper, we reveal intent legitimation, a previously underexplored safety failure in personalized agents, where benign personal memories bias intent inference and cause models to legitimize inherently harmful queries. To study this phenomenon, we introduce PS-Bench, a benchmark designed to identify and quantify intent legitimation in personalized interactions. Across multiple memory-augmented agent frameworks and base LLMs, personalization increases attack success rates by 15.8%-243.7% relative to stateless baselines. We further provide mechanistic evidence for intent legitimation from internal representations space, and propose a lightweight detection-reflection method that effectively reduces safety degradation. Overall, our work provides the first systematic exploration and evaluation of intent legitimation as a safety failure mode that naturally arises from benign, real-world personalization, highlighting the importance of assessing safety under long-term personal context. WARNING: This paper may contain harmful content.

</details>


### [308] [UniCog: Uncovering Cognitive Abilities of LLMs through Latent Mind Space Analysis](https://arxiv.org/abs/2601.17897)
*Jiayu Liu,Yinhe Long,Zhenya Huang,Enhong Chen*

Main category: cs.AI

TL;DR: UniCog是一个通过潜在心智空间分析LLM认知的统一框架，将密集模型激活编码为稀疏解耦的潜在维度，揭示了LLM认知的帕累托原则，并利用潜在激活异常检测推理失败，最终通过潜在信息候选优先级策略提升推理性能7.5%。


<details>
  <summary>Details</summary>
Motivation: 现有可解释性方法在解释LLM推理过程中如何运用认知能力方面存在局限，而研究表明LLM的认知过程与人类存在根本差异，需要新的分析框架来理解LLM的认知机制。

Method: 提出UniCog统一框架，采用潜在变量模型，将密集模型激活编码为稀疏解耦的潜在维度，构建潜在心智空间来分析LLM认知。对包括DeepSeek-V3.2和GPT-4o在内的六个先进LLM进行广泛分析。

Result: 揭示了LLM认知的帕累托原则：共享推理核心与能力特定特征互补；发现推理失败常表现为潜在激活的异常强度；提出的潜在信息候选优先级策略在挑战性基准测试中将推理性能提升高达7.5%。

Conclusion: UniCog为LLM分析开辟了新范式，提供了基于认知的推理动态视角，通过潜在心智空间分析能够深入理解LLM的认知机制并有效提升推理性能。

Abstract: A growing body of research suggests that the cognitive processes of large language models (LLMs) differ fundamentally from those of humans. However, existing interpretability methods remain limited in explaining how cognitive abilities are engaged during LLM reasoning. In this paper, we propose UniCog, a unified framework that analyzes LLM cognition via a latent mind space. Formulated as a latent variable model, UniCog encodes diverse abilities from dense model activations into sparse, disentangled latent dimensions. Through extensive analysis on six advanced LLMs, including DeepSeek-V3.2 and GPT-4o, we reveal a Pareto principle of LLM cognition, where a shared reasoning core is complemented by ability-specific signatures. Furthermore, we discover that reasoning failures often manifest as anomalous intensity in latent activations. These findings opens a new paradigm in LLM analysis, providing a cognition grounded view of reasoning dynamics. Finally, leveraging these insights, we introduce a latent-informed candidate prioritization strategy, which improves reasoning performance by up to 7.5% across challenging benchmarks. Our code is available at https://github.com/milksalute/unicog.

</details>


### [309] [Think Locally, Explain Globally: Graph-Guided LLM Investigations via Local Reasoning and Belief Propagation](https://arxiv.org/abs/2601.17915)
*Saurabh Jha,Rohan Arora,Bhavya,Noah Zheutlin,Paulina Toro Isaza,Laura Shwartz,Yu Deng,Daby Sow,Ruchi Mahindru,Ruchir Puri*

Main category: cs.AI

TL;DR: EoG框架通过将调查任务分解为依赖图上的溯因推理，解决了LLM代理在开放调查中的可靠性问题，显著提升了准确性和一致性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理（如ReAct）在处理需要从海量异构数据中迭代挖掘证据的开放调查任务时存在可靠性问题。这些任务具有隐藏的依赖结构，而有限的上下文窗口迫使代理在未知证据重要性时就进行摘要，增加了丢弃关键证据的风险。ReAct风格的代理在此类任务中特别脆弱，其检索-摘要-推理循环使结论对探索顺序敏感，并引入运行间不确定性。

Method: 提出EoG（Explanations over Graphs）框架，将调查任务形式化为依赖图上的溯因推理。该框架将LLM用于有界的局部证据挖掘和标注（原因vs症状），而确定性控制器负责图遍历、状态管理和信念传播，以计算最小解释边界。

Result: 在ITBench诊断任务上，EoG相比ReAct基线在准确性和运行间一致性方面均有提升，包括平均7倍的Majority-at-k实体F1增益。

Conclusion: 通过将语义推理与控制器职责解耦，EoG框架能够更可靠地处理具有隐藏依赖结构的开放调查任务，解决了传统LLM代理在此类任务中的根本局限性。

Abstract: LLM agents excel when environments are mostly static and the needed information fits in a model's context window, but they often fail in open-ended investigations where explanations must be constructed by iteratively mining evidence from massive, heterogeneous operational data. These investigations exhibit hidden dependency structure: entities interact, signals co-vary, and the importance of a fact may only become clear after other evidence is discovered. Because the context window is bounded, agents must summarize intermediate findings before their significance is known, increasing the risk of discarding key evidence. ReAct-style agents are especially brittle in this regime. Their retrieve-summarize-reason loop makes conclusions sensitive to exploration order and introduces run-to-run non-determinism, producing a reliability gap where Pass-at-k may be high but Majority-at-k remains low. Simply sampling more rollouts or generating longer reasoning traces does not reliably stabilize results, since hypotheses cannot be autonomously checked as new evidence arrives and there is no explicit mechanism for belief bookkeeping and revision. In addition, ReAct entangles semantic reasoning with controller duties such as tool orchestration and state tracking, so execution errors and plan drift degrade reasoning while consuming scarce context.
  We address these issues by formulating investigation as abductive reasoning over a dependency graph and proposing EoG (Explanations over Graphs), a disaggregated framework in which an LLM performs bounded local evidence mining and labeling (cause vs symptom) while a deterministic controller manages traversal, state, and belief propagation to compute a minimal explanatory frontier. On a representative ITBench diagnostics task, EoG improves both accuracy and run-to-run consistency over ReAct baselines, including a 7x average gain in Majority-at-k entity F1.

</details>


### [310] [Agentic AI for Self-Driving Laboratories in Soft Matter: Taxonomy, Benchmarks,and Open Challenges](https://arxiv.org/abs/2601.17920)
*Xuanzhou Chen,Audrey Wang,Stanley Yin,Hanyang Jiang,Dong Zhang*

Main category: cs.AI

TL;DR: 这篇综述将自驱动实验室(SDLs)视为智能体与环境交互问题，连接SDL流程与AI原理，回顾贝叶斯优化、主动学习、规划与强化学习等方法，提出能力驱动的分类体系，并总结部署经验与开放挑战。


<details>
  <summary>Details</summary>
Motivation: 自驱动实验室在昂贵操作、噪声延迟反馈、严格约束和非平稳性等挑战下，为智能体AI提供了重要测试平台。本文旨在通过软物质代表性场景，探讨真实实验室中出现的AI问题，建立SDL与AI原理的系统连接。

Method: 将SDL自主性框架化为智能体环境交互问题，回顾贝叶斯优化、主动学习、规划与强化学习等方法家族，提出基于决策视野、不确定性建模、动作参数化等维度的能力驱动分类法，并设计基准任务模板和评估指标。

Result: 建立了SDL与AI原理的系统连接框架，提出了能力驱动的分类体系，设计了强调成本感知性能、漂移鲁棒性、约束违反行为和可重复性的评估指标，为SDL系统比较提供了标准化基础。

Conclusion: SDL为AI在现实约束下的应用提供了重要测试平台，未来挑战包括多模态表示、校准不确定性、安全探索和共享基准基础设施。可验证和溯源感知的策略对调试、可重复性和安全操作至关重要。

Abstract: Self-driving laboratories (SDLs) close the loop between experiment design, automated execution, and data-driven decision making, and they provide a demanding testbed for agentic AI under expensive actions, noisy and delayed feedback, strict feasibility and safety constraints, and non-stationarity. This survey uses soft matter as a representative setting but focuses on the AI questions that arise in real laboratories. We frame SDL autonomy as an agent environment interaction problem with explicit observations, actions, costs, and constraints, and we use this formulation to connect common SDL pipelines to established AI principles. We review the main method families that enable closed loop experimentation, including Bayesian optimization and active learning for sample efficient experiment selection, planning and reinforcement learning for long horizon protocol optimization, and tool using agents that orchestrate heterogeneous instruments and software. We emphasize verifiable and provenance aware policies that support debugging, reproducibility, and safe operation. We then propose a capability driven taxonomy that organizes systems by decision horizon, uncertainty modeling, action parameterization, constraint handling, failure recovery, and human involvement. To enable meaningful comparison, we synthesize benchmark task templates and evaluation metrics that prioritize cost aware performance, robustness to drift, constraint violation behavior, and reproducibility. Finally, we distill lessons from deployed SDLs and outline open challenges in multi-modal representation, calibrated uncertainty, safe exploration, and shared benchmark infrastructure.

</details>


### [311] [Learning Transferable Skills in Action RPGs via Directed Skill Graphs and Selective Adaptation](https://arxiv.org/abs/2601.17923)
*Ali Najar*

Main category: cs.AI

TL;DR: 该论文提出了一种基于技能图的分层课程学习方法，用于在复杂实时环境（黑暗之魂III）中训练终身学习智能体，通过技能分解和选择性微调实现高效适应新环境。


<details>
  <summary>Details</summary>
Motivation: 终身学习智能体需要在不从头训练或覆盖已学行为的情况下随时间扩展能力，这在复杂实时控制环境中尤其具有挑战性。

Method: 将战斗表示为有向技能图，采用分层课程训练五个可重用技能：相机控制、目标锁定、移动、闪避和治疗-攻击决策策略，每个技能针对特定职责优化。

Result: 技能分解提高了样本效率，减少了单个策略的负担。当环境从第一阶段切换到第二阶段时，只需微调部分技能（两个技能）即可快速恢复性能，而上游技能保持可迁移性。

Conclusion: 技能图课程结合选择性微调为复杂实时环境中不断进化的持续学习智能体提供了实用路径，支持高效适应环境变化。

Abstract: Lifelong agents should expand their competence over time without retraining from scratch or overwriting previously learned behaviors. We investigate this in a challenging real-time control setting (Dark Souls III) by representing combat as a directed skill graph and training its components in a hierarchical curriculum. The resulting agent decomposes control into five reusable skills: camera control, target lock-on, movement, dodging, and a heal-attack decision policy, each optimized for a narrow responsibility. This factorization improves sample efficiency by reducing the burden on any single policy and supports selective post-training: when the environment shifts from Phase 1 to Phase 2, only a subset of skills must be adapted, while upstream skills remain transferable. Empirically, we find that targeted fine-tuning of just two skills rapidly recovers performance under a limited interaction budget, suggesting that skill-graph curricula together with selective fine-tuning offer a practical pathway toward evolving, continually learning agents in complex real-time environments.

</details>


### [312] [Sentipolis: Emotion-Aware Agents for Social Simulations](https://arxiv.org/abs/2601.18027)
*Chiyuan Fu,Lyuhao Chen,Yunze Xiao,Weihao Xuan,Carlos Busso,Mona Diab*

Main category: cs.AI

TL;DR: Sentipolis框架为LLM智能体提供情感状态管理，通过PAD情感表示、双速情感动态和情感-记忆耦合，提升社会模拟中的情感连续性和真实性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM智能体在社会模拟中常将情感视为瞬时线索，导致"情感失忆"和长期情感连续性不足，需要更系统的情感状态管理框架。

Method: 提出Sentipolis框架，包含：1) 连续的愉悦-唤醒-支配(PAD)情感表示；2) 双速情感动态（快速变化和缓慢变化）；3) 情感与记忆的耦合机制。

Result: 在数千次交互中，Sentipolis显著提升了情感基础行为、沟通能力和情感连续性。效果因模型而异：高容量模型可信度提升，小模型可能下降；情感意识可能轻微降低社会规范遵从度，反映了情感驱动行为与规则遵守之间的张力。

Conclusion: Sentipolis为LLM智能体提供了有效的情感状态管理，支持研究累积社会动态如联盟形成和关系渐变，揭示了情感意识与社会规范遵从之间的平衡关系。

Abstract: LLM agents are increasingly used for social simulation, yet emotion is often treated as a transient cue, causing emotional amnesia and weak long-horizon continuity. We present Sentipolis, a framework for emotionally stateful agents that integrates continuous Pleasure-Arousal-Dominance (PAD) representation, dual-speed emotion dynamics, and emotion--memory coupling. Across thousands of interactions over multiple base models and evaluators, Sentipolis improves emotionally grounded behavior, boosting communication, and emotional continuity. Gains are model-dependent: believability increases for higher-capacity models but can drop for smaller ones, and emotion-awareness can mildly reduce adherence to social norms, reflecting a human-like tension between emotion-driven behavior and rule compliance in social simulation. Network-level diagnostics show reciprocal, moderately clustered, and temporally stable relationship structures, supporting the study of cumulative social dynamics such as alliance formation and gradual relationship change.

</details>


### [313] [Expert Evaluation and the Limits of Human Feedback in Mental Health AI Safety Testing](https://arxiv.org/abs/2601.18061)
*Kiana Jafari,Paul Ulrich Nikolaus Rust,Duncan Eddy,Robbie Fraser,Nina Vasan,Darja Djordjevic,Akanksha Dadlani,Max Lamparth,Eugenia Kim,Mykel Kochenderfer*

Main category: cs.AI

TL;DR: 专家在AI心理健康安全评估中存在系统性分歧，而非随机误差，这挑战了基于人类反馈学习(LHF)中"专家共识即真理"的假设。


<details>
  <summary>Details</summary>
Motivation: 测试LHF的基本假设：专家判断经过适当聚合后能提供有效的训练和评估基础。在心理健康这一高风险领域，专家共识尤为重要，但这一假设尚未得到验证。

Method: 三位认证精神科医生使用校准的评分标准独立评估LLM生成的心理健康回复。通过ICC和Krippendorff's α等统计方法量化评分者间信度，并进行定性访谈了解分歧原因。

Result: 评分者间信度极低(ICC 0.087-0.295)，低于可接受阈值。在自杀和自伤等最安全关键的类别中分歧最大。分歧是系统性的而非随机的，反映了三种不同的临床框架：安全优先、参与为中心和文化导向。

Conclusion: 专家分歧是原则性的社会技术现象，而非测量误差。聚合标签只是算术妥协，抹杀了专业的哲学基础。建议从基于共识的聚合转向能够保留和学习专家分歧的对齐方法。

Abstract: Learning from human feedback~(LHF) assumes that expert judgments, appropriately aggregated, yield valid ground truth for training and evaluating AI systems. We tested this assumption in mental health, where high safety stakes make expert consensus essential. Three certified psychiatrists independently evaluated LLM-generated responses using a calibrated rubric. Despite similar training and shared instructions, inter-rater reliability was consistently poor ($ICC$ $0.087$--$0.295$), falling below thresholds considered acceptable for consequential assessment. Disagreement was highest on the most safety-critical items. Suicide and self-harm responses produced greater divergence than any other category, and was systematic rather than random. One factor yielded negative reliability (Krippendorff's $α= -0.203$), indicating structured disagreement worse than chance. Qualitative interviews revealed that disagreement reflects coherent but incompatible individual clinical frameworks, safety-first, engagement-centered, and culturally-informed orientations, rather than measurement error. By demonstrating that experts rely on holistic risk heuristics rather than granular factor discrimination, these findings suggest that aggregated labels function as arithmetic compromises that effectively erase grounded professional philosophies. Our results characterize expert disagreement in safety-critical AI as a sociotechnical phenomenon where professional experience introduces sophisticated layers of principled divergence. We discuss implications for reward modeling, safety classification, and evaluation benchmarks, recommending that practitioners shift from consensus-based aggregation to alignment methods that preserve and learn from expert disagreement.

</details>


### [314] [EvolVE: Evolutionary Search for LLM-based Verilog Generation and Optimization](https://arxiv.org/abs/2601.18067)
*Wei-Po Hsin,Ren-Hao Deng,Yao-Ting Hsieh,En-Ming Huang,Shih-Hao Hung*

Main category: cs.AI

TL;DR: EvolVE框架通过结合多种进化策略（MCTS和IGR）和结构化测试平台生成，在Verilog硬件设计自动化中实现了新的SOTA，显著提升了功能正确性和PPA优化。


<details>
  <summary>Details</summary>
Motivation: 传统Verilog设计流程劳动密集且需要大量领域专业知识，而现有LLM方法受限于训练数据和顺序推理能力，难以捕捉硬件系统的形式逻辑和并发特性。

Method: 提出EvolVE框架，分析多种进化策略：MCTS用于最大化功能正确性，Idea-Guided Refinement（IGR）用于优化；采用Structured Testbench Generation（STG）加速进化过程；并引入IC-RTL基准测试套件。

Result: 在VerilogEval v2上达到98.1%，RTLLM v2上达到92%；在IC-RTL行业级基准上，超越竞赛参与者参考实现，Huffman编码PPA降低66%，所有问题几何平均降低17%。

Conclusion: EvolVE框架通过进化策略和结构化方法成功解决了硬件设计自动化的关键挑战，在功能正确性和PPA优化方面均取得显著突破，为行业级硬件设计提供了有效解决方案。

Abstract: Verilog's design cycle is inherently labor-intensive and necessitates extensive domain expertise. Although Large Language Models (LLMs) offer a promising pathway toward automation, their limited training data and intrinsic sequential reasoning fail to capture the strict formal logic and concurrency inherent in hardware systems. To overcome these barriers, we present EvolVE, the first framework to analyze multiple evolution strategies on chip design tasks, revealing that Monte Carlo Tree Search (MCTS) excels at maximizing functional correctness, while Idea-Guided Refinement (IGR) proves superior for optimization. We further leverage Structured Testbench Generation (STG) to accelerate the evolutionary process. To address the lack of complex optimization benchmarks, we introduce IC-RTL, targeting industry-scale problems derived from the National Integrated Circuit Contest. Evaluations establish EvolVE as the new state-of-the-art, achieving 98.1% on VerilogEval v2 and 92% on RTLLM v2. Furthermore, on the industry-scale IC-RTL suite, our framework surpasses reference implementations authored by contest participants, reducing the Power, Performance, Area (PPA) product by up to 66% in Huffman Coding and 17% in the geometric mean across all problems. The source code of the IC-RTL benchmark is available at https://github.com/weiber2002/ICRTL.

</details>


### [315] [Beyond Text-to-SQL: Can LLMs Really Debug Enterprise ETL SQL?](https://arxiv.org/abs/2601.18119)
*Jing Ye,Yiwen Duan,Yonghong Yu,Victor Ma,Yang Gao,Xing Chen*

Main category: cs.AI

TL;DR: OurBench是首个企业级SQL推理与调试基准，包含469个语法错误查询和516个语义错误查询，评估显示当前LLMs在复杂SQL调试任务上表现不佳（最佳模型准确率仅36.46%）。


<details>
  <summary>Details</summary>
Motivation: 企业数据工程中SQL生成困难，即使是经验丰富的开发者和先进LLMs也难以一次生成完全正确的SQL代码，需要多次调试迭代，但缺乏专门的企业级SQL调试基准。

Method: 1) 自动化构建流程：通过逆向工程在大型SQL代码中系统注入真实错误，实现可扩展的多样化基准生成；2) 无执行评估框架：针对企业环境设计，提供快速、准确、资源高效的评估方法。

Result: OurBench包含985个高度复杂查询（平均140+行），评估近30个LLMs显示性能差距显著：最佳模型Claude-4-Sonnet在语法错误上准确率36.46%，语义错误上32.17%，大多数模型低于20%。

Conclusion: 企业SQL调试对LLMs仍是重大挑战，需要更先进的解决方案。论文探索了四种解决策略，识别了关键挑战，并为企业SQL调试的LLMs应用指明了有前景的方向。

Abstract: SQL is central to enterprise data engineering, yet generating fully correct SQL code in a single attempt remains difficult, even for experienced developers and advanced text-to-SQL LLMs, often requiring multiple debugging iterations. We introduce OurBench, the first benchmark for enterprise-level SQL reasoning and debugging. Our benchmark is built on two key innovations: (1) an automated construction workflow that uses reverse engineering to systematically inject realistic bugs into large-scale SQL code, enabling scalable and diverse benchmark generation; and (2) an execution-free evaluation framework tailored to enterprise settings, providing fast, accurate, and resource-efficient assessment.
  OurBench comprises 469 OurBenchSyn queries featuring syntax errors with explicit error messages, and 516 OurBenchSem queries targeting semantic errors in which the code fails to meet user intent. The queries are highly complex, averaging over 140 lines and featuring deep and wide abstract syntax trees.
  Evaluation of nearly 30 LLMs reveals a substantial performance gap: the best-performing model, Claude-4-Sonnet, achieves only 36.46 percent accuracy on OurBenchSyn and 32.17 percent on OurBenchSem, while most models score below 20 percent. We further explore four solution strategies, identify key challenges, and outline promising directions for enterprise SQL debugging with LLMs.

</details>


### [316] [Deadline-Aware, Energy-Efficient Control of Domestic Immersion Hot Water Heaters](https://arxiv.org/abs/2601.18123)
*Muhammad Ibrahim Khan,Bivin Pradeep,James Brusey*

Main category: cs.AI

TL;DR: 论文研究了家用浸入式热水器的截止时间感知控制，通过强化学习（PPO）方法在指定时间内达到目标温度的同时最小化能耗，相比传统bang-bang控制和MCTS规划器，PPO实现了26-69%的节能效果。


<details>
  <summary>Details</summary>
Motivation: 传统家用浸入式热水器在冬季通常连续运行，加热速度快但效率低，忽视了可预测的需求窗口和环境热损失。需要一种能在指定截止时间达到目标温度的同时最小化能耗的控制方法。

Method: 建立了Gymnasium环境模拟浸入式热水器，采用一阶热损失模型和每120秒切换的0W/6000W离散控制动作。比较了三种方法：时间最优的bang-bang基线控制、零样本蒙特卡洛树搜索规划器和近端策略优化强化学习策略。

Result: 在2小时（60步）的时间范围内，PPO仅消耗3.23千瓦时，而bang-bang控制消耗4.37-10.45千瓦时，MCTS消耗4.18-6.46千瓦时。PPO相比bang-bang控制节能26%（30步）到69%（90步）。在典型场景中，PPO比bang-bang控制节能54%，比MCTS节能33%。

Conclusion: 学习到的截止时间感知控制能在相同物理假设下显著降低能耗，规划器无需训练即可提供部分节能效果，而学习策略一旦训练完成，推理成本几乎为零，具有实际应用价值。

Abstract: Typical domestic immersion water heater systems are often operated continuously during winter, heating quickly rather than efficiently and ignoring predictable demand windows and ambient losses. We study deadline-aware control, where the aim is to reach a target temperature at a specified time while minimising energy consumption. We introduce an efficient Gymnasium environment that models an immersion hot water heater with first-order thermal losses and discrete on and off actions of 0 W and 6000 W applied every 120 seconds. Methods include a time-optimal bang-bang baseline, a zero-shot Monte Carlo Tree Search planner, and a Proximal Policy Optimisation policy. We report total energy consumption in watt-hours under identical physical dynamics. Across sweeps of initial temperature from 10 to 30 degrees Celsius, deadline from 30 to 90 steps, and target temperature from 40 to 80 degrees Celsius, PPO achieves the most energy-efficient performance at a 60-step horizon of 2 hours, using 3.23 kilowatt-hours, compared to 4.37 to 10.45 kilowatt-hours for bang-bang control and 4.18 to 6.46 kilowatt-hours for MCTS. This corresponds to energy savings of 26 percent at 30 steps and 69 percent at 90 steps. In a representative trajectory with a 50 kg water mass, 20 degrees Celsius ambient temperature, and a 60 degrees Celsius target, PPO consumes 54 percent less energy than bang-bang control and 33 percent less than MCTS. These results show that learned deadline-aware control reduces energy consumption under identical physical assumptions, while planners provide partial savings without training and learned policies offer near-zero inference cost once trained.

</details>


### [317] [RouteMoA: Dynamic Routing without Pre-Inference Boosts Efficient Mixture-of-Agents](https://arxiv.org/abs/2601.18130)
*Jize Wang,Han Wu,Zhiyuan You,Yiming Song,Yijun Wang,Zifei Shan,Yining Li,Songyang Zhang,Xinyi Le,Cailian Chen,Xinping Guan,Dacheng Tao*

Main category: cs.AI

TL;DR: RouteMoA通过动态路由机制优化MoA框架，使用轻量级评分器预筛选模型，混合评估器精调分数，平衡性能、成本和延迟，显著降低开销。


<details>
  <summary>Details</summary>
Motivation: 现有MoA方法采用密集拓扑结构导致成本和延迟过高，LLM法官方法仍需所有模型推理后才能筛选，无法有效降低成本，且缺乏模型选择标准，在大规模模型池中面临上下文限制问题。

Method: 1) 轻量级评分器基于查询预测粗略性能，预筛选高潜力候选模型子集；2) 混合评估器通过轻量级自评估和交叉评估精调分数；3) 模型排名机制平衡性能、成本和延迟进行最终选择。

Result: RouteMoA在不同任务和模型池规模下均优于MoA，在大规模模型池中降低成本89.8%，减少延迟63.6%。

Conclusion: RouteMoA通过动态路由机制有效解决了MoA框架的成本和延迟问题，实现了性能与效率的良好平衡，为大规模模型协作提供了实用解决方案。

Abstract: Mixture-of-Agents (MoA) improves LLM performance through layered collaboration, but its dense topology raises costs and latency. Existing methods employ LLM judges to filter responses, yet still require all models to perform inference before judging, failing to cut costs effectively. They also lack model selection criteria and struggle with large model pools, where full inference is costly and can exceed context limits. To address this, we propose RouteMoA, an efficient mixture-of-agents framework with dynamic routing. It employs a lightweight scorer to perform initial screening by predicting coarse-grained performance from the query, narrowing candidates to a high-potential subset without inference. A mixture of judges then refines these scores through lightweight self- and cross-assessment based on existing model outputs, providing posterior correction without additional inference. Finally, a model ranking mechanism selects models by balancing performance, cost, and latency. RouteMoA outperforms MoA across varying tasks and model pool sizes, reducing cost by 89.8% and latency by 63.6% in the large-scale model pool.

</details>


### [318] [RareAlert: Aligning heterogeneous large language model reasoning for early rare disease risk screening](https://arxiv.org/abs/2601.18132)
*Xi Chen,Hongru Zhou,Huahui Yi,Shiyu Feng,Hanyu Zhou,Tiancheng He,Mingke You,Li Wang,Qiankun Li,Kun Wang,Weili Fu,Kang Li,Jian Li*

Main category: cs.AI

TL;DR: RareAlert是一个基于LLM推理校准的罕见病早期筛查系统，通过整合多个大语言模型的医疗推理信号，训练出可在本地部署的单一模型，在罕见病风险预测上达到0.917 AUC，优于现有最佳机器学习方法和所有评估的LLM。


<details>
  <summary>Details</summary>
Motivation: 罕见病的漏诊和延迟诊断是重大临床挑战。现有初级医疗分诊流程在初次就诊时难以可靠识别罕见病患者，需要一种通用筛查方法来减少诊断延迟。目前缺乏基于常规初级就诊信息的患者级罕见病风险评估系统。

Method: 开发了RareAlert系统：1) 整合10个LLM生成的推理信号；2) 使用机器学习校准和加权这些信号；3) 将对齐的推理提炼成单一可本地部署的模型。使用RareBench数据集（158,666个病例，覆盖33个Orphanet疾病类别和7000+罕见病）进行开发和评估。

Result: RareAlert（基于Qwen3-4B训练）在独立测试集上达到0.917 AUC，优于最佳机器学习集成方法和所有评估的LLM（包括GPT-5、DeepSeek-R1、Claude-3.7-Sonnet等）。证明罕见病识别可重新概念化为对普通患者群体的通用不确定性解决过程。

Conclusion: LLM在医疗推理中存在多样性，通过校准对齐这种推理在高度不确定的临床任务中有效。RareAlert通过将校准推理整合到单一模型中，实现了准确、隐私保护、可扩展的罕见病风险筛查，适合大规模本地部署。

Abstract: Missed and delayed diagnosis remains a major challenge in rare disease care. At the initial clinical encounters, physicians assess rare disease risk using only limited information under high uncertainty. When high-risk patients are not recognised at this stage, targeted diagnostic testing is often not initiated, resulting in missed diagnosis. Existing primary care triage processes are structurally insufficient to reliably identify patients with rare diseases at initial clinical presentation and universal screening is needed to reduce diagnostic delay. Here we present RareAlert, an early screening system which predict patient-level rare disease risk from routinely available primary-visit information. RareAlert integrates reasoning generated by ten LLMs, calibrates and weights these signals using machine learning, and distils the aligned reasoning into a single locally deployable model. To develop and evaluate RareAlert, we curated RareBench, a real-world dataset of 158,666 cases covering 33 Orphanet disease categories and more than 7,000 rare conditions, including both rare and non-rare presentations. The results showed that rare disease identification can be reconceptualised as a universal uncertainty resolution process applied to the general patient population. On an independent test set, RareAlert, a Qwen3-4B based model trained with calibrated reasoning signals, achieved an AUC of 0.917, outperforming the best machine learning ensemble and all evaluated LLMs, including GPT-5, DeepSeek-R1, Claude-3.7-Sonnet, o3-mini, Gemini-2.5-Pro, and Qwen3-235B. These findings demonstrate the diversity in LLM medical reasoning and the effectiveness of aligning such reasoning in highly uncertain clinical tasks. By incorporating calibrated reasoning into a single model, RareAlert enables accurate, privacy-preserving, and scalable rare disease risk screening suitable for large-scale local deployment.

</details>


### [319] [DeepPlanning: Benchmarking Long-Horizon Agentic Planning with Verifiable Constraints](https://arxiv.org/abs/2601.18137)
*Yinger Zhang,Shutong Jiang,Renhao Li,Jianhong Tu,Yang Su,Lianghao Deng,Xudong Guo,Chenxu Lv,Junyang Lin*

Main category: cs.AI

TL;DR: DeepPlanning是一个针对实际长时程智能体规划的挑战性基准测试，包含多日旅行规划和多产品购物任务，要求主动信息获取、局部约束推理和全局约束优化，前沿智能体LLM在此基准上表现不佳。


<details>
  <summary>Details</summary>
Motivation: 当前智能体评估虽然转向长时程任务，但大多数基准测试仍侧重于局部、步骤级推理，而非需要真正规划能力的全局约束优化（如时间和财务预算）。同时，现有LLM规划基准未能充分体现现实世界中典型的主动信息收集和细粒度局部约束。

Method: 提出DeepPlanning基准，包含多日旅行规划和多产品购物两类任务，这些任务需要：1）主动信息获取；2）局部约束推理；3）全局约束优化。通过该基准评估前沿智能体LLM的性能。

Result: 评估显示，即使是前沿的智能体LLM在这些问题上也表现不佳，突显了可靠的显式推理模式和并行工具使用对于实现更好的效果-效率权衡的重要性。错误分析为进一步改进长时程规划提供了方向。

Conclusion: DeepPlanning基准填补了现有规划评估的空白，揭示了当前智能体LLM在实用长时程规划方面的局限性，并为未来研究提供了有前景的改进方向。作者开源了代码和数据以支持后续研究。

Abstract: While agent evaluation has shifted toward long-horizon tasks, most benchmarks still emphasize local, step-level reasoning rather than the global constrained optimization (e.g., time and financial budgets) that demands genuine planning ability. Meanwhile, existing LLM planning benchmarks underrepresent the active information gathering and fine-grained local constraints typical of real-world settings. To address this, we introduce DeepPlanning, a challenging benchmark for practical long-horizon agent planning. It features multi-day travel planning and multi-product shopping tasks that require proactive information acquisition, local constrained reasoning, and global constrained optimization. Evaluations on DeepPlanning show that even frontier agentic LLMs struggle with these problems, highlighting the importance of reliable explicit reasoning patterns and parallel tool use for achieving better effectiveness-efficiency trade-offs. Error analysis further points to promising directions for improving agentic LLMs over long planning horizons. We open-source the code and data to support future research.

</details>


### [320] [Success Conditioning as Policy Improvement: The Optimization Problem Solved by Imitating Success](https://arxiv.org/abs/2601.18175)
*Daniel Russo*

Main category: cs.AI

TL;DR: 成功条件化（success conditioning）精确解决了信任区域优化问题，最大化策略改进同时受χ²散度约束，约束半径由数据自动确定。


<details>
  <summary>Details</summary>
Motivation: 成功条件化（如拒绝采样+SFT、目标条件RL、决策变换器）被广泛用于改进策略，但其解决的优化问题本质一直不明确。本文旨在揭示其数学基础。

Method: 通过理论证明，将成功条件化形式化为信任区域优化问题，最大化策略改进同时约束χ²散度。提出相对策略改进、策略变化幅度和动作影响三者相等的恒等式。

Result: 成功条件化是保守的改进算子，不会降低性能或引发危险的分布偏移。失败时会通过几乎不改变策略来可观察地失败。应用于回报阈值化时，可能放大改进但可能偏离真实目标。

Conclusion: 成功条件化解决了明确的优化问题，是安全可靠的策略改进方法。其理论框架为理解多种相关技术提供了统一视角，并揭示了回报阈值化的潜在风险。

Abstract: A widely used technique for improving policies is success conditioning, in which one collects trajectories, identifies those that achieve a desired outcome, and updates the policy to imitate the actions taken along successful trajectories. This principle appears under many names -- rejection sampling with SFT, goal-conditioned RL, Decision Transformers -- yet what optimization problem it solves, if any, has remained unclear. We prove that success conditioning exactly solves a trust-region optimization problem, maximizing policy improvement subject to a $χ^2$ divergence constraint whose radius is determined automatically by the data. This yields an identity: relative policy improvement, the magnitude of policy change, and a quantity we call action-influence -- measuring how random variation in action choices affects success rates -- are exactly equal at every state. Success conditioning thus emerges as a conservative improvement operator. Exact success conditioning cannot degrade performance or induce dangerous distribution shift, but when it fails, it does so observably, by hardly changing the policy at all. We apply our theory to the common practice of return thresholding, showing this can amplify improvement, but at the cost of potential misalignment with the true objective.

</details>


### [321] [GAIA: A Data Flywheel System for Training GUI Test-Time Scaling Critic Models](https://arxiv.org/abs/2601.18197)
*Shaokang Wang,Pei Fu,Ruoceng Zhang,Shaojie Zhang,Xiuwen Xi,Jiahui Yang,Bin Qin,Ying Huang,Zhenbo Luo,Jian Luan*

Main category: cs.AI

TL;DR: GAIA框架通过训练直觉批判模型来提升GUI代理的测试时性能，通过数据飞轮实现自我改进循环


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型虽然提升了GUI代理的能力，但操作不可逆性导致单个错误动作可能引发灾难性偏差，需要解决这一问题

Method: 提出GAIA训练框架，首先用基础代理的正负动作示例训练直觉批判模型，该模型评估动作即时正确性；然后批判模型指导代理收集精炼样本，启动自我改进循环；增强数据训练第二轮批判模型

Result: 实验表明ICM能提升各种闭源和开源模型的测试时性能，且随着数据循环性能逐步提升

Conclusion: GAIA框架通过数据飞轮机制实现了GUI代理的自我改进，解决了操作不可逆性问题，代码和数据集将公开

Abstract: While Large Vision-Language Models (LVLMs) have significantly advanced GUI agents' capabilities in parsing textual instructions, interpreting screen content, and executing tasks, a critical challenge persists: the irreversibility of agent operations, where a single erroneous action can trigger catastrophic deviations. To address this, we propose the GUI Action Critic's Data Flywheel System (GAIA), a training framework that enables the models to have iterative critic capabilities, which are used to improve the Test-Time Scaling (TTS) of basic GUI agents' performance. Specifically, we train an Intuitive Critic Model (ICM) using positive and negative action examples from a base agent first. This critic evaluates the immediate correctness of the agent's intended actions, thereby selecting operations with higher success probability. Then, the initial critic guides agent actions to collect refined positive/negative samples, initiating the self-improving cycle. The augmented data then trains a second-round critic with enhanced discernment capability. We conduct experiments on various datasets and demonstrate that the proposed ICM can improve the test-time performance of various closed-source and open-source models, and the performance can be gradually improved as the data is recycled. The code and dataset will be publicly released.

</details>


### [322] [SAGE: Steerable Agentic Data Generation for Deep Search with Execution Feedback](https://arxiv.org/abs/2601.18202)
*Fangyuan Xu,Rujun Han,Yanfei Chen,Zifeng Wang,I-Hung Hsu,Jun Yan,Vishy Tirumalashetty,Eunsol Choi,Tomas Pfister,Chen-Yu Lee*

Main category: cs.AI

TL;DR: SAGE：一个自动生成高质量、难度可控的深度搜索问答对的智能体管道，通过生成器和搜索代理的交互迭代优化数据，显著提升深度搜索代理性能


<details>
  <summary>Details</summary>
Motivation: 深度搜索代理需要跨多文档推理的复杂问题，但人工标注成本过高，因为探索轨迹长且复杂。需要自动化方法生成高质量、难度可控的训练数据。

Method: 提出SAGE管道，包含数据生成器（提出QA对）和搜索代理（尝试解决问题并提供执行反馈）。两个组件通过多轮交互迭代优化问答对，直到达到目标难度水平。

Result: 内在评估显示SAGE生成的问题需要多样推理策略，同时显著提高生成数据的正确性和难度。外在评估表明在流行深度搜索基准上获得高达23%的相对性能提升。额外实验显示，用该数据训练的代理可以在推理时从固定语料库检索适应到Google搜索，无需进一步训练。

Conclusion: SAGE能够自动生成高质量、难度可控的深度搜索训练数据，显著提升深度搜索代理性能，并展示出良好的适应性，为解决人工标注成本高昂的问题提供了有效方案。

Abstract: Deep search agents, which aim to answer complex questions requiring reasoning across multiple documents, can significantly speed up the information-seeking process. Collecting human annotations for this application is prohibitively expensive due to long and complex exploration trajectories. We propose an agentic pipeline that automatically generates high quality, difficulty-controlled deep search question-answer pairs for a given corpus and a target difficulty level. Our pipeline, SAGE, consists of a data generator which proposes QA pairs and a search agent which attempts to solve the generated question and provide execution feedback for the data generator. The two components interact over multiple rounds to iteratively refine the question-answer pairs until they satisfy the target difficulty level. Our intrinsic evaluation shows SAGE generates questions that require diverse reasoning strategies, while significantly increases the correctness and difficulty of the generated data. Our extrinsic evaluation demonstrates up to 23% relative performance gain on popular deep search benchmarks by training deep search agents with our synthetic data. Additional experiments show that agents trained on our data can adapt from fixed-corpus retrieval to Google Search at inference time, without further training.

</details>


### [323] [Paying Less Generalization Tax: A Cross-Domain Generalization Study of RL Training for LLM Agents](https://arxiv.org/abs/2601.18217)
*Zhihan Liu,Lin Guan,Yixin Nie,Kai Zhang,Zhuoqun Hao,Lin Chen,Asli Celikyilmaz,Zhaoran Wang,Na Zhang*

Main category: cs.AI

TL;DR: 研究LLM智能体在未知测试域中的泛化能力，发现状态信息丰富度和规划复杂度是影响跨域泛化的关键因素，并提出增加干扰性非目标特征来提升泛化能力。


<details>
  <summary>Details</summary>
Motivation: 通用LLM智能体通常在狭窄环境集上进行后训练，但部署在更广泛的未见领域。本研究旨在探索当最终测试域未知时，哪些环境和建模因素对跨域性能影响最大。

Method: 1) 识别与跨域泛化强相关的环境轴：状态信息丰富度和规划复杂度；2) 提出随机化技术：在状态中添加少量干扰性非目标特征来增加信息丰富度；3) 分析建模选择：SFT预热/中期训练的影响，以及逐步思考在RL中的作用。

Result: 1) 状态信息丰富度和规划复杂度是跨域泛化的关键因素，而非领域真实性或文本相似性；2) 增加状态信息丰富度能有效提升跨域鲁棒性；3) SFT预热有助于防止灾难性遗忘但会损害未包含域的泛化；4) 逐步思考在RL中虽不总能提升域内性能，但对保持泛化至关重要。

Conclusion: 跨域泛化主要受状态信息丰富度和规划复杂度影响，通过增加干扰性特征可提升泛化能力。建模选择中，SFT预热和逐步思考对泛化有不同影响，需权衡使用。

Abstract: Generalist LLM agents are often post-trained on a narrow set of environments but deployed across far broader, unseen domains. In this work, we investigate the challenge of agentic post-training when the eventual test domains are unknown. Specifically, we analyze which properties of reinforcement learning (RL) environments and modeling choices have the greatest influence on out-of-domain performance. First, we identify two environment axes that strongly correlate with cross-domain generalization: (i) state information richness, i.e., the amount of information for the agent to process from the state, and (ii) planning complexity, estimated via goal reachability and trajectory length under a base policy. Notably, domain realism and text-level similarity are not the primary factors; for instance, the simple grid-world domain Sokoban leads to even stronger generalization in SciWorld than the more realistic ALFWorld. Motivated by these findings, we further show that increasing state information richness alone can already effectively improve cross-domain robustness. We propose a randomization technique, which is low-overhead and broadly applicable: add small amounts of distractive goal-irrelevant features to the state to make it richer without altering the task. Beyond environment-side properties, we also examine several modeling choices: (a) SFT warmup or mid-training helps prevent catastrophic forgetting during RL but undermines generalization to domains that are not included in the mid-training datamix; and (b) turning on step-by-step thinking during RL, while not always improving in-domain performance, plays a crucial role in preserving generalization.

</details>


### [324] [ShopSimulator: Evaluating and Exploring RL-Driven LLM Agent for Shopping Assistants](https://arxiv.org/abs/2601.18225)
*Pei Wang,Yanan Wu,Xiaoshuai Song,Weixun Wang,Gengru Chen,Zhongwen Li,Kezhong Yan,Ken Deng,Qi Liu,Shuaibing Zhao,Shaopan Xiong,Xuepeng Liu,Xuefeng Chen,Wanxi Deng,Wenbo Su,Bo Zheng*

Main category: cs.AI

TL;DR: ShopSimulator是一个大规模中文电商购物仿真环境，用于评估和训练LLM智能体在复杂购物场景中的表现，发现现有模型成功率不足40%，通过SFT+RL训练可显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前LLM智能体在电商购物应用中缺乏统一的仿真环境来全面评估其能力，现有研究只关注评测基准而缺乏训练支持，无法系统解决智能体在个性化搜索、多轮对话和产品辨别等方面的挑战。

Method: 提出ShopSimulator大规模中文购物环境，包含多样化购物场景，用于评估LLM智能体表现，并通过监督微调（SFT）和强化学习（RL）相结合的方法进行训练优化。

Result: 评估发现即使最佳模型的全成功率也低于40%，智能体在长轨迹中的深度搜索和产品选择、个性化线索平衡、用户交互等方面存在困难；SFT+RL训练组合能显著提升性能。

Conclusion: ShopSimulator为电商购物智能体提供了全面的评估和训练环境，揭示了现有LLM在复杂购物任务中的局限性，并展示了通过适当训练方法可以显著改善智能体性能。

Abstract: Large language model (LLM)-based agents are increasingly deployed in e-commerce shopping. To perform thorough, user-tailored product searches, agents should interpret personal preferences, engage in multi-turn dialogues, and ultimately retrieve and discriminate among highly similar products. However, existing research has yet to provide a unified simulation environment that consistently captures all of these aspects, and always focuses solely on evaluation benchmarks without training support. In this paper, we introduce ShopSimulator, a large-scale and challenging Chinese shopping environment. Leveraging ShopSimulator, we evaluate LLMs across diverse scenarios, finding that even the best-performing models achieve less than 40% full-success rate. Error analysis reveals that agents struggle with deep search and product selection in long trajectories, fail to balance the use of personalization cues, and to effectively engage with users. Further training exploration provides practical guidance for overcoming these weaknesses, with the combination of supervised fine-tuning (SFT) and reinforcement learning (RL) yielding significant performance improvements. Code and data will be released at https://github.com/ShopAgent-Team/ShopSimulator.

</details>


### [325] [Yunjue Agent Tech Report: A Fully Reproducible, Zero-Start In-Situ Self-Evolving Agent System for Open-Ended Tasks](https://arxiv.org/abs/2601.18226)
*Haotian Li,Shijun Yang,Weizhen Qi,Silei Zhao,Rui Hua,Mingzhu Song,Xiaojian Yang,Chao Peng*

Main category: cs.AI

TL;DR: 提出In-Situ Self-Evolving范式，让智能体在开放环境中通过任务交互自我进化工具集，无需真实标签，实现能力边界动态扩展。


<details>
  <summary>Details</summary>
Motivation: 传统智能体系统在开放环境中面临任务分布持续漂移和外部监督稀缺的挑战，依赖静态工具集或离线训练导致能力边界僵化且未知。

Method: 提出In-Situ Self-Evolving范式，将序列任务交互作为连续经验流，将短期执行反馈提炼为长期可重用能力。具体实现Yunjue Agent系统，通过工具演化作为能力扩展关键路径，引入Parallel Batch Evolution策略优化进化效率。

Result: 在五个不同基准测试的零起点设置下，相比专有基线取得显著性能提升。补充的暖启动评估证实积累的通用知识可无缝迁移到新领域。提出新的进化收敛监控指标。

Conclusion: In-Situ Self-Evolving范式使智能体能够在开放环境中自我进化，工具演化是关键能力扩展机制。该方法为构建弹性、自进化智能系统提供了新方向，并开源了代码库、系统轨迹和进化工具。

Abstract: Conventional agent systems often struggle in open-ended environments where task distributions continuously drift and external supervision is scarce. Their reliance on static toolsets or offline training lags behind these dynamics, leaving the system's capability boundaries rigid and unknown. To address this, we propose the In-Situ Self-Evolving paradigm. This approach treats sequential task interactions as a continuous stream of experience, enabling the system to distill short-term execution feedback into long-term, reusable capabilities without access to ground-truth labels. Within this framework, we identify tool evolution as the critical pathway for capability expansion, which provides verifiable, binary feedback signals. Within this framework, we develop Yunjue Agent, a system that iteratively synthesizes, optimizes, and reuses tools to navigate emerging challenges. To optimize evolutionary efficiency, we further introduce a Parallel Batch Evolution strategy. Empirical evaluations across five diverse benchmarks under a zero-start setting demonstrate significant performance gains over proprietary baselines. Additionally, complementary warm-start evaluations confirm that the accumulated general knowledge can be seamlessly transferred to novel domains. Finally, we propose a novel metric to monitor evolution convergence, serving as a function analogous to training loss in conventional optimization. We open-source our codebase, system traces, and evolved tools to facilitate future research in resilient, self-evolving intelligence.

</details>


### [326] [Think-Augmented Function Calling: Improving LLM Parameter Accuracy Through Embedded Reasoning](https://arxiv.org/abs/2601.18282)
*Lei Wei,Jinpeng Ou,Xiao Peng,Bin Wang*

Main category: cs.AI

TL;DR: 提出TAFC框架，通过函数和参数级别的显式推理增强LLM函数调用能力，无需修改模型架构


<details>
  <summary>Details</summary>
Motivation: 现有LLM函数调用机制缺乏参数生成的显式推理透明度，特别是对于具有相互依赖参数的复杂函数。现有方法如思维链提示在智能体层面操作，无法为单个函数参数提供细粒度推理指导。

Method: 提出Think-Augmented Function Calling (TAFC)框架：1) 引入通用的"think"参数增强，让模型表达决策过程；2) 动态优化参数描述以提高推理质量；3) 基于复杂度评分自动触发细粒度推理；4) 提出推理引导优化以对齐人类期望。

Result: 在ToolBench上对专有和开源模型进行评估，显示在多参数函数的参数生成准确性和推理连贯性方面有显著改进，同时为调试AI智能体行为提供增强的可解释性。

Conclusion: TAFC框架通过函数和参数级别的显式推理显著提高了LLM函数调用的准确性和可解释性，同时保持与现有API的完全兼容性，无需修改LLM架构。

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities in function calling for autonomous agents, yet current mechanisms lack explicit reasoning transparency during parameter generation, particularly for complex functions with interdependent parameters. While existing approaches like chain-of-thought prompting operate at the agent level, they fail to provide fine-grained reasoning guidance for individual function parameters. To address these limitations, we propose Think-Augmented Function Calling (TAFC), a novel framework that enhances function calling accuracy through explicit reasoning at both function and parameter levels. Our method introduces a universal "think" parameter augmentation that enables models to articulate their decision-making process, with dynamic optimization for parameter descriptions to improve reasoning quality. For complex parameters, TAFC automatically triggers granular reasoning based on complexity scoring, ensuring appropriate justification for critical decisions. Additionally, we propose reasoning-guided optimization to align generated reasoning with human expectations. TAFC requires no architectural modifications to existing LLMs while maintaining full API compatibility. Evaluation on ToolBench across proprietary and open-source models demonstrates significant improvements in parameter generation accuracy and reasoning coherence for multi-parameter functions, while providing enhanced interpretability for debugging AI agent behaviors.

</details>


### [327] [A Generative AI-Driven Reliability Layer for Action-Oriented Disaster Resilience](https://arxiv.org/abs/2601.18308)
*Geunsik Lim*

Main category: cs.AI

TL;DR: Climate RADAR是一个基于生成式AI的可靠性层，将传统预警系统从警报传递转变为行动执行，通过整合多源数据和LLM提供个性化建议，提高保护行动执行率并减少响应延迟。


<details>
  <summary>Details</summary>
Motivation: 传统预警系统虽然快速传播警报，但往往无法触发及时的保护行动，导致可预防的损失和不平等。需要将灾害通信从"警报传递"转变为"行动执行"。

Method: 整合气象、水文、脆弱性和社会数据形成综合风险指数，使用带有护栏的大型语言模型（LLMs）为公民、志愿者和市政界面提供个性化建议。

Result: 通过模拟、用户研究和市政试点评估显示：提高了保护行动执行率、减少了响应延迟、增加了可用性和信任度。

Conclusion: Climate RADAR通过结合预测分析、行为科学和负责任AI，推进了以人为本、透明和公平的预警系统，为合规就绪的灾害韧性基础设施提供了实用途径。

Abstract: As climate-related hazards intensify, conventional early warning systems (EWS) disseminate alerts rapidly but often fail to trigger timely protective actions, leading to preventable losses and inequities. We introduce Climate RADAR (Risk-Aware, Dynamic, and Action Recommendation system), a generative AI-based reliability layer that reframes disaster communication from alerts delivered to actions executed. It integrates meteorological, hydrological, vulnerability, and social data into a composite risk index and employs guardrail-embedded large language models (LLMs) to deliver personalized recommendations across citizen, volunteer, and municipal interfaces. Evaluation through simulations, user studies, and a municipal pilot shows improved outcomes, including higher protective action execution, reduced response latency, and increased usability and trust. By combining predictive analytics, behavioral science, and responsible AI, Climate RADAR advances people-centered, transparent, and equitable early warning systems, offering practical pathways toward compliance-ready disaster resilience infrastructures.

</details>


### [328] [Can Good Writing Be Generative? Expert-Level AI Writing Emerges through Fine-Tuning on High-Quality Books](https://arxiv.org/abs/2601.18353)
*Tuhin Chakrabarty,Paramveer S. Dhillon*

Main category: cs.AI

TL;DR: 专家在上下文提示条件下82.7%偏好人类写作，但经过微调后62%偏好AI写作；普通评委则始终偏好AI写作，引发专家作家的身份危机


<details>
  <summary>Details</summary>
Motivation: 挑战"创意写作是机器无法复制的独特人类活动"这一假设，研究生成式AI能否在模仿作家风格方面与人类专家竞争

Method: 行为实验：28名MFA作家与3个LLM竞争模仿50位知名作家风格；28名专家评委和131名普通评委进行盲测对比

Result: 专家评委在上下文提示条件下82.7%偏好人类写作，但经过微调后62%偏好AI写作；普通评委始终偏好AI写作；专家作家对AI写作的偏好引发身份危机

Conclusion: AI的创意能力挑战了传统认知，引发关于创意劳动未来的根本性问题，专家作家的审美自信受到侵蚀

Abstract: Creative writing has long been considered a uniquely human endeavor, requiring voice and style that machines could not replicate. This assumption is challenged by Generative AI that can emulate thousands of author styles in seconds with negligible marginal labor. To understand this better, we conducted a behavioral experiment where 28 MFA writers (experts) competed against three LLMs in emulating 50 critically acclaimed authors. Based on blind pairwise comparisons by 28 expert judges and 131 lay judges, we find that experts preferred human writing in 82.7% of cases under the in-context prompting condition but this reversed to 62% preference for AI after fine-tuning on authors' complete works. Lay judges, however, consistently preferred AI writing. Debrief interviews with expert writers revealed that their preference for AI writing triggered an identity crisis, eroding aesthetic confidence and questioning what constitutes "good writing." These findings challenge discourse about AI's creative limitations and raise fundamental questions about the future of creative labor.

</details>


### [329] [AI Agent for Reverse-Engineering Legacy Finite-Difference Code and Translating to Devito](https://arxiv.org/abs/2601.18381)
*Yinghan Hou,Zongyou Yang*

Main category: cs.AI

TL;DR: 开发了一个集成AI代理框架，用于将传统有限差分实现转换为Devito环境，结合RAG和开源大语言模型，通过多阶段工作流实现代码转换和优化。


<details>
  <summary>Details</summary>
Motivation: 为了促进传统有限差分实现向Devito环境的转换，解决现有转换方法缺乏动态适应性和精确上下文指导的问题。

Method: 采用混合LangGraph架构，结合RAG和开源大语言模型，通过多阶段迭代工作流构建Devito知识图谱，包括文档解析、结构感知分割、实体关系提取和社区检测。包含反向工程组件分析Fortran源代码，多阶段检索管道进行并行搜索和语义分析，代码合成使用Pydantic约束确保结构化输出。

Result: 实现了从静态代码翻译向动态自适应分析行为的转变，通过反馈机制和强化学习动机提高了转换的准确性和可靠性，验证框架覆盖了执行正确性、结构完整性、数学一致性和API合规性。

Conclusion: 该研究的主要贡献在于整合了基于强化学习动机的反馈机制，使代码转换从静态过程转变为动态自适应分析行为，为科学计算代码迁移提供了有效的AI驱动解决方案。

Abstract: To facilitate the transformation of legacy finite difference implementations into the Devito environment, this study develops an integrated AI agent framework. Retrieval-Augmented Generation (RAG) and open-source Large Language Models are combined through multi-stage iterative workflows in the system's hybrid LangGraph architecture. The agent constructs an extensive Devito knowledge graph through document parsing, structure-aware segmentation, extraction of entity relationships, and Leiden-based community detection. GraphRAG optimisation enhances query performance across semantic communities that include seismic wave simulation, computational fluid dynamics, and performance tuning libraries. A reverse engineering component derives three-level query strategies for RAG retrieval through static analysis of Fortran source code. To deliver precise contextual information for language model guidance, the multi-stage retrieval pipeline performs parallel searching, concept expansion, community-scale retrieval, and semantic similarity analysis. Code synthesis is governed by Pydantic-based constraints to guarantee structured outputs and reliability. A comprehensive validation framework integrates conventional static analysis with the G-Eval approach, covering execution correctness, structural soundness, mathematical consistency, and API compliance. The overall agent workflow is implemented on the LangGraph framework and adopts concurrent processing to support quality-based iterative refinement and state-aware dynamic routing. The principal contribution lies in the incorporation of feedback mechanisms motivated by reinforcement learning, enabling a transition from static code translation toward dynamic and adaptive analytical behavior.

</details>


### [330] [Dynamic Thinking-Token Selection for Efficient Reasoning in Large Reasoning Models](https://arxiv.org/abs/2601.18383)
*Zhenyuan Guo,Tong Chen,Wenlong Meng,Chen Gong,Xin Yu,Chengkun Wei,Wenzhi Chen*

Main category: cs.AI

TL;DR: DynTS通过注意力图分析推理轨迹，识别关键决策token并仅保留其KV缓存，优化大型推理模型的内存和计算效率


<details>
  <summary>Details</summary>
Motivation: 大型推理模型生成推理轨迹时会产生大量内存占用和计算开销，成为效率瓶颈。研究发现只有部分关键决策token对最终答案有决定性影响，其余token贡献可忽略

Method: 提出动态思维token选择方法(DynTS)，利用注意力图分析推理轨迹的影响，识别决策关键token，在推理过程中仅保留这些关键token的KV缓存状态，淘汰冗余条目

Result: 通过选择性保留关键token的KV缓存，显著减少了内存占用和计算开销，优化了大型推理模型的推理效率

Conclusion: 推理轨迹中存在大量冗余token，仅保留决策关键token的KV缓存可有效提升大型推理模型的效率，DynTS方法为此提供了实用解决方案

Abstract: Large Reasoning Models (LRMs) excel at solving complex problems by explicitly generating a reasoning trace before deriving the final answer. However, these extended generations incur substantial memory footprint and computational overhead, bottlenecking LRMs' efficiency. This work uses attention maps to analyze the influence of reasoning traces and uncover an interesting phenomenon: only some decision-critical tokens in a reasoning trace steer the model toward the final answer, while the remaining tokens contribute negligibly. Building on this observation, we propose Dynamic Thinking-Token Selection (DynTS). This method identifies decision-critical tokens and retains only their associated Key-Value (KV) cache states during inference, evicting the remaining redundant entries to optimize efficiency.

</details>


### [331] [OffSeeker: Online Reinforcement Learning Is Not All You Need for Deep Research Agents](https://arxiv.org/abs/2601.18467)
*Yuhang Zhou,Kai Zheng,Qiguang Chen,Mengkang Hu,Qingfeng Sun,Can Xu,Jingjing Chen*

Main category: cs.AI

TL;DR: 离线训练的8B参数研究智能体OffSeeker在六个基准测试中表现优异，与需要昂贵在线强化学习的30B参数系统竞争


<details>
  <summary>Details</summary>
Motivation: 当前深度研究智能体依赖昂贵的在线强化学习（需要大量API调用），而离线训练因缺乏高质量研究轨迹数据而受限。本文旨在证明不需要昂贵的在线强化学习也能构建强大的研究智能体。

Method: 提出完全开源的离线训练套件：1) DeepForge任务合成框架，无需大量预处理即可生成大规模研究查询；2) 精心策划的数据集包含66k问答对、33k监督微调轨迹和21k DPO对；3) 基于这些资源完全离线训练出8B参数的OffSeeker模型。

Result: 在六个基准测试上的广泛评估显示，OffSeeker不仅在类似规模的智能体中领先，还能与通过大量在线强化学习训练的30B参数系统保持竞争力。

Conclusion: 昂贵的在线强化学习并非构建强大研究智能体的唯一途径，通过开源工具和高质量数据集进行离线训练同样能取得优异性能，为研究智能体开发提供了更经济高效的替代方案。

Abstract: Deep research agents have shown remarkable potential in handling long-horizon tasks. However, state-of-the-art performance typically relies on online reinforcement learning (RL), which is financially expensive due to extensive API calls. While offline training offers a more efficient alternative, its progress is hindered by the scarcity of high-quality research trajectories. In this paper, we demonstrate that expensive online reinforcement learning is not all you need to build powerful research agents. To bridge this gap, we introduce a fully open-source suite designed for effective offline training. Our core contributions include DeepForge, a ready-to-use task synthesis framework that generates large-scale research queries without heavy preprocessing; and a curated collection of 66k QA pairs, 33k SFT trajectories, and 21k DPO pairs. Leveraging these resources, we train OffSeeker (8B), a model developed entirely offline. Extensive evaluations across six benchmarks show that OffSeeker not only leads among similar-sized agents but also remains competitive with 30B-parameter systems trained via heavy online RL.

</details>


### [332] [AgentDoG: A Diagnostic Guardrail Framework for AI Agent Safety and Security](https://arxiv.org/abs/2601.18491)
*Dongrui Liu,Qihan Ren,Chen Qian,Shuai Shao,Yuejin Xie,Yu Li,Zhonghao Yang,Haoyu Luo,Peng Wang,Qingyu Liu,Binxin Hu,Ling Tang,Jilin Mei,Dadi Guo,Leitao Yuan,Junyao Yang,Guanxu Chen,Qihao Lin,Yi Yu,Bo Zhang,Jiaxuan Guo,Jie Zhang,Wenqi Shao,Huiqi Deng,Zhiheng Xi,Wenjie Wang,Wenxuan Wang,Wen Shen,Zhikai Chen,Haoyu Xie,Jialing Tao,Juntao Dai,Jiaming Ji,Zhongjie Ba,Linfeng Zhang,Yong Liu,Quanshi Zhang,Lei Zhu,Zhihua Wei,Hui Xue,Chaochao Lu,Jing Shao,Xia Hu*

Main category: cs.AI

TL;DR: 提出AgentDoG框架，通过三维风险分类法构建细粒度智能体安全基准和诊断式护栏，实现透明化风险溯源和状态监测


<details>
  <summary>Details</summary>
Motivation: 当前护栏模型缺乏对智能体风险的感知能力和风险诊断的透明度，无法应对自主工具使用和环境交互带来的复杂安全挑战

Method: 1. 提出三维正交风险分类法（来源、失效模式、后果）；2. 构建细粒度智能体安全基准ATBench；3. 开发诊断式护栏框架AgentDoG，提供轨迹监控和风险根因诊断

Result: AgentDoG在多样复杂交互场景中实现最先进的智能体安全调控性能，提供4B、7B、8B三种参数规模的Qwen和Llama版本

Conclusion: AgentDoG框架通过结构化风险分类和透明化诊断，有效解决了智能体安全护栏的细粒度监控和风险溯源问题，促进智能体对齐

Abstract: The rise of AI agents introduces complex safety and security challenges arising from autonomous tool use and environmental interactions. Current guardrail models lack agentic risk awareness and transparency in risk diagnosis. To introduce an agentic guardrail that covers complex and numerous risky behaviors, we first propose a unified three-dimensional taxonomy that orthogonally categorizes agentic risks by their source (where), failure mode (how), and consequence (what). Guided by this structured and hierarchical taxonomy, we introduce a new fine-grained agentic safety benchmark (ATBench) and a Diagnostic Guardrail framework for agent safety and security (AgentDoG). AgentDoG provides fine-grained and contextual monitoring across agent trajectories. More Crucially, AgentDoG can diagnose the root causes of unsafe actions and seemingly safe but unreasonable actions, offering provenance and transparency beyond binary labels to facilitate effective agent alignment. AgentDoG variants are available in three sizes (4B, 7B, and 8B parameters) across Qwen and Llama model families. Extensive experimental results demonstrate that AgentDoG achieves state-of-the-art performance in agentic safety moderation in diverse and complex interactive scenarios. All models and datasets are openly released.

</details>


### [333] [DEEPMED: Building a Medical DeepResearch Agent via Multi-hop Med-Search Data and Turn-Controlled Agentic Training & Inference](https://arxiv.org/abs/2601.18496)
*Zihan wang,Hao Wang,Shi Feng,Xiaocui Yang,Daling Wang,Yiqun Zhang,Jinghao Lin,Haihua Yang,Xiaozhong Ji*

Main category: cs.AI

TL;DR: DeepMed：针对医学推理的深度研究模型，通过多跳医学搜索QA合成、难度感知轮次惩罚和推理监控，解决通用DR模型在医学领域性能受限的问题。


<details>
  <summary>Details</summary>
Motivation: 医学推理模型受限于参数化知识，易出现遗忘和幻觉。通用深度研究（DR）模型虽然能在一般领域基于工具证据产生输出，但直接迁移到医学领域效果有限，主要因为任务特性差异（需要临床上下文推理）和工具使用扩展问题（盲目扩展工具调用会引入噪声）。

Method: 1. 数据：采用多跳医学搜索QA合成方法，支持模型在医学上下文中应用DR范式；2. 训练：引入难度感知轮次惩罚，抑制过度工具调用增长；3. 推理：加入监控机制，在可控步骤内验证假设，避免上下文腐化。

Result: 在七个医学基准测试中，DeepMed相比基础模型平均提升9.79%，并优于更大的医学推理和DR模型。

Conclusion: DeepMed通过针对医学领域特点设计的数据合成、训练策略和推理监控，成功解决了通用DR模型在医学推理中的局限性，显著提升了医学推理性能。

Abstract: Medical reasoning models remain constrained by parametric knowledge and are thus susceptible to forgetting and hallucinations. DeepResearch (DR) models ground outputs in verifiable evidence from tools and perform strongly in general domains, but their direct transfer to medical field yields relatively limited gains. We attribute this to two gaps: task characteristic and tool-use scaling. Medical questions require evidence interpretation in a knowledge-intensive clinical context; while general DR models can retrieve information, they often lack clinical-context reasoning and thus "find it but fail to use it," leaving performance limited by medical abilities. Moreover, in medical scenarios, blindly scaling tool-call can inject noisy context, derailing sensitive medical reasoning and prompting repetitive evidence-seeking along incorrect paths. Therefore, we propose DeepMed. For data, we deploy a multi-hop med-search QA synthesis method supporting the model to apply the DR paradigm in medical contexts. For training, we introduce a difficulty-aware turn-penalty to suppress excessive tool-call growth. For inference, we bring a monitor to help validate hypotheses within a controlled number of steps and avoid context rot. Overall, on seven medical benchmarks, DeepMed improves its base model by 9.79\% on average and outperforms larger medical reasoning and DR models.

</details>


### [334] [Deconstructing Instruction-Following: A New Benchmark for Granular Evaluation of Large Language Model Instruction Compliance Abilities](https://arxiv.org/abs/2601.18554)
*Alberto Purpura,Li Wang,Sahil Badyal,Eugenio Beaufrand,Adam Faulkner*

Main category: cs.AI

TL;DR: MOSAIC是一个模块化框架，用于评估LLM遵循复杂指令的能力，通过动态生成包含多达20个应用导向约束的数据集，对五个LLM进行细粒度分析。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试往往无法反映真实世界使用情况，或无法将指令遵循能力与任务成功分离，因此需要更可靠的方法来确保LLM遵循复杂指令。

Method: 提出MOSAIC框架，使用动态生成的数据集，包含最多20个应用导向的生成约束，对五个不同家族的LLM进行细粒度评估。

Result: 分析显示指令遵循能力不是单一能力，而是随约束类型、数量和位置显著变化；揭示了模型特定弱点、指令间的协同与冲突关系，以及首因效应和近因效应等位置偏差。

Conclusion: 这些细粒度洞察对于诊断模型失败和开发更可靠的LLM至关重要，特别是在需要严格遵循复杂指令的系统中。

Abstract: Reliably ensuring Large Language Models (LLMs) follow complex instructions is a critical challenge, as existing benchmarks often fail to reflect real-world use or isolate compliance from task success. We introduce MOSAIC (MOdular Synthetic Assessment of Instruction Compliance), a modular framework that uses a dynamically generated dataset with up to 20 application-oriented generation constraints to enable a granular and independent analysis of this capability. Our evaluation of five LLMs from different families based on this new benchmark demonstrates that compliance is not a monolithic capability but varies significantly with constraint type, quantity, and position. The analysis reveals model-specific weaknesses, uncovers synergistic and conflicting interactions between instructions, and identifies distinct positional biases such as primacy and recency effects. These granular insights are critical for diagnosing model failures and developing more reliable LLMs for systems that demand strict adherence to complex instructions.

</details>


### [335] [Stability as a Liability:Systematic Breakdown of Linguistic Structure in LLMs](https://arxiv.org/abs/2601.18588)
*Xianzhe Meng,Qiangsheng Zeng,Ling Luo,Qinghan Yang,Jiarui Hao,Wenbo Wu,Qinyu Wang,Rui Yin,Lin Qi,Renzhi Lu*

Main category: cs.AI

TL;DR: 训练稳定性与生成质量不一定对齐：稳定的最大似然训练可能导致模型集中在有限的数据模式上，产生低熵、重复性输出，尽管损失平滑收敛。


<details>
  <summary>Details</summary>
Motivation: 研究训练稳定性如何影响语言模型的生成分布。传统观点认为训练稳定性是可靠优化的前提，但本文探讨稳定性是否真正保证生成质量。

Method: 理论分析标准最大似然训练下稳定参数轨迹的影响，并使用基于反馈的训练框架进行实证验证，该框架稳定内部生成统计量。

Result: 稳定训练导致模型近似最小化前向KL散度，同时隐式降低生成熵，使模型集中在有限的数据模式上，产生系统性退化（低熵输出和重复行为）。

Conclusion: 优化稳定性与生成表达能力并不天然对齐，稳定性本身不足以指示生成质量，需要更全面的评估指标。

Abstract: Training stability is typically regarded as a prerequisite for reliable optimization in large language models. In this work, we analyze how stabilizing training dynamics affects the induced generation distribution. We show that under standard maximum likelihood training, stable parameter trajectories lead stationary solutions to approximately minimize the forward KL divergence to the empirical distribution, while implicitly reducing generative entropy. As a consequence, the learned model can concentrate probability mass on a limited subset of empirical modes, exhibiting systematic degeneration despite smooth loss convergence. We empirically validate this effect using a controlled feedback-based training framework that stabilizes internal generation statistics, observing consistent low-entropy outputs and repetitive behavior across architectures and random seeds. It indicates that optimization stability and generative expressivity are not inherently aligned, and that stability alone is an insufficient indicator of generative quality.

</details>


### [336] [A Balanced Neuro-Symbolic Approach for Commonsense Abductive Logic](https://arxiv.org/abs/2601.18595)
*Joseph Cotnareanu,Didier Chetelat,Yingxue Zhang,Mark Coates*

Main category: cs.AI

TL;DR: 提出一种结合LLM与逻辑求解器的方法，通过迭代反馈机制补充缺失的常识关系，提升复杂逻辑推理能力。


<details>
  <summary>Details</summary>
Motivation: 虽然LLM在形式推理方面表现出色，但在需要复杂证明规划的问题上容易失败。现有逻辑求解器虽然推理效率高，但无法处理缺失的常识关系，需要人工提供所有相关事实。

Method: 提出新颖的迭代方法：使用逻辑求解器的反馈来指导LLM补充缺失的常识关系。通过搜索潜在的常识假设，最大化找到有用事实的机会，同时保持计算成本可控。

Result: 在多个纯逻辑推理数据集上（其中部分常识信息被移除），该方法相比现有技术持续取得显著改进，证明了在人类语境中平衡神经与符号元素的价值。

Conclusion: 通过结合LLM的常识推理能力和逻辑求解器的形式推理优势，该方法有效解决了复杂逻辑问题中的常识缺失问题，展示了神经符号混合方法的潜力。

Abstract: Although Large Language Models (LLMs) have demonstrated impressive formal reasoning abilities, they often break down when problems require complex proof planning. One promising approach for improving LLM reasoning abilities involves translating problems into formal logic and using a logic solver. Although off-the-shelf logic solvers are in principle substantially more efficient than LLMs at logical reasoning, they assume that all relevant facts are provided in a question and are unable to deal with missing commonsense relations. In this work, we propose a novel method that uses feedback from the logic solver to augment a logic problem with commonsense relations provided by the LLM, in an iterative manner. This involves a search procedure through potential commonsense assumptions to maximize the chance of finding useful facts while keeping cost tractable. On a collection of pure-logical reasoning datasets, from which some commonsense information has been removed, our method consistently achieves considerable improvements over existing techniques, demonstrating the value in balancing neural and symbolic elements when working in human contexts.

</details>


### [337] [PolySHAP: Extending KernelSHAP with Interaction-Informed Polynomial Regression](https://arxiv.org/abs/2601.18608)
*Fabian Fumagalli,R. Teal Witter,Christopher Musco*

Main category: cs.AI

TL;DR: PolySHAP扩展KernelSHAP，使用高阶多项式近似特征交互，提供更准确的Shapley值估计，并证明配对采样等价于二阶PolySHAP。


<details>
  <summary>Details</summary>
Motivation: Shapley值是XAI中的核心工具，但精确计算需要指数级复杂度。KernelSHAP通过线性近似避免了这一成本，但无法捕捉特征间的非线性交互。

Method: 提出PolySHAP方法，使用高阶多项式（而非线性函数）来近似游戏函数，从而捕捉特征间的非线性交互。同时证明配对采样（antithetic sampling）等价于二阶PolySHAP。

Result: PolySHAP在各种基准数据集上提供了更好的Shapley值估计，且估计具有一致性。配对采样与二阶PolySHAP输出完全相同的近似结果。

Conclusion: PolySHAP通过高阶多项式近似改进了Shapley值估计，并为配对采样启发式方法提供了首个强有力的理论依据。

Abstract: Shapley values have emerged as a central game-theoretic tool in explainable AI (XAI). However, computing Shapley values exactly requires $2^d$ game evaluations for a model with $d$ features. Lundberg and Lee's KernelSHAP algorithm has emerged as a leading method for avoiding this exponential cost. KernelSHAP approximates Shapley values by approximating the game as a linear function, which is fit using a small number of game evaluations for random feature subsets.
  In this work, we extend KernelSHAP by approximating the game via higher degree polynomials, which capture non-linear interactions between features. Our resulting PolySHAP method yields empirically better Shapley value estimates for various benchmark datasets, and we prove that these estimates are consistent.
  Moreover, we connect our approach to paired sampling (antithetic sampling), a ubiquitous modification to KernelSHAP that improves empirical accuracy. We prove that paired sampling outputs exactly the same Shapley value approximations as second-order PolySHAP, without ever fitting a degree 2 polynomial. To the best of our knowledge, this finding provides the first strong theoretical justification for the excellent practical performance of the paired sampling heuristic.

</details>


### [338] [Emergence of Phonemic, Syntactic, and Semantic Representations in Artificial Neural Networks](https://arxiv.org/abs/2601.18617)
*Pierre Orhan,Pablo Diego-Simón,Emmnanuel Chemla,Yair Lakretz,Yves Boubenec,Jean-Rémi King*

Main category: cs.AI

TL;DR: 该研究通过分析人工神经网络训练过程中的激活模式，发现语言习得的主要阶段（音素、词汇、句法表征）会自发出现，但需要比儿童多得多的数据量。


<details>
  <summary>Details</summary>
Motivation: 儿童语言习得过程（音素分类、词汇识别、句法组合）已有很好的行为描述，但缺乏统一的计算框架来解释其背后的神经表征机制。研究旨在探索人工神经网络训练中是否以及何时会出现类似的语言表征。

Method: 研究分析基于语音和文本的人工神经网络在训练过程中的激活模式，观察神经激活子空间的构建过程，检查其几何结构是否代表音素、词汇和句法结构。

Result: 研究发现语音和文本模型都遵循相似的学习阶段序列：训练过程中，神经激活逐步构建出代表音素、词汇和句法结构的子空间。虽然这种发展轨迹与儿童语言习得在性质上相似，但在数据量需求上存在巨大差异——这些算法需要比儿童多2-4个数量级的数据才能形成这些神经表征。

Conclusion: 研究结果表明，在特定条件下，语言习得的主要阶段会自发出现，这为理解语言习得背后的计算机制提供了一条有前景的路径，同时也揭示了人工系统与人类学习在数据效率上的显著差异。

Abstract: During language acquisition, children successively learn to categorize phonemes, identify words, and combine them with syntax to form new meaning. While the development of this behavior is well characterized, we still lack a unifying computational framework to explain its underlying neural representations. Here, we investigate whether and when phonemic, lexical, and syntactic representations emerge in the activations of artificial neural networks during their training. Our results show that both speech- and text-based models follow a sequence of learning stages: during training, their neural activations successively build subspaces, where the geometry of the neural activations represents phonemic, lexical, and syntactic structure. While this developmental trajectory qualitatively relates to children's, it is quantitatively different: These algorithms indeed require two to four orders of magnitude more data for these neural representations to emerge. Together, these results show conditions under which major stages of language acquisition spontaneously emerge, and hence delineate a promising path to understand the computations underpinning language acquisition.

</details>


### [339] [Assessing the Quality of Mental Health Support in LLM Responses through Multi-Attribute Human Evaluation](https://arxiv.org/abs/2601.18630)
*Abeer Badawi,Md Tahmid Rahman Laskar,Elahe Rahimi,Sheri Grach,Lindsay Bertrand,Lames Danok,Frank Rudzicz,Jimmy Huang,Elham Dolatabadi*

Main category: cs.AI

TL;DR: 该论文提出了一种基于人类专家的评估方法，用于评估大语言模型在心理健康对话中的表现，发现LLMs在认知支持方面表现可靠，但在情感共鸣方面存在不稳定，揭示了认知-情感差距。


<details>
  <summary>Details</summary>
Motivation: 全球心理健康危机日益严重，存在治疗缺口、资源不足和专业治疗师短缺等问题。大语言模型虽然提供了可扩展的情感支持潜力，但其可靠性、治疗相关性和与人类标准的对齐仍然难以评估。

Method: 开发了基于人类专家的评估方法：1）从真实场景数据集中整理500个心理健康对话；2）评估9个不同LLM（包括闭源和开源模型）生成的回复；3）由两名精神科专家独立使用5点李克特量表，基于包含6个属性的评估框架进行评分，重点关注认知支持和情感共鸣。

Result: LLMs在认知可靠性方面表现强劲，能提供安全、连贯且临床适当的信息，但在情感对齐方面表现不稳定。闭源模型（如GPT-4o）能提供更平衡的治疗性回复，而开源模型则表现出更大的变异性和情感平淡。研究揭示了持续的认知-情感差距。

Conclusion: 需要建立具有失败意识、基于临床的评估框架，在心理健康导向的LLMs中优先考虑关系敏感性而不仅仅是信息准确性。提倡采用人类在环的平衡评估协议，以治疗敏感性为中心，为心理健康对话AI的负责任设计和临床监督提供指导框架。

Abstract: The escalating global mental health crisis, marked by persistent treatment gaps, availability, and a shortage of qualified therapists, positions Large Language Models (LLMs) as a promising avenue for scalable support. While LLMs offer potential for accessible emotional assistance, their reliability, therapeutic relevance, and alignment with human standards remain challenging to address. This paper introduces a human-grounded evaluation methodology designed to assess LLM generated responses in therapeutic dialogue. Our approach involved curating a dataset of 500 mental health conversations from datasets with real-world scenario questions and evaluating the responses generated by nine diverse LLMs, including closed source and open source models. More specifically, these responses were evaluated by two psychiatric trained experts, who independently rated each on a 5 point Likert scale across a comprehensive 6 attribute rubric. This rubric captures Cognitive Support and Affective Resonance, providing a multidimensional perspective on therapeutic quality. Our analysis reveals that LLMs provide strong cognitive reliability by producing safe, coherent, and clinically appropriate information, but they demonstrate unstable affective alignment. Although closed source models (e.g., GPT-4o) offer balanced therapeutic responses, open source models show greater variability and emotional flatness. We reveal a persistent cognitive-affective gap and highlight the need for failure aware, clinically grounded evaluation frameworks that prioritize relational sensitivity alongside informational accuracy in mental health oriented LLMs. We advocate for balanced evaluation protocols with human in the loop that center on therapeutic sensitivity and provide a framework to guide the responsible design and clinical oversight of mental health oriented conversational AI.

</details>


### [340] [AdaReasoner: Dynamic Tool Orchestration for Iterative Visual Reasoning](https://arxiv.org/abs/2601.18631)
*Mingyang Song,Haoyu Sun,Jiawei Gu,Linjie Li,Luxin Xu,Ranjay Krishna,Yu Cheng*

Main category: cs.AI

TL;DR: AdaReasoner是一个多模态模型家族，通过学习工具使用作为通用推理技能，而非特定工具或显式监督行为，实现了在视觉推理任务中的自适应工具使用和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 人类在面对超出自身能力的问题时会依赖工具，这为提高多模态大语言模型（MLLMs）的视觉推理能力提供了有前景的范式。有效的推理需要知道使用哪些工具、何时调用它们以及如何在多步骤中组合它们，即使面对新工具或新任务时也是如此。

Method: 1）可扩展的数据整理流程，让模型接触长视野、多步骤的工具交互；2）Tool-GRPO强化学习算法，基于最终任务成功优化工具选择和序列；3）自适应学习机制，动态调节工具使用。这些组件使模型能够从任务上下文和中间结果推断工具效用，实现多个工具的协调和对未见工具的泛化。

Result: AdaReasoner表现出强大的工具自适应和泛化行为：自主采用有益工具、抑制无关工具、根据任务需求调整工具使用频率，尽管从未被明确训练这样做。这些能力转化为在具有挑战性的基准测试中的最先进性能，将7B基础模型平均提升+24.9%，并在多个任务（包括VSP和Jigsaw）上超越GPT-5等强大的专有系统。

Conclusion: AdaReasoner通过将工具使用学习为通用推理技能而非特定工具行为，实现了多模态模型的自适应工具使用能力，显著提升了视觉推理性能并展现出良好的泛化能力。

Abstract: When humans face problems beyond their immediate capabilities, they rely on tools, providing a promising paradigm for improving visual reasoning in multimodal large language models (MLLMs). Effective reasoning, therefore, hinges on knowing which tools to use, when to invoke them, and how to compose them over multiple steps, even when faced with new tools or new tasks. We introduce \textbf{AdaReasoner}, a family of multimodal models that learn tool use as a general reasoning skill rather than as tool-specific or explicitly supervised behavior. AdaReasoner is enabled by (i) a scalable data curation pipeline exposing models to long-horizon, multi-step tool interactions; (ii) Tool-GRPO, a reinforcement learning algorithm that optimizes tool selection and sequencing based on end-task success; and (iii) an adaptive learning mechanism that dynamically regulates tool usage. Together, these components allow models to infer tool utility from task context and intermediate outcomes, enabling coordination of multiple tools and generalization to unseen tools. Empirically, AdaReasoner exhibits strong tool-adaptive and generalization behaviors: it autonomously adopts beneficial tools, suppresses irrelevant ones, and adjusts tool usage frequency based on task demands, despite never being explicitly trained to do so. These capabilities translate into state-of-the-art performance across challenging benchmarks, improving the 7B base model by +24.9\% on average and surpassing strong proprietary systems such as GPT-5 on multiple tasks, including VSP and Jigsaw.

</details>


### [341] [FadeMem: Biologically-Inspired Forgetting for Efficient Agent Memory](https://arxiv.org/abs/2601.18642)
*Lei Wei,Xu Dong,Xiao Peng,Niantao Xie,Bin Wang*

Main category: cs.AI

TL;DR: FadeMem：受生物启发的智能体记忆架构，通过选择性遗忘机制解决LLM记忆限制问题，实现存储减少45%的同时提升多跳推理能力


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型作为自主智能体部署时面临关键记忆限制，缺乏选择性遗忘机制，导致要么在上下文边界发生灾难性遗忘，要么在边界内信息过载。人类记忆通过自适应衰减过程自然平衡保留与遗忘，而现有AI系统采用二元保留策略（要么全部保留，要么全部丢失）。

Method: 提出FadeMem，一种受生物启发的智能体记忆架构，包含模拟人类认知效率的主动遗忘机制。该系统实现双层记忆层次结构中的差异衰减率，保留由自适应指数衰减函数控制，该函数受语义相关性、访问频率和时间模式调节。通过LLM引导的冲突解决和智能记忆融合，系统整合相关信息同时允许无关细节逐渐消失。

Result: 在Multi-Session Chat、LoCoMo和LTI-Bench上的实验表明，系统在存储减少45%的同时实现了优越的多跳推理和检索能力，验证了生物启发遗忘在智能体记忆系统中的有效性。

Conclusion: FadeMem通过引入受生物启发的选择性遗忘机制，有效解决了LLM智能体的记忆限制问题，在减少存储需求的同时提升了推理能力，为智能体记忆系统设计提供了新方向。

Abstract: Large language models deployed as autonomous agents face critical memory limitations, lacking selective forgetting mechanisms that lead to either catastrophic forgetting at context boundaries or information overload within them. While human memory naturally balances retention and forgetting through adaptive decay processes, current AI systems employ binary retention strategies that preserve everything or lose it entirely. We propose FadeMem, a biologically-inspired agent memory architecture that incorporates active forgetting mechanisms mirroring human cognitive efficiency. FadeMem implements differential decay rates across a dual-layer memory hierarchy, where retention is governed by adaptive exponential decay functions modulated by semantic relevance, access frequency, and temporal patterns. Through LLM-guided conflict resolution and intelligent memory fusion, our system consolidates related information while allowing irrelevant details to fade. Experiments on Multi-Session Chat, LoCoMo, and LTI-Bench demonstrate superior multi-hop reasoning and retrieval with 45\% storage reduction, validating the effectiveness of biologically-inspired forgetting in agent memory systems.

</details>


### [342] [TEA-Bench: A Systematic Benchmarking of Tool-enhanced Emotional Support Dialogue Agent](https://arxiv.org/abs/2601.18700)
*Xingyu Sui,Yanyan Zhao,Yulin Hu,Jiahe Guo,Weixiang Zhao,Bing Qin*

Main category: cs.AI

TL;DR: TEA-Bench是首个用于评估工具增强型情感支持对话系统的交互式基准，包含真实情感场景、工具环境和过程级评估指标，实验表明工具增强能提升支持质量并减少幻觉，但效果受模型能力影响显著。


<details>
  <summary>Details</summary>
Motivation: 现有情感支持对话系统和基准主要关注文本环境下的情感支持，忽视了外部工具如何提供事实基础并减少多轮对话中的幻觉问题，需要建立工具增强的情感支持评估框架。

Method: 提出TEA-Bench基准，包含真实情感场景、MCP风格工具环境，以及联合评估情感支持质量和事实基础的过程级指标；在9个LLM上进行实验，并发布TEA-Dialog工具增强对话数据集。

Result: 工具增强普遍提升情感支持质量并减少幻觉，但效果强烈依赖模型能力：强模型能更选择性和有效地使用工具，弱模型获益有限；监督微调能改善分布内支持但泛化能力差。

Conclusion: 工具使用对于构建可靠的情感支持代理至关重要，TEA-Bench为评估工具增强型情感支持系统提供了重要基准，揭示了模型能力在有效利用工具方面的关键作用。

Abstract: Emotional Support Conversation requires not only affective expression but also grounded instrumental support to provide trustworthy guidance. However, existing ESC systems and benchmarks largely focus on affective support in text-only settings, overlooking how external tools can enable factual grounding and reduce hallucination in multi-turn emotional support. We introduce TEA-Bench, the first interactive benchmark for evaluating tool-augmented agents in ESC, featuring realistic emotional scenarios, an MCP-style tool environment, and process-level metrics that jointly assess the quality and factual grounding of emotional support. Experiments on nine LLMs show that tool augmentation generally improves emotional support quality and reduces hallucination, but the gains are strongly capacity-dependent: stronger models use tools more selectively and effectively, while weaker models benefit only marginally. We further release TEA-Dialog, a dataset of tool-enhanced ESC dialogues, and find that supervised fine-tuning improves in-distribution support but generalizes poorly. Our results underscore the importance of tool use in building reliable emotional support agents.

</details>


### [343] [Health-SCORE: Towards Scalable Rubrics for Improving Health-LLMs](https://arxiv.org/abs/2601.18706)
*Zhichao Yang,Sepehr Janghorbani,Dongxu Zhang,Jun Han,Qian Qian,Andrew Ressler,Gregory D. Lyng,Sanjit Singh Batra,Robert E. Tillman*

Main category: cs.AI

TL;DR: Health-SCORE：一个可扩展的基于量规的医疗LLM训练评估框架，显著降低量规开发成本，同时保持评估质量


<details>
  <summary>Details</summary>
Motivation: 在医疗等安全关键领域，量规对于评估开放式LLM响应至关重要，但创建高质量、领域特定的量规需要大量专家时间和开发成本，这使得基于量规的评估和训练难以扩展

Method: 开发Health-SCORE框架，这是一个通用且可扩展的基于量规的训练评估框架，通过减少量规开发成本而不牺牲性能。框架提供两种实用功能：作为结构化奖励信号指导强化学习的安全监督，以及直接融入提示中通过上下文学习提高响应质量

Result: 在开放式医疗任务中，Health-SCORE实现了与人工创建量规相当的评估质量，同时显著降低了开发工作量，使基于量规的评估和训练更具可扩展性

Conclusion: Health-SCORE框架成功解决了医疗领域量规开发成本高的问题，为基于量规的LLM评估和训练提供了可扩展的解决方案，具有实际应用价值

Abstract: Rubrics are essential for evaluating open-ended LLM responses, especially in safety-critical domains such as healthcare. However, creating high-quality and domain-specific rubrics typically requires significant human expertise time and development cost, making rubric-based evaluation and training difficult to scale. In this work, we introduce Health-SCORE, a generalizable and scalable rubric-based training and evaluation framework that substantially reduces rubric development costs without sacrificing performance. We show that Health-SCORE provides two practical benefits beyond standalone evaluation: it can be used as a structured reward signal to guide reinforcement learning with safety-aware supervision, and it can be incorporated directly into prompts to improve response quality through in-context learning. Across open-ended healthcare tasks, Health-SCORE achieves evaluation quality comparable to human-created rubrics while significantly lowering development effort, making rubric-based evaluation and training more scalable.

</details>


### [344] [Conditioned Generative Modeling of Molecular Glues: A Realistic AI Approach for Synthesizable Drug-like Molecules](https://arxiv.org/abs/2601.18716)
*Naeyma N. Islam,Thomas R. Caulfield*

Main category: cs.AI

TL;DR: AI辅助药物设计新方法，通过E3连接酶导向的分子胶促进Aβ-42靶向降解，用于阿尔茨海默病治疗


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病中细胞内Aβ-42的积累是疾病进展的早期毒性驱动因素，需要开发靶向降解策略

Method: 使用基于结构的建模、ADMET筛选和对接评估Aβ-42与三种E3连接酶的复合物形成潜力，开发LC-JT-VAE生成连接酶特异性小分子

Result: 生成模型能产生化学有效、新颖且靶向特异性的分子胶，能够促进Aβ-42降解

Conclusion: 该方法为设计神经退行性疾病的UPS靶向治疗提供了有前景的框架

Abstract: Alzheimer's disease (AD) is marked by the pathological accumulation of amyloid beta-42 (Abeta-42), contributing to synaptic dysfunction and neurodegeneration. While extracellular amyloid plaques are well-studied, increasing evidence highlights intracellular Abeta-42 as an early and toxic driver of disease progression. In this study, we present a novel, AI-assisted drug design approach to promote targeted degradation of Abeta-42 via the ubiquitin-proteasome system (UPS), using E3 ligase-directed molecular glues. We systematically evaluated the ternary complex formation potential of Abeta-42 with three E3 ligases: CRBN, VHL, and MDM2, through structure-based modeling, ADMET screening, and docking. We then developed a Ligase-Conditioned Junction Tree Variational Autoencoder (LC-JT-VAE) to generate ligase-specific small molecules, incorporating protein sequence embeddings and torsional angle-aware molecular graphs. Our results demonstrate that this generative model can produce chemically valid, novel, and target-specific molecular glues capable of facilitating Abeta-42 degradation. This integrated approach offers a promising framework for designing UPS-targeted therapies for neurodegenerative diseases.

</details>


### [345] [Why Keep Your Doubts to Yourself? Trading Visual Uncertainties in Multi-Agent Bandit Systems](https://arxiv.org/abs/2601.18735)
*Jusheng Zhang,Yijia Fan,Kaitong Cai,Jing Yang,Jiawei Yao,Jian Wang,Guanlong Qu,Ziliang Chen,Keze Wang*

Main category: cs.AI

TL;DR: Agora框架将多智能体协调重构为不确定性市场，通过将认知不确定性转化为可交易资产，基于经济规则驱动智能体协作，在提升性能的同时大幅降低成本。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型多智能体系统存在经济不可持续问题：异构智能体在信息不对称下的协调成本高昂。现有方法依赖启发式代理，忽略成本并破坏不确定性结构，导致次优协调。

Method: Agora将认知不确定性形式化为结构化可交易资产（感知、语义、推理），基于理性经济规则强制智能体进行盈利驱动的交易。扩展Thompson采样的市场感知经纪人发起协作，引导系统达到成本高效均衡。

Result: 在五个多模态基准测试（MMMU、MMBench、MathVision、InfoVQA、CC-OCR）上，Agora优于强视觉语言模型和启发式多智能体策略，如在MMMU上比最佳基线准确率提升8.5%，同时降低成本3倍以上。

Conclusion: 基于市场的协调为构建经济可行的多智能体视觉智能系统提供了原则性和可扩展的范式。

Abstract: Vision-Language Models (VLMs) enable powerful multi-agent systems, but scaling them is economically unsustainable: coordinating heterogeneous agents under information asymmetry often spirals costs. Existing paradigms, such as Mixture-of-Agents and knowledge-based routers, rely on heuristic proxies that ignore costs and collapse uncertainty structure, leading to provably suboptimal coordination. We introduce Agora, a framework that reframes coordination as a decentralized market for uncertainty. Agora formalizes epistemic uncertainty into a structured, tradable asset (perceptual, semantic, inferential), and enforces profitability-driven trading among agents based on rational economic rules. A market-aware broker, extending Thompson Sampling, initiates collaboration and guides the system toward cost-efficient equilibria. Experiments on five multimodal benchmarks (MMMU, MMBench, MathVision, InfoVQA, CC-OCR) show that Agora outperforms strong VLMs and heuristic multi-agent strategies, e.g., achieving +8.5% accuracy over the best baseline on MMMU while reducing cost by over 3x. These results establish market-based coordination as a principled and scalable paradigm for building economically viable multi-agent visual intelligence systems.

</details>


### [346] [TSRBench: A Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models](https://arxiv.org/abs/2601.18744)
*Fangxu Yu,Xingang Guo,Lingzhi Yuan,Haoqiang Kang,Hongyu Zhao,Lianhui Qin,Furong Huang,Bin Hu,Tianyi Zhou*

Main category: cs.AI

TL;DR: TSRBench是一个全面的多模态时间序列推理基准测试，包含4125个问题、14个领域、4个维度（感知、推理、预测、决策），评估了30多个领先模型，揭示了时间序列推理中的关键挑战。


<details>
  <summary>Details</summary>
Motivation: 时间序列数据在现实世界中无处不在且至关重要，但现有通用模型基准测试缺乏时间序列维度。为了填补这一空白，需要建立一个全面的基准测试来评估模型的时间序列推理能力。

Method: 构建了TSRBench基准测试，包含4125个问题，涵盖14个领域，分为4个主要维度（感知、推理、预测、决策）和15个任务。评估了30多个领先的专有和开源LLM、VLM和TSLLM模型。

Result: 研究发现：1）缩放定律适用于感知和推理，但在预测中失效；2）强大的推理能力不能保证准确的上下文感知预测，表明语义理解和数值预测之间存在脱节；3）当前多模态模型未能有效融合文本和视觉表示以获得相互增益。

Conclusion: TSRBench提供了一个标准化的评估平台，不仅突显了现有挑战，还为推进通用模型的发展提供了宝贵见解。代码和数据集已公开。

Abstract: Time series data is ubiquitous in real-world scenarios and crucial for critical applications ranging from energy management to traffic control. Consequently, the ability to reason over time series is a fundamental skill for generalist models to solve practical problems. However, this dimension is notably absent from existing benchmarks of generalist models. To bridge this gap, we introduce TSRBench, a comprehensive multi-modal benchmark designed to stress-test the full spectrum of time series reasoning capabilities. TSRBench features: i) a diverse set of 4125 problems from 14 domains, and is categorized into 4 major dimensions: Perception, Reasoning, Prediction, and Decision-Making. ii) 15 tasks from the 4 dimensions evaluating essential reasoning capabilities (e.g., numerical reasoning). Through extensive experiments, we evaluated over 30 leading proprietary and open-source LLMs, VLMs, and TSLLMs within TSRBench. Our findings reveal that: i) scaling laws hold for perception and reasoning but break down for prediction; ii) strong reasoning does not guarantee accurate context-aware forecasting, indicating a decoupling between semantic understanding and numerical prediction; and iii) despite the complementary nature of textual and visual represenations of time series as inputs, current multimodal models fail to effectively fuse them for reciprocal performance gains. TSRBench provides a standardized evaluation platform that not only highlights existing challenges but also offers valuable insights to advance generalist models. Our code and dataset are available at https://tsrbench.github.io/.

</details>
