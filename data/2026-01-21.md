<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 266]
- [cs.CL](#cs.CL) [Total: 184]
- [cs.DB](#cs.DB) [Total: 13]
- [cs.AI](#cs.AI) [Total: 101]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Domain-Specific Self-Supervised Pre-training for Agricultural Disease Classification: A Hierarchical Vision Transformer Study](https://arxiv.org/abs/2601.11612)
*Arnav S. Sonavane*

Main category: cs.CV

TL;DR: 在农业病害分类任务中，领域特定的自监督预训练（SimCLR）仅需3000张无标签农业图像即可带来+4.57%的准确率提升，超过了层次架构设计带来的增益（+3.70%）。该自监督学习优势具有架构无关性，表明实践者应优先收集领域数据而非纠结于架构选择。


<details>
  <summary>Details</summary>
Motivation: 研究领域特定自监督预训练对农业病害分类的影响，探索在资源有限情况下如何更有效地提升模型性能，比较数据收集与架构设计对性能提升的相对重要性。

Method: 使用SimCLR在3000张无标签农业图像上进行自监督预训练，然后应用于多种视觉Transformer架构（包括提出的HierarchicalViT、Swin-Base和ViT-Base）。在三个农业病害数据集（Cotton Leaf Disease、PlantVillage、PlantDoc）上进行评估，并分析模型校准性能。

Result: 自监督预训练带来显著性能提升：+4.57%（SimCLR预训练）vs +3.70%（层次架构设计）。该优势具有架构无关性：Swin-Base提升+4.08%，ViT-Base提升+4.20%。在参数量相近情况下，HVT-Base（78M）达到88.91%，优于Swin-Base（87.23%）。校准分析显示HVT的ECE为3.56%（温度缩放后降至1.52%）。

Conclusion: 领域特定的自监督预训练比架构设计对农业病害分类性能提升更为关键。实践者应优先投资于收集领域相关无标签数据，而非过度优化模型架构。提出的HierarchicalViT在性能上优于Swin Transformer，且经过校准后具有更好的部署可靠性。

Abstract: We investigate the impact of domain-specific self-supervised pre-training on agricultural disease classification using hierarchical vision transformers. Our key finding is that SimCLR pre-training on just 3,000 unlabeled agricultural images provides a +4.57% accuracy improvement--exceeding the +3.70% gain from hierarchical architecture design. Critically, we show this SSL benefit is architecture-agnostic: applying the same pre-training to Swin-Base yields +4.08%, to ViT-Base +4.20%, confirming practitioners should prioritize domain data collection over architectural choices. Using HierarchicalViT (HVT), a Swin-style hierarchical transformer, we evaluate on three datasets: Cotton Leaf Disease (7 classes, 90.24%), PlantVillage (38 classes, 96.3%), and PlantDoc (27 classes, 87.1%). At matched parameter counts, HVT-Base (78M) achieves 88.91% vs. Swin-Base (88M) at 87.23%, a +1.68% improvement. For deployment reliability, we report calibration analysis showing HVT achieves 3.56% ECE (1.52% after temperature scaling). Code: https://github.com/w2sg-arnav/HierarchicalViT

</details>


### [2] [Multi-modal MRI-Based Alzheimer's Disease Diagnosis with Transformer-based Image Synthesis and Transfer Learning](https://arxiv.org/abs/2601.11614)
*Jason Qiu*

Main category: cs.CV

TL;DR: 提出3D TransUNet框架，从常规T1加权MRI预测扩散MRI指标（FA和MD），提升阿尔茨海默病早期诊断准确性


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病需要早期检测，但常规T1加权MRI只能检测晚期宏观变化，而扩散MRI能检测早期微观异常但扫描时间长且易受运动伪影影响，限制了临床常规使用

Method: 使用3D TransUNet图像合成框架，直接从T1加权MRI预测分数各向异性（FA）和平均扩散率（MD）图

Result: 模型生成高质量FA和MD图，结构相似性指数超过0.93，与真实扩散MRI的皮尔逊相关系数>0.94；集成到多模态诊断模型中，AD分类准确率提升5%（78.75%→83.75%），轻度认知障碍检测提升12.5%

Conclusion: 从常规T1加权MRI可以推断高质量的扩散微观结构信息，将多模态成像优势转移到无扩散数据的场景，减少扫描时间同时保留互补信息，有望提高AD诊断的可及性、效率和准确性

Abstract: Alzheimer's disease (AD) is a progressive neurodegenerative disorder in which pathological changes begin many years before the onset of clinical symptoms, making early detection essential for timely intervention. T1-weighted (T1w) Magnetic Resonance Imaging (MRI) is routinely used in clinical practice to identify macroscopic brain alterations, but these changes typically emerge relatively late in the disease course. Diffusion MRI (dMRI), in contrast, is sensitive to earlier microstructural abnormalities by probing water diffusion in brain tissue. dMRI metrics, including fractional anisotropy (FA) and mean diffusivity (MD), provide complementary information about white matter integrity and neurodegeneration. However, dMRI acquisitions are time-consuming and susceptible to motion artifacts, limiting their routine use in clinical populations. To bridge this gap, I propose a 3D TransUNet image synthesis framework that predicts FA and MD maps directly from T1w MRI. My model generates high-fidelity maps, achieving a structural similarity index (SSIM) exceeding 0.93 and a strong Pearson correlation (>0.94) with ground-truth dMRI. When integrated into a multi-modal diagnostic model, these synthetic features boost AD classification accuracy by 5% (78.75%->83.75%) and, most importantly, improve mild cognitive impairment (MCI) detection by 12.5%. This study demonstrates that high-quality diffusion microstructural information can be inferred from routinely acquired T1w MRI, effectively transferring the benefits of multi-modality imaging to settings where diffusion data are unavailable. By reducing scan time while preserving complementary structural and microstructural information, the proposed approach has the potential to improve the accessibility, efficiency, and accuracy of AD diagnosis in clinical practice.

</details>


### [3] [PointSLAM++: Robust Dense Neural Gaussian Point Cloud-based SLAM](https://arxiv.org/abs/2601.11617)
*Xu Wang,Boyao Han,Xiaojun Chen,Ying Liu,Ruihui Li*

Main category: cs.CV

TL;DR: PointSLAM++：基于分层约束神经高斯表示的RGB-D SLAM系统，通过渐进姿态优化和动态神经表示图实现高精度3D重建和真实感渲染


<details>
  <summary>Details</summary>
Motivation: 当前SLAM方法在深度噪声存在时难以保持结构一致性和鲁棒的姿态估计，这限制了机器人技术和增强现实中的实时3D重建应用

Method: 1. 使用分层约束神经高斯表示保持结构关系并生成高斯基元进行场景建图；2. 采用渐进姿态优化减轻深度传感器噪声；3. 利用动态神经表示图根据局部几何复杂度调整高斯节点分布

Result: PointSLAM++在重建精度和渲染质量上优于现有的基于3DGS的SLAM方法，展示了其在大规模AR和机器人应用中的优势

Conclusion: PointSLAM++通过创新的分层约束神经高斯表示和动态自适应机制，实现了高精度3D建图和真实感场景渲染，为实时3D重建提供了有效的解决方案

Abstract: Real-time 3D reconstruction is crucial for robotics and augmented reality, yet current simultaneous localization and mapping(SLAM) approaches often struggle to maintain structural consistency and robust pose estimation in the presence of depth noise. This work introduces PointSLAM++, a novel RGB-D SLAM system that leverages a hierarchically constrained neural Gaussian representation to preserve structural relationships while generating Gaussian primitives for scene mapping. It also employs progressive pose optimization to mitigate depth sensor noise, significantly enhancing localization accuracy. Furthermore, it utilizes a dynamic neural representation graph that adjusts the distribution of Gaussian nodes based on local geometric complexity, enabling the map to adapt to intricate scene details in real time. This combination yields high-precision 3D mapping and photorealistic scene rendering. Experimental results show PointSLAM++ outperforms existing 3DGS-based SLAM methods in reconstruction accuracy and rendering quality, demonstrating its advantages for large-scale AR and robotics.

</details>


### [4] [Handcrafted Feature-Assisted One-Class Learning for Artist Authentication in Historical Drawings](https://arxiv.org/abs/2601.11627)
*Hassan Ugail,Jan Ritch-Frel,Irina Matuzava*

Main category: cs.CV

TL;DR: 提出基于单类自动编码器的历史绘画认证框架，使用手工特征在小型参考语料库中实现艺术家身份验证


<details>
  <summary>Details</summary>
Motivation: 纸质作品的身份验证和归属在文化遗产领域面临挑战，特别是当参考语料库小且风格线索主要通过线条和有限色调变化表达时

Method: 使用单类自动编码器训练十个艺术家特定的验证器，特征向量包括傅里叶域能量、香农熵、全局对比度、GLCM同质性和盒计数分形复杂度估计

Result: 在900个验证决策中，系统真接受率为83.3%，假接受率为9.5%，性能因艺术家而异，假接受分析显示与风格接近性和共享绘画惯例一致的结构化错误路径

Conclusion: 该方法旨在补充而非取代鉴赏力，为历史素描归属中常见的数据稀缺环境提供可重复的定量证据

Abstract: Authentication and attribution of works on paper remain persistent challenges in cultural heritage, particularly when the available reference corpus is small and stylistic cues are primarily expressed through line and limited tonal variation. We present a verification-based computational framework for historical drawing authentication using one-class autoencoders trained on a compact set of interpretable handcrafted features. Ten artist-specific verifiers are trained using authenticated sketches from the Metropolitan Museum of Art open-access collection, the Ashmolean Collections Catalogue, the Morgan Library and Museum, the Royal Collection Trust (UK), the Victoria and Albert Museum Collections, and an online catalogue of the Casa Buonarroti collection and evaluated under a biometric-style protocol with genuine and impostor trials. Feature vectors comprise Fourier-domain energy, Shannon entropy, global contrast, GLCM-based homogeneity, and a box-counting estimate of fractal complexity. Across 900 verification decisions (90 genuine and 810 impostor trials), the pooled system achieves a True Acceptance Rate of 83.3% with a False Acceptance Rate of 9.5% at the chosen operating point. Performance varies substantially by artist, with near-zero false acceptance for some verifiers and elevated confusability for others. A pairwise attribution of false accepts indicates structured error pathways consistent with stylistic proximity and shared drawing conventions, whilst also motivating tighter control of digitisation artefacts and threshold calibration. The proposed methodology is designed to complement, rather than replace, connoisseurship by providing reproducible, quantitative evidence suitable for data-scarce settings common in historical sketch attribution.

</details>


### [5] [A one-step generation model with a Single-Layer Transformer: Layer number re-distillation of FreeFlow](https://arxiv.org/abs/2601.11630)
*Haonan Wei,Linyuan Wang,Nuolin Sun,Zhizhong Zheng,Lei Li,Bin Yan*

Main category: cs.CV

TL;DR: 提出SLT（单层Transformer），通过蒸馏训练将28层FreeFlow模型压缩为单个共享DiT块，参数从675M降至4.3M，并利用其快速采样能力筛选高质量初始噪声点，提升一步生成的质量和稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有Flow matching方法（如MeanFlow、FreeFlow）虽然实现了一步生成，但FreeFlow的28层Transformer架构计算量大。观察到该架构可视为ODE的欧拉离散化，因此希望通过蒸馏压缩层数，同时利用压缩模型的快速采样能力筛选高质量初始噪声点，解决有限采样次数下因低质量初始噪声导致的生成质量波动问题。

Method: 将FreeFlow的28层Transformer视为ODE的欧拉离散化，提出SLT（单层Transformer）：1）使用单个共享DiT块近似28层教师模型的深度特征演化；2）训练时匹配教师模型在多个深度补丁的中间特征，融合这些补丁级表示；3）同时对齐教师的最终速度预测。通过蒸馏训练将675M参数的DiT-XL/2压缩为4.3M参数的单个Transformer块。

Result: 成功将28层FreeFlow模型压缩为单层SLT，参数从675M降至4.3M。在相当于教师模型两次随机采样的时间内，SLT能进行超过100次噪声筛选，为教师模型选择高质量初始点。实验表明该方法有效避免了有限FreeFlow采样次数下因低质量初始噪声导致的质量波动，显著提升了一步生成的稳定性和平均质量。

Conclusion: SLT通过蒸馏压缩实现了高效的模型简化，不仅大幅减少参数和计算量，还利用其快速采样能力优化初始噪声选择，有效提升了一步生成方法的稳定性和生成质量，为高质量快速图像生成提供了新思路。

Abstract: Currently, Flow matching methods aim to compress the iterative generation process of diffusion models into a few or even a single step, with MeanFlow and FreeFlow being representative achievements of one-step generation based on Ordinary Differential Equations (ODEs). We observe that the 28-layer Transformer architecture of FreeFlow can be characterized as an Euler discretization scheme for an ODE along the depth axis, where the layer index serves as the discrete time step. Therefore, we distill the number of layers of the FreeFlow model, following the same derivation logic as FreeFlow, and propose SLT (Single-Layer Transformer), which uses a single shared DiT block to approximate the depth-wise feature evolution of the 28-layer teacher. During training, it matches the teacher's intermediate features at several depth patches, fuses those patch-level representations, and simultaneously aligns the teacher's final velocity prediction. Through distillation training, we compress the 28 independent Transformer Blocks of the teacher model DiT-XL/2 into a single Transformer Block, reducing the parameter count from 675M to 4.3M. Furthermore, leveraging its minimal parameters and rapid sampling speed, SLT can screen more candidate points in the noise space within the same timeframe, thereby selecting higher-quality initial points for the teacher model FreeFlow and ultimately enhancing the quality of generated images. Experimental results demonstrate that within a time budget comparable to two random samplings of the teacher model, our method performs over 100 noise screenings and produces a high-quality sample through the teacher model using the selected points. Quality fluctuations caused by low-quality initial noise under a limited number of FreeFlow sampling calls are effectively avoided, substantially improving the stability and average generation quality of one-step generation.

</details>


### [6] [Compress to Focus: Efficient Coordinate Compression for Policy Optimization in Multi-Turn GUI Agents](https://arxiv.org/abs/2601.11631)
*Yurun Song,Jiong Yin,Rongjunchen Zhang,Ian G. Harris*

Main category: cs.CV

TL;DR: CCPO是一个用于多轮GUI代理的高效策略优化框架，通过坐标感知空间压缩减少上下文膨胀，结合距离优势奖励提升性能，实现55%令牌压缩和3.8倍训练加速。


<details>
  <summary>Details</summary>
Motivation: 多轮GUI代理在处理复杂任务时会积累大量交互历史，导致严重的上下文膨胀问题。现有方法要么通过截断牺牲长期上下文，要么通过令牌剪枝破坏空间结构，需要一种既能保持空间结构又能有效压缩上下文的方法。

Method: 提出坐标压缩策略优化（CCPO）框架，包含：1）坐标感知空间压缩（CASC），通过聚合多个rollout的坐标信息捕捉目标相关区域，逐步缩小历史注意力范围；2）基于距离的优势函数，提供细粒度学习信号，根据距离而非二元正确性优化策略。

Result: 在四个基准测试中达到最先进性能，实现高达55%的令牌压缩和3.8倍的训练加速，同时提高了接地准确性和压缩质量。

Conclusion: CCPO通过耦合视觉压缩与策略优化，有效解决了多轮GUI代理的上下文膨胀问题，在保持空间结构的同时显著提升了计算效率和任务性能。

Abstract: Multi-turn GUI agents enable complex task completion through sequential decision-making, but suffer from severe context inflation as interaction history accumulates. Existing strategies either sacrifice long-term context via truncation or compromise spatial structure through token pruning. In this paper, we propose Coordinate Compression Policy Optimization (CCPO), an efficient policy optimization framework that couples visual compression with policy optimization for multi-turn GUI agents. CCPO introduces Coordinate-Aware Spatial Compression (CASC), which aggregates coordinates from multiple rollouts to capture target-relevant regions and progressively narrow historical attention around key visual areas. From interactions across rollouts, CASC adaptively constructs attention boundaries that concentrate computation on the most informative regions of the scene. We further design a Distance-Based Advantage that provides fine-grained learning signals based on distance rather than binary correctness, improving both grounding accuracy and compression quality. Extensive experiments demonstrate that CCPO achieves SOTA performance across four benchmarks with up to 55% token compression and 3.8$\times$ training speedup.

</details>


### [7] [KG-ViP: Bridging Knowledge Grounding and Visual Perception in Multi-modal LLMs for Visual Question Answering](https://arxiv.org/abs/2601.11632)
*Zhiyang Li,Ao Ke,Yukun Cao,Xike Xie*

Main category: cs.CV

TL;DR: KG-ViP通过融合场景图和常识图来解决MLLMs在VQA中的知识幻觉和细粒度视觉感知不足问题，显著提升了VQA性能。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在视觉问答中存在两个主要问题：知识幻觉（生成与视觉内容不符的信息）和细粒度视觉感知不足。作者发现场景图和常识图恰好能互补解决这两个问题，但以往工作通常将它们孤立处理，忽略了它们的协同潜力。

Method: 提出KG-ViP统一框架，通过新颖的检索-融合管道，利用查询作为语义桥梁逐步整合场景图和常识图，合成统一的结构化上下文来促进可靠的多模态推理。

Result: 在FVQA 2.0+和MVQA基准测试上的广泛实验表明，KG-ViP显著优于现有的VQA方法。

Conclusion: 融合场景图和常识图能有效解决MLLMs在VQA中的双重限制，KG-ViP框架通过结构化知识融合实现了更可靠的多模态推理。

Abstract: Multi-modal Large Language Models (MLLMs) for Visual Question Answering (VQA) often suffer from dual limitations: knowledge hallucination and insufficient fine-grained visual perception. Crucially, we identify that commonsense graphs and scene graphs provide precisely complementary solutions to these respective deficiencies by providing rich external knowledge and capturing fine-grained visual details. However, prior works typically treat them in isolation, overlooking their synergistic potential. To bridge this gap, we propose KG-ViP, a unified framework that empowers MLLMs by fusing scene graphs and commonsense graphs. The core of the KG-ViP framework is a novel retrieval-and-fusion pipeline that utilizes the query as a semantic bridge to progressively integrate both graphs, synthesizing a unified structured context that facilitates reliable multi-modal reasoning. Extensive experiments on FVQA 2.0+ and MVQA benchmarks demonstrate that KG-ViP significantly outperforms existing VQA methods.

</details>


### [8] [Beyond Accuracy: Evaluating Grounded Visual Evidence in Thinking with Images](https://arxiv.org/abs/2601.11633)
*Xuchen Li,Xuzhao Li,Renjie Pi,Shiyu Hu,Jian Zhao,Jiahui Gao*

Main category: cs.CV

TL;DR: ViEBench是一个过程可验证的视觉推理基准测试，包含200张多场景高分辨率图像和专家标注的视觉证据，通过双轴矩阵提供细粒度评估指标，用于评估视觉语言模型的忠实推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要依赖结果导向的准确率，缺乏评估模型是否能够准确利用细粒度视觉线索进行多步推理的能力，需要更可解释和实用的基准来全面评估视觉语言模型的有效性。

Method: 构建包含200张多场景高分辨率图像的数据集，专家标注视觉证据，将任务按难度分为感知和推理两个维度，引入双轴矩阵提供四个诊断象限的细粒度评估指标。

Result: 实验发现：(1) 视觉语言模型有时能基于不相关区域产生正确答案；(2) 模型可能成功定位正确证据但仍无法利用其得出准确结论。ViEBench能够更透明地诊断模型行为。

Conclusion: ViEBench作为一个过程可验证的基准测试，能够更可解释和实用地全面评估视觉语言模型的忠实推理能力，揭示模型推理过程中的问题。

Abstract: Despite the remarkable progress of Vision-Language Models (VLMs) in adopting "Thinking-with-Images" capabilities, accurately evaluating the authenticity of their reasoning process remains a critical challenge. Existing benchmarks mainly rely on outcome-oriented accuracy, lacking the capability to assess whether models can accurately leverage fine-grained visual cues for multi-step reasoning. To address these limitations, we propose ViEBench, a process-verifiable benchmark designed to evaluate faithful visual reasoning. Comprising 200 multi-scenario high-resolution images with expert-annotated visual evidence, ViEBench uniquely categorizes tasks by difficulty into perception and reasoning dimensions, where reasoning tasks require utilizing localized visual details with prior knowledge. To establish comprehensive evaluation criteria, we introduce a dual-axis matrix that provides fine-grained metrics through four diagnostic quadrants, enabling transparent diagnosis of model behavior across varying task complexities. Our experiments yield several interesting observations: (1) VLMs can sometimes produce correct final answers despite grounding on irrelevant regions, and (2) they may successfully locate the correct evidence but still fail to utilize it to reach accurate conclusions. Our findings demonstrate that ViEBench can serve as a more explainable and practical benchmark for comprehensively evaluating the effectiveness agentic VLMs. The codes will be released at: https://github.com/Xuchen-Li/ViEBench.

</details>


### [9] [When Rules Fall Short: Agent-Driven Discovery of Emerging Content Issues in Short Video Platforms](https://arxiv.org/abs/2601.11634)
*Chenghui Yu,Hongwei Wang,Junwen Chen,Zixuan Wang,Bingfeng Deng,Zhuolin Hao,Hongyu Xiong,Yang Song*

Main category: cs.CV

TL;DR: 基于多模态LLM代理的短视频平台新兴问题自动发现方法，通过两阶段聚类和策略生成，显著提升问题发现效果并加速标注策略迭代


<details>
  <summary>Details</summary>
Motivation: 短视频平台趋势快速演变，新内容问题不断涌现，超出已有标注策略覆盖范围。传统人工发现问题速度太慢，导致标注策略更新延迟，严重影响内容治理效果。

Method: 提出基于多模态LLM代理的自动问题发现方法：1）自动召回包含潜在新问题的短视频；2）采用两阶段聚类策略将视频分组，每个聚类对应一个新发现的问题；3）代理从聚类中生成更新的标注策略。

Result: 方法已在实际系统中部署。离线和在线实验显示：新兴问题发现效果显著提升（F1分数提高超过20%）；后续问题治理性能增强（问题视频观看量减少约15%）；相比人工发现问题，大幅降低时间成本并加速标注策略迭代。

Conclusion: 基于多模态LLM代理的自动问题发现方法能有效解决短视频平台新兴内容问题发现延迟的挑战，显著提升内容治理效率和标注策略迭代速度。

Abstract: Trends on short-video platforms evolve at a rapid pace, with new content issues emerging every day that fall outside the coverage of existing annotation policies. However, traditional human-driven discovery of emerging issues is too slow, which leads to delayed updates of annotation policies and poses a major challenge for effective content governance. In this work, we propose an automatic issue discovery method based on multimodal LLM agents. Our approach automatically recalls short videos containing potential new issues and applies a two-stage clustering strategy to group them, with each cluster corresponding to a newly discovered issue. The agent then generates updated annotation policies from these clusters, thereby extending coverage to these emerging issues. Our agent has been deployed in the real system. Both offline and online experiments demonstrate that this agent-based method significantly improves the effectiveness of emerging-issue discovery (with an F1 score improvement of over 20%) and enhances the performance of subsequent issue governance (reducing the view count of problematic videos by approximately 15%). More importantly, compared to manual issue discovery, it greatly reduces time costs and substantially accelerates the iteration of annotation policies.

</details>


### [10] [Now You See Me, Now You Don't: A Unified Framework for Expression Consistent Anonymization in Talking Head Videos](https://arxiv.org/abs/2601.11635)
*Anil Egin,Andrea Tangherloni,Antitza Dantcheva*

Main category: cs.CV

TL;DR: Anon-NET是一个统一框架，通过扩散生成模型进行人脸视频匿名化，在保护隐私的同时保留年龄、性别、种族、姿态和表情等属性。


<details>
  <summary>Details</summary>
Motivation: 人脸视频匿名化需要在保护隐私的同时，允许计算机视觉下游任务（如表情识别、人员跟踪、动作识别）的分析。现有方法需要在身份混淆和属性保留之间取得平衡。

Method: 提出Anon-NET框架：1）使用基于扩散的生成模型进行人脸修复，通过高级属性识别和运动感知的表情转移引导；2）通过视频驱动动画对去身份化的人脸进行动画化，接受去身份化人脸和原始视频作为输入。

Result: 在VoxCeleb2、CelebV-HQ和HDTF等包含多样化面部动态的数据集上进行广泛实验，证明Anon-NET在混淆身份的同时保持了视觉真实性和时间一致性。

Conclusion: Anon-NET提供了一个有效的人脸视频匿名化解决方案，能够在保护隐私的同时保留重要的视觉属性，代码将公开发布。

Abstract: Face video anonymization is aimed at privacy preservation while allowing for the analysis of videos in a number of computer vision downstream tasks such as expression recognition, people tracking, and action recognition. We propose here a novel unified framework referred to as Anon-NET, streamlined to de-identify facial videos, while preserving age, gender, race, pose, and expression of the original video. Specifically, we inpaint faces by a diffusion-based generative model guided by high-level attribute recognition and motion-aware expression transfer. We then animate deidentified faces by video-driven animation, which accepts the de-identified face and the original video as input. Extensive experiments on the datasets VoxCeleb2, CelebV-HQ, and HDTF, which include diverse facial dynamics, demonstrate the effectiveness of AnonNET in obfuscating identity while retaining visual realism and temporal consistency. The code of AnonNet will be publicly released.

</details>


### [11] [Evaluating Self-Correcting Vision Agents Through Quantitative and Qualitative Metrics](https://arxiv.org/abs/2601.11637)
*Aradhya Dixit*

Main category: cs.CV

TL;DR: 论文提出诊断性微基准测试，量化视觉语言代理的自我修正能力，揭示任务成功率与修正成功率之间的差距，识别语义漂移为主要失败原因。


<details>
  <summary>Details</summary>
Motivation: 当前多模态基础模型使视觉语言代理能够将复杂视觉任务分解为可执行的工具计划，但迭代自我修正的定量限制和主要推理瓶颈尚未得到充分表征。

Method: 引入诊断性微基准测试，解耦任务成功率（TSR）与修正成功率（CSR），量化修正的递减回报，并通过失败分类法识别语义漂移为主要瓶颈。

Result: 任务成功率为62%，修正成功率仅为25-33%，初始能力不能预测修复能力；修正效果在三次尝试后饱和；约28%的失败由语义漂移（上下文状态丢失）导致。

Conclusion: 该基准测试通过隔离语义漂移这一推理瓶颈，为开发具有状态保持能力的可信多模态代理提供了可复现的评估框架。

Abstract: Recent progress in multimodal foundation models has enabled Vision-Language Agents (VLAs) to decompose complex visual tasks into executable tool-based plans. While recent benchmarks have begun to evaluate iterative self-correction, its quantitative limits and dominant reasoning bottlenecks remain poorly characterized. This work introduces a Diagnostic Micro-Benchmark. Our analysis decouples Task Success Rate (TSR = 62 percent) from Correction Success Rate (CSR = 25 to 33 percent), revealing that initial competence does not predict repair ability. We explicitly quantify the diminishing returns of correction, which saturates after three retries. Our Failure Taxonomy reveals a frequent factor is Semantic Drift (about 28 percent of failures), a loss of contextual state. By isolating this reasoning bottleneck, this benchmark defines a reproducible framework toward stateful, trustworthy multimodal agents.

</details>


### [12] [Confident Learning for Object Detection under Model Constraints](https://arxiv.org/abs/2601.11640)
*Yingda Yu,Jiaqi Xuan,Shuhui Shi,Xuanyu Teng,Shuyang Xu,Guanchao Tong*

Main category: cs.CV

TL;DR: 提出MDDC框架，通过数据质量诊断与修正提升边缘设备杂草检测性能，在固定轻量模型下实现5-25% mAP提升


<details>
  <summary>Details</summary>
Motivation: 边缘设备上的农业杂草检测面临严格的计算资源、模型容量和实时推理延迟限制，无法通过模型扩展或集成来提升性能，需要数据层面的优化方案

Method: 提出模型驱动数据修正（MDDC）框架，包含自动化错误分析（将检测失败分为四类：假阴性、假阳性、类别混淆、定位误差），通过结构化训练-修正-再训练流程和版本控制数据管理来系统解决数据质量问题

Result: 在多个杂草检测数据集上，使用固定轻量检测器（YOLOv8n）实现了5-25%的mAP@0.5一致提升，表明系统化数据质量优化能有效缓解固定模型容量下的性能瓶颈

Conclusion: 在边缘设备检测场景中，当模型容量固定时，通过系统化的数据质量优化可以显著提升检测性能，为资源受限环境下的计算机视觉应用提供了有效的数据中心化解决方案

Abstract: Agricultural weed detection on edge devices is subject to strict constraints on model capacity, computational resources, and real-time inference latency, which prevent performance improvements through model scaling or ensembling. This paper proposes Model-Driven Data Correction (MDDC), a data-centric framework that enhances detection performance by iteratively diagnosing and correcting data quality deficiencies. An automated error analysis procedure categorizes detection failures into four types: false negatives, false positives, class confusion, and localization errors. These error patterns are systematically addressed through a structured train-fix-retrain pipeline with version-controlled data management. Experimental results on multiple weed detection datasets demonstrate consistent improvements of 5-25 percent in mAP at 0.5 using a fixed lightweight detector (YOLOv8n), indicating that systematic data quality optimization can effectively alleviate performance bottlenecks under fixed model capacity constraints.

</details>


### [13] [Mixture of Distributions Matters: Dynamic Sparse Attention for Efficient Video Diffusion Transformers](https://arxiv.org/abs/2601.11641)
*Yuxi Liu,Yipeng Hu,Zekun Zhang,Kunze Jiang,Kun Yuan*

Main category: cs.CV

TL;DR: MOD-DiT提出了一种无需采样的动态注意力框架，通过两阶段过程准确建模视频生成中的注意力模式，解决了传统稀疏注意力方法的计算效率和质量问题。


<details>
  <summary>Details</summary>
Motivation: 扩散变换器在视频生成中面临自注意力机制二次复杂度的限制，现有稀疏注意力方法要么依赖过于简化的静态模式，要么需要计算昂贵的采样操作来实现动态稀疏性，导致模式预测不准确和生成质量下降。

Method: MOD-DiT采用两阶段过程：1）利用早期去噪步骤的先验信息，采用分布式混合方法建模高效的线性近似模型，预测特定去噪区间的掩码模式；2）在线块掩码策略动态应用这些预测的掩码，同时保持历史稀疏信息，无需重复采样操作。

Result: 在多个基准测试和模型架构上实现了持续的加速和质量改进，验证了MOD-DiT在高效高质量视频生成方面的有效性，克服了传统稀疏注意力方法的计算限制。

Conclusion: MOD-DiT通过创新的无需采样动态注意力框架，成功解决了视频生成中注意力机制的计算效率问题，为实际部署提供了可行的解决方案。

Abstract: While Diffusion Transformers (DiTs) have achieved notable progress in video generation, this long-sequence generation task remains constrained by the quadratic complexity inherent to self-attention mechanisms, creating significant barriers to practical deployment. Although sparse attention methods attempt to address this challenge, existing approaches either rely on oversimplified static patterns or require computationally expensive sampling operations to achieve dynamic sparsity, resulting in inaccurate pattern predictions and degraded generation quality. To overcome these limitations, we propose a \underline{\textbf{M}}ixtrue-\underline{\textbf{O}}f-\underline{\textbf{D}}istribution \textbf{DiT} (\textbf{MOD-DiT}), a novel sampling-free dynamic attention framework that accurately models evolving attention patterns through a two-stage process. First, MOD-DiT leverages prior information from early denoising steps and adopts a {distributed mixing approach} to model an efficient linear approximation model, which is then used to predict mask patterns for a specific denoising interval. Second, an online block masking strategy dynamically applies these predicted masks while maintaining historical sparsity information, eliminating the need for repetitive sampling operations. Extensive evaluations demonstrate consistent acceleration and quality improvements across multiple benchmarks and model architectures, validating MOD-DiT's effectiveness for efficient, high-quality video generation while overcoming the computational limitations of traditional sparse attention approaches.

</details>


### [14] [PSSF: Early osteoarthritis detection using physical synthetic knee X-ray scans and AI radiomics models](https://arxiv.org/abs/2601.11642)
*Abbas Alzubaidi,Ali Al-Bayaty*

Main category: cs.CV

TL;DR: 提出物理基础合成模拟框架(PSSF)生成可控膝关节X光片，用于骨关节炎AI评估，解决数据隐私和获取难题。


<details>
  <summary>Details</summary>
Motivation: 膝关节骨关节炎评估主要依赖主观的Kellgren-Lawrence分级，AI和影像组学需要大量标注数据，但实际中因隐私、治理和资源限制难以获取患者X光数据。

Method: 开发2D X光投影模拟器，基于参数化解剖模型生成远端股骨和近端胫骨的前后位膝关节X光片。创建180名虚拟受试者(260个膝盖)，每种采用三种成像协议。使用IBSI标准处理内侧关节区域，采用逻辑回归、随机森林和梯度提升三种ML模型进行二元和三类预测。

Result: 在IBSI协议内、跨协议和多协议场景下评估模型鲁棒性，通过类内相关系数评估特征在不同采集条件下的稳定性。

Conclusion: PSSF框架能够生成可控的合成X光数据，解决真实患者数据获取难题，为骨关节炎AI评估提供隐私安全的替代方案。

Abstract: Knee osteoarthritis (OA) is a major cause of disability worldwide and is still largely assessed using subjective radiographic grading, most commonly the Kellgren-Lawrence (KL) scale. Artificial intelligence (AI) and radiomics offer quantitative tools for OA assessment but depend on large, well-annotated image datasets, mainly X-ray scans, that are often difficult to obtain because of privacy, governance and resourcing constraints. In this research, we introduce a physics-based synthetic simulation framework (PSSF) to fully generate controllable X-ray scans without patients' involvement and violating their privacy and institutional constraints. This PSSF is a 2D X-ray projection simulator of anteroposterior knee radiographs from a parametric anatomical model of the distal femur and proximal tibia. Using PSSF, we create a virtual cohort of 180 subjects (260 knees), each is imaged under three protocols (reference, low-dose, and geometry-shift). Medial joint regions are automatically localized, preprocessed, and processed with the Image Biomarker Standardisation Initiative (IBSI). Practically, three machine learning (ML) models are utilized, logistic regression, random forest, and gradient boosting, to train binary (KL-like "0" vs. "2") and three-class (0-2) prediction radiographic images. Robustness is assessed within IBSI protocol, cross-protocol, and multi-protocol scenarios. Finally, features stability is then evaluated using intraclass correlation coefficients across acquisition changes.

</details>


### [15] [Predicting When to Trust Vision-Language Models for Spatial Reasoning](https://arxiv.org/abs/2601.11644)
*Muhammad Imran,Yugyung Lee*

Main category: cs.CV

TL;DR: 提出基于视觉的置信度估计框架，通过独立几何验证来预测何时信任VLM的空间预测，显著优于基于文本的自评估方法


<details>
  <summary>Details</summary>
Motivation: 尽管视觉语言模型在多模态任务中表现出色，但在空间推理方面存在系统性失败（准确率仅49%-54%）。为确保在机器人和自主系统中的安全部署，需要预测何时可以信任VLM的空间预测，而不是接受所有输出。

Method: 提出基于视觉的置信度估计框架，通过独立几何验证使用目标检测来验证VLM预测。融合四个信号：VLM声明与坐标的几何对齐、重叠空间模糊度、检测质量和VLM内部不确定性，使用梯度提升进行融合。

Result: 在BLIP-2上达到0.674 AUROC（比文本基线提升34.0%），在CLIP上达到0.583 AUROC（提升16.1%）。在60%目标准确率下，覆盖率达到61.9%（基线为27.6%，提升2.2倍）。特征分析显示视觉信号贡献87.4%重要性，VLM置信度仅12.7%。场景图构建中，置信度剪枝将精度从52.1%提升至78.3%，同时保留68.2%边。

Conclusion: 外部几何验证显著优于VLM自评估，提出的框架能够可靠地预测何时信任VLM的空间预测，为机器人和自主系统中的安全部署提供了有效解决方案。

Abstract: Vision-Language Models (VLMs) demonstrate impressive capabilities across multimodal tasks, yet exhibit systematic spatial reasoning failures, achieving only 49% (CLIP) to 54% (BLIP-2) accuracy on basic directional relationships. For safe deployment in robotics and autonomous systems, we need to predict when to trust VLM spatial predictions rather than accepting all outputs. We propose a vision-based confidence estimation framework that validates VLM predictions through independent geometric verification using object detection. Unlike text-based approaches relying on self-assessment, our method fuses four signals via gradient boosting: geometric alignment between VLM claims and coordinates, spatial ambiguity from overlap, detection quality, and VLM internal uncertainty. We achieve 0.674 AUROC on BLIP-2 (34.0% improvement over text-based baselines) and 0.583 AUROC on CLIP (16.1% improvement), generalizing across generative and classification architectures. Our framework enables selective prediction: at 60% target accuracy, we achieve 61.9% coverage versus 27.6% baseline (2.2x improvement) on BLIP-2. Feature analysis reveals vision-based signals contribute 87.4% of model importance versus 12.7% from VLM confidence, validating that external geometric verification outperforms self-assessment. We demonstrate reliable scene graph construction where confidence-based pruning improves precision from 52.1% to 78.3% while retaining 68.2% of edges.

</details>


### [16] [IMSAHLO: Integrating Multi-Scale Attention and Hybrid Loss Optimization Framework for Robust Neuronal Brain Cell Segmentation](https://arxiv.org/abs/2601.11645)
*Ujjwal Jain,Oshin Misra,Roshni Chakraborty,Mahua Bhattacharya*

Main category: cs.CV

TL;DR: 提出IMSAHLO框架，结合多尺度注意力与混合损失优化，用于荧光显微镜神经元细胞分割，解决密集/稀疏细胞共存、形态复杂、类别不平衡等挑战，在FNC数据集上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 荧光显微镜神经元分割面临密集与稀疏细胞共存、复杂重叠形态、严重类别不平衡等挑战，传统深度学习方法难以保持精细拓扑细节和准确边界划分。

Method: 提出IMSAHLO框架：1) 多尺度密集块(MSDBs)捕捉不同感受野特征；2) 分层注意力(HA)机制聚焦形态特征；3) 混合损失函数结合Tversky损失、Focal损失、拓扑感知中心线Dice损失和轮廓加权边界损失。

Result: 在FNC数据集上，精度81.4%，宏F1分数82.7%，微F1分数83.3%，平衡准确率99.5%，在密集和稀疏困难案例上均优于现有方法。消融研究验证了多尺度注意力和混合损失项的协同效益。

Conclusion: 该工作为适用于多种生物医学成像模态的可泛化分割模型奠定了基础，推动AI辅助分析向高通量神经生物学流程发展。

Abstract: Accurate segmentation of neuronal cells in fluorescence microscopy is a fundamental task for quantitative analysis in computational neuroscience. However, it is significantly impeded by challenges such as the coexistence of densely packed and sparsely distributed cells, complex overlapping morphologies, and severe class imbalance. Conventional deep learning models often fail to preserve fine topological details or accurately delineate boundaries under these conditions. To address these limitations, we propose a novel deep learning framework, IMSAHLO (Integrating Multi-Scale Attention and Hybrid Loss Optimization), for robust and adaptive neuronal segmentation. The core of our model features Multi-Scale Dense Blocks (MSDBs) to capture features at various receptive fields, effectively handling variations in cell density, and a Hierarchical Attention (HA) mechanism that adaptively focuses on salient morphological features to preserve Region of Interest (ROI) boundary details. Furthermore, we introduce a novel hybrid loss function synergistically combining Tversky and Focal loss to combat class imbalance, alongside a topology-aware Centerline Dice (clDice) loss and a Contour-Weighted Boundary loss to ensure topological continuity and precise separation of adjacent cells. Large-scale experiments on the public Fluorescent Neuronal Cells (FNC) dataset demonstrate that our framework outperforms state-of-the-art architectures, achieving precision of 81.4%, macro F1 score of 82.7%, micro F1 score of 83.3%, and balanced accuracy of 99.5% on difficult dense and sparse cases. Ablation studies validate the synergistic benefits of multi-scale attention and hybrid loss terms. This work establishes a foundation for generalizable segmentation models applicable to a wide range of biomedical imaging modalities, pushing AI-assisted analysis toward high-throughput neurobiological pipelines.

</details>


### [17] [Aesthetics as Structural Harm: Algorithmic Lookism Across Text-to-Image Generation and Classification](https://arxiv.org/abs/2601.11651)
*Miriam Doh,Aditya Gulati,Corina Canali,Nuria Oliver*

Main category: cs.CV

TL;DR: 研究发现文本到图像生成AI存在"算法外貌主义"偏见，将面部吸引力与积极属性系统关联，并在性别分类任务中表现出显著性别偏见，女性面孔误分类率更高，新模型加剧了审美约束。


<details>
  <summary>Details</summary>
Motivation: 研究动机是揭示文本到图像生成AI系统中存在的算法外貌主义偏见——基于外貌的系统性优待，以及这种偏见如何在下游性别分类任务中加剧不平等。

Method: 使用Stable Diffusion 2.1和3.5 Medium生成26,400张合成人脸，分析生成AI模型如何系统地将面部吸引力与积极属性关联，并评估三种性别分类算法在不同属性输入下的性别偏见。

Result: 发现三个关键危害：1) T2I模型系统编码吸引力-积极属性关联；2) 性别分类系统中女性面孔误分类率显著更高，特别是带有负面属性的女性面孔；3) 新模型通过年龄同质化、性别化曝光模式和地理简化加剧审美约束。

Conclusion: 算法外貌主义是跨AI视觉系统的系统性基础设施，通过表征和识别两方面加剧现有不平等。研究发现的偏见来自生成AI系统的嵌入偏见，而非经验事实或作者观点。

Abstract: This paper examines algorithmic lookism-the systematic preferential treatment based on physical appearance-in text-to-image (T2I) generative AI and a downstream gender classification task. Through the analysis of 26,400 synthetic faces created with Stable Diffusion 2.1 and 3.5 Medium, we demonstrate how generative AI models systematically associate facial attractiveness with positive attributes and vice-versa, mirroring socially constructed biases rather than evidence-based correlations. Furthermore, we find significant gender bias in three gender classification algorithms depending on the attributes of the input faces. Our findings reveal three critical harms: (1) the systematic encoding of attractiveness-positive attribute associations in T2I models; (2) gender disparities in classification systems, where women's faces, particularly those generated with negative attributes, suffer substantially higher misclassification rates than men's; and (3) intensifying aesthetic constraints in newer models through age homogenization, gendered exposure patterns, and geographic reductionism. These convergent patterns reveal algorithmic lookism as systematic infrastructure operating across AI vision systems, compounding existing inequalities through both representation and recognition.
  Disclaimer: This work includes visual and textual content that reflects stereotypical associations between physical appearance and socially constructed attributes, including gender, race, and traits associated with social desirability. Any such associations found in this study emerge from the biases embedded in generative AI systems-not from empirical truths or the authors' views.

</details>


### [18] [PSSI-MaxST: An Efficient Pixel-Segment Similarity Index Using Intensity and Smoothness Features for Maximum Spanning Tree Based Segmentation](https://arxiv.org/abs/2601.11654)
*Kaustubh Shivshankar Shejole,Gaurav Mishra*

Main category: cs.CV

TL;DR: 提出基于像素段相似性指数(PSSI)和最大生成树(MaxST)的交互式图分割方法，在GrabCut和Images250数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有交互式图分割方法存在计算成本高、对用户交互敏感、前景背景颜色相似时性能下降等问题，关键挑战在于图边权重的相似性度量。

Method: 提出像素段相似性指数(PSSI)，利用通道间相似性的调和均值结合像素强度和空间平滑特征；使用MeanShift进行低级分割，构建像素-段图，用PSSI计算边权重，采用最大生成树(MaxST)进行分割。

Result: 在GrabCut和Images250数据集上，方法在Jaccard指数(IoU)、F1分数、执行时间和平均误差(ME)方面优于AMOE、OneCut、SSNCut等现有图分割方法。

Conclusion: 提出的PSSI-MaxST框架通过整合颜色相似性、平滑性、纹理、形状和强局部连通性，实现了更鲁棒高效的交互式图像分割。

Abstract: Interactive graph-based segmentation methods partition an image into foreground and background regions with the aid of user inputs. However, existing approaches often suffer from high computational costs, sensitivity to user interactions, and degraded performance when the foreground and background share similar color distributions. A key factor influencing segmentation performance is the similarity measure used for assigning edge weights in the graph. To address these challenges, we propose a novel Pixel Segment Similarity Index (PSSI), which leverages the harmonic mean of inter-channel similarities by incorporating both pixel intensity and spatial smoothness features. The harmonic mean effectively penalizes dissimilarities in any individual channel, enhancing robustness. The computational complexity of PSSI is $\mathcal{O}(B)$, where $B$ denotes the number of histogram bins. Our segmentation framework begins with low-level segmentation using MeanShift, which effectively captures color, texture, and segment shape. Based on the resulting pixel segments, we construct a pixel-segment graph with edge weights determined by PSSI. For partitioning, we employ the Maximum Spanning Tree (MaxST), which captures strongly connected local neighborhoods beneficial for precise segmentation. The integration of the proposed PSSI, MeanShift, and MaxST allows our method to jointly capture color similarity, smoothness, texture, shape, and strong local connectivity. Experimental evaluations on the GrabCut and Images250 datasets demonstrate that our method consistently outperforms current graph-based interactive segmentation methods such as AMOE, OneCut, and SSNCut in terms of segmentation quality, as measured by Jaccard Index (IoU), $F_1$ score, execution time and Mean Error (ME). Code is publicly available at: https://github.com/KaustubhShejole/PSSI-MaxST.

</details>


### [19] [Zeros can be Informative: Masked Binary U-Net for Image Segmentation on Tensor Cores](https://arxiv.org/abs/2601.11660)
*Chunshu Wu,Ruibing Song,Sushant Kondguli,Tong Geng,Ang Li*

Main category: cs.CV

TL;DR: MBU-Net：一种通过掩码二进制权重和二进制激活的U-Net变体，在保持接近全精度准确率的同时，在GPU上实现2.04倍加速和3.54倍能耗降低


<details>
  <summary>Details</summary>
Motivation: 实时图像分割在AR/VR、机器人、无人机和自动驾驶等边缘设备上需要满足严格的精度、延迟和能耗要求。虽然U-Net相比大型Transformer模型在精度和效率上更平衡，但在高分辨率输入上实现实时性能仍面临计算、内存和功耗限制。极端量化（特别是二进制网络）因其硬件友好性而具有吸引力，但存在两个障碍：严重精度下降和缺乏能在通用GPU上实现高效性的端到端实现。

Method: 提出Masked Binary U-Net (MBU-Net)：基于两个经验观察（1）显式零状态对训练至关重要，通过零掩码到二进制U-Net权重会产生显著稀疏性；（2）量化敏感性在各层间是均匀的。采用成本感知掩码策略，优先在精度-成本比最高的地方进行掩码，从而在保持接近二进制效率的同时实现高精度。开发GPU执行框架，通过减法位编码方案将MBU-Net映射到Tensor Core，利用原生二进制Tensor Core BMMA指令实现高效执行。

Result: 在3个分割基准测试中，MBU-Net达到接近全精度准确率（平均下降3%），同时相比16位浮点U-Net实现2.04倍加速和3.54倍能耗降低。

Conclusion: MBU-Net通过掩码二进制权重和二进制激活，在保持高精度的同时显著提升了实时图像分割的效率，为资源受限的边缘设备上的实时分割任务提供了实用解决方案。

Abstract: Real-time image segmentation is a key enabler for AR/VR, robotics, drones, and autonomous systems, where tight accuracy, latency, and energy budgets must be met on resource-constrained edge devices. While U-Net offers a favorable balance of accuracy and efficiency compared to large transformer-based models, achieving real-time performance on high-resolution input remains challenging due to compute, memory, and power limits. Extreme quantization, particularly binary networks, is appealing for its hardware-friendly operations. However, two obstacles limit practicality: (1) severe accuracy degradation, and (2) a lack of end-to-end implementations that deliver efficiency on general-purpose GPUs.
  We make two empirical observations that guide our design. (1) An explicit zero state is essential: training with zero masking to binary U-Net weights yields noticeable sparsity. (2) Quantization sensitivity is uniform across layers. Motivated by these findings, we introduce Masked Binary U-Net (MBU-Net), obtained through a cost-aware masking strategy that prioritizes masking where it yields the highest accuracy-per-cost, reconciling accuracy with near-binary efficiency.
  To realize these gains in practice, we develop a GPU execution framework that maps MBU-Net to Tensor Cores via a subtractive bit-encoding scheme, efficiently implementing masked binary weights with binary activations. This design leverages native binary Tensor Core BMMA instructions, enabling high throughput and energy savings on widely available GPUs. Across 3 segmentation benchmarks, MBU-Net attains near full-precision accuracy (3% average drop) while delivering 2.04x speedup and 3.54x energy reductions over a 16-bit floating point U-Net.

</details>


### [20] [LTV-YOLO: A Lightweight Thermal Object Detector for Young Pedestrians in Adverse Conditions](https://arxiv.org/abs/2601.11662)
*Abdullah Jirjees,Ryan Myers,Muhammad Haris Ikram,Mohamed H. Zaki*

Main category: cs.CV

TL;DR: 提出LTV-YOLO模型，基于YOLO11架构优化，专为热成像检测儿童等弱势道路使用者设计，在低光照和恶劣天气条件下实现实时边缘设备检测。


<details>
  <summary>Details</summary>
Motivation: 传统RGB相机在低光照和恶劣天气条件下检测弱势道路使用者（特别是儿童和青少年）效果不佳，需要一种可靠的热成像检测方案来提升行人安全。

Method: 基于YOLO11架构定制热成像检测模型LTV-YOLO，集成深度可分离卷积和特征金字塔网络（FPN），针对热成像数据优化，专门检测小尺度、部分遮挡和热特征明显的弱势道路使用者。

Result: LTV-YOLO在计算效率、准确性和实时性能方面表现优异，能够在边缘设备上可靠检测低光照和恶劣天气条件下的年轻行人，为智能交通系统提供实用解决方案。

Conclusion: 该研究提出了一种专门针对热成像检测儿童等弱势道路使用者的轻量级模型，通过创新的架构集成优化了在恶劣条件下的检测性能，为行人安全提供了可扩展的解决方案。

Abstract: Detecting vulnerable road users (VRUs), particularly children and adolescents, in low light and adverse weather conditions remains a critical challenge in computer vision, surveillance, and autonomous vehicle systems. This paper presents a purpose-built lightweight object detection model designed to identify young pedestrians in various environmental scenarios. To address these challenges, our approach leverages thermal imaging from long-wave infrared (LWIR) cameras, which enhances detection reliability in conditions where traditional RGB cameras operating in the visible spectrum fail. Based on the YOLO11 architecture and customized for thermal detection, our model, termed LTV-YOLO (Lightweight Thermal Vision YOLO), is optimized for computational efficiency, accuracy and real-time performance on edge devices. By integrating separable convolutions in depth and a feature pyramid network (FPN), LTV-YOLO achieves strong performance in detecting small-scale, partially occluded, and thermally distinct VRUs while maintaining a compact architecture. This work contributes a practical and scalable solution to improve pedestrian safety in intelligent transportation systems, particularly in school zones, autonomous navigation, and smart city infrastructure. Unlike prior thermal detectors, our contribution is task-specific: a thermally only edge-capable design designed for young and small VRUs (children and distant adults). Although FPN and depthwise separable convolutions are standard components, their integration into a thermal-only pipeline optimized for short/occluded VRUs under adverse conditions is, to the best of our knowledge, novel.

</details>


### [21] [UAV-Based Infrastructure Inspections: A Literature Review and Proposed Framework for AEC+FM](https://arxiv.org/abs/2601.11665)
*Amir Farzin Nikkhah,Dong Chen,Bradford Campbell,Somayeh Asadi,Arsalan Heydarian*

Main category: cs.CV

TL;DR: 这篇综述论文分析了无人机在AEC+FM领域基础设施检测中的应用，总结了数据采集、建模、缺陷检测和决策支持的方法，提出了一个融合多模态数据和自适应路径规划的框架，并指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 无人机正在改变建筑、工程、施工和设施管理领域的基础设施检测方式，但现有方法在实时处理、多模态数据融合和泛化能力方面仍面临挑战，需要系统性的框架来整合先进技术。

Method: 通过综合150多项研究，提出了一个工作流程框架，整合RGB图像、LiDAR和热成像数据，结合基于Transformer的架构，并采用动态自适应路径规划，以提高结构缺陷、热异常和几何不一致检测的准确性。

Result: 无人机已在结构健康监测、灾害响应、城市基础设施管理、能源效率评估和文化遗产保护中证明价值。提出的框架通过多模态数据融合和自适应路径规划，能够提供精确且可操作的检测见解。

Conclusion: 尽管无人机在基础设施检测中取得显著进展，但仍需解决实时处理、数据融合和泛化等挑战。未来研究方向包括轻量级AI模型、自适应飞行规划、合成数据集和更丰富的模态融合，以优化现代基础设施检测流程。

Abstract: Unmanned Aerial Vehicles (UAVs) are transforming infrastructure inspections in the Architecture, Engineering, Construction, and Facility Management (AEC+FM) domain. By synthesizing insights from over 150 studies, this review paper highlights UAV-based methodologies for data acquisition, photogrammetric modeling, defect detection, and decision-making support. Key innovations include path optimization, thermal integration, and advanced machine learning (ML) models such as YOLO and Faster R-CNN for anomaly detection. UAVs have demonstrated value in structural health monitoring (SHM), disaster response, urban infrastructure management, energy efficiency evaluations, and cultural heritage preservation. Despite these advancements, challenges in real-time processing, multimodal data fusion, and generalizability remain. A proposed workflow framework, informed by literature and a case study, integrates RGB imagery, LiDAR, and thermal sensing with transformer-based architectures to improve accuracy and reliability in detecting structural defects, thermal anomalies, and geometric inconsistencies. The proposed framework ensures precise and actionable insights by fusing multimodal data and dynamically adapting path planning for complex environments, presented as a comprehensive step-by-step guide to address these challenges effectively. This paper concludes with future research directions emphasizing lightweight AI models, adaptive flight planning, synthetic datasets, and richer modality fusion to streamline modern infrastructure inspections.

</details>


### [22] [MATEX: Multi-scale Attention and Text-guided Explainability of Medical Vision-Language Models](https://arxiv.org/abs/2601.11666)
*Muhammad Imran,Chi Lee,Yugyung Lee*

Main category: cs.CV

TL;DR: MATEX是一个用于医学视觉语言模型的新型可解释性框架，通过多尺度注意力、文本引导空间先验和层一致性分析，生成精确、稳定且临床相关的梯度归因图。


<details>
  <summary>Details</summary>
Motivation: 现有医学视觉语言模型的可解释性方法存在空间不精确、缺乏解剖学基础、注意力粒度有限等问题，需要更忠实、可解释的模型解释来增强放射学AI应用的信任和透明度。

Method: MATEX结合了多层注意力展开、文本引导空间先验和层一致性分析，通过解剖学信息化的空间推理来生成精确的梯度归因图。

Result: 在MS-CXR数据集上的评估显示，MATEX在空间精度和与专家标注结果的匹配度方面均优于当前最先进的M2IB方法。

Conclusion: MATEX框架能够显著提升医学视觉语言模型的可解释性，增强放射学AI应用的信任和透明度，具有重要的临床应用潜力。

Abstract: We introduce MATEX (Multi-scale Attention and Text-guided Explainability), a novel framework that advances interpretability in medical vision-language models by incorporating anatomically informed spatial reasoning. MATEX synergistically combines multi-layer attention rollout, text-guided spatial priors, and layer consistency analysis to produce precise, stable, and clinically meaningful gradient attribution maps. By addressing key limitations of prior methods, such as spatial imprecision, lack of anatomical grounding, and limited attention granularity, MATEX enables more faithful and interpretable model explanations. Evaluated on the MS-CXR dataset, MATEX outperforms the state-of-the-art M2IB approach in both spatial precision and alignment with expert-annotated findings. These results highlight MATEX's potential to enhance trust and transparency in radiological AI applications.

</details>


### [23] [Generating metamers of human scene understanding](https://arxiv.org/abs/2601.11675)
*Ritik Raina,Abe Leite,Alexandros Graikos,Seoyoung Ahn,Dimitris Samaras,Gregory J. Zelinsky*

Main category: cs.CV

TL;DR: MetamerGen是一个潜在扩散模型，通过结合外围低分辨率场景信息和注视点高分辨率信息，生成与人类场景表征对齐的图像元匹配，用于研究人类场景理解机制。


<details>
  <summary>Details</summary>
Motivation: 人类视觉通过结合外围低分辨率"概要"信息和注视点高分辨率信息来理解场景，但现有方法难以生成与人类内在场景表征对齐的图像。需要一种工具来研究人类如何从这些视觉输入构建连贯的场景理解。

Method: 提出MetamerGen——基于潜在扩散模型的双流架构，使用DINOv2 token融合注视区域的详细特征和外围降级特征。通过行为实验评估生成图像与人类场景表征的感知对齐度。

Result: MetamerGen能够生成与人类场景表征对齐的图像元匹配。当生成条件基于观看者自身注视区域时，高层次语义对齐最能预测元匹配性。概念验证分析揭示了多个视觉处理层次的特征对人类判断的贡献。

Conclusion: MetamerGen是理解场景理解的强大工具，能够生成与人类内在场景表征对齐的图像，为研究人类视觉场景理解机制提供了新方法。

Abstract: Human vision combines low-resolution "gist" information from the visual periphery with sparse but high-resolution information from fixated locations to construct a coherent understanding of a visual scene. In this paper, we introduce MetamerGen, a tool for generating scenes that are aligned with latent human scene representations. MetamerGen is a latent diffusion model that combines peripherally obtained scene gist information with information obtained from scene-viewing fixations to generate image metamers for what humans understand after viewing a scene. Generating images from both high and low resolution (i.e. "foveated") inputs constitutes a novel image-to-image synthesis problem, which we tackle by introducing a dual-stream representation of the foveated scenes consisting of DINOv2 tokens that fuse detailed features from fixated areas with peripherally degraded features capturing scene context. To evaluate the perceptual alignment of MetamerGen generated images to latent human scene representations, we conducted a same-different behavioral experiment where participants were asked for a "same" or "different" response between the generated and the original image. With that, we identify scene generations that are indeed metamers for the latent scene representations formed by the viewers. MetamerGen is a powerful tool for understanding scene understanding. Our proof-of-concept analyses uncovered specific features at multiple levels of visual processing that contributed to human judgments. While it can generate metamers even conditioned on random fixations, we find that high-level semantic alignment most strongly predicts metamerism when the generated scenes are conditioned on viewers' own fixated regions.

</details>


### [24] [Conformal Point and the Calibrated Conic](https://arxiv.org/abs/2601.11679)
*Richard Hartley*

Main category: cs.CV

TL;DR: 该论文探讨了共形点和校准圆锥的概念及其相互关系，这些概念有助于可视化图像几何，并为计算图像中的角度和方向等几何属性提供了直观方法。


<details>
  <summary>Details</summary>
Motivation: 论文旨在开发更直观的图像几何可视化工具，通过引入共形点和校准圆锥的概念，简化图像中几何属性（如角度和方向）的计算过程，使复杂的几何关系更易于理解和操作。

Method: 论文提出了共形点和校准圆锥的数学框架，并详细阐述了它们之间的相互关系。这些概念基于投影几何原理，为图像几何分析提供了理论基础。

Result: 研究结果表明，共形点和校准圆锥的概念能够有效地可视化图像几何，并提供了直观的方法来计算图像中的角度和方向等几何属性，简化了传统复杂的几何计算过程。

Conclusion: 共形点和校准圆锥是理解图像几何的有力工具，它们不仅提供了直观的可视化手段，还简化了几何计算，为计算机视觉和图像处理领域的几何分析提供了新的理论框架。

Abstract: This gives some information about the conformal point and the calibrating conic, and their relationship one to the other. These concepts are useful for visualizing image geometry, and lead to intuitive ways to compute geometry, such as angles and directions in an image.

</details>


### [25] [Telling Human and Machine Handwriting Apart](https://arxiv.org/abs/2601.11700)
*Luis A. Leiva,Moises Diaz,Nuwan T. Attygalle,Miguel A. Ferrer,Rejean Plamondon*

Main category: cs.CV

TL;DR: 该研究利用手写运动作为行为生物特征，通过浅层循环神经网络检测手写输入是否由人类生成，对抗多种合成器生成的人工手写，在多个数据集上达到98.3%的AUC和1.4%的等错误率。


<details>
  <summary>Details</summary>
Motivation: 手写运动可作为独特的生物特征来验证设备或应用是否由真实用户操作，这相当于一种反向图灵测试，需要计算机区分人类生成和人工合成的手写输入，为系统安全提供额外保护层。

Method: 使用10个公开手写符号数据集（字符、数字、手势、指向轨迹和签名），通过7种不同合成器（包括运动学理论、GAN、Transformer和扩散模型）人工复制。训练浅层循环神经网络，使用非特征化的轨迹数据作为输入。

Result: 在所有合成器和数据集上平均达到98.3%的AUC和1.4%的等错误率。在小样本设置中，仅用10%数据训练即可在剩余90%测试集上保持优异性能。在域外设置中也表现出色。

Conclusion: 该研究为需要验证人类存在的计算机系统提供了有效解决方案，通过检测手写输入的真实性增加了安全防护层，能够有效防御攻击者。

Abstract: Handwriting movements can be leveraged as a unique form of behavioral biometrics, to verify whether a real user is operating a device or application. This task can be framed as a reverse Turing test in which a computer has to detect if an input instance has been generated by a human or artificially. To tackle this task, we study ten public datasets of handwritten symbols (isolated characters, digits, gestures, pointing traces, and signatures) that are artificially reproduced using seven different synthesizers, including, among others, the Kinematic Theory (Sigma h model), generative adversarial networks, Transformers, and Diffusion models. We train a shallow recurrent neural network that achieves excellent performance (98.3 percent Area Under the ROC Curve (AUC) score and 1.4 percent equal error rate on average across all synthesizers and datasets) using nonfeaturized trajectory data as input. In few-shot settings, we show that our classifier achieves such an excellent performance when trained on just 10 percent of the data, as evaluated on the remaining 90% of the data as a test set. We further challenge our classifier in out-of-domain settings, and observe very competitive results as well. Our work has implications for computerized systems that need to verify human presence, and adds an additional layer of security to keep attackers at bay.

</details>


### [26] [SemAlign: Language Guided Semi-supervised Domain Generalization](https://arxiv.org/abs/2601.11724)
*Muditha Fernando,Kajhanan Kailainathan,Krishnakanth Nagaratnam,Isuranga Udaravi Bandara Senavirathne,Ranga Rodrigo*

Main category: cs.CV

TL;DR: 本文提出了一种新的半监督域泛化方法，通过将模型中间特征与视觉语言模型的语义丰富特征空间对齐来提升性能，同时采用数据增强和正则化策略防止过拟合。


<details>
  <summary>Details</summary>
Motivation: 现有SSDG方法过度关注伪标签精度而忽视了训练过程中的数据最大化利用，限制了性能提升潜力。需要一种既能利用有限标注数据又能有效泛化到未见域的方法。

Method: 1) 将模型中间特征与视觉语言模型的语义丰富且泛化的特征空间对齐以促进域不变性；2) 采用有效的图像级数据增强策略；3) 实施输出级正则化策略来防止过拟合。

Result: 在四个基准测试上与现有SSDG基线方法进行广泛实验，结果表明该方法在定性和定量上都达到了最先进的性能。

Conclusion: 通过特征对齐、数据增强和正则化的综合方法，成功解决了SSDG中数据利用不足和过拟合的问题，实现了更好的域泛化性能。

Abstract: Semi-supervised Domain Generalization (SSDG) addresses the challenge of generalizing to unseen target domains with limited labeled data. Existing SSDG methods highlight the importance of achieving high pseudo-labeling (PL) accuracy and preventing model overfitting as the main challenges in SSDG. In this light, we show that the SSDG literature's excessive focus on PL accuracy, without consideration for maximum data utilization during training, limits potential performance improvements. We propose a novel approach to the SSDG problem by aligning the intermediate features of our model with the semantically rich and generalized feature space of a Vision Language Model (VLM) in a way that promotes domain-invariance. The above approach is enhanced with effective image-level augmentation and output-level regularization strategies to improve data utilization and minimize overfitting. Extensive experimentation across four benchmarks against existing SSDG baselines suggests that our method achieves SOTA results both qualitatively and quantitatively. The code will be made publicly available.

</details>


### [27] [SpaRRTa: A Synthetic Benchmark for Evaluating Spatial Intelligence in Visual Foundation Models](https://arxiv.org/abs/2601.11729)
*Turhan Can Kargin,Wojciech Jasiński,Adam Pardyl,Bartosz Zieliński,Marcin Przewięźlikowski*

Main category: cs.CV

TL;DR: 论文提出了SpaRRTa基准测试，用于评估视觉基础模型的空间关系识别能力，发现现有模型在空间推理方面存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 现有视觉基础模型（如DINO和CLIP）在语义理解方面表现出色，但空间推理能力有限，限制了它们在具身系统中的应用。虽然近期研究尝试将3D任务（如深度估计）融入训练，但模型在不同空间任务上的表现不一致，需要评估这些模型是否真正具备空间意识还是仅仅过拟合特定3D目标。

Method: 提出了空间关系识别任务（SpaRRTa）基准测试，通过生成任意数量的逼真图像，包含多样化场景和完全可控的物体排列，同时提供可自由访问的空间标注。该基准测试评估视觉基础模型识别图像中物体相对位置的能力。

Result: 评估了一系列最先进的视觉基础模型，揭示了它们在空间推理能力方面存在显著差异。分析提供了对现代视觉基础模型中支持或阻碍空间意识的机制的见解。

Conclusion: SpaRRTa基准测试有助于指导未来具备空间意识的视觉模型的发展，为评估和改进视觉基础模型的空间理解能力提供了有用工具。

Abstract: Visual Foundation Models (VFMs), such as DINO and CLIP, excel in semantic understanding of images but exhibit limited spatial reasoning capabilities, which limits their applicability to embodied systems. As a result, recent work incorporates some 3D tasks (such as depth estimation) into VFM training. However, VFM performance remains inconsistent across other spatial tasks, raising the question of whether these models truly have spatial awareness or overfit to specific 3D objectives. To address this question, we introduce the Spatial Relation Recognition Task (SpaRRTa) benchmark, which evaluates the ability of VFMs to identify relative positions of objects in the image. Unlike traditional 3D objectives that focus on precise metric prediction (e.g., surface normal estimation), SpaRRTa probes a fundamental capability underpinning more advanced forms of human-like spatial understanding. SpaRRTa generates an arbitrary number of photorealistic images with diverse scenes and fully controllable object arrangements, along with freely accessible spatial annotations. Evaluating a range of state-of-the-art VFMs, we reveal significant disparities between their spatial reasoning abilities. Through our analysis, we provide insights into the mechanisms that support or hinder spatial awareness in modern VFMs. We hope that SpaRRTa will serve as a useful tool for guiding the development of future spatially aware visual models.

</details>


### [28] [From Pixels to Purchase: Building and Evaluating a Taxonomy-Decoupled Visual Search Engine for Home Goods E-commerce](https://arxiv.org/abs/2601.11769)
*Cheng Lyu,Jingyue Zhang,Ryan Maunu,Mengwei Li,Vinny DeGenova,Yuanli Pei*

Main category: cs.CV

TL;DR: 提出了一种解耦分类的视觉搜索架构，使用无分类区域建议和统一嵌入进行相似性检索，并引入LLM-as-a-Judge框架进行零样本评估，在电商平台部署后提升了检索质量和用户参与度。


<details>
  <summary>Details</summary>
Motivation: 现有电商视觉搜索系统通常将目标检测与基于分类学的分类耦合，并依赖目录数据进行评估，这种方法容易受到噪声影响，限制了系统的鲁棒性和可扩展性。特别是在风格驱动的领域，用户意图主观且开放，需要更灵活通用的解决方案。

Method: 1. 提出分类学解耦架构：使用无分类区域建议生成候选区域，通过统一嵌入进行相似性检索；2. 引入LLM-as-a-Judge评估框架：以零样本方式评估查询-结果对的视觉相似性和类别相关性，无需人工标注或噪声目录数据。

Result: 在全球家居用品平台上大规模部署后，该系统提高了检索质量，带来了可衡量的用户参与度提升。离线评估指标与实际业务结果强相关，验证了方法的有效性。

Conclusion: 提出的分类学解耦视觉搜索架构和LLM-as-a-Judge评估框架解决了现有工业系统的局限性，提供了更灵活、可扩展的解决方案，在实际电商应用中取得了显著效果。

Abstract: Visual search is critical for e-commerce, especially in style-driven domains where user intent is subjective and open-ended. Existing industrial systems typically couple object detection with taxonomy-based classification and rely on catalog data for evaluation, which is prone to noise that limits robustness and scalability. We propose a taxonomy-decoupled architecture that uses classification-free region proposals and unified embeddings for similarity retrieval, enabling a more flexible and generalizable visual search. To overcome the evaluation bottleneck, we propose an LLM-as-a-Judge framework that assesses nuanced visual similarity and category relevance for query-result pairs in a zero-shot manner, removing dependence on human annotations or noise-prone catalog data. Deployed at scale on a global home goods platform, our system improves retrieval quality and yields a measurable uplift in customer engagement, while our offline evaluation metrics strongly correlate with real-world outcomes.

</details>


### [29] [studentSplat: Your Student Model Learns Single-view 3D Gaussian Splatting](https://arxiv.org/abs/2601.11772)
*Yimu Pan,Hongda Mao,Qingshuang Chen,Yelin Kim*

Main category: cs.CV

TL;DR: studentSplat：一种用于单视图3D场景重建的3D高斯泼溅方法，通过教师-学生架构和推断网络解决单视图的尺度模糊和推断问题


<details>
  <summary>Details</summary>
Motivation: 虽然前馈式3D高斯泼溅在多视图3D场景重建和单视图3D物体重建方面取得了显著进展，但单视图3D场景重建由于单视图固有的模糊性仍然研究不足

Method: 1）教师-学生架构：多视图教师模型在训练期间为单视图学生提供几何监督，解决尺度模糊并鼓励几何有效性；2）推断网络：完成缺失的场景上下文，实现高质量推断

Result: studentSplat在单视图新视角重建质量上达到最先进水平，在场景级别上与多视图方法性能相当，同时作为自监督单视图深度估计方法也表现出竞争力

Conclusion: studentSplat展示了在通用单视图3D理解任务中的潜力，通过创新的架构设计成功解决了单视图3D场景重建的挑战

Abstract: Recent advance in feed-forward 3D Gaussian splatting has enable remarkable multi-view 3D scene reconstruction or single-view 3D object reconstruction but single-view 3D scene reconstruction remain under-explored due to inherited ambiguity in single-view. We present \textbf{studentSplat}, a single-view 3D Gaussian splatting method for scene reconstruction. To overcome the scale ambiguity and extrapolation problems inherent in novel-view supervision from a single input, we introduce two techniques: 1) a teacher-student architecture where a multi-view teacher model provides geometric supervision to the single-view student during training, addressing scale ambiguity and encourage geometric validity; and 2) an extrapolation network that completes missing scene context, enabling high-quality extrapolation. Extensive experiments show studentSplat achieves state-of-the-art single-view novel-view reconstruction quality and comparable performance to multi-view methods at the scene level. Furthermore, studentSplat demonstrates competitive performance as a self-supervised single-view depth estimation method, highlighting its potential for general single-view 3D understanding tasks.

</details>


### [30] [Cross-Domain Object Detection Using Unsupervised Image Translation](https://arxiv.org/abs/2601.11779)
*Vinicius F. Arruda,Rodrigo F. Berriel,Thiago M. Paixão,Claudine Badue,Alberto F. De Souza,Nicu Sebe,Thiago Oliveira-Santos*

Main category: cs.CV

TL;DR: 提出一种通过生成目标域人工数据集来训练目标检测器的方法，使用CycleGAN和AdaIN模型进行无监督图像翻译，在自动驾驶场景中显著提升性能并接近上界。


<details>
  <summary>Details</summary>
Motivation: 现有无监督域自适应目标检测方法虽然通过中间特征对齐取得了不错效果，但实现复杂、难以解释，且与目标域训练的上界仍有差距。

Method: 使用两种无监督图像翻译模型（CycleGAN和AdaIN-based模型），仅利用源域标注数据和目标域非标注数据，生成目标域人工数据集来训练目标检测器。

Result: 在自动驾驶真实场景中取得显著改进，在大多数情况下超越现有最佳方法，进一步缩小了与目标域训练上界的差距。

Conclusion: 提出了一种更简单、更有效且可解释性更强的无监督域自适应目标检测方法，通过生成目标域人工数据集有效提升了检测性能。

Abstract: Unsupervised domain adaptation for object detection addresses the adaption of detectors trained in a source domain to work accurately in an unseen target domain. Recently, methods approaching the alignment of the intermediate features proven to be promising, achieving state-of-the-art results. However, these methods are laborious to implement and hard to interpret. Although promising, there is still room for improvements to close the performance gap toward the upper-bound (when training with the target data). In this work, we propose a method to generate an artificial dataset in the target domain to train an object detector. We employed two unsupervised image translators (CycleGAN and an AdaIN-based model) using only annotated data from the source domain and non-annotated data from the target domain. Our key contributions are the proposal of a less complex yet more effective method that also has an improved interpretability. Results on real-world scenarios for autonomous driving show significant improvements, outperforming state-of-the-art methods in most cases, further closing the gap toward the upper-bound.

</details>


### [31] [Digital FAST: An AI-Driven Multimodal Framework for Rapid and Early Stroke Screening](https://arxiv.org/abs/2601.11896)
*Ngoc-Khai Hoang,Thi-Nhu-Mai Nguyen,Huy-Hieu Pham*

Main category: cs.CV

TL;DR: 提出一个基于F.A.S.T.评估的多模态深度学习框架，通过面部表情、语音信号和上半身运动的融合，实现快速、非侵入性的卒中筛查，准确率达95.83%。


<details>
  <summary>Details</summary>
Motivation: 卒中早期识别对及时干预和改善患者预后至关重要，特别是在院前环境中。需要开发快速、非侵入性的自动筛查方法，利用F.A.S.T.评估中的多模态信息提高诊断鲁棒性。

Method: 提出多模态深度学习框架：面部动态使用基于关键点的特征和Transformer建模时间依赖；语音信号转换为梅尔频谱图并用音频频谱Transformer处理；上半身姿态序列用MLP-Mixer网络分析时空运动模式；通过注意力融合机制整合多模态表示。

Result: 在自收集的222个视频数据集（37名受试者）上，多模态模型优于单模态基线，达到95.83%准确率和96.00% F1分数，敏感性和特异性平衡良好，测试集中所有卒中病例均被成功检测。

Conclusion: 多模态学习和迁移学习在早期卒中筛查中具有潜力，但需要更大、更具临床代表性的数据集来支持可靠的现实世界部署。

Abstract: Early identification of stroke symptoms is essential for enabling timely intervention and improving patient outcomes, particularly in prehospital settings. This study presents a fast, non-invasive multimodal deep learning framework for automatic binary stroke screening based on data collected during the F.A.S.T. assessment. The proposed approach integrates complementary information from facial expressions, speech signals, and upper-body movements to enhance diagnostic robustness. Facial dynamics are represented using landmark based features and modeled with a Transformer architecture to capture temporal dependencies. Speech signals are converted into mel spectrograms and processed using an Audio Spectrogram Transformer, while upper-body pose sequences are analyzed with an MLP-Mixer network to model spatiotemporal motion patterns. The extracted modality specific representations are combined through an attention-based fusion mechanism to effectively learn cross modal interactions. Experiments conducted on a self-collected dataset of 222 videos from 37 subjects demonstrate that the proposed multimodal model consistently outperforms unimodal baselines, achieving 95.83% accuracy and a 96.00% F1-score. The model attains a strong balance between sensitivity and specificity and successfully detects all stroke cases in the test set. These results highlight the potential of multimodal learning and transfer learning for early stroke screening, while emphasizing the need for larger, clinically representative datasets to support reliable real-world deployment.

</details>


### [32] [RemoteVAR: Autoregressive Visual Modeling for Remote Sensing Change Detection](https://arxiv.org/abs/2601.11898)
*Yilmaz Korkmaz,Vishal M. Patel*

Main category: cs.CV

TL;DR: RemoteVAR是一个基于视觉自回归模型的遥感变化检测框架，通过多分辨率融合双时相特征和专门设计的自回归训练策略，在标准基准测试中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 遥感变化检测在环境监测和灾害评估中至关重要，但现有的视觉自回归模型在像素级判别任务中存在可控性弱、密集预测性能不佳和暴露偏差等限制，需要新的解决方案。

Method: 提出RemoteVAR框架：1) 通过交叉注意力将自回归预测条件化于多分辨率融合的双时相特征；2) 采用专门为变化图预测设计的自回归训练策略。

Result: 在标准变化检测基准测试中，RemoteVAR相比基于扩散模型和Transformer的基线方法取得了持续且显著的改进，为遥感变化检测建立了有竞争力的自回归替代方案。

Conclusion: RemoteVAR成功解决了视觉自回归模型在像素级判别任务中的局限性，为遥感变化检测提供了一个有效的自回归框架，代码将开源供社区使用。

Abstract: Remote sensing change detection aims to localize and characterize scene changes between two time points and is central to applications such as environmental monitoring and disaster assessment. Meanwhile, visual autoregressive models (VARs) have recently shown impressive image generation capability, but their adoption for pixel-level discriminative tasks remains limited due to weak controllability, suboptimal dense prediction performance and exposure bias. We introduce RemoteVAR, a new VAR-based change detection framework that addresses these limitations by conditioning autoregressive prediction on multi-resolution fused bi-temporal features via cross-attention, and by employing an autoregressive training strategy designed specifically for change map prediction. Extensive experiments on standard change detection benchmarks show that RemoteVAR delivers consistent and significant improvements over strong diffusion-based and transformer-based baselines, establishing a competitive autoregressive alternative for remote sensing change detection. Code will be available \href{https://github.com/yilmazkorkmaz1/RemoteVAR}{\underline{here}}.

</details>


### [33] [Towards Airborne Object Detection: A Deep Learning Analysis](https://arxiv.org/abs/2601.11907)
*Prosenjit Chatterjee,ANK Zaman*

Main category: cs.CV

TL;DR: 提出基于EfficientNetB4的双任务模型，同时进行空中物体分类和威胁等级预测，在自建AODTA数据集上取得96%分类准确率和90%威胁预测准确率


<details>
  <summary>Details</summary>
Motivation: 随着商业飞机、无人机等空中平台的快速增加，需要实时自动威胁评估系统。现有方法依赖人工监控，可扩展性有限且操作效率低下

Method: 使用EfficientNetB4构建双任务模型，同时处理分类和威胁预测；构建AODTA数据集整合多个公开数据源；与ResNet-50基线模型对比

Result: EfficientNetB4模型在物体分类上达到96%准确率，威胁等级预测达到90%准确率；优于ResNet-50基线模型；在AVD数据集和自建AODTA数据集上均表现良好

Conclusion: 该双任务模型在监视、防御和空域管理应用中具有潜力，虽然标题提到检测，但实际研究聚焦于使用预定位图像进行分类和威胁推断

Abstract: The rapid proliferation of airborne platforms, including commercial aircraft, drones, and UAVs, has intensified the need for real-time, automated threat assessment systems. Current approaches depend heavily on manual monitoring, resulting in limited scalability and operational inefficiencies. This work introduces a dual-task model based on EfficientNetB4 capable of performing airborne object classification and threat-level prediction simultaneously. To address the scarcity of clean, balanced training data, we constructed the AODTA Dataset by aggregating and refining multiple public sources. We benchmarked our approach on both the AVD Dataset and the newly developed AODTA Dataset and further compared performance against a ResNet-50 baseline, which consistently underperformed EfficientNetB4. Our EfficientNetB4 model achieved 96% accuracy in object classification and 90% accuracy in threat-level prediction, underscoring its promise for applications in surveillance, defense, and airspace management. Although the title references detection, this study focuses specifically on classification and threat-level inference using pre-localized airborne object images provided by existing datasets.

</details>


### [34] [Effects of the retina-inspired light intensity encoding on color discrimination performance](https://arxiv.org/abs/2601.11909)
*Io Yamada,Hirotsugu Okuno*

Main category: cs.CV

TL;DR: 研究比较了对数函数和Naka-Rushton函数在中心/周边Retinex模型中如何影响颜色恒常性性能，发现N-R函数结合双对立色平面表示效果最佳


<details>
  <summary>Details</summary>
Motivation: 颜色是视觉功能的重要信息源，但受光照颜色影响很大。颜色恒常性（CC）是视觉系统的重要特性，本研究旨在探索光强编码函数对C/S Retinex模型颜色恒常性性能的影响

Method: 使用两种光强编码函数：原始C/S Retinex模型的对数函数和视网膜光感受器响应模型Naka-Rushton函数。使用可变颜色LED以不同光照颜色照射视觉目标，通过HSV颜色空间和基于经典对立色理论的色平面表示颜色信息，评估模型区分不同光照下目标颜色的能力

Result: 结果显示，Naka-Rushton函数与双对立色平面表示的组合提供了更优的区分性能

Conclusion: Naka-Rushton函数作为光强编码函数，结合双对立色平面表示，能够有效提升中心/周边Retinex模型的颜色恒常性性能

Abstract: Color is an important source of information for visual functions such as object recognition, but it is greatly affected by the color of illumination. The ability to perceive the color of a visual target independent of illumination color is called color constancy (CC), and is an important feature for vision systems that use color information. In this study, we investigated the effects of the light intensity encoding function on the performance of CC of the center/surround (C/S) retinex model, which is a well-known model inspired by CC of the visual nervous system. The functions used to encode light intensity are the logarithmic function used in the original C/S retinex model and the Naka-Rushton (N-R) function, which is a model of retinal photoreceptor response. Color-variable LEDs were used to illuminate visual targets with various lighting colors, and color information computed by each model was used to evaluate the degree to which the color of visual targets illuminated with different lighting colors could be discriminated. Color information was represented using the HSV color space and a color plane based on the classical opponent color theory. The results showed that the combination of the N-R function and the double opponent color plane representation provided superior discrimination performance.

</details>


### [35] [A Training-Free Guess What Vision Language Model from Snippets to Open-Vocabulary Object Detection](https://arxiv.org/abs/2601.11910)
*Guiying Zhu,Bowen Yang,Yin Zhuang,Tong Zhang,Guanqun Wang,Zhihao Che,He Chen,Lianlin Li*

Main category: cs.CV

TL;DR: 提出GW-VLM，一种无需训练的开集目标检测方法，通过多尺度视觉语言搜索和上下文概念提示，利用预训练视觉语言模型和大语言模型实现"猜猜看"游戏机制，在自然和遥感数据集上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有开集目标检测方法通常忽视根据预训练基础模型建立通用对象认知理解的重要性。虽然大规模预训练已经构建了具有零样本能力的多功能基础模型，但如何基于这些模型形成对任意对象的通用理解范式尚未得到充分探索。

Method: 提出GW-VLM框架：1）多尺度视觉语言搜索（MS-VLS）：利用多尺度视觉语言软对齐，从类别无关目标检测结果生成片段；2）上下文概念提示（CCP）：基于MS-VLS形成概念流，让大语言模型理解片段以实现开集目标检测。该方法无需训练，通过预训练VLM和LLM进行"猜猜看"游戏。

Result: 在COCO val、Pascal VOC、DIOR和NWPU-10等自然和遥感数据集上进行广泛实验，结果表明GW-VLM无需任何训练步骤即可实现优于现有最先进方法的开集目标检测性能。

Conclusion: GW-VLM通过创新的训练免费方法，成功构建了基于预训练基础模型的通用对象理解范式，为开集目标检测提供了有效解决方案，在多个数据集上验证了其优越性能。

Abstract: Open-Vocabulary Object Detection (OVOD) aims to develop the capability to detect anything. Although myriads of large-scale pre-training efforts have built versatile foundation models that exhibit impressive zero-shot capabilities to facilitate OVOD, the necessity of creating a universal understanding for any object cognition according to already pretrained foundation models is usually overlooked. Therefore, in this paper, a training-free Guess What Vision Language Model, called GW-VLM, is proposed to form a universal understanding paradigm based on our carefully designed Multi-Scale Visual Language Searching (MS-VLS) coupled with Contextual Concept Prompt (CCP) for OVOD. This approach can engage a pre-trained Vision Language Model (VLM) and a Large Language Model (LLM) in the game of "guess what". Wherein, MS-VLS leverages multi-scale visual-language soft-alignment for VLM to generate snippets from the results of class-agnostic object detection, while CCP can form the concept of flow referring to MS-VLS and then make LLM understand snippets for OVOD. Finally, the extensive experiments are carried out on natural and remote sensing datasets, including COCO val, Pascal VOC, DIOR, and NWPU-10, and the results indicate that our proposed GW-VLM can achieve superior OVOD performance compared to the-state-of-the-art methods without any training step.

</details>


### [36] [Reliable Deep Learning for Small-Scale Classifications: Experiments on Real-World Image Datasets from Bangladesh](https://arxiv.org/abs/2601.11911)
*Muhammad Ibrahim,Alfe Suny,MD Sakib Ul Islam,Md. Imran Hossain*

Main category: cs.CV

TL;DR: 紧凑型CNN在孟加拉国五个真实世界图像数据集上表现出高分类准确率、快速收敛和低计算开销，验证了简化CNN架构在小类图像分类任务中的适用性。


<details>
  <summary>Details</summary>
Motivation: 传统CNN在图像识别任务中表现出色，但复杂架构容易在小数据集上过拟合。本研究旨在评估简化CNN架构在小类图像分类任务中的实际效果。

Method: 使用紧凑型卷积神经网络，在孟加拉国五个公开的真实世界图像数据集上进行评估，包括城市侵占、车辆检测、道路损坏和农作物等场景。

Result: 模型表现出高分类准确率、高效收敛和低计算开销。定量指标和显著性分析表明模型能有效捕捉判别性特征，并在多样化场景中具有良好泛化能力。

Conclusion: 简化CNN架构在小类图像分类任务中具有良好适用性，能够有效处理真实世界图像数据，为资源受限环境提供了实用的解决方案。

Abstract: Convolutional neural networks (CNNs) have achieved state-of-the-art performance in image recognition tasks but often involve complex architectures that may overfit on small datasets. In this study, we evaluate a compact CNN across five publicly available, real-world image datasets from Bangladesh, including urban encroachment, vehicle detection, road damage, and agricultural crops. The network demonstrates high classification accuracy, efficient convergence, and low computational overhead. Quantitative metrics and saliency analyses indicate that the model effectively captures discriminative features and generalizes robustly across diverse scenarios, highlighting the suitability of streamlined CNN architectures for small-class image classification tasks.

</details>


### [37] [From Spurious to Causal: Low-rank Orthogonal Subspace Intervention for Generalizable Face Forgery Detection](https://arxiv.org/abs/2601.11915)
*Chi Wang,Xinjue Hu,Boyu Wang,Ziwen He,Zhangjie Fu*

Main category: cs.CV

TL;DR: 提出一种通过低秩子空间干预消除人脸伪造检测中虚假相关性的新方法，仅需0.43M可训练参数就在多个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 人脸伪造检测中的泛化问题是一个关键挑战。研究发现，伪造无关信息到标签的"后门路径"会导致有偏学习，阻碍泛化。这些伪造无关信息被统称为虚假相关性因素。现有方法主要关注识别具体的虚假相关性并设计相应解决方案，但由于虚假相关性源于不可观测的混杂因素，逐个识别和处理不切实际。

Method: 提出表示空间的干预范式。不逐个追踪和阻断实例级的虚假相关性，而是将其统一建模为低秩子空间并进行干预。具体通过正交低秩投影将虚假相关特征分解为低秩子空间，然后从原始表示中移除该子空间，并训练其正交补集来捕获伪造相关特征。这种低秩投影移除有效消除了虚假相关性因素。

Result: 仅使用0.43M可训练参数，该方法在多个基准测试中实现了最先进的性能，展示了出色的鲁棒性和泛化能力。

Conclusion: 通过将虚假相关性统一建模为低秩子空间并进行干预，能够有效消除伪造检测中的虚假相关性，提高模型的泛化性能，同时保持参数效率。

Abstract: The generalization problem remains a critical challenge in face forgery detection. Some researches have discovered that ``a backdoor path" in the representations from forgery-irrelevant information to labels induces biased learning, thereby hindering the generalization. In this paper, these forgery-irrelevant information are collectively termed spurious correlations factors. Previous methods predominantly focused on identifying concrete, specific spurious correlation and designing corresponding solutions to address them. However, spurious correlations arise from unobservable confounding factors, making it impractical to identify and address each one individually. To address this, we propose an intervention paradigm for representation space. Instead of tracking and blocking various instance-level spurious correlation one by one, we uniformly model them as a low-rank subspace and intervene in them. Specifically, we decompose spurious correlation features into a low-rank subspace via orthogonal low-rank projection, subsequently removing this subspace from the original representation and training its orthogonal complement to capture forgery-related features. This low-rank projection removal effectively eliminates spurious correlation factors, ensuring that classification decision is based on authentic forgery cues. With only 0.43M trainable parameters, our method achieves state-of-the-art performance across several benchmarks, demonstrating excellent robustness and generalization.

</details>


### [38] [Effects of Gabor Filters on Classification Performance of CNNs Trained on a Limited Number of Conditions](https://arxiv.org/abs/2601.11918)
*Akito Morita,Hirotsugu Okuno*

Main category: cs.CV

TL;DR: 使用Gabor滤波器作为CNN预处理，提升边缘设备上机器人视觉应用的泛化性能并减小模型尺寸


<details>
  <summary>Details</summary>
Motivation: 边缘设备上的CNN需要小型架构，机器人视觉应用需要在有限数据条件下高效训练。视觉神经系统（VNS）能从少量视觉经验中学习，因此研究其模型Gabor滤波器作为CNN预处理的效果

Method: 使用Gabor滤波器（VNS特征提取器模型）作为CNN的预处理层，创建包含不同相机位置获取的图像数据集，在有限条件下训练CNN，比较有/无Gabor预处理的多种CNN架构性能

Result: Gabor滤波器预处理能提高CNN的泛化性能，并有助于减小CNN的模型尺寸

Conclusion: Gabor滤波器作为预处理能有效提升边缘设备上CNN在机器人视觉应用中的性能，特别是在数据有限条件下的泛化能力和模型压缩

Abstract: In this study, we propose a technique to improve the accuracy and reduce the size of convolutional neural networks (CNNs) running on edge devices for real-world robot vision applications. CNNs running on edge devices must have a small architecture, and CNNs for robot vision applications involving on-site object recognition must be able to be trained efficiently to identify specific visual targets from data obtained under a limited variation of conditions. The visual nervous system (VNS) is a good example that meets the above requirements because it learns from few visual experiences. Therefore, we used a Gabor filter, a model of the feature extractor of the VNS, as a preprocessor for CNNs to investigate the accuracy of the CNNs trained with small amounts of data. To evaluate how well CNNs trained on image data acquired under a limited variation of conditions generalize to data acquired under other conditions, we created an image dataset consisting of images acquired from different camera positions, and investigated the accuracy of the CNNs that trained using images acquired at a certain distance. The results were compared after training on multiple CNN architectures with and without Gabor filters as preprocessing. The results showed that preprocessing with Gabor filters improves the generalization performance of CNNs and contributes to reducing the size of CNNs.

</details>


### [39] [SupScene: Learning Overlap-Aware Global Descriptor for Unconstrained SfM](https://arxiv.org/abs/2601.11930)
*Xulei Shi,Maoyu Wang,Yuning Peng,Guanbo Wang,Xin Wang,Qi Chen,Pengjie Tao*

Main category: cs.CV

TL;DR: SupScene提出了一种用于SfM图像检索的新方法，通过子图训练策略和DiVLAD聚合器学习更适合几何匹配的全局描述符，在GL3D数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的图像检索方法通常关注语义相似性而非几何匹配性，使用简单的重叠/非重叠二元标签，无法捕捉SfM中需要的几何重叠关系的细微差别。

Method: 1) 采用子图训练策略，利用不同权重的几何重叠关系提供细粒度监督；2) 提出DiVLAD聚合器，利用ViT的多头注意力图；3) 设计可学习的门控机制自适应结合语义线索和视觉特征。

Result: 在GL3D数据集上达到state-of-the-art性能，显著优于NetVLAD，同时仅增加少量可训练参数。训练策略在不同聚合技术上都带来一致提升。

Conclusion: SupScene通过学习更适合SfM几何匹配的全局描述符，有效提升了图像检索性能，为SfM中的图像匹配提供了更有效的解决方案。

Abstract: Image retrieval is a critical step for alleviating the quadratic complexity of image matching in unconstrained Structure-from-Motion (SfM). However, in this context, image retrieval typically focuses more on the image pairs of geometric matchability than on those of semantic similarity, a nuance that most existing deep learning-based methods guided by batched binaries (overlapping vs. non-overlapping pairs) fail to capture. In this paper, we introduce SupScene, a novel solution that learns global descriptors tailored for finding overlapping image pairs of similar geometric nature for SfM. First, to better underline co-visible regions, we employ a subgraph-based training strategy that moves beyond equally important isolated pairs, leveraging ground-truth geometric overlapping relationships with various weights to provide fine-grained supervision via a soft supervised contrastive loss. Second, we introduce DiVLAD, a DINO-inspired VLAD aggregator that leverages the inherent multi-head attention maps from the last block of ViT. And then, a learnable gating mechanism is designed to adaptively utilize these semantically salient cues with visual features, enabling a more discriminative global descriptor. Extensive experiments on the GL3D dataset demonstrate that our method achieves state-of-the-art performance, significantly outperforming NetVLAD while introducing a negligible number of additional trainable parameters. Furthermore, we show that the proposed training strategy brings consistent gains across different aggregation techniques. Code and models are available at https://anonymous.4open.science/r/SupScene-5B73.

</details>


### [40] [Language-Guided and Motion-Aware Gait Representation for Generalizable Recognition](https://arxiv.org/abs/2601.11931)
*Zhengxian Wu,Chuanrui Zhang,Shenao Jiang,Hangrui Xu,Zirui Liao,Luyuan Zhang,Huaqiu Li,Peng Jiao,Haoqian Wang*

Main category: cs.CV

TL;DR: 提出LMGait框架，利用语言引导和运动感知进行步态识别，解决现有方法过度拟合静态噪声和未能有效捕捉动态运动区域的问题


<details>
  <summary>Details</summary>
Motivation: 现有步态识别方法通常依赖复杂架构直接从图像提取特征，并通过池化操作获得序列级表示，这种设计容易过度拟合静态噪声（如衣物），同时未能有效捕捉动态运动区域

Method: 提出LMGait框架，利用设计的步态相关语言提示来捕捉步态序列中的关键运动特征，实现语言引导和运动感知的步态识别

Result: 论文声称提出的方法能够更好地捕捉动态运动特征，减少对静态噪声的过度拟合

Conclusion: LMGait框架通过语言引导和运动感知机制，有效解决了现有步态识别方法在捕捉动态特征和避免静态噪声过度拟合方面的局限性

Abstract: Gait recognition is emerging as a promising technology and an innovative field within computer vision. However, existing methods typically rely on complex architectures to directly extract features from images and apply pooling operations to obtain sequence-level representations. Such designs often lead to overfitting on static noise (e.g., clothing), while failing to effectively capture dynamic motion regions.To address the above challenges, we present a Language guided and Motion-aware gait recognition framework, named LMGait.In particular, we utilize designed gait-related language cues to capture key motion features in gait sequences.

</details>


### [41] [Deep learning-based neurodevelopmental assessment in preterm infants](https://arxiv.org/abs/2601.11944)
*Lexin Ren,Jiamiao Lu,Weichuan Zhang,Benqing Wu,Tuo Wang,Yi Liao,Jiapan Guo,Changming Sun,Liang Guo*

Main category: cs.CV

TL;DR: 提出Hierarchical Dense Attention Network用于早产儿脑MRI白质和灰质分割，解决等信号强度组织区分难题，性能优于现有方法


<details>
  <summary>Details</summary>
Motivation: 早产儿神经发育延迟风险高，需要早期识别。脑MRI体积分割是评估神经发育的有前景方法，但早产儿白质和灰质在MRI上信号强度相似（等信号外观），导致准确分割困难

Method: 提出Hierarchical Dense Attention Network，结合3D空间-通道注意力机制和注意力引导的密集上采样策略，增强低对比度体积数据的特征区分能力

Result: 定量实验显示该方法在分割性能上优于最先进的基线方法，有效解决了等信号组织区分挑战。应用算法证实早产儿白质和灰质体积显著低于足月儿

Conclusion: 提出的网络能够准确分割早产儿脑MRI中的白质和灰质，为早产相关的神经发育延迟提供了额外的影像学证据，代码已开源

Abstract: Preterm infants (born between 28 and 37 weeks of gestation) face elevated risks of neurodevelopmental delays, making early identification crucial for timely intervention. While deep learning-based volumetric segmentation of brain MRI scans offers a promising avenue for assessing neonatal neurodevelopment, achieving accurate segmentation of white matter (WM) and gray matter (GM) in preterm infants remains challenging due to their comparable signal intensities (isointense appearance) on MRI during early brain development. To address this, we propose a novel segmentation neural network, named Hierarchical Dense Attention Network. Our architecture incorporates a 3D spatial-channel attention mechanism combined with an attention-guided dense upsampling strategy to enhance feature discrimination in low-contrast volumetric data. Quantitative experiments demonstrate that our method achieves superior segmentation performance compared to state-of-the-art baselines, effectively tackling the challenge of isointense tissue differentiation. Furthermore, application of our algorithm confirms that WM and GM volumes in preterm infants are significantly lower than those in term infants, providing additional imaging evidence of the neurodevelopmental delays associated with preterm birth. The code is available at: https://github.com/ICL-SUST/HDAN.

</details>


### [42] [Decoder Gradient Shields: A Family of Provable and High-Fidelity Methods Against Gradient-Based Box-Free Watermark Removal](https://arxiv.org/abs/2601.11952)
*Haonan An,Guang Hua,Wei Du,Hangcheng Cao,Yihang Tao,Guowen Xu,Susanto Rahardja,Yuguang Fang*

Main category: cs.CV

TL;DR: 提出Decoder Gradient Shields (DGS)防御机制，保护无盒模型水印的解码器免受基于梯度泄露查询的攻击，在多种应用场景中实现100%防御成功率。


<details>
  <summary>Details</summary>
Motivation: 无盒模型水印因其模型无关性和对生成模型高熵输出的灵活管理而受到关注。现有研究主要关注编码器的鲁棒性，而解码器被忽视，导致水印面临攻击。本文识别出一种针对解码器的攻击，攻击者利用查询响应获取反向传播梯度来训练水印移除器。

Method: 提出Decoder Gradient Shields (DGS)防御机制家族，包括输出层DGS-O、输入层DGS-I和层间DGS-L。通过重新定向和缩放水印通道梯度泄露查询的梯度，防止水印移除器达到低损失值的训练收敛，同时保持解码器输出的图像质量。DGS-O有闭式解，所有DGS都有可证明的性能。

Result: 在去雨和图像生成任务中，使用最先进的无盒水印技术进行实验，DGS在所有设置下都实现了100%的防御成功率，有效保护水印免受攻击。

Conclusion: DGS机制成功解决了无盒模型水印中解码器面临的梯度泄露攻击问题，为DNN知识产权保护提供了有效的防御方案，在保持图像质量的同时确保水印安全性。

Abstract: Box-free model watermarking has gained significant attention in deep neural network (DNN) intellectual property protection due to its model-agnostic nature and its ability to flexibly manage high-entropy image outputs from generative models. Typically operating in a black-box manner, it employs an encoder-decoder framework for watermark embedding and extraction. While existing research has focused primarily on the encoders for the robustness to resist various attacks, the decoders have been largely overlooked, leading to attacks against the watermark. In this paper, we identify one such attack against the decoder, where query responses are utilized to obtain backpropagated gradients to train a watermark remover. To address this issue, we propose Decoder Gradient Shields (DGSs), a family of defense mechanisms, including DGS at the output (DGS-O), at the input (DGS-I), and in the layers (DGS-L) of the decoder, with a closed-form solution for DGS-O and provable performance for all DGS. Leveraging the joint design of reorienting and rescaling of the gradients from watermark channel gradient leaking queries, the proposed DGSs effectively prevent the watermark remover from achieving training convergence to the desired low-loss value, while preserving image quality of the decoder output. We demonstrate the effectiveness of our proposed DGSs in diverse application scenarios. Our experimental results on deraining and image generation tasks with the state-of-the-art box-free watermarking show that our DGSs achieve a defense success rate of 100% under all settings.

</details>


### [43] [Real-Time Multi-Modal Embedded Vision Framework for Object Detection Facial Emotion Recognition and Biometric Identification on Low-Power Edge Platforms](https://arxiv.org/abs/2601.11970)
*S. M. Khalid Bin Zahid,Md. Rakibul Hasan Nishat,Abdul Hasib,Md. Rakibul Hasan,Md. Ashiqussalehin,Md. Sahadat Hossen Sajib,A. S. M. Ahsanul Sarkar Akib*

Main category: cs.CV

TL;DR: 提出一个在树莓派5边缘设备上部署的实时多模态视觉框架，通过自适应调度机制将目标检测、人脸识别和情绪检测集成到统一管道中，相比持续处理减少65%计算负载。


<details>
  <summary>Details</summary>
Motivation: 现有智能监控系统通常独立处理感知任务（如目标检测、人脸识别、情绪分析），缺乏统一的、自适应的运行时调度器来根据上下文触发动态分配计算资源，这限制了它们在低功耗边缘设备上的整体理解能力和效率。

Method: 提出一个实时多模态视觉框架，将目标检测（YOLOv8n）、所有者特定人脸识别（基于FaceNet的自定义嵌入系统）和情绪检测（DeepFace的CNN）集成到统一管道中。核心是自适应调度机制，通过选择性激活模块来减少计算负载。

Result: 目标检测模块平均精度（AP）达到0.861，人脸识别准确率达到88%，情绪检测显示强大的区分能力（特定情绪的AUC高达0.97），系统以5.6帧/秒的速度运行，计算负载相比持续处理减少65%。

Conclusion: 上下文感知调度是实现复杂多模态AI在成本效益边缘硬件上运行的关键，使智能感知更加可访问且保护隐私。

Abstract: Intelligent surveillance systems often handle perceptual tasks such as object detection, facial recognition, and emotion analysis independently, but they lack a unified, adaptive runtime scheduler that dynamically allocates computational resources based on contextual triggers. This limits their holistic understanding and efficiency on low-power edge devices. To address this, we present a real-time multi-modal vision framework that integrates object detection, owner-specific face recognition, and emotion detection into a unified pipeline deployed on a Raspberry Pi 5 edge platform. The core of our system is an adaptive scheduling mechanism that reduces computational load by 65\% compared to continuous processing by selectively activating modules such as, YOLOv8n for object detection, a custom FaceNet-based embedding system for facial recognition, and DeepFace's CNN for emotion classification. Experimental results demonstrate the system's efficacy, with the object detection module achieving an Average Precision (AP) of 0.861, facial recognition attaining 88\% accuracy, and emotion detection showing strong discriminatory power (AUC up to 0.97 for specific emotions), while operating at 5.6 frames per second. Our work demonstrates that context-aware scheduling is the key to unlocking complex multi-modal AI on cost-effective edge hardware, making intelligent perception more accessible and privacy-preserving.

</details>


### [44] [AVIR: Adaptive Visual In-Document Retrieval for Efficient Multi-Page Document Question Answering](https://arxiv.org/abs/2601.11976)
*Zongmin Li,Yachuan Li,Lei Kang,Dimosthenis Karatzas,Wenkang Ma*

Main category: cs.CV

TL;DR: AVIR框架通过自适应视觉文档检索，先评估页面相关性，再聚类筛选，仅将相关页面输入冻结的大视觉语言模型，显著减少计算量并提升MP-DocVQA性能。


<details>
  <summary>Details</summary>
Motivation: 多页文档视觉问答面临两个主要挑战：长文档计算资源消耗大，以及大视觉语言模型的注意力机制在长文档上效果下降。需要一种高效的方法来减少输入页面数量而不损失性能。

Method: 提出自适应视觉文档检索(AVIR)框架：1) 轻量级检索模型为每个页面评分；2) 根据分数分布聚类页面自适应选择相关内容；3) 对聚类页面进行Top-K筛选保持上下文紧凑；4) 对短文档使用相关性概率阈值选择页面；5) 仅将选定页面输入冻结的LVLM生成答案。

Result: 在MP-DocVQA数据集上，AVIR将问答所需的平均页面数减少70%，达到84.58%的ANLS分数，超越先前方法且计算成本显著降低。在SlideVQA和DUDE基准测试中也验证了有效性。

Conclusion: AVIR框架通过自适应页面选择和检索，有效解决了多页文档VQA的计算效率和注意力机制问题，无需微调模型，在多个基准测试中表现出色。

Abstract: Multi-page Document Visual Question Answering (MP-DocVQA) remains challenging because long documents not only strain computational resources but also reduce the effectiveness of the attention mechanism in large vision-language models (LVLMs). We tackle these issues with an Adaptive Visual In-document Retrieval (AVIR) framework. A lightweight retrieval model first scores each page for question relevance. Pages are then clustered according to the score distribution to adaptively select relevant content. The clustered pages are screened again by Top-K to keep the context compact. However, for short documents, clustering reliability decreases, so we use a relevance probability threshold to select pages. The selected pages alone are fed to a frozen LVLM for answer generation, eliminating the need for model fine-tuning. The proposed AVIR framework reduces the average page count required for question answering by 70%, while achieving an ANLS of 84.58% on the MP-DocVQA dataset-surpassing previous methods with significantly lower computational cost. The effectiveness of the proposed AVIR is also verified on the SlideVQA and DUDE benchmarks. The code is available at https://github.com/Li-yachuan/AVIR.

</details>


### [45] [Nip Rumors in the Bud: Retrieval-Guided Topic-Level Adaptation for Test-Time Fake News Video Detection](https://arxiv.org/abs/2601.11981)
*Jian Lang,Rongpei Hong,Ting Zhong,Yong Wang,Fan Zhou*

Main category: cs.CV

TL;DR: RADAR是一个用于假新闻视频检测的测试时自适应框架，通过检索引导的适应范式处理未见过的新闻主题，利用稳定视频作为参考来对齐不稳定实例，实现对新主题的快速适应。


<details>
  <summary>Details</summary>
Motivation: 现有假新闻视频检测方法通常假设训练和测试阶段新闻主题分布一致，无法检测与新兴事件和未见主题相关的假新闻视频，需要能够适应未见新闻视频的测试时自适应框架。

Method: 提出RADAR框架，采用检索引导的适应范式：1) 基于熵选择的检索机制，为不稳定实例提供稳定相关的参考视频；2) 稳定锚点引导的对齐模块，通过分布级匹配将不稳定实例表示与源域对齐；3) 目标域感知的自训练范式，生成增强的伪标签来适应快速变化的标签分布。

Result: 大量实验表明RADAR在测试时假新闻视频检测方面取得了优越性能，能够对未见过的假新闻视频主题实现强大的即时适应能力。

Conclusion: RADAR是首个实现测试时自适应的假新闻视频检测框架，通过创新的检索引导适应范式有效解决了未见新闻主题的检测问题，为动态变化的假新闻检测提供了有效解决方案。

Abstract: Fake News Video Detection (FNVD) is critical for social stability. Existing methods typically assume consistent news topic distribution between training and test phases, failing to detect fake news videos tied to emerging events and unseen topics. To bridge this gap, we introduce RADAR, the first framework that enables test-time adaptation to unseen news videos. RADAR pioneers a new retrieval-guided adaptation paradigm that leverages stable (source-close) videos from the target domain to guide robust adaptation of semantically related but unstable instances. Specifically, we propose an Entropy Selection-Based Retrieval mechanism that provides videos with stable (low-entropy), relevant references for adaptation. We also introduce a Stable Anchor-Guided Alignment module that explicitly aligns unstable instances' representations to the source domain via distribution-level matching with their stable references, mitigating severe domain discrepancies. Finally, our novel Target-Domain Aware Self-Training paradigm can generate informative pseudo-labels augmented by stable references, capturing varying and imbalanced category distributions in the target domain and enabling RADAR to adapt to the fast-changing label distributions. Extensive experiments demonstrate that RADAR achieves superior performance for test-time FNVD, enabling strong on-the-fly adaptation to unseen fake news video topics.

</details>


### [46] [An AI-IoT Based Smart Wheelchair with Gesture-Controlled Mobility, Deep Learning-Based Obstacle Detection, Multi-Sensor Health Monitoring, and Emergency Alert System](https://arxiv.org/abs/2601.11983)
*Md. Asiful Islam,Abdul Hasib,Tousif Mahmud Emon,Khandaker Tabin Hasan,A. S. M. Ahsanul Sarkar Akib*

Main category: cs.CV

TL;DR: 提出一个基于AI-IoT的智能轮椅系统，整合手势控制、实时物体检测和健康监测，为残障人士和老年人提供经济实惠的辅助解决方案。


<details>
  <summary>Details</summary>
Motivation: 传统轮椅缺乏动态功能，现有智能轮椅成本高昂且功能单一，需要为日益增长的残障和老年人群提供先进、个性化且经济实惠的辅助技术。

Method: 采用模块化低成本架构，结合手套手势控制（95.5%成功率）、超声波碰撞避免（94%准确率）、YOLOv8物体检测（带听觉反馈），以及持续监测心率、血氧、心电图、体温等生命体征并上传至ThingSpeak平台。

Result: 手势控制成功率95.5%，超声波障碍检测准确率94%，YOLOv8物体检测达到91.5%精确率、90.2%召回率和90.8% F1分数，系统能触发关键状况的邮件警报。

Conclusion: 这种集成多模态方法提供了实用、可扩展且经济实惠的解决方案，通过弥合创新研究与实际部署之间的差距，显著增强了用户的自主性、安全性和独立性。

Abstract: The growing number of differently-abled and elderly individuals demands affordable, intelligent wheelchairs that combine safe navigation with health monitoring. Traditional wheelchairs lack dynamic features, and many smart alternatives remain costly, single-modality, and limited in health integration. Motivated by the pressing demand for advanced, personalized, and affordable assistive technologies, we propose a comprehensive AI-IoT based smart wheelchair system that incorporates glove-based gesture control for hands-free navigation, real-time object detection using YOLOv8 with auditory feedback for obstacle avoidance, and ultrasonic for immediate collision avoidance. Vital signs (heart rate, SpO$_2$, ECG, temperature) are continuously monitored, uploaded to ThingSpeak, and trigger email alerts for critical conditions. Built on a modular and low-cost architecture, the gesture control achieved a 95.5\% success rate, ultrasonic obstacle detection reached 94\% accuracy, and YOLOv8-based object detection delivered 91.5\% Precision, 90.2\% Recall, and a 90.8\% F1-score. This integrated, multi-modal approach offers a practical, scalable, and affordable solution, significantly enhancing user autonomy, safety, and independence by bridging the gap between innovative research and real-world deployment.

</details>


### [47] [Structural Graph Neural Networks with Anatomical Priors for Explainable Chest X-ray Diagnosis](https://arxiv.org/abs/2601.11987)
*Khaled Berkani*

Main category: cs.CV

TL;DR: 提出一种结合解剖先验的结构化图推理框架，用于可解释的视觉诊断，通过定制化的结构传播机制建模空间关系，支持病灶级预测和诊断级推理。


<details>
  <summary>Details</summary>
Motivation: 当前基于视觉的诊断方法缺乏可解释性，传统图神经网络使用通用消息传递机制，未能充分利用解剖结构先验知识。需要一种能够显式建模空间关系、提供内在可解释性的结构化推理框架。

Method: 将卷积特征图重新解释为补丁级图，节点编码外观和空间坐标，边反映局部结构邻接关系。引入定制的结构传播机制，显式建模相对空间关系作为推理过程的一部分，而非被动的关系表示。

Result: 通过胸部X光案例研究证明，结构先验能够指导关系推理并提高可解释性。模型支持节点级病灶感知预测和图级诊断推理，通过学习节点重要性分数提供内在可解释性，无需依赖事后可视化技术。

Conclusion: 该框架将图作为结构化推理的计算基础，提供领域无关的结构感知和可解释学习方案。虽然以医学影像为案例，但适用于更广泛的人工智能系统，推动图作为计算基质的结构感知和可解释学习研究。

Abstract: We present a structural graph reasoning framework that incorporates explicit anatomical priors for explainable vision-based diagnosis. Convolutional feature maps are reinterpreted as patch-level graphs, where nodes encode both appearance and spatial coordinates, and edges reflect local structural adjacency. Unlike conventional graph neural networks that rely on generic message passing, we introduce a custom structural propagation mechanism that explicitly models relative spatial relations as part of the reasoning process. This design enables the graph to act as an inductive bias for structured inference rather than a passive relational representation. The proposed model jointly supports node-level lesion-aware predictions and graph-level diagnostic reasoning, yielding intrinsic explainability through learned node importance scores without relying on post-hoc visualization techniques. We demonstrate the approach through a chest X-ray case study, illustrating how structural priors guide relational reasoning and improve interpretability. While evaluated in a medical imaging context, the framework is domain-agnostic and aligns with the broader vision of graph-based reasoning across artificial intelligence systems. This work contributes to the growing body of research exploring graphs as computational substrates for structure-aware and explainable learning.

</details>


### [48] [DAOS: A Multimodal In-cabin Behavior Monitoring with Driver Action-Object Synergy Dataset](https://arxiv.org/abs/2601.11990)
*Yiming Li,Chen Cai,Tianyi Liu,Dan Lin,Wenqian Wang,Wenfei Liang,Bingbing Li,Kim-Hui Yap*

Main category: cs.CV

TL;DR: 提出DAOS数据集和AOR-Net模型，通过建模驾驶员动作与物体关系提升驾驶监控中的动作识别准确率


<details>
  <summary>Details</summary>
Motivation: 现有驾驶员监控数据集缺乏准确的物体位置标注或未将物体与相关动作关联，导致相似的上半身动作难以区分，影响可靠的动作识别

Method: 1) 引入DAOS数据集：包含9,787个视频片段，标注36个细粒度驾驶员动作和15个物体类别，提供多模态多视角数据；2) 提出AOR-Net模型：通过多级推理和动作链提示机制建模动作-物体-关系逻辑，引入思维混合模块动态选择关键知识

Result: AOR-Net在多个数据集上优于其他最先进方法，在物体丰富和稀缺条件下都表现出更强的鲁棒性

Conclusion: 通过DAOS数据集和AOR-Net模型，有效解决了驾驶员监控中相似动作区分困难的问题，证明了建模人-物关系对动作识别的重要性

Abstract: In driver activity monitoring, movements are mostly limited to the upper body, which makes many actions look similar. To tell these actions apart, human often rely on the objects the driver is using, such as holding a phone compared with gripping the steering wheel. However, most existing driver-monitoring datasets lack accurate object-location annotations or do not link objects to their associated actions, leaving a critical gap for reliable action recognition. To address this, we introduce the Driver Action with Object Synergy (DAOS) dataset, comprising 9,787 video clips annotated with 36 fine-grained driver actions and 15 object classes, totaling more than 2.5 million corresponding object instances. DAOS offers multi-modal, multi-view data (RGB, IR, and depth) from front, face, left, and right perspectives. Although DAOS captures a wide range of cabin objects, only a few are directly relevant to each action for prediction, so focusing on task-specific human-object relations is essential. To tackle this challenge, we propose the Action-Object-Relation Network (AOR-Net). AOR-Net comprehends complex driver actions through multi-level reasoning and a chain-of-action prompting mechanism that models the logical relationships among actions, objects, and their relations. Additionally, the Mixture of Thoughts module is introduced to dynamically select essential knowledge at each stage, enhancing robustness in object-rich and object-scarce conditions. Extensive experiments demonstrate that our model outperforms other state-of-the-art methods on various datasets.

</details>


### [49] [SMc2f: Robust Scenario Mining for Robotic Autonomy from Coarse to Fine](https://arxiv.org/abs/2601.12010)
*Yifei Chen,Ross Greer*

Main category: cs.CV

TL;DR: 提出SMc2f框架，通过视觉语言模型粗筛、构建成功案例库、文本-轨迹对比学习，改进自动驾驶场景挖掘的检索质量和效率


<details>
  <summary>Details</summary>
Motivation: 现有RefAV框架依赖轨迹标签检索，忽略了自然语言与原始RGB图像的直接联系，且受上游3D目标检测和跟踪质量影响，轨迹数据不准确导致时空定位不准确

Method: 1) 使用视觉语言模型进行粗粒度图像-文本过滤；2) 在RefAV基础上构建成功挖掘案例库，自动检索示例进行少样本条件学习；3) 引入文本-轨迹对比学习，在共享嵌入空间拉近匹配对、推开不匹配对，形成细粒度匹配器

Result: 在公开数据集上实验表明，在检索质量和效率方面都有显著提升

Conclusion: 提出的SMc2f框架通过从粗到细的流程，结合视觉语言模型和对比学习，有效解决了现有场景挖掘方法的局限性，实现了更鲁棒的自动驾驶场景检索

Abstract: The safety validation of autonomous robotic vehicles hinges on systematically testing their planning and control stacks against rare, safety-critical scenarios. Mining these long-tail events from massive real-world driving logs is therefore a critical step in the robotic development lifecycle. The goal of the Scenario Mining task is to retrieve useful information to enable targeted re-simulation, regression testing, and failure analysis of the robot's decision-making algorithms. RefAV, introduced by the Argoverse team, is an end-to-end framework that uses large language models (LLMs) to spatially and temporally localize scenarios described in natural language. However, this process performs retrieval on trajectory labels, ignoring the direct connection between natural language and raw RGB images, which runs counter to the intuition of video retrieval; it also depends on the quality of upstream 3D object detection and tracking. Further, inaccuracies in trajectory data lead to inaccuracies in downstream spatial and temporal localization. To address these issues, we propose Robust Scenario Mining for Robotic Autonomy from Coarse to Fine (SMc2f), a coarse-to-fine pipeline that employs vision-language models (VLMs) for coarse image-text filtering, builds a database of successful mining cases on top of RefAV and automatically retrieves exemplars to few-shot condition the LLM for more robust retrieval, and introduces text-trajectory contrastive learning to pull matched pairs together and push mismatched pairs apart in a shared embedding space, yielding a fine-grained matcher that refines the LLM's candidate trajectories. Experiments on public datasets demonstrate substantial gains in both retrieval quality and efficiency.

</details>


### [50] [SAR-Based Marine Oil Spill Detection Using the DeepSegFusion Architecture](https://arxiv.org/abs/2601.12015)
*Pavan Kumar Yata,Pediredla Pradeep,Goli Himanish,Swathi M*

Main category: cs.CV

TL;DR: 提出DeepSegFusion混合深度学习模型用于SAR图像油污分割，结合SegNet和DeepLabV3+并加入注意力特征融合机制，显著降低误报率，适用于近实时油污监测。


<details>
  <summary>Details</summary>
Motivation: 传统基于阈值的方法在卫星图像油污检测中因风浪条纹、船尾波等类似现象导致高误报率，需要更精确的检测方法。

Method: 提出DeepSegFusion混合深度学习模型，整合SegNet和DeepLabV3+架构，加入基于注意力的特征融合机制，提升边界精度和上下文理解能力。

Result: 在SAR油污数据集上达到94.85%准确率、0.5685 IoU和0.9330 ROC-AUC，误报率比基线模型降低64.4%，在各种海洋条件下表现稳定。

Conclusion: DeepSegFusion模型能有效降低油污检测的误报率，在各种海洋条件下表现稳定，适用于近实时油污监测场景。

Abstract: Detection of oil spills from satellite images is essential for both environmental surveillance and maritime safety. Traditional threshold-based methods frequently encounter performance degradation due to very high false alarm rates caused by look-alike phenomena such as wind slicks and ship wakes. Here, a hybrid deep learning model, DeepSegFusion, is presented for oil spill segmentation in Synthetic Aperture Radar (SAR) images. The model uses SegNet and DeepLabV3+ integrated with an attention-based feature fusion mechanism to achieve better boundary precision as well as improved contextual understanding. Results obtained on SAR oil spill datasets, including ALOS PALSAR imagery, confirm that the proposed DeepSegFusion model achieves an accuracy of 94.85%, an Intersection over Union (IoU) of 0.5685, and a ROC-AUC score of 0.9330. The proposed method delivers more than three times fewer false detections compared to individual baseline models and traditional non-segmentation methods, achieving a reduction of 64.4%. These results indicate that DeepSegFusion is a stable model under various marine conditions and can therefore be used in near real-time oil spill monitoring scenarios.

</details>


### [51] [DIAMOND-SSS: Diffusion-Augmented Multi-View Optimization for Data-efficient SubSurface Scattering](https://arxiv.org/abs/2601.12020)
*Guillermo Figueroa-Araneda,Iris Diana Jimenez,Florian Hofherr,Manny Ko,Hector Andrade-Loarca,Daniel Cremers*

Main category: cs.CV

TL;DR: DIAMOND-SSS：使用扩散模型进行数据增强，仅需极少图像（最少10张）即可实现高质量半透明材质重建，将真实采集需求减少90%


<details>
  <summary>Details</summary>
Motivation: 半透明材质（如蜡、玉、大理石、皮肤）的次表面散射效果在神经渲染中建模困难，传统方法需要密集的多视角多光照数据集（通常超过100个视角和112个OLAT），数据采集成本高昂

Method: 1）使用扩散模型进行新视角合成和重光照，基于估计的几何信息，仅需不到7%的数据集进行训练；2）引入光照无关的几何先验：多视角轮廓一致性损失和多视角深度一致性损失，以稳定稀疏或合成监督下的重建

Result: 在所有稀疏度条件下，DIAMOND-SSS在可重光照高斯渲染中达到最先进质量，相比SSS-3DGS将真实采集需求减少高达90%，仅需10张图像即可实现高质量重建

Conclusion: DIAMOND-SSS通过数据高效的扩散模型增强和几何一致性约束，显著降低了半透明材质重建的数据需求，为高质量神经渲染提供了实用的解决方案

Abstract: Subsurface scattering (SSS) gives translucent materials -- such as wax, jade, marble, and skin -- their characteristic soft shadows, color bleeding, and diffuse glow. Modeling these effects in neural rendering remains challenging due to complex light transport and the need for densely captured multi-view, multi-light datasets (often more than 100 views and 112 OLATs).
  We present DIAMOND-SSS, a data-efficient framework for high-fidelity translucent reconstruction from extremely sparse supervision -- even as few as ten images. We fine-tune diffusion models for novel-view synthesis and relighting, conditioned on estimated geometry and trained on less than 7 percent of the dataset, producing photorealistic augmentations that can replace up to 95 percent of missing captures. To stabilize reconstruction under sparse or synthetic supervision, we introduce illumination-independent geometric priors: a multi-view silhouette consistency loss and a multi-view depth consistency loss.
  Across all sparsity regimes, DIAMOND-SSS achieves state-of-the-art quality in relightable Gaussian rendering, reducing real capture requirements by up to 90 percent compared to SSS-3DGS.

</details>


### [52] [\textit{FocaLogic}: Logic-Based Interpretation of Visual Model Decisions](https://arxiv.org/abs/2601.12049)
*Chenchen Zhao,Muxi Chen,Qiang Xu*

Main category: cs.CV

TL;DR: FocaLogic是一个模型无关的视觉模型解释框架，通过逻辑表示来量化和解释模型决策，识别关键视觉区域并转化为逻辑表达式，提供定量评估指标。


<details>
  <summary>Details</summary>
Motivation: 现有视觉模型解释方法存在两个主要问题：要么依赖白盒模型访问权限，要么缺乏足够的定量严谨性。在高风险应用中，模型的可解释性至关重要，需要解决这些限制。

Method: FocaLogic框架识别影响模型预测的最小可解释视觉区域子集（称为视觉焦点），将这些视觉焦点转化为精确紧凑的逻辑表达式，并提出一套定量指标（焦点精度、召回率、发散度）来客观评估模型行为。

Result: 实证分析表明FocaLogic能够揭示关键洞察：训练引起的集中性、通过泛化提高焦点准确性、以及在偏见和对抗攻击下的异常焦点。框架提供了系统、可扩展和定量的视觉模型解释方案。

Conclusion: FocaLogic为解释视觉模型提供了一个系统化、可扩展且定量的解决方案，通过逻辑表示和定量评估，增强了视觉模型决策的透明度和可解释性。

Abstract: Interpretability of modern visual models is crucial, particularly in high-stakes applications. However, existing interpretability methods typically suffer from either reliance on white-box model access or insufficient quantitative rigor. To address these limitations, we introduce FocaLogic, a novel model-agnostic framework designed to interpret and quantify visual model decision-making through logic-based representations. FocaLogic identifies minimal interpretable subsets of visual regions-termed visual focuses-that decisively influence model predictions. It translates these visual focuses into precise and compact logical expressions, enabling transparent and structured interpretations. Additionally, we propose a suite of quantitative metrics, including focus precision, recall, and divergence, to objectively evaluate model behavior across diverse scenarios. Empirical analyses demonstrate FocaLogic's capability to uncover critical insights such as training-induced concentration, increasing focus accuracy through generalization, and anomalous focuses under biases and adversarial attacks. Overall, FocaLogic provides a systematic, scalable, and quantitative solution for interpreting visual models.

</details>


### [53] [A Unified Masked Jigsaw Puzzle Framework for Vision and Language Models](https://arxiv.org/abs/2601.12051)
*Weixin Ye,Wei Wang,Yahui Liu,Yue Song,Bin Ren,Wei Bi,Rita Cucchiara,Nicu Sebe*

Main category: cs.CV

TL;DR: 提出MJP框架，通过随机打乱token顺序并使用可学习的未知位置嵌入来掩码位置信息，既增强Transformer模型对抗梯度攻击的鲁棒性，又提升其在CV和NLP任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中Transformer面临梯度攻击防御和性能提升的双重挑战。研究发现位置嵌入的梯度包含足够信息可用于重构输入数据，存在安全风险。

Method: 提出Masked Jigsaw Puzzle (MJP)框架：1) 随机打乱token顺序破坏token顺序；2) 使用可学习的未知位置嵌入掩码打乱token的位置信息；3) 破坏局部空间信息，迫使模型学习不依赖局部空间信息的特征表示。

Result: 实验表明MJP不仅能提高模型对抗梯度攻击的鲁棒性，还能提升在图像分类（如ImageNet-1K）和文本情感分析（如Yelp和Amazon）等任务中的性能。MJP是适用于不同Transformer模型的统一框架。

Conclusion: MJP通过破坏位置嵌入中的局部空间信息，有效解决了Transformer在联邦学习中的安全性和性能问题，为CV和NLP任务提供了统一的解决方案。

Abstract: In federated learning, Transformer, as a popular architecture, faces critical challenges in defending against gradient attacks and improving model performance in both Computer Vision (CV) and Natural Language Processing (NLP) tasks. It has been revealed that the gradient of Position Embeddings (PEs) in Transformer contains sufficient information, which can be used to reconstruct the input data. To mitigate this issue, we introduce a Masked Jigsaw Puzzle (MJP) framework. MJP starts with random token shuffling to break the token order, and then a learnable \textit{unknown (unk)} position embedding is used to mask out the PEs of the shuffled tokens. In this manner, the local spatial information which is encoded in the position embeddings is disrupted, and the models are forced to learn feature representations that are less reliant on the local spatial information. Notably, with the careful use of MJP, we can not only improve models' robustness against gradient attacks, but also boost their performance in both vision and text application scenarios, such as classification for images (\textit{e.g.,} ImageNet-1K) and sentiment analysis for text (\textit{e.g.,} Yelp and Amazon). Experimental results suggest that MJP is a unified framework for different Transformer-based models in both vision and language tasks. Code is publicly available via https://github.com/ywxsuperstar/transformerattack

</details>


### [54] [Task-Driven Prompt Learning: A Joint Framework for Multi-modal Cloud Removal and Segmentation](https://arxiv.org/abs/2601.12052)
*Zaiyan Zhang,Jie Li,Shaowei Shi,Qiangqiang Yuan*

Main category: cs.CV

TL;DR: TDP-CR是一个任务驱动的多模态云去除框架，通过可学习的退化提示编码云层厚度和空间不确定性，结合SAR数据自适应修复光学图像，同时进行云去除和土地覆盖分割，在参数效率方面显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统云去除方法过度关注低层保真度，容易过度平滑纹理和边界，导致视觉上合理的修复与语义实用性之间存在不匹配。光学遥感图像中的云遮挡限制了其下游应用，需要既能有效去除云层又能保持分析就绪数据质量的方法。

Method: 提出TDP-CR框架，核心是提示引导融合机制，使用可学习的退化提示编码云厚度和空间不确定性，结合全局通道上下文和局部提示条件空间偏置，自适应集成SAR信息。采用参数高效的两阶段训练策略，解耦重建和语义表示学习。

Result: 在LuojiaSET-OSFCR数据集上，TDP-CR在PSNR上超过最先进基线0.18dB，同时仅使用15%的参数；在mIoU上比多任务竞争对手持续提升1.4%，有效提供分析就绪数据。

Conclusion: TDP-CR通过任务驱动的多模态框架成功解决了云去除中视觉保真度与语义实用性之间的不匹配问题，通过提示引导融合机制和高效训练策略，在保持参数效率的同时实现了优越的性能。

Abstract: Optical remote sensing imagery is indispensable for Earth observation, yet persistent cloud occlusion limits its downstream utility. Most cloud removal (CR) methods are optimized for low-level fidelity and can over-smooth textures and boundaries that are critical for analysis-ready data (ARD), leading to a mismatch between visually plausible restoration and semantic utility. To bridge this gap, we propose TDP-CR, a task-driven multimodal framework that jointly performs cloud removal and land-cover segmentation. Central to our approach is a Prompt-Guided Fusion (PGF) mechanism, which utilizes a learnable degradation prompt to encode cloud thickness and spatial uncertainty. By combining global channel context with local prompt-conditioned spatial bias, PGF adaptively integrates Synthetic Aperture Radar (SAR) information only where optical data is corrupted. We further introduce a parameter-efficient two-phase training strategy that decouples reconstruction and semantic representation learning. Experiments on the LuojiaSET-OSFCR dataset demonstrate the superiority of our framework: TDP-CR surpasses heavy state-of-the-art baselines by 0.18 dB in PSNR while using only 15\% of the parameters, and achieves a 1.4\% improvement in mIoU consistently against multi-task competitors, effectively delivering analysis-ready data.

</details>


### [55] [Automating Parameter Selection in Deep Image Prior for Fluorescence Microscopy Image Denoising via Similarity-Based Parameter Transfer](https://arxiv.org/abs/2601.12055)
*Lina Meyer,Felix Wissel,Tobias Knopp,Susanne Pfefferle,Ralf Fliegert,Maximilian Sandmann,Liana Uebler,Franziska Möckl,Björn-Philipp Diercks,David Lohr,René Werner*

Main category: cs.CV

TL;DR: AUTO-DIP：基于图像元数据相似性的无监督深度图像先验参数自动迁移方法，用于荧光显微镜图像去噪，无需逐图优化，优于原始DIP配置和变分去噪方法。


<details>
  <summary>Details</summary>
Motivation: 无监督深度图像先验（DIP）解决了监督深度学习的训练数据需求和泛化能力限制问题，但其性能依赖于网络架构和迭代停止点。为每张新图像优化这些参数耗时，限制了DIP在需要处理大量图像领域的应用。针对荧光显微镜数据，假设相似图像在DIP去噪中具有可比较的最优参数配置，可能实现免优化的DIP应用。

Method: 1. 从开源数据集生成校准集（n=110）和验证集（n=55），包含语义不同的图像；2. 针对理想U-net架构和停止点进行网络架构搜索；3. 基于图像元数据相似性（如显微镜类型、成像样本）而非定量图像相似性度量进行参数迁移；4. 实现AUTO-DIP自动参数迁移管道，与原始DIP配置和最先进的图像特定变分去噪方法进行比较。

Result: 1. 基于图像元数据相似性的参数迁移比基于定量图像相似性度量的迁移表现更好或相当；2. AUTO-DIP在多个不同复杂度的开源测试数据集上优于原始DIP配置和变分去噪方法，特别是在噪声较大的输入中；3. 在本地采集的荧光显微镜图像应用中进一步证明了AUTO-DIP的优越性。

Conclusion: 针对荧光显微镜图像，基于图像元数据相似性的参数迁移可以实现免优化的DIP去噪。AUTO-DIP方法在保持DIP无监督优势的同时，解决了参数优化耗时的问题，为大规模荧光显微镜图像处理提供了高效解决方案。

Abstract: Unsupervised deep image prior (DIP) addresses shortcomings of training data requirements and limited generalization associated with supervised deep learning. The performance of DIP depends on the network architecture and the stopping point of its iterative process. Optimizing these parameters for a new image requires time, restricting DIP application in domains where many images need to be processed. Focusing on fluorescence microscopy data, we hypothesize that similar images share comparable optimal parameter configurations for DIP-based denoising, potentially enabling optimization-free DIP for fluorescence microscopy. We generated a calibration (n=110) and validation set (n=55) of semantically different images from an open-source dataset for a network architecture search targeted towards ideal U-net architectures and stopping points. The calibration set represented our transfer basis. The validation set enabled the assessment of which image similarity criterion yields the best results. We then implemented AUTO-DIP, a pipeline for automatic parameter transfer, and compared it to the originally published DIP configuration (baseline) and a state-of-the-art image-specific variational denoising approach. We show that a parameter transfer from the calibration dataset to a test image based on only image metadata similarity (e.g., microscope type, imaged specimen) leads to similar and better performance than a transfer based on quantitative image similarity measures. AUTO-DIP outperforms the baseline DIP (DIP with original DIP parameters) as well as the variational denoising approaches for several open-source test datasets of varying complexity, particularly for very noisy inputs. Applications to locally acquired fluorescence microscopy images further proved superiority of AUTO-DIP.

</details>


### [56] [Learning Language-Driven Sequence-Level Modal-Invariant Representations for Video-Based Visible-Infrared Person Re-Identification](https://arxiv.org/abs/2601.12062)
*Xiaomei Yang,Xizhan Gao,Antai Liu,Kang Wei,Fa Zhu,Guang Feng,Xiaofeng Qu,Sijie Niu*

Main category: cs.CV

TL;DR: 提出LSMRL方法，通过语言驱动的序列级模态不变表示学习，解决VVI-ReID中空间-时间建模效率、跨模态交互不足和显式模态级损失指导问题


<details>
  <summary>Details</summary>
Motivation: 现有基于CLIP语言提示的方法在VVI-ReID中存在三个主要问题：1) 空间-时间建模效率不足；2) 跨模态交互不充分；3) 缺乏显式的模态级损失指导。这些问题限制了模态不变表示的学习效果。

Method: 提出LSMRL方法，包含三个核心模块：1) STFL模块：基于CLIP进行最小修改，实现参数和计算高效的空间-时间建模；2) SD模块：将模态共享的语言提示扩散到可见光和红外特征中，建立初步模态一致性；3) CMI模块：利用双向跨模态自注意力消除剩余模态差距，精炼模态不变表示。同时引入两种模态级损失来增强特征判别性和泛化能力。

Result: 在大规模VVI-ReID数据集上的大量实验表明，LSMRL方法优于所有现有方法（AOTA methods），取得了最优性能。

Conclusion: LSMRL方法通过高效的空间-时间建模、充分的跨模态交互和显式的模态级损失指导，有效解决了VVI-ReID中的关键挑战，实现了更好的模态不变表示学习。

Abstract: The core of video-based visible-infrared person re-identification (VVI-ReID) lies in learning sequence-level modal-invariant representations across different modalities. Recent research tends to use modality-shared language prompts generated by CLIP to guide the learning of modal-invariant representations. Despite achieving optimal performance, such methods still face limitations in efficient spatial-temporal modeling, sufficient cross-modal interaction, and explicit modality-level loss guidance. To address these issues, we propose the language-driven sequence-level modal-invariant representation learning (LSMRL) method, which includes spatial-temporal feature learning (STFL) module, semantic diffusion (SD) module and cross-modal interaction (CMI) module. To enable parameter- and computation-efficient spatial-temporal modeling, the STFL module is built upon CLIP with minimal modifications. To achieve sufficient cross-modal interaction and enhance the learning of modal-invariant features, the SD module is proposed to diffuse modality-shared language prompts into visible and infrared features to establish preliminary modal consistency. The CMI module is further developed to leverage bidirectional cross-modal self-attention to eliminate residual modality gaps and refine modal-invariant representations. To explicitly enhance the learning of modal-invariant representations, two modality-level losses are introduced to improve the features' discriminative ability and their generalization to unseen categories. Extensive experiments on large-scale VVI-ReID datasets demonstrate the superiority of LSMRL over AOTA methods.

</details>


### [57] [Learning Stochastic Bridges for Video Object Removal via Video-to-Video Translation](https://arxiv.org/abs/2601.12066)
*Zijie Lou,Xiangwei Feng,Jiaxin Wang,Xiaochao Qu,Luoqi Liu,Ting Liu*

Main category: cs.CV

TL;DR: 提出基于随机桥模型的视频物体移除方法，将任务重新定义为视频到视频的转换，利用源视频作为结构先验，通过自适应掩码调制策略平衡背景保真度和生成灵活性。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的视频物体移除方法从高斯噪声开始生成，丢弃了原始视频丰富的结构和上下文先验，导致物体移除不完整或生成内容与场景物理逻辑冲突。

Method: 将视频物体移除重新定义为通过随机桥模型实现的视频到视频转换任务，建立从源视频（含物体）到目标视频（移除物体）的直接随机路径。提出自适应掩码调制策略，根据掩码特征动态调节输入嵌入，平衡背景保真度和生成灵活性。

Result: 大量实验表明，该方法在视觉质量和时间一致性方面显著优于现有方法。

Conclusion: 通过随机桥模型和自适应掩码调制，能够有效利用输入视频作为结构先验，实现精确的物体移除并确保填充区域与周围环境逻辑一致。

Abstract: Existing video object removal methods predominantly rely on diffusion models following a noise-to-data paradigm, where generation starts from uninformative Gaussian noise. This approach discards the rich structural and contextual priors present in the original input video. Consequently, such methods often lack sufficient guidance, leading to incomplete object erasure or the synthesis of implausible content that conflicts with the scene's physical logic. In this paper, we reformulate video object removal as a video-to-video translation task via a stochastic bridge model. Unlike noise-initialized methods, our framework establishes a direct stochastic path from the source video (with objects) to the target video (objects removed). This bridge formulation effectively leverages the input video as a strong structural prior, guiding the model to perform precise removal while ensuring that the filled regions are logically consistent with the surrounding environment. To address the trade-off where strong bridge priors hinder the removal of large objects, we propose a novel adaptive mask modulation strategy. This mechanism dynamically modulates input embeddings based on mask characteristics, balancing background fidelity with generative flexibility. Extensive experiments demonstrate that our approach significantly outperforms existing methods in both visual quality and temporal consistency.

</details>


### [58] [ARMARecon: An ARMA Convolutional Filter based Graph Neural Network for Neurodegenerative Dementias Classification](https://arxiv.org/abs/2601.12067)
*VSS Tejaswi Abburi,Ananya Singhal,Saurabh J. Shigwan,Nitin Kumar*

Main category: cs.CV

TL;DR: ARMARecon：一种结合ARMA图滤波和重构目标的统一图学习框架，用于阿尔茨海默病和额颞叶痴呆的早期检测，在ADNI和NIFD数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病（AD）和额颞叶痴呆（FTD）等神经退行性疾病的早期检测对于降低进展为严重疾病阶段的风险至关重要。由于AD和FTD沿着白质区域以全局、图依赖的方式传播，基于图的神经网络非常适合捕捉这些模式。

Method: 提出ARMARecon统一图学习框架，整合自回归移动平均（ARMA）图滤波与重构驱动目标，增强特征表示并提高分类准确性。该方法利用从白质区域提取的20-bin分数各向异性（FA）直方图特征，有效建模局部和全局连接性，同时缓解过平滑问题。

Result: ARMARecon在多站点dMRI数据集ADNI和NIFD上实现了优于最先进方法的性能。

Conclusion: ARMARecon通过结合ARMA图滤波和重构目标，为AD和FTD的早期检测提供了一个有效的图学习框架，能够捕捉疾病传播的局部和全局模式，并在实际数据集上表现出优越性能。

Abstract: Early detection of neurodegenerative diseases such as Alzheimer's Disease (AD) and Frontotemporal Dementia (FTD) is essential for reducing the risk of progression to severe disease stages. As AD and FTD propagate along white-matter regions in a global, graph-dependent manner, graph-based neural networks are well suited to capture these patterns. Hence, we introduce ARMARecon, a unified graph learning framework that integrates Autoregressive Moving Average (ARMA) graph filtering with a reconstruction-driven objective to enhance feature representation and improve classification accuracy. ARMARecon effectively models both local and global connectivity by leveraging 20-bin Fractional Anisotropy (FA) histogram features extracted from white-matter regions, while mitigating over-smoothing. Overall, ARMARecon achieves superior performance compared to state-of-the-art methods on the multi-site dMRI datasets ADNI and NIFD.

</details>


### [59] [CroBIM-V: Memory-Quality Controlled Remote Sensing Referring Video Object Segmentation](https://arxiv.org/abs/2601.12076)
*H. Jiang,Y. Sun,Z. Dong,T. Liu,Y. Gu*

Main category: cs.CV

TL;DR: 提出了首个大规模遥感视频指称对象分割基准RS-RVOS Bench和基于记忆质量控制的在线分割框架MQC-SAM，解决了弱目标显著性和视觉信息截断问题。


<details>
  <summary>Details</summary>
Motivation: 遥感视频指称对象分割面临弱目标显著性和动态场景中视觉信息截断的挑战，现有方法存在初始记忆构建偏差和噪声积累导致的错误传播问题，且缺乏大规模专用基准数据集。

Method: 构建了包含111个视频序列、约25,000帧和213,000个时序指称标注的RS-RVOS Bench基准数据集，采用因果感知标注策略。提出了MQC-SAM框架，包含时间运动一致性模块用于初始记忆校准，以及解耦注意力记忆集成机制进行动态质量评估。

Result: 在RS-RVOS Bench上的大量实验表明，MQC-SAM实现了最先进的性能。

Conclusion: 该研究通过构建首个大规模遥感视频指称对象分割基准和提出记忆质量感知的在线分割框架，有效解决了该领域的关键挑战，为后续研究提供了重要基础。

Abstract: Remote sensing video referring object segmentation (RS-RVOS) is challenged by weak target saliency and severe visual information truncation in dynamic scenes, making it extremely difficult to maintain discriminative target representations during segmentation. Moreover, progress in this field is hindered by the absence of large-scale dedicated benchmarks, while existing models are often affected by biased initial memory construction that impairs accurate instance localization in complex scenarios, as well as indiscriminate memory accumulation that encodes noise from occlusions or misclassifications, leading to persistent error propagation. This paper advances RS-RVOS research through dual contributions in data and methodology. First, we construct RS-RVOS Bench, the first large-scale benchmark comprising 111 video sequences, about 25,000 frames, and 213,000 temporal referring annotations. Unlike common RVOS benchmarks where many expressions are written with access to the full video context, our dataset adopts a strict causality-aware annotation strategy in which linguistic references are generated solely from the target state in the initial frame. Second, we propose a memory-quality-aware online referring segmentation framework, termed Memory Quality Control with Segment Anything Model (MQC-SAM). MQC-SAM introduces a temporal motion consistency module for initial memory calibration, leveraging short-term motion trajectory priors to correct structural deviations and establish accurate memory anchoring. Furthermore, it incorporates a decoupled attention-based memory integration mechanism with dynamic quality assessment, selectively updating high-confidence semantic features while filtering unreliable information, thereby effectively preventing error accumulation and propagation. Extensive experiments on RS-RVOS Bench demonstrate that MQC-SAM achieves state-of-the-art performance.

</details>


### [60] [EmoLat: Text-driven Image Sentiment Transfer via Emotion Latent Space](https://arxiv.org/abs/2601.12079)
*Jing Zhang,Bingjie Fan,Jixiang Zhu,Zhe Wang*

Main category: cs.CV

TL;DR: EmoLat是一种新颖的情感潜在空间，通过建模文本语义与视觉情感特征之间的跨模态相关性，实现细粒度的文本驱动图像情感迁移。


<details>
  <summary>Details</summary>
Motivation: 现有图像情感迁移方法通常缺乏细粒度控制和文本引导能力，难以实现基于文本输入的精确情感编辑。需要建立文本语义与视觉情感特征之间的有效关联。

Method: 1. 构建EmoLat情感潜在空间，建立情感语义图捕捉情感、物体和视觉属性之间的关系结构；2. 使用对抗正则化增强情感表示的可区分性和可迁移性；3. 提出跨模态情感迁移框架，通过文本和EmoLat特征的联合嵌入来操控图像情感；4. 使用包含语义一致性、情感对齐和对抗正则化的多目标损失优化网络；5. 构建大规模基准数据集EmoSpace Set，包含情感、物体语义和视觉属性的密集标注。

Result: 在EmoSpace Set数据集上的大量实验表明，该方法在定量指标和定性迁移保真度方面显著优于现有最先进方法，为文本引导的可控图像情感编辑建立了新范式。

Conclusion: EmoLat成功建立了文本语义与视觉情感特征之间的跨模态关联，实现了细粒度的文本驱动图像情感迁移，为可控图像情感编辑提供了有效解决方案。数据集和代码已开源。

Abstract: We propose EmoLat, a novel emotion latent space that enables fine-grained, text-driven image sentiment transfer by modeling cross-modal correlations between textual semantics and visual emotion features. Within EmoLat, an emotion semantic graph is constructed to capture the relational structure among emotions, objects, and visual attributes. To enhance the discriminability and transferability of emotion representations, we employ adversarial regularization, aligning the latent emotion distributions across modalities. Building upon EmoLat, a cross-modal sentiment transfer framework is proposed to manipulate image sentiment via joint embedding of text and EmoLat features. The network is optimized using a multi-objective loss incorporating semantic consistency, emotion alignment, and adversarial regularization. To support effective modeling, we construct EmoSpace Set, a large-scale benchmark dataset comprising images with dense annotations on emotions, object semantics, and visual attributes. Extensive experiments on EmoSpace Set demonstrate that our approach significantly outperforms existing state-of-the-art methods in both quantitative metrics and qualitative transfer fidelity, establishing a new paradigm for controllable image sentiment editing guided by textual input. The EmoSpace Set and all the code are available at http://github.com/JingVIPLab/EmoLat.

</details>


### [61] [Toward Real-World High-Precision Image Matting and Segmentation](https://arxiv.org/abs/2601.12080)
*Haipeng Zhou,Zhaohu Xing,Hongqiu Wang,Jun Ma,Ping Li,Lei Zhu*

Main category: cs.CV

TL;DR: FCLM模型通过深度感知蒸馏和领域不变学习解决高精度场景解析中的前景一致性问题，支持视觉和语言提示的交互预测。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注显著的单前景物体，交互方法类别不可知限制了跨类别泛化，高质量标注稀缺导致依赖不和谐的合成数据，泛化到真实场景效果差。

Method: 提出前景一致学习模型FCLM：1）深度感知蒸馏策略，转移深度相关知识以改善前景表示；2）将合成数据处理视为领域适应问题，提出领域不变学习策略专注于前景学习；3）面向对象解码器，可接收视觉和语言提示来预测参考目标。

Result: 实验结果表明，该方法在定量和定性评估上均优于当前最先进方法。

Conclusion: FCLM通过深度感知蒸馏、领域不变学习和面向对象解码器，有效解决了高精度场景解析中的前景一致性问题，提升了跨类别泛化和真实场景适应性。

Abstract: High-precision scene parsing tasks, including image matting and dichotomous segmentation, aim to accurately predict masks with extremely fine details (such as hair). Most existing methods focus on salient, single foreground objects. While interactive methods allow for target adjustment, their class-agnostic design restricts generalization across different categories. Furthermore, the scarcity of high-quality annotation has led to a reliance on inharmonious synthetic data, resulting in poor generalization to real-world scenarios. To this end, we propose a Foreground Consistent Learning model, dubbed as FCLM, to address the aforementioned issues. Specifically, we first introduce a Depth-Aware Distillation strategy where we transfer the depth-related knowledge for better foreground representation. Considering the data dilemma, we term the processing of synthetic data as domain adaptation problem where we propose a domain-invariant learning strategy to focus on foreground learning. To support interactive prediction, we contribute an Object-Oriented Decoder that can receive both visual and language prompts to predict the referring target. Experimental results show that our method quantitatively and qualitatively outperforms SOTA methods.

</details>


### [62] [Conditional Random Fields for Interactive Refinement of Histopathological Predictions](https://arxiv.org/abs/2601.12082)
*Tiffanie Godelaine,Maxime Zanella,Karim El Khoury,Saïd Mahmoudi,Benoît Macq,Christophe De Vleeschouwer*

Main category: cs.CV

TL;DR: 提出HistoCRF框架，通过条件随机场优化组织病理学图像中视觉语言模型的零样本预测，无需额外训练，利用专家标注提升分类准确性。


<details>
  <summary>Details</summary>
Motivation: 组织病理学图像分析对癌症检测和分期具有重要临床价值。虽然视觉语言模型（VLMs）能提供零样本预测，但预测结果不够完美，需要进一步优化。

Method: 提出HistoCRF框架，将条件随机场（CRFs）应用于组织病理学图像分析。设计了新的成对势函数，促进标签多样性并利用专家标注。考虑了三种实验设置：无标注、有专家标注、以及迭代式人机协同标注。

Result: 在五个涵盖不同器官和疾病的patch级分类数据集上，相比零样本预测，平均准确率提升：无标注时16.0%，仅100个标注时27.5%。加入人机协同标注后，相同标注数量下进一步提升32.6%。

Conclusion: HistoCRF能有效优化组织病理学图像分析中视觉语言模型的预测性能，无需额外训练，通过条件随机场和专家标注显著提升分类准确性，具有临床实用价值。

Abstract: Assisting pathologists in the analysis of histopathological images has high clinical value, as it supports cancer detection and staging. In this context, histology foundation models have recently emerged. Among them, Vision-Language Models (VLMs) provide strong yet imperfect zero-shot predictions. We propose to refine these predictions by adapting Conditional Random Fields (CRFs) to histopathological applications, requiring no additional model training. We present HistoCRF, a CRF-based framework, with a novel definition of the pairwise potential that promotes label diversity and leverages expert annotations. We consider three experiments: without annotations, with expert annotations, and with iterative human-in-the-loop annotations that progressively correct misclassified patches. Experiments on five patch-level classification datasets covering different organs and diseases demonstrate average accuracy gains of 16.0% without annotations and 27.5% with only 100 annotations, compared to zero-shot predictions. Moreover, integrating a human in the loop reaches a further gain of 32.6% with the same number of annotations. The code will be made available on https://github.com/tgodelaine/HistoCRF.

</details>


### [63] [Detecting 3D Line Segments for 6DoF Pose Estimation with Limited Data](https://arxiv.org/abs/2601.12090)
*Matej Mok,Lukáš Gajdošech,Michal Mesároš,Martin Madaras,Viktor Kocur*

Main category: cs.CV

TL;DR: 提出了一种针对工业料箱的6DoF位姿估计方法，利用料箱的立方体几何特性，通过检测3D线段来估计位姿，无需实例特定的CAD模型


<details>
  <summary>Details</summary>
Motivation: 传统6DoF物体位姿估计方法需要大量训练数据或CAD模型，限制了在数据稀缺、物体实例多变的工业场景中的应用。工业料箱具有标准化的立方体几何形状，可以利用这一特性简化位姿估计问题。

Method: 首先检测料箱顶边的3D线段，将2D线段检测网络LeTR扩展到结构化点云数据上。然后通过简单的几何处理程序，利用检测到的3D线段稳健地确定料箱的6DoF位姿。使用合成训练数据提升真实扫描数据的准确性。

Result: 方法在公开数据集上评估，显著优于当前最先进的6DoF位姿估计方法，达到3厘米平移误差和8.2°旋转误差，且推理时不需要实例特定的CAD模型。

Conclusion: 该方法为工业料箱的6DoF位姿估计提供了一种高效解决方案，利用几何特性简化问题，减少对大量训练数据和CAD模型的依赖，在工业自动化应用中具有实用价值。

Abstract: The task of 6DoF object pose estimation is one of the fundamental problems of 3D vision with many practical applications such as industrial automation. Traditional deep learning approaches for this task often require extensive training data or CAD models, limiting their application in real-world industrial settings where data is scarce and object instances vary. We propose a novel method for 6DoF pose estimation focused specifically on bins used in industrial settings. We exploit the cuboid geometry of bins by first detecting intermediate 3D line segments corresponding to their top edges. Our approach extends the 2D line segment detection network LeTR to operate on structured point cloud data. The detected 3D line segments are then processed using a simple geometric procedure to robustly determine the bin's 6DoF pose. To evaluate our method, we extend an existing dataset with a newly collected and annotated dataset, which we make publicly available. We show that incorporating synthetic training data significantly improves pose estimation accuracy on real scans. Moreover, we show that our method significantly outperforms current state-of-the-art 6DoF pose estimation methods in terms of the pose accuracy (3 cm translation error, 8.2$^\circ$ rotation error) while not requiring instance-specific CAD models during inference.

</details>


### [64] [Energy-Aware Ensemble Learning for Coffee Leaf Disease Classification](https://arxiv.org/abs/2601.12109)
*Larissa Ferreira Rodrigues Moreira,Rodrigo Moreira,Leonardo Gabriel Ferreira Rodrigues*

Main category: cs.CV

TL;DR: 通过知识蒸馏和集成学习，将高容量CNN模型的知识转移到紧凑CNN模型上，实现咖啡叶病害的轻量级设备端诊断，在保持竞争力的同时显著降低能耗和碳足迹。


<details>
  <summary>Details</summary>
Motivation: 咖啡病害的及时准确诊断对产量至关重要，但田间叶片病害评估面临挑战。虽然AI视觉模型精度高，但受限于设备计算能力和间歇性连接，难以在实际场景中部署应用。

Method: 采用知识蒸馏方法：在数据中心训练的高容量CNN模型通过集成学习将知识转移到紧凑CNN模型。通过简单优化的集成方法整合密集微小模型对，在严格的计算和能耗约束下提升精度。

Result: 在精心策划的咖啡叶数据集上，蒸馏后的微小集成模型在保持与先前工作竞争力的同时，显著降低了能耗和碳足迹。

Conclusion: 轻量级模型经过适当蒸馏和集成后，可以为物联网应用提供实用的诊断解决方案，实现可持续的设备端病害诊断。

Abstract: Coffee yields are contingent on the timely and accurate diagnosis of diseases; however, assessing leaf diseases in the field presents significant challenges. Although Artificial Intelligence (AI) vision models achieve high accuracy, their adoption is hindered by the limitations of constrained devices and intermittent connectivity. This study aims to facilitate sustainable on-device diagnosis through knowledge distillation: high-capacity Convolutional Neural Networks (CNNs) trained in data centers transfer knowledge to compact CNNs through Ensemble Learning (EL). Furthermore, dense tiny pairs were integrated through simple and optimized ensembling to enhance accuracy while adhering to strict computational and energy constraints. On a curated coffee leaf dataset, distilled tiny ensembles achieved competitive with prior work with significantly reduced energy consumption and carbon footprint. This indicates that lightweight models, when properly distilled and ensembled, can provide practical diagnostic solutions for Internet of Things (IoT) applications.

</details>


### [65] [RCDN: Real-Centered Detection Network for Robust Face Forgery Identification](https://arxiv.org/abs/2601.12111)
*Wyatt McCurdy,Xin Zhang,Yuqi Song,Min Gao*

Main category: cs.CV

TL;DR: RCDN是一个专注于真实图像一致性的频率空间CNN框架，通过双分支架构和真实中心损失设计，在图像伪造检测中实现了优异的跨域泛化能力。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成工具的普及，图像伪造检测面临严峻挑战。现有方法在相同域内表现优异，但在跨域场景下性能大幅下降，而新的伪造技术不断涌现，检测器必须对未见过的伪造操作保持可靠。

Method: 提出Real-Centered Detection Network (RCDN)，这是一个基于Xception骨干网络的频率空间CNN框架。RCDN不建模多样且不断演变的伪造模式，而是将表示空间锚定在真实面部图像周围，采用双分支架构和真实中心损失设计来增强分布偏移下的鲁棒性。

Result: 在DiFF数据集上对三种代表性伪造类型（FE、I2I、T2I）进行广泛实验，RCDN不仅实现了最先进的域内准确率，还表现出显著更强的跨域泛化能力。相比领先基线，RCDN减少了泛化差距，并实现了最高的跨域/域内稳定性比率。

Conclusion: RCDN通过强调真实图像的一致性而非建模伪造模式，为防御不断演变和未见过的图像伪造技术提供了一个实用的解决方案，具有优异的跨域泛化能力。

Abstract: Image forgery has become a critical threat with the rapid proliferation of AI-based generation tools, which make it increasingly easy to synthesize realistic but fraudulent facial content. Existing detection methods achieve near-perfect performance when training and testing are conducted within the same domain, yet their effectiveness deteriorates substantially in crossdomain scenarios. This limitation is problematic, as new forgery techniques continuously emerge and detectors must remain reliable against unseen manipulations. To address this challenge, we propose the Real-Centered Detection Network (RCDN), a frequency spatial convolutional neural networks(CNN) framework with an Xception backbone that anchors its representation space around authentic facial images. Instead of modeling the diverse and evolving patterns of forgeries, RCDN emphasizes the consistency of real images, leveraging a dual-branch architecture and a real centered loss design to enhance robustness under distribution shifts. Extensive experiments on the DiFF dataset, focusing on three representative forgery types (FE, I2I, T2I), demonstrate that RCDN achieves both state-of-the-art in-domain accuracy and significantly stronger cross-domain generalization. Notably, RCDN reduces the generalization gap compared to leading baselines and achieves the highest cross/in-domain stability ratio, highlighting its potential as a practical solution for defending against evolving and unseen image forgery techniques.

</details>


### [66] [CARLA-Round: A Multi-Factor Simulation Dataset for Roundabout Trajectory Prediction](https://arxiv.org/abs/2601.12119)
*Xiaotong Zhou,Zhenhui Yuan,Yi Han,Tianhua Xu,Laurence T. Yang*

Main category: cs.CV

TL;DR: 提出CARLA-Round仿真数据集，用于环岛场景下的轨迹预测研究，通过系统控制天气和交通密度条件，量化分析各因素对预测性能的影响。


<details>
  <summary>Details</summary>
Motivation: 环岛场景的轨迹预测对减少交通事故至关重要，但由于其环形几何结构、连续汇入让行交互以及无交通信号等特点，预测极具挑战性。现有数据集稀缺，且真实世界数据存在观测不完整、因素混杂难以分离的问题。

Method: 开发CARLA-Round仿真数据集，系统设计5种天气条件和5个交通密度等级（服务水平A-E），形成25个受控场景。每个场景包含真实的驾驶行为混合，并提供现有数据集缺乏的明确标注。使用标准基线模型（LSTM、GCN、GRU+GCN）进行验证实验。

Result: 验证实验显示交通密度对预测难度具有主导性的单调效应，而天气条件呈现非线性影响。最佳模型在真实世界rounD数据集上达到0.312m ADE，证明了有效的仿真到真实迁移能力。

Conclusion: CARLA-Round数据集通过系统化方法量化了在混杂的真实世界数据集中无法分离的因素影响，为环岛轨迹预测研究提供了可靠、多模态、现实的仿真数据集。

Abstract: Accurate trajectory prediction of vehicles at roundabouts is critical for reducing traffic accidents, yet it remains highly challenging due to their circular road geometry, continuous merging and yielding interactions, and absence of traffic signals. Developing accurate prediction algorithms relies on reliable, multimodal, and realistic datasets; however, such datasets for roundabout scenarios are scarce, as real-world data collection is often limited by incomplete observations and entangled factors that are difficult to isolate. We present CARLA-Round, a systematically designed simulation dataset for roundabout trajectory prediction. The dataset varies weather conditions (five types) and traffic density levels (spanning Level-of-Service A-E) in a structured manner, resulting in 25 controlled scenarios. Each scenario incorporates realistic mixtures of driving behaviors and provides explicit annotations that are largely absent from existing datasets. Unlike randomly sampled simulation data, this structured design enables precise analysis of how different conditions influence trajectory prediction performance. Validation experiments using standard baselines (LSTM, GCN, GRU+GCN) reveal traffic density dominates prediction difficulty with strong monotonic effects, while weather shows non-linear impacts. The best model achieves 0.312m ADE on real-world rounD dataset, demonstrating effective sim-to-real transfer. This systematic approach quantifies factor impacts impossible to isolate in confounded real-world datasets. Our CARLA-Round dataset is available at https://github.com/Rebecca689/CARLA-Round.

</details>


### [67] [Segment and Matte Anything in a Unified Model](https://arxiv.org/abs/2601.12147)
*Zezhong Fan,Xiaohan Li,Topojoy Biswas,Kaushiki Nag,Kannan Achan*

Main category: cs.CV

TL;DR: SAMA是一个轻量级的SAM扩展模型，能够在单一框架中同时实现高质量交互式图像分割和抠图，通过多视图定位编码器和局部适配器提升边界细节，在多个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: SAM在分割精度上仍无法满足实际应用需求，现有细化模块无法在统一框架中实现高精度对象轮廓。同时，交互式图像抠图尚未在SAM背景下探索，而分割与抠图之间存在强相关性，因此需要开发一个能同时处理两种任务的统一模型。

Method: 1. 提出SAMA作为SAM的轻量级扩展；2. 设计多视图定位编码器（MVLE）从局部视图捕获细节特征；3. 使用局部适配器（Local-Adapter）通过恢复细微边界细节来优化掩码输出；4. 在架构中为每个任务集成两个预测头，同时生成分割和抠图掩码；5. 在公开数据集上进行训练。

Result: SAMA在多个分割和抠图基准测试中实现了最先进的性能，展示了其在广泛下游任务中的适应性和有效性。

Conclusion: SAMA成功地将分割和抠图任务统一到一个轻量级框架中，通过创新的多视图定位编码器和局部适配器显著提升了边界细节恢复能力，为实际应用提供了高质量的交互式图像处理解决方案。

Abstract: Segment Anything (SAM) has recently pushed the boundaries of segmentation by demonstrating zero-shot generalization and flexible prompting after training on over one billion masks. Despite this, its mask prediction accuracy often falls short of the precision required in real-world applications. While several refinement modules have been proposed to boost SAM's segmentation quality, achieving highly accurate object delineation within a single, unified framework remains an open challenge. Furthermore, interactive image matting, which aims to generate fine-grained alpha mattes guided by diverse user hints, has not yet been explored in the context of SAM. Insights from recent studies highlight strong correlations between segmentation and matting, suggesting the feasibility of a unified model capable of both tasks. In this paper, we introduce Segment And Matte Anything (SAMA), a lightweight extension of SAM that delivers high-quality interactive image segmentation and matting with minimal extra parameters. Our Multi-View Localization Encoder (MVLE) captures detailed features from local views, while the Localization Adapter (Local-Adapter) refines mask outputs by recovering subtle boundary details. We also incorporate two prediction heads for each task into the architecture to generate segmentation and matting masks, simultaneously. Trained on a diverse dataset aggregated from publicly available sources, SAMA achieves state-of-the-art performance across multiple segmentation and matting benchmarks, showcasing its adaptability and effectiveness in a wide range of downstream tasks.

</details>


### [68] [Principal Component Analysis-Based Terahertz Self-Supervised Denoising and Deblurring Deep Neural Networks](https://arxiv.org/abs/2601.12149)
*Pengfei Zhu,Xavier Maldague*

Main category: cs.CV

TL;DR: 提出基于主成分分析的太赫兹自监督去噪去模糊网络（THz-SSDD），通过重损坏自监督学习策略和PCA分解重建，解决太赫兹图像低频模糊和高频噪声问题


<details>
  <summary>Details</summary>
Motivation: 太赫兹系统固有的频率相关退化效应导致振幅图像出现低频模糊和高频噪声，传统图像处理方法无法同时解决这两个问题，且去噪与去模糊的边界未知需要人工干预

Method: 提出THz-SSDD网络，采用重损坏到重损坏自监督学习策略，通过重复损坏下的不变性捕捉噪声内在特征，然后应用PCA分解和重建来恢复低频和高频图像

Result: 在四类样本上评估网络性能，仅需少量无标签噪声图像进行训练，在不同材料特性和测量模式的样本测试中表现出有效的去噪和去模糊效果，定量分析验证了网络可行性

Conclusion: THz-SSDD网络能够有效改善太赫兹图像质量，同时保持原始信号的物理特性，为解决太赫兹图像处理中的频率相关退化问题提供了有效解决方案

Abstract: Terahertz (THz) systems inherently introduce frequency-dependent degradation effects, resulting in low-frequency blurring and high-frequency noise in amplitude images. Conventional image processing techniques cannot simultaneously address both issues, and manual intervention is often required due to the unknown boundary between denoising and deblurring. To tackle this challenge, we propose a principal component analysis (PCA)-based THz self-supervised denoising and deblurring network (THz-SSDD). The network employs a Recorrupted-to-Recorrupted self-supervised learning strategy to capture the intrinsic features of noise by exploiting invariance under repeated corruption. PCA decomposition and reconstruction are then applied to restore images across both low and high frequencies. The performance of the THz-SSDD network was evaluated on four types of samples. Training requires only a small set of unlabeled noisy images, and testing across samples with different material properties and measurement modes demonstrates effective denoising and deblurring. Quantitative analysis further validates the network feasibility, showing improvements in image quality while preserving the physical characteristics of the original signals.

</details>


### [69] [Enhanced Diagnostic Performance via Large-Resolution Inference Optimization for Pathology Foundation Models](https://arxiv.org/abs/2601.12150)
*Mengxuan Hu,Zihan Guan,John Kang,Sheng Li,Zhongliang Zhou*

Main category: cs.CV

TL;DR: 提出一种针对病理学基础模型的高效推理策略，通过空间感知的邻近块稀疏化注意力机制和基于全局注意力分数的非信息性令牌过滤，显著降低GPU内存和运行时间，同时保持甚至提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有病理学基础模型受限于特定输入尺寸（如224×224），在处理数千分辨率级别的全切片图像时效率低下。简单的放大输入会导致GPU内存消耗过高，而降低采样则会丢失关键形态学细节。

Method: 提出空间和时间高效的推理策略：1）使用空间感知的邻近块稀疏化注意力机制；2）通过全局注意力分数过滤非信息性令牌。这种设计在保持高分辨率WSI推理的同时，显著减少GPU内存和运行时间。

Result: 实验结果显示，该方法在ROI分类任务上实现了高达7.67%的性能提升，在分割任务上获得了兼容的结果，能够在相同GPU预算下实现更高分辨率的推理。

Conclusion: 该方法有效解决了病理学基础模型在处理全切片图像时的效率瓶颈，通过创新的注意力稀疏化和令牌过滤策略，实现了高效的高分辨率推理，为病理图像分析提供了实用解决方案。

Abstract: Despite their prominent performance on tasks such as ROI classification and segmentation, many pathology foundation models remain constrained by a specific input size e.g. 224 x 224, creating substantial inefficiencies when applied to whole-slide images (WSIs), which span thousands of resolutions. A naive strategy is to either enlarge inputs or downsample the WSIs. However, enlarging inputs results in prohibitive GPU memory consumption, while downsampling alters the microns-per-pixel resolution and obscures critical morphological details. To overcome these limitations, we propose an space- and time- efficient inference strategy that sparsifies attention using spatially aware neighboring blocks and filters out non-informative tokens through global attention scores. This design substantially reduces GPU memory and runtime during high-resolution WSI inference while preserving and even improving the downstream performance, enabling inference at higher resolutions under the same GPU budget. The experimental results show that our method can achieves up to an 7.67% improvement in the ROI classification and compatible results in segmentation.

</details>


### [70] [Inverse Rendering for High-Genus 3D Surface Meshes from Multi-view Images with Persistent Homology Priors](https://arxiv.org/abs/2601.12155)
*Xiang Gao,Xinmu Wang,Yuanpeng Liu,Yue Wang,Junqi Huang,Wei Chen,Xianfeng Gu*

Main category: cs.CV

TL;DR: 提出结合持续同调先验的协作式逆渲染方法，利用拓扑约束解决3D重建中的几何、外观和拓扑模糊问题，特别针对高亏格曲面重建。


<details>
  <summary>Details</summary>
Motivation: 从图像重建3D物体本质上是病态问题，存在几何、外观和拓扑的模糊性。传统方法难以重建高亏格曲面，容易导致隧道塌陷或高亏格结构丢失等灾难性失败。

Method: 采用协作式逆渲染框架，结合多视角图像的光度一致性和持续同调先验的拓扑约束。使用基于网格的逆渲染框架进行梯度优化，而非神经网络，以突出拓扑先验的作用。持续同调先验捕捉关键拓扑特征如隧道环和手柄环。

Result: 实验结果表明，引入持续同调先验相比最先进的基于网格方法，获得了更低的Chamfer距离和更高的体积IoU，提高了几何精度和对拓扑失败的鲁棒性。

Conclusion: 通过将拓扑先验整合到逆渲染中，能够有效解决高亏格曲面重建的模糊性问题，恢复复杂的高亏格几何结构，避免拓扑灾难性失败。

Abstract: Reconstructing 3D objects from images is inherently an ill-posed problem due to ambiguities in geometry, appearance, and topology. This paper introduces collaborative inverse rendering with persistent homology priors, a novel strategy that leverages topological constraints to resolve these ambiguities. By incorporating priors that capture critical features such as tunnel loops and handle loops, our approach directly addresses the difficulty of reconstructing high-genus surfaces. The collaboration between photometric consistency from multi-view images and homology-based guidance enables recovery of complex high-genus geometry while circumventing catastrophic failures such as collapsing tunnels or losing high-genus structure. Instead of neural networks, our method relies on gradient-based optimization within a mesh-based inverse rendering framework to highlight the role of topological priors. Experimental results show that incorporating persistent homology priors leads to lower Chamfer Distance (CD) and higher Volume IoU compared to state-of-the-art mesh-based methods, demonstrating improved geometric accuracy and robustness against topological failure.

</details>


### [71] [VIRTUE: Versatile Video Retrieval Through Unified Embeddings](https://arxiv.org/abs/2601.12193)
*Shaunak Halbe,Bhagyashree Puranik,Jayakrishnan Unnikrishnan,Kushan Thakkar,Vimal Bhat,Toufiq Parag*

Main category: cs.CV

TL;DR: VIRTUE是一个基于MLLM的多功能视频检索框架，支持语料库级检索、细粒度时刻定位和组合多模态查询，通过对比对齐和LoRA高效训练，在零样本视频检索和组合检索任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有视频检索系统存在局限性：专用架构虽然检索性能强，但无法处理组合多模态查询；而基于MLLM的方法支持丰富多模态搜索，但检索性能远低于专用系统。需要一种既能处理组合查询又能达到高性能的解决方案。

Method: 使用共享MLLM骨干网络生成视觉和文本嵌入，通过对比对齐促进高效的基于嵌入的候选搜索。采用低秩适应（LoRA）在70万对视觉-文本数据上高效训练嵌入模型，并可通过重排序进一步提升性能。

Result: 在零样本视频检索任务上超越其他MLLM方法；无需额外训练即可在零样本时刻检索上获得有竞争力的结果；在零样本组合视频检索上达到SOTA；通过重排序后，性能大幅超越现有MLLM系统，与在更大数据上训练的专用模型相当。

Conclusion: VIRTUE展示了MLLM框架在视频检索任务中的强大潜力，通过单一架构实现了多任务支持和高性能检索，为通用视频检索系统提供了有前景的方向。

Abstract: Modern video retrieval systems are expected to handle diverse tasks ranging from corpus-level retrieval and fine-grained moment localization to flexible multimodal querying. Specialized architectures achieve strong retrieval performance by training modality-specific encoders on massive datasets, but they lack the ability to process composed multimodal queries. In contrast, multimodal LLM (MLLM)-based methods support rich multimodal search but their retrieval performance remains well below that of specialized systems. We present VIRTUE, an MLLM-based versatile video retrieval framework that integrates corpus and moment-level retrieval capabilities while accommodating composed multimodal queries within a single architecture. We use contrastive alignment of visual and textual embeddings generated using a shared MLLM backbone to facilitate efficient embedding-based candidate search. Our embedding model, trained efficiently using low-rank adaptation (LoRA) on 700K paired visual-text data samples, surpasses other MLLM-based methods on zero-shot video retrieval tasks. Additionally, we demonstrate that the same model can be adapted without further training to achieve competitive results on zero-shot moment retrieval, and state of the art results for zero-shot composed video retrieval. With additional training for reranking candidates identified in the embedding-based search, our model substantially outperforms existing MLLM-based retrieval systems and achieves retrieval performance comparable to state of the art specialized models which are trained on orders of magnitude larger data.

</details>


### [72] [Where It Moves, It Matters: Referring Surgical Instrument Segmentation via Motion](https://arxiv.org/abs/2601.12224)
*Meng Wei,Kun Yuan,Shi Li,Yue Zhou,Long Bai,Nassir Navab,Hongliang Ren,Hong Joo Lee,Tom Vercauteren,Nicolas Padoy*

Main category: cs.CV

TL;DR: SurgRef：一种基于运动引导的框架，通过追踪手术器械的运动轨迹而非静态外观，实现自然语言描述下的手术器械分割，解决了遮挡、模糊和术语不熟悉等问题。


<details>
  <summary>Details</summary>
Motivation: 当前手术场景中的指代分割任务主要依赖静态视觉特征和预定义器械名称，难以处理遮挡、模糊描述和陌生术语，限制了智能手术室和自主手术机器人的发展。

Method: 提出SurgRef框架，通过运动引导将自由形式的语言表达与器械运动轨迹关联，捕捉工具在时间维度上的移动和交互模式，而非依赖外观特征。

Result: 在Ref-IMotion数据集上实现最先进的准确性和泛化能力，能够跨不同手术程序稳健地进行语言驱动的视频分割。

Conclusion: SurgRef通过运动导向的方法为手术视频中的语言驱动分割设立了新基准，显著提升了在复杂手术场景下的鲁棒性和适应性。

Abstract: Enabling intuitive, language-driven interaction with surgical scenes is a critical step toward intelligent operating rooms and autonomous surgical robotic assistance. However, the task of referring segmentation, localizing surgical instruments based on natural language descriptions, remains underexplored in surgical videos, with existing approaches struggling to generalize due to reliance on static visual cues and predefined instrument names. In this work, we introduce SurgRef, a novel motion-guided framework that grounds free-form language expressions in instrument motion, capturing how tools move and interact across time, rather than what they look like. This allows models to understand and segment instruments even under occlusion, ambiguity, or unfamiliar terminology. To train and evaluate SurgRef, we present Ref-IMotion, a diverse, multi-institutional video dataset with dense spatiotemporal masks and rich motion-centric expressions. SurgRef achieves state-of-the-art accuracy and generalization across surgical procedures, setting a new benchmark for robust, language-driven surgical video segmentation.

</details>


### [73] [DiffusionQC: Artifact Detection in Histopathology via Diffusion Model](https://arxiv.org/abs/2601.12233)
*Zhenzhen Wang,Zhongliang Zhou,Zhuoyu Wen,Jeong Hwan Kook,John B Wojcik,John Kang*

Main category: cs.CV

TL;DR: 提出DiffusionQC方法，仅需干净图像训练即可检测病理图像中的伪影，无需像素级标注或预定义伪影类型，通过对比学习增强性能


<details>
  <summary>Details</summary>
Motivation: 数字病理学在疾病诊断、预后和治疗中至关重要，但组织病理学图像常包含制备和数字化过程中引入的伪影。传统监督模型需要大量标注数据，资源密集且难以泛化到新伪影类型

Method: 提出DiffusionQC方法，使用扩散模型将伪影检测为干净图像中的异常值，仅需干净图像训练，无需像素级标注或预定义伪影类型。引入对比学习模块明确扩大伪影与干净图像的分布分离

Result: 实证结果显示优于最先进方法的性能，具有跨染色泛化能力，所需数据和标注显著减少

Conclusion: DiffusionQC为病理图像伪影检测提供了一种高效、泛化性强的解决方案，减少了对大量标注数据的依赖

Abstract: Digital pathology plays a vital role across modern medicine, offering critical insights for disease diagnosis, prognosis, and treatment. However, histopathology images often contain artifacts introduced during slide preparation and digitization. Detecting and excluding them is essential to ensure reliable downstream analysis. Traditional supervised models typically require large annotated datasets, which is resource-intensive and not generalizable to novel artifact types. To address this, we propose DiffusionQC, which detects artifacts as outliers among clean images using a diffusion model. It requires only a set of clean images for training rather than pixel-level artifact annotations and predefined artifact types. Furthermore, we introduce a contrastive learning module to explicitly enlarge the distribution separation between artifact and clean images, yielding an enhanced version of our method. Empirical results demonstrate superior performance to state-of-the-art and offer cross-stain generalization capacity, with significantly less data and annotations.

</details>


### [74] [Less is More: Label-Guided Summarization of Procedural and Instructional Videos](https://arxiv.org/abs/2601.12243)
*Shreya Rajpal,Michal Golovanesky,Carsten Eickhoff*

Main category: cs.CV

TL;DR: PRISM是一个三阶段视频摘要框架，通过自适应视觉采样、标签驱动的关键帧锚定和LLM上下文验证，生成语义基础的程序性视频摘要，在采样少于5%帧的情况下保留84%语义内容。


<details>
  <summary>Details</summary>
Motivation: 视频摘要在手术培训等高风险领域很重要，现有方法从基本视觉特征发展到预训练视觉语言模型，但需要更好的语义理解和程序性过渡捕捉，以生成更上下文感知的视频摘要。

Method: 提出PRISM三阶段框架：1) 自适应视觉采样，2) 标签驱动的关键帧锚定，3) 使用大语言模型进行上下文验证。该方法结合语义和多模态分析，确保选择反映有意义程序性过渡的帧，过滤通用或幻觉内容。

Result: 在指令和活动数据集上评估，尽管采样少于5%的原始帧，摘要保留84%语义内容，比基线方法提升高达33%。方法在程序性和领域特定视频任务上具有良好泛化能力，实现语义对齐和精度的强性能。

Conclusion: PRISM框架通过集成语义和多模态分析，能够生成语义基础的程序性视频摘要，在保留关键语义内容的同时显著减少帧数，在多种视频任务上表现出良好的泛化能力和性能优势。

Abstract: Video summarization helps turn long videos into clear, concise representations that are easier to review, document, and analyze, especially in high-stakes domains like surgical training. Prior work has progressed from using basic visual features like color, motion, and structural changes to using pre-trained vision-language models that can better understand what's happening in the video (semantics) and capture temporal flow, resulting in more context-aware video summarization. We propose a three-stage framework, PRISM: Procedural Representation via Integrated Semantic and Multimodal analysis, that produces semantically grounded video summaries. PRISM combines adaptive visual sampling, label-driven keyframe anchoring, and contextual validation using a large language model (LLM). Our method ensures that selected frames reflect meaningful and procedural transitions while filtering out generic or hallucinated content, resulting in contextually coherent summaries across both domain-specific and instructional videos. We evaluate our method on instructional and activity datasets, using reference summaries for instructional videos. Despite sampling fewer than 5% of the original frames, our summaries retain 84% semantic content while improving over baselines by as much as 33%. Our approach generalizes across procedural and domain-specific video tasks, achieving strong performance with both semantic alignment and precision.

</details>


### [75] [An Innovative Framework for Breast Cancer Detection Using Pyramid Adaptive Atrous Convolution, Transformer Integration, and Multi-Scale Feature Fusion](https://arxiv.org/abs/2601.12249)
*Ehsan Sadeghi Pour,Mahdi Esmaeili,Morteza Romoozi*

Main category: cs.CV

TL;DR: 提出一种结合金字塔自适应空洞卷积(PAAC)和Transformer架构的创新框架，用于乳腺X光图像中恶性肿块的检测，在多个数据集上达到98.5%的准确率。


<details>
  <summary>Details</summary>
Motivation: 乳腺癌是全球女性最常见的癌症之一，准确及时的诊断对改善治疗效果至关重要。传统方法在复杂场景和大数据集中的检测效果有限。

Method: 整合金字塔自适应空洞卷积(PAAC)和Transformer架构，采用多尺度特征融合增强良恶性组织特征提取，结合Dice Loss和Focal Loss函数优化学习过程，使用INbreast、MIAS和DDSM数据集进行训练。

Result: 模型在准确率(98.5%)、敏感性(97.8%)、特异性(96.3%)、F1分数(98.2%)和精确率(97.9%)上表现优异，超越了BreastNet、DeepMammo、Multi-Scale CNN、Swin-Unet和SegFormer等基准模型。

Conclusion: 该模型在复杂场景和大数据集中能有效识别癌性肿块，显著优于传统方法，有望成为乳腺癌诊断的可靠高效工具，可集成到医疗诊断系统中。

Abstract: Breast cancer is one of the most common cancers among women worldwide, and its accurate and timely diagnosis plays a critical role in improving treatment outcomes. This thesis presents an innovative framework for detecting malignant masses in mammographic images by integrating the Pyramid Adaptive Atrous Convolution (PAAC) and Transformer architectures. The proposed approach utilizes Multi-Scale Feature Fusion to enhance the extraction of features from benign and malignant tissues and combines Dice Loss and Focal Loss functions to improve the model's learning process, effectively reducing errors in binary breast cancer classification and achieving high accuracy and efficiency. In this study, a comprehensive dataset of breast cancer images from INbreast, MIAS, and DDSM was preprocessed through data augmentation and contrast enhancement and resized to 227x227 pixels for model training. Leveraging the Transformer's ability to manage long-range dependencies with Self-Attention mechanisms, the proposed model achieved high accuracy in detecting cancerous masses, outperforming foundational models such as BreastNet, DeepMammo, Multi-Scale CNN, Swin-Unet, and SegFormer. The final evaluation results for the proposed model include an accuracy of 98.5\%, sensitivity of 97.8\%, specificity of 96.3\%, F1-score of 98.2\%, and overall precision of 97.9\%. These metrics demonstrate a significant improvement over traditional methods and confirm the model's effectiveness in identifying cancerous masses in complex scenarios and large datasets. This model shows potential as a reliable and efficient tool for breast cancer diagnosis and can be effectively integrated into medical diagnostic systems.

</details>


### [76] [Federated Joint Learning for Domain and Class Generalization](https://arxiv.org/abs/2601.12253)
*Haoran Xu,Jiaze Li,Jianzhong Ju,Zhenbo Luo*

Main category: cs.CV

TL;DR: FedDCG：一种联邦学习框架，同时解决类别和领域泛化问题，通过领域分组策略和可学习网络提升未见类别和未见领域的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常单独处理未见类别或未见领域问题，缺乏同时解决两者的联合框架。CLIP等视觉语言模型参数量大、预训练需求高，需要高效的微调方法。

Method: 提出FedDCG框架：1）领域分组策略，在每个组内训练类别泛化网络以避免决策边界混淆；2）推理时基于领域相似性聚合类别泛化结果；3）使用可学习网络增强类别泛化能力；4）解耦机制分离通用知识和领域特定知识。

Result: 在多个数据集上的实验表明，FedDCG在准确性和鲁棒性方面优于现有最先进基线方法。

Conclusion: FedDCG成功解决了联邦学习环境中同时处理类别和领域泛化的挑战，通过创新的分组和解耦策略实现了更好的泛化性能。

Abstract: Efficient fine-tuning of visual-language models like CLIP has become crucial due to their large-scale parameter size and extensive pretraining requirements. Existing methods typically address either the issue of unseen classes or unseen domains in isolation, without considering a joint framework for both. In this paper, we propose \textbf{Fed}erated Joint Learning for \textbf{D}omain and \textbf{C}lass \textbf{G}eneralization, termed \textbf{FedDCG}, a novel approach that addresses both class and domain generalization in federated learning settings. Our method introduces a domain grouping strategy where class-generalized networks are trained within each group to prevent decision boundary confusion. During inference, we aggregate class-generalized results based on domain similarity, effectively integrating knowledge from both class and domain generalization. Specifically, a learnable network is employed to enhance class generalization capabilities, and a decoupling mechanism separates general and domain-specific knowledge, improving generalization to unseen domains. Extensive experiments across various datasets show that \textbf{FedDCG} outperforms state-of-the-art baselines in terms of accuracy and robustness.

</details>


### [77] [Soft Shadow Diffusion (SSD): Physics-inspired Learning for 3D Computational Periscopy](https://arxiv.org/abs/2601.12257)
*Fadlullah Raji,John Murray-Bruce*

Main category: cs.CV

TL;DR: 该论文提出了一种从普通非视距(NLOS)照片进行3D场景重建的新方法，通过将隐藏场景分解为光遮挡和非光遮挡组件，并使用梯度优化和物理启发神经网络(SSD)解决逆问题。


<details>
  <summary>Details</summary>
Motivation: 传统成像需要视线才能创建准确的场景表示，但在某些情况下获得合适的视线可能不切实际、危险甚至不可能。现有的被动NLOS方法仅限于1D或低分辨率2D彩色成像，或只能定位形状近似已知的隐藏物体。

Method: 提出新的光传输模型重新表述，将隐藏场景分解为光遮挡和非光遮挡组件，形成可分离非线性最小二乘(SNLLS)逆问题。开发两种解决方案：基于梯度的优化方法和物理启发神经网络方法(Soft Shadow diffusion, SSD)。

Result: 方法在真实实验场景中对多个3D场景有效，SSD在模拟中训练但能很好地泛化到模拟和真实世界NLOS场景中的未见类别，并显示出对噪声和环境照明的惊人鲁棒性。

Conclusion: 该研究将被动NLOS成像从1D/低分辨率2D扩展到3D重建，通过创新的场景分解和逆问题求解方法，实现了从普通NLOS照片进行隐藏场景的3D重建。

Abstract: Conventional imaging requires a line of sight to create accurate visual representations of a scene. In certain circumstances, however, obtaining a suitable line of sight may be impractical, dangerous, or even impossible. Non-line-of-sight (NLOS) imaging addresses this challenge by reconstructing the scene from indirect measurements. Recently, passive NLOS methods that use an ordinary photograph of the subtle shadow cast onto a visible wall by the hidden scene have gained interest. These methods are currently limited to 1D or low-resolution 2D color imaging or to localizing a hidden object whose shape is approximately known. Here, we generalize this class of methods and demonstrate a 3D reconstruction of a hidden scene from an ordinary NLOS photograph. To achieve this, we propose a novel reformulation of the light transport model that conveniently decomposes the hidden scene into \textit{light-occluding} and \textit{non-light-occluding} components to yield a separable non-linear least squares (SNLLS) inverse problem. We develop two solutions: A gradient-based optimization method and a physics-inspired neural network approach, which we call Soft Shadow diffusion (SSD). Despite the challenging ill-conditioned inverse problem encountered here, our approaches are effective on numerous 3D scenes in real experimental scenarios. Moreover, SSD is trained in simulation but generalizes well to unseen classes in simulation and real-world NLOS scenes. SSD also shows surprising robustness to noise and ambient illumination.

</details>


### [78] [AgenticPruner: MAC-Constrained Neural Network Compression via LLM-Driven Strategy Search](https://arxiv.org/abs/2601.12272)
*Shahrzad Esmat,Mahdi Banisharif,Ali Jannesari*

Main category: cs.CV

TL;DR: AgenticPruner：利用大语言模型进行MAC约束优化的神经网络剪枝框架，通过三个智能体协同工作，在满足计算预算的同时保持或提升模型精度。


<details>
  <summary>Details</summary>
Motivation: 现有神经网络剪枝方法主要关注参数减少，但无法直接控制计算成本，导致在需要严格满足MAC操作预算的部署场景中，推理延迟不可预测。

Method: 提出AgenticPruner框架，利用大语言模型通过迭代策略学习实现MAC约束优化。框架包含三个专业智能体：分析模型架构和MAC分布的Profiling Agent、协调工作流程的Master Agent、以及基于Claude 3.5 Sonnet从历史尝试中学习最优策略的Analysis Agent。结合同构剪枝的图结构分组方法，通过分析剪枝迭代中的模式实现上下文感知适应。

Result: 在ImageNet-1K数据集上验证，ResNet-50达到1.77G MACs且精度77.04%（比基线+0.91%）；ResNet-101达到4.22G MACs且精度78.94%（+1.56%）。ConvNeXt-Small剪枝到8.17G MACs实现1.41x GPU和1.07x CPU加速，参数减少45%。在Vision Transformers上，MAC预算控制在用户定义的容差范围内（通常+1%到+5%超调，-5%到-15%欠调）。

Conclusion: AgenticPruner框架能够自动收敛到目标MAC预算，为需要严格计算保证的部署场景提供了可行的解决方案，通过智能体协同和上下文学习显著提升了剪枝效率和精度保持能力。

Abstract: Neural network pruning remains essential for deploying deep learning models on resource-constrained devices, yet existing approaches primarily target parameter reduction without directly controlling computational cost. This yields unpredictable inference latency in deployment scenarios where strict Multiply-Accumulate (MAC) operation budgets must be met. We propose AgenticPruner, a framework utilizing large language models to achieve MAC-constrained optimization through iterative strategy learning. Our approach coordinates three specialized agents: a Profiling Agent that analyzes model architecture and MAC distributions, a Master Agent that orchestrates the workflow with divergence monitoring, and an Analysis Agent powered by Claude 3.5 Sonnet that learns optimal strategies from historical attempts. Through in-context learning, the Analysis Agent improves convergence success rate from 48% to 71% compared to grid search. Building upon isomorphic pruning's graph-based structural grouping, our method adds context-aware adaptation by analyzing patterns across pruning iterations, enabling automatic convergence to target MAC budgets within user-defined tolerance bands.
  We validate our framework on ImageNet-1K across ResNet, ConvNeXt, and DeiT architectures. On CNNs, our approach achieves MAC targeting while maintaining or improving accuracy: ResNet-50 reaches 1.77G MACs with 77.04% accuracy (+0.91% vs baseline); ResNet-101 achieves 4.22G MACs with 78.94% accuracy (+1.56% vs baseline). For ConvNeXt-Small, pruning to 8.17G MACs yields 1.41x GPU and 1.07x CPU speedup with 45% parameter reduction. On Vision Transformers, we demonstrate MAC-budget compliance within user-defined tolerance bands (typically +1% to +5% overshoot, -5% to -15% undershoot), establishing feasibility for deployment scenarios requiring strict computational guarantees.

</details>


### [79] [CytoCLIP: Learning Cytoarchitectural Characteristics in Developing Human Brain Using Contrastive Language Image Pre-Training](https://arxiv.org/abs/2601.12282)
*Pralaypati Ta,Sriram Venkatesaperumal,Keerthi Ram,Mohanasankar Sivaprakasam*

Main category: cs.CV

TL;DR: CytoCLIP：基于CLIP预训练框架的视觉语言模型，用于学习大脑细胞构筑的联合视觉-文本表示，实现大脑区域的自动识别


<details>
  <summary>Details</summary>
Motivation: 大脑不同区域的功能与其独特的细胞构筑密切相关，但手动在脑组织切片中划分这些区域耗时且需要专业知识，需要自动化方法来减少专家工作量

Method: 提出CytoCLIP模型套件，包含两个变体：一个使用低分辨率全区域图像学习整体细胞构筑模式，另一个使用高分辨率图像块学习细胞级细节表示。使用不同孕周胎儿脑NISSL染色切片构建训练数据集

Result: CytoCLIP在区域分类和跨模态检索任务中优于现有方法，全区域分类F1分数达0.87，高分辨率图像块分类F1分数达0.91，展示了良好的细胞构筑理解和泛化能力

Conclusion: CytoCLIP能够有效学习大脑细胞构筑的视觉-文本表示，为大脑区域自动识别提供了高效解决方案，在神经解剖学研究中具有重要应用价值

Abstract: The functions of different regions of the human brain are closely linked to their distinct cytoarchitecture, which is defined by the spatial arrangement and morphology of the cells. Identifying brain regions by their cytoarchitecture enables various scientific analyses of the brain. However, delineating these areas manually in brain histological sections is time-consuming and requires specialized knowledge. An automated approach is necessary to minimize the effort needed from human experts. To address this, we propose CytoCLIP, a suite of vision-language models derived from pre-trained Contrastive Language-Image Pre-Training (CLIP) frameworks to learn joint visual-text representations of brain cytoarchitecture. CytoCLIP comprises two model variants: one is trained using low-resolution whole-region images to understand the overall cytoarchitectural pattern of an area, and the other is trained on high-resolution image tiles for detailed cellular-level representation. The training dataset is created from NISSL-stained histological sections of developing fetal brains of different gestational weeks. It includes 86 distinct regions for low-resolution images and 384 brain regions for high-resolution tiles. We evaluate the model's understanding of the cytoarchitecture and generalization ability using region classification and cross-modal retrieval tasks. Multiple experiments are performed under various data setups, including data from samples of different ages and sectioning planes. Experimental results demonstrate that CytoCLIP outperforms existing methods. It achieves an F1 score of 0.87 for whole-region classification and 0.91 for high-resolution image tile classification.

</details>


### [80] [SDiT: Semantic Region-Adaptive for Diffusion Transformers](https://arxiv.org/abs/2601.12283)
*Bowen Lin,Fanjiang Ye,Yihua Liu,Zhenghui Guo,Boyuan Zhang,Weijian Zheng,Yufan Xu,Tiancheng Xing,Yuke Wang,Chengming Zhang*

Main category: cs.CV

TL;DR: SDiT提出了一种无需训练的区域自适应扩散Transformer，通过语义感知聚类和复杂度驱动调度，在保持图像质量的同时实现3倍加速


<details>
  <summary>Details</summary>
Motivation: 现有的Diffusion Transformers（DiTs）在文本到图像合成中表现出色，但由于迭代去噪和全局注意力的二次计算成本，计算开销很大。研究发现去噪动态在空间上不均匀：背景区域收敛快，而边缘和纹理区域变化更活跃。

Method: SDiT采用无需训练的框架，包含三个核心组件：1）基于快速Quickshift的语义感知聚类进行区域分割；2）复杂度驱动的区域调度，选择性更新信息丰富的区域；3）边界感知细化以保持空间连贯性。

Result: 在不进行模型重新训练或架构修改的情况下，SDiT实现了高达3.0倍的加速，同时保持与完整注意力推理几乎相同的感知和语义质量。

Conclusion: SDiT通过利用去噪动态的空间不均匀性，提出了一种高效的区域自适应计算分配方法，显著降低了Diffusion Transformers的计算成本，同时保持生成质量。

Abstract: Diffusion Transformers (DiTs) achieve state-of-the-art performance in text-to-image synthesis but remain computationally expensive due to the iterative nature of denoising and the quadratic cost of global attention. In this work, we observe that denoising dynamics are spatially non-uniform-background regions converge rapidly while edges and textured areas evolve much more actively. Building on this insight, we propose SDiT, a Semantic Region-Adaptive Diffusion Transformer that allocates computation according to regional complexity. SDiT introduces a training-free framework combining (1) semantic-aware clustering via fast Quickshift-based segmentation, (2) complexity-driven regional scheduling to selectively update informative areas, and (3) boundary-aware refinement to maintain spatial coherence. Without any model retraining or architectural modification, SDiT achieves up to 3.0x acceleration while preserving nearly identical perceptual and semantic quality to full-attention inference.

</details>


### [81] [LegacyAvatars: Volumetric Face Avatars For Traditional Graphics Pipelines](https://arxiv.org/abs/2601.12285)
*Safa C. Medin,Gengyan Li,Ziqian Bai,Ruofei Du,Leonhard Helminger,Yinda Zhang,Stephan J. Garbin,Philip L. Davidson,Gregory W. Wornell,Thabo Beeler,Abhimitra Meka*

Main category: cs.CV

TL;DR: 提出一种基于参数化人脸模型的新型显式表示方法，用于高效经典渲染3D人脸化身，支持在线流式传输和传统图形平台渲染


<details>
  <summary>Details</summary>
Motivation: 现有基于辐射场的3D人脸化身渲染方法通常需要定制化工程集成，无法在传统图形平台上高效运行。需要一种既能保持高质量渲染效果，又能在标准图形硬件上高效运行的显式表示方法。

Method: 基于参数化人脸模型锚定辐射场，学习3D空间中的辐射流形，提取显式分层网格、外观纹理和变形纹理。通过线性混合和alpha合成纹理在静态网格上进行控制和动画化。

Result: 实现了可控的体积渲染复杂面部特征（头发、皮肤、眼睛），生成的化身可高效在线流式传输，并能在传统图形平台上使用经典网格和着色器进行渲染，无需定制工程集成。

Conclusion: 该方法提供了一种高效、可流式传输的显式3D人脸化身表示，实现了高质量渲染与标准图形硬件兼容性的平衡，为实际应用部署提供了可行解决方案。

Abstract: We introduce a novel representation for efficient classical rendering of photorealistic 3D face avatars. Leveraging recent advances in radiance fields anchored to parametric face models, our approach achieves controllable volumetric rendering of complex facial features, including hair, skin, and eyes. At enrollment time, we learn a set of radiance manifolds in 3D space to extract an explicit layered mesh, along with appearance and warp textures. During deployment, this allows us to control and animate the face through simple linear blending and alpha compositing of textures over a static mesh. This explicit representation also enables the generated avatar to be efficiently streamed online and then rendered using classical mesh and shader-based rendering on legacy graphics platforms, eliminating the need for any custom engineering or integration.

</details>


### [82] [Concepts from Representations: Post-hoc Concept Bottleneck Models via Sparse Decomposition of Visual Representations](https://arxiv.org/abs/2601.12303)
*Shizhan Gong,Xiaofan Zhang,Qi Dou*

Main category: cs.CV

TL;DR: PCBM-ReD提出了一种后处理概念瓶颈模型，通过表示分解为预训练模型添加可解释性，自动提取视觉概念并使用多模态大语言模型标注，在保持高性能的同时提升模型可解释性。


<details>
  <summary>Details</summary>
Motivation: 深度学习在图像识别中表现出色，但其黑盒特性限制了在关键领域的应用。现有的概念解释方法存在概念相关性不可靠、概念定义非视觉化或劳动密集、模型或数据无关假设等局限性。

Method: PCBM-ReD通过表示分解将预训练模型改造为可解释模型：1)从预训练编码器自动提取视觉概念；2)使用多模态大语言模型基于视觉可识别性和任务相关性标注和筛选概念；3)通过重建引导优化选择独立概念子集；4)利用CLIP的视觉-文本对齐将图像表示分解为概念嵌入的线性组合。

Result: 在11个图像分类任务上的广泛实验表明，PCBM-ReD达到了最先进的准确率，缩小了与端到端模型的性能差距，并展现出更好的可解释性。

Conclusion: PCBM-ReD成功地为预训练黑盒模型添加了可解释性，通过自动概念提取和多模态大语言模型标注，实现了高性能与良好可解释性的平衡，为关键领域的模型部署提供了可行方案。

Abstract: Deep learning has achieved remarkable success in image recognition, yet their inherent opacity poses challenges for deployment in critical domains. Concept-based interpretations aim to address this by explaining model reasoning through human-understandable concepts. However, existing post-hoc methods and ante-hoc concept bottleneck models (CBMs), suffer from limitations such as unreliable concept relevance, non-visual or labor-intensive concept definitions, and model or data-agnostic assumptions. This paper introduces Post-hoc Concept Bottleneck Model via Representation Decomposition (PCBM-ReD), a novel pipeline that retrofits interpretability onto pretrained opaque models. PCBM-ReD automatically extracts visual concepts from a pre-trained encoder, employs multimodal large language models (MLLMs) to label and filter concepts based on visual identifiability and task relevance, and selects an independent subset via reconstruction-guided optimization. Leveraging CLIP's visual-text alignment, it decomposes image representations into linear combination of concept embeddings to fit into the CBMs abstraction. Extensive experiments across 11 image classification tasks show PCBM-ReD achieves state-of-the-art accuracy, narrows the performance gap with end-to-end models, and exhibits better interpretability.

</details>


### [83] [A Two-Stage Globally-Diverse Adversarial Attack for Vision-Language Pre-training Models](https://arxiv.org/abs/2601.12304)
*Wutao Chen,Huaqin Zou,Chen Wan,Lifeng Huang*

Main category: cs.CV

TL;DR: 提出2S-GDA框架，通过全局多样性策略增强视觉语言预训练模型的黑盒对抗攻击效果


<details>
  <summary>Details</summary>
Motivation: 现有多模态攻击方法存在扰动多样性有限和多阶段流程不稳定的问题，需要更有效的黑盒对抗攻击框架

Method: 采用两阶段全局多样性攻击框架：第一阶段通过候选文本扩展和全局感知替换引入文本扰动；第二阶段使用多尺度调整和块洗牌旋转增强视觉多样性

Result: 在VLP模型上实验表明，2S-GDA相比现有方法攻击成功率显著提升，在黑盒设置下最高提升11.17%

Conclusion: 提出的框架具有模块化特性，能与现有方法结合进一步提升对抗迁移性，为多模态对抗攻击提供了有效解决方案

Abstract: Vision-language pre-training (VLP) models are vulnerable to adversarial examples, particularly in black-box scenarios. Existing multimodal attacks often suffer from limited perturbation diversity and unstable multi-stage pipelines. To address these challenges, we propose 2S-GDA, a two-stage globally-diverse attack framework. The proposed method first introduces textual perturbations through a globally-diverse strategy by combining candidate text expansion with globally-aware replacement. To enhance visual diversity, image-level perturbations are generated using multi-scale resizing and block-shuffle rotation. Extensive experiments on VLP models demonstrate that 2S-GDA consistently improves attack success rates over state-of-the-art methods, with gains of up to 11.17\% in black-box settings. Our framework is modular and can be easily combined with existing methods to further enhance adversarial transferability.

</details>


### [84] [Adaptive Multi-Scale Correlation Meta-Network for Few-Shot Remote Sensing Image Classification](https://arxiv.org/abs/2601.12308)
*Anurag Kaushish,Ayan Sar,Sampurna Roy,Sudeshna Chakraborty,Prashant Trivedi,Tanupriya Choudhury,Kanav Gupta*

Main category: cs.CV

TL;DR: AMC-MetaNet是一个轻量级小样本遥感学习框架，通过相关引导特征金字塔、自适应通道相关模块和相关引导元学习解决数据稀缺、领域偏移和多尺度问题，参数量仅60万，推理时间<50ms，在多个数据集上达到86.65%准确率。


<details>
  <summary>Details</summary>
Motivation: 遥感小样本学习面临三大挑战：标记数据稀缺、显著的领域偏移以及地理空间对象的多尺度特性。现有方法通常依赖大型预训练模型或Transformer，计算成本高且难以适应多尺度变化。

Method: 提出AMC-MetaNet框架，包含三个核心创新：1) 相关引导特征金字塔捕捉尺度不变模式；2) 自适应通道相关模块学习动态跨尺度关系；3) 相关引导元学习利用相关模式而非传统原型平均。框架从零开始训练，仅约60万参数。

Result: 在EuroSAT、NWPU-RESISC45、UC Merced Land Use和AID等多个遥感数据集上，5-way 5-shot分类准确率最高达86.65%。相比ResNet-18参数量减少20倍，每张图像推理时间小于50毫秒，计算效率高。

Conclusion: AMC-MetaNet是一个计算高效、尺度感知的框架，适用于实际遥感小样本学习场景，解决了传统方法的计算负担和多尺度适应问题，为轻量级遥感分析提供了新思路。

Abstract: Few-shot learning in remote sensing remains challenging due to three factors: the scarcity of labeled data, substantial domain shifts, and the multi-scale nature of geospatial objects. To address these issues, we introduce Adaptive Multi-Scale Correlation Meta-Network (AMC-MetaNet), a lightweight yet powerful framework with three key innovations: (i) correlation-guided feature pyramids for capturing scale-invariant patterns, (ii) an adaptive channel correlation module (ACCM) for learning dynamic cross-scale relationships, and (iii) correlation-guided meta-learning that leverages correlation patterns instead of conventional prototype averaging. Unlike prior approaches that rely on heavy pre-trained models or transformers, AMC-MetaNet is trained from scratch with only $\sim600K$ parameters, offering $20\times$ fewer parameters than ResNet-18 while maintaining high efficiency ($<50$ms per image inference). AMC-MetaNet achieves up to 86.65\% accuracy in 5-way 5-shot classification on various remote sensing datasets, including EuroSAT, NWPU-RESISC45, UC Merced Land Use, and AID. Our results establish AMC-MetaNet as a computationally efficient, scale-aware framework for real-world few-shot remote sensing.

</details>


### [85] [CurConMix+: A Unified Spatio-Temporal Framework for Hierarchical Surgical Workflow Understanding](https://arxiv.org/abs/2601.12312)
*Yongjun Jeon,Jongmin Shin,Kanggil Park,Seonmin Park,Soyoung Lim,Jung Yong Kim,Jinsoo Rhu,Jongman Kim,Gyu-Seong Choi,Namkee Oh,Kyu-Hwan Jung*

Main category: cs.CV

TL;DR: 提出CurConMix+框架，结合课程引导对比学习与多分辨率时序Transformer，解决手术动作三元组识别中的类别不平衡、视觉变化细微和语义依赖问题，并在新数据集LLS48上验证效果。


<details>
  <summary>Details</summary>
Motivation: 手术动作三元组识别对手术流程分析和技能评估很重要，但面临类别严重不平衡、视觉变化细微、三元组组件间语义依赖等挑战。现有方法通常只解决部分问题，缺乏整体解决方案。

Method: 基于CurConMix空间表示框架，采用课程引导对比学习策略学习区分性特征，结合结构化难对采样和特征级混合。扩展版CurConMix+集成多分辨率时序Transformer(MRTT)，自适应融合多尺度时序特征并动态平衡时空线索。同时提出新数据集LLS48。

Result: 在CholecT45和LLS48数据集上的实验表明，CurConMix+在手术动作三元组识别上优于现有方法，并展现出强大的跨层次泛化能力，其细粒度特征能有效迁移到更高层次的手术阶段和步骤识别任务。

Conclusion: 该框架和数据集为层次感知、可复现、可解释的手术流程理解提供了统一基础。代码和数据集将在GitHub公开以促进可复现性和进一步研究。

Abstract: Surgical action triplet recognition aims to understand fine-grained surgical behaviors by modeling the interactions among instruments, actions, and anatomical targets. Despite its clinical importance for workflow analysis and skill assessment, progress has been hindered by severe class imbalance, subtle visual variations, and the semantic interdependence among triplet components. Existing approaches often address only a subset of these challenges rather than tackling them jointly, which limits their ability to form a holistic understanding. This study builds upon CurConMix, a spatial representation framework. At its core, a curriculum-guided contrastive learning strategy learns discriminative and progressively correlated features, further enhanced by structured hard-pair sampling and feature-level mixup. Its temporal extension, CurConMix+, integrates a Multi-Resolution Temporal Transformer (MRTT) that achieves robust, context-aware understanding by adaptively fusing multi-scale temporal features and dynamically balancing spatio-temporal cues. Furthermore, we introduce LLS48, a new, hierarchically annotated benchmark for complex laparoscopic left lateral sectionectomy, providing step-, task-, and action-level annotations. Extensive experiments on CholecT45 and LLS48 demonstrate that CurConMix+ not only outperforms state-of-the-art approaches in triplet recognition, but also exhibits strong cross-level generalization, as its fine-grained features effectively transfer to higher-level phase and step recognition tasks. Together, the framework and dataset provide a unified foundation for hierarchy-aware, reproducible, and interpretable surgical workflow understanding. The code and dataset will be publicly released on GitHub to facilitate reproducibility and further research.

</details>


### [86] [S^2F-Net:A Robust Spatial-Spectral Fusion Framework for Cross-Model AIGC Detection](https://arxiv.org/abs/2601.12313)
*Xiangyu Hu,Yicheng Hong,Hongchuang Zheng,Wenjun Zeng,Bingyao Liu*

Main category: cs.CV

TL;DR: S²F-Net：一种基于频谱差异的跨模型生成图像检测框架，通过可学习频率注意力模块增强判别性频带，在17类生成模型上达到90.49%检测准确率


<details>
  <summary>Details</summary>
Motivation: 生成模型的快速发展对具有强泛化能力的检测方案提出了迫切需求。现有检测方法通常过度拟合特定源模型，在面对未见过的生成架构时性能显著下降。

Method: 提出S²F-Net跨模型检测框架，核心是探索和利用真实与合成纹理之间的固有频谱差异。引入可学习频率注意力模块，通过协同空间纹理分析和频谱依赖关系，自适应加权和增强判别性频带。

Result: 在包含17类生成模型的AIGCDetectBenchmark上，S²F-Net达到90.49%的检测准确率，在跨域检测场景中显著优于各种现有基线方法。

Conclusion: 通过关注上采样操作留下的频率指纹和频谱差异，S²F-Net从根本上改善了模型的泛化性能，为解决生成模型检测中的过拟合问题提供了有效方案。

Abstract: The rapid development of generative models has imposed an urgent demand for detection schemes with strong generalization capabilities. However, existing detection methods generally suffer from overfitting to specific source models, leading to significant performance degradation when confronted with unseen generative architectures. To address these challenges, this paper proposes a cross-model detection framework called S 2 F-Net, whose core lies in exploring and leveraging the inherent spectral discrepancies between real and synthetic textures. Considering that upsampling operations leave unique and distinguishable frequency fingerprints in both texture-poor and texture-rich regions, we focus our research on the detection of frequency-domain artifacts, aiming to fundamentally improve the generalization performance of the model. Specifically, we introduce a learnable frequency attention module that adaptively weights and enhances discriminative frequency bands by synergizing spatial texture analysis and spectral dependencies.On the AIGCDetectBenchmark, which includes 17 categories of generative models, S 2 F-Net achieves a detection accuracy of 90.49%, significantly outperforming various existing baseline methods in cross-domain detection scenarios.

</details>


### [87] [GazeFormer-MoE: Context-Aware Gaze Estimation via CLIP and MoE Transformer](https://arxiv.org/abs/2601.12316)
*Xinyuan Zhao,Xianrui Chen,Ahmad Chaddad*

Main category: cs.CV

TL;DR: 提出一种语义调制多尺度Transformer用于3D视线估计，通过可学习原型库调节CLIP全局特征，融合多尺度特征，使用混合专家网络提升条件容量，在多个数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有视线估计方法在处理复杂真实场景时面临挑战，需要更好地建模光照、头部姿态、背景等语义因素对视线估计的影响，并有效融合多尺度特征。

Method: 1) 使用可学习原型库（光照、头部姿态、背景、方向）调节CLIP全局特征；2) 在统一注意力空间中融合原型增强的全局向量、CLIP补丁token和高分辨率CNN token；3) 用路由/共享混合专家网络替换多个FFN块以增加条件容量。

Result: 在MPIIFaceGaze、EYEDIAP、Gaze360和ETH-XGaze数据集上分别达到2.49°、3.22°、10.16°和1.44°的角误差，相比之前结果相对提升最高达64%，创下新的SOTA。

Conclusion: 提出的语义调制多尺度Transformer通过原型条件调节、跨尺度融合和混合专家网络显著提升了3D视线估计性能，消融实验验证了各组件贡献，代码已开源。

Abstract: We present a semantics modulated, multi scale Transformer for 3D gaze estimation. Our model conditions CLIP global features with learnable prototype banks (illumination, head pose, background, direction), fuses these prototype-enriched global vectors with CLIP patch tokens and high-resolution CNN tokens in a unified attention space, and replaces several FFN blocks with routed/shared Mixture of Experts to increase conditional capacity. Evaluated on MPIIFaceGaze, EYEDIAP, Gaze360 and ETH-XGaze, our model achieves new state of the art angular errors of 2.49°, 3.22°, 10.16°, and 1.44°, demonstrating up to a 64% relative improvement over previously reported results. ablations attribute gains to prototype conditioning, cross scale fusion, MoE and hyperparameter. Our code is publicly available at https://github. com/AIPMLab/Gazeformer.

</details>


### [88] [Multi-Sensor Matching with HyperNetworks](https://arxiv.org/abs/2601.12325)
*Eli Passov,Nathan S. Netanyahu,Yosi Keller*

Main category: cs.CV

TL;DR: 提出一种基于超网络的轻量级描述子学习架构，通过自适应通道缩放/平移和条件实例归一化增强孪生CNN，在VIS-IR跨模态匹配中实现SOTA性能，同时发布GAP-VIR数据集。


<details>
  <summary>Details</summary>
Motivation: 超网络能够生成或调节其他网络的权重，为上下文和任务条件提供灵活机制。本文利用超网络改进多模态图像块匹配，旨在提升跨模态（如可见光与红外）匹配的鲁棒性，同时保持描述子方法的高效推理特性。

Method: 提出轻量级描述子学习架构：1）超网络模块计算自适应、每通道的缩放和平移参数；2）条件实例归一化在浅层提供模态特定适应（如VIS-IR）。结合孪生CNN，使用三元组损失和困难负样本挖掘进行训练。

Result: 在VIS-NIR和其他VIS-IR基准测试中取得最先进结果，在额外数据集上匹配或超越先前方法（尽管先前方法推理成本更高）。同时发布GAP-VIR数据集，包含50万对跨平台（地面/空中）VIS-IR图像块。

Conclusion: 通过超网络增强的轻量级架构在保持推理效率的同时显著提升了跨模态匹配的鲁棒性。GAP-VIR数据集的发布将促进领域偏移问题的研究进展。

Abstract: Hypernetworks are models that generate or modulate the weights of another network. They provide a flexible mechanism for injecting context and task conditioning and have proven broadly useful across diverse applications without significant increases in model size. We leverage hypernetworks to improve multimodal patch matching by introducing a lightweight descriptor-learning architecture that augments a Siamese CNN with (i) hypernetwork modules that compute adaptive, per-channel scaling and shifting and (ii) conditional instance normalization that provides modality-specific adaptation (e.g., visible vs. infrared, VIS-IR) in shallow layers. This combination preserves the efficiency of descriptor-based methods during inference while increasing robustness to appearance shifts. Trained with a triplet loss and hard-negative mining, our approach achieves state-of-the-art results on VIS-NIR and other VIS-IR benchmarks and matches or surpasses prior methods on additional datasets, despite their higher inference cost. To spur progress on domain shift, we also release GAP-VIR, a cross-platform (ground/aerial) VIS-IR patch dataset with 500K pairs, enabling rigorous evaluation of cross-domain generalization and adaptation.

</details>


### [89] [EmoKGEdit: Training-free Affective Injection via Visual Cue Transformation](https://arxiv.org/abs/2601.12326)
*Jing Zhang,Bingjie Fan*

Main category: cs.CV

TL;DR: EmoKGEdit：基于多模态情感关联知识图谱的无训练图像情感编辑框架，通过解耦情感与内容表示实现精确且结构保持的情感编辑


<details>
  <summary>Details</summary>
Motivation: 现有图像情感编辑方法难以从潜在内容表示中解耦情感线索，导致情感表达弱且视觉结构扭曲，需要更精确的结构保持情感编辑方法

Method: 构建多模态情感关联知识图谱（MSA-KG）解耦对象、场景、属性、视觉线索与情感的关系；设计解耦结构-情感编辑模块，在潜在空间中分离情感属性与布局特征

Result: EmoKGEdit在情感保真度和内容保持方面表现优异，优于现有最先进方法

Conclusion: 通过知识图谱引导的链式推理和潜在空间解耦，EmoKGEdit实现了精确且结构保持的图像情感编辑，解决了现有方法的局限性

Abstract: Existing image emotion editing methods struggle to disentangle emotional cues from latent content representations, often yielding weak emotional expression and distorted visual structures. To bridge this gap, we propose EmoKGEdit, a novel training-free framework for precise and structure-preserving image emotion editing. Specifically, we construct a Multimodal Sentiment Association Knowledge Graph (MSA-KG) to disentangle the intricate relationships among objects, scenes, attributes, visual clues and emotion. MSA-KG explicitly encode the causal chain among object-attribute-emotion, and as external knowledge to support chain of thought reasoning, guiding the multimodal large model to infer plausible emotion-related visual cues and generate coherent instructions. In addition, based on MSA-KG, we design a disentangled structure-emotion editing module that explicitly separates emotional attributes from layout features within the latent space, which ensures that the target emotion is effectively injected while strictly maintaining visual spatial coherence. Extensive experiments demonstrate that EmoKGEdit achieves excellent performance in both emotion fidelity and content preservation, and outperforms the state-of-the-art methods.

</details>


### [90] [FlowIID: Single-Step Intrinsic Image Decomposition via Latent Flow Matching](https://arxiv.org/abs/2601.12329)
*Mithlesh Singla,Seema Kumari,Shanmuganathan Raman*

Main category: cs.CV

TL;DR: 提出FlowIID，一种基于流匹配的轻量级本征图像分解方法，在保持性能的同时大幅减少参数量，适合实时应用


<details>
  <summary>Details</summary>
Motivation: 现有本征图像分解模型虽然效果好，但参数量大，难以与其他模型结合应用于实际场景，需要更轻量高效的解决方案

Method: 基于流匹配设计FlowIID架构，结合VAE引导的潜空间和流匹配模块，实现稳定的反照率和阴影分解

Result: FlowIID不仅参数量高效，只需单次推理步骤，而且在多个基准测试中取得竞争性甚至更优的结果

Conclusion: FlowIID适合部署在资源受限和实时视觉应用中，为实际应用提供了高效的解决方案

Abstract: Intrinsic Image Decomposition (IID) separates an image into albedo and shading components. It is a core step in many real-world applications, such as relighting and material editing. Existing IID models achieve good results, but often use a large number of parameters. This makes them costly to combine with other models in real-world settings. To address this problem, we propose a flow matching-based solution. For this, we design a novel architecture, FlowIID, based on latent flow matching. FlowIID combines a VAE-guided latent space with a flow matching module, enabling a stable decomposition of albedo and shading. FlowIID is not only parameter-efficient, but also produces results in a single inference step. Despite its compact design, FlowIID delivers competitive and superior results compared to existing models across various benchmarks. This makes it well-suited for deployment in resource-constrained and real-time vision applications.

</details>


### [91] [Turbo-GoDec: Exploiting the Cluster Sparsity Prior for Hyperspectral Anomaly Detection](https://arxiv.org/abs/2601.12337)
*Jiahui Sheng,Xiaorun Li,Shuhan Chen*

Main category: cs.CV

TL;DR: 提出Turbo-GoDec方法，将异常点的簇稀疏先验结合到GoDec算法中，用于高光谱图像异常检测


<details>
  <summary>Details</summary>
Motivation: 现有高光谱异常检测方法主要依赖低秩背景和稀疏异常假设，但很少对异常的空间分布特性进行深入挖掘。通过观察发现异常像素在空间上常呈现小规模聚集分布，即"簇稀疏性"

Method: 将簇稀疏先验结合到经典GoDec算法的S-step中，使用马尔可夫随机场建模异常簇稀疏性，通过因子图上的消息传递计算异常边际概率，高概率位置作为Turbo-GoDec的稀疏分量

Result: 在三个真实高光谱图像数据集上的实验表明，Turbo-GoDec在小尺寸异常检测方面优于原始GoDec（LSMAD）和其他先进异常检测方法

Conclusion: 提出的Turbo-GoDec方法通过引入异常簇稀疏先验，有效提升了高光谱图像异常检测性能，特别是在检测小尺寸异常方面表现优异

Abstract: As a key task in hyperspectral image processing, hyperspectral anomaly detection has garnered significant attention and undergone extensive research. Existing methods primarily relt on two prior assumption: low-rank background and sparse anomaly, along with additional spatial assumptions of the background. However, most methods only utilize the sparsity prior assumption for anomalies and rarely expand on this hypothesis. From observations of hyperspectral images, we find that anomalous pixels exhibit certain spatial distribution characteristics: they often manifest as small, clustered groups in space, which we refer to as cluster sparsity of anomalies. Then, we combined the cluster sparsity prior with the classical GoDec algorithm, incorporating the cluster sparsity prior into the S-step of GoDec. This resulted in a new hyperspectral anomaly detection method, which we called Turbo-GoDec. In this approach, we modeled the cluster sparsity prior of anomalies using a Markov random field and computed the marginal probabilities of anomalies through message passing on a factor graph. Locations with high anomalous probabilities were treated as the sparse component in the Turbo-GoDec. Experiments are conducted on three real hyperspectral image (HSI) datasets which demonstrate the superior performance of the proposed Turbo-GoDec method in detecting small-size anomalies comparing with the vanilla GoDec (LSMAD) and state-of-the-art anomaly detection methods. The code is available at https://github.com/jiahuisheng/Turbo-GoDec.

</details>


### [92] [MMDeepResearch-Bench: A Benchmark for Multimodal Deep Research Agents](https://arxiv.org/abs/2601.12346)
*Peizhou Huang,Zixuan Zhong,Zhongwei Wan,Donghao Zhou,Samiul Alam,Xin Wang,Zexin Li,Zhihao Dou,Li Zhu,Jing Xiong,Chaofan Tao,Yan Xu,Dimitrios Dimitriadis,Tuo Zhang,Mi Zhang*

Main category: cs.CV

TL;DR: MMDR-Bench：首个评估多模态深度研究代理的基准，包含140个专家构建任务，强调带引用的报告生成和多模态证据使用，并提出三部分评估框架。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要针对纯文本设置或短格式多模态问答，缺乏端到端的多模态证据使用评估，无法全面评估深度研究代理的多模态理解和引用报告生成能力。

Method: 提出MMDR-Bench基准，包含140个专家构建任务覆盖21个领域，每个任务提供图像-文本捆绑数据。开发统一可解释评估管道：FLAE评估报告质量，TRACE评估引用证据对齐，MOSAIC评估文本-视觉完整性。

Result: 在25个最先进模型上的实验揭示了生成质量、引用纪律和多模态基础之间的系统性权衡，表明强大的文本生成能力不能保证忠实证据使用，多模态完整性仍是深度研究代理的关键瓶颈。

Conclusion: MMDR-Bench填补了多模态深度研究评估的空白，揭示了当前模型在多模态证据使用方面的局限性，为未来研究提供了诊断性评估框架，强调需要同时提升生成质量、引用纪律和多模态完整性。

Abstract: Deep Research Agents (DRAs) generate citation-rich reports via multi-step search and synthesis, yet existing benchmarks mainly target text-only settings or short-form multimodal QA, missing end-to-end multimodal evidence use. We introduce MMDeepResearch-Bench (MMDR-Bench), a benchmark of 140 expert-crafted tasks across 21 domains, where each task provides an image-text bundle to evaluate multimodal understanding and citation-grounded report generation. Compared to prior setups, MMDR-Bench emphasizes report-style synthesis with explicit evidence use, where models must connect visual artifacts to sourced claims and maintain consistency across narrative, citations, and visual references. We further propose a unified, interpretable evaluation pipeline: Formula-LLM Adaptive Evaluation (FLAE) for report quality, Trustworthy Retrieval-Aligned Citation Evaluation (TRACE) for citation-grounded evidence alignment, and Multimodal Support-Aligned Integrity Check (MOSAIC) for text-visual integrity, each producing fine-grained signals that support error diagnosis beyond a single overall score. Experiments across 25 state-of-the-art models reveal systematic trade-offs between generation quality, citation discipline, and multimodal grounding, highlighting that strong prose alone does not guarantee faithful evidence use and that multimodal integrity remains a key bottleneck for deep research agents.

</details>


### [93] [SimpleMatch: A Simple and Strong Baseline for Semantic Correspondence](https://arxiv.org/abs/2601.12357)
*Hailing Jin,Huiying Li*

Main category: cs.CV

TL;DR: SimpleMatch是一个用于语义匹配的简单高效框架，通过轻量级上采样解码器和多尺度监督损失，在低分辨率下实现强性能，同时减少51%训练内存使用。


<details>
  <summary>Details</summary>
Motivation: 当前基于预训练大模型的语义匹配方法依赖高分辨率输入以获得最佳性能，导致计算开销大。深层下采样操作会导致相邻关键点特征不可逆融合，当语义不同的关键点落入同一感受野时性能受限。

Method: 提出SimpleMatch框架：1) 轻量级上采样解码器，逐步将深层特征上采样到1/4分辨率以恢复空间细节；2) 多尺度监督损失，确保上采样特征在不同空间尺度上保持判别性；3) 稀疏匹配和基于窗口的定位，优化训练内存使用。

Result: 在252x252分辨率（比当前SOTA方法小3.3倍）下，在SPair-71k基准测试上达到84.1% PCK@0.1的优异性能，同时训练内存使用减少51%。

Conclusion: SimpleMatch为语义匹配的未来研究提供了一个实用高效的基线框架，能够在低分辨率下实现强性能，解决了当前方法对高分辨率输入的依赖问题。

Abstract: Recent advances in semantic correspondence have been largely driven by the use of pre-trained large-scale models. However, a limitation of these approaches is their dependence on high-resolution input images to achieve optimal performance, which results in considerable computational overhead. In this work, we address a fundamental limitation in current methods: the irreversible fusion of adjacent keypoint features caused by deep downsampling operations. This issue is triggered when semantically distinct keypoints fall within the same downsampled receptive field (e.g., 16x16 patches). To address this issue, we present SimpleMatch, a simple yet effective framework for semantic correspondence that delivers strong performance even at low resolutions. We propose a lightweight upsample decoder that progressively recovers spatial detail by upsampling deep features to 1/4 resolution, and a multi-scale supervised loss that ensures the upsampled features retain discriminative features across different spatial scales. In addition, we introduce sparse matching and window-based localization to optimize training memory usage and reduce it by 51%. At a resolution of 252x252 (3.3x smaller than current SOTA methods), SimpleMatch achieves superior performance with 84.1% PCK@0.1 on the SPair-71k benchmark. We believe this framework provides a practical and efficient baseline for future research in semantic correspondence. Code is available at: https://github.com/hailong23-jin/SimpleMatch.

</details>


### [94] [From Prompts to Pavement: LMMs-based Agentic Behavior-Tree Generation Framework for Autonomous Vehicles](https://arxiv.org/abs/2601.12358)
*Omar Y. Goba,Ahmed Y. Gado,Catherine M. Elias,Ahmed Hussein*

Main category: cs.CV

TL;DR: 论文提出了一种基于LLM和LVM的自主车辆行为规划框架，能够动态生成和调整行为树，以应对不可预测的驾驶场景。


<details>
  <summary>Details</summary>
Motivation: 传统行为树（BTs）虽然提供结构化决策逻辑，但本质上是静态的，需要大量人工调优，这限制了其在SAE Level 5级自动驾驶中的应用。自主车辆需要能够适应不可预测的真实环境的行为规划器。

Method: 提出了一个基于智能体（agentic）的框架，利用大语言模型（LLMs）和多模态视觉模型（LVMs）动态生成和调整行为树。包含三个专门智能体：Descriptor智能体使用符号链提示评估场景关键性；Planner智能体通过上下文学习构建高层子目标；Generator智能体以XML格式合成可执行的行为树子树。系统仅在基线行为树失败时触发，集成到CARLA+Nav2仿真中。

Result: 在CARLA+Nav2仿真中，系统成功导航绕过意外障碍物（如街道堵塞），无需人工干预。与静态行为树基线相比，该方法能够扩展到多样化的驾驶场景。

Conclusion: 该框架是一个概念验证，展示了利用LLMs和LVMs动态生成和调整行为树的可行性，为自主车辆在不可预测环境中的自适应行为规划提供了新途径。

Abstract: Autonomous vehicles (AVs) require adaptive behavior planners to navigate unpredictable, real-world environments safely. Traditional behavior trees (BTs) offer structured decision logic but are inherently static and demand labor-intensive manual tuning, limiting their applicability at SAE Level 5 autonomy. This paper presents an agentic framework that leverages large language models (LLMs) and multi-modal vision models (LVMs) to generate and adapt BTs on the fly. A specialized Descriptor agent applies chain-of-symbols prompting to assess scene criticality, a Planner agent constructs high-level sub-goals via in-context learning, and a Generator agent synthesizes executable BT sub-trees in XML format. Integrated into a CARLA+Nav2 simulation, our system triggers only upon baseline BT failure, demonstrating successful navigation around unexpected obstacles (e.g., street blockage) with no human intervention. Compared to a static BT baseline, this approach is a proof-of-concept that extends to diverse driving scenarios.

</details>


### [95] [DepthCropSeg++: Scaling a Crop Segmentation Foundation Model With Depth-Labeled Data](https://arxiv.org/abs/2601.12366)
*Jiafei Zhang,Songliang Cao,Binghui Xu,Yanan Li,Weiwei Jia,Tingting Wu,Hao Lu,Weijuan Hu,Zhiguo Han*

Main category: cs.CV

TL;DR: DepthCropSeg++是一个用于作物分割的基础模型，能够在开放田间环境下分割不同作物物种，在多个挑战性场景中表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前作物分割模型由于像素级标注成本高昂，通常只能从有限数据中学习，导致只能在特定作物类型或受控环境下表现良好。需要开发能够跨物种、跨场景泛化的作物分割基础模型。

Method: 1) 扩展跨物种和跨场景的作物分割数据集（28,406张图像，30+物种，15种环境条件）；2) 基于ViT-Adapter架构，增强动态上采样以改进细节感知；3) 采用两阶段自训练管道进行训练。

Result: 在综合测试集上达到93.11% mIoU，显著优于监督基线（+0.36%）和通用视觉基础模型如SAM（+48.57%）。在夜间环境（86.90% mIoU）、高密度冠层（90.09% mIoU）和未见作物品种（90.09% mIoU）等挑战性场景中表现优异。

Conclusion: DepthCropSeg++为作物分割建立了新的技术水平，展示了基础模型在农业视觉任务中的潜力，能够有效应对开放田间环境下的各种挑战。

Abstract: DepthCropSeg++: a foundation model for crop segmentation, capable of segmenting different crop species under open in-field environment. Crop segmentation is a fundamental task for modern agriculture, which closely relates to many downstream tasks such as plant phenotyping, density estimation, and weed control. In the era of foundation models, a number of generic large language and vision models have been developed. These models have demonstrated remarkable real world generalization due to significant model capacity and largescale datasets. However, current crop segmentation models mostly learn from limited data due to expensive pixel-level labelling cost, often performing well only under specific crop types or controlled environment. In this work, we follow the vein of our previous work DepthCropSeg, an almost unsupervised approach to crop segmentation, to scale up a cross-species and crossscene crop segmentation dataset, with 28,406 images across 30+ species and 15 environmental conditions. We also build upon a state-of-the-art semantic segmentation architecture ViT-Adapter architecture, enhance it with dynamic upsampling for improved detail awareness, and train the model with a two-stage selftraining pipeline. To systematically validate model performance, we conduct comprehensive experiments to justify the effectiveness and generalization capabilities across multiple crop datasets. Results demonstrate that DepthCropSeg++ achieves 93.11% mIoU on a comprehensive testing set, outperforming both supervised baselines and general-purpose vision foundation models like Segmentation Anything Model (SAM) by significant margins (+0.36% and +48.57% respectively). The model particularly excels in challenging scenarios including night-time environment (86.90% mIoU), high-density canopies (90.09% mIoU), and unseen crop varieties (90.09% mIoU), indicating a new state of the art for crop segmentation.

</details>


### [96] [CD-TWINSAFE: A ROS-enabled Digital Twin for Scene Understanding and Safety Emerging V2I Technology](https://arxiv.org/abs/2601.12373)
*Amro Khaled,Farah Khaled,Omar Riad,Catherine M. Elias*

Main category: cs.CV

TL;DR: 提出CD-TWINSAFE，一种基于V2I的自动驾驶车辆数字孪生系统，包含车载驾驶堆栈和数字孪生堆栈，通过4G网络实现实时通信和安全预警。


<details>
  <summary>Details</summary>
Motivation: 为了提高自动驾驶车辆的安全性，需要一种能够实时监控车辆状态和环境、提供安全预警的系统。传统方法缺乏对车辆周围环境的数字孪生表示和实时安全评估能力。

Method: 采用双堆栈架构：1）车载驾驶堆栈包含立体相机、定位和感知模块，处理20fps图像并提取物体检测、速度、偏航角及安全指标；2）数字孪生堆栈使用Unreal Engine 5创建场景副本，通过ROS2消息和UDP/4G通信接收实时数据更新，生成安全警报。

Result: 通过多种驾驶场景测试验证了系统架构的有效性和实时响应能力，能够成功实现车辆定位、环境感知、数字孪生同步和安全预警功能。

Conclusion: CD-TWINSAFE系统成功实现了基于V2I的自动驾驶数字孪生架构，通过实时数据同步和安全指标计算，为自动驾驶车辆提供了有效的安全监控和预警能力。

Abstract: In this paper, the CD-TWINSAFE is introduced, a V2I-based digital twin for Autonomous Vehicles. The proposed architecture is composed of two stacks running simultaneously, an on-board driving stack that includes a stereo camera for scene understanding, and a digital twin stack that runs an Unreal Engine 5 replica of the scene viewed by the camera as well as returning safety alerts to the cockpit. The on-board stack is implemented on the vehicle side including 2 main autonomous modules; localization and perception. The position and orientation of the ego vehicle are obtained using on-board sensors. Furthermore, the perception module is responsible for processing 20-fps images from stereo camera and understands the scene through two complementary pipelines. The pipeline are working on object detection and feature extraction including object velocity, yaw and the safety metrics time-to-collision and time-headway. The collected data form the driving stack are sent to the infrastructure side through the ROS-enabled architecture in the form of custom ROS2 messages and sent over UDP links that ride a 4G modem for V2I communication. The environment is monitored via the digital twin through the shared messages which update the information of the spawned ego vehicle and detected objects based on the real-time localization and perception data. Several tests with different driving scenarios to confirm the validity and real-time response of the proposed architecture.

</details>


### [97] [Utilizing the Score of Data Distribution for Hyperspectral Anomaly Detection](https://arxiv.org/abs/2601.12379)
*Jiahui Sheng,Yidan Shi,Shu Xiang,Xiaorun Li,Shuhan Chen*

Main category: cs.CV

TL;DR: 提出基于分数生成模型的HSI异常检测方法ScoreAD，利用光谱数据的流形假设和分数梯度场区分背景与异常光谱


<details>
  <summary>Details</summary>
Motivation: 高光谱图像的光谱数据由少数因素（如化学成分、光照）决定，满足流形假设。背景光谱位于低维流形上，而异常光谱由于独特的光谱特征成为流形上的离群点，基于这种分布差异进行异常检测

Method: 提出ScoreAD方法：1）使用分数生成模型在整个光谱集上训练；2）测试时通过扰动核处理每个光谱，输入训练好的SGM获取估计分数；3）利用背景与异常光谱在流形分布上的差异进行检测

Result: 在四个高光谱数据集上的实验证明了该方法的有效性

Conclusion: 基于高光谱流形假设和分数生成模型的方法能够有效检测异常光谱，代码已开源

Abstract: Hyperspectral images (HSIs) are a type of image that contains abundant spectral information. As a type of real-world data, the high-dimensional spectra in hyperspectral images are actually determined by only a few factors, such as chemical composition and illumination. Thus, spectra in hyperspectral images are highly likely to satisfy the manifold hypothesis. Based on the hyperspectral manifold hypothesis, we propose a novel hyperspectral anomaly detection method (named ScoreAD) that leverages the time-dependent gradient field of the data distribution (i.e., the score), as learned by a score-based generative model (SGM). Our method first trains the SGM on the entire set of spectra from the hyperspectral image. At test time, each spectrum is passed through a perturbation kernel, and the resulting perturbed spectrum is fed into the trained SGM to obtain the estimated score. The manifold hypothesis of HSIs posits that background spectra reside on one or more low-dimensional manifolds. Conversely, anomalous spectra, owing to their unique spectral signatures, are considered outliers that do not conform to the background manifold. Based on this fundamental discrepancy in their manifold distributions, we leverage a generative SGM to achieve hyperspectral anomaly detection. Experiments on the four hyperspectral datasets demonstrate the effectiveness of the proposed method. The code is available at https://github.com/jiahuisheng/ScoreAD.

</details>


### [98] [A Hierarchical Benchmark of Foundation Models for Dermatology](https://arxiv.org/abs/2601.12382)
*Furkan Yuceyalcin,Abdurrahim Yilmaz,Burak Temelkuran*

Main category: cs.CV

TL;DR: 评估10个基础模型在皮肤病变分层分类中的表现，发现通用医学模型在高层次筛查表现最佳，而皮肤病专用模型在细粒度亚型分类上更优，存在"粒度差距"


<details>
  <summary>Details</summary>
Motivation: 当前皮肤病学基准测试常将复杂的诊断分类简化为二元分类任务，这种过度简化掩盖了模型进行细粒度鉴别诊断的能力，而这对临床工作流程整合至关重要

Method: 使用DERM12345数据集（40个病变亚类），计算10个基础模型（涵盖通用计算机视觉、通用医学影像和皮肤病专用领域）的冻结嵌入，训练轻量级适配器模型，采用五折交叉验证，并引入分层评估框架评估四个临床粒度级别的性能

Result: MedImageInsights在二元恶性检测中表现最佳（97.52%加权F1分数），但在40类亚型分类中降至65.50%；MedSigLip（69.79%）和皮肤病专用模型在细粒度亚型分类上表现优异，但整体性能低于MedImageInsights，显示出"粒度差距"

Conclusion: 通用医学基础模型在高层次筛查中非常有效，但诊断支持系统所需的细粒度区分需要专门的建模策略

Abstract: Foundation models have transformed medical image analysis by providing robust feature representations that reduce the need for large-scale task-specific training. However, current benchmarks in dermatology often reduce the complex diagnostic taxonomy to flat, binary classification tasks, such as distinguishing melanoma from benign nevi. This oversimplification obscures a model's ability to perform fine-grained differential diagnoses, which is critical for clinical workflow integration. This study evaluates the utility of embeddings derived from ten foundation models, spanning general computer vision, general medical imaging, and dermatology-specific domains, for hierarchical skin lesion classification. Using the DERM12345 dataset, which comprises 40 lesion subclasses, we calculated frozen embeddings and trained lightweight adapter models using a five-fold cross-validation. We introduce a hierarchical evaluation framework that assesses performance across four levels of clinical granularity: 40 Subclasses, 15 Main Classes, 2 and 4 Superclasses, and Binary Malignancy. Our results reveal a "granularity gap" in model capabilities: MedImageInsights achieved the strongest overall performance (97.52% weighted F1-Score on Binary Malignancy detection) but declined to 65.50% on fine-grained 40-class subtype classification. Conversely, MedSigLip (69.79%) and dermatology-specific models (Derm Foundation and MONET) excelled at fine-grained 40-class subtype discrimination while achieving lower overall performance than MedImageInsights on broader classification tasks. Our findings suggest that while general medical foundation models are highly effective for high-level screening, specialized modeling strategies are necessary for the granular distinctions required in diagnostic support systems.

</details>


### [99] [Class-Partitioned VQ-VAE and Latent Flow Matching for Point Cloud Scene Generation](https://arxiv.org/abs/2601.12391)
*Dasith de Silva Edirimuni,Ajmal Saeed Mian*

Main category: cs.CV

TL;DR: 提出CPVQ-VAE和LFMM方法，实现无需外部数据库的纯点云场景生成，通过类分区码本解决复杂场景中扩散特征解码问题。


<details>
  <summary>Details</summary>
Motivation: 现有3D场景生成方法大多只能生成物体边界框参数，较新的扩散方法能生成类别标签和潜在特征，但需要从预定义数据库中检索物体。对于复杂多样的多类别场景，当前自编码器无法有效将扩散潜在特征解码为符合目标类别的正确点云物体。

Method: 1. 提出类分区向量量化变分自编码器(CPVQ-VAE)，采用类分区码本，码向量按类别标记；2. 提出类感知运行平均更新策略，重新初始化每个分区中的"死亡"码向量，解决码本坍缩问题；3. 设计专门用于场景生成的潜在空间流匹配模型(LFMM)，生成物体特征和类别标签；4. CPVQ-VAE通过类感知逆查找将生成的特征映射到码本条目，解码为类别特定的点云形状。

Result: 实验表明该方法能可靠恢复合理的点云场景，在复杂客厅场景上，Chamfer误差和Point2Mesh误差分别减少70.4%和72.3%。

Conclusion: 该方法实现了无需依赖外部物体数据库检索的纯点云生成，通过类分区码本和类感知更新策略有效解决了复杂场景中扩散特征解码问题。

Abstract: Most 3D scene generation methods are limited to only generating object bounding box parameters while newer diffusion methods also generate class labels and latent features. Using object size or latent feature, they then retrieve objects from a predefined database. For complex scenes of varied, multi-categorical objects, diffusion-based latents cannot be effectively decoded by current autoencoders into the correct point cloud objects which agree with target classes. We introduce a Class-Partitioned Vector Quantized Variational Autoencoder (CPVQ-VAE) that is trained to effectively decode object latent features, by employing a pioneering $\textit{class-partitioned codebook}$ where codevectors are labeled by class. To address the problem of $\textit{codebook collapse}$, we propose a $\textit{class-aware}$ running average update which reinitializes dead codevectors within each partition. During inference, object features and class labels, both generated by a Latent-space Flow Matching Model (LFMM) designed specifically for scene generation, are consumed by the CPVQ-VAE. The CPVQ-VAE's class-aware inverse look-up then maps generated latents to codebook entries that are decoded to class-specific point cloud shapes. Thereby, we achieve pure point cloud generation without relying on an external objects database for retrieval. Extensive experiments reveal that our method reliably recovers plausible point cloud scenes, with up to 70.4% and 72.3% reduction in Chamfer and Point2Mesh errors on complex living room scenes.

</details>


### [100] [Weaknesses of Facial Emotion Recognition Systems](https://arxiv.org/abs/2601.12402)
*Aleksandra Jamróz,Patrycja Wysocka,Piotr Garbat*

Main category: cs.CV

TL;DR: 该论文对基于面部表情的情感检测方法进行了综述，选取了三种最佳神经网络解决方案和三个多样化数据集进行实验比较，揭示了现有方法在数据集差异、特定情感识别难度和相似情感区分方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 面部情感检测是人机交互中的重要机器学习问题，现有方法众多且差异大，需要进行深入综述和系统比较，以揭示现有解决方案的优缺点。

Method: 1. 对相关文献进行深入综述；2. 选取三种最优秀的情感检测神经网络；3. 选择三个具有图像多样性和数量优势的数据集；4. 训练所选神经网络；5. 进行一系列实验比较，包括在不同数据集上进行跨数据集测试。

Result: 实验揭示了现有解决方案的多个弱点：1. 不同数据集之间存在显著差异；2. 识别特定情感时存在难度不均的问题；3. 在区分密切相关的情绪方面面临挑战；4. 模型在不同数据集上的泛化能力有限。

Conclusion: 面部情感检测领域仍面临数据集不一致、特定情感识别难度差异和相似情感区分困难等核心挑战，需要进一步研究来提升模型的鲁棒性和泛化能力。

Abstract: Emotion detection from faces is one of the machine learning problems needed for human-computer interaction. The variety of methods used is enormous, which motivated an in-depth review of articles and scientific studies. Three of the most interesting and best solutions are selected, followed by the selection of three datasets that stood out for the diversity and number of images in them. The selected neural networks are trained, and then a series of experiments are performed to compare their performance, including testing on different datasets than a model was trained on. This reveals weaknesses in existing solutions, including differences between datasets, unequal levels of difficulty in recognizing certain emotions and the challenges in differentiating between closely related emotions.

</details>


### [101] [HOT-POT: Optimal Transport for Sparse Stereo Matching](https://arxiv.org/abs/2601.12423)
*Antonin Clerc,Michael Quellmalz,Moritz Piening,Philipp Flotho,Gregor Kornhardt,Gabriele Steidl*

Main category: cs.CV

TL;DR: 提出基于最优传输的稀疏特征立体匹配方法，利用极线距离和3D射线距离作为成本函数，解决面部标志点匹配等应用中的参数敏感性和遮挡问题


<details>
  <summary>Details</summary>
Motivation: 立体视觉面临遮挡、运动和相机畸变等挑战，特别是在使用稀疏特征（如面部标志点）进行立体匹配时，参数敏感性导致问题更加复杂。需要克服这种不适定性，实现无监督的稀疏匹配。

Method: 从最优传输视角考虑相机几何的线约束，将相机投影点建模为（半）线，提出使用经典极线距离和3D射线距离来量化匹配质量。将这些距离作为（部分）最优传输问题的成本函数，形成可高效求解的分配问题。还扩展到无监督物体匹配，将其表述为分层最优传输问题。

Result: 提出的算法能够高效进行特征和物体匹配，数值实验证明其有效性，特别是在面部分析应用中匹配不同的标志点标注规范。

Conclusion: 通过最优传输框架结合几何约束，成功解决了稀疏特征立体匹配的挑战，为面部分析等应用提供了有效的无监督匹配解决方案。

Abstract: Stereo vision between images faces a range of challenges, including occlusions, motion, and camera distortions, across applications in autonomous driving, robotics, and face analysis. Due to parameter sensitivity, further complications arise for stereo matching with sparse features, such as facial landmarks. To overcome this ill-posedness and enable unsupervised sparse matching, we consider line constraints of the camera geometry from an optimal transport (OT) viewpoint. Formulating camera-projected points as (half)lines, we propose the use of the classical epipolar distance as well as a 3D ray distance to quantify matching quality. Employing these distances as a cost function of a (partial) OT problem, we arrive at efficiently solvable assignment problems. Moreover, we extend our approach to unsupervised object matching by formulating it as a hierarchical OT problem. The resulting algorithms allow for efficient feature and object matching, as demonstrated in our numerical experiments. Here, we focus on applications in facial analysis, where we aim to match distinct landmarking conventions.

</details>


### [102] [SkeFi: Cross-Modal Knowledge Transfer for Wireless Skeleton-Based Action Recognition](https://arxiv.org/abs/2601.12432)
*Shunyu Huang,Yunjiao Zhou,Jianfei Yang*

Main category: cs.CV

TL;DR: SkeFi通过跨模态知识迁移，利用RGB数据训练无线传感器（LiDAR和mmWave）的骨架估计和动作识别模型，解决了黑暗环境和隐私问题


<details>
  <summary>Details</summary>
Motivation: 基于RGB摄像机的骨架动作识别在黑暗环境下性能下降且存在隐私问题，限制了在智能家居和医院等场景的应用。无线传感器（LiDAR和mmWave）可以解决这些问题，但面临数据不足和噪声大的挑战。

Method: 提出SkeFi框架，采用跨模态知识迁移从数据丰富的RGB模态获取知识。设计了增强的时间相关自适应图卷积（TC-AGC）处理缺失或不连续帧的噪声，并通过双时间卷积增强多尺度时间建模。

Result: 实验表明SkeFi在mmWave和LiDAR传感器上实现了最先进的性能，能够从噪声无线传感器中提取准确的姿态和动作。

Conclusion: SkeFi通过创新的跨模态知识迁移和时间建模方法，成功解决了无线传感器骨架动作识别中的数据不足和噪声问题，为黑暗环境和隐私敏感场景提供了可行的替代方案。

Abstract: Skeleton-based action recognition leverages human pose keypoints to categorize human actions, which shows superior generalization and interoperability compared to regular end-to-end action recognition. Existing solutions use RGB cameras to annotate skeletal keypoints, but their performance declines in dark environments and raises privacy concerns, limiting their use in smart homes and hospitals. This paper explores non-invasive wireless sensors, i.e., LiDAR and mmWave, to mitigate these challenges as a feasible alternative. Two problems are addressed: (1) insufficient data on wireless sensor modality to train an accurate skeleton estimation model, and (2) skeletal keypoints derived from wireless sensors are noisier than RGB, causing great difficulties for subsequent action recognition models. Our work, SkeFi, overcomes these gaps through a novel cross-modal knowledge transfer method acquired from the data-rich RGB modality. We propose the enhanced Temporal Correlation Adaptive Graph Convolution (TC-AGC) with frame interactive enhancement to overcome the noise from missing or inconsecutive frames. Additionally, our research underscores the effectiveness of enhancing multiscale temporal modeling through dual temporal convolution. By integrating TC-AGC with temporal modeling for cross-modal transfer, our framework can extract accurate poses and actions from noisy wireless sensors. Experiments demonstrate that SkeFi realizes state-of-the-art performances on mmWave and LiDAR. The code is available at https://github.com/Huang0035/Skefi.

</details>


### [103] [Adversarial Defense in Vision-Language Models: An Overview](https://arxiv.org/abs/2601.12443)
*Xiaowei Fu,Lei Zhang*

Main category: cs.CV

TL;DR: 这篇论文综述了视觉语言模型（VLMs）对抗性防御的三大范式：训练时防御、测试时适应防御和免训练防御，分析了各自的优缺点及当前挑战。


<details>
  <summary>Details</summary>
Motivation: 随着视觉语言模型（如CLIP）的广泛应用，其对抗性攻击的脆弱性引发了安全担忧。这些攻击可能损害跨模态任务中的模型性能和系统安全，因此需要系统性地研究防御策略。

Method: 论文采用文献综述方法，系统性地分析三种主要防御范式：1）训练时防御（通过对抗性微调增强鲁棒性）；2）测试时适应防御（在推理时更新参数处理对抗样本）；3）免训练防御（通过修改对抗输入或特征嵌入来减轻攻击影响）。

Result: 综述总结了各种防御方法的最新进展：训练时防御有效但计算成本高且泛化能力有限；测试时适应防御灵活但增加复杂性和计算开销；免训练防御无需修改模型但效果可能受限。同时指出了增强VLM鲁棒性面临的持续挑战。

Conclusion: 视觉语言模型的对抗性防御是一个活跃的研究领域，三种防御范式各有优劣。未来需要开发更高效、通用且实用的防御策略来应对日益复杂的对抗性攻击，确保VLM在实际应用中的安全性和可靠性。

Abstract: The widespread use of Vision Language Models (VLMs, e.g. CLIP) has raised concerns about their vulnerability to sophisticated and imperceptible adversarial attacks. These attacks could compromise model performance and system security in cross-modal tasks. To address this challenge, three main defense paradigms have been proposed: Training-time Defense, Test-time Adaptation Defense, and Training-free Defense. Training-time Defense involves modifying the training process, typically through adversarial fine-tuning to improve the robustness to adversarial examples. While effective, this approach requires substantial computational resources and may not generalize across all adversarial attacks. Test-time Adaptation Defense focuses on adapting the model at inference time by updating its parameters to handle unlabeled adversarial examples, offering flexibility but often at the cost of increased complexity and computational overhead. Training-free Defense avoids modifying the model itself, instead focusing on altering the adversarial inputs or their feature embeddings, which enforces input perturbations to mitigate the impact of attacks without additional training. This survey reviews the latest advancements in adversarial defense strategies for VLMs, highlighting the strengths and limitations of such approaches and discussing ongoing challenges in enhancing the robustness of VLMs.

</details>


### [104] [Large-scale EM Benchmark for Multi-Organelle Instance Segmentation in the Wild](https://arxiv.org/abs/2601.12464)
*Yanrui Lu,Danyang Chen,Haowen Xiao,Jiarui Zhu,Fukang Ge,Binqian Zou,Jiali Guan,Jiayin Liang,Yuting Wang,Ziqian Guan,Xiangcheng Bao,Jinhao Bi,Lin Gu,Jun He,Yingying Zhu*

Main category: cs.CV

TL;DR: 开发了一个大规模多源电子显微镜多细胞器实例分割基准数据集，包含超过10万张2D EM图像，涵盖多种细胞类型和5种细胞器类别，以解决现有基准数据集小、无法捕捉真实世界变异性的问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于小型精选数据集的基准无法捕捉真实世界EM数据的固有异质性和大空间上下文，这给当前基于patch的方法带来了根本性限制，需要更符合实际应用场景的基准。

Method: 1) 开发大规模多源基准数据集，包含超过10万张2D EM图像，涵盖多种细胞类型和5种细胞器类别；2) 使用设计的连通性感知标签传播算法(3D LPA)生成数据集标注，并进行专家精修；3) 对U-Net、SAM变体和Mask2Former等最先进模型进行基准测试。

Result: 当前模型在异质EM数据上泛化能力不足，对具有全局分布形态的细胞器（如内质网）表现较差，揭示了局部上下文模型与建模长程结构连续性之间的根本性不匹配。

Conclusion: 需要开发能够处理真实世界变异性和长程结构连续性的新模型，基准数据集和标注工具将公开发布以促进该领域发展。

Abstract: Accurate instance-level segmentation of organelles in electron microscopy (EM) is critical for quantitative analysis of subcellular morphology and inter-organelle interactions. However, current benchmarks, based on small, curated datasets, fail to capture the inherent heterogeneity and large spatial context of in-the-wild EM data, imposing fundamental limitations on current patch-based methods. To address these limitations, we developed a large-scale, multi-source benchmark for multi-organelle instance segmentation, comprising over 100,000 2D EM images across variety cell types and five organelle classes that capture real-world variability. Dataset annotations were generated by our designed connectivity-aware Label Propagation Algorithm (3D LPA) with expert refinement. We further benchmarked several state-of-the-art models, including U-Net, SAM variants, and Mask2Former. Our results show several limitations: current models struggle to generalize across heterogeneous EM data and perform poorly on organelles with global, distributed morphologies (e.g., Endoplasmic Reticulum). These findings underscore the fundamental mismatch between local-context models and the challenge of modeling long-range structural continuity in the presence of real-world variability. The benchmark dataset and labeling tool will be publicly released soon.

</details>


### [105] [DCAC: Dynamic Class-Aware Cache Creates Stronger Out-of-Distribution Detectors](https://arxiv.org/abs/2601.12468)
*Yanqi Wu,Qichao Chen,Runhe Lai,Xinhua Lu,Jia-Xin Zhuang,Zhilin Zhao,Wei-Shi Zheng,Ruixuan Wang*

Main category: cs.CV

TL;DR: DCAC是一种无需训练、测试时校准模块，通过为每个ID类别维护单独缓存来收集高熵样本，以缓解OOD样本的过度自信预测问题。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在OOD检测中存在过度自信预测问题，研究发现被预测为同一类别的OOD样本在视觉上比真实ID样本更相似，这启发了基于类别的校准方法。

Method: 提出DCAC模块，为每个ID类别维护动态缓存收集高熵样本，通过轻量级两层模块利用缓存视觉特征和预测概率来校准原始预测，可与现有OOD检测方法无缝集成。

Result: 在多个OOD基准测试中显著提升现有方法性能，如在ImageNet OOD基准上集成ASH-S时FPR95降低6.55%，计算开销极小。

Conclusion: DCAC是一种有效的训练免费测试时校准方法，通过类感知缓存机制显著改善OOD检测性能，适用于单模态和视觉语言模型。

Abstract: Out-of-distribution (OOD) detection remains a fundamental challenge for deep neural networks, particularly due to overconfident predictions on unseen OOD samples during testing. We reveal a key insight: OOD samples predicted as the same class, or given high probabilities for it, are visually more similar to each other than to the true in-distribution (ID) samples. Motivated by this class-specific observation, we propose DCAC (Dynamic Class-Aware Cache), a training-free, test-time calibration module that maintains separate caches for each ID class to collect high-entropy samples and calibrate the raw predictions of input samples. DCAC leverages cached visual features and predicted probabilities through a lightweight two-layer module to mitigate overconfident predictions on OOD samples. This module can be seamlessly integrated with various existing OOD detection methods across both unimodal and vision-language models while introducing minimal computational overhead. Extensive experiments on multiple OOD benchmarks demonstrate that DCAC significantly enhances existing methods, achieving substantial improvements, i.e., reducing FPR95 by 6.55% when integrated with ASH-S on ImageNet OOD benchmark.

</details>


### [106] [NeuralFur: Animal Fur Reconstruction From Multi-View Images](https://arxiv.org/abs/2601.12481)
*Vanessa Sklyarova,Berna Kabadayi,Anastasios Yiannakidis,Giorgio Becherini,Michael J. Black,Justus Thies*

Main category: cs.CV

TL;DR: 提出首个基于多视角图像重建动物3D毛发的系统，利用视觉语言模型指导毛发长度和生长方向，实现不同动物毛发的高保真重建。


<details>
  <summary>Details</summary>
Motivation: 从图像重建真实动物毛发几何极具挑战，因为毛发细节精细、存在自遮挡和视角依赖外观。与人类发型重建不同，缺乏可用于学习不同动物毛发先验的数据集。

Method: 1) 使用传统多视角立体技术重建粗糙表面几何；2) 利用视觉语言模型检索身体各部位毛发长度结构信息；3) 构建无毛几何并在其上生长毛发束；4) 使用几何和光度损失监督重建；5) 利用VLM指导毛发生长方向并加入重力向量损失。

Result: 展示了该方法在不同动物和毛发类型上的泛化能力，能够重建高保真的3D毛发几何。

Conclusion: 提出了首个使用视觉语言模型指导多视角3D重建的系统，成功解决了动物毛发重建的挑战，实现了对不同动物毛发的高质量建模。

Abstract: Reconstructing realistic animal fur geometry from images is a challenging task due to the fine-scale details, self-occlusion, and view-dependent appearance of fur. In contrast to human hairstyle reconstruction, there are also no datasets that can be leveraged to learn a fur prior for different animals. In this work, we present a first multi-view-based method for high-fidelity 3D fur modeling of animals using a strand-based representation, leveraging the general knowledge of a vision language model. Given multi-view RGB images, we first reconstruct a coarse surface geometry using traditional multi-view stereo techniques. We then use a vision language model (VLM) system to retrieve information about the realistic length structure of the fur for each part of the body. We use this knowledge to construct the animal's furless geometry and grow strands atop it. The fur reconstruction is supervised with both geometric and photometric losses computed from multi-view images. To mitigate orientation ambiguities stemming from the Gabor filters that are applied to the input images, we additionally utilize the VLM to guide the strands' growth direction and their relation to the gravity vector that we incorporate as a loss. With this new schema of using a VLM to guide 3D reconstruction from multi-view inputs, we show generalization across a variety of animals with different fur types. For additional results and code, please refer to https://neuralfur.is.tue.mpg.de.

</details>


### [107] [Histopath-C: Towards Realistic Domain Shifts for Histopathology Vision-Language Adaptation](https://arxiv.org/abs/2601.12493)
*Mehrdad Noori,Gustavo Adolfo Vargas Hakim,David Osowiechi,Fereshteh Shakeri,Ali Bahri,Moslem Yazdanpanah,Sahar Dastani,Ismail Ben Ayed,Christian Desrosiers*

Main category: cs.CV

TL;DR: 提出Histopath-C基准测试和LATTE方法，用于增强医学视觉语言模型在组织病理学图像中的鲁棒性，应对真实世界分布偏移。


<details>
  <summary>Details</summary>
Motivation: 组织病理学图像存在染色、污染、模糊、噪声等严重域偏移问题，会显著降低视觉语言模型的下游性能，需要专门的方法来增强模型鲁棒性。

Method: 1) 提出Histopath-C基准测试，包含模拟真实世界分布偏移的合成损坏；2) 提出LATTE方法，一种利用多文本模板的转导低秩适应策略，减少模型对文本输入的敏感性。

Result: LATTE方法在多个组织病理学数据集上超越了为自然图像设计的最先进测试时适应方法，证明了该方法在组织病理学图像中鲁棒适应的有效性。

Conclusion: 提出的Histopath-C基准和LATTE方法能够有效增强医学视觉语言模型在组织病理学图像中的鲁棒性，应对真实世界的域偏移问题，代码和数据已开源。

Abstract: Medical Vision-language models (VLMs) have shown remarkable performances in various medical imaging domains such as histo\-pathology by leveraging pre-trained, contrastive models that exploit visual and textual information. However, histopathology images may exhibit severe domain shifts, such as staining, contamination, blurring, and noise, which may severely degrade the VLM's downstream performance. In this work, we introduce Histopath-C, a new benchmark with realistic synthetic corruptions designed to mimic real-world distribution shifts observed in digital histopathology. Our framework dynamically applies corruptions to any available dataset and evaluates Test-Time Adaptation (TTA) mechanisms on the fly. We then propose LATTE, a transductive, low-rank adaptation strategy that exploits multiple text templates, mitigating the sensitivity of histopathology VLMs to diverse text inputs. Our approach outperforms state-of-the-art TTA methods originally designed for natural images across a breadth of histopathology datasets, demonstrating the effectiveness of our proposed design for robust adaptation in histopathology images. Code and data are available at https://github.com/Mehrdad-Noori/Histopath-C.

</details>


### [108] [Video Individual Counting and Tracking from Moving Drones: A Benchmark and Methods](https://arxiv.org/abs/2601.12500)
*Yaowu Fan,Jia Wan,Tao Han,Andy J. Ma,Antoni B. Chan*

Main category: cs.CV

TL;DR: 提出基于移动无人机的大规模密集人群计数与跟踪方法，包括新数据集MovingDroneCrowd++和GD3A/DVTrack算法，显著提升性能


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖固定摄像头数据集，空间覆盖有限，无法满足大规模密集人群分析需求。移动无人机能提供更灵活的视角和更广的覆盖范围

Method: 1) 提出MovingDroneCrowd++数据集，包含移动无人机在不同高度、角度和光照条件下拍摄的密集人群视频；2) 提出GD3A方法，通过最优传输和自适应dustbin分数建立像素级行人描述符对应关系，将全局密度图分解为共享、流入和流出分量；3) 提出DVTrack方法，通过描述符投票机制将描述符级匹配转换为实例级关联

Result: 在密集人群和复杂运动条件下，方法显著优于现有方法：计数误差降低47.4%，跟踪性能提升39.2%

Conclusion: 移动无人机为大规模密集人群分析提供了更灵活的解决方案，提出的GD3A和DVTrack方法在复杂条件下表现出色，为无人机视频分析开辟了新方向

Abstract: Counting and tracking dense crowds in large-scale scenes is highly challenging, yet existing methods mainly rely on datasets captured by fixed cameras, which provide limited spatial coverage and are inadequate for large-scale dense crowd analysis. To address this limitation, we propose a flexible solution using moving drones to capture videos and perform video-level crowd counting and tracking of unique pedestrians across entire scenes. We introduce MovingDroneCrowd++, the largest video-level dataset for dense crowd counting and tracking captured by moving drones, covering diverse and complex conditions with varying flight altitudes, camera angles, and illumination. Existing methods fail to achieve satisfactory performance on this dataset. To this end, we propose GD3A (Global Density Map Decomposition via Descriptor Association), a density map-based video individual counting method that avoids explicit localization. GD3A establishes pixel-level correspondences between pedestrian descriptors across consecutive frames via optimal transport with an adaptive dustbin score, enabling the decomposition of global density maps into shared, inflow, and outflow components. Building on this framework, we further introduce DVTrack, which converts descriptor-level matching into instance-level associations through a descriptor voting mechanism for pedestrian tracking. Experimental results show that our methods significantly outperform existing approaches under dense crowds and complex motion, reducing counting error by 47.4 percent and improving tracking performance by 39.2 percent.

</details>


### [109] [SDCoNet: Saliency-Driven Multi-Task Collaborative Network for Remote Sensing Object Detection](https://arxiv.org/abs/2601.12507)
*Ruo Qi,Linhui Dai,Yusong Qin,Chaolei Yang,Yanshan Li*

Main category: cs.CV

TL;DR: 提出SDCoNet网络，通过显著性驱动的多任务协作，将超分辨率与检测任务耦合，解决遥感图像小目标检测难题


<details>
  <summary>Details</summary>
Motivation: 遥感图像背景复杂、目标信号弱、尺度小，传统串行超分辨率+检测方法存在优化目标不一致、特征冗余、任务间缺乏有效交互等问题

Method: 1) 使用Swin Transformer共享编码器实现跨任务特征协作；2) 多尺度显著性预测模块选择关键token，关注弱目标区域；3) 梯度路由策略缓解优化冲突，引导超分辨率生成对检测有益的高频细节

Result: 在NWPU VHR-10-Split、DOTAv1.5-Split、HRSSD-Split等公开数据集上，显著优于现有主流算法，同时保持计算效率竞争力

Conclusion: SDCoNet通过任务耦合、显著性引导和梯度路由，有效解决了低质量遥感图像小目标检测问题，为多任务学习提供了新思路

Abstract: In remote sensing images, complex backgrounds, weak object signals, and small object scales make accurate detection particularly challenging, especially under low-quality imaging conditions. A common strategy is to integrate single-image super-resolution (SR) before detection; however, such serial pipelines often suffer from misaligned optimization objectives, feature redundancy, and a lack of effective interaction between SR and detection. To address these issues, we propose a Saliency-Driven multi-task Collaborative Network (SDCoNet) that couples SR and detection through implicit feature sharing while preserving task specificity. SDCoNet employs the swin transformer-based shared encoder, where hierarchical window-shifted self-attention supports cross-task feature collaboration and adaptively balances the trade-off between texture refinement and semantic representation. In addition, a multi-scale saliency prediction module produces importance scores to select key tokens, enabling focused attention on weak object regions, suppression of background clutter, and suppression of adverse features introduced by multi-task coupling. Furthermore, a gradient routing strategy is introduced to mitigate optimization conflicts. It first stabilizes detection semantics and subsequently routes SR gradients along a detection-oriented direction, enabling the framework to guide the SR branch to generate high-frequency details that are explicitly beneficial for detection. Experiments on public datasets, including NWPU VHR-10-Split, DOTAv1.5-Split, and HRSSD-Split, demonstrate that the proposed method, while maintaining competitive computational efficiency, significantly outperforms existing mainstream algorithms in small object detection on low-quality remote sensing images. Our code is available at https://github.com/qiruo-ya/SDCoNet.

</details>


### [110] [Fine-Tuning Cycle-GAN for Domain Adaptation of MRI Images](https://arxiv.org/abs/2601.12512)
*Mohd Usama,Belal Ahmad,Faleh Menawer R Althiyabi*

Main category: cs.CV

TL;DR: 提出基于CycleGAN的无监督医学图像域适应方法，解决MRI扫描因不同扫描仪/机构导致的域偏移问题，无需配对训练数据即可实现源域和目标域间的双向映射。


<details>
  <summary>Details</summary>
Motivation: 不同扫描仪或机构获取的MRI扫描存在域偏移（硬件、协议、采集参数差异），导致在源域数据上训练的深度学习模型在目标域图像上性能下降，需要解决这一跨域适应问题。

Method: 基于CycleGAN的无监督域适应模型，学习源域和目标域间的双向映射，无需配对训练数据。结合内容和差异损失函数，在适应过程中保持图像解剖内容的完整性。

Result: 在多个MRI数据集上的实验表明，该方法能有效实现无标签数据的双向域适应，提高模型性能并减少域相关变异性，为更精确、一致的医学图像分析做出贡献。

Conclusion: 提出的CycleGAN基模型为无监督医学图像域适应提供了有效解决方案，能够改善医疗诊断准确性，为医疗保健领域提供了有前景的研究方向。

Abstract: Magnetic Resonance Imaging (MRI) scans acquired from different scanners or institutions often suffer from domain shifts owing to variations in hardware, protocols, and acquisition parameters. This discrepancy degrades the performance of deep learning models trained on source domain data when applied to target domain images. In this study, we propose a Cycle-GAN-based model for unsupervised medical-image domain adaptation. Leveraging CycleGANs, our model learns bidirectional mappings between the source and target domains without paired training data, preserving the anatomical content of the images. By leveraging Cycle-GAN capabilities with content and disparity loss for adaptation tasks, we ensured image-domain adaptation while maintaining image integrity. Several experiments on MRI datasets demonstrated the efficacy of our model in bidirectional domain adaptation without labelled data. Furthermore, research offers promising avenues for improving the diagnostic accuracy of healthcare. The statistical results confirm that our approach improves model performance and reduces domain-related variability, thus contributing to more precise and consistent medical image analysis.

</details>


### [111] [Deep Feature Deformation Weights](https://arxiv.org/abs/2601.12527)
*Richard Liu,Itai Lang,Rana Hanocka*

Main category: cs.CV

TL;DR: 提出融合传统优化方法和数据驱动方法的网格变形技术，通过深度特征邻近性实现语义化权重计算，支持实时变形和高分辨率网格处理。


<details>
  <summary>Details</summary>
Motivation: 传统基于手柄的网格变形方法需要用户预先知道理想的手柄分布，且手柄设置与变形行为之间的映射不直观、非语义化。而现代数据驱动方法虽然能获得语义化编辑，但速度慢且不精确。需要结合两者的优势。

Method: 使用深度特征邻近性计算平滑的语义化变形权重，无需额外正则化。提出重心特征蒸馏管道，利用形状渲染的视觉信号最小化蒸馏成本。通过特征空间约束和局部性加权保留传统方法的特性，并支持语义对称性检测和保持。

Result: 方法能在1分钟内为高分辨率网格计算权重（传统和神经方法可能需要数小时），在消费级机器上实时处理百万面网格变形。权重可实时计算，支持语义部件的协同变形。

Conclusion: 该方法成功融合了数据驱动的语义先验与传统方法的精确控制和速度优势，通过深度特征邻近性实现了简单而有效的语义化网格变形，扩展了传统方法的特性并支持实时处理。

Abstract: Handle-based mesh deformation has been a long-standing paradigm in computer graphics, enabling intuitive shape edits from sparse controls. Classic techniques offer precise and rapid deformation control. However, they solve an optimization problem with constraints defined by control handle placement, requiring a user to know apriori the ideal distribution of handles on the shape to accomplish the desired edit. The mapping from handle set to deformation behavior is often unintuitive and, importantly, non-semantic. Modern data-driven methods, on the other hand, leverage a data prior to obtain semantic edits, but are slow and imprecise. We propose a technique that fuses the semantic prior of data with the precise control and speed of traditional frameworks. Our approach is surprisingly simple yet effective: deep feature proximity makes for smooth and semantic deformation weights, with no need for additional regularization. The weights can be computed in real-time for any surface point, whereas prior methods require optimization for new handles. Moreover, the semantic prior from deep features enables co-deformation of semantic parts. We introduce an improved feature distillation pipeline, barycentric feature distillation, which efficiently uses the visual signal from shape renders to minimize distillation cost. This allows our weights to be computed for high resolution meshes in under a minute, in contrast to potentially hours for both classical and neural methods. We preserve and extend properties of classical methods through feature space constraints and locality weighting. Our field representation allows for automatic detection of semantic symmetries, which we use to produce symmetry-preserving deformations. We show a proof-of-concept application which can produce deformations for meshes up to 1 million faces in real-time on a consumer-grade machine.

</details>


### [112] [XRefine: Attention-Guided Keypoint Match Refinement](https://arxiv.org/abs/2601.12530)
*Jan Fabian Schmid,Annika Hagemann*

Main category: cs.CV

TL;DR: XRefine是一种与检测器无关的亚像素关键点细化方法，通过跨注意力架构仅处理匹配关键点周围的图像块，无需依赖检测器内部表示，可泛化到不同检测器并扩展到多视角特征跟踪。


<details>
  <summary>Details</summary>
Motivation: 当前关键点检测器产生的匹配在空间上不准确，现有细化方法通常需要针对特定检测器重新训练，缺乏通用性。

Method: 提出XRefine方法，基于跨注意力架构，仅使用匹配关键点周围的图像块来预测细化后的关键点坐标，不依赖检测器内部表示，支持扩展到多视角特征跟踪。

Result: 在MegaDepth、KITTI和ScanNet数据集上的实验表明，该方法能持续提高几何估计精度，性能优于现有细化方法，同时保持运行效率。

Conclusion: XRefine提供了一种通用、高效的亚像素关键点细化解决方案，可泛化到不同检测器，显著提升3D视觉任务的几何估计准确性。

Abstract: Sparse keypoint matching is crucial for 3D vision tasks, yet current keypoint detectors often produce spatially inaccurate matches. Existing refinement methods mitigate this issue through alignment of matched keypoint locations, but they are typically detector-specific, requiring retraining for each keypoint detector. We introduce XRefine, a novel, detector-agnostic approach for sub-pixel keypoint refinement that operates solely on image patches centered at matched keypoints. Our cross-attention-based architecture learns to predict refined keypoint coordinates without relying on internal detector representations, enabling generalization across detectors. Furthermore, XRefine can be extended to handle multi-view feature tracks. Experiments on MegaDepth, KITTI, and ScanNet demonstrate that the approach consistently improves geometric estimation accuracy, achieving superior performance compared to existing refinement methods while maintaining runtime efficiency. Our code and trained models can be found at https://github.com/boschresearch/xrefine.

</details>


### [113] [BirdsEye-RU: A Dataset For Detecting Faces from Overhead Images](https://arxiv.org/abs/2601.12533)
*Md. Ahanaf Arif Khan,Ariful Islam,Sangeeta Biswas,Md. Iqbal Aziz Khan,Subrata Pramanik,Sanjoy Kumar Chakrabarty,Bimal Kumar Pramanik*

Main category: cs.CV

TL;DR: 作者创建了BirdsEye-RU数据集，包含2,978张图像和8,000多个标注人脸，专门用于检测高空图像中的小尺寸和远距离人脸，数据集包含无人机和智能手机拍摄的高空图像。


<details>
  <summary>Details</summary>
Motivation: 高空图像中的人脸检测面临极端尺度变化和环境杂波的重大挑战，现有数据集难以有效应对这些困难。

Method: 创建了BirdsEye-RU数据集，包含2,978张图像，涵盖8,000多个标注人脸，专门设计用于捕捉不同环境中的小尺寸和远距离人脸，包含无人机和智能手机从高空拍摄的图像。

Result: 成功构建了一个全面的高空人脸检测数据集，该数据集已公开免费提供，可通过Kaggle平台访问。

Conclusion: BirdsEye-RU数据集为解决高空图像中人脸检测的挑战提供了有价值的资源，有助于推动该领域的研究进展。

Abstract: Detecting faces in overhead images remains a significant challenge due to extreme scale variations and environmental clutter. To address this, we created the BirdsEye-RU dataset, a comprehensive collection of 2,978 images containing over eight thousand annotated faces. This dataset is specifically designed to capture small and distant faces across diverse environments, containing both drone images and smartphone-captured images from high altitude. We present a detailed description of the BirdsEye-RU dataset in this paper. We made our dataset freely available to the public, and it can be accessed at https://www.kaggle.com/datasets/mdahanafarifkhan/birdseye-ru.

</details>


### [114] [Encoding Emotion Through Self-Supervised Eye Movement Reconstruction](https://arxiv.org/abs/2601.12534)
*Marcus Ma,Jordan Prescott,Emily Zhou,Tiantian Feng,Kleanthis Avramidis,Gabor Mihaly Toth,Shrikanth Narayanan*

Main category: cs.CV

TL;DR: 论文提出一种自监督视线检测模型，通过眼动重建从低分辨率视频预测情感表达，在Holocaust幸存者访谈数据上验证了模型对情感行为的预测能力。


<details>
  <summary>Details</summary>
Motivation: 现有眼动-情感关系研究多依赖高精度眼动仪，限制了应用范围。本文旨在探索如何从自然、低分辨率视频中利用眼动预测多模态情感表达标记。

Method: 受语言模型预训练启发，开发自监督眼动重建模型，利用未标记视频数据。使用该模型的编码器嵌入微调两个下游任务：1) 眼动与语音情感方向估计对齐；2) 眼动预测三种瞬时情感行为（笑、哭/抽泣、叹气）。

Result: 新模型能有效预测情感结果，观察到预训练性能与情感处理性能呈正相关，验证了自监督眼动重建对编码情感信号的有效性。

Conclusion: 自监督眼动重建是编码眼动所携带情感信号的有效方法，为从低分辨率视频中提取情感信息提供了新途径。

Abstract: The relationship between emotional expression and eye movement is well-documented, with literature establishing gaze patterns are reliable indicators of emotion. However, most studies utilize specialized, high-resolution eye-tracking equipment, limiting the potential reach of findings. We investigate how eye movement can be used to predict multimodal markers of emotional expression from naturalistic, low-resolution videos. We utilize a collection of video interviews from the USC Shoah Foundation's Visual History Archive with Holocaust survivors as they recount their experiences in the Auschwitz concentration camp. Inspired by pretraining methods on language models, we develop a novel gaze detection model that uses self-supervised eye movement reconstruction that can effectively leverage unlabeled video. We use this model's encoder embeddings to fine-tune models on two downstream tasks related to emotional expression. The first is aligning eye movement with directional emotion estimates from speech. The second task is using eye gaze as a predictor of three momentary manifestations of emotional behaviors: laughing, crying/sobbing, and sighing. We find our new model is predictive of emotion outcomes and observe a positive correlation between pretraining performance and emotion processing performance for both experiments. We conclude self-supervised eye movement reconstruction is an effective method for encoding the affective signal they carry.

</details>


### [115] [PISE: Physics-Anchored Semantically-Enhanced Deep Computational Ghost Imaging for Robust Low-Bandwidth Machine Perception](https://arxiv.org/abs/2601.12551)
*Tong Wu*

Main category: cs.CV

TL;DR: PISE是一个物理信息深度鬼成像框架，用于低带宽边缘感知，通过结合伴随算子初始化和语义指导，在5%采样率下将分类准确率提升2.57%，方差降低9倍


<details>
  <summary>Details</summary>
Motivation: 解决低带宽边缘感知中的挑战，传统鬼成像方法在有限采样率下性能受限，需要提高分类准确率并降低方差

Method: 提出物理信息深度鬼成像框架PISE，结合伴随算子初始化和语义指导，通过物理约束优化深度学习模型

Result: 在5%采样率下，分类准确率提升2.57%，方差降低9倍，显著改善低带宽边缘感知性能

Conclusion: PISE框架有效解决了低带宽边缘感知问题，通过物理信息与深度学习的结合，在有限采样条件下实现了更稳定和准确的分类性能

Abstract: We propose PISE, a physics-informed deep ghost imaging framework for low-bandwidth edge perception. By combining adjoint operator initialization with semantic guidance, PISE improves classification accuracy by 2.57% and reduces variance by 9x at 5% sampling.

</details>


### [116] [Camera Pose Revisited](https://arxiv.org/abs/2601.12567)
*Władysław Skarbek,Michał Salomonowicz,Michał Król*

Main category: cs.CV

TL;DR: 提出PnP-ProCay78算法，通过Cayley参数化旋转和最小二乘优化解决平面PnP问题，避免昂贵的解空间搜索，在RGB和热成像相机上验证性能接近最优方法但算法更简单。


<details>
  <summary>Details</summary>
Motivation: 解决相机标定和多传感器系统中的核心问题——相机位姿估计，特别关注标定物体初始位姿估计的平面PnP问题，旨在开发既准确又算法简单的解决方案。

Method: 结合经典重建误差的二次形式与Cayley旋转参数化和最小二乘优化，关键创新是基于两个规范向量重建误差分析的确定性起始点选择，避免解空间搜索，使用混合成本公式（投影误差最小化与解析消除平移重建误差替代）。

Result: 在RGB和低分辨率热成像相机集成系统中验证，投影精度与最优SQPnP几乎相同，略高于IPPE，但算法结构显著更简单；Cayley空间优化轨迹分析提供了收敛过程的直观理解。

Conclusion: PnP-ProCay78算法在保持高精度的同时具有更简单的算法结构，几何透明且计算高效，收敛过程直观易懂，具有教学价值，是平面PnP问题的有效解决方案。

Abstract: Estimating the position and orientation of a camera with respect to an observed scene is one of the central problems in computer vision, particularly in the context of camera calibration and multi-sensor systems. This paper addresses the planar Perspective--$n$--Point problem, with special emphasis on the initial estimation of the pose of a calibration object. As a solution, we propose the \texttt{PnP-ProCay78} algorithm, which combines the classical quadratic formulation of the reconstruction error with a Cayley parameterization of rotations and least-squares optimization. The key component of the method is a deterministic selection of starting points based on an analysis of the reconstruction error for two canonical vectors, allowing costly solution-space search procedures to be avoided. Experimental validation is performed using data acquired also from high-resolution RGB cameras and very low-resolution thermal cameras in an integrated RGB--IR setup. The results demonstrate that the proposed algorithm achieves practically the same projection accuracy as optimal \texttt{SQPnP} and slightly higher than \texttt{IPPE}, both prominent \texttt{PnP-OpenCV} procedures. However, \texttt{PnP-ProCay78} maintains a significantly simpler algorithmic structure. Moreover, the analysis of optimization trajectories in Cayley space provides an intuitive insight into the convergence process, making the method attractive also from a didactic perspective. Unlike existing PnP solvers, the proposed \texttt{PnP-ProCay78} algorithm combines projection error minimization with an analytically eliminated reconstruction-error surrogate for translation, yielding a hybrid cost formulation that is both geometrically transparent and computationally efficient.

</details>


### [117] [Linear Mechanisms for Spatiotemporal Reasoning in Vision Language Models](https://arxiv.org/abs/2601.12626)
*Raphi Kang,Hongqiao Chen,Georgia Gkioxari,Pietro Perona*

Main category: cs.CV

TL;DR: 论文发现视觉语言模型通过线性绑定空间ID到文本激活来编码物体位置，并通过语言token进行推理，揭示了VLM内部时空推理的线性机制。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型具有显著的时空推理能力，但其底层机制仍然不透明。作者假设视觉/几何和文本的空间结构表示必须在VLM计算的某个点结合，并探索这种结合点及其对模型行为的因果解释。

Method: 通过经验研究显示VLM通过线性绑定空间ID到文本激活来编码物体位置，然后通过语言token进行推理。通过严格的因果干预证明这些ID在模型各层普遍存在，并能系统性地调节模型信念。将分析扩展到视频VLM，识别类似的线性时间ID机制。

Result: 发现VLM中存在普遍的空间ID机制，这些ID可以作为诊断工具识别现有VLM的局限性，并作为有价值的学习信号。在视频VLM中也发现了类似的时间ID机制。

Conclusion: 通过表征提出的时空ID机制，阐明了VLM中先前未被充分探索的内部推理过程，为改进可解释性和设计更对齐、更强大的模型提供了理论基础。

Abstract: Spatio-temporal reasoning is a remarkable capability of Vision Language Models (VLMs), but the underlying mechanisms of such abilities remain largely opaque. We postulate that visual/geometrical and textual representations of spatial structure must be combined at some point in VLM computations. We search for such confluence, and ask whether the identified representation can causally explain aspects of input-output model behavior through a linear model. We show empirically that VLMs encode object locations by linearly binding \textit{spatial IDs} to textual activations, then perform reasoning via language tokens. Through rigorous causal interventions we demonstrate that these IDs, which are ubiquitous across the model, can systematically mediate model beliefs at intermediate VLM layers. Additionally, we find that spatial IDs serve as a diagnostic tool for identifying limitations in existing VLMs, and as a valuable learning signal. We extend our analysis to video VLMs and identify an analogous linear temporal ID mechanism. By characterizing our proposed spatiotemporal ID mechanism, we elucidate a previously underexplored internal reasoning process in VLMs, toward improved interpretability and the principled design of more aligned and capable models. We release our code for reproducibility: https://github.com/Raphoo/linear-mech-vlms.

</details>


### [118] [From Bands to Depth: Understanding Bathymetry Decisions on Sentinel-2](https://arxiv.org/abs/2601.12636)
*Satyaki Roy Chowdhury,Aswathnarayan Radhakrishnan,Hsiao Jou Hsu,Hari Subramoni,Joachim Moortgat*

Main category: cs.CV

TL;DR: 本文分析了基于Swin-Transformer的U-Net模型(Swin-BathyUNet)在Sentinel-2卫星测深中的应用，研究了其深度推断机制和预测可靠性，提出了跨区域部署的实用指导。


<details>
  <summary>Details</summary>
Motivation: Sentinel-2卫星测深在不同地点的稳健部署仍然具有挑战性，需要理解模型如何推断深度以及何时预测可信。

Method: 使用Swin-BathyUNet模型，进行波段重要性分析，开发回归版A-CAM-R注意力机制，进行注意力消融实验和跨区域推理测试。

Result: 绿/蓝波段对测深最重要；A-CAM-R能有效定位模型依赖的证据；解码器跨注意力提升抗眩光/泡沫能力；跨区域测试显示误差随深度线性增长。

Conclusion: 提出实用指导：保持大感受野，保护绿/蓝波段辐射精度，预过滤近岸高亮度区域，结合深度感知校准进行跨区域迁移学习。

Abstract: Deploying Sentinel-2 satellite derived bathymetry (SDB) robustly across sites remains challenging. We analyze a Swin-Transformer based U-Net model (Swin-BathyUNet) to understand how it infers depth and when its predictions are trustworthy. A leave-one-band out study ranks spectral importance to the different bands consistent with shallow water optics. We adapt ablation-based CAM to regression (A-CAM-R) and validate the reliability via a performance retention test: keeping only the top-p% salient pixels while neutralizing the rest causes large, monotonic RMSE increase, indicating explanations localize on evidence the model relies on. Attention ablations show decoder conditioned cross attention on skips is an effective upgrade, improving robustness to glint/foam. Cross-region inference (train on one site, test on another) reveals depth-dependent degradation: MAE rises nearly linearly with depth, and bimodal depth distributions exacerbate mid/deep errors. Practical guidance follows: maintain wide receptive fields, preserve radiometric fidelity in green/blue channels, pre-filter bright high variance near shore, and pair light target site fine tuning with depth aware calibration to transfer across regions.

</details>


### [119] [Mixed Precision PointPillars for Efficient 3D Object Detection with TensorRT](https://arxiv.org/abs/2601.12638)
*Ninnart Fuengfusin,Keisuke Yoneda,Naoki Suganuma*

Main category: cs.CV

TL;DR: 提出用于PointPillars的混合精度量化框架，通过敏感层搜索和贪婪组合优化，在保持性能的同时实现2.35倍加速和2.26倍模型压缩


<details>
  <summary>Details</summary>
Motivation: 激光雷达3D目标检测需要实时运行，但直接量化会导致性能下降，因为激光雷达数据具有宽数值分布和极端异常值

Method: 1) 使用PTQ单层量化搜索敏感层，将top-k敏感层设为浮点；2) 贪婪搜索层组合生成混合精度候选模型；3) 使用少量校准数据减少异常值影响；4) 提供PTQ和QAT两种流水线

Result: 混合精度模型在TensorRT部署下，延迟降低2.35倍，模型大小减少2.26倍，QAT流水线性能可与浮点模型竞争

Conclusion: 提出的混合精度量化框架有效解决了激光雷达数据量化挑战，在保持检测精度的同时显著提升了推理速度并减少了模型大小

Abstract: LIDAR 3D object detection is one of the important tasks for autonomous vehicles. Ensuring that this task operates in real-time is crucial. Toward this, model quantization can be used to accelerate the runtime. However, directly applying model quantization often leads to performance degradation due to LIDAR's wide numerical distributions and extreme outliers. To address the wide numerical distribution, we proposed a mixed precision framework designed for PointPillars. Our framework first searches for sensitive layers with post-training quantization (PTQ) by quantizing one layer at a time to 8-bit integer (INT8) and evaluating each model for average precision (AP). The top-k most sensitive layers are assigned as floating point (FP). Combinations of these layers are greedily searched to produce candidate mixed precision models, which are finalized with either PTQ or quantization-aware training (QAT). Furthermore, to handle outliers, we observe that using a very small number of calibration data reduces the likelihood of encountering outliers, thereby improving PTQ performance. Our methods provides mixed precision models without training in the PTQ pipeline, while our QAT pipeline achieves the performance competitive to FP models. With TensorRT deployment, our models offer less latency and sizes by up to 2.35 and 2.26 times, respectively.

</details>


### [120] [Generalizable Hyperparameter Optimization for Federated Learning on Non-IID Cancer Images](https://arxiv.org/abs/2601.12664)
*Elisa Gonçalves Ribeiro,Rodrigo Moreira,Larissa Ferreira Rodrigues Moreira,André Ricardo Backes*

Main category: cs.CV

TL;DR: 研究探索了在非独立同分布联邦学习场景中，针对癌症病理图像分类任务的超参数优化策略，提出了一种简单的跨数据集聚合启发式方法。


<details>
  <summary>Details</summary>
Motivation: 深度学习在癌症病理学训练中面临隐私约束问题，联邦学习虽然能保持数据本地化，但其性能在非独立同分布客户端数据集下高度依赖超参数选择。需要研究超参数优化策略在不同癌症数据集间的泛化能力。

Method: 采用集中式贝叶斯超参数优化，将数据集特定的最优超参数迁移到非独立同分布联邦学习设置中。提出跨数据集聚合启发式方法：通过平均学习率、考虑模态优化器和批量大小的组合配置。

Result: 提出的组合配置在卵巢癌和结直肠癌的二元病理分类任务中取得了有竞争力的分类性能。

Conclusion: 简单的跨数据集超参数聚合启发式方法能够在非独立同分布联邦学习场景中实现有效的癌症病理图像分类，为临床隐私约束下的深度学习应用提供了实用解决方案。

Abstract: Deep learning for cancer histopathology training conflicts with privacy constraints in clinical settings. Federated Learning (FL) mitigates this by keeping data local; however, its performance depends on hyperparameter choices under non-independent and identically distributed (non-IID) client datasets. This paper examined whether hyperparameters optimized on one cancer imaging dataset generalized across non-IID federated scenarios. We considered binary histopathology tasks for ovarian and colorectal cancers. We perform centralized Bayesian hyperparameter optimization and transfer dataset-specific optima to the non-IID FL setup. The main contribution of this study is the introduction of a simple cross-dataset aggregation heuristic by combining configurations by averaging the learning rates and considering the modal optimizers and batch sizes. This combined configuration achieves a competitive classification performance.

</details>


### [121] [Near-Light Color Photometric Stereo for mono-Chromaticity non-lambertian surface](https://arxiv.org/abs/2601.12666)
*Zonglin Li,Jieji Ren,Shuangfan Zhou,Heng Guo,Jinnuo Zhang,Jiang Zhou,Boxin Shi,Zhanyu Ma,Guoying Gu*

Main category: cs.CV

TL;DR: 提出基于神经隐式表示的单图像彩色光度立体框架，在单色性假设下实现近光和非朗伯表面的单次重建，并设计光学触觉传感器进行验证。


<details>
  <summary>Details</summary>
Motivation: 现有彩色光度立体方法大多假设理想远距离照明和朗伯反射，对更实际的近光条件和非朗伯表面研究不足，需要解决这些限制以实现更实用的单次表面重建。

Method: 提出神经隐式表示框架，在单色性假设（均匀色度和同质材料）下对深度和BRDF进行建模，缓解彩色光度立体的不适定性，实现单图像详细表面恢复，并设计紧凑光学触觉传感器进行验证。

Result: 在合成和真实数据集上的实验表明，该方法实现了准确且鲁棒的表面重建，验证了在近光条件和非朗伯表面下的有效性。

Conclusion: 该框架成功扩展了彩色光度立体的应用范围，通过神经隐式表示和单色性假设解决了实际近光和非朗伯条件下的单次表面重建问题，为动态场景的表面恢复提供了实用解决方案。

Abstract: Color photometric stereo enables single-shot surface reconstruction, extending conventional photometric stereo that requires multiple images of a static scene under varying illumination to dynamic scenarios. However, most existing approaches assume ideal distant lighting and Lambertian reflectance, leaving more practical near-light conditions and non-Lambertian surfaces underexplored. To overcome this limitation, we propose a framework that leverages neural implicit representations for depth and BRDF modeling under the assumption of mono-chromaticity (uniform chromaticity and homogeneous material), which alleviates the inherent ill-posedness of color photometric stereo and allows for detailed surface recovery from just one image. Furthermore, we design a compact optical tactile sensor to validate our approach. Experiments on both synthetic and real-world datasets demonstrate that our method achieves accurate and robust surface reconstruction.

</details>


### [122] [Exploiting Test-Time Augmentation in Federated Learning for Brain Tumor MRI Classification](https://arxiv.org/abs/2601.12671)
*Thamara Leandra de Deus Melo,Rodrigo Moreira,Larissa Ferreira Rodrigues Moreira,André Ricardo Backes*

Main category: cs.CV

TL;DR: 在联邦学习框架下，预处理单独使用效果有限，但结合测试时增强(TTA)能显著提升脑肿瘤MRI分类性能，建议将TTA作为默认推理策略。


<details>
  <summary>Details</summary>
Motivation: 脑肿瘤的早期诊断对治疗至关重要，但由于病变变异性和图像复杂性，高效诊断面临挑战。研究旨在探索联邦学习环境下卷积神经网络在MRI图像分类中的优化方法。

Method: 在联邦学习设置中评估卷积神经网络，比较原始MRI图像与预处理图像（包括调整大小、灰度转换、归一化、滤波和直方图均衡化）的训练效果，并测试预处理与测试时增强(TTA)的组合效果。

Result: 单独预处理带来的增益可忽略不计，但预处理与测试时增强(TTA)结合后，在联邦MRI分类中产生了持续且统计显著的改进(p<0.001)。

Conclusion: 在基于联邦学习的医学影像应用中，TTA应作为默认推理策略；当计算预算允许时，将TTA与轻度预处理结合可提供额外的可靠性能提升。

Abstract: Efficient brain tumor diagnosis is crucial for early treatment; however, it is challenging because of lesion variability and image complexity. We evaluated convolutional neural networks (CNNs) in a federated learning (FL) setting, comparing models trained on original versus preprocessed MRI images (resizing, grayscale conversion, normalization, filtering, and histogram equalization). Preprocessing alone yielded negligible gains; combined with test-time augmentation (TTA), it delivered consistent, statistically significant improvements in federated MRI classification (p<0.001). In practice, TTA should be the default inference strategy in FL-based medical imaging; when the computational budget permits, pairing TTA with light preprocessing provides additional reliable gains.

</details>


### [123] [VILTA: A VLM-in-the-Loop Adversary for Enhancing Driving Policy Robustness](https://arxiv.org/abs/2601.12672)
*Qimao Chen,Fang Li,Shaoqing Xu,Zhiyi Lai,Zixun Xie,Yuechen Luo,Shengyin Jiang,Hanbing Li,Long Chen,Bing Wang,Yi Zhang,Zhi-Xin Yang*

Main category: cs.CV

TL;DR: VILTA：一种将视觉语言模型集成到自动驾驶代理闭环训练中的新框架，通过直接编辑周围智能体的未来轨迹来生成多样化的挑战性场景，解决长尾安全问题。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统的安全部署受到长尾问题的根本性阻碍，即罕见但关键的驾驶场景在真实世界数据中严重不足。现有解决方案（包括安全关键场景生成和闭环学习）通常依赖于基于规则的启发式方法、重采样方法和从离线数据集学习的生成模型，限制了它们产生多样化和新颖挑战的能力。

Method: VILTA（VLM-In-the-Loop Trajectory Adversary）框架将视觉语言模型集成到自动驾驶代理的闭环训练中。与先前工作不同，VILTA通过理解动态驾驶环境并直接、细粒度地编辑周围智能体的未来轨迹来战略性地生成挑战性场景，充分利用VLM的强大泛化能力。

Result: 该方法显著增强了所得自动驾驶策略的安全性和鲁棒性，特别是在处理关键长尾事件的能力方面。

Conclusion: VILTA框架通过将视觉语言模型直接集成到训练循环中，克服了传统方法的局限性，能够生成超越传统方法范围的合理且具有挑战性的多样化场景课程，从而有效解决自动驾驶的长尾安全问题。

Abstract: The safe deployment of autonomous driving (AD) systems is fundamentally hindered by the long-tail problem, where rare yet critical driving scenarios are severely underrepresented in real-world data. Existing solutions including safety-critical scenario generation and closed-loop learning often rely on rule-based heuristics, resampling methods and generative models learned from offline datasets, limiting their ability to produce diverse and novel challenges. While recent works leverage Vision Language Models (VLMs) to produce scene descriptions that guide a separate, downstream model in generating hazardous trajectories for agents, such two-stage framework constrains the generative potential of VLMs, as the diversity of the final trajectories is ultimately limited by the generalization ceiling of the downstream algorithm. To overcome these limitations, we introduce VILTA (VLM-In-the-Loop Trajectory Adversary), a novel framework that integrates a VLM into the closed-loop training of AD agents. Unlike prior works, VILTA actively participates in the training loop by comprehending the dynamic driving environment and strategically generating challenging scenarios through direct, fine-grained editing of surrounding agents' future trajectories. This direct-editing approach fully leverages the VLM's powerful generalization capabilities to create a diverse curriculum of plausible yet challenging scenarios that extend beyond the scope of traditional methods. We demonstrate that our approach substantially enhances the safety and robustness of the resulting AD policy, particularly in its ability to navigate critical long-tail events.

</details>


### [124] [Fusion-Restoration Image Processing Algorithm to Improve the High-Temperature Deformation Measurement](https://arxiv.org/abs/2601.12682)
*Banglei Guan,Dongcai Tan,Jing Tao,Ang Su,Yang Shang,Qifeng Yu*

Main category: cs.CV

TL;DR: 提出融合-恢复图像处理方法，抑制高温结构变形测量中的热辐射和热雾干扰，提高DIC测量精度


<details>
  <summary>Details</summary>
Motivation: 高温结构变形测量中，热辐射引起的图像退化和热雾引入的随机误差限制了测量精度和有效性，需要抑制这些干扰

Method: 1) 基于图像分层表示，将图像分解为正负通道并行处理，通过多曝光图像融合优化质量；2) 采用FSIM作为目标函数指导模型参数迭代优化，结合灰度平均算法均衡异常灰度值

Result: 多曝光融合算法将欠曝光图像有效计算区域从26%提升至50%，过曝光图像从32%提升至40%；图像恢复结合灰度平均算法将ε_xx误差降低85.3%，ε_yy和γ_xy误差分别降低36.0%和36.4%

Conclusion: 提出的图像处理方法能有效抑制高温变形测量中的热辐射和热雾干扰，提高图像质量，降低变形测量误差，在热变形测量中具有潜在应用价值

Abstract: In the deformation measurement of high-temperature structures, image degradation caused by thermal radiation and random errors introduced by heat haze restrict the accuracy and effectiveness of deformation measurement. To suppress thermal radiation and heat haze using fusion-restoration image processing methods, thereby improving the accuracy and effectiveness of DIC in the measurement of high-temperature deformation. For image degradation caused by thermal radiation, based on the image layered representation, the image is decomposed into positive and negative channels for parallel processing, and then optimized for quality by multi-exposure image fusion. To counteract the high-frequency, random errors introduced by heat haze, we adopt the FSIM as the objective function to guide the iterative optimization of model parameters, and the grayscale average algorithm is applied to equalize anomalous gray values, thereby reducing measurement error. The proposed multi-exposure image fusion algorithm effectively suppresses image degradation caused by complex illumination conditions, boosting the effective computation area from 26% to 50% for under-exposed images and from 32% to 40% for over-exposed images without degrading measurement accuracy in the experiment. Meanwhile, the image restoration combined with the grayscale average algorithm reduces static thermal deformation measurement errors. The error in ε_xx is reduced by 85.3%, while the errors in ε_yy and γ_xy are reduced by 36.0% and 36.4%, respectively. We present image processing methods to suppress the interference of thermal radiation and heat haze in high-temperature deformation measurement using DIC. The experimental results verify that the proposed method can effectively improve image quality, reduce deformation measurement errors, and has potential application value in thermal deformation measurement.

</details>


### [125] [GaussianTrimmer: Online Trimming Boundaries for 3DGS Segmentation](https://arxiv.org/abs/2601.12683)
*Liwei Liao,Ronggang Wang*

Main category: cs.CV

TL;DR: 提出GaussianTrimmer，一种用于3D高斯分割方法的在线边界修整后处理技术，通过虚拟相机和2D分割结果来修整粗糙边界


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯分割方法基于高斯基元进行分割，但由于3D高斯尺度变化范围大，大尺寸高斯常跨越前景和背景，导致分割对象边界锯齿状

Method: 包含两个核心步骤：1. 生成均匀且覆盖良好的虚拟相机；2. 基于虚拟相机上的2D分割结果在基元级别修整高斯

Result: 广泛的定量和定性实验表明，该方法作为即插即用方法能够提高现有3D高斯分割方法的分割质量

Conclusion: GaussianTrimmer是一种高效、即插即用的后处理方法，能够为现有3D高斯分割方法修整粗糙边界

Abstract: With the widespread application of 3D Gaussians in 3D scene representation, 3D scene segmentation methods based on 3D Gaussians have also gradually emerged. However, existing 3D Gaussian segmentation methods basically segment on the basis of Gaussian primitives. Due to the large variation range of the scale of 3D Gaussians, large-sized Gaussians that often span the foreground and background lead to jagged boundaries of segmented objects. To this end, we propose an online boundary trimming method, GaussianTrimmer, which is an efficient and plug-and-play post-processing method capable of trimming coarse boundaries for existing 3D Gaussian segmentation methods. Our method consists of two core steps: 1. Generating uniformly and well-covered virtual cameras; 2. Trimming Gaussian at the primitive level based on 2D segmentation results on virtual cameras. Extensive quantitative and qualitative experiments demonstrate that our method can improve the segmentation quality of existing 3D Gaussian segmentation methods as a plug-and-play method.

</details>


### [126] [Fusing in 3D: Free-Viewpoint Fusion Rendering with a 3D Infrared-Visible Scene Representation](https://arxiv.org/abs/2601.12697)
*Chao Yang,Deshui Miao,Chao Tian,Guoqing Zhu,Yameng Gu,Zhenyu He*

Main category: cs.CV

TL;DR: 提出IVGF框架，通过3D高斯重建解决传统2D红外-可见光图像融合方法视角固定、信息丢失的问题，实现多视角融合图像渲染。


<details>
  <summary>Details</summary>
Motivation: 现有2D融合方法局限于固定相机视角，无法全面理解复杂场景，导致关键信息丢失。需要从多模态2D输入重建场景几何，实现更全面的融合。

Method: 提出红外-可见光高斯融合(IVGF)框架：1) 从多模态2D输入重建场景几何；2) 设计跨模态调整(CMA)模块，通过调制高斯不透明度解决跨模态冲突；3) 引入融合损失指导CMA优化，保留各模态关键特征。

Result: 综合定性和定量实验证明该方法有效，能够生成保留红外和可见光关键特征的融合图像。

Conclusion: IVGF框架通过3D场景重建和跨模态调整，解决了传统2D融合方法的局限性，实现了更全面的红外-可见光信息融合。

Abstract: Infrared-visible image fusion aims to integrate infrared and visible information into a single fused image. Existing 2D fusion methods focus on fusing images from fixed camera viewpoints, neglecting a comprehensive understanding of complex scenarios, which results in the loss of critical information about the scene. To address this limitation, we propose a novel Infrared-Visible Gaussian Fusion (IVGF) framework, which reconstructs scene geometry from multimodal 2D inputs and enables direct rendering of fused images. Specifically, we propose a cross-modal adjustment (CMA) module that modulates the opacity of Gaussians to solve the problem of cross-modal conflicts. Moreover, to preserve the distinctive features from both modalities, we introduce a fusion loss that guides the optimization of CMA, thus ensuring that the fused image retains the critical characteristics of each modality. Comprehensive qualitative and quantitative experiments demonstrate the effectiveness of the proposed method.

</details>


### [127] [P2L-CA: An Effective Parameter Tuning Framework for Rehearsal-Free Multi-Label Class-Incremental Learning](https://arxiv.org/abs/2601.12714)
*Songlin Dong,Jiangyang Li,Chenhao Ding,Zhiheng Ma,Haoyu Luo,Yuhang He,Yihong Gong*

Main category: cs.CV

TL;DR: P2L-CA：一种参数高效的多标签类增量学习框架，通过提示到标签模块和连续适配器模块，解决特征混淆和领域差异问题，无需内存缓冲区


<details>
  <summary>Details</summary>
Motivation: 现有多标签类增量学习方法存在计算成本高（全参数微调）、存储开销大（内存缓冲区）以及特征混淆和领域差异问题，需要更高效的解决方案

Method: 提出P2L-CA框架，包含两个核心模块：1) P2L模块使用类别特定提示解耦多标签表示，结合语言先验稳定语义-视觉对齐；2) CA模块使用轻量适配器缓解预训练模型与下游任务间的领域差异

Result: 在MS-COCO和PASCAL VOC的标准和挑战性MLCIL设置上，P2L-CA显著超越现有最优方法，在CIL场景中表现出强泛化能力，同时只需极少的可训练参数且无需内存缓冲区

Conclusion: P2L-CA通过参数高效的设计有效解决了多标签类增量学习中的计算成本、存储开销和特征混淆问题，为实际应用提供了可行的解决方案

Abstract: Multi-label Class-Incremental Learning aims to continuously recognize novel categories in complex scenes where multiple objects co-occur. However, existing approaches often incur high computational costs due to full-parameter fine-tuning and substantial storage overhead from memory buffers, or they struggle to address feature confusion and domain discrepancies adequately. To overcome these limitations, we introduce P2L-CA, a parameter-efficient framework that integrates a Prompt-to-Label module with a Continuous Adapter module. The P2L module leverages class-specific prompts to disentangle multi-label representations while incorporating linguistic priors to enforce stable semantic-visual alignment. Meanwhile, the CA module employs lightweight adapters to mitigate domain gaps between pre-trained models and downstream tasks, thereby enhancing model plasticity. Extensive experiments across standard and challenging MLCIL settings on MS-COCO and PASCAL VOC show that P2L-CA not only achieves substantial improvements over state-of-the-art methods but also demonstrates strong generalization in CIL scenarios, all while requiring minimal trainable parameters and eliminating the need for memory buffers.

</details>


### [128] [RSOD: Reliability-Guided Sonar Image Object Detection with Extremely Limited Labels](https://arxiv.org/abs/2601.12715)
*Chengzhou Li,Ping Guo,Guanchen Meng,Qi Jia,Jinyuan Liu,Zhu Liu,Xiaokang Liu,Yu Liu,Zhongxuan Luo,Xin Fan*

Main category: cs.CV

TL;DR: 提出RSOD教师-学生框架，通过可靠性评分和对象混合伪标签策略，解决声纳图像标注数据极度有限情况下的目标检测问题，在仅5%标注数据下达到与100%标注数据基线相当的性能。


<details>
  <summary>Details</summary>
Motivation: 声纳图像纹理细节少、噪声多，非专家难以区分类别间的细微差异，无法提供精确标注数据。因此，在标注数据极度有限的情况下设计有效的声纳图像目标检测方法尤为重要。

Method: 提出RSOD教师-学生框架：1) 通过评估教师模型在不同视图下预测的一致性计算可靠性评分；2) 引入对象混合伪标签方法解决声纳图像标注数据不足问题；3) 实施可靠性引导的自适应约束优化学生模型性能。

Result: 在UATD数据集上，仅使用5%标注数据的方法结果可与基线算法使用100%标注数据训练的结果竞争。同时收集了新数据集为声纳领域研究提供更有价值的数据。

Conclusion: RSOD框架通过充分利用未标注数据，在标注数据极度有限的情况下仍能实现良好的目标检测性能，为解决声纳图像标注困难问题提供了有效方案。

Abstract: Object detection in sonar images is a key technology in underwater detection systems. Compared to natural images, sonar images contain fewer texture details and are more susceptible to noise, making it difficult for non-experts to distinguish subtle differences between classes. This leads to their inability to provide precise annotation data for sonar images. Therefore, designing effective object detection methods for sonar images with extremely limited labels is particularly important. To address this, we propose a teacher-student framework called RSOD, which aims to fully learn the characteristics of sonar images and develop a pseudo-label strategy suitable for these images to mitigate the impact of limited labels. First, RSOD calculates a reliability score by assessing the consistency of the teacher's predictions across different views. To leverage this score, we introduce an object mixed pseudo-label method to tackle the shortage of labeled data in sonar images. Finally, we optimize the performance of the student by implementing a reliability-guided adaptive constraint. By taking full advantage of unlabeled data, the student can perform well even in situations with extremely limited labels. Notably, on the UATD dataset, our method, using only 5% of labeled data, achieves results that can compete against those of our baseline algorithm trained on 100% labeled data. We also collected a new dataset to provide more valuable data for research in the field of sonar.

</details>


### [129] [S2DiT: Sandwich Diffusion Transformer for Mobile Streaming Video Generation](https://arxiv.org/abs/2601.12719)
*Lin Zhao,Yushu Wu,Aleksei Lebedev,Dishani Lahiri,Meng Dong,Arpit Sahni,Michael Vasilkovsky,Hao Chen,Ju Hu,Aliaksandr Siarohin,Sergey Tulyakov,Yanzhi Wang,Anil Kag,Yanyu Li*

Main category: cs.CV

TL;DR: S2DiT：用于移动设备高效流式视频生成的Streaming Sandwich Diffusion Transformer，通过新颖注意力机制、三明治设计和知识蒸馏，在iPhone上实现超过10FPS的实时生成


<details>
  <summary>Details</summary>
Motivation: 当前Diffusion Transformers (DiTs) 在视频生成质量上有所提升，但计算成本过高，无法在移动设备上实现实时或设备端生成。需要开发能够在移动硬件上高效运行的高质量视频生成模型。

Method: 1. 提出Streaming Sandwich Diffusion Transformer (S2DiT)架构；2. 引入两种高效注意力机制：LinConv Hybrid Attention (LCHA) 和 Stride Self-Attention (SSA)；3. 通过预算感知动态规划搜索发现三明治设计；4. 提出2合1蒸馏框架，将大型教师模型能力迁移到紧凑的少步三明治模型。

Result: S2DiT在质量上与最先进的服务器视频模型相当，同时在iPhone上实现超过10FPS的流式生成，显著降低了计算成本并提高了移动设备上的生成效率。

Conclusion: S2DiT通过创新的注意力机制、三明治架构设计和知识蒸馏技术，成功实现了在移动设备上高效、高质量的视频生成，为实时设备端视频生成提供了可行的解决方案。

Abstract: Diffusion Transformers (DiTs) have recently improved video generation quality. However, their heavy computational cost makes real-time or on-device generation infeasible. In this work, we introduce S2DiT, a Streaming Sandwich Diffusion Transformer designed for efficient, high-fidelity, and streaming video generation on mobile hardware. S2DiT generates more tokens but maintains efficiency with novel efficient attentions: a mixture of LinConv Hybrid Attention (LCHA) and Stride Self-Attention (SSA). Based on this, we uncover the sandwich design via a budget-aware dynamic programming search, achieving superior quality and efficiency. We further propose a 2-in-1 distillation framework that transfers the capacity of large teacher models (e.g., Wan 2.2-14B) to the compact few-step sandwich model. Together, S2DiT achieves quality on par with state-of-the-art server video models, while streaming at over 10 FPS on an iPhone.

</details>


### [130] [DC-VLAQ: Query-Residual Aggregation for Robust Visual Place Recognition](https://arxiv.org/abs/2601.12729)
*Hanyu Zhu,Zhihao Zhan,Yuhang Ming,Liang Li,Dibo Hou,Javier Civera,Wanzeng Kong*

Main category: cs.CV

TL;DR: DC-VLAQ：一个用于视觉地点识别的表示中心框架，通过融合互补的视觉基础模型和稳健的全局聚合，提升在视角变化、光照变化和领域偏移下的识别性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉地点识别方法通常依赖单一视觉基础模型，忽略了不同模型提供的互补信息。然而，利用这些互补信息会改变token分布，挑战现有基于查询的全局聚合方案的稳定性。

Method: 1. 轻量级残差引导互补融合：以DINOv2特征空间为锚点，通过学习的残差校正注入CLIP的互补语义。2. 局部聚合查询向量：一种查询-残差全局聚合方案，通过局部token对可学习查询的残差响应进行编码，提高稳定性并保留细粒度判别线索。

Result: 在Pitts30k、Tokyo24/7、MSLS、Nordland、SPED和AmsterTime等标准VPR基准测试中，DC-VLAQ始终优于强基线方法，特别是在挑战性的领域偏移和长期外观变化下实现了最先进的性能。

Conclusion: DC-VLAQ通过有效融合互补视觉基础模型和稳健的全局聚合，解决了视觉地点识别中的表示学习挑战，在多种复杂场景下展现出优越性能。

Abstract: One of the central challenges in visual place recognition (VPR) is learning a robust global representation that remains discriminative under large viewpoint changes, illumination variations, and severe domain shifts. While visual foundation models (VFMs) provide strong local features, most existing methods rely on a single model, overlooking the complementary cues offered by different VFMs. However, exploiting such complementary information inevitably alters token distributions, which challenges the stability of existing query-based global aggregation schemes. To address these challenges, we propose DC-VLAQ, a representation-centric framework that integrates the fusion of complementary VFMs and robust global aggregation. Specifically, we first introduce a lightweight residual-guided complementary fusion that anchors representations in the DINOv2 feature space while injecting complementary semantics from CLIP through a learned residual correction. In addition, we propose the Vector of Local Aggregated Queries (VLAQ), a query--residual global aggregation scheme that encodes local tokens by their residual responses to learnable queries, resulting in improved stability and the preservation of fine-grained discriminative cues. Extensive experiments on standard VPR benchmarks, including Pitts30k, Tokyo24/7, MSLS, Nordland, SPED, and AmsterTime, demonstrate that DC-VLAQ consistently outperforms strong baselines and achieves state-of-the-art performance, particularly under challenging domain shifts and long-term appearance changes.

</details>


### [131] [KaoLRM: Repurposing Pre-trained Large Reconstruction Models for Parametric 3D Face Reconstruction](https://arxiv.org/abs/2601.12736)
*Qingtian Zhu,Xu Cao,Zhixiang Wang,Yinqiang Zheng,Takafumi Taketomi*

Main category: cs.CV

TL;DR: KaoLRM利用大型重建模型(LRM)的预训练3D先验，结合FLAME参数化人脸模型和2D高斯泼溅，实现单视角图像到3D人脸的高质量重建，显著提升了跨视角一致性。


<details>
  <summary>Details</summary>
Motivation: 现有3D形变模型(3DMM)回归器在不同视角下的一致性较差，特别是在自遮挡和多样化视角情况下重建效果不佳。需要利用更强大的3D先验知识来提升重建的准确性和鲁棒性。

Method: 将LRM预训练的三平面特征投影到FLAME参数空间来恢复几何形状，并通过与FLAME网格紧密耦合的2D高斯基元建模外观。在LRM的渲染流程中集成了基于FLAME的2D高斯泼溅技术。

Result: 在受控和真实场景基准测试中，KaoLRM实现了卓越的重建精度和跨视角一致性，显著优于对视角变化敏感的传统方法。

Conclusion: 通过利用LRM的丰富3D先验知识，KaoLRM能够生成准确且鲁棒的3D人脸重建结果，有效解决了现有方法在跨视角一致性方面的局限性。

Abstract: We propose KaoLRM to re-target the learned prior of the Large Reconstruction Model (LRM) for parametric 3D face reconstruction from single-view images. Parametric 3D Morphable Models (3DMMs) have been widely used for facial reconstruction due to their compact and interpretable parameterization, yet existing 3DMM regressors often exhibit poor consistency across varying viewpoints. To address this, we harness the pre-trained 3D prior of LRM and incorporate FLAME-based 2D Gaussian Splatting into LRM's rendering pipeline. Specifically, KaoLRM projects LRM's pre-trained triplane features into the FLAME parameter space to recover geometry, and models appearance via 2D Gaussian primitives that are tightly coupled to the FLAME mesh. The rich prior enables the FLAME regressor to be aware of the 3D structure, leading to accurate and robust reconstructions under self-occlusions and diverse viewpoints. Experiments on both controlled and in-the-wild benchmarks demonstrate that KaoLRM achieves superior reconstruction accuracy and cross-view consistency, while existing methods remain sensitive to viewpoint variations. The code is released at https://github.com/CyberAgentAILab/KaoLRM.

</details>


### [132] [SSPFormer: Self-Supervised Pretrained Transformer for MRI Images](https://arxiv.org/abs/2601.12747)
*Jingkai Li,Xiaoze Tian,Yuhang Shen,Jia Wang,Dianjie Lu,Guijuan Zhang,Zhuoran Zheng*

Main category: cs.CV

TL;DR: SSPFormer：针对MRI图像的自监督预训练Transformer，通过逆频率投影掩码和频率加权FFT噪声增强，解决医学图像领域适应和数据稀缺问题，在分割、超分辨率和去噪任务中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 预训练Transformer在自然图像处理中表现出色，但直接应用于MRI图像面临两大挑战：1）无法适应医学解剖结构的特异性；2）医学数据隐私性和稀缺性带来的限制。

Method: 提出SSPFormer自监督预训练Transformer，采用两种核心策略：1）逆频率投影掩码，优先重建高频解剖区域以强制结构感知表示学习；2）频率加权FFT噪声增强，在傅里叶域注入生理真实噪声以增强对MRI伪影的鲁棒性。

Result: 在分割、超分辨率和去噪任务上的大量实验表明，SSPFormer实现了最先进的性能，充分验证了其捕获细粒度MRI图像保真度和适应临床应用需求的能力。

Conclusion: SSPFormer通过自监督学习从原始扫描数据中学习领域不变和伪影鲁棒的特征，有效解决了MRI图像处理中的领域适应和数据稀缺问题，为临床应用提供了有效的解决方案。

Abstract: The pre-trained transformer demonstrates remarkable generalization ability in natural image processing. However, directly transferring it to magnetic resonance images faces two key challenges: the inability to adapt to the specificity of medical anatomical structures and the limitations brought about by the privacy and scarcity of medical data. To address these issues, this paper proposes a Self-Supervised Pretrained Transformer (SSPFormer) for MRI images, which effectively learns domain-specific feature representations of medical images by leveraging unlabeled raw imaging data. To tackle the domain gap and data scarcity, we introduce inverse frequency projection masking, which prioritizes the reconstruction of high-frequency anatomical regions to enforce structure-aware representation learning. Simultaneously, to enhance robustness against real-world MRI artifacts, we employ frequency-weighted FFT noise enhancement that injects physiologically realistic noise into the Fourier domain. Together, these strategies enable the model to learn domain-invariant and artifact-robust features directly from raw scans. Through extensive experiments on segmentation, super-resolution, and denoising tasks, the proposed SSPFormer achieves state-of-the-art performance, fully verifying its ability to capture fine-grained MRI image fidelity and adapt to clinical application requirements.

</details>


### [133] [Moaw: Unleashing Motion Awareness for Video Diffusion Models](https://arxiv.org/abs/2601.12761)
*Tianqi Zhang,Ziyi Wang,Wenzhao Zheng,Weiliang Chen,Yuanhui Huang,Zhengyang Huang,Jie Zhou,Jiwen Lu*

Main category: cs.CV

TL;DR: Moaw框架通过训练视频扩散模型进行运动感知，实现零样本运动迁移，无需额外适配器


<details>
  <summary>Details</summary>
Motivation: 视频扩散模型在大型数据集训练中自然捕捉帧间特征对应关系，已有工作利用这一特性进行零样本光流预测和跟踪。本研究旨在探索监督训练是否能更充分利用视频扩散模型的跟踪能力。

Method: 提出Moaw框架：1) 训练扩散模型进行运动感知，从图像到视频生成转向视频到密集跟踪；2) 构建运动标注数据集识别最强运动信息编码特征；3) 将这些特征注入结构相同的视频生成模型，利用网络同质性实现零样本适应

Result: 实现了无需额外适配器的运动迁移，为生成建模与运动理解搭建了新桥梁

Conclusion: Moaw框架展示了监督训练能有效利用视频扩散模型的运动感知能力，为更统一可控的视频学习框架铺平道路

Abstract: Video diffusion models, trained on large-scale datasets, naturally capture correspondences of shared features across frames. Recent works have exploited this property for tasks such as optical flow prediction and tracking in a zero-shot setting. Motivated by these findings, we investigate whether supervised training can more fully harness the tracking capability of video diffusion models. To this end, we propose Moaw, a framework that unleashes motion awareness for video diffusion models and leverages it to facilitate motion transfer. Specifically, we train a diffusion model for motion perception, shifting its modality from image-to-video generation to video-to-dense-tracking. We then construct a motion-labeled dataset to identify features that encode the strongest motion information, and inject them into a structurally identical video generation model. Owing to the homogeneity between the two networks, these features can be naturally adapted in a zero-shot manner, enabling motion transfer without additional adapters. Our work provides a new paradigm for bridging generative modeling and motion understanding, paving the way for more unified and controllable video learning frameworks.

</details>


### [134] [Towards Unbiased Source-Free Object Detection via Vision Foundation Models](https://arxiv.org/abs/2601.12765)
*Zhi Cai,Yingjie Gao,Yanan Zhang,Xinzhu Ma,Di Huang*

Main category: cs.CV

TL;DR: 提出DSOD框架解决SFOD中的源偏差问题，通过VFM辅助的特征注入和正则化，在多个跨域检测任务上取得SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有SFOD方法存在源偏差问题，即适应后的模型仍然偏向源域，导致泛化能力差和自训练过程中的误差累积。需要解决这一挑战以提高跨域目标检测性能。

Method: 提出DSOD框架：1) UFI模块通过SSE和DAAW将VFM特征集成到CNN骨干网络；2) SAFR通过语义感知特征正则化防止过拟合源域特征；3) 为计算受限场景提出DSOD-distill变体，采用双教师蒸馏方案。

Result: 在多个基准测试中表现优异：Normal-to-Foggy天气适应达到48.1% AP，Cross-scene适应达到39.3% AP，Synthetic-to-Real适应达到61.4% AP，均超越现有SOTA SFOD方法。

Conclusion: DSOD框架有效缓解了SFOD中的源偏差问题，通过VFM辅助的特征集成和正则化机制显著提升了跨域目标检测性能，并为计算受限场景提供了实用解决方案。

Abstract: Source-Free Object Detection (SFOD) has garnered much attention in recent years by eliminating the need of source-domain data in cross-domain tasks, but existing SFOD methods suffer from the Source Bias problem, i.e. the adapted model remains skewed towards the source domain, leading to poor generalization and error accumulation during self-training. To overcome this challenge, we propose Debiased Source-free Object Detection (DSOD), a novel VFM-assisted SFOD framework that can effectively mitigate source bias with the help of powerful VFMs. Specifically, we propose Unified Feature Injection (UFI) module that integrates VFM features into the CNN backbone through Simple-Scale Extension (SSE) and Domain-aware Adaptive Weighting (DAAW). Then, we propose Semantic-aware Feature Regularization (SAFR) that constrains feature learning to prevent overfitting to source domain characteristics. Furthermore, we propose a VFM-free variant, termed DSOD-distill for computation-restricted scenarios through a novel Dual-Teacher distillation scheme. Extensive experiments on multiple benchmarks demonstrate that DSOD outperforms state-of-the-art SFOD methods, achieving 48.1% AP on Normal-to-Foggy weather adaptation, 39.3% AP on Cross-scene adaptation, and 61.4% AP on Synthetic-to-Real adaptation.

</details>


### [135] [Spatial-VLN: Zero-Shot Vision-and-Language Navigation With Explicit Spatial Perception and Exploration](https://arxiv.org/abs/2601.12766)
*Lu Yue,Yue Fan,Shiwei Lian,Yu Zhao,Jiaxin Yu,Liang Xie,Feitian Zhang*

Main category: cs.CV

TL;DR: Spatial-VLN：一个感知引导的探索框架，通过增强空间感知和专家推理机制，解决了零样本视觉语言导航中的三个关键空间挑战，在复杂连续环境中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的零样本视觉语言导航代理在泛化能力上表现良好，但在复杂连续环境中存在空间感知不足的问题。论文识别了三个关键的空间挑战：门交互、多房间导航和模糊指令执行，这些是现有方法失败率高的主要原因。

Method: 提出Spatial-VLN框架，包含两个主要模块：1）空间感知增强模块，通过全景过滤和专门的门与区域专家，生成空间一致、跨视图一致的感知表示；2）探索多专家推理模块，使用并行LLM专家处理路径点级语义和区域级空间转换，当专家预测出现分歧时，激活查询-探索机制主动探测关键区域解决感知模糊性。

Result: 在VLN-CE基准测试中，Spatial-VLN仅使用低成本LLM就实现了最先进的性能。此外，通过引入基于值的路径点采样策略有效缩小了仿真到现实的差距，大量真实世界评估证实了该框架在复杂环境中具有优越的泛化能力和鲁棒性。

Conclusion: Spatial-VLN通过增强空间感知和主动探索机制，成功解决了零样本视觉语言导航中的关键空间挑战，在仿真和真实世界环境中都表现出卓越的性能，为实际应用提供了有效的解决方案。

Abstract: Zero-shot Vision-and-Language Navigation (VLN) agents leveraging Large Language Models (LLMs) excel in generalization but suffer from insufficient spatial perception. Focusing on complex continuous environments, we categorize key perceptual bottlenecks into three spatial challenges: door interaction,multi-room navigation, and ambiguous instruction execution, where existing methods consistently suffer high failure rates. We present Spatial-VLN, a perception-guided exploration framework designed to overcome these challenges. The framework consists of two main modules. The Spatial Perception Enhancement (SPE) module integrates panoramic filtering with specialized door and region experts to produce spatially coherent, cross-view consistent perceptual representations. Building on this foundation, our Explored Multi-expert Reasoning (EMR) module uses parallel LLM experts to address waypoint-level semantics and region-level spatial transitions. When discrepancies arise between expert predictions, a query-and-explore mechanism is activated, prompting the agent to actively probe critical areas and resolve perceptual ambiguities. Experiments on VLN-CE demonstrate that Spatial VLN achieves state-of-the-art performance using only low-cost LLMs. Furthermore, to validate real-world applicability, we introduce a value-based waypoint sampling strategy that effectively bridges the Sim2Real gap. Extensive real-world evaluations confirm that our framework delivers superior generalization and robustness in complex environments. Our codes and videos are available at https://yueluhhxx.github.io/Spatial-VLN-web/.

</details>


### [136] [Delving Deeper: Hierarchical Visual Perception for Robust Video-Text Retrieval](https://arxiv.org/abs/2601.12768)
*Zequn Xie,Boyun Zhang,Yuxiao Lin,Tao Jin*

Main category: cs.CV

TL;DR: HVP-Net通过从视觉编码器的多个中间层提取和精炼特征，挖掘更丰富的视频语义，在视频文本检索任务中取得了新的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于预训练模型（如CLIP）的视频文本检索方法存在两个主要问题：1）视频固有的冗余性；2）依赖粗糙的最终层特征，限制了匹配准确性。

Method: 提出HVP-Net（分层视觉感知网络），通过从视觉编码器的多个中间层提取特征，在不同语义层次上从原始补丁标记中逐步蒸馏出显著的视觉概念，减少冗余同时保留对齐所需的关键细节。

Result: 在MSRVTT、DiDeMo和ActivityNet等具有挑战性的基准测试中取得了新的最先进性能。

Conclusion: 验证了利用分层特征提升视频文本检索效果的有效性，为视频表示学习提供了新思路。

Abstract: Video-text retrieval (VTR) aims to locate relevant videos using natural language queries. Current methods, often based on pre-trained models like CLIP, are hindered by video's inherent redundancy and their reliance on coarse, final-layer features, limiting matching accuracy. To address this, we introduce the HVP-Net (Hierarchical Visual Perception Network), a framework that mines richer video semantics by extracting and refining features from multiple intermediate layers of a vision encoder. Our approach progressively distills salient visual concepts from raw patch-tokens at different semantic levels, mitigating redundancy while preserving crucial details for alignment. This results in a more robust video representation, leading to new state-of-the-art performance on challenging benchmarks including MSRVTT, DiDeMo, and ActivityNet. Our work validates the effectiveness of exploiting hierarchical features for advancing video-text retrieval. Our codes are available at https://github.com/boyun-zhang/HVP-Net.

</details>


### [137] [Generalizable and Animatable 3D Full-Head Gaussian Avatar from a Single Image](https://arxiv.org/abs/2601.12770)
*Shuling Zhao,Dan Xu*

Main category: cs.CV

TL;DR: 提出一种从单张图像构建3D可动画头部化身的单次前馈框架，支持实时动画和360度渲染


<details>
  <summary>Details</summary>
Motivation: 现有方法在大相机姿态变化下效果不佳，影响3D化身的真实感，需要解决单张图像重建3D可动画头部化身的挑战

Method: 使用参数化人脸模型UV空间上的高斯基元建模3D头部；利用预训练3D GAN提取全局全头特征和多视角监督；利用UV空间和人脸对称性融合局部细粒度图像特征与全局纹理

Result: 实现了高质量3D全头建模和实时动画，提升了3D说话化身的真实感

Conclusion: 提出的框架有效解决了单张图像重建3D可动画头部化身的难题，实现了实时动画和高质量渲染

Abstract: Building 3D animatable head avatars from a single image is an important yet challenging problem. Existing methods generally collapse under large camera pose variations, compromising the realism of 3D avatars. In this work, we propose a new framework to tackle the novel setting of one-shot 3D full-head animatable avatar reconstruction in a single feed-forward pass, enabling real-time animation and simultaneous 360$^\circ$ rendering views. To facilitate efficient animation control, we model 3D head avatars with Gaussian primitives embedded on the surface of a parametric face model within the UV space. To obtain knowledge of full-head geometry and textures, we leverage rich 3D full-head priors within a pretrained 3D generative adversarial network (GAN) for global full-head feature extraction and multi-view supervision. To increase the fidelity of the 3D reconstruction of the input image, we take advantage of the symmetric nature of the UV space and human faces to fuse local fine-grained input image features with the global full-head textures. Extensive experiments demonstrate the effectiveness of our method, achieving high-quality 3D full-head modeling as well as real-time animation, thereby improving the realism of 3D talking avatars.

</details>


### [138] [Open Vocabulary Panoptic Segmentation With Retrieval Augmentation](https://arxiv.org/abs/2601.12779)
*Nafis Sadeq,Qingfeng Liu,Mostafa El-Khamy*

Main category: cs.CV

TL;DR: RetCLIP是一种检索增强的全景分割方法，通过构建掩码片段特征数据库，在推理时检索相似特征和类别标签，结合CLIP分数提升未见类别的分割性能。


<details>
  <summary>Details</summary>
Motivation: 传统全景分割方法在训练数据集上表现良好，但难以泛化到未见类别。开放词汇全景分割需要能够根据用户输入分割任意类别，现有方法在未见类别上性能有限。

Method: 使用配对图像-文本数据构建掩码片段特征数据库。推理时，将输入图像的掩码片段特征作为查询键，从数据库中检索相似特征和相关类别标签。基于查询特征与检索特征的相似度分配分类分数，并与CLIP分数结合得到最终输出。

Result: 在COCO上训练后，在ADE20k数据集上达到30.9 PQ、19.3 mAP、44.0 mIoU，相比基线方法分别提升+4.5 PQ、+2.5 mAP、+10.0 mIoU的绝对改进。

Conclusion: RetCLIP通过检索增强机制有效提升了开放词汇全景分割中未见类别的性能，结合检索特征和CLIP分数的方法显著优于现有方法。

Abstract: Given an input image and set of class names, panoptic segmentation aims to label each pixel in an image with class labels and instance labels. In comparison, Open Vocabulary Panoptic Segmentation aims to facilitate the segmentation of arbitrary classes according to user input. The challenge is that a panoptic segmentation system trained on a particular dataset typically does not generalize well to unseen classes beyond the training data. In this work, we propose RetCLIP, a retrieval-augmented panoptic segmentation method that improves the performance of unseen classes. In particular, we construct a masked segment feature database using paired image-text data. At inference time, we use masked segment features from the input image as query keys to retrieve similar features and associated class labels from the database. Classification scores for the masked segment are assigned based on the similarity between query features and retrieved features. The retrieval-based classification scores are combined with CLIP-based scores to produce the final output. We incorporate our solution with a previous SOTA method (FC-CLIP). When trained on COCO, the proposed method demonstrates 30.9 PQ, 19.3 mAP, 44.0 mIoU on the ADE20k dataset, achieving +4.5 PQ, +2.5 mAP, +10.0 mIoU absolute improvement over the baseline.

</details>


### [139] [SKANet: A Cognitive Dual-Stream Framework with Adaptive Modality Fusion for Robust Compound GNSS Interference Classification](https://arxiv.org/abs/2601.12791)
*Zhihan Zeng,Yang Zhao,Kaihe Wang,Dusit Niyato,Hongyuan Shu,Junchu Zhao,Yanjun Huang,Yue Xiu,Zhongpei Zhang,Ning Wei*

Main category: cs.CV

TL;DR: SKANet：一种基于双流架构的认知深度学习框架，通过选择性核与不对称卷积动态调整感受野，有效识别GNSS复合干扰信号，在低干噪比下表现优异。


<details>
  <summary>Details</summary>
Motivation: 随着电磁环境日益复杂，GNSS面临越来越复杂的干扰威胁。深度学习能识别基本干扰，但对复合干扰分类困难，因为不同干扰源叠加且瞬态突发信号与连续全局信号需要冲突的特征提取尺度。

Method: 提出SKANet框架，采用双流架构整合时频图像和功率谱密度。核心是多分支选择性核模块与不对称卷积块结合，动态调整感受野，同时捕获微尺度瞬态特征和宏尺度频谱趋势。融合阶段加入Squeeze-and-Excitation机制自适应重新校准各模态特征贡献。

Result: 在405,000个样本数据集上，SKANet达到96.99%的整体准确率，在复合干扰分类方面表现出优越的鲁棒性，特别是在低干噪比条件下。

Conclusion: SKANet通过动态感受野调整和自适应特征融合，有效解决了GNSS复合干扰分类的挑战，为复杂电磁环境下的干扰识别提供了有效解决方案。

Abstract: As the electromagnetic environment becomes increasingly complex, Global Navigation Satellite Systems (GNSS) face growing threats from sophisticated jamming interference. Although Deep Learning (DL) effectively identifies basic interference, classifying compound interference remains difficult due to the superposition of diverse jamming sources. Existing single-domain approaches often suffer from performance degradation because transient burst signals and continuous global signals require conflicting feature extraction scales. We propose the Selective Kernel and Asymmetric convolution Network(SKANet), a cognitive deep learning framework built upon a dual-stream architecture that integrates Time-Frequency Images (TFIs) and Power Spectral Density (PSD). Distinct from conventional fusion methods that rely on static receptive fields, the proposed architecture incorporates a Multi-Branch Selective Kernel (SK) module combined with Asymmetric Convolution Blocks (ACBs). This mechanism enables the network to dynamically adjust its receptive fields, acting as an adaptive filter that simultaneously captures micro-scale transient features and macro-scale spectral trends within entangled compound signals. To complement this spatial-temporal adaptation, a Squeeze-and-Excitation (SE) mechanism is integrated at the fusion stage to adaptively recalibrate the contribution of heterogeneous features from each modality. Evaluations on a dataset of 405,000 samples demonstrate that SKANet achieves an overall accuracy of 96.99\%, exhibiting superior robustness for compound jamming classification, particularly under low Jamming-to-Noise Ratio (JNR) regimes.

</details>


### [140] [Combating Noisy Labels through Fostering Self- and Neighbor-Consistency](https://arxiv.org/abs/2601.12795)
*Zeren Sun,Yazhou Yao,Tongliang Liu,Zechao Li,Fumin Shen,Jinhui Tang*

Main category: cs.CV

TL;DR: Jo-SNC：一种基于自一致性和邻域一致性的联合样本选择与模型正则化方法，用于处理标签噪声问题，特别关注小批量噪声不平衡和分布外噪声数据。


<details>
  <summary>Details</summary>
Motivation: 现实场景中普遍存在标签噪声，深度网络容易记忆这些噪声样本。现有方法主要关注识别干净数据，但忽略了小批量间噪声分布的不平衡，且对分布外噪声数据关注不足。

Method: 提出Jo-SNC方法：1) 使用Jensen-Shannon散度结合样本的最近邻信息衡量样本干净或分布外的"可能性"；2) 设计自适应数据驱动的阈值方案调整每类选择阈值；3) 干净样本常规训练，分布内噪声样本使用部分标签学习，分布外噪声样本使用负学习；4) 提出三元组一致性正则化促进自预测一致性、邻域预测一致性和特征一致性。

Result: 在多个基准数据集上的大量实验和全面的消融研究表明，该方法相比现有最先进方法具有有效性和优越性。

Conclusion: Jo-SNC通过联合样本选择和模型正则化，有效处理标签噪声问题，特别是解决了小批量噪声不平衡和分布外噪声的挑战，显著提升了模型在噪声环境下的性能。

Abstract: Label noise is pervasive in various real-world scenarios, posing challenges in supervised deep learning. Deep networks are vulnerable to such label-corrupted samples due to the memorization effect. One major stream of previous methods concentrates on identifying clean data for training. However, these methods often neglect imbalances in label noise across different mini-batches and devote insufficient attention to out-of-distribution noisy data. To this end, we propose a noise-robust method named Jo-SNC (\textbf{Jo}int sample selection and model regularization based on \textbf{S}elf- and \textbf{N}eighbor-\textbf{C}onsistency). Specifically, we propose to employ the Jensen-Shannon divergence to measure the ``likelihood'' of a sample being clean or out-of-distribution. This process factors in the nearest neighbors of each sample to reinforce the reliability of clean sample identification. We design a self-adaptive, data-driven thresholding scheme to adjust per-class selection thresholds. While clean samples undergo conventional training, detected in-distribution and out-of-distribution noisy samples are trained following partial label learning and negative learning, respectively. Finally, we advance the model performance further by proposing a triplet consistency regularization that promotes self-prediction consistency, neighbor-prediction consistency, and feature consistency. Extensive experiments on various benchmark datasets and comprehensive ablation studies demonstrate the effectiveness and superiority of our approach over existing state-of-the-art methods.

</details>


### [141] [PhyG-MoE: A Physics-Guided Mixture-of-Experts Framework for Energy-Efficient GNSS Interference Recognition](https://arxiv.org/abs/2601.12798)
*Zhihan Zeng,Yang Zhao,Kaihe Wang,Dusit Niyato,Yue Xiu,Lu Chen,Zhongpei Zhang,Ning Wei*

Main category: cs.CV

TL;DR: PhyG-MoE：一种基于物理引导的专家混合框架，通过动态调整模型容量与信号复杂度对齐，解决GNSS干扰识别中静态模型计算资源不匹配问题，在21种干扰类别上达到97.58%准确率。


<details>
  <summary>Details</summary>
Motivation: 当前GNSS干扰识别中的深度学习模型存在根本性局限：无论输入信号的物理熵如何，都采用固定的计算拓扑结构。这种刚性导致严重的资源不匹配问题，简单信号和复杂饱和信号消耗相同的处理成本，无法适应动态电磁环境。

Method: 提出PhyG-MoE（物理引导的专家混合）框架，采用基于频谱的门控机制，根据信号的频谱特征纠缠程度进行路由。对于复杂饱和场景，按需激活高容量的TransNeXt专家来解纠缠复杂特征；对于基础信号，使用轻量级专家处理以最小化延迟。

Result: 在21种干扰类别上的评估显示，PhyG-MoE实现了97.58%的整体准确率。该框架显著降低了计算开销，同时保持性能不下降，解决了静态计算与动态电磁环境之间的内在冲突。

Conclusion: PhyG-MoE通过动态对齐模型容量与信号复杂度，为资源受限的认知接收器提供了可行的解决方案，有效解决了GNSS干扰识别中静态模型的资源不匹配问题，在保证高准确率的同时显著降低计算成本。

Abstract: Complex electromagnetic interference increasingly compromises Global Navigation Satellite Systems (GNSS), threatening the reliability of Space-Air-Ground Integrated Networks (SAGIN). Although deep learning has advanced interference recognition, current static models suffer from a \textbf{fundamental limitation}: they impose a fixed computational topology regardless of the input's physical entropy. This rigidity leads to severe resource mismatch, where simple primitives consume the same processing cost as chaotic, saturated mixtures. To resolve this, this paper introduces PhyG-MoE (Physics-Guided Mixture-of-Experts), a framework designed to \textbf{dynamically align model capacity with signal complexity}. Unlike static architectures, the proposed system employs a spectrum-based gating mechanism that routes signals based on their spectral feature entanglement. A high-capacity TransNeXt expert is activated on-demand to disentangle complex features in saturated scenarios, while lightweight experts handle fundamental signals to minimize latency. Evaluations on 21 jamming categories demonstrate that PhyG-MoE achieves an overall accuracy of 97.58\%. By resolving the intrinsic conflict between static computing and dynamic electromagnetic environments, the proposed framework significantly reduces computational overhead without performance degradation, offering a viable solution for resource-constrained cognitive receivers.

</details>


### [142] [Left-Right Symmetry Breaking in CLIP-style Vision-Language Models Trained on Synthetic Spatial-Relation Data](https://arxiv.org/abs/2601.12809)
*Takaki Yamamoto,Chihiro Noguchi,Toshihiro Tanizawa*

Main category: cs.CV

TL;DR: 本文通过可控的1D图像-文本测试平台，探究了CLIP风格Transformer模型如何学习左右空间关系，发现标签多样性比布局多样性更能驱动泛化能力，并通过注意力分解揭示了位置嵌入与词嵌入交互如何打破左右对称性。


<details>
  <summary>Details</summary>
Motivation: 空间理解是视觉语言模型的关键挑战，但目前尚不清楚这种理解是否真正被习得，以及通过何种机制习得。本文旨在探究CLIP风格对比训练中左右关系理解是如何出现的。

Method: 使用轻量级Transformer视觉和文本编码器，在描述一物体和两物体场景的配对数据上进行端到端训练，评估未见物体对的泛化能力，系统性地变化标签和布局多样性，并进行注意力分解分析。

Result: 对比训练确实能学习左右关系，标签多样性比布局多样性更能驱动泛化；注意力分解显示位置嵌入与词嵌入的交互诱导出水平注意力梯度，打破了编码器的左右对称性，消除这一贡献会显著降低左右辨别能力。

Conclusion: 研究提供了CLIP风格模型何时以及如何获得关系能力的机制性见解，揭示了标签多样性在空间关系学习中的关键作用，以及位置-词嵌入交互在打破对称性中的机制。

Abstract: Spatial understanding remains a key challenge in vision-language models. Yet it is still unclear whether such understanding is truly acquired, and if so, through what mechanisms. We present a controllable 1D image-text testbed to probe how left-right relational understanding emerges in Transformer-based vision and text encoders trained with a CLIP-style contrastive objective. We train lightweight Transformer-based vision and text encoders end-to-end on paired descriptions of one- and two-object scenes and evaluate generalization to unseen object pairs while systematically varying label and layout diversity. We find that contrastive training learns left-right relations and that label diversity, more than layout diversity, is the primary driver of generalization in this setting. To gain the mechanistic understanding, we perform an attention decomposition and show that interactions between positional and token embeddings induce a horizontal attention gradient that breaks left-right symmetry in the encoders; ablating this contribution substantially reduces left-right discrimination. Our results provide a mechanistic insight of when and how CLIP-style models acquire relational competence.

</details>


### [143] [CSGaussian: Progressive Rate-Distortion Compression and Segmentation for 3D Gaussian Splatting](https://arxiv.org/abs/2601.12814)
*Yu-Jen Tseng,Chia-Hao Kao,Jing-Zhong Chen,Alessandro Gnutti,Shao-Yuan Lo,Yen-Yu Lin,Wen-Hsiao Peng*

Main category: cs.CV

TL;DR: 首个统一框架，用于3D高斯溅射的率失真优化压缩与分割，支持解码端场景编辑等应用


<details>
  <summary>Details</summary>
Motivation: 虽然3DGS在实时渲染和语义场景理解中有效，但先前工作将这两个任务独立处理，未探索它们的联合优化。需要支持解码端应用（如场景编辑）而不仅仅是传统场景重建和视图合成。

Method: 1. 轻量级隐式神经表示超先验，高效编码颜色和语义属性；2. 压缩引导的分割学习，包括量化感知训练增强特征可分性和质量感知权重机制抑制不可靠高斯基元

Result: 在LERF和3D-OVS数据集上的实验表明，该方法显著降低传输成本，同时保持高渲染质量和强分割性能

Conclusion: 提出了首个统一框架，成功将语义学习集成到3DGS压缩流程中，支持解码端应用，在压缩效率和分割质量方面取得良好平衡

Abstract: We present the first unified framework for rate-distortion-optimized compression and segmentation of 3D Gaussian Splatting (3DGS). While 3DGS has proven effective for both real-time rendering and semantic scene understanding, prior works have largely treated these tasks independently, leaving their joint consideration unexplored. Inspired by recent advances in rate-distortion-optimized 3DGS compression, this work integrates semantic learning into the compression pipeline to support decoder-side applications--such as scene editing and manipulation--that extend beyond traditional scene reconstruction and view synthesis. Our scheme features a lightweight implicit neural representation-based hyperprior, enabling efficient entropy coding of both color and semantic attributes while avoiding costly grid-based hyperprior as seen in many prior works. To facilitate compression and segmentation, we further develop compression-guided segmentation learning, consisting of quantization-aware training to enhance feature separability and a quality-aware weighting mechanism to suppress unreliable Gaussian primitives. Extensive experiments on the LERF and 3D-OVS datasets demonstrate that our approach significantly reduces transmission cost while preserving high rendering quality and strong segmentation performance.

</details>


### [144] [A Generalist Foundation Model for Total-body PET/CT Enables Diagnostic Reporting and System-wide Metabolic Profiling](https://arxiv.org/abs/2601.12820)
*Wei Chen,Liang Wu,Shuyi Lu,Yuanyuan Sun,Wenkai Bi,Zilong Yuan,Yaoyao He,Feng Wang,Junchi Ma,Shuyong Liu,Zhaoping Cheng,Xiaoyan Hu,Jianfeng Qiu*

Main category: cs.CV

TL;DR: SDF-HOLO是一个用于全身PET/CT的多模态基础模型，通过双流编码器分离CT和PET表示学习，使用跨模态交互模块耦合，结合分层上下文建模处理长距离依赖，利用解剖分割掩码作为语义锚点进行体素-掩码-文本对齐，在肿瘤分割、低剂量病变检测和多语言诊断报告生成等任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 全身PET/CT具有系统范围的分子成像能力，但存在解剖和代谢信号异质性、约2米轴向覆盖范围以及结构化放射学语义等挑战，现有医学AI模型假设单模态输入、局部视野和粗略的图像-文本对齐，无法有效处理这些复杂问题。

Method: 1. 使用双流编码器分离CT和PET表示学习，通过跨模态交互模块耦合；2. 分层上下文建模结合高效局部窗口和全局注意力处理长距离依赖；3. 使用解剖分割掩码作为显式语义锚点，在预训练期间进行体素-掩码-文本对齐；4. 在超过10,000名患者数据上进行预训练。

Result: 在肿瘤分割、低剂量病变检测和多语言诊断报告生成任务中，SDF-HOLO优于强任务特定和临床参考基线，减少了定位错误和幻觉发现。此外，模型能够进行系统范围的代谢分析，并揭示肿瘤相关的器官间代谢网络相互作用指纹。

Conclusion: SDF-HOLO为全身PET/CT诊断和系统级精准肿瘤学提供了可扩展的计算基础，超越了局部解释，实现了系统范围的代谢分析和肿瘤相关代谢网络相互作用的发现。

Abstract: Total-body PET/CT enables system-wide molecular imaging, but heterogeneous anatomical and metabolic signals, approximately 2 m axial coverage, and structured radiology semantics challenge existing medical AI models that assume single-modality inputs, localized fields of view, and coarse image-text alignment. We introduce SDF-HOLO (Systemic Dual-stream Fusion Holo Model), a multimodal foundation model for holistic total-body PET/CT, pre-trained on more than 10,000 patients. SDF-HOLO decouples CT and PET representation learning with dual-stream encoders and couples them through a cross-modal interaction module, allowing anatomical context to refine PET aggregation while metabolic saliency guides subtle morphological reasoning. To model long-range dependencies across the body, hierarchical context modeling combines efficient local windows with global attention. To bridge voxels and clinical language, we use anatomical segmentation masks as explicit semantic anchors and perform voxel-mask-text alignment during pre-training. Across tumor segmentation, low-dose lesion detection, and multilingual diagnostic report generation, SDF-HOLO outperforms strong task-specific and clinical-reference baselines while reducing localization errors and hallucinated findings. Beyond focal interpretation, the model enables system-wide metabolic profiling and reveals tumor-associated fingerprints of inter-organ metabolic network interactions, providing a scalable computational foundation for total-body PET/CT diagnostics and system-level precision oncology.

</details>


### [145] [TreeDGS: Aerial Gaussian Splatting for Distant DBH Measurement](https://arxiv.org/abs/2601.12823)
*Belal Shaheen,Minh-Hieu Nguyen,Bach-Thuan Bui,Shubham,Tim Wu,Michael Fairley,Matthew David Zane,Michael Wu,James Tompkin*

Main category: cs.CV

TL;DR: TreeDGS使用3D高斯泼溅技术从航拍图像重建森林场景，通过不透明度加权圆拟合实现树干胸径的精确测量，在10个样地的测试中达到4.79厘米RMSE，优于激光雷达基线。


<details>
  <summary>Details</summary>
Motivation: 航拍遥感虽然能高效进行大面积调查，但在复杂自然场景中难以实现精确的对象级测量。现有3D重建方法（如NeRF和3D高斯泼溅）在重建保真度方面有所提升，但对于航拍图像中稀疏观测的树干（通常只占几个像素），传统方法难以准确约束胸高处的树干几何形状，导致胸径测量困难。

Method: TreeDGS采用3D高斯泼溅作为连续、可密集化的场景表示。首先通过SfM-MVS初始化和高斯优化，然后使用RaDe-GS的深度感知累积不透明度积分从高斯场提取密集点集，并为每个样本分配多视角不透明度可靠性分数。最后通过不透明度加权的实心圆拟合从树干分离点中估计胸径。

Result: 在10个具有实地测量胸径的样地评估中，TreeDGS达到4.79厘米RMSE（约2.6像素），优于最先进的激光雷达基线（7.91厘米RMSE）。这表明基于泼溅的密集化几何能够实现准确、低成本的航拍胸径测量。

Conclusion: TreeDGS通过3D高斯泼溅技术成功解决了航拍图像中树干稀疏观测的挑战，实现了精确的胸径测量，为低成本、高效的森林调查提供了新方法。

Abstract: Aerial remote sensing enables efficient large-area surveying, but accurate direct object-level measurement remains difficult in complex natural scenes. Recent advancements in 3D vision, particularly learned radiance-field representations such as NeRF and 3D Gaussian Splatting, have begun to raise the ceiling on reconstruction fidelity and densifiable geometry from posed imagery. Nevertheless, direct aerial measurement of important natural attributes such as tree diameter at breast height (DBH) remains challenging. Trunks in aerial forest scans are distant and sparsely observed in image views: at typical operating altitudes, stems may span only a few pixels. With these constraints, conventional reconstruction methods leave breast-height trunk geometry weakly constrained. We present TreeDGS, an aerial image reconstruction method that leverages 3D Gaussian Splatting as a continuous, densifiable scene representation for trunk measurement. After SfM-MVS initialization and Gaussian optimization, we extract a dense point set from the Gaussian field using RaDe-GS's depth-aware cumulative-opacity integration and associate each sample with a multi-view opacity reliability score. We then estimate DBH from trunk-isolated points using opacity-weighted solid-circle fitting. Evaluated on 10 plots with field-measured DBH, TreeDGS reaches 4.79,cm RMSE (about 2.6 pixels at this GSD) and outperforms a state-of-the-art LiDAR baseline (7.91,cm RMSE), demonstrating that densified splat-based geometry can enable accurate, low-cost aerial DBH measurement.

</details>


### [146] [Seeing Isn't Always Believing: Analysis of Grad-CAM Faithfulness and Localization Reliability in Lung Cancer CT Classification](https://arxiv.org/abs/2601.12826)
*Teerapong Panboonyuen*

Main category: cs.CV

TL;DR: 研究发现Grad-CAM在医学影像解释中存在局限性，特别是在视觉Transformer模型中表现不佳，揭示了当前显著性解释方法的可靠性问题


<details>
  <summary>Details</summary>
Motivation: 尽管Grad-CAM等XAI技术在医学影像分析中被广泛使用，但其解释的忠实性和可靠性仍受到质疑。本研究旨在探究Grad-CAM是否真正反映了深度学习模型在肺癌图像分类中的内部决策过程

Method: 使用IQ-OTH/NCCD公开数据集，评估了五种代表性架构：ResNet-50、ResNet-101、DenseNet-161、EfficientNet-B0和ViT-Base-Patch16-224。提出了一个定量评估框架，结合定位准确性、基于扰动的忠实性和解释一致性来评估Grad-CAM在不同架构中的可靠性

Result: 实验发现：1) Grad-CAM在大多数卷积网络中能有效突出肿瘤区域；2) 在视觉Transformer模型中解释忠实性显著下降，归因于非局部注意力行为；3) 跨模型比较显示显著性定位存在显著差异，表明Grad-CAM解释可能并不总是对应网络使用的真实诊断证据

Conclusion: 本研究揭示了当前基于显著性的XAI方法在医学影像中的关键局限性，强调需要开发既计算可靠又具有临床意义的模型感知解释方法。研究结果旨在促进医学AI中视觉解释工具的更谨慎和严格采用，促使社区重新思考"信任"模型解释的真正含义

Abstract: Explainable Artificial Intelligence (XAI) techniques, such as Gradient-weighted Class Activation Mapping (Grad-CAM), have become indispensable for visualizing the reasoning process of deep neural networks in medical image analysis. Despite their popularity, the faithfulness and reliability of these heatmap-based explanations remain under scrutiny. This study critically investigates whether Grad-CAM truly represents the internal decision-making of deep models trained for lung cancer image classification. Using the publicly available IQ-OTH/NCCD dataset, we evaluate five representative architectures: ResNet-50, ResNet-101, DenseNet-161, EfficientNet-B0, and ViT-Base-Patch16-224, to explore model-dependent variations in Grad-CAM interpretability. We introduce a quantitative evaluation framework that combines localization accuracy, perturbation-based faithfulness, and explanation consistency to assess Grad-CAM reliability across architectures. Experimental findings reveal that while Grad-CAM effectively highlights salient tumor regions in most convolutional networks, its interpretive fidelity significantly degrades for Vision Transformer models due to non-local attention behavior. Furthermore, cross-model comparisons indicate substantial variability in saliency localization, implying that Grad-CAM explanations may not always correspond to the true diagnostic evidence used by the networks. This work exposes critical limitations of current saliency-based XAI approaches in medical imaging and emphasizes the need for model-aware interpretability methods that are both computationally sound and clinically meaningful. Our findings aim to inspire a more cautious and rigorous adoption of visual explanation tools in medical AI, urging the community to rethink what it truly means to "trust" a model's explanation.

</details>


### [147] [FGTBT: Frequency-Guided Task-Balancing Transformer for Unified Facial Landmark Detection](https://arxiv.org/abs/2601.12863)
*Jun Wan,Xinyu Xiong,Ning Chen,Zhihui Lai,Jie Zhou,Wenwen Min*

Main category: cs.CV

TL;DR: 本文提出FGTBT框架，通过频率引导任务平衡Transformer解决面部关键点检测在挑战性场景下的性能下降问题，使用细粒度多任务平衡损失和频率引导结构感知模型提升面部结构感知能力。


<details>
  <summary>Details</summary>
Motivation: 当前基于深度学习的面部关键点检测方法在姿态变化大、光照变化、表情变化等挑战性场景下难以准确捕捉面部几何结构，导致性能下降。同时，现有数据集规模有限且多样性不足，限制了模型的鲁棒性训练。

Method: 提出频率引导任务平衡Transformer框架，包含两个核心组件：1) 细粒度多任务平衡损失，基于各关键点在数据集中的出现频率为单个关键点分配权重，实现更有效的统一训练；2) 频率引导结构感知模型，利用频率引导的结构注入和正则化来学习面部结构约束。

Result: 在多个流行基准数据集上的实验结果表明，将FMB-loss和FGSA模型集成到FGTBT框架中，取得了与最先进方法相当的性能。

Conclusion: 提出的FGTBT框架通过频率域建模和多数据集统一训练增强了面部结构感知能力，解决了面部关键点检测在挑战性场景下的性能问题，代码已开源。

Abstract: Recently, deep learning based facial landmark detection (FLD) methods have achieved considerable success. However, in challenging scenarios such as large pose variations, illumination changes, and facial expression variations, they still struggle to accurately capture the geometric structure of the face, resulting in performance degradation. Moreover, the limited size and diversity of existing FLD datasets hinder robust model training, leading to reduced detection accuracy. To address these challenges, we propose a Frequency-Guided Task-Balancing Transformer (FGTBT), which enhances facial structure perception through frequency-domain modeling and multi-dataset unified training. Specifically, we propose a novel Fine-Grained Multi-Task Balancing loss (FMB-loss), which moves beyond coarse task-level balancing by assigning weights to individual landmarks based on their occurrence across datasets. This enables more effective unified training and mitigates the issue of inconsistent gradient magnitudes. Additionally, a Frequency-Guided Structure-Aware (FGSA) model is designed to utilize frequency-guided structure injection and regularization to help learn facial structure constraints. Extensive experimental results on popular benchmark datasets demonstrate that the integration of the proposed FMB-loss and FGSA model into our FGTBT framework achieves performance comparable to state-of-the-art methods. The code is available at https://github.com/Xi0ngxinyu/FGTBT.

</details>


### [148] [Proxy Robustness in Vision Language Models is Effortlessly Transferable](https://arxiv.org/abs/2601.12865)
*Xiaowei Fu,Fuxiang Huang,Lei Zhang*

Main category: cs.CV

TL;DR: 提出HPT-GPD方法，通过异构代理转移框架实现视觉语言模型的对抗鲁棒性蒸馏，同时保持零样本泛化能力


<details>
  <summary>Details</summary>
Motivation: 传统对抗鲁棒性蒸馏方法在应用于视觉语言模型（如CLIP）时面临计算资源过高的问题，需要寻找更高效的鲁棒性转移方法

Method: 提出异构代理转移（HPT）框架，利用不同架构CLIP模型之间的内在防御能力建立鲁棒性蒸馏通道；设计泛化-枢轴解耦（GPD）策略，通过不同的学习率调度将代理转移过程分解为保持泛化的预热阶段和提升对抗鲁棒性的HPT阶段

Result: 在15个零样本数据集上的实验证明了HPT-GPD方法的有效性，能够在保持自然泛化能力的同时提升对抗鲁棒性

Conclusion: 该方法成功解决了视觉语言模型对抗鲁棒性转移中的计算资源问题和泛化能力下降问题，为大规模多模态模型的鲁棒性提升提供了高效解决方案

Abstract: As a pivotal technique for improving the defense of deep models, adversarial robustness transfer via distillation has demonstrated remarkable success in conventional image classification tasks. However, this paradigm encounters critical challenges when applied to vision-language models (VLM) (e.g., CLIP): constructing adversarially robust teacher for large-scale multi-modal models demands prohibitively high computational resources. We bridge this gap by revealing an interesting phenomenon: vanilla CLIP (without adversarial training) exhibits intrinsic defensive capabilities against adversarial examples generated by another CLIP with different architectures. We formally define this as proxy adversarial robustness, and naturally propose a Heterogeneous Proxy Transfer (HPT) framework that establishes cross-architectural robustness distillation channels between CLIP variants, effortlessly enabling the VLM robustness transfer from proxy to target models. Yet, such proxy transfer paradigm easily induces severe overfitting, leading to a sharp degradation in zero-shot natural generalization. To resolve that, we design Generalization-Pivot Decoupling (GPD) by leveraging the difference in learning rate scheduling. This decouples the proxy transfer process into a generalization-anchored warm-up that maintains generalization and a generalization-pulled HPT that promotes adversarial robustness, to achieve an equilibrium between natural generalization and adversarial robustness. Extensive experiments on 15 zero-shot datasets demonstrate the effectiveness of our HPT-GPD method. The code is available at the website of github.com/fxw13/HPT-GPD.

</details>


### [149] [Exploring Talking Head Models With Adjacent Frame Prior for Speech-Preserving Facial Expression Manipulation](https://arxiv.org/abs/2601.12876)
*Zhenxuan Lu,Zhihua Xu,Zhijing Yang,Feng Gao,Yongyi Lu,Keze Wang,Tianshui Chen*

Main category: cs.CV

TL;DR: 提出THFEM框架，整合音频驱动说话头生成模型与表情保持技术，通过相邻帧学习策略提升表情操纵时的唇形同步质量


<details>
  <summary>Details</summary>
Motivation: 现有SPFEM技术在表情操纵时难以保持准确的唇形同步，而音频驱动说话头生成模型擅长生成精确的唇部运动，因此探索将两者结合以改善表情操纵效果

Method: 提出THFEM框架：1) 使用AD-THG模型从音频输入和SPFEM处理图像生成唇形同步的帧；2) 开发相邻帧学习策略，微调AD-THG模型以预测连续帧序列，利用相邻帧信息提升图像质量

Result: 实验证明该框架能有效保持表情操纵时的唇形，整合AD-THG与SPFEM带来显著优势，相邻帧学习策略显著提升测试时的图像质量

Conclusion: THFEM框架成功解决了SPFEM中的唇形同步问题，通过整合音频驱动说话头生成模型和相邻帧学习策略，实现了表情操纵时更自然的唇部运动保持

Abstract: Speech-Preserving Facial Expression Manipulation (SPFEM) is an innovative technique aimed at altering facial expressions in images and videos while retaining the original mouth movements. Despite advancements, SPFEM still struggles with accurate lip synchronization due to the complex interplay between facial expressions and mouth shapes. Capitalizing on the advanced capabilities of audio-driven talking head generation (AD-THG) models in synthesizing precise lip movements, our research introduces a novel integration of these models with SPFEM. We present a new framework, Talking Head Facial Expression Manipulation (THFEM), which utilizes AD-THG models to generate frames with accurately synchronized lip movements from audio inputs and SPFEM-altered images. However, increasing the number of frames generated by AD-THG models tends to compromise the realism and expression fidelity of the images. To counter this, we develop an adjacent frame learning strategy that finetunes AD-THG models to predict sequences of consecutive frames. This strategy enables the models to incorporate information from neighboring frames, significantly improving image quality during testing. Our extensive experimental evaluations demonstrate that this framework effectively preserves mouth shapes during expression manipulations, highlighting the substantial benefits of integrating AD-THG with SPFEM.

</details>


### [150] [YOLO26: An Analysis of NMS-Free End to End Framework for Real-Time Object Detection](https://arxiv.org/abs/2601.12882)
*Sudip Chakrabarty*

Main category: cs.CV

TL;DR: YOLO26通过消除NMS后处理，采用端到端学习策略，在推理速度和检测精度上超越了YOLO系列及其他SOTA方法，建立了新的帕累托前沿。


<details>
  <summary>Details</summary>
Motivation: 传统YOLO系列（YOLOv1到YOLO11）受到非极大值抑制（NMS）后处理的延迟和超参数敏感性的限制，需要在延迟和精度之间做出权衡。

Method: 1. 消除NMS，采用原生端到端学习策略；2. 引入MuSGD优化器稳定轻量级骨干网络；3. 使用STAL进行小目标感知分配；4. 采用ProgLoss进行动态监督。

Result: YOLO26在官方性能基准测试中超越了包括RTMDet和DAMO-YOLO在内的众多前代方法和SOTA竞争对手，在推理速度和检测精度上建立了新的帕累托前沿。

Conclusion: 通过将表示学习与启发式后处理解耦，YOLO26成功解决了延迟与精度之间的历史权衡，标志着边缘计算机视觉的下一个进化步骤。

Abstract: The "You Only Look Once" (YOLO) framework has long served as the benchmark for real-time object detection, yet traditional iterations (YOLOv1 through YOLO11) remain constrained by the latency and hyperparameter sensitivity of Non-Maximum Suppression (NMS) post-processing. This paper analyzes a comprehensive analysis of YOLO26, an architecture that fundamentally redefines this paradigm by eliminating NMS in favor of a native end-to-end learning strategy. This study examines the critical innovations that enable this transition, specifically the introduction of the MuSGD optimizer for stabilizing lightweight backbones, STAL for small-target-aware assignment, and ProgLoss for dynamic supervision. Through a systematic review of official performance benchmarks, the results demonstrate that YOLO26 establishes a new Pareto front, outperforming a comprehensive suite of predecessors and state-of-the-art competitors (including RTMDet and DAMO-YOLO) in both inference speed and detection accuracy. The analysis confirms that by decoupling representation learning from heuristic post-processing, YOLOv26 successfully resolves the historical trade-off between latency and precision, signaling the next evolutionary step in edge-based computer vision.

</details>


### [151] [Simultaneous Detection of LSD and FMD in Cattle Using Ensemble Deep Learning](https://arxiv.org/abs/2601.12889)
*Nazibul Basar Ayon,Abdul Hasib,Md. Faishal Ahmed,Md. Sadiqur Rahman,Kamrul Islam,T. M. Mehrab Hasan,A. S. M. Ahsanul Sarkar Akib*

Main category: cs.CV

TL;DR: 提出集成深度学习框架，结合VGG16、ResNet50和InceptionV3模型，通过优化加权平均实现牛结节性皮肤病和口蹄疫的同时检测，准确率达98.2%，解决症状重叠的诊断难题。


<details>
  <summary>Details</summary>
Motivation: 牛结节性皮肤病(LSD)和口蹄疫(FMD)是高度传染性病毒疾病，造成重大经济损失。视觉诊断因症状重叠（包括彼此之间以及与良性病症如昆虫叮咬或化学烧伤）而复杂化，阻碍及时控制措施。

Method: 使用来自印度、巴西和美国18个农场的10,516张专家标注图像数据集，提出集成深度学习框架，整合VGG16、ResNet50和InceptionV3模型，采用优化加权平均方法进行LSD和FMD同时检测。

Result: 模型达到最先进的98.2%准确率，宏平均精确率98.2%、召回率98.1%、F1分数98.1%、AUC-ROC 99.5%，有效解决多疾病检测中的症状重叠挑战。

Conclusion: 该框架能够实现早期、精确和自动化的疾病诊断，有潜力增强疾病管理，支持全球农业可持续性，并设计用于未来在资源有限环境中的部署。

Abstract: Lumpy Skin Disease (LSD) and Foot-and-Mouth Disease (FMD) are highly contagious viral diseases affecting cattle, causing significant economic losses and welfare challenges. Their visual diagnosis is complicated by significant symptom overlap with each other and with benign conditions like insect bites or chemical burns, hindering timely control measures. Leveraging a comprehensive dataset of 10,516 expert-annotated images from 18 farms across India, Brazil, and the USA, this study presents a novel Ensemble Deep Learning framework integrating VGG16, ResNet50, and InceptionV3 with optimized weighted averaging for simultaneous LSD and FMD detection. The model achieves a state-of-the-art accuracy of 98.2\%, with macro-averaged precision of 98.2\%, recall of 98.1\%, F1-score of 98.1\%, and an AUC-ROC of 99.5\%. This approach uniquely addresses the critical challenge of symptom overlap in multi-disease detection, enabling early, precise, and automated diagnosis. This tool has the potential to enhance disease management, support global agricultural sustainability, and is designed for future deployment in resource-limited settings.

</details>


### [152] [TwoHead-SwinFPN: A Unified DL Architecture for Synthetic Manipulation, Detection and Localization in Identity Documents](https://arxiv.org/abs/2601.12895)
*Chan Naseeb,Adeel Ashraf Cheema,Hassan Sami,Tayyab Afzal,Muhammad Omair,Usman Habib*

Main category: cs.CV

TL;DR: TwoHead-SwinFPN：一种用于身份证件防伪检测的统一深度学习架构，同时进行篡改分类和区域定位，在FantasyIDiap数据集上取得优异性能。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI模型的普及，身份证件面临面部替换和文本修复等合成篡改威胁，需要有效的检测和定位方法。

Method: 提出TwoHead-SwinFPN架构，集成Swin Transformer骨干网络、特征金字塔网络（FPN）和UNet风格解码器，采用CBAM注意力模块增强特征表示，使用双头架构进行联合优化，通过不确定性加权多任务学习。

Result: 在FantasyIDiap数据集上取得84.31%准确率、90.78% AUC（分类）和57.24%平均Dice分数（定位），F1分数88.61%，计算效率高，支持10种语言和3种采集设备。

Conclusion: TwoHead-SwinFPN是一种有效的身份证件防伪检测解决方案，能够同时准确检测篡改并定位篡改区域，适合实际部署应用。

Abstract: The proliferation of sophisticated generative AI models has significantly escalated the threat of synthetic manipulations in identity documents, particularly through face swapping and text inpainting attacks. This paper presents TwoHead-SwinFPN, a unified deep learning architecture that simultaneously performs binary classification and precise localization of manipulated regions in ID documents. Our approach integrates a Swin Transformer backbone with Feature Pyramid Network (FPN) and UNet-style decoder, enhanced with Convolutional Block Attention Module (CBAM) for improved feature representation. The model employs a dual-head architecture for joint optimization of detection and segmentation tasks, utilizing uncertainty-weighted multi-task learning. Extensive experiments on the FantasyIDiap dataset demonstrate superior performance with 84.31\% accuracy, 90.78\% AUC for classification, and 57.24\% mean Dice score for localization. The proposed method achieves an F1-score of 88.61\% for binary classification while maintaining computational efficiency suitable for real-world deployment through FastAPI implementation. Our comprehensive evaluation includes ablation studies, cross-device generalization analysis, and detailed performance assessment across 10 languages and 3 acquisition devices.

</details>


### [153] [Supervision-by-Hallucination-and-Transfer: A Weakly-Supervised Approach for Robust and Precise Facial Landmark Detection](https://arxiv.org/abs/2601.12919)
*Jun Wan,Yuanzhi Yao,Zhihui Lai,Jie Zhou,Xianxu Hou,Wenwen Min*

Main category: cs.CV

TL;DR: 提出SHT弱监督框架，通过面部幻觉和姿态迁移任务提升低分辨率人脸图像的关键点检测精度


<details>
  <summary>Details</summary>
Motivation: 低分辨率人脸图像或特征压缩会降低面部关键点检测精度，同时训练数据不足和标注不精确进一步影响性能

Method: 提出SHT框架，包含两个相互增强模块：DHLN（双幻觉学习网络）通过面部关键点检测和幻觉任务学习高分辨率表示；FPTN（面部姿态迁移网络）通过姿态变换进一步优化关键点热图和幻觉人脸

Result: 实验结果表明，该方法在面部幻觉和关键点检测任务上均超越了现有最先进技术

Conclusion: 这是首个通过整合面部幻觉和姿态迁移任务探索弱监督面部关键点检测的研究，证明了该方法的有效性

Abstract: High-precision facial landmark detection (FLD) relies on high-resolution deep feature representations. However, low-resolution face images or the compression (via pooling or strided convolution) of originally high-resolution images hinder the learning of such features, thereby reducing FLD accuracy. Moreover, insufficient training data and imprecise annotations further degrade performance. To address these challenges, we propose a weakly-supervised framework called Supervision-by-Hallucination-and-Transfer (SHT) for more robust and precise FLD. SHT contains two novel mutually enhanced modules: Dual Hallucination Learning Network (DHLN) and Facial Pose Transfer Network (FPTN). By incorporating FLD and face hallucination tasks, DHLN is able to learn high-resolution representations with low-resolution inputs for recovering both facial structures and local details and generating more effective landmark heatmaps. Then, by transforming faces from one pose to another, FPTN can further improve landmark heatmaps and faces hallucinated by DHLN for detecting more accurate landmarks. To the best of our knowledge, this is the first study to explore weakly-supervised FLD by integrating face hallucination and facial pose transfer tasks. Experimental results of both face hallucination and FLD demonstrate that our method surpasses state-of-the-art techniques.

</details>


### [154] [Dual-Stream Collaborative Transformer for Image Captioning](https://arxiv.org/abs/2601.12926)
*Jun Wan,Jun Liu,Zhihui lai,Jie Zhou*

Main category: cs.CV

TL;DR: 提出DSCT模型，通过融合区域特征和分割特征解决图像描述生成中的上下文信息不足问题，实现更准确、描述性更强的字幕生成。


<details>
  <summary>Details</summary>
Motivation: 当前基于区域特征的图像描述方法虽然进展迅速，但仍容易生成不相关的描述，主要原因是缺乏上下文信息以及过度依赖已生成的部分描述来预测剩余词汇。

Method: 提出双流协作Transformer（DSCT），引入分割特征并与区域特征融合。包含多个模式特定互注意力编码器（PSMAE）和动态提名解码器（DND）。PSMAE通过相互查询有效突出和整合两种表示的私有信息；DND动态搜索与输入文本表示最相关的学习块，并利用整合后的区域和分割特征之间的同质特征生成更准确的描述句子。

Result: 在流行基准数据集上的实验结果表明，DSCT优于文献中最先进的图像描述模型。

Conclusion: 这是首个探索如何以动态方式融合不同模式特定特征以绕过其语义不一致和空间错位问题的研究，为图像描述任务提供了更有效的解决方案。

Abstract: Current region feature-based image captioning methods have progressed rapidly and achieved remarkable performance. However, they are still prone to generating irrelevant descriptions due to the lack of contextual information and the over-reliance on generated partial descriptions for predicting the remaining words. In this paper, we propose a Dual-Stream Collaborative Transformer (DSCT) to address this issue by introducing the segmentation feature. The proposed DSCT consolidates and then fuses the region and segmentation features to guide the generation of caption sentences. It contains multiple Pattern-Specific Mutual Attention Encoders (PSMAEs) and Dynamic Nomination Decoders (DNDs). The PSMAE effectively highlights and consolidates the private information of two representations by querying each other. The DND dynamically searches for the most relevant learning blocks to the input textual representations and exploits the homogeneous features between the consolidated region and segmentation features to generate more accurate and descriptive caption sentences. To the best of our knowledge, this is the first study to explore how to fuse different pattern-specific features in a dynamic way to bypass their semantic inconsistencies and spatial misalignment issues for image captioning. The experimental results from popular benchmark datasets demonstrate that our DSCT outperforms the state-of-the-art image captioning models in the literature.

</details>


### [155] [Membership Inference Test: Auditing Training Data in Object Classification Models](https://arxiv.org/abs/2601.12929)
*Gonzalo Mancera,Daniel DeAlcala,Aythami Morales,Ruben Tolosana,Julian Fierrez*

Main category: cs.CV

TL;DR: 该研究提出针对目标识别领域的成员推断测试（MINT）架构，通过卷积层建模训练过程中的激活模式，在三个公开数据库上实现70-80%的精度来识别数据是否用于训练。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决目标识别领域中成员推断测试（MINT）的性能问题，即确定给定数据是否在训练阶段被使用。当前MINT方法在目标识别这一复杂领域缺乏专门优化的架构，需要开发针对性的解决方案来提高数据利用效率和性能。

Method: 方法包括：1）提出专门针对目标识别领域的MINT架构；2）使用卷积层来捕获和建模训练过程中的数据激活模式；3）构建包含目标检测模型、嵌入提取器和MINT模块的实验系统；4）在三个公开数据库（总计超过17.4万张图像）上进行实验；5）分析不同检测模块层深度对MINT性能的影响。

Result: 实验结果：1）能够识别用于测试和训练的数据；2）达到70-80%的精度范围，具体取决于输入MINT模块的检测模块层深度；3）分析了影响MINT模块性能的因素；4）深入探讨了训练过程透明化的贡献因素。

Conclusion: 结论：提出的专门针对目标识别领域的MINT架构能够有效识别数据是否用于训练，精度达到70-80%。研究不仅提供了性能优化的解决方案，还深入分析了影响MINT性能的因素，为训练过程透明化提供了重要见解。

Abstract: In this research, we analyze the performance of Membership Inference Tests (MINT), focusing on determining whether given data were utilized during the training phase, specifically in the domain of object recognition. Within the area of object recognition, we propose and develop architectures tailored for MINT models. These architectures aim to optimize performance and efficiency in data utilization, offering a tailored solution to tackle the complexities inherent in the object recognition domain. We conducted experiments involving an object detection model, an embedding extractor, and a MINT module. These experiments were performed in three public databases, totaling over 174K images. The proposed architecture leverages convolutional layers to capture and model the activation patterns present in the data during the training process. Through our analysis, we are able to identify given data used for testing and training, achieving precision rates ranging between 70% and 80%, contingent upon the depth of the detection module layer chosen for input to the MINT module. Additionally, our studies entail an analysis of the factors influencing the MINT Module, delving into the contributing elements behind more transparent training processes.

</details>


### [156] [QASA: Quality-Guided K-Adaptive Slot Attention for Unsupervised Object-Centric Learning](https://arxiv.org/abs/2601.12936)
*Tianran Ouyang,Xingping Dong,Jing Zhang,Mang Ye,Jun Chen,Bo Du*

Main category: cs.CV

TL;DR: QASA提出质量引导的K自适应槽注意力，通过解耦槽选择与重建、设计槽质量度量、质量引导槽选择机制，显著提升K自适应方法的性能，甚至超越K固定方法。


<details>
  <summary>Details</summary>
Motivation: 现有K自适应方法存在两个主要问题：1) 没有明确约束槽绑定质量，导致低质量槽产生模糊特征归属；2) 在重建目标中添加槽数量惩罚会造成减少活跃槽数量与保持重建保真度之间的优化目标冲突。这些问题导致现有K自适应方法性能显著落后于K固定基线。

Method: 1) 解耦槽选择与重建，消除两个目标间的相互约束；2) 提出无监督的槽质量度量来评估每个槽的质量，为细粒度槽-对象绑定提供原则性信号；3) 基于该度量设计质量引导的槽选择方案，动态选择高质量槽子集，输入新设计的门控解码器进行训练重建；4) 推理时通过槽注意力上的令牌级竞争获得K自适应结果。

Result: 实验表明，QASA在真实和合成数据集上都显著优于现有K自适应方法。更重要的是，在真实世界数据集上，QASA甚至超越了K固定方法。

Conclusion: 通过解耦槽选择与重建、引入槽质量度量、设计质量引导的槽选择机制，QASA成功解决了现有K自适应方法的局限性，实现了在动态对象基数场景下的高性能对象中心学习。

Abstract: Slot Attention, an approach that binds different objects in a scene to a set of "slots", has become a leading method in unsupervised object-centric learning. Most methods assume a fixed slot count K, and to better accommodate the dynamic nature of object cardinality, a few works have explored K-adaptive variants. However, existing K-adaptive methods still suffer from two limitations. First, they do not explicitly constrain slot-binding quality, so low-quality slots lead to ambiguous feature attribution. Second, adding a slot-count penalty to the reconstruction objective creates conflicting optimization goals between reducing the number of active slots and maintaining reconstruction fidelity. As a result, they still lag significantly behind strong K-fixed baselines. To address these challenges, we propose Quality-Guided K-Adaptive Slot Attention (QASA). First, we decouple slot selection from reconstruction, eliminating the mutual constraints between the two objectives. Then, we propose an unsupervised Slot-Quality metric to assess per-slot quality, providing a principled signal for fine-grained slot--object binding. Based on this metric, we design a Quality-Guided Slot Selection scheme that dynamically selects a subset of high-quality slots and feeds them into our newly designed gated decoder for reconstruction during training. At inference, token-wise competition on slot attention yields a K-adaptive outcome. Experiments show that QASA substantially outperforms existing K-adaptive methods on both real and synthetic datasets. Moreover, on real-world datasets QASA surpasses K-fixed methods.

</details>


### [157] [GazeD: Context-Aware Diffusion for Accurate 3D Gaze Estimation](https://arxiv.org/abs/2601.12948)
*Riccardo Catalini,Davide Di Nucci,Guido Borghi,Davide Davoli,Lorenzo Garattoni,Giampiero Francesca,Yuki Kawana,Roberto Vezzani*

Main category: cs.CV

TL;DR: GazeD：基于扩散模型的单张RGB图像3D视线与人体姿态联合估计方法


<details>
  <summary>Details</summary>
Motivation: 现有方法通常单独估计3D视线或人体姿态，忽略了二者之间的紧密关联。扩散模型能够处理不确定性，适合生成多模态的3D视线和姿态假设。

Method: 提出GazeD方法：1）将3D视线表示为距离眼睛固定距离的额外身体关节点；2）基于扩散模型，以2D姿态、人物周围环境和场景上下文为条件进行去噪；3）联合去噪生成多个合理的3D视线和姿态假设。

Result: 在三个基准数据集上的评估表明，GazeD在3D视线估计方面达到了最先进的性能，甚至超过了依赖时序信息的方法。

Conclusion: GazeD通过扩散模型联合估计3D视线和人体姿态，利用二者之间的关联性提升了估计精度，为单张RGB图像的3D视线估计提供了有效解决方案。

Abstract: We introduce GazeD, a new 3D gaze estimation method that jointly provides 3D gaze and human pose from a single RGB image. Leveraging the ability of diffusion models to deal with uncertainty, it generates multiple plausible 3D gaze and pose hypotheses based on the 2D context information extracted from the input image. Specifically, we condition the denoising process on the 2D pose, the surroundings of the subject, and the context of the scene. With GazeD we also introduce a novel way of representing the 3D gaze by positioning it as an additional body joint at a fixed distance from the eyes. The rationale is that the gaze is usually closely related to the pose, and thus it can benefit from being jointly denoised during the diffusion process. Evaluations across three benchmark datasets demonstrate that GazeD achieves state-of-the-art performance in 3D gaze estimation, even surpassing methods that rely on temporal information. Project details will be available at https://aimagelab.ing.unimore.it/go/gazed.

</details>


### [158] [StyMam: A Mamba-Based Generator for Artistic Style Transfer](https://arxiv.org/abs/2601.12954)
*Zhou Hong,Rongsheng Hu,Yicheng Di,Xiaolong Xu,Ning Dong,Yihua Shao,Run Ling,Yun Wang,Juqin Wang,Zhanjie Zhang,Ao Ma*

Main category: cs.CV

TL;DR: 提出基于Mamba的生成器StyMam，用于图像风格迁移，解决了现有GAN方法局部与全局依赖捕获不足导致的伪影问题，以及SD方法内容结构保持差、推理慢的问题。


<details>
  <summary>Details</summary>
Motivation: 现有图像风格迁移方法存在局限性：基于GAN的方法（使用CNN或Transformer）难以同时捕获局部和全局依赖，导致伪影和不协调模式；基于稳定扩散的方法虽然减少了这些问题，但往往无法保持内容结构且推理速度慢。

Method: 提出基于Mamba的生成器StyMam，包含残差双路径条带扫描机制和通道重加权空间注意力模块。前者高效捕获局部纹理特征，后者建模全局依赖关系。

Result: 广泛的定性和定量实验表明，该方法在质量和速度上都优于最先进的算法，能生成高质量的风格化图像而不引入伪影和不协调模式。

Conclusion: 重新审视GAN架构，通过Mamba-based生成器StyMam成功解决了图像风格迁移中的关键问题，实现了高质量、高效率的风格迁移效果。

Abstract: Image style transfer aims to integrate the visual patterns of a specific artistic style into a content image while preserving its content structure. Existing methods mainly rely on the generative adversarial network (GAN) or stable diffusion (SD). GAN-based approaches using CNNs or Transformers struggle to jointly capture local and global dependencies, leading to artifacts and disharmonious patterns. SD-based methods reduce such issues but often fail to preserve content structures and suffer from slow inference. To address these issues, we revisit GAN and propose a mamba-based generator, termed as StyMam, to produce high-quality stylized images without introducing artifacts and disharmonious patterns. Specifically, we introduce a mamba-based generator with a residual dual-path strip scanning mechanism and a channel-reweighted spatial attention module. The former efficiently captures local texture features, while the latter models global dependencies. Finally, extensive qualitative and quantitative experiments demonstrate that the proposed method outperforms state-of-the-art algorithms in both quality and speed.

</details>


### [159] [Cross-Scale Pretraining: Enhancing Self-Supervised Learning for Low-Resolution Satellite Imagery for Semantic Segmentation](https://arxiv.org/abs/2601.12964)
*John Waithaka,Gustave Bwirayesu,Moise Busogi*

Main category: cs.CV

TL;DR: 提出一种空间亲和性组件，可将高分辨率遥感图像融入自监督预训练，提升中分辨率图像表示学习和下游分割性能


<details>
  <summary>Details</summary>
Motivation: 目前遥感自监督预训练主要使用中分辨率图像数据集，但随着高分辨率数据集的出现，需要研究如何利用高分辨率数据来增强中分辨率图像的表示学习，提升下游分割任务性能

Method: 设计了一个空间亲和性组件，可以集成到现有的自监督学习框架中，利用高分辨率图像来学习中分辨率图像的更好表示

Result: 在两个自监督学习框架上测试了空间亲和性组件，结果显示它优于仅使用高分辨率或中分辨率图像单独预训练的模型

Conclusion: 通过空间亲和性组件将高分辨率图像融入自监督预训练，可以有效提升中分辨率图像的表示学习能力和下游分割任务性能

Abstract: Self-supervised pretraining in remote sensing is mostly done using mid-spatial resolution (MR) image datasets due to their high availability. Given the release of high-resolution (HR) datasets, we ask how HR datasets can be included in self-supervised pretraining to enhance MR image representation learning and downstream segmentation performance on MR tasks. We design a spatial affinity component that can be added to existing self-supervised learning frameworks and that uses HR imagery to learn better representations of MR imagery. We test the spatial affinity component on two self-supervised learning frameworks and show that it outperforms models pretrained on HR or MR images alone.

</details>


### [160] [Early Prediction of Type 2 Diabetes Using Multimodal data and Tabular Transformers](https://arxiv.org/abs/2601.12981)
*Sulaiman Khan,Md. Rafiul Biswas,Zubair Shah*

Main category: cs.CV

TL;DR: 提出基于表格Transformer（TabTrans）的早期2型糖尿病风险预测方法，整合电子健康记录和DXA骨密度数据，在卡塔尔生物银行队列上验证，性能优于传统机器学习和生成式AI模型。


<details>
  <summary>Details</summary>
Motivation: 传统方法难以捕捉疾病进展中的复杂长期依赖关系，需要开发能够处理纵向患者数据和表格数据的先进模型，以改善2型糖尿病的早期预测和个性化管理。

Method: 使用表格Transformer（TabTrans）架构处理纵向健康记录和骨相关表格数据，整合电子健康记录和DXA数据，采用SMOTE和SMOTE-ENN处理类别不平衡，并与传统ML和生成式AI模型（Claude 3.5 Sonnet、GPT-4、Gemini Pro）进行比较。

Result: TabTrans模型在T2DM预测中表现最佳，ROC AUC ≥ 79.7%，优于生成式AI模型和传统ML方法。特征解释分析识别出内脏脂肪组织质量/体积、ward骨密度/骨矿物质含量、T/Z分数、L1-L4评分等关键风险指标。

Conclusion: TabTrans在分析复杂表格医疗数据方面具有显著潜力，为卡塔尔人群的主动T2DM管理和个性化临床干预提供了有力工具，内脏脂肪和骨密度相关指标是糖尿病发展的关键预测因子。

Abstract: This study introduces a novel approach for early Type 2 Diabetes Mellitus (T2DM) risk prediction using a tabular transformer (TabTrans) architecture to analyze longitudinal patient data. By processing patients` longitudinal health records and bone-related tabular data, our model captures complex, long-range dependencies in disease progression that conventional methods often overlook. We validated our TabTrans model on a retrospective Qatar BioBank (QBB) cohort of 1,382 subjects, comprising 725 men (146 diabetic, 579 healthy) and 657 women (133 diabetic, 524 healthy). The study integrated electronic health records (EHR) with dual-energy X-ray absorptiometry (DXA) data. To address class imbalance, we employed SMOTE and SMOTE-ENN resampling techniques. The proposed model`s performance is evaluated against conventional machine learning (ML) and generative AI models, including Claude 3.5 Sonnet (Anthropic`s constitutional AI), GPT-4 (OpenAI`s generative pre-trained transformer), and Gemini Pro (Google`s multimodal language model). Our TabTrans model demonstrated superior predictive performance, achieving ROC AUC $\geq$ 79.7 % for T2DM prediction compared to both generative AI models and conventional ML approaches. Feature interpretation analysis identified key risk indicators, with visceral adipose tissue (VAT) mass and volume, ward bone mineral density (BMD) and bone mineral content (BMC), T and Z-scores, and L1-L4 scores emerging as the most important predictors associated with diabetes development in Qatari adults. These findings demonstrate the significant potential of TabTrans for analyzing complex tabular healthcare data, providing a powerful tool for proactive T2DM management and personalized clinical interventions in the Qatari population.
  Index Terms: tabular transformers, multimodal data, DXA data, diabetes, T2DM, feature interpretation, tabular data

</details>


### [161] [AsyncBEV: Cross-modal Flow Alignment in Asynchronous 3D Object Detection](https://arxiv.org/abs/2601.12994)
*Shiming Wang,Holger Caesar,Liangliang Nan,Julian F. P. Kooij*

Main category: cs.CV

TL;DR: AsyncBEV是一个可训练的轻量级模块，用于提高3D BEV目标检测模型对传感器异步的鲁棒性，通过估计特征流来对齐不同传感器模态的特征图。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中的多模态感知任务通常依赖同步良好的传感器，但实际中由于传感器频率不同、网络延迟、硬件故障等因素，完美同步很难保证，这种异步会降低感知性能，特别是对动态物体。

Method: 受场景流估计启发，AsyncBEV首先从两种不同传感器模态的BEV特征中估计2D流，考虑已知的时间偏移，然后使用预测的特征流来扭曲和对齐特征图，可集成到不同的BEV检测器架构中。

Result: 实验表明AsyncBEV提高了对LiDAR或相机传感器之间小和大异步的鲁棒性，在0.5秒时间偏移的最坏情况下，动态物体的NDS比基线分别提升了16.6%和11.9%。

Conclusion: AsyncBEV是一个有效且通用的解决方案，能够显著提高BEV检测器对传感器异步的鲁棒性，特别是在动态物体检测方面表现优异。

Abstract: In autonomous driving, multi-modal perception tasks like 3D object detection typically rely on well-synchronized sensors, both at training and inference. However, despite the use of hardware- or software-based synchronization algorithms, perfect synchrony is rarely guaranteed: Sensors may operate at different frequencies, and real-world factors such as network latency, hardware failures, or processing bottlenecks often introduce time offsets between sensors. Such asynchrony degrades perception performance, especially for dynamic objects. To address this challenge, we propose AsyncBEV, a trainable lightweight and generic module to improve the robustness of 3D Birds' Eye View (BEV) object detection models against sensor asynchrony. Inspired by scene flow estimation, AsyncBEV first estimates the 2D flow from the BEV features of two different sensor modalities, taking into account the known time offset between these sensor measurements. The predicted feature flow is then used to warp and spatially align the feature maps, which we show can easily be integrated into different current BEV detector architectures (e.g., BEV grid-based and token-based). Extensive experiments demonstrate AsyncBEV improves robustness against both small and large asynchrony between LiDAR or camera sensors in both the token-based CMT and grid-based UniBEV, especially for dynamic objects. We significantly outperform the ego motion compensated CMT and UniBEV baselines, notably by $16.6$ % and $11.9$ % NDS on dynamic objects in the worst-case scenario of a $0.5 s$ time offset. Code will be released upon acceptance.

</details>


### [162] [Think3D: Thinking with Space for Spatial Reasoning](https://arxiv.org/abs/2601.13029)
*Zaibin Zhang,Yuhan Wu,Lianjie Jia,Yifan Wang,Zhongbo Zhang,Yijiang Li,Binghao Ran,Fuxi Zhang,Zhuohan Sun,Zhenfei Yin,Lijun Wang,Huchuan Lu*

Main category: cs.CV

TL;DR: Think3D是一个无需额外训练即可增强视觉大模型3D空间推理能力的框架，通过3D重建和交互式空间操作，显著提升模型在空间推理任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 当前视觉大模型虽然擅长2D视觉理解，但缺乏真正的3D空间推理能力，无法理解和推理物理世界的几何、视角和空间关系。

Method: 利用3D重建模型从图像或视频恢复点云和相机姿态，通过相机操作和自我/全局视角切换实现交互式3D思维链推理，并为小模型引入强化学习策略选择信息丰富的视角和操作。

Result: Think3D显著提升了GPT-4.1和Gemini 2.5 Pro等先进模型的空间推理性能，在BLINK Multi-view和MindCube上平均提升7.8%，在VSI-Bench上提升4.7%。小模型通过强化学习策略，工具使用收益从0.7%提升到6.8%。

Conclusion: 无需训练的工具增强空间探索是实现更灵活、更类人3D推理的可行路径，为多模态智能建立了新的维度。

Abstract: Understanding and reasoning about the physical world requires spatial intelligence: the ability to interpret geometry, perspective, and spatial relations beyond 2D perception. While recent vision large models (VLMs) excel at visual understanding, they remain fundamentally 2D perceivers and struggle with genuine 3D reasoning. We introduce Think3D, a framework that enables VLM agents to think with 3D space. By leveraging 3D reconstruction models that recover point clouds and camera poses from images or videos, Think3D allows the agent to actively manipulate space through camera-based operations and ego/global-view switching, transforming spatial reasoning into an interactive 3D chain-of-thought process. Without additional training, Think3D significantly improves the spatial reasoning performance of advanced models such as GPT-4.1 and Gemini 2.5 Pro, yielding average gains of +7.8% on BLINK Multi-view and MindCube, and +4.7% on VSI-Bench. We further show that smaller models, which struggle with spatial exploration, benefit significantly from a reinforcement learning policy that enables the model to select informative viewpoints and operations. With RL, the benefit from tool usage increases from +0.7% to +6.8%. Our findings demonstrate that training-free, tool-augmented spatial exploration is a viable path toward more flexible and human-like 3D reasoning in multimodal agents, establishing a new dimension of multimodal intelligence. Code and weights are released at https://github.com/zhangzaibin/spagent.

</details>


### [163] [GridNet-HD: A High-Resolution Multi-Modal Dataset for LiDAR-Image Fusion on Power Line Infrastructure](https://arxiv.org/abs/2601.13052)
*Antoine Carreaud,Shanci Li,Malo De Lacour,Digre Frinde,Jan Skaloud,Adrien Gressin*

Main category: cs.CV

TL;DR: GridNet-HD是一个用于电力基础设施3D语义分割的多模态数据集，结合高密度LiDAR和高分辨率倾斜影像，包含7,694张图像和25亿个点，标注为11个类别，提供基准模型和代码。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏同时提供高密度LiDAR和高分辨率倾斜影像的公开数据集用于电力线路资产的3D语义标注，这限制了多模态融合方法在电力基础设施分析中的应用。

Method: 创建了GridNet-HD数据集，包含7,694张图像和25亿个LiDAR点，标注为11个语义类别，提供预定义的数据划分和mIoU评估指标，并建立了单模态（仅LiDAR、仅图像）和多模态融合的基准模型。

Result: 在多模态融合模型中，融合方法比最佳单模态基准模型提升了+5.55 mIoU，证明了几何信息（LiDAR）和外观信息（图像）的互补性。

Conclusion: GridNet-HD填补了电力基础设施多模态3D语义分割数据集的空白，展示了多模态融合在电力线路资产分析中的优势，数据集、基准模型和代码已公开。

Abstract: This paper presents GridNet-HD, a multi-modal dataset for 3D semantic segmentation of overhead electrical infrastructures, pairing high-density LiDAR with high-resolution oblique imagery. The dataset comprises 7,694 images and 2.5 billion points annotated into 11 classes, with predefined splits and mIoU metrics. Unimodal (LiDAR-only, image-only) and multi-modal fusion baselines are provided. On GridNet-HD, fusion models outperform the best unimodal baseline by +5.55 mIoU, highlighting the complementarity of geometry and appearance. As reviewed in Sec. 2, no public dataset jointly provides high-density LiDAR and high-resolution oblique imagery with 3D semantic labels for power-line assets. Dataset, baselines, and codes are available: https://huggingface.co/collections/heig-vd-geo/gridnet-hd.

</details>


### [164] [Prototype Learning-Based Few-Shot Segmentation for Low-Light Crack on Concrete Structures](https://arxiv.org/abs/2601.13059)
*Yulun Guo*

Main category: cs.CV

TL;DR: 提出一种结合Retinex理论和少样本学习的双分支原型学习网络，用于低光照条件下的裂缝分割，通过反射分量引导光照不变表示学习，减少对大规模标注数据的依赖。


<details>
  <summary>Details</summary>
Motivation: 混凝土基础设施裂缝检测在低光照环境（如隧道、桥底）中至关重要，但现有计算机视觉方法在低光照条件下分割精度下降，且像素级标注耗时费力，大多数深度学习方法需要大规模良好光照数据集。

Method: 提出双分支原型学习网络：1）基于Retinex理论的反射分量引导光照不变全局表示学习；2）度量学习减少对大规模标注数据的依赖；3）交叉相似性先验掩码生成模块计算查询和支持特征的高维相似性以捕捉裂缝位置和结构；4）多尺度特征增强模块融合多尺度特征与先验掩码以缓解空间不一致性。

Result: 在多个基准测试上的广泛实验表明，该方法在低光照条件下实现了持续的最先进性能。

Conclusion: 提出的方法有效解决了低光照环境下裂缝分割的挑战，通过结合Retinex理论和少样本学习，实现了光照不变表示和减少标注数据依赖，为实际基础设施检测提供了实用解决方案。

Abstract: Crack detection is critical for concrete infrastructure safety, but real-world cracks often appear in low-light environments like tunnels and bridge undersides, degrading computer vision segmentation accuracy. Pixel-level annotation of low-light crack images is extremely time-consuming, yet most deep learning methods require large, well-illuminated datasets. We propose a dual-branch prototype learning network integrating Retinex theory with few-shot learning for low-light crack segmentation. Retinex-based reflectance components guide illumination-invariant global representation learning, while metric learning reduces dependence on large annotated datasets. We introduce a cross-similarity prior mask generation module that computes high-dimensional similarities between query and support features to capture crack location and structure, and a multi-scale feature enhancement module that fuses multi-scale features with the prior mask to alleviate spatial inconsistency. Extensive experiments on multiple benchmarks demonstrate consistent state-of-the-art performance under low-light conditions. Code: https://github.com/YulunGuo/CrackFSS.

</details>


### [165] [Patient-Conditioned Adaptive Offsets for Reliable Diagnosis across Subgroups](https://arxiv.org/abs/2601.13094)
*Gelei Xu,Yuying Duan,Jun Xia,Ruining Deng,Wei Jin,Yiyu Shi*

Main category: cs.CV

TL;DR: HyperAdapt是一个患者条件适应框架，通过超网络风格模块生成残差调制参数，在保持共享诊断模型的同时提高亚组可靠性，解决医疗AI模型在不同患者群体中性能不均的问题。


<details>
  <summary>Details</summary>
Motivation: 医疗AI模型在不同患者群体中表现出不均匀的性能，现有公平性方法通过抑制敏感属性来减少差异，但这在医疗环境中会丢失重要的诊断信息，降低准确性和可靠性。临床决策明确纳入患者背景来解释诊断证据，这为亚组感知模型提供了不同的设计方向。

Method: 提出HyperAdapt患者条件适应框架：将年龄、性别等临床相关属性编码为紧凑嵌入，用于调节超网络风格模块，该模块为共享骨干网络的选定层生成小型残差调制参数。通过低秩和瓶颈参数化约束适应，限制模型复杂性和计算开销。

Result: 在多个公共医疗影像基准测试中，该方法持续提高亚组级别性能而不牺牲整体准确性。在PAD-UFES-20数据集上，比最强竞争基线在召回率上高出4.1%，F1分数高出4.4%，对代表性不足的患者群体观察到更大增益。

Conclusion: HyperAdapt框架通过患者条件适应，在保持共享诊断模型的同时提高亚组可靠性，为医疗AI模型提供了一种有效处理患者群体异质性的方法，既保留了敏感属性的诊断信息，又改善了公平性表现。

Abstract: AI models for medical diagnosis often exhibit uneven performance across patient populations due to heterogeneity in disease prevalence, imaging appearance, and clinical risk profiles. Existing algorithmic fairness approaches typically seek to reduce such disparities by suppressing sensitive attributes. However, in medical settings these attributes often carry essential diagnostic information, and removing them can degrade accuracy and reliability, particularly in high-stakes applications. In contrast, clinical decision making explicitly incorporates patient context when interpreting diagnostic evidence, suggesting a different design direction for subgroup-aware models. In this paper, we introduce HyperAdapt, a patient-conditioned adaptation framework that improves subgroup reliability while maintaining a shared diagnostic model. Clinically relevant attributes such as age and sex are encoded into a compact embedding and used to condition a hypernetwork-style module, which generates small residual modulation parameters for selected layers of a shared backbone. This design preserves the general medical knowledge learned by the backbone while enabling targeted adjustments that reflect patient-specific variability. To ensure efficiency and robustness, adaptations are constrained through low-rank and bottlenecked parameterizations, limiting both model complexity and computational overhead. Experiments across multiple public medical imaging benchmarks demonstrate that the proposed approach consistently improves subgroup-level performance without sacrificing overall accuracy. On the PAD-UFES-20 dataset, our method outperforms the strongest competing baseline by 4.1% in recall and 4.4% in F1 score, with larger gains observed for underrepresented patient populations.

</details>


### [166] [A Streamlined Attention-Based Network for Descriptor Extraction](https://arxiv.org/abs/2601.13126)
*Mattia D'Urso,Emanuele Santellani,Christian Sormann,Mattia Rossi,Andreas Kuhn,Friedrich Fraundorfer*

Main category: cs.CV

TL;DR: SANDesc是一个简化的基于注意力的描述符提取网络，通过改进现有关键点检测器的描述符来提升匹配性能，参数量仅240万。


<details>
  <summary>Details</summary>
Motivation: 现有关键点描述符在匹配任务中仍有改进空间，需要一种能够在不修改底层关键点检测器的情况下提升描述符性能的轻量级网络架构。

Method: 采用改进的U-Net架构，结合卷积块注意力模块和残差路径，构建残差U-Net注意力块；使用改进的三元组损失和课程学习启发的困难负样本挖掘策略进行训练。

Result: 在HPatches、MegaDepth-1500和Image Matching Challenge 2021上，SANDesc在现有关键点检测器基础上训练后，在多个匹配任务中优于原始描述符；在新提出的城市数据集上表现显著优于现有描述符。

Conclusion: SANDesc是一种高效轻量的描述符提取网络，能够显著提升关键点匹配性能，同时引入的新城市数据集为特征提取器评估提供了有价值的基准。

Abstract: We introduce SANDesc, a Streamlined Attention-Based Network for Descriptor extraction that aims to improve on existing architectures for keypoint description.
  Our descriptor network learns to compute descriptors that improve matching without modifying the underlying keypoint detector. We employ a revised U-Net-like architecture enhanced with Convolutional Block Attention Modules and residual paths, enabling effective local representation while maintaining computational efficiency. We refer to the building blocks of our model as Residual U-Net Blocks with Attention. The model is trained using a modified triplet loss in combination with a curriculum learning-inspired hard negative mining strategy, which improves training stability.
  Extensive experiments on HPatches, MegaDepth-1500, and the Image Matching Challenge 2021 show that training SANDesc on top of existing keypoint detectors leads to improved results on multiple matching tasks compared to the original keypoint descriptors. At the same time, SANDesc has a model complexity of just 2.4 million parameters.
  As a further contribution, we introduce a new urban dataset featuring 4K images and pre-calibrated intrinsics, designed to evaluate feature extractors. On this benchmark, SANDesc achieves substantial performance gains over the existing descriptors while operating with limited computational resources.

</details>


### [167] [PhaseMark: A Post-hoc, Optimization-Free Watermarking of AI-generated Images in the Latent Frequency Domain](https://arxiv.org/abs/2601.13128)
*Sung Ju Lee,Nam Ik Cho*

Main category: cs.CV

TL;DR: PhaseMark：一种基于VAE潜在频率域相位调制的单次优化自由水印框架，比基于优化的方法快数千倍，在保持图像质量的同时实现最先进的抗攻击能力


<details>
  <summary>Details</summary>
Motivation: 潜在扩散模型生成的超真实图像需要强大的水印技术，但现有的后处理方法由于需要迭代优化或反演过程而速度极慢

Method: 直接在VAE潜在频率域调制相位，采用单次优化自由框架，分析了四种调制变体，揭示了性能与质量的权衡关系

Result: PhaseMark比基于优化的技术快数千倍，在包括再生在内的严重攻击下实现最先进的抗攻击能力，且不降低图像质量

Conclusion: PhaseMark展示了通过利用潜在固有属性实现高效、抗攻击水印的新范式

Abstract: The proliferation of hyper-realistic images from Latent Diffusion Models (LDMs) demands robust watermarking, yet existing post-hoc methods are prohibitively slow due to iterative optimization or inversion processes. We introduce PhaseMark, a single-shot, optimization-free framework that directly modulates the phase in the VAE latent frequency domain. This approach makes PhaseMark thousands of times faster than optimization-based techniques while achieving state-of-the-art resilience against severe attacks, including regeneration, without degrading image quality. We analyze four modulation variants, revealing a clear performance-quality trade-off. PhaseMark demonstrates a new paradigm where efficient, resilient watermarking is achieved by exploiting intrinsic latent properties.

</details>


### [168] [GaussExplorer: 3D Gaussian Splatting for Embodied Exploration and Reasoning](https://arxiv.org/abs/2601.13132)
*Kim Yu-Ji,Dahye Lee,Kim Jun-Seong,GeonU Kim,Nam Hyeon-Woo,Yongjin Kwon,Yu-Chiang Frank Wang,Jaesung Choe,Tae-Hyun Oh*

Main category: cs.CV

TL;DR: GaussExplorer是一个基于3D高斯泼溅的具身探索与推理框架，通过视觉语言模型实现3D场景中的问题驱动探索和推理，解决了现有方法在处理复杂组合查询和固定视角限制的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于语言嵌入的3D高斯泼溅方法只能处理简单文本查询，难以解释复杂的组合语言查询；而基于对象中心RGB-D结构化记忆的方法虽然提供空间基础，但受限于预固定视角。需要一种能处理复杂查询并支持自由视角探索的方法。

Method: 在3D高斯泼溅基础上引入视觉语言模型，首先识别与查询问题最相关的预捕获图像，然后将这些图像调整到新的视角以更准确地捕捉视觉信息，从而支持VLM进行更好的推理。

Result: 实验表明，该方法在多个基准测试中优于现有方法，证明了将基于VLM的推理与3D高斯泼溅集成在具身任务中的有效性。

Conclusion: GaussExplorer成功地将视觉语言模型与3D高斯泼溅相结合，实现了对3D场景的问题驱动探索和推理，为处理复杂组合查询提供了有效解决方案。

Abstract: We present GaussExplorer, a framework for embodied exploration and reasoning built on 3D Gaussian Splatting (3DGS). While prior approaches to language-embedded 3DGS have made meaningful progress in aligning simple text queries with Gaussian embeddings, they are generally optimized for relatively simple queries and struggle to interpret more complex, compositional language queries. Alternative studies based on object-centric RGB-D structured memories provide spatial grounding but are constrained by pre-fixed viewpoints. To address these issues, GaussExplorer introduces Vision-Language Models (VLMs) on top of 3DGS to enable question-driven exploration and reasoning within 3D scenes. We first identify pre-captured images that are most correlated with the query question, and subsequently adjust them into novel viewpoints to more accurately capture visual information for better reasoning by VLMs. Experiments show that ours outperforms existing methods on several benchmarks, demonstrating the effectiveness of integrating VLM-based reasoning with 3DGS for embodied tasks.

</details>


### [169] [CLIP-Guided Adaptable Self-Supervised Learning for Human-Centric Visual Tasks](https://arxiv.org/abs/2601.13133)
*Mingshuang Luo,Ruibing Hou,Bo Chao,Hong Chang,Zimo Liu,Yaowei Wang,Shiguang Shan*

Main category: cs.CV

TL;DR: CLASP是一个用于以人为中心的视觉任务的通用无监督预训练框架，利用CLIP生成多级语义伪标签，通过Prompt-Controlled MoE模块动态适应不同下游任务，在多个基准测试中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 随着大规模未标记人体图像数据集的出现，需要一种通用的无监督预训练模型来支持多样化的以人为中心的下游任务，如监控、医疗和人机交互。

Method: 1. 利用CLIP生成低级（身体部位）和高级（属性）语义伪标签；2. 将这些多级语义线索整合到学习的视觉表示中；3. 引入Prompt-Controlled Mixture-of-Experts模块，根据任务特定提示动态调整特征提取；4. 采用多任务预训练策略，由CLIP衍生的部位和属性级伪标签指导表示学习。

Result: 在多个基准测试上的广泛实验表明，CLASP始终优于现有的无监督预训练方法，推进了以人为中心的视觉分析领域。

Conclusion: CLASP通过结合CLIP的多级语义伪标签和Prompt-Controlled MoE模块，成功创建了一个通用且可适应的无监督预训练框架，能够有效支持多样化的以人为中心的视觉任务。

Abstract: Human-centric visual analysis plays a pivotal role in diverse applications, including surveillance, healthcare, and human-computer interaction. With the emergence of large-scale unlabeled human image datasets, there is an increasing need for a general unsupervised pre-training model capable of supporting diverse human-centric downstream tasks. To achieve this goal, we propose CLASP (CLIP-guided Adaptable Self-suPervised learning), a novel framework designed for unsupervised pre-training in human-centric visual tasks. CLASP leverages the powerful vision-language model CLIP to generate both low-level (e.g., body parts) and high-level (e.g., attributes) semantic pseudo-labels. These multi-level semantic cues are then integrated into the learned visual representations, enriching their expressiveness and generalizability. Recognizing that different downstream tasks demand varying levels of semantic granularity, CLASP incorporates a Prompt-Controlled Mixture-of-Experts (MoE) module. MoE dynamically adapts feature extraction based on task-specific prompts, mitigating potential feature conflicts and enhancing transferability. Furthermore, CLASP employs a multi-task pre-training strategy, where part- and attribute-level pseudo-labels derived from CLIP guide the representation learning process. Extensive experiments across multiple benchmarks demonstrate that CLASP consistently outperforms existing unsupervised pre-training methods, advancing the field of human-centric visual analysis.

</details>


### [170] [TVWorld: Foundations for Remote-Control TV Agents](https://arxiv.org/abs/2601.13142)
*Zhantao Ma,Quanfeng Lu,Shuai Zhong,Dahai Yu,Ping Luo,Michael K. Ng*

Main category: cs.CV

TL;DR: TVWorld：一个离线图结构抽象的真实世界电视导航基准，包含TVWorld-N（拓扑感知导航）和TVWorld-G（焦点感知定位）两个互补基准，揭示了现有智能体在电视导航中的拓扑感知不足问题，并提出了拓扑感知训练框架和TVTheseus模型。


<details>
  <summary>Details</summary>
Motivation: 现有大型视觉语言模型主要关注点按交互，而日常电视使用中常见的遥控交互研究不足。需要填补这一空白，建立可重复、免部署的电视导航评估基准。

Method: 1. 提出TVWorld：离线图结构的真实世界电视导航抽象；2. 创建两个互补基准：TVWorld-N（拓扑感知导航）和TVWorld-G（焦点感知定位）；3. 提出拓扑感知训练框架，将拓扑感知注入大型视觉语言模型；4. 开发TVTheseus：专门用于电视导航的基础模型。

Result: TVTheseus在TVWorld-N上达到68.3%的成功率，超过Gemini 3 Flash等强闭源基线，建立了最先进的性能。分析为开发有效的电视使用智能体提供了有价值的见解。

Conclusion: 现有智能体在基于焦点的长视野电视导航中存在拓扑感知不足的关键限制。通过拓扑感知训练框架开发的TVTheseus模型在电视导航任务上表现出色，为电视使用智能体的发展提供了重要方向。

Abstract: Recent large vision-language models (LVLMs) have demonstrated strong potential for device control. However, existing research has primarily focused on point-and-click (PnC) interaction, while remote-control (RC) interaction commonly encountered in everyday TV usage remains largely underexplored. To fill this gap, we introduce \textbf{TVWorld}, an offline graph-based abstraction of real-world TV navigation that enables reproducible and deployment-free evaluation. On this basis, we derive two complementary benchmarks that comprehensively assess TV-use capabilities: \textbf{TVWorld-N} for topology-aware navigation and \textbf{TVWorld-G} for focus-aware grounding. These benchmarks expose a key limitation of existing agents: insufficient topology awareness for focus-based, long-horizon TV navigation. Motivated by this finding, we propose a \emph{Topology-Aware Training} framework that injects topology awareness into LVLMs. Using this framework, we develop \textbf{TVTheseus}, a foundation model specialized for TV navigation. TVTheseus achieves a success rate of $68.3\%$ on TVWorld-N, surpassing strong closed-source baselines such as Gemini 3 Flash and establishing state-of-the-art (SOTA) performance. Additional analyses further provide valuable insights into the development of effective TV-use agents.

</details>


### [171] [ICo3D: An Interactive Conversational 3D Virtual Human](https://arxiv.org/abs/2601.13148)
*Richard Shaw,Youngkyoon Jang,Athanasios Papaioannou,Arthur Moreau,Helisa Dhamo,Zhensong Zhang,Eduardo Pérez-Pellitero*

Main category: cs.CV

TL;DR: ICo3D是一个交互式、对话式、照片级真实的3D虚拟人方法，结合了可动画的3D面部模型和动态3D身体模型，使用高斯基元渲染，并集成LLM实现对话能力，支持实时用户交互。


<details>
  <summary>Details</summary>
Motivation: 创建能够进行实时对话交互的照片级真实3D虚拟人，适用于游戏、虚拟助手、个性化教育等多种应用场景，提供沉浸式的虚拟化身体验。

Method: 基于多视角捕捉创建可动画的3D面部模型和动态3D身体模型，使用高斯基元渲染；改进动态高斯模型（SWinGS++用于身体重建，HeadGaS++用于面部重建）；集成LLM实现对话能力；使用音频语音驱动面部动画实现精确同步；提供无伪影的面部和身体模型融合方案。

Result: 开发了完整的ICo3D系统，展示了实时与3D虚拟人对话的多个用例，实现了完全集成的虚拟化身体验，支持沉浸式环境中的口头和书面形式交互。

Conclusion: ICo3D提供了一个功能完整的交互式对话3D虚拟人解决方案，结合了照片级真实感、实时交互和对话能力，在游戏、虚拟助手、教育等多个领域具有广泛应用前景。

Abstract: This work presents Interactive Conversational 3D Virtual Human (ICo3D), a method for generating an interactive, conversational, and photorealistic 3D human avatar. Based on multi-view captures of a subject, we create an animatable 3D face model and a dynamic 3D body model, both rendered by splatting Gaussian primitives. Once merged together, they represent a lifelike virtual human avatar suitable for real-time user interactions. We equip our avatar with an LLM for conversational ability. During conversation, the audio speech of the avatar is used as a driving signal to animate the face model, enabling precise synchronization. We describe improvements to our dynamic Gaussian models that enhance photorealism: SWinGS++ for body reconstruction and HeadGaS++ for face reconstruction, and provide as well a solution to merge the separate face and body models without artifacts. We also present a demo of the complete system, showcasing several use cases of real-time conversation with the 3D avatar. Our approach offers a fully integrated virtual avatar experience, supporting both oral and written form interactions in immersive environments. ICo3D is applicable to a wide range of fields, including gaming, virtual assistance, and personalized education, among others. Project page: https://ico3d.github.io/

</details>


### [172] [From 100,000+ images to winning the first brain MRI foundation model challenges: Sharing lessons and models](https://arxiv.org/abs/2601.13166)
*Pedro M. Gordaliza,Jaume Banus,Benoît Gérin,Maxence Wynen,Nataliia Molchanova,Jonas Richiardi,Meritxell Bach Cuadra*

Main category: cs.CV

TL;DR: 该论文提出了一种用于3D脑MRI分析的医学基础模型，在MICCAI 2025的SSL3D和FOMO25挑战赛中均获得第一名，采用U-Net CNN架构结合解剖学先验知识，比基于transformer的方法训练速度快1-2个数量级且模型小10倍。


<details>
  <summary>Details</summary>
Motivation: 开发医学图像分析的基础模型对于克服放射学任务的独特挑战至关重要，特别是在3D脑MRI领域。

Method: 采用U-Net CNN架构，结合利用解剖学先验知识和神经影像领域知识的策略。

Result: 在MICCAI 2025的SSL3D和FOMO25挑战赛的两个赛道中均排名第一，模型训练速度比基于transformer的方法快1-2个数量级，模型大小小10倍。

Conclusion: 提出的基于U-Net CNN的医学基础模型在3D脑MRI分析中表现出色，证明了结合领域知识和高效架构的优势，模型已开源供社区使用。

Abstract: Developing Foundation Models for medical image analysis is essential to overcome the unique challenges of radiological tasks. The first challenges of this kind for 3D brain MRI, SSL3D and FOMO25, were held at MICCAI 2025. Our solution ranked first in tracks of both contests. It relies on a U-Net CNN architecture combined with strategies leveraging anatomical priors and neuroimaging domain knowledge. Notably, our models trained 1-2 orders of magnitude faster and were 10 times smaller than competing transformer-based approaches. Models are available here: https://github.com/jbanusco/BrainFM4Challenges.

</details>


### [173] [GTPred: Benchmarking MLLMs for Interpretable Geo-localization and Time-of-capture Prediction](https://arxiv.org/abs/2601.13207)
*Jinnao Li,Zijian Chen,Tingzhu Chen,Changbo Wang*

Main category: cs.CV

TL;DR: GTPred：首个地理-时间预测基准，包含370张全球分布、跨越120年的图像，评估多模态大语言模型的地理时间推理能力


<details>
  <summary>Details</summary>
Motivation: 现有地理定位基准大多忽略图像中的时间信息，而时间信息可以进一步约束位置推断。为了填补这一空白，需要创建包含时间维度的地理定位基准

Method: 引入GTPred基准，包含370张全球分布、跨越120年的图像。评估方法包括联合考虑年份和分层位置序列匹配，并使用精心标注的真实推理过程评估中间推理链

Result: 在8个专有和7个开源MLLM上的实验表明，尽管模型有较强的视觉感知能力，但在世界知识和地理时间推理方面仍有限制。结果还显示，加入时间信息能显著提升位置推断性能

Conclusion: 当前MLLM在地理时间推理方面仍有局限，但时间信息对地理定位有重要提升作用。GTPred基准为评估和改进模型的时空推理能力提供了重要工具

Abstract: Geo-localization aims to infer the geographic location where an image was captured using observable visual evidence. Traditional methods achieve impressive results through large-scale training on massive image corpora. With the emergence of multi-modal large language models (MLLMs), recent studies have explored their applications in geo-localization, benefiting from improved accuracy and interpretability. However, existing benchmarks largely ignore the temporal information inherent in images, which can further constrain the location. To bridge this gap, we introduce GTPred, a novel benchmark for geo-temporal prediction. GTPred comprises 370 globally distributed images spanning over 120 years. We evaluate MLLM predictions by jointly considering year and hierarchical location sequence matching, and further assess intermediate reasoning chains using meticulously annotated ground-truth reasoning processes. Experiments on 8 proprietary and 7 open-source MLLMs show that, despite strong visual perception, current models remain limited in world knowledge and geo-temporal reasoning. Results also demonstrate that incorporating temporal information significantly enhances location inference performance.

</details>


### [174] [Rethinking Skip Connections: Additive U-Net for Robust and Interpretable Denoising](https://arxiv.org/abs/2601.13208)
*Vikram R Lakkavalli*

Main category: cs.CV

TL;DR: 提出Additive U-Net，用可学习的门控加法连接替代传统U-Net中的拼接连接，减少通道维度膨胀，提供显式可控的编码器贡献，在图像去噪任务中取得竞争性性能。


<details>
  <summary>Details</summary>
Motivation: 传统U-Net中的跳跃连接通过拼接方式会加倍通道维度，同时导致信息流不清晰，允许不受控制的噪声传递。需要更轻量、可解释的连接方式。

Method: 提出Additive U-Net架构，用门控加法连接替代拼接跳跃连接。每个跳跃路径通过可学习的非负标量进行缩放，提供对编码器贡献的显式控制，避免通道维度膨胀。

Result: 在Kodak-17去噪基准测试中，在噪声水平σ=15、25、50下取得竞争性的PSNR/SSIM分数。模型对不同的核调度和深度具有鲁棒性。即使没有显式的下采样/上采样或强制层次结构，模型也能自然学习从高频到带通再到低频特征的渐进过程。

Conclusion: 加法跳跃连接是拼接连接的轻量级、可解释替代方案，既能实现高效设计，又能更清晰地理解重建网络中的多尺度信息传递。

Abstract: Skip connections are central to U-Net architectures for image denoising, but standard concatenation doubles channel dimensionality and obscures information flow, allowing uncontrolled noise transfer. We propose the Additive U-Net, which replaces concatenative skips with gated additive connections. Each skip pathway is scaled by a learnable non-negative scalar, offering explicit and interpretable control over encoder contributions while avoiding channel inflation. Evaluations on the Kodak-17 denoising benchmark show that Additive U-Net achieves competitive PSNR/SSIM at noise levels σ = 15, 25, 50, with robustness across kernel schedules and depths. Notably, effective denoising is achieved even without explicit down/up-sampling or forced hierarchies, as the model naturally learns a progression from high-frequency to band-pass to low-frequency features. These results position additive skips as a lightweight and interpretable alternative to concatenation, enabling both efficient design and a clearer understanding of multi-scale information transfer in reconstruction networks.

</details>


### [175] [ObjectVisA-120: Object-based Visual Attention Prediction in Interactive Street-crossing Environments](https://arxiv.org/abs/2601.13218)
*Igor Vozniak,Philipp Mueller,Nils Lipp,Janis Sprenger,Konstantin Poddubnyy,Davit Hovhannisyan,Christian Mueller,Andreas Bulling,Philipp Slusallek*

Main category: cs.CV

TL;DR: 提出VR街景导航数据集和对象注意力评估新指标oSIM，展示对象注意力优化提升模型性能


<details>
  <summary>Details</summary>
Motivation: 人类视觉注意力的对象特性在认知科学中已知，但在计算视觉注意力模型中作用有限，主要缺乏合适的数据集和评估指标

Method: 1) 创建120人参与的VR街景导航数据集，包含准确注视数据、完整对象状态空间、丰富注释；2) 提出对象相似度(oSIM)作为对象注意力评估新指标；3) 提出SUMGraph模型，基于Mamba U-Net，将关键场景对象编码为图表示

Result: 1) 数据集包含丰富注释和可变场景复杂度；2) 对象注意力优化不仅提升oSIM性能，也改善常见指标表现；3) SUMGraph模型在多个SOTA视觉注意力预测方法上表现更优

Conclusion: 通过新数据集和评估指标推动对象注意力研究，展示对象注意力优化的重要性，提出的SUMGraph模型表现优异，所有资源将公开

Abstract: The object-based nature of human visual attention is well-known in cognitive science, but has only played a minor role in computational visual attention models so far. This is mainly due to a lack of suitable datasets and evaluation metrics for object-based attention. To address these limitations, we present \dataset~ -- a novel 120-participant dataset of spatial street-crossing navigation in virtual reality specifically geared to object-based attention evaluations. The uniqueness of the presented dataset lies in the ethical and safety affiliated challenges that make collecting comparable data in real-world environments highly difficult. \dataset~ not only features accurate gaze data and a complete state-space representation of objects in the virtual environment, but it also offers variable scenario complexities and rich annotations, including panoptic segmentation, depth information, and vehicle keypoints. We further propose object-based similarity (oSIM) as a novel metric to evaluate the performance of object-based visual attention models, a previously unexplored performance characteristic. Our evaluations show that explicitly optimising for object-based attention not only improves oSIM performance but also leads to an improved model performance on common metrics. In addition, we present SUMGraph, a Mamba U-Net-based model, which explicitly encodes critical scene objects (vehicles) in a graph representation, leading to further performance improvements over several state-of-the-art visual attention prediction methods. The dataset, code and models will be publicly released.

</details>


### [176] [Not all Blends are Equal: The BLEMORE Dataset of Blended Emotion Expressions with Relative Salience Annotations](https://arxiv.org/abs/2601.13225)
*Tim Lachmann,Alexandra Israelsson,Christina Tornberg,Teimuraz Saghinadze,Michal Balazia,Philipp Müller,Petri Laukka*

Main category: cs.CV

TL;DR: 论文介绍了BLEMORE数据集，用于多模态混合情感识别，包含情感相对显著度信息，评估了现有方法在混合情感识别任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 人类经常同时体验多种混合情感，但现有视频情感识别方法大多只能识别单一情感，缺乏包含相对显著度标注的混合情感数据集。

Method: 构建了包含3000多个视频片段的BLEMORE数据集，涵盖6种基本情感和10种不同混合，每种混合有3种显著度配置（50/50、70/30、30/70）。使用该数据集评估了最先进的视频分类方法在两个任务上的表现：情感存在预测和情感显著度预测。

Result: 单模态分类器在验证集上达到29%的存在准确率和13%的显著度准确率，多模态方法有明显改进，ImageBind + WavLM达到35%存在准确率，HiCMAE达到18%显著度准确率。在测试集上，最佳模型达到33%存在准确率（VideoMAEv2 + HuBERT）和18%显著度准确率（HiCMAE）。

Conclusion: BLEMORE数据集为推进考虑混合情感表达复杂性和重要性的情感识别系统研究提供了宝贵资源。

Abstract: Humans often experience not just a single basic emotion at a time, but rather a blend of several emotions with varying salience. Despite the importance of such blended emotions, most video-based emotion recognition approaches are designed to recognize single emotions only. The few approaches that have attempted to recognize blended emotions typically cannot assess the relative salience of the emotions within a blend. This limitation largely stems from the lack of datasets containing a substantial number of blended emotion samples annotated with relative salience. To address this shortcoming, we introduce BLEMORE, a novel dataset for multimodal (video, audio) blended emotion recognition that includes information on the relative salience of each emotion within a blend. BLEMORE comprises over 3,000 clips from 58 actors, performing 6 basic emotions and 10 distinct blends, where each blend has 3 different salience configurations (50/50, 70/30, and 30/70). Using this dataset, we conduct extensive evaluations of state-of-the-art video classification approaches on two blended emotion prediction tasks: (1) predicting the presence of emotions in a given sample, and (2) predicting the relative salience of emotions in a blend. Our results show that unimodal classifiers achieve up to 29% presence accuracy and 13% salience accuracy on the validation set, while multimodal methods yield clear improvements, with ImageBind + WavLM reaching 35% presence accuracy and HiCMAE 18% salience accuracy. On the held-out test set, the best models achieve 33% presence accuracy (VideoMAEv2 + HuBERT) and 18% salience accuracy (HiCMAE). In sum, the BLEMORE dataset provides a valuable resource to advancing research on emotion recognition systems that account for the complexity and significance of blended emotion expressions.

</details>


### [177] [ConvMambaNet: A Hybrid CNN-Mamba State Space Architecture for Accurate and Real-Time EEG Seizure Detection](https://arxiv.org/abs/2601.13234)
*Md. Nishan Khan,Kazi Shahriar Sanjid,Md. Tanzim Hossain,Asib Mostakim Fony,Istiak Ahmed,M. Monir Uddin*

Main category: cs.CV

TL;DR: 提出ConvMambaNet混合深度学习模型，结合CNN和Mamba-SSM，用于EEG癫痫发作检测，在CHB-MIT数据集上达到99%准确率


<details>
  <summary>Details</summary>
Motivation: 癫痫严重影响生活质量，EEG是主要监测工具但自动分析困难，因为EEG信号具有时间复杂性，需要更好的特征提取方法

Method: 提出ConvMambaNet混合模型，将Mamba结构化状态空间模型块嵌入CNN框架中，同时捕捉空间特征和长程时间动态

Result: 在CHB-MIT头皮EEG数据集上评估，达到99%准确率，在严重类别不平衡下表现稳健

Conclusion: ConvMambaNet具有精确高效癫痫检测潜力，为临床环境中实时自动化癫痫监测提供了可行路径

Abstract: Epilepsy is a chronic neurological disorder marked by recurrent seizures that can severely impact quality of life. Electroencephalography (EEG) remains the primary tool for monitoring neural activity and detecting seizures, yet automated analysis remains challenging due to the temporal complexity of EEG signals. This study introduces ConvMambaNet, a hybrid deep learning model that integrates Convolutional Neural Networks (CNNs) with the Mamba Structured State Space Model (SSM) to enhance temporal feature extraction. By embedding the Mamba-SSM block within a CNN framework, the model effectively captures both spatial and long-range temporal dynamics. Evaluated on the CHB-MIT Scalp EEG dataset, ConvMambaNet achieved a 99% accuracy and demonstrated robust performance under severe class imbalance. These results underscore the model's potential for precise and efficient seizure detection, offering a viable path toward real-time, automated epilepsy monitoring in clinical environments.

</details>


### [178] [A Semantic Decoupling-Based Two-Stage Rainy-Day Attack for Revealing Weather Robustness Deficiencies in Vision-Language Models](https://arxiv.org/abs/2601.13238)
*Chengyin Hu,Xiang Chen,Zhe Jia,Weiwen Shi,Fengyu Zhang,Jiujiang Guo,Yiwei Wei*

Main category: cs.CV

TL;DR: 该论文提出了首个利用真实天气条件攻击视觉语言模型的对抗框架，通过两阶段参数化扰动模型分析雨天气候对VLM决策的影响，揭示了物理上合理的天气扰动能导致主流VLM的语义错位风险。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型通常在规范视觉条件下训练，但对真实天气条件（特别是雨天）的鲁棒性以及跨模态语义对齐的稳定性研究不足。需要探索天气扰动如何影响VLM的决策边界，以评估其在现实部署中的安全性和可靠性风险。

Method: 提出两阶段参数化扰动框架：第一阶段通过低维全局调制建模降雨的全局效应，逐渐削弱原始语义决策边界；第二阶段显式建模多尺度雨滴外观和降雨引起的照明变化，优化不可微的天气空间以诱导稳定的语义偏移。整个框架在非像素参数空间中操作，生成物理基础且可解释的扰动。

Result: 实验表明，即使是物理上合理且高度约束的天气扰动，也能在主流VLM中引发显著的语义错位。消融研究进一步证实，照明建模和多尺度雨滴结构是这些语义偏移的关键驱动因素。

Conclusion: 该研究揭示了视觉语言模型在真实天气条件下的脆弱性，物理上合理的天气扰动能够显著破坏跨模态语义对齐，对VLM在现实世界部署的安全性和可靠性构成潜在风险，强调了增强模型对天气扰动鲁棒性的必要性。

Abstract: Vision-Language Models (VLMs) are trained on image-text pairs collected under canonical visual conditions and achieve strong performance on multimodal tasks. However, their robustness to real-world weather conditions, and the stability of cross-modal semantic alignment under such structured perturbations, remain insufficiently studied. In this paper, we focus on rainy scenarios and introduce the first adversarial framework that exploits realistic weather to attack VLMs, using a two-stage, parameterized perturbation model based on semantic decoupling to analyze rain-induced shifts in decision-making. In Stage 1, we model the global effects of rainfall by applying a low-dimensional global modulation to condition the embedding space and gradually weaken the original semantic decision boundaries. In Stage 2, we introduce structured rain variations by explicitly modeling multi-scale raindrop appearance and rainfall-induced illumination changes, and optimize the resulting non-differentiable weather space to induce stable semantic shifts. Operating in a non-pixel parameter space, our framework generates perturbations that are both physically grounded and interpretable. Experiments across multiple tasks show that even physically plausible, highly constrained weather perturbations can induce substantial semantic misalignment in mainstream VLMs, posing potential safety and reliability risks in real-world deployment. Ablations further confirm that illumination modeling and multi-scale raindrop structures are key drivers of these semantic shifts.

</details>


### [179] [Deep Learning for Semantic Segmentation of 3D Ultrasound Data](https://arxiv.org/abs/2601.13263)
*Chenyu Liu,Marco Cecotti,Harikrishnan Vijayakumar,Patrick Robinson,James Barson,Mihai Caleap*

Main category: cs.CV

TL;DR: 提出基于Calyo Pulse固态3D超声传感器的学习式3D语义分割框架，用于恶劣环境下的自动驾驶感知


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶感知系统（LiDAR和摄像头）在成本、鲁棒性和恶劣环境性能方面存在权衡，需要开发更经济可靠且能在恶劣环境下工作的感知方案

Method: 使用Calyo Pulse模块化固态3D超声传感器系统，引入3D U-Net架构对空间超声数据进行训练，实现体素化语义分割

Result: Calyo Pulse传感器展现出稳健的分割性能，通过更大数据集、更精确真值标注和加权损失函数有进一步提升潜力

Conclusion: 3D超声传感是自动驾驶可靠感知的有前景的补充模态，为恶劣和杂乱环境下的感知提供了新方案

Abstract: Developing cost-efficient and reliable perception systems remains a central challenge for automated vehicles. LiDAR and camera-based systems dominate, yet they present trade-offs in cost, robustness and performance under adverse conditions. This work introduces a novel framework for learning-based 3D semantic segmentation using Calyo Pulse, a modular, solid-state 3D ultrasound sensor system for use in harsh and cluttered environments. A 3D U-Net architecture is introduced and trained on the spatial ultrasound data for volumetric segmentation. Results demonstrate robust segmentation performance from Calyo Pulse sensors, with potential for further improvement through larger datasets, refined ground truth, and weighted loss functions. Importantly, this study highlights 3D ultrasound sensing as a promising complementary modality for reliable autonomy.

</details>


### [180] [Enginuity: Building an Open Multi-Domain Dataset of Complex Engineering Diagrams](https://arxiv.org/abs/2601.13299)
*Ethan Seefried,Prahitha Movva,Naga Harshita Marupaka,Tilak Kasturi,Tirthankar Ghosal*

Main category: cs.CV

TL;DR: Enginuity是首个开放、大规模、多领域的工程图数据集，包含全面的结构化标注，旨在实现自动化图表解析，支持多模态大语言模型处理工程图相关任务。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统在科学发现工作流中面临主要障碍：无法理解和操作工程图中的视觉结构知识。工程图在科学工作流中至关重要，但AI缺乏解析这些复杂视觉表示的能力，限制了其在假设生成、实验设计和发现中的参与。

Method: 创建了一个开放、大规模、多领域的工程图数据集，包含全面的结构化标注，捕捉层次化的组件关系、连接和语义元素。该数据集设计用于支持多模态大语言模型。

Result: 提出的Enginuity数据集将能够支持关键下游任务，包括结构化图表解析、跨模态信息检索和AI辅助工程仿真。该数据集将打破AI参与科学工作流的障碍。

Conclusion: Enginuity将对科学发现的AI产生变革性影响，使AI系统能够理解和操作工程图中嵌入的视觉结构知识，从而让AI能够充分参与需要图表解释、技术图纸分析和视觉推理的科学工作流。

Abstract: We propose Enginuity - the first open, large-scale, multi-domain engineering diagram dataset with comprehensive structural annotations designed for automated diagram parsing. By capturing hierarchical component relationships, connections, and semantic elements across diverse engineering domains, our proposed dataset would enable multimodal large language models to address critical downstream tasks including structured diagram parsing, cross-modal information retrieval, and AI-assisted engineering simulation. Enginuity would be transformative for AI for Scientific Discovery by enabling artificial intelligence systems to comprehend and manipulate the visual-structural knowledge embedded in engineering diagrams, breaking down a fundamental barrier that currently prevents AI from fully participating in scientific workflows where diagram interpretation, technical drawing analysis, and visual reasoning are essential for hypothesis generation, experimental design, and discovery.

</details>


### [181] [CausalSpatial: A Benchmark for Object-Centric Causal Spatial Reasoning](https://arxiv.org/abs/2601.13304)
*Wenxin Ma,Chenlong Wang,Ruisheng Yuan,Hao Chen,Nanru Dai,S. Kevin Zhou,Yijun Yang,Alan Yuille,Jieneng Chen*

Main category: cs.CV

TL;DR: 论文提出CausalSpatial基准测试，评估多模态大语言模型在因果空间推理能力上的不足，并开发COW框架通过生成假设动态视频来改善模型的空间推理能力。


<details>
  <summary>Details</summary>
Motivation: 人类能够通过观察静态场景预测物体运动的因果后果，但当前的多模态大语言模型主要局限于静态空间感知，无法回答3D场景中的"如果...会怎样"问题。需要评估和改进模型在因果空间推理方面的能力。

Method: 1) 创建CausalSpatial诊断基准，包含碰撞、兼容性、遮挡和轨迹四个任务；2) 分析模型失败原因，发现模型过度依赖文本链式推理而脱离视觉证据；3) 提出因果对象世界模型(COW)框架，通过生成假设动态视频来外部化模拟过程，提供明确的因果视觉线索。

Result: 人类在CausalSpatial基准上得分84%，而GPT-5仅得54%，显示出显著差距。分析发现模型产生流畅但空间无根据的幻觉。COW框架通过可视化因果动态，使模型能够基于物理现实而非语言先验进行推理。

Conclusion: 多模态大语言模型在因果空间推理方面存在严重缺陷，主要问题是过度依赖文本推理而脱离视觉证据。提出的COW框架通过外部化模拟过程，为模型提供明确的因果视觉线索，有望改善模型的空间推理能力。数据集和代码已开源。

Abstract: Humans can look at a static scene and instantly predict what happens next -- will moving this object cause a collision? We call this ability Causal Spatial Reasoning. However, current multimodal large language models (MLLMs) cannot do this, as they remain largely restricted to static spatial perception, struggling to answer "what-if" questions in a 3D scene. We introduce CausalSpatial, a diagnostic benchmark evaluating whether models can anticipate consequences of object motions across four tasks: Collision, Compatibility, Occlusion, and Trajectory. Results expose a severe gap: humans score 84% while GPT-5 achieves only 54%. Why do MLLMs fail? Our analysis uncovers a fundamental deficiency: models over-rely on textual chain-of-thought reasoning that drifts from visual evidence, producing fluent but spatially ungrounded hallucinations. To address this, we propose the Causal Object World model (COW), a framework that externalizes the simulation process by generating videos of hypothetical dynamics. With explicit visual cues of causality, COW enables models to ground their reasoning in physical reality rather than linguistic priors. We make the dataset and code publicly available here: https://github.com/CausalSpatial/CausalSpatial

</details>


### [182] [MultiST: A Cross-Attention-Based Multimodal Model for Spatial Transcriptomic](https://arxiv.org/abs/2601.13331)
*Wei Wang,Quoc-Toan Ly,Chong Yu,Jun Bai*

Main category: cs.CV

TL;DR: MultiST是一个多模态空间转录组学框架，通过交叉注意力融合空间拓扑、基因表达和组织形态学，实现更清晰的空间域边界识别。


<details>
  <summary>Details</summary>
Motivation: 现有空间转录组学方法在整合组织形态学和分子谱方面存在不足，通常采用浅层融合策略或完全忽略组织图像，导致空间域边界识别模糊。

Method: 提出MultiST统一多模态框架，使用基于交叉注意力的融合技术联合建模空间拓扑、基因表达和组织形态学；采用基于图的基因编码器配合对抗对齐学习鲁棒空间表示，并整合颜色归一化的组织学特征捕获分子-形态学依赖关系。

Result: 在13个不同ST数据集（包括人脑皮层和乳腺癌组织）上评估，MultiST相比现有方法产生边界更清晰、更一致的空间域，获得更稳定的伪时间轨迹和更具生物学可解释性的细胞-细胞相互作用模式。

Conclusion: MultiST通过有效整合多模态信息，显著提升了空间转录组学分析中空间域识别的准确性和生物学解释性，为研究组织结构和细胞相互作用提供了更强大的工具。

Abstract: Spatial transcriptomics (ST) enables transcriptome-wide profiling while preserving the spatial context of tissues, offering unprecedented opportunities to study tissue organization and cell-cell interactions in situ. Despite recent advances, existing methods often lack effective integration of histological morphology with molecular profiles, relying on shallow fusion strategies or omitting tissue images altogether, which limits their ability to resolve ambiguous spatial domain boundaries. To address this challenge, we propose MultiST, a unified multimodal framework that jointly models spatial topology, gene expression, and tissue morphology through cross-attention-based fusion. MultiST employs graph-based gene encoders with adversarial alignment to learn robust spatial representations, while integrating color-normalized histological features to capture molecular-morphological dependencies and refine domain boundaries. We evaluated the proposed method on 13 diverse ST datasets spanning two organs, including human brain cortex and breast cancer tissue. MultiST yields spatial domains with clearer and more coherent boundaries than existing methods, leading to more stable pseudotime trajectories and more biologically interpretable cell-cell interaction patterns. The MultiST framework and source code are available at https://github.com/LabJunBMI/MultiST.git.

</details>


### [183] [Real-Time 4D Radar Perception for Robust Human Detection in Harsh Enclosed Environments](https://arxiv.org/abs/2601.13364)
*Zhenan Liu,Yaodong Cui,Amir Khajepour,George Shaker*

Main category: cs.CV

TL;DR: 提出在粉尘环境中生成可控多级粉尘浓度的方法，创建4D毫米波雷达数据集，开发基于阈值的噪声过滤框架和基于规则的分类管道，显著提升粉尘环境下行人检测的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 地下矿井、道路隧道等封闭恶劣环境中存在大量粉尘和反射表面，严重影响毫米波雷达的感知功能，需要开发能够在这些恶劣电磁约束下进行可重复传播研究的方法。

Method: 1) 在高度杂乱环境中生成可控多级粉尘浓度的方法；2) 创建包含相机和LiDAR的4D毫米波雷达数据集；3) 开发基于阈值(RCS、速度、方位角、仰角)的噪声过滤框架；4) 构建基于聚类的规则分类管道，利用雷达语义特征进行实时行人检测。

Result: 实验结果表明，该集成方法在粉尘环境中显著增强了杂波抑制、检测鲁棒性和系统整体弹性，实现了可靠的实时行人检测。

Conclusion: 提出的方法为恶劣粉尘环境中的毫米波雷达感知提供了有效的解决方案，通过数据生成、噪声过滤和语义分类的集成框架，实现了可靠的实时行人检测，具有实际应用价值。

Abstract: This paper introduces a novel methodology for generating controlled, multi-level dust concentrations in a highly cluttered environment representative of harsh, enclosed environments, such as underground mines, road tunnels, or collapsed buildings, enabling repeatable mm-wave propagation studies under severe electromagnetic constraints. We also present a new 4D mmWave radar dataset, augmented by camera and LiDAR, illustrating how dust particles and reflective surfaces jointly impact the sensing functionality. To address these challenges, we develop a threshold-based noise filtering framework leveraging key radar parameters (RCS, velocity, azimuth, elevation) to suppress ghost targets and mitigate strong multipath reflections at the raw data level. Building on the filtered point clouds, a cluster-level, rule-based classification pipeline exploits radar semantics-velocity, RCS, and volumetric spread-to achieve reliable, real-time pedestrian detection without extensive domainspecific training. Experimental results confirm that this integrated approach significantly enhances clutter mitigation, detection robustness, and overall system resilience in dust-laden mining environments.

</details>


### [184] [Spherical Geometry Diffusion: Generating High-quality 3D Face Geometry via Sphere-anchored Representations](https://arxiv.org/abs/2601.13371)
*Junyi Zhang,Yiming Wang,Yunhong Lu,Qichao Wang,Wenzhe Qian,Xiaoyin Xu,David Gu,Min Zhang*

Main category: cs.CV

TL;DR: 提出了一种基于球形几何表示和扩散模型的文本到3D人脸生成方法，通过将几何约束在拓扑球面上实现高质量几何重建，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 文本到3D人脸生成面临的核心挑战是几何质量差，主要原因是3D空间中顶点分布任意复杂，难以建立干净的连接性，导致几何结构不理想。

Method: 1. 提出球形几何表示：将几何信号锚定到均匀球面坐标上，保证规则点分布，从而能稳健重建网格连接性；2. 引入球形几何扩散：基于2D映射的条件扩散框架，联合建模几何和纹理，几何明确条件化纹理合成过程。

Result: 方法在文本到3D生成、人脸重建和基于文本的3D编辑等任务中表现优异，在几何质量、文本保真度和推理效率方面显著优于现有方法。

Conclusion: 通过将几何约束在简单规则的拓扑球面上，解决了3D人脸生成中的几何质量问题，球形表示与2D生成模型的完美协同实现了高质量、可控的3D人脸生成。

Abstract: A fundamental challenge in text-to-3D face generation is achieving high-quality geometry. The core difficulty lies in the arbitrary and intricate distribution of vertices in 3D space, making it challenging for existing models to establish clean connectivity and resulting in suboptimal geometry. To address this, our core insight is to simplify the underlying geometric structure by constraining the distribution onto a simple and regular manifold, a topological sphere. Building on this, we first propose the Spherical Geometry Representation, a novel face representation that anchors geometric signals to uniform spherical coordinates. This guarantees a regular point distribution, from which the mesh connectivity can be robustly reconstructed. Critically, this canonical sphere can be seamlessly unwrapped into a 2D map, creating a perfect synergy with powerful 2D generative models. We then introduce Spherical Geometry Diffusion, a conditional diffusion framework built upon this 2D map. It enables diverse and controllable generation by jointly modeling geometry and texture, where the geometry explicitly conditions the texture synthesis process. Our method's effectiveness is demonstrated through its success in a wide range of tasks: text-to-3D generation, face reconstruction, and text-based 3D editing. Extensive experiments show that our approach substantially outperforms existing methods in geometric quality, textual fidelity, and inference efficiency.

</details>


### [185] [A Lightweight Model-Driven 4D Radar Framework for Pervasive Human Detection in Harsh Conditions](https://arxiv.org/abs/2601.13373)
*Zhenan Liu,Amir Khajepour,George Shaker*

Main category: cs.CV

TL;DR: 提出一个完全模型驱动的4D毫米波雷达感知框架，用于恶劣工业环境中的实时人体检测，在粉尘和能见度下降条件下比相机和LiDAR更可靠。


<details>
  <summary>Details</summary>
Motivation: 工业环境和地下空间中的粉尘、烟雾、狭窄几何结构和金属结构严重限制了光学和LiDAR感知，需要能在恶劣条件下可靠工作的感知系统。

Method: 开发了一个完全模型驱动的4D雷达感知框架，包括：领域感知多阈值滤波、自我运动补偿时间累积、KD树欧几里得聚类与多普勒感知细化、基于规则的3D分类器。

Result: 在粉尘填充的封闭拖车和真实地下采矿隧道中评估，雷达检测器在相机和LiDAR因严重能见度下降而失效时，仍能保持稳定的行人识别。

Conclusion: 提出的模型驱动方法为恶劣工业和地下环境中的安全关键应用提供了鲁棒、可解释且计算高效的感知解决方案。

Abstract: Pervasive sensing in industrial and underground environments is severely constrained by airborne dust, smoke, confined geometry, and metallic structures, which rapidly degrade optical and LiDAR based perception. Elevation resolved 4D mmWave radar offers strong resilience to such conditions, yet there remains a limited understanding of how to process its sparse and anisotropic point clouds for reliable human detection in enclosed, visibility degraded spaces. This paper presents a fully model-driven 4D radar perception framework designed for real-time execution on embedded edge hardware. The system uses radar as its sole perception modality and integrates domain aware multi threshold filtering, ego motion compensated temporal accumulation, KD tree Euclidean clustering with Doppler aware refinement, and a rule based 3D classifier. The framework is evaluated in a dust filled enclosed trailer and in real underground mining tunnels, and in the tested scenarios the radar based detector maintains stable pedestrian identification as camera and LiDAR modalities fail under severe visibility degradation. These results suggest that the proposed model-driven approach provides robust, interpretable, and computationally efficient perception for safety-critical applications in harsh industrial and subterranean environments.

</details>


### [186] [Practical Insights into Semi-Supervised Object Detection Approaches](https://arxiv.org/abs/2601.13380)
*Chaoxin Wang,Bharaneeshwar Balasubramaniyam,Anurag Sangem,Nicolais Guevara,Doina Caragea*

Main category: cs.CV

TL;DR: 本文对三种先进的半监督目标检测方法（MixPL、Semi-DETR、Consistent-Teacher）在数据稀缺场景下进行综合比较，分析标注图像数量对性能的影响。


<details>
  <summary>Details</summary>
Motivation: 数据稀缺场景下的学习研究日益重要，半监督目标检测旨在利用大量未标注图像和少量标注图像提升检测性能。需要理解不同方法在不同标注数据量下的表现差异。

Method: 使用MS-COCO和Pascal VOC两个标准目标检测数据集，以及自定义的Beetle数据集，对三种SOTA SSOD方法（MixPL、Semi-DETR、Consistent-Teacher）进行系统实验比较，分析标注图像数量变化对性能的影响。

Result: 实验揭示了不同方法在准确率、模型大小和延迟之间的权衡关系，为低数据场景下的方法选择提供了重要见解。

Conclusion: 研究为数据稀缺场景下的半监督目标检测方法选择提供了实证指导，帮助研究者根据具体需求（精度、效率、数据特性）选择最合适的方法。

Abstract: Learning in data-scarce settings has recently gained significant attention in the research community. Semi-supervised object detection(SSOD) aims to improve detection performance by leveraging a large number of unlabeled images alongside a limited number of labeled images(a.k.a.,few-shot learning). In this paper, we present a comprehensive comparison of three state-of-the-art SSOD approaches, including MixPL, Semi-DETR and Consistent-Teacher, with the goal of understanding how performance varies with the number of labeled images. We conduct experiments using the MS-COCO and Pascal VOC datasets, two popular object detection benchmarks which allow for standardized evaluation. In addition, we evaluate the SSOD approaches on a custom Beetle dataset which enables us to gain insights into their performance on specialized datasets with a smaller number of object categories. Our findings highlight the trade-offs between accuracy, model size, and latency, providing insights into which methods are best suited for low-data regimes.

</details>


### [187] [Organ-Aware Attention Improves CT Triage and Classification](https://arxiv.org/abs/2601.13385)
*Lavsen Dahal,Yubraj Bhandari,Geoffrey D. Rubin,Joseph Y. Lo*

Main category: cs.CV

TL;DR: ORACLE-CT：一种用于CT影像分类的器官感知注意力模型，在胸部和腹部CT分类任务中达到最先进的监督性能


<details>
  <summary>Details</summary>
Motivation: 需要解决大规模医学影像（如CT）的分类和分诊问题，以改善患者护理并减轻放射科医生负担。现有视觉语言模型在3D解剖结构、协议变化和噪声报告监督方面存在困难。

Method: 提出ORACLE-CT，一种编码器无关的器官感知头部，结合器官掩码注意力（产生空间证据）和器官标量融合（融合归一化体积和平均HU值线索）。使用CT-RATE和RADCHEST-CT数据集进行验证。

Result: 在胸部CT-RATE数据集上达到AUROC 0.86；在腹部MERLIN数据集（30个发现）上，监督基线超过零样本VLM基线，加入掩码注意力和标量融合后性能提升至AUROC 0.85。

Conclusion: ORACLE-CT在统一评估协议下，在胸部和腹部CT分类任务中实现了最先进的监督分类性能，为医学影像分诊提供了有效解决方案。

Abstract: There is an urgent need for triage and classification of high-volume medical imaging modalities such as computed tomography (CT), which can improve patient care and mitigate radiologist burnout. Study-level CT triage requires calibrated predictions with localized evidence; however, off-the-shelf Vision Language Models (VLM) struggle with 3D anatomy, protocol shifts, and noisy report supervision. This study used the two largest publicly available chest CT datasets: CT-RATE and RADCHEST-CT (held-out external test set). Our carefully tuned supervised baseline (instantiated as a simple Global Average Pooling head) establishes a new supervised state of the art, surpassing all reported linear-probe VLMs. Building on this baseline, we present ORACLE-CT, an encoder-agnostic, organ-aware head that pairs Organ-Masked Attention (mask-restricted, per-organ pooling that yields spatial evidence) with Organ-Scalar Fusion (lightweight fusion of normalized volume and mean-HU cues). In the chest setting, ORACLE-CT masked attention model achieves AUROC 0.86 on CT-RATE; in the abdomen setting, on MERLIN (30 findings), our supervised baseline exceeds a reproduced zero-shot VLM baseline obtained by running publicly released weights through our pipeline, and adding masked attention plus scalar fusion further improves performance to AUROC 0.85. Together, these results deliver state-of-the-art supervised classification performance across both chest and abdomen CT under a unified evaluation protocol. The source code is available at https://github.com/lavsendahal/oracle-ct.

</details>


### [188] [Leveraging Transformer Decoder for Automotive Radar Object Detection](https://arxiv.org/abs/2601.13386)
*Changxu Zhang,Zhaoze Wang,Tai Fei,Christopher Grimm,Yi Jin,Claas Tebruegge,Ernst Warsitz,Markus Gardill*

Main category: cs.CV

TL;DR: 提出基于Transformer的3D雷达目标检测架构，使用Transformer Decoder作为预测头直接从雷达特征回归3D边界框和类别分数，通过Pyramid Token Fusion模块融合多尺度特征，将检测建模为集合预测问题。


<details>
  <summary>Details</summary>
Motivation: 传统雷达目标检测方法通常需要密集的候选框生成和启发式的后处理（如NMS调参），这些步骤计算量大且需要手动调整。本文旨在设计一个端到端的检测框架，消除这些繁琐步骤，同时更好地建模雷达数据中的长距离时空关联和跨特征交互。

Method: 1. 使用Transformer Decoder作为预测头直接回归3D边界框和类别分数；2. 提出Pyramid Token Fusion (PTF)轻量级模块，将特征金字塔转换为统一的、尺度感知的token序列；3. 将检测建模为集合预测问题，使用可学习的对象查询和位置编码；4. 无需密集候选框生成和NMS后处理。

Result: 在RADDet数据集上评估，相比最先进的纯雷达基线方法取得了显著改进。

Conclusion: 提出的基于Transformer的3D雷达目标检测框架通过端到端的集合预测方法，成功消除了传统检测流程中的密集候选框生成和NMS后处理需求，同时通过建模长距离时空关联提升了检测性能。

Abstract: In this paper, we present a Transformer-based architecture for 3D radar object detection that uses a novel Transformer Decoder as the prediction head to directly regress 3D bounding boxes and class scores from radar feature representations. To bridge multi-scale radar features and the decoder, we propose Pyramid Token Fusion (PTF), a lightweight module that converts a feature pyramid into a unified, scale-aware token sequence. By formulating detection as a set prediction problem with learnable object queries and positional encodings, our design models long-range spatial-temporal correlations and cross-feature interactions. This approach eliminates dense proposal generation and heuristic post-processing such as extensive non-maximum suppression (NMS) tuning. We evaluate the proposed framework on the RADDet, where it achieves significant improvements over state-of-the-art radar-only baselines.

</details>


### [189] [Deep Image Prior with L0 Gradient Regularizer for Image Smoothing](https://arxiv.org/abs/2601.13400)
*Nhat Thanh Tran,Kevin Bui,Jack Xin*

Main category: cs.CV

TL;DR: 提出DIP-ℓ₀框架，结合深度图像先验和ℓ₀梯度正则化，无需训练数据实现高质量图像平滑


<details>
  <summary>Details</summary>
Motivation: 传统图像平滑方法依赖局部窗口统计或优化问题，深度学习方法需要精心构建的训练数据集，但构建合适的图像平滑训练数据集具有挑战性

Method: 提出DIP-ℓ₀框架，将ℓ₀梯度正则化融入深度图像先验，使用ADMM算法优化非凸非光滑的ℓ₀"范数"损失函数，利用现成的ℓ₀梯度最小化求解器

Result: 数值实验表明，DIP-ℓ₀在边缘保持图像平滑和JPEG伪影去除方面优于许多现有图像平滑算法

Conclusion: DIP-ℓ₀框架无需训练数据即可实现高质量图像平滑，在边缘保持和伪影去除方面表现优异，为图像平滑提供了有效的无监督深度学习方法

Abstract: Image smoothing is a fundamental image processing operation that preserves the underlying structure, such as strong edges and contours, and removes minor details and textures in an image. Many image smoothing algorithms rely on computing local window statistics or solving an optimization problem. Recent state-of-the-art methods leverage deep learning, but they require a carefully curated training dataset. Because constructing a proper training dataset for image smoothing is challenging, we propose DIP-$\ell_0$, a deep image prior framework that incorporates the $\ell_0$ gradient regularizer. This framework can perform high-quality image smoothing without any training data. To properly minimize the associated loss function that has the nonconvex, nonsmooth $\ell_0$ ``norm", we develop an alternating direction method of multipliers algorithm that utilizes an off-the-shelf $\ell_0$ gradient minimization solver. Numerical experiments demonstrate that the proposed DIP-$\ell_0$ outperforms many image smoothing algorithms in edge-preserving image smoothing and JPEG artifact removal.

</details>


### [190] [Reasoning with Pixel-level Precision: QVLM Architecture and SQuID Dataset for Quantitative Geospatial Analytics](https://arxiv.org/abs/2601.13401)
*Peter A. Massih,Eric Cosatto*

Main category: cs.CV

TL;DR: 本文针对当前视觉语言模型在定量空间推理上的失败，提出了SQuID基准数据集和QVLM模型架构，通过代码生成保持像素级精度，显著提升了卫星图像定量推理性能。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在定量空间推理任务上表现不佳，主要因为其架构通过patch嵌入压缩图像，破坏了像素级信息，导致计数和测量所需的精确空间索引丢失。

Method: 提出两个贡献：1) SQuID数据集：包含2000个卫星图像问答对，涵盖数值范围和分类答案，分为三个难度层级；2) QVLM模型：采用代码生成架构，将语言理解与视觉分析解耦，通过生成可执行代码调用分割模型获取像素级掩码，直接在掩码上进行操作。

Result: QVLM使用GPT-5作为编码器，在SQuID基准上达到42.0%的准确率，显著优于传统VLM的28.1%。

Conclusion: 对于定量空间推理任务，架构解耦能够保持像素级精度，显著提升准确性，为卫星图像定量分析提供了有效解决方案。

Abstract: Current Vision-Language Models (VLMs) fail at quantitative spatial reasoning because their architectures destroy pixel-level information required for counting and measurements. Vision encoders compress images through patch embeddings, reducing spatial indexing and losing the precise pixel-level tracking required for accurate counting. We present two contributions to address this fundamental limitation. First, we introduce SQuID (Satellite Quantitative Intelligence Dataset), a benchmark of 2,000 satellite image Question-Answer pairs with both numerical range and categorical answers, designed to evaluate quantitative spatial reasoning. The dataset spans three difficulty tiers with annotations automatically generated from human labels and their learned variability. Second, we propose QVLM (Quantitative Vision-Language Model), a code-generation architecture that maintains pixel precision by decoupling language understanding from visual analysis. Instead of encoding images into embeddings, QVLM generates executable code that first calls a segmentation model to obtain pixel-level masks, then operates directly on these masks, preserving spatial indexing throughout the reasoning process. Our experiments show that QVLM using GPT-5 as coder achieves 42.0% accuracy on SQuID compared to 28.1% for a VLM prompted with image-question pairs. Our work reveals that, for quantitative spatial reasoning, architectural decoupling enables better accuracy on quantitative tasks.

</details>


### [191] [Local-to-Global Logical Explanations for Deep Vision Models](https://arxiv.org/abs/2601.13404)
*Bhavan Vasu,Giuseppe Raffa,Prasad Tadepalli*

Main category: cs.CV

TL;DR: 提出基于可识别原始概念的黑盒模型解释方法，使用单调析取范式逻辑公式生成局部和全局解释，在视觉数据集上保持高保真度和覆盖率。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络虽然图像分类效果出色，但缺乏可解释性，是黑盒模型。需要开发能够生成人类可理解概念解释的方法。

Method: 1. 局部解释（单张图像）和全局解释（图像集）都表示为单调析取范式逻辑公式；2. 公式满足时保证模型对给定类别给出高分；3. 提出多类别分类解释算法，生成基于原始概念的单调解释列表。

Result: 尽管方法简单且可解释性强，但在具有挑战性的视觉数据集上，解释方法对目标黑盒模型保持了高保真度和覆盖率。

Conclusion: 提出的基于原始概念的解释方法能够有效解释黑盒模型决策，平衡了可解释性与模型保真度，为深度学习模型提供透明解释。

Abstract: While deep neural networks are extremely effective at classifying images, they remain opaque and hard to interpret. We introduce local and global explanation methods for black-box models that generate explanations in terms of human-recognizable primitive concepts. Both the local explanations for a single image and the global explanations for a set of images are cast as logical formulas in monotone disjunctive-normal-form (MDNF), whose satisfaction guarantees that the model yields a high score on a given class. We also present an algorithm for explaining the classification of examples into multiple classes in the form of a monotone explanation list over primitive concepts. Despite their simplicity and interpretability we show that the explanations maintain high fidelity and coverage with respect to the blackbox models they seek to explain in challenging vision datasets.

</details>


### [192] [Using deep learning for predicting cleansing quality of colon capsule endoscopy images](https://arxiv.org/abs/2601.13412)
*Puneet Sharma,Kristian Dalsbø Hindberg,Benedicte Schelde-Olesen,Ulrik Deding,Esmaeil S. Nadimi,Jan-Matthias Braun*

Main category: cs.CV

TL;DR: 使用ResNet-18模型预测结肠胶囊内镜图像清洁质量，通过结构化剪枝实现79%稀疏度同时保持88%准确率，并利用多种CAM方法进行模型可解释性分析。


<details>
  <summary>Details</summary>
Motivation: 结肠胶囊内镜图像清洁质量评估对临床诊断至关重要，但传统评估方法存在主观性和不一致性。需要开发自动化的深度学习模型来提供客观、一致的清洁质量预测，同时确保模型在临床环境中的可解释性和效率。

Method: 使用500张由14名临床医生标注的结肠胶囊内镜图像数据集，基于Leighton-Rex量表（差、一般、好、优秀）进行标注。采用ResNet-18模型进行分类，使用分层K折交叉验证确保稳健性。应用结构化剪枝技术迭代优化模型，实现高稀疏度。使用Grad-CAM、Grad-CAM++、Eigen-CAM、Ablation-CAM和Random-CAM进行可解释性分析，采用ROAD方法进行一致性评估。最后使用自适应温度缩放变体对剪枝模型进行外部数据集校准。

Result: 剪枝后的模型在保持88%交叉验证准确率的同时实现了79%的稀疏度，相比未剪枝模型84%的准确率有所提升。研究还展示了剪枝在提高效率方面的有效性，同时讨论了CCE图像清洁质量评估的挑战、可解释性在临床应用中的重要性，以及ROAD方法在本任务中使用的挑战。

Conclusion: 结构化剪枝技术能够显著提高结肠胶囊内镜清洁质量预测模型的效率，同时保持高准确率。模型可解释性对于临床应用至关重要，多种CAM方法结合ROAD评估提供了深入的分析。自适应温度缩放有助于模型在外部数据集上的校准，增强了模型的泛化能力。

Abstract: In this study, we explore the application of deep learning techniques for predicting cleansing quality in colon capsule endoscopy (CCE) images. Using a dataset of 500 images labeled by 14 clinicians on the Leighton-Rex scale (Poor, Fair, Good, and Excellent), a ResNet-18 model was trained for classification, leveraging stratified K-fold cross-validation to ensure robust performance. To optimize the model, structured pruning techniques were applied iteratively, achieving significant sparsity while maintaining high accuracy. Explainability of the pruned model was evaluated using Grad-CAM, Grad-CAM++, Eigen-CAM, Ablation-CAM, and Random-CAM, with the ROAD method employed for consistent evaluation. Our results indicate that for a pruned model, we can achieve a cross-validation accuracy of 88% with 79% sparsity, demonstrating the effectiveness of pruning in improving efficiency from 84% without compromising performance. We also highlight the challenges of evaluating cleansing quality of CCE images, emphasize the importance of explainability in clinical applications, and discuss the challenges associated with using the ROAD method for our task. Finally, we employ a variant of adaptive temperature scaling to calibrate the pruned models for an external dataset.

</details>


### [193] [Diffusion Representations for Fine-Grained Image Classification: A Marine Plankton Case Study](https://arxiv.org/abs/2601.13416)
*A. Nieto Juscafresa,Á. Mazcuñán Herreros,J. Sullivan*

Main category: cs.CV

TL;DR: 扩散模型作为图像生成SOTA方法，其作为通用特征编码器的潜力未被充分探索。研究表明冻结的扩散骨干网络通过探测中间去噪特征，在细粒度识别任务中表现出色，在浮游生物监测应用中超越其他自监督方法。


<details>
  <summary>Details</summary>
Motivation: 扩散模型作为最先进的图像生成方法，其作为通用特征编码器的潜力尚未被充分探索。虽然扩散模型在无标签条件下进行去噪和生成训练，可被视为自监督学习器，能够捕捉低层和高层结构，但其在特征表示方面的能力需要进一步验证。

Method: 使用冻结的扩散模型骨干网络，探测中间去噪特征（跨层和时间步），为每一对特征训练线性分类器。在真实世界的浮游生物监测场景中，通过受控且可比较的训练设置，与已有的监督和自监督基线方法进行对比评估。

Result: 冻结的扩散特征与监督基线方法表现相当，在平衡和自然长尾设置中均优于其他自监督方法。在时间和地理分布偏移的浮游生物数据集上进行OOD评估显示，冻结扩散特征在显著分布偏移下仍保持较高的准确率和Macro F1分数。

Conclusion: 扩散模型不仅是强大的生成模型，也是有效的通用特征编码器。冻结的扩散骨干网络能够提供高质量的特征表示，在细粒度识别任务中表现出色，特别是在分布偏移情况下具有鲁棒性，为自监督特征学习提供了有前景的新方向。

Abstract: Diffusion models have emerged as state-of-the-art generative methods for image synthesis, yet their potential as general-purpose feature encoders remains underexplored. Trained for denoising and generation without labels, they can be interpreted as self-supervised learners that capture both low- and high-level structure. We show that a frozen diffusion backbone enables strong fine-grained recognition by probing intermediate denoising features across layers and timesteps and training a linear classifier for each pair. We evaluate this in a real-world plankton-monitoring setting with practical impact, using controlled and comparable training setups against established supervised and self-supervised baselines. Frozen diffusion features are competitive with supervised baselines and outperform other self-supervised methods in both balanced and naturally long-tailed settings. Out-of-distribution evaluations on temporally and geographically shifted plankton datasets further show that frozen diffusion features maintain strong accuracy and Macro F1 under substantial distribution shift.

</details>


### [194] [SGW-GAN: Sliced Gromov-Wasserstein Guided GANs for Retinal Fundus Image Enhancement](https://arxiv.org/abs/2601.13417)
*Yujian Xiong,Xuanzhao Dong,Wenhui Zhu,Xin Li,Oana Dumitrascu,Yalin Wang*

Main category: cs.CV

TL;DR: 提出SGW-GAN框架，首次将切片Gromov Wasserstein距离引入视网膜图像增强，在提升图像质量的同时保持疾病分类的几何结构，改善下游临床任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有GAN和扩散模型在视网膜图像增强中过度关注感知质量，导致类内几何结构扭曲（临床相关样本分散、疾病边界模糊），损害下游诊断任务。需要一种既能提升图像质量又能保持临床相关结构的方法。

Method: 提出SGW-GAN框架，首次将切片Gromov Wasserstein距离整合到视网膜图像增强中。SGW通过随机投影近似GW距离，保留了分布间的成对距离关系（保持类内结构），同时大幅降低计算成本。

Result: 在公开数据集上，SGW-GAN产生视觉上令人满意的增强效果，在糖尿病视网膜病变分级任务上表现最优，并在疾病标签间报告最低的GW差异，证明了效率和临床保真度。

Conclusion: SGW-GAN为无配对医学图像增强提供了一种高效且临床保真的解决方案，通过保留类内几何结构，既改善了图像质量又提升了下游诊断任务的性能。

Abstract: Retinal fundus photography is indispensable for ophthalmic screening and diagnosis, yet image quality is often degraded by noise, artifacts, and uneven illumination. Recent GAN- and diffusion-based enhancement methods improve perceptual quality by aligning degraded images with high-quality distributions, but our analysis shows that this focus can distort intra-class geometry: clinically related samples become dispersed, disease-class boundaries blur, and downstream tasks such as grading or lesion detection are harmed. The Gromov Wasserstein (GW) discrepancy offers a principled solution by aligning distributions through internal pairwise distances, naturally preserving intra-class structure, but its high computational cost restricts practical use. To overcome this, we propose SGW-GAN, the first framework to incorporate Sliced GW (SGW) into retinal image enhancement. SGW approximates GW via random projections, retaining relational fidelity while greatly reducing cost. Experiments on public datasets show that SGW-GAN produces visually compelling enhancements, achieves superior diabetic retinopathy grading, and reports the lowest GW discrepancy across disease labels, demonstrating both efficiency and clinical fidelity for unpaired medical image enhancement.

</details>


### [195] [Analyzing VLM-Based Approaches for Anomaly Classification and Segmentation](https://arxiv.org/abs/2601.13440)
*Mohit Kakda,Mirudula Shri Muthukumaran,Uttapreksha Patel,Lawrence Swaminathan Xavier Prince*

Main category: cs.CV

TL;DR: 该论文系统分析了基于视觉语言模型（VLMs）的异常检测方法，重点研究了CLIP在零样本/少样本异常分类和分割中的应用，比较了不同架构范式在多个维度上的性能表现。


<details>
  <summary>Details</summary>
Motivation: 传统异常检测方法需要大量标注数据和特定任务训练，而视觉语言模型通过学习图像和文本的对齐表示，能够实现零样本和少样本的缺陷识别，无需大量标注数据或缺陷样本，这为工业质量控制提供了更高效的解决方案。

Method: 系统研究了三种关键架构范式：1）基于滑动窗口的密集特征提取（WinCLIP）；2）具有可学习投影的多阶段特征对齐（AprilLab框架）；3）组合提示集成策略。从特征提取机制、文本-视觉对齐策略、提示工程、零样本与少样本权衡、计算效率和跨域泛化等多个维度进行分析。

Result: 通过在MVTec AD和VisA等基准数据集上的严格实验，比较了分类准确率、分割精度和推理效率。结果表明VLM方法在异常检测方面具有显著优势，特别是在零样本和少样本场景下。

Conclusion: 该研究为理解VLM在异常检测中的成功机制提供了基础性认识，为方法选择提供了实用见解，并指出了当前限制。这项工作旨在促进VLM方法在工业质量控制中的明智采用，并指导未来研究方向。

Abstract: Vision-Language Models (VLMs), particularly CLIP, have revolutionized anomaly detection by enabling zero-shot and few-shot defect identification without extensive labeled datasets. By learning aligned representations of images and text, VLMs facilitate anomaly classification and segmentation through natural language descriptions of normal and abnormal states, eliminating traditional requirements for task-specific training or defect examples. This project presents a comprehensive analysis of VLM-based approaches for anomaly classification (AC) and anomaly segmentation (AS). We systematically investigate key architectural paradigms including sliding window-based dense feature extraction (WinCLIP), multi-stage feature alignment with learnable projections (AprilLab framework), and compositional prompt ensemble strategies. Our analysis evaluates these methods across critical dimensions: feature extraction mechanisms, text-visual alignment strategies, prompt engineering techniques, zero-shot versus few-shot trade-offs, computational efficiency, and cross-domain generalization. Through rigorous experimentation on benchmarks such as MVTec AD and VisA, we compare classification accuracy, segmentation precision, and inference efficiency. The primary contribution is a foundational understanding of how and why VLMs succeed in anomaly detection, synthesizing practical insights for method selection and identifying current limitations. This work aims to facilitate informed adoption of VLM-based methods in industrial quality control and guide future research directions.

</details>


### [196] [Optical Linear Systems Framework for Event Sensing and Computational Neuromorphic Imaging](https://arxiv.org/abs/2601.13498)
*Nimrod Kruger,Nicholas Owen Ralph,Gregory Cohen,Paul Hurley*

Main category: cs.CV

TL;DR: 提出了一种将事件相机数据映射到对数强度和强度导数估计，并嵌入动态线性系统模型的方法，使事件数据能够直接进行逆滤波和维纳解卷积。


<details>
  <summary>Details</summary>
Motivation: 事件视觉传感器（神经形态相机）输出稀疏、异步的ON/OFF事件，具有微秒级传感、高动态范围和低数据带宽的优势。然而，这种非线性事件表示难以与大多数计算成像和光学系统设计所依赖的线性前向模型集成。

Method: 提出了一个基于物理的处理流程：1) 将事件流映射到每个像素的对数强度和强度导数估计；2) 将这些测量嵌入具有时变点扩散函数的动态线性系统模型；3) 使用频域维纳解卷积与已知（或参数化）的动态传递函数，直接从事件数据进行逆滤波。

Result: 在模拟中验证了调制离焦下单点和重叠点源的方法，并在真实事件数据上（来自可调焦望远镜拍摄星场）展示了源定位和可分离性，证明了该方法的有效性。

Conclusion: 该框架为事件传感和基于模型的计算成像之间建立了实用的桥梁，特别适用于动态光学系统。

Abstract: Event vision sensors (neuromorphic cameras) output sparse, asynchronous ON/OFF events triggered by log-intensity threshold crossings, enabling microsecond-scale sensing with high dynamic range and low data bandwidth. As a nonlinear system, this event representation does not readily integrate with the linear forward models that underpin most computational imaging and optical system design. We present a physics-grounded processing pipeline that maps event streams to estimates of per-pixel log-intensity and intensity derivatives, and embeds these measurements in a dynamic linear systems model with a time-varying point spread function. This enables inverse filtering directly from event data, using frequency-domain Wiener deconvolution with a known (or parameterised) dynamic transfer function. We validate the approach in simulation for single and overlapping point sources under modulated defocus, and on real event data from a tunable-focus telescope imaging a star field, demonstrating source localisation and separability. The proposed framework provides a practical bridge between event sensing and model-based computational imaging for dynamic optical systems.

</details>


### [197] [DIS2: Disentanglement Meets Distillation with Classwise Attention for Robust Remote Sensing Segmentation under Missing Modalities](https://arxiv.org/abs/2601.13502)
*Nhi Kieu,Kien Nguyen,Arnold Wiliem,Clinton Fookes,Sridha Sridharan*

Main category: cs.CV

TL;DR: DIS2：一种针对遥感多模态学习的新范式，通过DLKD（解缠学习与知识蒸馏协同）和CFLM（类特定特征学习模块）解决模态缺失问题，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 遥感多模态学习面临模态缺失的严重挑战，且数据高度异构、尺度变化大。传统解缠学习依赖模态间特征重叠，不适用于异构数据；知识蒸馏则成为不明确的模仿任务，无法弥补语义鸿沟。

Method: 提出DIS2方法，包含三个核心：1）DLKD：重新构建解缠学习与知识蒸馏的协同，明确捕获补偿特征；2）CFLM：类特定特征学习模块，自适应学习每个目标的判别证据；3）分层混合融合结构，利用多分辨率特征增强预测。

Result: 大量实验验证，所提方法在多个基准测试中显著优于最先进的方法。

Conclusion: DIS2通过从模态共享特征依赖和无目标模仿转向主动、引导的缺失特征补偿，为遥感多模态学习提供了有效解决方案，解决了异构数据和尺度变化带来的独特挑战。

Abstract: The efficacy of multimodal learning in remote sensing (RS) is severely undermined by missing modalities. The challenge is exacerbated by the RS highly heterogeneous data and huge scale variation. Consequently, paradigms proven effective in other domains often fail when confronted with these unique data characteristics. Conventional disentanglement learning, which relies on significant feature overlap between modalities (modality-invariant), is insufficient for this heterogeneity. Similarly, knowledge distillation becomes an ill-posed mimicry task where a student fails to focus on the necessary compensatory knowledge, leaving the semantic gap unaddressed. Our work is therefore built upon three pillars uniquely designed for RS: (1) principled missing information compensation, (2) class-specific modality contribution, and (3) multi-resolution feature importance. We propose a novel method DIS2, a new paradigm shifting from modality-shared feature dependence and untargeted imitation to active, guided missing features compensation. Its core novelty lies in a reformulated synergy between disentanglement learning and knowledge distillation, termed DLKD. Compensatory features are explicitly captured which, when fused with the features of the available modality, approximate the ideal fused representation of the full-modality case. To address the class-specific challenge, our Classwise Feature Learning Module (CFLM) adaptively learn discriminative evidence for each target depending on signal availability. Both DLKD and CFLM are supported by a hierarchical hybrid fusion (HF) structure using features across resolutions to strengthen prediction. Extensive experiments validate that our proposed approach significantly outperforms state-of-the-art methods across benchmarks.

</details>


### [198] [GO-MLVTON: Garment Occlusion-Aware Multi-Layer Virtual Try-On with Diffusion Models](https://arxiv.org/abs/2601.13524)
*Yang Yu,Yunze Deng,Yige Zhang,Yanjie Xiao,Youkun Ou,Wenhao Hu,Mingchao Li,Bin Feng,Wenyu Liu,Dandan Zheng,Jingdong Chen*

Main category: cs.CV

TL;DR: GO-MLVTON是首个多层虚拟试穿方法，通过服装遮挡学习和基于StableDiffusion的服装变形拟合模块，解决多层服装试穿中的遮挡关系和变形问题。


<details>
  <summary>Details</summary>
Motivation: 现有虚拟试穿方法主要关注单层或多件服装试穿，忽略了多层服装试穿（ML-VTON），即需要将多层服装穿在人体上并产生真实的变形和层次感。主要挑战在于准确建模内外服装之间的遮挡关系，以减少冗余内层服装特征的干扰。

Method: 提出GO-MLVTON方法，包含两个核心模块：1) 服装遮挡学习模块，用于学习遮挡关系；2) 基于StableDiffusion的服装变形与拟合模块，用于将服装变形并贴合到人体上。此外还构建了MLG数据集用于该任务。

Result: 实验表明GO-MLVTON取得了最先进的性能。同时提出了新的评估指标Layered Appearance Coherence Difference（LACD）用于评估多层试穿效果。

Conclusion: GO-MLVTON是首个解决多层虚拟试穿问题的方法，通过遮挡学习和服装变形拟合，能够生成高质量的多层试穿结果，为多层服装试穿任务提供了有效的解决方案。

Abstract: Existing Image-based virtual try-on (VTON) methods primarily focus on single-layer or multi-garment VTON, neglecting multi-layer VTON (ML-VTON), which involves dressing multiple layers of garments onto the human body with realistic deformation and layering to generate visually plausible outcomes. The main challenge lies in accurately modeling occlusion relationships between inner and outer garments to reduce interference from redundant inner garment features. To address this, we propose GO-MLVTON, the first multi-layer VTON method, introducing the Garment Occlusion Learning module to learn occlusion relationships and the StableDiffusion-based Garment Morphing & Fitting module to deform and fit garments onto the human body, producing high-quality multi-layer try-on results. Additionally, we present the MLG dataset for this task and propose a new metric named Layered Appearance Coherence Difference (LACD) for evaluation. Extensive experiments demonstrate the state-of-the-art performance of GO-MLVTON. Project page: https://upyuyang.github.io/go-mlvton/.

</details>


### [199] [CARPE: Context-Aware Image Representation Prioritization via Ensemble for Large Vision-Language Models](https://arxiv.org/abs/2601.13622)
*Donghee Lee,Rui Cai,Zhe Zhao*

Main category: cs.CV

TL;DR: CARPE是一个模型无关的框架，通过视觉集成层和上下文感知集成策略，让大型视觉语言模型在图像分类等视觉中心任务中更好地利用视觉表示，提升性能。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在图像分类等视觉中心任务上表现不佳，常常不如其基础的视觉编码器（如CLIP模型），需要解决这一局限性。

Method: 提出CARPE框架：1）引入视觉集成层；2）采用上下文感知集成策略，动态决定何时优先使用图像表示或依赖语言模型的推理能力；3）自适应加权视觉和文本模态。

Result: CARPE在图像分类基准测试中显著提升性能，同时在各种视觉语言基准测试中也获得改进，具有良好的泛化能力。

Conclusion: CARPE是一个有效的模型无关框架，能够与大多数开源大型视觉语言模型集成，提升其在视觉中心任务上的表现，同时保持对多样化架构的适应性。

Abstract: Recent advancements in Large Vision-Language Models (LVLMs) have pushed them closer to becoming general-purpose assistants. Despite their strong performance, LVLMs still struggle with vision-centric tasks such as image classification, underperforming compared to their base vision encoders, which are often CLIP-based models. To address this limitation, we propose Context-Aware Image Representation Prioritization via Ensemble (CARPE), a novel, model-agnostic framework which introduces vision-integration layers and a context-aware ensemble strategy to identify when to prioritize image representations or rely on the reasoning capabilities of the language model. This design enhances the model's ability to adaptively weight visual and textual modalities and enables the model to capture various aspects of image representations, leading to consistent improvements in generalization across classification and vision-language benchmarks. Extensive experiments demonstrate that CARPE not only improves performance on image classification benchmarks but also enhances results across various vision-language benchmarks. Finally, CARPE is designed to be effectively integrated with most open-source LVLMs that consist of a vision encoder and a language model, ensuring its adaptability across diverse architectures.

</details>


### [200] [DiffFace-Edit: A Diffusion-Based Facial Dataset for Forgery-Semantic Driven Deepfake Detection Analysis](https://arxiv.org/abs/2601.13551)
*Feng Ding,Wenhui Yi,Xinan He,Mengyao Xiao,Jianfeng Xu,Jianqiang Du*

Main category: cs.CV

TL;DR: 提出了DiffFace-Edit数据集，包含200多万张AI生成的人脸图像，专注于细粒度区域编辑，并首次研究了拼接攻击对检测器的影响。


<details>
  <summary>Details</summary>
Motivation: 当前生成模型能产生难以察觉的细粒度人脸篡改，带来隐私风险，但现有数据集缺乏细粒度区域操作的样本，且无人研究真实与生成样本间的拼接攻击对检测器的影响。

Method: 创建DiffFace-Edit数据集，包含200多万张AI生成假图像，涵盖8个面部区域（如眼睛、鼻子）的编辑，包括单区域和多区域编辑组合。提出跨域评估方法，结合IMDL方法分析检测器逃避样本的影响。

Result: 建立了大规模细粒度人脸编辑数据集，首次系统分析了检测器逃避样本对检测模型的影响，为相关研究提供了重要数据基础。

Conclusion: DiffFace-Edit数据集填补了细粒度区域操作数据集的空白，为研究AI生成人脸检测和拼接攻击影响提供了重要资源，有助于提升检测模型的鲁棒性。

Abstract: Generative models now produce imperceptible, fine-grained manipulated faces, posing significant privacy risks. However, existing AI-generated face datasets generally lack focus on samples with fine-grained regional manipulations. Furthermore, no researchers have yet studied the real impact of splice attacks, which occur between real and manipulated samples, on detectors. We refer to these as detector-evasive samples. Based on this, we introduce the DiffFace-Edit dataset, which has the following advantages: 1) It contains over two million AI-generated fake images. 2) It features edits across eight facial regions (e.g., eyes, nose) and includes a richer variety of editing combinations, such as single-region and multi-region edits. Additionally, we specifically analyze the impact of detector-evasive samples on detection models. We conduct a comprehensive analysis of the dataset and propose a cross-domain evaluation that combines IMDL methods. Dataset will be available at https://github.com/ywh1093/DiffFace-Edit.

</details>


### [201] [Learning Fine-Grained Correspondence with Cross-Perspective Perception for Open-Vocabulary 6D Object Pose Estimation](https://arxiv.org/abs/2601.13565)
*Yu Qin,Shimeng Fan,Fan Yang,Zixuan Xue,Zijie Mai,Wenrui Chen,Kailun Yang,Zhiyong Li*

Main category: cs.CV

TL;DR: FiCoP提出了一种从噪声全局匹配转向空间约束的patch级对应的细粒度对应姿态估计框架，通过patch-to-patch相关矩阵作为结构先验来缩小匹配范围，在开放世界场景中显著提升6D姿态估计性能。


<details>
  <summary>Details</summary>
Motivation: 现有开放词汇6D物体姿态估计方法依赖无约束的全局匹配策略，在开放世界场景中，将锚点特征与整个查询图像空间匹配会引入过多歧义，目标特征容易与背景干扰物混淆，导致姿态估计性能下降。

Method: 1) 物体中心解耦预处理：隔离语义目标与环境噪声；2) 跨视角全局感知模块：融合双视角特征，通过显式上下文推理建立结构共识；3) Patch相关预测器：生成精确的块级关联图，作为空间滤波器实现细粒度、抗噪声的匹配。

Result: 在REAL275和Toyota-Light数据集上，FiCoP相比最先进方法分别提升了8.0%和6.1%的平均召回率，证明了其在复杂、无约束开放世界环境中为机器人提供鲁棒和泛化感知的能力。

Conclusion: FiCoP通过从全局匹配转向空间约束的patch级对应，有效解决了开放词汇6D姿态估计中的歧义问题，为机器人在开放世界环境中的操作提供了更可靠的感知基础。

Abstract: Open-vocabulary 6D object pose estimation empowers robots to manipulate arbitrary unseen objects guided solely by natural language. However, a critical limitation of existing approaches is their reliance on unconstrained global matching strategies. In open-world scenarios, trying to match anchor features against the entire query image space introduces excessive ambiguity, as target features are easily confused with background distractors. To resolve this, we propose Fine-grained Correspondence Pose Estimation (FiCoP), a framework that transitions from noise-prone global matching to spatially-constrained patch-level correspondence. Our core innovation lies in leveraging a patch-to-patch correlation matrix as a structural prior to narrowing the matching scope, effectively filtering out irrelevant clutter to prevent it from degrading pose estimation. Firstly, we introduce an object-centric disentanglement preprocessing to isolate the semantic target from environmental noise. Secondly, a Cross-Perspective Global Perception (CPGP) module is proposed to fuse dual-view features, establishing structural consensus through explicit context reasoning. Finally, we design a Patch Correlation Predictor (PCP) that generates a precise block-wise association map, acting as a spatial filter to enforce fine-grained, noise-resilient matching. Experiments on the REAL275 and Toyota-Light datasets demonstrate that FiCoP improves Average Recall by 8.0% and 6.1%, respectively, compared to the state-of-the-art method, highlighting its capability to deliver robust and generalized perception for robotic agents operating in complex, unconstrained open-world environments. The source code will be made publicly available at https://github.com/zjjqinyu/FiCoP.

</details>


### [202] [DermaBench: A Clinician-Annotated Benchmark Dataset for Dermatology Visual Question Answering and Reasoning](https://arxiv.org/abs/2601.14084)
*Abdurrahim Yilmaz,Ozan Erdem,Ece Gokyayla,Ayda Acar,Burc Bugra Dagtas,Dilara Ilhan Erdil,Gulsum Gencoglan,Burak Temelkuran*

Main category: cs.CV

TL;DR: DermaBench是一个由临床医生标注的皮肤病视觉问答基准，基于DDI数据集构建，包含656张临床图像和约14,474个VQA标注，用于评估视觉语言模型在皮肤病学中的综合能力。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在皮肤病学中的评估主要局限于图像级分类任务（如病变识别），无法全面评估模型的多模态理解、语言基础和临床推理能力，需要专门的视觉问答基准来评估模型对皮肤病图像的解读、形态学推理和临床描述生成能力。

Method: 基于Diverse Dermatology Images (DDI)数据集，构建了包含656张临床图像（来自570名患者，涵盖Fitzpatrick皮肤类型I-VI）的基准。采用分层标注模式，包含22个主要问题类型（单选、多选和开放式问题），由专业皮肤科医生对每张图像进行诊断、解剖部位、病变形态、分布、表面特征、颜色和图像质量等标注，同时包含开放式叙述描述和总结。

Result: 创建了DermaBench基准，包含约14,474个VQA风格标注，作为仅元数据集发布以尊重上游许可，在哈佛Dataverse上公开可用。

Conclusion: DermaBench填补了皮肤病学中视觉问答基准的空白，能够全面评估视觉语言模型在皮肤病图像理解、临床推理和描述生成方面的能力，为模型开发和评估提供了重要资源。

Abstract: Vision-language models (VLMs) are increasingly important in medical applications; however, their evaluation in dermatology remains limited by datasets that focus primarily on image-level classification tasks such as lesion recognition. While valuable for recognition, such datasets cannot assess the full visual understanding, language grounding, and clinical reasoning capabilities of multimodal models. Visual question answering (VQA) benchmarks are required to evaluate how models interpret dermatological images, reason over fine-grained morphology, and generate clinically meaningful descriptions. We introduce DermaBench, a clinician-annotated dermatology VQA benchmark built on the Diverse Dermatology Images (DDI) dataset. DermaBench comprises 656 clinical images from 570 unique patients spanning Fitzpatrick skin types I-VI. Using a hierarchical annotation schema with 22 main questions (single-choice, multi-choice, and open-ended), expert dermatologists annotated each image for diagnosis, anatomic site, lesion morphology, distribution, surface features, color, and image quality, together with open-ended narrative descriptions and summaries, yielding approximately 14.474 VQA-style annotations. DermaBench is released as a metadata-only dataset to respect upstream licensing and is publicly available at Harvard Dataverse.

</details>


### [203] [ChartVerse: Scaling Chart Reasoning via Reliable Programmatic Synthesis from Scratch](https://arxiv.org/abs/2601.13606)
*Zheng Liu,Honglin Lin,Chonghan Qin,Xiaoyang Wang,Xin Gao,Yu Li,Mengzhang Cai,Yun Zhu,Zhanping Zhong,Qizhi Pei,Zhuoshi Pan,Xiaoran Shang,Bin Cui,Conghui He,Wentao Zhang,Lijun Wu*

Main category: cs.CV

TL;DR: ChartVerse框架通过量化图表复杂度和答案先行的逆向QA合成，生成高质量图表推理训练数据，使8B模型超越其教师模型性能。


<details>
  <summary>Details</summary>
Motivation: 开源视觉语言模型在图表推理方面的发展受到高质量训练数据缺乏的严重制约。现有数据集存在双重挑战：合成图表过于简单重复，而相关QA对存在幻觉且缺乏复杂任务所需的推理深度。

Method: 1) 提出Rollout Posterior Entropy(RPE)量化图表复杂度，指导复杂度感知图表编码器通过可执行程序自主合成多样化高复杂度图表；2) 采用答案先行的逆向QA合成范式，从源代码提取确定性答案，基于这些锚点生成问题，并进行严格一致性验证；3) 基于模型失败率筛选样本并提炼高质量思维链推理，进一步提升难度和推理深度。

Result: 构建了ChartVerse-SFT-600K和ChartVerse-RL-40K数据集，使用Qwen3-VL-30B-A3B-Thinking作为教师模型。ChartVerse-8B模型实现了最先进的性能，显著超越其教师模型，并与更强的Qwen3-VL-32B-Thinking模型相媲美。

Conclusion: ChartVerse框架成功解决了图表推理训练数据质量不足的问题，通过复杂度量化和答案先行的逆向合成方法，生成了高质量的训练数据，显著提升了模型在图表推理任务上的性能。

Abstract: Chart reasoning is a critical capability for Vision Language Models (VLMs). However, the development of open-source models is severely hindered by the lack of high-quality training data. Existing datasets suffer from a dual challenge: synthetic charts are often simplistic and repetitive, while the associated QA pairs are prone to hallucinations and lack the reasoning depth required for complex tasks. To bridge this gap, we propose ChartVerse, a scalable framework designed to synthesize complex charts and reliable reasoning data from scratch. (1) To address the bottleneck of simple patterns, we first introduce Rollout Posterior Entropy (RPE), a novel metric that quantifies chart complexity. Guided by RPE, we develop complexity-aware chart coder to autonomously synthesize diverse, high-complexity charts via executable programs. (2) To guarantee reasoning rigor, we develop truth-anchored inverse QA synthesis. Diverging from standard generation, we adopt an answer-first paradigm: we extract deterministic answers directly from the source code, generate questions conditional on these anchors, and enforce strict consistency verification. To further elevate difficulty and reasoning depth, we filter samples based on model fail-rate and distill high-quality Chain-of-Thought (CoT) reasoning. We curate ChartVerse-SFT-600K and ChartVerse-RL-40K using Qwen3-VL-30B-A3B-Thinking as the teacher. Experimental results demonstrate that ChartVerse-8B achieves state-of-the-art performance, notably surpassing its teacher and rivaling the stronger Qwen3-VL-32B-Thinking.

</details>


### [204] [The Side Effects of Being Smart: Safety Risks in MLLMs' Multi-Image Reasoning](https://arxiv.org/abs/2601.14127)
*Renmiao Chen,Yida Lu,Shiyao Cui,Xuan Ouyang,Victor Shea-Jay Huang,Shumin Zhang,Chengwei Pan,Han Qiu,Minlie Huang*

Main category: cs.CV

TL;DR: MIR-SafetyBench是首个专注于多图像推理安全性的基准测试，包含2,676个实例和9种多图像关系分类。研究发现，多图像推理能力更强的模型在安全性方面反而更脆弱，存在表面安全但实际误解或回避问题的响应模式。


<details>
  <summary>Details</summary>
Motivation: 随着多模态大语言模型在多图像复杂指令处理能力增强，这种进步可能带来新的安全风险。目前缺乏专门评估多图像推理安全性的基准测试，需要系统研究模型在多图像场景下的安全漏洞。

Method: 构建MIR-SafetyBench基准，包含2,676个实例，涵盖9种多图像关系分类。对19个MLLM进行广泛评估，分析攻击成功率、响应质量，并研究不安全生成与注意力熵之间的关系。

Result: 评估发现：1）多图像推理能力更强的模型在MIR-SafetyBench上更脆弱；2）许多标记为安全的响应是表面的，源于误解或回避性回答；3）不安全生成的注意力熵平均低于安全生成，表明模型可能过度专注于任务解决而忽视安全约束。

Conclusion: 多图像推理能力的提升可能伴随新的安全风险，需要专门的安全评估基准。模型内部注意力模式显示不安全响应与过度任务专注相关，这为未来模型安全改进提供了重要洞见。

Abstract: As Multimodal Large Language Models (MLLMs) acquire stronger reasoning capabilities to handle complex, multi-image instructions, this advancement may pose new safety risks. We study this problem by introducing MIR-SafetyBench, the first benchmark focused on multi-image reasoning safety, which consists of 2,676 instances across a taxonomy of 9 multi-image relations. Our extensive evaluations on 19 MLLMs reveal a troubling trend: models with more advanced multi-image reasoning can be more vulnerable on MIR-SafetyBench. Beyond attack success rates, we find that many responses labeled as safe are superficial, often driven by misunderstanding or evasive, non-committal replies. We further observe that unsafe generations exhibit lower attention entropy than safe ones on average. This internal signature suggests a possible risk that models may over-focus on task solving while neglecting safety constraints. Our code and data are available at https://github.com/thu-coai/MIR-SafetyBench.

</details>


### [205] [Scaling Test-time Inference for Visual Grounding](https://arxiv.org/abs/2601.13633)
*Guanqi Zhan,Changye Li,Zhijian Liu,Yao Lu,Yi Wu,Song Han,Ligeng Zhu*

Main category: cs.CV

TL;DR: EGM方法通过扩展小型视觉语言模型的测试时计算（生成更多token），在保持部署友好的同时，将视觉定位性能提升到与大型模型相当甚至更好的水平，同时显著降低推理延迟。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的视觉定位模型通常模型尺寸很大，部署困难且推理速度慢。研究发现小型和大型VLM的主要差异在于语言模型大小而非视觉编码器，小型VLM在定位任务上表现不佳主要是因为语言理解能力不足而非视觉信息处理问题。

Method: 提出EGM（高效视觉定位语言模型）方法，通过扩展小型模型的测试时计算（增加生成token数量）来提升性能。这种方法部署友好，因为每个token的计算成本远低于直接运行大型模型。

Result: 在RefCOCO基准测试中，EGM-Qwen3-VL-8B达到91.4 IoU，平均延迟737ms（比Qwen3-VL-235B快5.9倍），而后者需要4320ms达到90.5 IoU。在新建立的amodal grounding设置中，该方法也能持续显著提升小型模型的定位能力。

Conclusion: EGM方法通过扩展测试时计算，能够将小型视觉语言模型的视觉定位能力提升到与大型模型相当甚至更好的水平，同时显著提高推理效率，为高效视觉定位提供了有效解决方案。

Abstract: Visual grounding is an essential capability of Visual Language Models (VLMs) to understand the real physical world. Previous state-of-the-art grounding visual language models usually have large model sizes, making them heavy for deployment and slow for inference. However, we notice that the sizes of visual encoders are nearly the same for small and large VLMs and the major difference is the sizes of the language models. Small VLMs fall behind larger VLMs in grounding because of the difference in language understanding capability rather than visual information handling. To mitigate the gap, we introduce 'Efficient visual Grounding language Models' (EGM): a method to scale the test-time computation (#generated tokens). Scaling the test-time computation of a small model is deployment-friendly, and yields better end-to-end latency as the cost of each token is much cheaper compared to directly running a large model. On the RefCOCO benchmark, our EGM-Qwen3-VL-8B demonstrates 91.4 IoU with an average of 737ms (5.9x faster) latency while Qwen3-VL-235B demands 4,320ms to achieve 90.5 IoU. To validate our approach's generality, we further set up a new amodal grounding setting that requires the model to predict both the visible and occluded parts of the objects. Experiments show our method can consistently and significantly improve the vanilla grounding and amodal grounding capabilities of small models to be on par with or outperform the larger models, thereby improving the efficiency for visual grounding.

</details>


### [206] [Attention-space Contrastive Guidance for Efficient Hallucination Mitigation in LVLMs](https://arxiv.org/abs/2601.13707)
*Yujin Jo,Sangyoon Bae,Taesup Kim*

Main category: cs.CV

TL;DR: 提出Attention-space Contrastive Guidance (ACG)方法，通过单次前向计算中的注意力空间对比引导，减少大视觉语言模型中的幻觉问题，在保持生成质量的同时显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 大视觉语言模型中的幻觉问题主要源于语言先验对视觉证据的压制，导致物体误识别和视觉不一致描述。现有方法通常需要多次前向计算，计算成本高。

Method: 提出注意力空间对比引导(ACG)方法：1）在自注意力层中构建视觉-语言和纯语言两种注意力路径；2）采用正交化校正消除单次前向计算引入的近似偏差；3）选择性增强视觉贡献，减少对语言先验的过度依赖。

Result: 在CHAIR和POPE基准测试中达到最先进的忠实度和字幕质量，同时显著降低计算成本，相比之前需要多次前向计算的对比解码方法，延迟降低高达2倍。

Conclusion: ACG为幻觉缓解提供了一种原理性且高效的方法，通过在注意力空间中进行对比引导，有效平衡语言先验和视觉证据，实现了计算效率与生成质量的优化。

Abstract: Hallucinations in large vision-language models (LVLMs) often arise when language priors dominate over visual evidence, causing object misidentification and visually inconsistent descriptions. We address this issue by framing hallucination mitigation as contrastive guidance, steering generation toward visually grounded and semantically faithful text. This approach regulates the model's internal behavior by reducing over-dependence on language priors and contrasting visually grounded with language-only representations. We propose Attention-space Contrastive Guidance (ACG), a single-pass mechanism that operates within self-attention layers to construct both vision-language and language-only attention paths in a single forward computation. This integration enables computationally efficient guidance directly embedded in the model's representation contextualization. To correct approximation bias introduced by the single-pass formulation, we further apply an orthogonalized correction that removes components aligned with the language-only path, selectively amplifying visual contributions. Experiments on the CHAIR and POPE benchmarks show that ACG achieves state-of-the-art faithfulness and caption quality while significantly reducing computational cost. Our method establishes a principled and efficient alternative, reducing latency by up to 2x compared to prior contrastive decoding methods that require multiple forward passes.

</details>


### [207] [Face-Voice Association with Inductive Bias for Maximum Class Separation](https://arxiv.org/abs/2601.13651)
*Marta Moscati,Oleksandr Kats,Mubashir Noman,Muhammad Zaigham Zaheer,Yufang Hou,Markus Schedl,Shah Nawaz*

Main category: cs.CV

TL;DR: 该论文提出了一种在人脸-语音关联任务中引入最大类别分离作为归纳偏置的新方法，通过强制不同说话者的多模态表示最大程度分离来增强嵌入的判别能力，在两个任务上实现了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 人脸-语音关联研究通常使用损失函数使同一人的面部和语音嵌入接近而与其他人的分离。最近分类领域的进展表明，通过强制最大类别分离作为归纳偏置可以增强嵌入的判别能力，但这种方法从未在人脸-语音关联领域应用过。

Method: 开发了一种人脸-语音关联方法，将不同说话者的多模态表示之间的最大类别分离作为归纳偏置。该方法结合了类间正交性损失，通过强制不同说话者的表示最大程度分离来增强判别能力。

Result: 该方法在人脸-语音关联的两个任务公式上实现了最先进的性能。消融研究表明，当归纳偏置与类间正交性损失结合时效果最佳。

Conclusion: 这是首次在多模态学习中应用并证明最大类别分离作为归纳偏置有效性的工作，为建立新范式铺平了道路。

Abstract: Face-voice association is widely studied in multimodal learning and is approached representing faces and voices with embeddings that are close for a same person and well separated from those of others. Previous work achieved this with loss functions. Recent advancements in classification have shown that the discriminative ability of embeddings can be strengthened by imposing maximum class separation as inductive bias. This technique has never been used in the domain of face-voice association, and this work aims at filling this gap. More specifically, we develop a method for face-voice association that imposes maximum class separation among multimodal representations of different speakers as an inductive bias. Through quantitative experiments we demonstrate the effectiveness of our approach, showing that it achieves SOTA performance on two task formulation of face-voice association. Furthermore, we carry out an ablation study to show that imposing inductive bias is most effective when combined with losses for inter-class orthogonality. To the best of our knowledge, this work is the first that applies and demonstrates the effectiveness of maximum class separation as an inductive bias in multimodal learning; it hence paves the way to establish a new paradigm.

</details>


### [208] [VIAFormer: Voxel-Image Alignment Transformer for High-Fidelity Voxel Refinement](https://arxiv.org/abs/2601.13664)
*Tiancheng Fang,Bowen Pan,Lingxi Chen,Jiangjing Lyu,Chengfei Lyu,Chaoyue Niu,Fan Wu*

Main category: cs.CV

TL;DR: VIAFormer是一个用于多视角条件体素精化的体素-图像对齐Transformer模型，通过校准的多视角图像修复不完整噪声体素，在合成和真实体素修复任务上达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有体素修复方法在处理不完整噪声体素时效果有限，需要利用多视角图像信息进行更精确的3D修复，为实际3D创作流程提供可靠桥梁。

Method: 提出三个核心设计：1) 图像索引为2D图像token提供显式3D空间定位；2) 校正流目标学习直接体素精化轨迹；3) 混合流Transformer实现鲁棒的跨模态融合。

Result: 在纠正严重合成损坏和从强大视觉基础模型获得的体素形状的真实伪影方面建立了新的SOTA，并在实际3D创作流程中展示了实用性和可靠性。

Conclusion: VIAFormer为体素基方法在大模型大数据浪潮中蓬勃发展铺平了道路，是实际3D创作流程中实用可靠的桥梁。

Abstract: We propose VIAFormer, a Voxel-Image Alignment Transformer model designed for Multi-view Conditioned Voxel Refinement--the task of repairing incomplete noisy voxels using calibrated multi-view images as guidance. Its effectiveness stems from a synergistic design: an Image Index that provides explicit 3D spatial grounding for 2D image tokens, a Correctional Flow objective that learns a direct voxel-refinement trajectory, and a Hybrid Stream Transformer that enables robust cross-modal fusion. Experiments show that VIAFormer establishes a new state of the art in correcting both severe synthetic corruptions and realistic artifacts on the voxel shape obtained from powerful Vision Foundation Models. Beyond benchmarking, we demonstrate VIAFormer as a practical and reliable bridge in real-world 3D creation pipelines, paving the way for voxel-based methods to thrive in large-model, big-data wave.

</details>


### [209] [Hierarchical Long Video Understanding with Audiovisual Entity Cohesion and Agentic Search](https://arxiv.org/abs/2601.13719)
*Xinlei Yin,Xiulian Peng,Xiao Li,Zhiwei Xiong,Yan Lu*

Main category: cs.CV

TL;DR: HAVEN：通过视听实体凝聚和分层视频索引结合智能搜索的统一长视频理解框架，在LVBench上达到84.1%的准确率


<details>
  <summary>Details</summary>
Motivation: 现有基于分块策略和检索增强生成的长视频理解方法存在信息碎片化和全局连贯性丢失的问题，需要更有效的解决方案

Method: 1）通过整合视觉和听觉流的实体级表示保持语义一致性；2）将内容组织成全局摘要、场景、片段和实体的分层结构；3）采用智能搜索机制在这些层级间进行动态检索和推理

Result: 在LVBench上达到84.1%的整体准确率，在具有挑战性的推理类别中达到80.1%，表现出良好的时间连贯性、实体一致性和检索效率

Conclusion: 结构化多模态推理对于实现全面且上下文一致的长视频理解是有效的，HAVEN框架为此提供了新的解决方案

Abstract: Long video understanding presents significant challenges for vision-language models due to extremely long context windows. Existing solutions relying on naive chunking strategies with retrieval-augmented generation, typically suffer from information fragmentation and a loss of global coherence. We present HAVEN, a unified framework for long-video understanding that enables coherent and comprehensive reasoning by integrating audiovisual entity cohesion and hierarchical video indexing with agentic search. First, we preserve semantic consistency by integrating entity-level representations across visual and auditory streams, while organizing content into a structured hierarchy spanning global summary, scene, segment, and entity levels. Then we employ an agentic search mechanism to enable dynamic retrieval and reasoning across these layers, facilitating coherent narrative reconstruction and fine-grained entity tracking. Extensive experiments demonstrate that our method achieves good temporal coherence, entity consistency, and retrieval efficiency, establishing a new state-of-the-art with an overall accuracy of 84.1% on LVBench. Notably, it achieves outstanding performance in the challenging reasoning category, reaching 80.1%. These results highlight the effectiveness of structured, multimodal reasoning for comprehensive and context-consistent understanding of long-form videos.

</details>


### [210] [Transformer based Multi-task Fusion Network for Food Spoilage Detection and Shelf life Forecasting](https://arxiv.org/abs/2601.13665)
*Mounika Kanulla,Rajasree Dadigi,Sailaja Thota,Vivek Yelleti*

Main category: cs.CV

TL;DR: 提出融合CNN与LSTM和DeiT Transformer的架构，同时处理蔬菜分类、食品腐败检测和保质期预测三个任务，在自建数据集上表现优于多个深度学习模型。


<details>
  <summary>Details</summary>
Motivation: 食品浪费是农业供应链中的关键挑战，准确的腐败检测和预测有助于减少浪费，延长供应链管理寿命。

Method: 提出融合架构：CNN+CNN-LSTM和CNN+DeiT Transformer，同时处理蔬菜分类、腐败检测和保质期预测三个任务。使用自建数据集（从新鲜到完全腐败的蔬菜图像）。

Result: CNN+DeiT Transformer在蔬菜分类和腐败检测上分别获得0.98和0.61的F1分数，在腐败预测上MSE为3.58，SMAPE为41.66%。融合架构优于CNN、VGG16、ResNet50、胶囊网络和DeiT Transformer等模型。

Conclusion: 融合架构能有效同时处理多个食品腐败相关任务，CNN+DeiT Transformer表现最佳，模型可靠性通过噪声图像验证，并使用LIME可视化决策过程。

Abstract: Food wastage is one of the critical challenges in the agricultural supply chain, and accurate and effective spoilage detection can help to reduce it. Further, it is highly important to forecast the spoilage information. This aids the longevity of the supply chain management in the agriculture field. This motivated us to propose fusion based architectures by combining CNN with LSTM and DeiT transformer for the following multi-tasks simultaneously: (i) vegetable classification, (ii) food spoilage detection, and (iii) shelf life forecasting. We developed a dataset by capturing images of vegetables from their fresh state until they were completely spoiled. From the experimental analysis it is concluded that the proposed fusion architectures CNN+CNN-LSTM and CNN+DeiT Transformer outperformed several deep learning models such as CNN, VGG16, ResNet50, Capsule Networks, and DeiT Transformers. Overall, CNN + DeiT Transformer yielded F1-score of 0.98 and 0.61 in vegetable classification and spoilage detection respectively and mean squared error (MSE) and symmetric mean absolute percentage error (SMAPE) of 3.58, and 41.66% respectively in spoilage forecasting. Further, the reliability of the fusion models was validated on noisy images and integrated with LIME to visualize the model decisions.

</details>


### [211] [Finally Outshining the Random Baseline: A Simple and Effective Solution for Active Learning in 3D Biomedical Imaging](https://arxiv.org/abs/2601.13677)
*Carsten T. Lüth,Jeremias Traub,Kim-Celine Kahl,Till J. Bungert,Lukas Klein,Lars Krämer,Paul F. Jäger,Klaus Maier-Hein,Fabian Isensee*

Main category: cs.CV

TL;DR: ClaSP PE是一种用于3D生物医学图像分割的主动学习方法，通过类别分层查询和噪声调度策略，在24个实验设置中显著优于随机基线，并能泛化到未见数据集。


<details>
  <summary>Details</summary>
Motivation: 3D生物医学图像分割的标注成本高昂，现有主动学习方法无法在3D数据上稳定优于改进的随机采样基线，缺乏可靠解决方案。

Method: 提出ClaSP PE方法：1）类别分层查询确保覆盖欠表示结构；2）对数尺度功率噪声配合衰减调度，早期增强查询多样性，后期鼓励利用。

Result: 在nnActive基准测试的24个实验设置中，ClaSP PE是唯一能稳定优于改进随机基线的方法，在分割质量和标注效率上均有统计显著提升，并能泛化到4个未见数据集。

Conclusion: ClaSP PE首次证明主动学习方法能在3D分割任务中稳定优于随机基线，提供了实用的开源实现和部署指南，适用于实际应用场景。

Abstract: Active learning (AL) has the potential to drastically reduce annotation costs in 3D biomedical image segmentation, where expert labeling of volumetric data is both time-consuming and expensive. Yet, existing AL methods are unable to consistently outperform improved random sampling baselines adapted to 3D data, leaving the field without a reliable solution. We introduce Class-stratified Scheduled Power Predictive Entropy (ClaSP PE), a simple and effective query strategy that addresses two key limitations of standard uncertainty-based AL methods: class imbalance and redundancy in early selections. ClaSP PE combines class-stratified querying to ensure coverage of underrepresented structures and log-scale power noising with a decaying schedule to enforce query diversity in early-stage AL and encourage exploitation later. In our evaluation on 24 experimental settings using four 3D biomedical datasets within the comprehensive nnActive benchmark, ClaSP PE is the only method that generally outperforms improved random baselines in terms of both segmentation quality with statistically significant gains, whilst remaining annotation efficient. Furthermore, we explicitly simulate the real-world application by testing our method on four previously unseen datasets without manual adaptation, where all experiment parameters are set according to predefined guidelines. The results confirm that ClaSP PE robustly generalizes to novel tasks without requiring dataset-specific tuning. Within the nnActive framework, we present compelling evidence that an AL method can consistently outperform random baselines adapted to 3D segmentation, in terms of both performance and annotation efficiency in a realistic, close-to-production scenario. Our open-source implementation and clear deployment guidelines make it readily applicable in practice. Code is at https://github.com/MIC-DKFZ/nnActive.

</details>


### [212] [Dynamic Differential Linear Attention: Enhancing Linear Diffusion Transformer for High-Quality Image Generation](https://arxiv.org/abs/2601.13683)
*Boyuan Cao,Xingbo Yao,Chenhui Wang,Jiaxin Ye,Yujie Wei,Hongming Shan*

Main category: cs.CV

TL;DR: DyDiLA是一种新型线性注意力机制，通过动态投影、动态测量核和令牌差分算子解决线性扩散变换器中注意力权重过度平滑的问题，提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 扩散变换器(DiTs)在高保真图像生成中表现出色，但自注意力的二次计算成本成为主要扩展瓶颈。线性注意力机制虽然降低了计算成本，但线性扩散变换器(LiTs)往往以牺牲生成性能为代价，产生过度平滑的注意力权重，限制了表达能力。

Method: 提出动态差分线性注意力(DyDiLA)，包含三个关键设计：1) 动态投影模块，通过动态分配知识学习实现令牌表示的解耦；2) 动态测量核，通过为令牌处理动态分配核函数提供更好的相似性度量；3) 令牌差分算子，通过计算令牌与其对应信息冗余之间的差异实现更稳健的查询-键检索。基于DyDiLA构建了改进的LiT模型DyDi-LiT。

Result: 大量实验表明，DyDi-LiT在多个指标上持续优于当前最先进的模型，显示出强大的实际潜力。

Conclusion: DyDiLA通过创新的动态差分线性注意力机制，有效解决了线性扩散变换器中注意力权重过度平滑的问题，显著提升了生成质量，为高效高质的图像生成提供了有前景的解决方案。

Abstract: Diffusion transformers (DiTs) have emerged as a powerful architecture for high-fidelity image generation, yet the quadratic cost of self-attention poses a major scalability bottleneck. To address this, linear attention mechanisms have been adopted to reduce computational cost; unfortunately, the resulting linear diffusion transformers (LiTs) models often come at the expense of generative performance, frequently producing over-smoothed attention weights that limit expressiveness. In this work, we introduce Dynamic Differential Linear Attention (DyDiLA), a novel linear attention formulation that enhances the effectiveness of LiTs by mitigating the oversmoothing issue and improving generation quality. Specifically, the novelty of DyDiLA lies in three key designs: (i) dynamic projection module, which facilitates the decoupling of token representations by learning with dynamically assigned knowledge; (ii) dynamic measure kernel, which provides a better similarity measurement to capture fine-grained semantic distinctions between tokens by dynamically assigning kernel functions for token processing; and (iii) token differential operator, which enables more robust query-to-key retrieval by calculating the differences between the tokens and their corresponding information redundancy produced by dynamic measure kernel. To capitalize on DyDiLA, we introduce a refined LiT, termed DyDi-LiT, that systematically incorporates our advancements. Extensive experiments show that DyDi-LiT consistently outperforms current state-of-the-art (SOTA) models across multiple metrics, underscoring its strong practical potential.

</details>


### [213] [Reasoning or Pattern Matching? Probing Large Vision-Language Models with Visual Puzzles](https://arxiv.org/abs/2601.13705)
*Maria Lymperaiou,Vasileios Karampinis,Giorgos Filandrianos,Angelos Vlachos,Chrysoula Zerva,Athanasios Voulodimos*

Main category: cs.CV

TL;DR: 该论文是一篇关于视觉谜题作为大型视觉语言模型推理能力诊断工具的综述，系统分析了现有基准测试并总结了当前模型的局限性。


<details>
  <summary>Details</summary>
Motivation: 视觉谜题长期以来作为人类认知的探针，能够以最小的先验知识需求来测试抽象、规则发现和系统推理能力。作者希望利用这一特性，将视觉谜题发展为评估大型视觉语言模型推理能力的强大诊断工具，提供可控、可验证的替代方案来替代开放式的多模态基准测试。

Method: 作者通过统一的抽象框架来组织视觉谜题，将现有基准测试按照其针对的推理机制进行分类（归纳、类比、算法、演绎和几何/空间推理），从而将谜题设计与所需的认知操作联系起来。通过综合这些类别中的实证证据，系统分析当前模型的局限性。

Result: 研究发现当前模型存在一致的局限性，包括脆弱的泛化能力、感知与推理之间的紧密纠缠、流畅解释与忠实执行之间的持续差距。通过将视觉谜题视为诊断工具而非任务格式，该综述阐明了LVLM推理的现状。

Conclusion: 视觉谜题作为诊断工具能够有效评估大型视觉语言模型的推理能力。该综述为未来的基准测试和推理感知的多模态系统指明了关键方向，强调了需要开发更鲁棒的推理模型来解决当前发现的局限性。

Abstract: Puzzles have long served as compact and revealing probes of human cognition, isolating abstraction, rule discovery, and systematic reasoning with minimal reliance on prior knowledge. Leveraging these properties, visual puzzles have recently emerged as a powerful diagnostic tool for evaluating the reasoning abilities of Large Vision-Language Models (LVLMs), offering controlled, verifiable alternatives to open-ended multimodal benchmarks. This survey provides a unified perspective of visual puzzle reasoning in LVLMs. We frame visual puzzles through a common abstraction and organize existing benchmarks by the reasoning mechanisms they target (inductive, analogical, algorithmic, deductive, and geometric/spatial), thereby linking puzzle design to the cognitive operations required for solving. Synthesizing empirical evidence across these categories, we identify consistent limitations in current models, including brittle generalization, tight entanglement between perception and reasoning, and a persistent gap between fluent explanations and faithful execution. By framing visual puzzles as diagnostic instruments rather than task formats, this survey elaborates on the state of LVLM reasoning and outlines key directions for future benchmarks and reasoning-aware multimodal systems.

</details>


### [214] [Insight: Interpretable Semantic Hierarchies in Vision-Language Encoders](https://arxiv.org/abs/2601.13798)
*Kai Wittenmayer,Sukrut Rao,Amin Parchami-Araghi,Bernt Schiele,Jonas Fischer*

Main category: cs.CV

TL;DR: Insight是一个语言对齐的概念基础模型，通过分层稀疏自编码器提取多粒度、可解释且空间定位的概念，在保持分类和分割性能的同时提供高质量的概念解释。


<details>
  <summary>Details</summary>
Motivation: 现有的语言对齐视觉基础模型虽然在下游任务中表现良好，但其表示不透明、难以解释决策过程。现有概念分解方法空间定位能力差，且仅限于图像分类任务。

Method: 使用分层稀疏自编码器和具有强语义表示的基础模型自动提取多粒度概念；通过分析概念的局部共现依赖关系定义概念关系；利用这些关系改进概念命名并获得更丰富的解释。

Result: 在基准数据上，Insight在分类和分割任务上性能与不透明基础模型相当，同时提供细粒度、高质量的概念解释。

Conclusion: Insight成功构建了一个既能保持性能又能提供可解释概念表示的语言对齐概念基础模型，解决了现有模型表示不透明和解释能力有限的问题。

Abstract: Language-aligned vision foundation models perform strongly across diverse downstream tasks. Yet, their learned representations remain opaque, making interpreting their decision-making hard. Recent works decompose these representations into human-interpretable concepts, but provide poor spatial grounding and are limited to image classification tasks. In this work, we propose Insight, a language-aligned concept foundation model that provides fine-grained concepts, which are human-interpretable and spatially grounded in the input image. We leverage a hierarchical sparse autoencoder and a foundation model with strong semantic representations to automatically extract concepts at various granularities. Examining local co-occurrence dependencies of concepts allows us to define concept relationships. Through these relations we further improve concept naming and obtain richer explanations. On benchmark data, we show that Insight provides performance on classification and segmentation that is competitive with opaque foundation models while providing fine-grained, high quality concept-based explanations. Code is available at https://github.com/kawi19/Insight.

</details>


### [215] [ParkingTwin: Training-Free Streaming 3D Reconstruction for Parking-Lot Digital Twins](https://arxiv.org/abs/2601.13706)
*Xinhao Liu,Yu Wang,Xiansheng Guo,Gordon Owusu Boateng,Yu Cao,Haonan Si,Xingchen Guo,Nirwan Ansari*

Main category: cs.CV

TL;DR: ParkingTwin是一个免训练、轻量级的在线流式3D重建系统，专门用于停车场数字孪生，解决了传统方法在稀疏视角、动态遮挡和光照变化下的重建难题。


<details>
  <summary>Details</summary>
Motivation: 停车场数字孪生对自动驾驶代客泊车至关重要，但现有机器人导向重建面临三难困境：稀疏前向视角导致弱视差和几何不适定；动态遮挡和极端光照阻碍稳定纹理融合；神经渲染通常需要昂贵的离线优化，违反边缘端流式约束。

Method: 1) 使用OpenStreetMap语义拓扑直接生成度量一致的TSDF，替代盲目几何搜索；2) 采用四模态约束场（法线/高度/深度一致性）实时过滤动态车辆和瞬态遮挡；3) 在CIELAB色彩空间通过自适应L通道加权和深度梯度抑制实现光照鲁棒融合。

Result: 在入门级GTX 1660上达到30+ FPS，在68,000 m²真实世界数据集上SSIM达到0.87（提升16.0%），相比需要高端GPU（RTX 4090D）的3D高斯泼溅技术，端到端加速约15倍，GPU内存减少83.3%。

Conclusion: ParkingTwin实现了高效、鲁棒的在线停车场3D重建，输出与Unity/Unreal数字孪生管道兼容的显式三角网格，为边缘端自动驾驶应用提供了实用解决方案。

Abstract: High-fidelity parking-lot digital twins provide essential priors for path planning, collision checking, and perception validation in Automated Valet Parking (AVP). Yet robot-oriented reconstruction faces a trilemma: sparse forward-facing views cause weak parallax and ill-posed geometry; dynamic occlusions and extreme lighting hinder stable texture fusion; and neural rendering typically needs expensive offline optimization, violating edge-side streaming constraints. We propose ParkingTwin, a training-free, lightweight system for online streaming 3D reconstruction. First, OSM-prior-driven geometric construction uses OpenStreetMap semantic topology to directly generate a metric-consistent TSDF, replacing blind geometric search with deterministic mapping and avoiding costly optimization. Second, geometry-aware dynamic filtering employs a quad-modal constraint field (normal/height/depth consistency) to reject moving vehicles and transient occlusions in real time. Third, illumination-robust fusion in CIELAB decouples luminance and chromaticity via adaptive L-channel weighting and depth-gradient suppression, reducing seams under abrupt lighting changes. ParkingTwin runs at 30+ FPS on an entry-level GTX 1660. On a 68,000 m^2 real-world dataset, it achieves SSIM 0.87 (+16.0%), delivers about 15x end-to-end speedup, and reduces GPU memory by 83.3% compared with state-of-the-art 3D Gaussian Splatting (3DGS) that typically requires high-end GPUs (RTX 4090D). The system outputs explicit triangle meshes compatible with Unity/Unreal digital-twin pipelines. Project page: https://mihoutao-liu.github.io/ParkingTwin/

</details>


### [216] [OmniOVCD: Streamlining Open-Vocabulary Change Detection with SAM 3](https://arxiv.org/abs/2601.13895)
*Xu Zhang,Danyang Li,Yingjie Xia,Xiaohang Dong,Hualong Yu,Jianye Wang,Qicheng Li*

Main category: cs.CV

TL;DR: 提出OmniOVCD框架，利用SAM 3的解耦输出头，通过SFID策略融合语义、实例和存在性输出构建地物掩码，再分解为实例掩码进行变化检测，在四个基准测试中取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有免训练的开放词汇变化检测方法通常结合CLIP和DINO等不同模型，导致特征匹配问题和系统不稳定。SAM 3集成了分割和识别能力，为OVCD任务提供了新可能。

Method: 提出OmniOVCD框架，利用SAM 3的解耦输出头，设计SFID策略：先融合SAM 3的语义、实例和存在性输出构建地物掩码，再分解为单个实例掩码进行变化比较。

Result: 在四个公开基准测试（LEVIR-CD、WHU-CD、S2Looking、SECOND）上取得SOTA性能，IoU分数分别为67.2、66.5、24.5和27.1（类别平均），超越所有先前方法。

Conclusion: OmniOVCD通过SFID策略有效利用SAM 3的集成能力，在保持类别识别高精度的同时维护跨图像的实例级一致性，能够生成准确的变化掩码。

Abstract: Change Detection (CD) is a fundamental task in remote sensing. It monitors the evolution of land cover over time. Based on this, Open-Vocabulary Change Detection (OVCD) introduces a new requirement. It aims to reduce the reliance on predefined categories. Existing training-free OVCD methods mostly use CLIP to identify categories. These methods also need extra models like DINO to extract features. However, combining different models often causes problems in matching features and makes the system unstable. Recently, the Segment Anything Model 3 (SAM 3) is introduced. It integrates segmentation and identification capabilities within one promptable model, which offers new possibilities for the OVCD task. In this paper, we propose OmniOVCD, a standalone framework designed for OVCD. By leveraging the decoupled output heads of SAM 3, we propose a Synergistic Fusion to Instance Decoupling (SFID) strategy. SFID first fuses the semantic, instance, and presence outputs of SAM 3 to construct land-cover masks, and then decomposes them into individual instance masks for change comparison. This design preserves high accuracy in category recognition and maintains instance-level consistency across images. As a result, the model can generate accurate change masks. Experiments on four public benchmarks (LEVIR-CD, WHU-CD, S2Looking, and SECOND) demonstrate SOTA performance, achieving IoU scores of 67.2, 66.5, 24.5, and 27.1 (class-average), respectively, surpassing all previous methods.

</details>


### [217] [MVGD-Net: A Novel Motion-aware Video Glass Surface Detection Network](https://arxiv.org/abs/2601.13715)
*Yiwei Lu,Hao Huang,Tao Yan*

Main category: cs.CV

TL;DR: MVGD-Net：利用运动不一致性检测视频中玻璃表面的新型网络，通过跨尺度多模态融合和历史引导注意力模块，在自建大规模数据集上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 玻璃表面在日常生活和专业环境中普遍存在，对机器人、无人机等视觉系统构成潜在威胁。现有研究主要关注视频玻璃表面检测（VGSD），但需要更有效的方法来识别玻璃区域。

Method: 提出MVGD-Net网络，利用玻璃表面反射/透射层物体运动较慢的运动不一致性线索。包含三个核心模块：跨尺度多模态融合模块（CMFM）整合空间特征和光流图；历史引导注意力模块（HGAM）和时间交叉注意力模块（TCAM）增强时序特征；时空解码器（TSD）融合时空特征生成玻璃区域掩码。

Result: 构建了包含312个多样化玻璃场景、共19,268帧的大规模数据集。大量实验表明，MVGD-Net在视频玻璃表面检测任务上超越了相关的最先进方法。

Conclusion: 通过利用玻璃表面特有的运动不一致性线索，MVGD-Net能够有效检测视频中的玻璃表面，为机器人导航等视觉系统提供了重要的安全保障。

Abstract: Glass surface ubiquitous in both daily life and professional environments presents a potential threat to vision-based systems, such as robot and drone navigation. To solve this challenge, most recent studies have shown significant interest in Video Glass Surface Detection (VGSD). We observe that objects in the reflection (or transmission) layer appear farther from the glass surfaces. Consequently, in video motion scenarios, the notable reflected (or transmitted) objects on the glass surface move slower than objects in non-glass regions within the same spatial plane, and this motion inconsistency can effectively reveal the presence of glass surfaces. Based on this observation, we propose a novel network, named MVGD-Net, for detecting glass surfaces in videos by leveraging motion inconsistency cues. Our MVGD-Net features three novel modules: the Cross-scale Multimodal Fusion Module (CMFM) that integrates extracted spatial features and estimated optical flow maps, the History Guided Attention Module (HGAM) and Temporal Cross Attention Module (TCAM), both of which further enhances temporal features. A Temporal-Spatial Decoder (TSD) is also introduced to fuse the spatial and temporal features for generating the glass region mask. Furthermore, for learning our network, we also propose a large-scale dataset, which comprises 312 diverse glass scenarios with a total of 19,268 frames. Extensive experiments demonstrate that our MVGD-Net outperforms relevant state-of-the-art methods.

</details>


### [218] [Glance-or-Gaze: Incentivizing LMMs to Adaptively Focus Search via Reinforcement Learning](https://arxiv.org/abs/2601.13942)
*Hongbo Bai,Yujin Zhou,Yile Wu,Chi-Min Chan,Pengcheng Wen,Kunhao Pan,Sirui Han,Yike Guo*

Main category: cs.CV

TL;DR: GoG框架通过选择性注视机制和双阶段训练策略，解决了大型多模态模型在知识密集型视觉查询中的局限性，实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 大型多模态模型在视觉理解方面取得了显著成功，但在处理涉及长尾实体或动态信息的知识密集型查询时存在局限，因为其参数知识是静态的。现有的搜索增强方法存在视觉冗余和噪声问题，且缺乏深度迭代反思。

Method: 提出了Glance-or-Gaze框架，包含选择性注视机制（动态选择全局上下文或高价值区域），以及双阶段训练策略：通过监督微调进行反思性行为对齐，再通过复杂度自适应强化学习增强处理复杂查询的能力。

Result: 在六个基准测试中展示了最先进的性能。消融研究证实选择性注视机制和复杂度自适应强化学习对有效视觉搜索都至关重要。

Conclusion: GoG框架通过从被动感知转向主动视觉规划，解决了现有方法的局限性，为知识密集型视觉查询提供了有效的解决方案。

Abstract: Large Multimodal Models (LMMs) have achieved remarkable success in visual understanding, yet they struggle with knowledge-intensive queries involving long-tail entities or evolving information due to static parametric knowledge. Recent search-augmented approaches attempt to address this limitation, but existing methods rely on indiscriminate whole-image retrieval that introduces substantial visual redundancy and noise, and lack deep iterative reflection, limiting their effectiveness on complex visual queries. To overcome these challenges, we propose Glance-or-Gaze (GoG), a fully autonomous framework that shifts from passive perception to active visual planning. GoG introduces a Selective Gaze mechanism that dynamically chooses whether to glance at global context or gaze into high-value regions, filtering irrelevant information before retrieval. We design a dual-stage training strategy: Reflective GoG Behavior Alignment via supervised fine-tuning instills the fundamental GoG paradigm, while Complexity-Adaptive Reinforcement Learning further enhances the model's capability to handle complex queries through iterative reasoning. Experiments across six benchmarks demonstrate state-of-the-art performance. Ablation studies confirm that both Selective Gaze and complexity-adaptive RL are essential for effective visual search. We will release our data and models for further exploration soon.

</details>


### [219] [Facial Spatiotemporal Graphs: Leveraging the 3D Facial Surface for Remote Physiological Measurement](https://arxiv.org/abs/2601.13724)
*Sam Cantrill,David Ahmedt-Aristizabal,Lars Petersson,Hanna Suominen,Mohammad Ali Armin*

Main category: cs.CV

TL;DR: 提出Facial STGraph表示法和MeshPhys网络，通过3D面部网格序列实现表面对齐的时空处理，用于远程光电容积描记法(rPPG)生理信号估计。


<details>
  <summary>Details</summary>
Motivation: 现有rPPG方法未能显式对齐其感受野与3D面部表面（rPPG信号的空间支撑），需要一种能明确编码面部表面颜色和结构的表示方法。

Method: 提出Facial Spatiotemporal Graph (STGraph)表示法，使用3D面部网格序列编码面部颜色和结构；设计MeshPhys轻量级时空图卷积网络，在STGraph上进行处理以估计生理信号。

Result: 在四个基准数据集上，MeshPhys在数据集内和跨数据集设置中都达到了最先进或具有竞争力的性能。消融研究表明，将模型感受野限制在面部表面起到了强大的结构先验作用。

Conclusion: STGraph和MeshPhys构成了面部rPPG的新建模范式，能够实现鲁棒、可解释和可泛化的生理信号估计，表面对齐的3D感知节点特征对鲁棒编码面部表面颜色至关重要。

Abstract: Facial remote photoplethysmography (rPPG) methods estimate physiological signals by modeling subtle color changes on the 3D facial surface over time. However, existing methods fail to explicitly align their receptive fields with the 3D facial surface-the spatial support of the rPPG signal. To address this, we propose the Facial Spatiotemporal Graph (STGraph), a novel representation that encodes facial color and structure using 3D facial mesh sequences-enabling surface-aligned spatiotemporal processing. We introduce MeshPhys, a lightweight spatiotemporal graph convolutional network that operates on the STGraph to estimate physiological signals. Across four benchmark datasets, MeshPhys achieves state-of-the-art or competitive performance in both intra- and cross-dataset settings. Ablation studies show that constraining the model's receptive field to the facial surface acts as a strong structural prior, and that surface-aligned, 3D-aware node features are critical for robustly encoding facial surface color. Together, the STGraph and MeshPhys constitute a novel, principled modeling paradigm for facial rPPG, enabling robust, interpretable, and generalizable estimation. Code is available at https://samcantrill.github.io/facial-stgraph-rppg/ .

</details>


### [220] [Generalizing Abstention for Noise-Robust Learning in Medical Image Segmentation](https://arxiv.org/abs/2601.14039)
*Wesam Moustafa,Hossam Elsafty,Helen Schneider,Lorenz Sparrenberg,Rafet Sifa*

Main category: cs.CV

TL;DR: 提出一个通用的弃权框架来增强医学图像分割中的噪声鲁棒性，通过选择性忽略噪声样本提升模型可靠性


<details>
  <summary>Details</summary>
Motivation: 医学图像分割中标签噪声是严重问题，现有方法对此探索不足。分类任务中弃权机制已证明有效，但在分割领域潜力尚未验证

Method: 提出通用模块化弃权框架，包含两个关键组件：引导弃权行为的知情正则化项，以及基于幂律的自适应调参算法。将框架与三种损失函数集成，创建GAC、SAC和ADS三种噪声鲁棒变体

Result: 在CaDIS和DSAD医学数据集上的实验表明，该方法在多种噪声水平下均显著优于非弃权基线，尤其在高噪声水平下表现突出

Conclusion: 使模型能够选择性忽略损坏样本是构建更可靠分割模型的强大且可泛化策略。弃权机制在分割领域具有重要应用价值

Abstract: Label noise is a critical problem in medical image segmentation, often arising from the inherent difficulty of manual annotation. Models trained on noisy data are prone to overfitting, which degrades their generalization performance. While a number of methods and strategies have been proposed to mitigate noisy labels in the segmentation domain, this area remains largely under-explored. The abstention mechanism has proven effective in classification tasks by enhancing the capabilities of Cross Entropy, yet its potential in segmentation remains unverified. In this paper, we address this gap by introducing a universal and modular abstention framework capable of enhancing the noise-robustness of a diverse range of loss functions. Our framework improves upon prior work with two key components: an informed regularization term to guide abstention behaviour, and a more flexible power-law-based auto-tuning algorithm for the abstention penalty. We demonstrate the framework's versatility by systematically integrating it with three distinct loss functions to create three novel, noise-robust variants: GAC, SAC, and ADS. Experiments on the CaDIS and DSAD medical datasets show our methods consistently and significantly outperform their non-abstaining baselines, especially under high noise levels. This work establishes that enabling models to selectively ignore corrupted samples is a powerful and generalizable strategy for building more reliable segmentation models. Our code is publicly available at https://github.com/wemous/abstention-for-segmentation.

</details>


### [221] [HiT: History-Injection Transformers for Onboard Continuous Flood Change Detection](https://arxiv.org/abs/2601.13751)
*Daniel Kyselica,Jonáš Herec,Oliver Kutis,Rado Pitoňák*

Main category: cs.CV

TL;DR: 提出HiT机制用于Transformer模型，实现卫星上的洪水检测，在保持精度的同时将历史数据存储减少99%以上，并在Jetson Orin Nano上达到43 FPS


<details>
  <summary>Details</summary>
Motivation: 自然灾害监测需要处理多时相卫星数据，但受限于小型卫星的内存和计算资源。洪水检测作为灾害管理的关键应用，需要开发能在星上运行的变化检测系统

Method: 提出HiT（History Injection for Transformers）机制，在Transformer模型中维护历史观测的上下文信息，同时将数据存储减少到原始图像大小的1%以下。基于Prithvi-tiny基础模型构建HiT-Prithvi模型

Result: 在STTORM-CD洪水数据集上测试，HiT机制在Prithvi-tiny模型中保持了与双时相基线相当的检测精度。HiT-Prithvi模型在Jetson Orin Nano（纳米卫星代表性硬件）上达到43 FPS

Conclusion: 建立了卫星连续监测自然灾害的实用框架，支持实时灾害评估，无需依赖地面处理基础设施。代码和模型已开源

Abstract: Natural disaster monitoring through continuous satellite observation requires processing multi-temporal data under strict operational constraints. This paper addresses flood detection, a critical application for hazard management, by developing an onboard change detection system that operates within the memory and computational limits of small satellites. We propose History Injection mechanism for Transformer models (HiT), that maintains historical context from previous observations while reducing data storage by over 99\% of original image size. Moreover, testing on the STTORM-CD flood dataset confirms that the HiT mechanism within the Prithvi-tiny foundation model maintains detection accuracy compared to the bitemporal baseline. The proposed HiT-Prithvi model achieved 43 FPS on Jetson Orin Nano, a representative onboard hardware used in nanosats. This work establishes a practical framework for satellite-based continuous monitoring of natural disasters, supporting real-time hazard assessment without dependency on ground-based processing infrastructure. Architecture as well as model checkpoints is available at https://github.com/zaitra/HiT-change-detection

</details>


### [222] [PREGEN: Uncovering Latent Thoughts in Composed Video Retrieval](https://arxiv.org/abs/2601.13797)
*Gabriele Serussi,David Vainshtein,Jonathan Kouchly,Dotan Di Castro,Chaim Baskin*

Main category: cs.CV

TL;DR: PREGEN：一种高效的组合视频检索框架，无需微调预训练视觉语言模型，通过提取隐藏状态和轻量编码实现SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有组合视频检索方法未能充分利用现代视觉语言模型，要么使用过时架构，要么需要昂贵的微调和缓慢的标题生成

Method: 将查询视频和修改文本输入冻结的预训练VLM，提取每层最后一个token的隐藏状态，训练简单编码器生成紧凑的语义嵌入

Result: 在标准CoVR基准上显著超越所有先前方法，Recall@1提升+27.23和+69.59，在不同VLM骨干上表现鲁棒，对复杂文本修改有强零样本泛化能力

Conclusion: PREGEN提供了一种高效强大的CoVR框架，无需VLM微调，展示了卓越的语义能力和泛化性能

Abstract: Composed Video Retrieval (CoVR) aims to retrieve a video based on a query video and a modifying text. Current CoVR methods fail to fully exploit modern Vision-Language Models (VLMs), either using outdated architectures or requiring computationally expensive fine-tuning and slow caption generation. We introduce PREGEN (PRE GENeration extraction), an efficient and powerful CoVR framework that overcomes these limitations. Our approach uniquely pairs a frozen, pre-trained VLM with a lightweight encoding model, eliminating the need for any VLM fine-tuning. We feed the query video and modifying text into the VLM and extract the hidden state of the final token from each layer. A simple encoder is then trained on these pooled representations, creating a semantically rich and compact embedding for retrieval. PREGEN significantly advances the state of the art, surpassing all prior methods on standard CoVR benchmarks with substantial gains in Recall@1 of +27.23 and +69.59. Our method demonstrates robustness across different VLM backbones and exhibits strong zero-shot generalization to more complex textual modifications, highlighting its effectiveness and semantic capabilities.

</details>


### [223] [Decoder-Free Supervoxel GNN for Accurate Brain-Tumor Localization in Multi-Modal MRI](https://arxiv.org/abs/2601.14055)
*Andrea Protani,Marc Molina Van Den Bosch,Lorenzo Giusti,Heloisa Barbosa Da Silva,Paolo Cacace,Albert Sund Aillet,Miguel Angel Gonzalez Ballester,Friedhelm Hummel,Luigi Serio*

Main category: cs.CV

TL;DR: SVGFormer：基于语义图分割的3D医学影像解码器免架构，通过内容感知分组将体素网格转换为超体素图，结合Transformer和GAT实现双尺度特征学习，在脑肿瘤分割任务上表现优异且具有固有可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统3D医学影像骨干网络通常采用参数密集的编码器-解码器结构，大量参数用于空间重建而非特征学习。需要一种更专注于特征编码且具有固有可解释性的替代方案。

Method: 提出SVGFormer解码器免管道：1) 内容感知分组阶段将体素网格分割成语义超体素图；2) 分层编码器结合补丁级Transformer和超体素级图注意力网络，联合建模细粒度区域内特征和区域间依赖关系。

Result: 在BraTS数据集上训练的两个专用模型：节点分类模型F1分数0.875，肿瘤比例回归模型MAE 0.028。证明编码器能够学习判别性和局部化特征。

Conclusion: 基于图的编码器免范式为3D医学图像表示提供了准确且固有可解释的替代方案，将所有可学习容量集中于特征编码，提供从补丁到区域级的双尺度可解释性。

Abstract: Modern vision backbones for 3D medical imaging typically process dense voxel grids through parameter-heavy encoder-decoder structures, a design that allocates a significant portion of its parameters to spatial reconstruction rather than feature learning. Our approach introduces SVGFormer, a decoder-free pipeline built upon a content-aware grouping stage that partitions the volume into a semantic graph of supervoxels. Its hierarchical encoder learns rich node representations by combining a patch-level Transformer with a supervoxel-level Graph Attention Network, jointly modeling fine-grained intra-region features and broader inter-regional dependencies. This design concentrates all learnable capacity on feature encoding and provides inherent, dual-scale explainability from the patch to the region level. To validate the framework's flexibility, we trained two specialized models on the BraTS dataset: one for node-level classification and one for tumor proportion regression. Both models achieved strong performance, with the classification model achieving a F1-score of 0.875 and the regression model a MAE of 0.028, confirming the encoder's ability to learn discriminative and localized features. Our results establish that a graph-based, encoder-only paradigm offers an accurate and inherently interpretable alternative for 3D medical image representation.

</details>


### [224] [Discriminant Learning-based Colorspace for Blade Segmentation](https://arxiv.org/abs/2601.13816)
*Raül Pérez-Gonzalo,Andreas Espersen,Antonio Agudo*

Main category: cs.CV

TL;DR: 提出CSDA算法，通过多维非线性判别分析优化色彩表示，提升图像分割精度


<details>
  <summary>Details</summary>
Motivation: 现有图像分割算法往往忽视色彩表示这一关键预处理步骤，而次优的色彩表示会阻碍准确分割

Method: 提出Colorspace Discriminant Analysis (CSDA)算法，将线性判别分析扩展到深度学习框架中，通过最大化类间可分性并最小化类内变异性来定制色彩表示，引入三种替代损失函数实现端到端优化

Result: 在风力涡轮机叶片数据上的实验显示显著精度提升，证明了定制化预处理在领域特定分割中的重要性

Conclusion: CSDA算法通过优化色彩表示显著改善图像分割性能，强调了预处理步骤在分割任务中的关键作用

Abstract: Suboptimal color representation often hinders accurate image segmentation, yet many modern algorithms neglect this critical preprocessing step. This work presents a novel multidimensional nonlinear discriminant analysis algorithm, Colorspace Discriminant Analysis (CSDA), for improved segmentation. Extending Linear Discriminant Analysis into a deep learning context, CSDA customizes color representation by maximizing multidimensional signed inter-class separability while minimizing intra-class variability through a generalized discriminative loss. To ensure stable training, we introduce three alternative losses that enable end-to-end optimization of both the discriminative colorspace and segmentation process. Experiments on wind turbine blade data demonstrate significant accuracy gains, emphasizing the importance of tailored preprocessing in domain-specific segmentation.

</details>


### [225] [POCI-Diff: Position Objects Consistently and Interactively with 3D-Layout Guided Diffusion](https://arxiv.org/abs/2601.14056)
*Andrea Rigo,Luca Stornaiuolo,Weijie Wang,Mauro Martino,Bruno Lepri,Nicu Sebe*

Main category: cs.CV

TL;DR: POCI-Diff：一种基于扩散的文本到图像生成方法，通过3D布局控制和交互式编辑实现一致的多对象场景合成，避免几何扭曲并保持编辑一致性。


<details>
  <summary>Details</summary>
Motivation: 现有方法使用2D线索或迭代复制-变形-粘贴策略来改善空间一致性，但经常扭曲对象几何形状，并且在编辑过程中无法保持一致性。需要一种能够同时执行3D几何约束和实例级语义绑定的统一框架。

Method: 提出POCI-Diff框架，通过Blended Latent Diffusion将单个文本描述绑定到特定3D边界框，实现显式的每对象语义控制。采用无变形生成编辑流程，通过重新生成而非像素变形支持对象插入、移除和变换。使用IP-Adapter基于参考图像调节扩散过程，保持对象身份和编辑一致性。

Result: 实验结果表明，POCI-Diff能够生成与指定3D布局和编辑一致的高质量图像，在视觉保真度和布局一致性方面优于现有方法，同时消除了变形引起的几何伪影。

Conclusion: POCI-Diff提供了一种有效的文本到图像生成方法，通过统一的扩散过程实现一致的3D布局控制和交互式编辑，解决了现有方法在几何保真度和编辑一致性方面的局限性。

Abstract: We propose a diffusion-based approach for Text-to-Image (T2I) generation with consistent and interactive 3D layout control and editing. While prior methods improve spatial adherence using 2D cues or iterative copy-warp-paste strategies, they often distort object geometry and fail to preserve consistency across edits. To address these limitations, we introduce a framework for Positioning Objects Consistently and Interactively (POCI-Diff), a novel formulation for jointly enforcing 3D geometric constraints and instance-level semantic binding within a unified diffusion process. Our method enables explicit per-object semantic control by binding individual text descriptions to specific 3D bounding boxes through Blended Latent Diffusion, allowing one-shot synthesis of complex multi-object scenes. We further propose a warping-free generative editing pipeline that supports object insertion, removal, and transformation via regeneration rather than pixel deformation. To preserve object identity and consistency across edits, we condition the diffusion process on reference images using IP-Adapter, enabling coherent object appearance throughout interactive 3D editing while maintaining global scene coherence. Experimental results demonstrate that POCI-Diff produces high-quality images consistent with the specified 3D layouts and edits, outperforming state-of-the-art methods in both visual fidelity and layout adherence while eliminating warping-induced geometric artifacts.

</details>


### [226] [FastGHA: Generalized Few-Shot 3D Gaussian Head Avatars with Real-Time Animation](https://arxiv.org/abs/2601.13837)
*Xinya Ji,Sebastian Weiss,Manuel Kansy,Jacek Naruniec,Xun Cao,Barbara Solenthaler,Derek Bradley*

Main category: cs.CV

TL;DR: 提出了一种名为OURS的feed-forward方法，仅需少量输入图像即可生成高质量的高斯头部化身，并支持实时动画。


<details>
  <summary>Details</summary>
Motivation: 当前基于3D高斯的方法需要大量多视角捕获设备或单目视频的逐身份优化，限制了在未见主体上的可扩展性和易用性。需要克服这些效率缺陷。

Method: 1) 从输入图像直接学习逐像素高斯表示；2) 使用基于transformer的编码器融合DINOv3和Stable Diffusion VAE的图像特征；3) 为实时动画扩展显式高斯表示，引入轻量级MLP动态网络预测3D高斯形变；4) 使用预训练大型重建模型的点云图进行几何监督。

Result: 实验表明，该方法在渲染质量和推理效率上显著优于现有方法，同时支持实时动态化身动画。

Conclusion: OURS方法能够仅从少量图像高效生成高质量的高斯头部化身，解决了现有方法的可扩展性和效率问题，实现了实时动画能力。

Abstract: Despite recent progress in 3D Gaussian-based head avatar modeling, efficiently generating high fidelity avatars remains a challenge. Current methods typically rely on extensive multi-view capture setups or monocular videos with per-identity optimization during inference, limiting their scalability and ease of use on unseen subjects. To overcome these efficiency drawbacks, we propose \OURS, a feed-forward method to generate high-quality Gaussian head avatars from only a few input images while supporting real-time animation. Our approach directly learns a per-pixel Gaussian representation from the input images, and aggregates multi-view information using a transformer-based encoder that fuses image features from both DINOv3 and Stable Diffusion VAE. For real-time animation, we extend the explicit Gaussian representations with per-Gaussian features and introduce a lightweight MLP-based dynamic network to predict 3D Gaussian deformations from expression codes. Furthermore, to enhance geometric smoothness of the 3D head, we employ point maps from a pre-trained large reconstruction model as geometry supervision. Experiments show that our approach significantly outperforms existing methods in both rendering quality and inference efficiency, while supporting real-time dynamic avatar animation.

</details>


### [227] [DisasterVQA: A Visual Question Answering Benchmark Dataset for Disaster Scenes](https://arxiv.org/abs/2601.13839)
*Aisha Al-Mohannadi,Ayisha Firoz,Yin Yang,Muhammad Imran,Ferda Ofli*

Main category: cs.CV

TL;DR: DisasterVQA是一个针对灾害响应场景的视觉问答基准数据集，包含1,395张真实灾害图像和4,405个专家标注的问答对，评估现有VQA模型在灾害情境下的感知和推理能力。


<details>
  <summary>Details</summary>
Motivation: 社交媒体图像在灾害期间提供低延迟的态势信息，但现有通用VQA模型是否适用于灾害响应所需的复杂安全关键推理尚不明确。需要专门针对灾害场景的基准来评估和指导模型开发。

Method: 创建DisasterVQA数据集，包含洪水、野火、地震等灾害的真实图像，基于FEMA ESF和OCHA MIRA等人道主义框架设计专家标注的问答对（二元、多选、开放式问题），涵盖态势感知和操作决策任务。

Result: 评估7个最先进的视觉语言模型，发现模型在二元问题上表现良好，但在细粒度定量推理、物体计数和上下文敏感解释方面存在困难，特别是在代表性不足的灾害场景中。

Conclusion: DisasterVQA为灾害响应提供了具有挑战性和实用性的基准，揭示了现有模型在灾害场景中的局限性，将指导开发更鲁棒和操作意义更强的视觉语言模型。

Abstract: Social media imagery provides a low-latency source of situational information during natural and human-induced disasters, enabling rapid damage assessment and response. While Visual Question Answering (VQA) has shown strong performance in general-purpose domains, its suitability for the complex and safety-critical reasoning required in disaster response remains unclear. We introduce DisasterVQA, a benchmark dataset designed for perception and reasoning in crisis contexts. DisasterVQA consists of 1,395 real-world images and 4,405 expert-curated question-answer pairs spanning diverse events such as floods, wildfires, and earthquakes. Grounded in humanitarian frameworks including FEMA ESF and OCHA MIRA, the dataset includes binary, multiple-choice, and open-ended questions covering situational awareness and operational decision-making tasks. We benchmark seven state-of-the-art vision-language models and find performance variability across question types, disaster categories, regions, and humanitarian tasks. Although models achieve high accuracy on binary questions, they struggle with fine-grained quantitative reasoning, object counting, and context-sensitive interpretation, particularly for underrepresented disaster scenarios. DisasterVQA provides a challenging and practical benchmark to guide the development of more robust and operationally meaningful vision-language models for disaster response. The dataset is publicly available at https://zenodo.org/records/18267770.

</details>


### [228] [Unsupervised Video Class-Incremental Learning via Deep Embedded Clustering Management](https://arxiv.org/abs/2601.14069)
*Nattapong Kurpukdee,Adrian G. Bors*

Main category: cs.CV

TL;DR: 本文提出了一种无监督视频类增量学习方法，通过深度特征提取和渐进式深度聚类，在不使用标签和任务边界信息的情况下有效学习视频信息而不遗忘。


<details>
  <summary>Details</summary>
Motivation: 现有的监督类增量学习方法依赖于标签和任务边界信息，这需要人工标注且成本高昂，在现实场景中往往不可行。因此需要开发无监督的视频类增量学习方法。

Method: 首先使用深度特征提取网络获取每个任务的代表性视频特征，然后渐进式构建深度聚类。在连续任务学习中，将前一任务更新后的模型作为初始状态，以将知识迁移到当前学习任务。

Result: 在UCF101、HMDB51和Something-to-Something V2三个标准视频动作识别数据集上进行了深入评估，方法在所有数据集上都显著优于其他基线方法。

Conclusion: 提出的无监督视频类增量学习方法简单而有效，能够在不需要标签和任务边界信息的情况下学习视频信息而不遗忘，为现实应用提供了可行的解决方案。

Abstract: Unsupervised video class incremental learning (uVCIL) represents an important learning paradigm for learning video information without forgetting, and without considering any data labels. Prior approaches have focused on supervised class-incremental learning, relying on using the knowledge of labels and task boundaries, which is costly, requires human annotation, or is simply not a realistic option. In this paper, we propose a simple yet effective approach to address the uVCIL. We first consider a deep feature extractor network, providing a set of representative video features during each task without assuming any class or task information. We then progressively build a series of deep clusters from the extracted features. During the successive task learning, the model updated from the previous task is used as an initial state in order to transfer knowledge to the current learning task. We perform in-depth evaluations on three standard video action recognition datasets, including UCF101, HMDB51, and Something-to-Something V2, by ignoring the labels from the supervised setting. Our approach significantly outperforms other baselines on all datasets.

</details>


### [229] [Probabilistic Deep Discriminant Analysis for Wind Blade Segmentation](https://arxiv.org/abs/2601.13852)
*Raül Pérez-Gonzalo,Andreas Espersen,Antonio Agudo*

Main category: cs.CV

TL;DR: 提出Deep Discriminant Analysis (DDA)和Probabilistic DDA (PDDA)方法，通过深度网络直接优化Fisher准则，解决非线性可分数据问题，首次应用于图像分割任务


<details>
  <summary>Details</summary>
Motivation: 线性判别分析(LDA)能提高类别可分性，但难以处理非线性可分数据。需要一种能利用深度网络优势的判别分析方法，同时保证训练稳定性

Method: 1. 提出Deep Discriminant Analysis (DDA)，直接优化Fisher准则；2. 引入带符号的类间方差、sigmoid函数约束输出、将乘法关系转为加法关系以确保稳定性；3. 提出两种稳定的DDA损失函数；4. 结合概率损失扩展为Probabilistic DDA (PDDA)，最小化输出分布的类别重叠

Result: PDDA能有效减少类内方差，产生高置信度预测。在风力叶片分割任务中展现出显著的性能提升和一致性改进，这对风力能源维护至关重要

Conclusion: PDDA是首个将DDA应用于图像分割的方法，通过深度网络优化判别分析，解决了非线性可分数据的挑战，在风力叶片分割等实际应用中表现出优越性能

Abstract: Linear discriminant analysis improves class separability but struggles with non-linearly separable data. To overcome this, we introduce Deep Discriminant Analysis (DDA), which directly optimizes the Fisher criterion utilizing deep networks. To ensure stable training and avoid computational instabilities, we incorporate signed between-class variance, bound outputs with a sigmoid function, and convert multiplicative relationships into additive ones. We present two stable DDA loss functions and augment them with a probability loss, resulting in Probabilistic DDA (PDDA). PDDA effectively minimizes class overlap in output distributions, producing highly confident predictions with reduced within-class variance. When applied to wind blade segmentation, PDDA showcases notable advances in performance and consistency, critical for wind energy maintenance. To our knowledge, this is the first application of DDA to image segmentation.

</details>


### [230] [OCCAM: Class-Agnostic, Training-Free, Prior-Free and Multi-Class Object Counting](https://arxiv.org/abs/2601.13871)
*Michail Spanakis,Iason Oikonomidis,Antonis Argyros*

Main category: cs.CV

TL;DR: OCCAM是首个无需训练、无需额外信息的类无关物体计数方法，能同时处理图像中多个物体类别的计数问题，基于SAM2和FINCH算法实现。


<details>
  <summary>Details</summary>
Motivation: 现有类无关物体计数方法通常假设每张图像只有一个物体类别，需要大量训练数据或额外信息（如视觉示例或文本提示），限制了实际应用。

Method: 结合Segment Anything Model 2（SAM2）基础模型和自定义阈值版本的FINCH聚类算法，无需训练即可实现多类别物体计数。

Result: 在FSC-147和CARPK基准数据集上取得有竞争力的性能，提出了合成多类别数据集和更合适的F1评分评估指标。

Conclusion: OCCAM是首个训练免费、无需额外信息的类无关物体计数方法，能有效处理多类别计数问题，为实际应用提供了更灵活的解决方案。

Abstract: Class-Agnostic object Counting (CAC) involves counting instances of objects from arbitrary classes within an image. Due to its practical importance, CAC has received increasing attention in recent years. Most existing methods assume a single object class per image, rely on extensive training of large deep learning models and address the problem by incorporating additional information, such as visual exemplars or text prompts. In this paper, we present OCCAM, the first training-free approach to CAC that operates without the need of any supplementary information. Moreover, our approach addresses the multi-class variant of the problem, as it is capable of counting the object instances in each and every class among arbitrary object classes within an image. We leverage Segment Anything Model 2 (SAM2), a foundation model, and a custom threshold-based variant of the First Integer Neighbor Clustering Hierarchy (FINCH) algorithm to achieve competitive performance on widely used benchmark datasets, FSC-147 and CARPK. We propose a synthetic multi-class dataset and F1 score as a more suitable evaluation metric. The code for our method and the proposed synthetic dataset will be made publicly available at https://mikespanak.github.io/OCCAM_counter.

</details>


### [231] [Two-Stream temporal transformer for video action classification](https://arxiv.org/abs/2601.14086)
*Nattapong Kurpukdee,Adrian G. Bors*

Main category: cs.CV

TL;DR: 提出一种双流Transformer视频分类器，结合内容帧和光流信息，在三个视频数据集上取得优秀分类效果


<details>
  <summary>Details</summary>
Motivation: 运动表示在视频理解中很重要，Transformer的自注意力机制在许多应用中表现出色，但需要更好地结合时空信息

Method: 提出双流Transformer视频分类器，分别从内容帧和光流中提取时空信息，通过自注意力机制在联合光流和时间帧域中识别特征关系

Result: 在三个人类活动视频数据集上取得了优秀的分类结果

Conclusion: 提出的双流Transformer方法能有效结合时空信息，在视频分类任务中表现优异

Abstract: Motion representation plays an important role in video understanding and has many applications including action recognition, robot and autonomous guidance or others. Lately, transformer networks, through their self-attention mechanism capabilities, have proved their efficiency in many applications. In this study, we introduce a new two-stream transformer video classifier, which extracts spatio-temporal information from content and optical flow representing movement information. The proposed model identifies self-attention features across the joint optical flow and temporal frame domain and represents their relationships within the transformer encoder mechanism. The experimental results show that our proposed methodology provides excellent classification results on three well-known video datasets of human activities.

</details>


### [232] [Revisiting Multi-Task Visual Representation Learning](https://arxiv.org/abs/2601.13886)
*Shangzhe Di,Zhonghua Zhai,Weidi Xie*

Main category: cs.CV

TL;DR: MTV是一个多任务视觉预训练框架，通过联合优化视觉语言对比、自监督和密集空间目标，结合了CLIP的全局语义对齐和MAE/DINO的局部结构捕捉优势，利用专家模型生成伪标签实现无人工标注的密集监督。


<details>
  <summary>Details</summary>
Motivation: 当前视觉表示学习存在分裂：视觉语言模型（如CLIP）擅长全局语义对齐但缺乏空间精度，而自监督方法（如MAE、DINO）能捕捉局部结构但缺乏高层语义上下文。作者认为这两种范式本质上是互补的，可以集成到一个统一的多任务框架中。

Method: 提出MTV多任务视觉预训练框架，联合优化共享骨干网络的三个目标：1）视觉语言对比学习，2）自监督学习，3）密集空间监督。利用Depth Anything V2和OWLv2等高容量专家模型生成密集结构化伪标签，避免人工标注。系统研究多任务学习机制，包括各目标的边际增益、任务协同与干扰、不同数据规模和模型规模的扩展行为。

Result: MTV实现了"两全其美"的性能，显著增强了细粒度空间推理能力，同时不损害全局语义理解。研究表明多任务学习结合高质量伪监督是构建更通用视觉编码器的可扩展路径。

Conclusion: 多任务学习框架能够有效整合不同视觉表示学习范式的优势，通过专家模型生成的伪标签提供密集监督，是实现更通用、更强大的视觉编码器的有前景方向。

Abstract: Current visual representation learning remains bifurcated: vision-language models (e.g., CLIP) excel at global semantic alignment but lack spatial precision, while self-supervised methods (e.g., MAE, DINO) capture intricate local structures yet struggle with high-level semantic context. We argue that these paradigms are fundamentally complementary and can be integrated into a principled multi-task framework, further enhanced by dense spatial supervision. We introduce MTV, a multi-task visual pretraining framework that jointly optimizes a shared backbone across vision-language contrastive, self-supervised, and dense spatial objectives. To mitigate the need for manual annotations, we leverage high-capacity "expert" models -- such as Depth Anything V2 and OWLv2 -- to synthesize dense, structured pseudo-labels at scale. Beyond the framework, we provide a systematic investigation into the mechanics of multi-task visual learning, analyzing: (i) the marginal gain of each objective, (ii) task synergies versus interference, and (iii) scaling behavior across varying data and model scales. Our results demonstrate that MTV achieves "best-of-both-worlds" performance, significantly enhancing fine-grained spatial reasoning without compromising global semantic understanding. Our findings suggest that multi-task learning, fueled by high-quality pseudo-supervision, is a scalable path toward more general visual encoders.

</details>


### [233] [Towards Visually Explaining Statistical Tests with Applications in Biomedical Imaging](https://arxiv.org/abs/2601.13899)
*Masoumeh Javanbakhat,Piotr Komorowski,Dilyara Bareeva,Wei-Chang Lai,Wojciech Samek,Christoph Lippert*

Main category: cs.CV

TL;DR: 提出可解释的深度统计测试框架，为深度双样本测试提供样本级和特征级解释，揭示哪些样本和特征驱动组间差异


<details>
  <summary>Details</summary>
Motivation: 深度双样本测试虽然检测能力强，但黑盒性质限制了可解释性，且现有解释方法依赖类别标签，不适用于无标签的统计测试场景

Method: 提出可解释的深度统计测试框架，为深度双样本测试增加样本级和特征级解释，识别驱动统计显著差异的个体样本和输入特征

Result: 框架能突出显示哪些图像区域和哪些个体样本对检测到的组间差异贡献最大，在生物医学影像数据中识别有影响力的样本并突出与疾病相关变化的解剖学意义区域

Conclusion: 该工作桥接了统计推断和可解释AI，实现了医学影像中可解释、无标签的群体分析

Abstract: Deep neural two-sample tests have recently shown strong power for detecting distributional differences between groups, yet their black-box nature limits interpretability and practical adoption in biomedical analysis. Moreover, most existing post-hoc explainability methods rely on class labels, making them unsuitable for label-free statistical testing settings. We propose an explainable deep statistical testing framework that augments deep two-sample tests with sample-level and feature-level explanations, revealing which individual samples and which input features drive statistically significant group differences. Our method highlights which image regions and which individual samples contribute most to the detected group difference, providing spatial and instance-wise insight into the test's decision. Applied to biomedical imaging data, the proposed framework identifies influential samples and highlights anatomically meaningful regions associated with disease-related variation. This work bridges statistical inference and explainable AI, enabling interpretable, label-free population analysis in medical imaging.

</details>


### [234] [LLM Augmented Intervenable Multimodal Adaptor for Post-operative Complication Prediction in Lung Cancer Surgery](https://arxiv.org/abs/2601.14154)
*Shubham Pandey,Bhavin Jawade,Srirangaraj Setlur,Venu Govindaraju,Kenneth Seastedt*

Main category: cs.CV

TL;DR: MIRACLE是一种深度学习架构，通过整合术前临床和放射学数据来预测肺癌手术后的并发症风险，采用超球嵌入空间融合异构输入，并包含干预性深度学习模块以提高预测透明度和临床实用性。


<details>
  <summary>Details</summary>
Motivation: 术后并发症严重影响患者预后并增加医疗成本，需要更准确、可解释的风险预测方法来改善临床决策和个性化风险管理。

Method: 提出MIRACLE深度学习架构，采用超球嵌入空间融合结构化临床记录和高维放射学图像，包含干预性深度学习模块提供可解释的预测结果，允许临床专家基于专业知识交互调整建议。

Result: 在包含3,094名肺癌手术患者的真实世界数据集POC-L上验证，MIRACLE在个性化术后风险管理方面优于传统机器学习模型和当代大型语言模型变体。

Conclusion: MIRACLE通过融合多模态数据和提供可解释的预测，为术后并发症风险预测提供了有效的深度学习解决方案，具有临床实用价值。

Abstract: Postoperative complications remain a critical concern in clinical practice, adversely affecting patient outcomes and contributing to rising healthcare costs. We present MIRACLE, a deep learning architecture for prediction of risk of postoperative complications in lung cancer surgery by integrating preoperative clinical and radiological data. MIRACLE employs a hyperspherical embedding space fusion of heterogeneous inputs, enabling the extraction of robust, discriminative features from both structured clinical records and high-dimensional radiological images. To enhance transparency of prediction and clinical utility, we incorporate an interventional deep learning module in MIRACLE, that not only refines predictions but also provides interpretable and actionable insights, allowing domain experts to interactively adjust recommendations based on clinical expertise. We validate our approach on POC-L, a real-world dataset comprising 3,094 lung cancer patients who underwent surgery at Roswell Park Comprehensive Cancer Center. Our results demonstrate that MIRACLE outperforms various traditional machine learning models and contemporary large language models (LLM) variants alone, for personalized and explainable postoperative risk management.

</details>


### [235] [On the Role of Rotation Equivariance in Monocular 3D Human Pose Estimation](https://arxiv.org/abs/2601.13913)
*Pavlo Melnyk,Cuong Le,Urs Waldmann,Per-Erik Forssén,Bastian Wandt*

Main category: cs.CV

TL;DR: 该论文提出通过数据增强学习2D旋转等变性来改进单目3D人体姿态估计，相比显式设计的等变方法更简单有效


<details>
  <summary>Details</summary>
Motivation: 单目3D人体姿态估计是一个不适定问题，现有方法通常采用两步法（2D检测+2D到3D提升）。作者发现现有提升模型在处理旋转输入时表现不佳，认为学习人体姿态及其平面内旋转比直接学习点对点映射更简单且几何基础更扎实。

Method: 提出通过数据增强让模型学习2D旋转等变性，而不是显式约束参数空间的等变设计。这种方法更直接简单，通过增强训练使模型获得旋转等变特性。

Result: 在常用的人体姿态估计基准测试中，验证了2D旋转等变性本身能显著提升模型在图像平面内旋转姿态上的性能，且通过增强学习的方法优于当前最先进的显式等变设计方法。

Conclusion: 通过数据增强学习旋转等变性是一种高效直接的方法，能够改善单目3D人体姿态估计的性能，特别是在处理旋转输入时，比显式设计的等变方法表现更好。

Abstract: Estimating 3D from 2D is one of the central tasks in computer vision. In this work, we consider the monocular setting, i.e. single-view input, for 3D human pose estimation (HPE). Here, the task is to predict a 3D point set of human skeletal joints from a single 2D input image. While by definition this is an ill-posed problem, recent work has presented methods that solve it with up to several-centimetre error. Typically, these methods employ a two-step approach, where the first step is to detect the 2D skeletal joints in the input image, followed by the step of 2D-to-3D lifting. We find that common lifting models fail when encountering a rotated input. We argue that learning a single human pose along with its in-plane rotations is considerably easier and more geometrically grounded than directly learning a point-to-point mapping. Furthermore, our intuition is that endowing the model with the notion of rotation equivariance without explicitly constraining its parameter space should lead to a more straightforward learning process than one with equivariance by design. Utilising the common HPE benchmarks, we confirm that the 2D rotation equivariance per se improves the model performance on human poses akin to rotations in the image plane, and can be efficiently and straightforwardly learned by augmentation, outperforming state-of-the-art equivariant-by-design methods.

</details>


### [236] [TrackletGPT: A Language-like GPT Framework for White Matter Tract Segmentation](https://arxiv.org/abs/2601.13935)
*Anoushkrit Goel,Simroop Singh,Ankita Joshi,Ranjeet Ranjan Jha,Chirag Ahuja,Aditya Nigam,Arnav Bhavsar*

Main category: cs.CV

TL;DR: TrackletGPT：一种基于GPT框架的白质纤维束分割方法，通过引入轨迹片段（tracklets）编码序列信息，在多个数据集上实现全自动分割，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 白质纤维束分割对研究大脑结构连接、神经系统疾病和神经外科手术至关重要。该任务面临复杂挑战：不同纤维束之间存在差异，跨受试者和条件变化，但在半球和受试者间具有相似的3D结构。

Method: 提出TrackletGPT，一种类似语言的GPT框架，通过轨迹片段（tracklets）在token中重新引入序列信息。该方法可无缝泛化到不同数据集，完全自动化，编码细粒度的子流线片段（Tracklets），在纤维束分割中扩展和优化GPT模型。

Result: 在TractoInferno和HCP数据集上，TrackletGPT在平均DICE、Overlap和Overreach分数上优于最先进方法，即使在跨数据集实验中也能保持优异性能。

Conclusion: TrackletGPT通过引入轨迹片段和GPT框架，有效解决了白质纤维束分割中的复杂挑战，实现了跨数据集的泛化能力和优异的性能表现。

Abstract: White Matter Tract Segmentation is imperative for studying brain structural connectivity, neurological disorders and neurosurgery. This task remains complex, as tracts differ among themselves, across subjects and conditions, yet have similar 3D structure across hemispheres and subjects. To address these challenges, we propose TrackletGPT, a language-like GPT framework which reintroduces sequential information in tokens using tracklets. TrackletGPT generalises seamlessly across datasets, is fully automatic, and encodes granular sub-streamline segments, Tracklets, scaling and refining GPT models in Tractography Segmentation. Based on our experiments, TrackletGPT outperforms state-of-the-art methods on average DICE, Overlap and Overreach scores on TractoInferno and HCP datasets, even on inter-dataset experiments.

</details>


### [237] [VTONGuard: Automatic Detection and Authentication of AI-Generated Virtual Try-On Content](https://arxiv.org/abs/2601.13951)
*Shengyi Wu,Yan Hong,Shengyao Chen,Zheng Wang,Xianbing Sun,Jiahui Zhan,Jun Lan,Jianfu Zhang*

Main category: cs.CV

TL;DR: VTONGuard：一个包含77.5万张真实与合成试穿图像的大规模基准数据集，用于评估虚拟试穿内容检测方法，并提出多任务框架提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI虚拟试穿系统的快速发展，AI生成的试穿内容越来越逼真，引发了关于真实性和负责任使用的紧迫担忧。需要建立基准数据集来评估检测方法，促进虚拟试穿技术的安全部署。

Method: 1) 构建VTONGuard数据集：包含超过77.5万张真实和合成试穿图像，涵盖姿势、背景、服装风格等多样化真实场景；2) 在统一训练和测试协议下系统评估多种检测范式；3) 设计多任务框架，集成辅助分割以增强边界感知特征学习。

Result: 1) 揭示了各种检测方法的优缺点，突出了跨范式泛化的持续挑战；2) 提出的多任务框架在VTONGuard基准上实现了最佳整体性能；3) 建立了公平比较的标准，促进了更鲁棒检测模型的开发。

Conclusion: VTONGuard基准数据集能够实现公平比较，促进更鲁棒检测模型的开发，推动虚拟试穿技术在实践中的安全和负责任部署。

Abstract: With the rapid advancement of generative AI, virtual try-on (VTON) systems are becoming increasingly common in e-commerce and digital entertainment. However, the growing realism of AI-generated try-on content raises pressing concerns about authenticity and responsible use. To address this, we present VTONGuard, a large-scale benchmark dataset containing over 775,000 real and synthetic try-on images. The dataset covers diverse real-world conditions, including variations in pose, background, and garment styles, and provides both authentic and manipulated examples. Based on this benchmark, we conduct a systematic evaluation of multiple detection paradigms under unified training and testing protocols. Our results reveal each method's strengths and weaknesses and highlight the persistent challenge of cross-paradigm generalization. To further advance detection, we design a multi-task framework that integrates auxiliary segmentation to enhance boundary-aware feature learning, achieving the best overall performance on VTONGuard. We expect this benchmark to enable fair comparisons, facilitate the development of more robust detection models, and promote the safe and responsible deployment of VTON technologies in practice.

</details>


### [238] [DExTeR: Weakly Semi-Supervised Object Detection with Class and Instance Experts for Medical Imaging](https://arxiv.org/abs/2601.13954)
*Adrien Meyer,Didier Mutter,Nicolas Padoy*

Main category: cs.CV

TL;DR: DExTeR：基于Transformer的医学影像点标注到边界框回归器，通过类引导可变形注意力、CLICK-MoE专家混合和多点训练策略，在三个医学数据集上实现最先进性能


<details>
  <summary>Details</summary>
Motivation: 医学影像中的解剖标志检测对诊断和介入指导至关重要，但传统目标检测模型依赖昂贵的边界框标注。弱半监督目标检测使用点标注可减少标注成本，但医学影像存在解剖结构重叠、尺寸多变和结构难以捕捉等独特挑战，阻碍了准确的边界框推断。

Method: 基于Point-DETR构建DExTeR，将单点标注编码为对象查询，使用类引导可变形注意力改进特征提取，通过CLICK-MoE分离类和实例表示以减少相邻或重叠实例的混淆，并采用多点训练策略提高对标注变化的鲁棒性。

Result: 在三个不同医学领域数据集（内窥镜、胸部X光和内窥镜超声）上实现了最先进的性能，展示了在降低标注成本的同时保持高检测精度的潜力。

Conclusion: DExTeR通过专门设计的Transformer架构有效解决了医学影像中点标注到边界框回归的挑战，为减少医学影像标注成本提供了有效解决方案，在多个医学领域展现了优越性能。

Abstract: Detecting anatomical landmarks in medical imaging is essential for diagnosis and intervention guidance. However, object detection models rely on costly bounding box annotations, limiting scalability. Weakly Semi-Supervised Object Detection (WSSOD) with point annotations proposes annotating each instance with a single point, minimizing annotation time while preserving localization signals. A Point-to-Box teacher model, trained on a small box-labeled subset, converts these point annotations into pseudo-box labels to train a student detector. Yet, medical imagery presents unique challenges, including overlapping anatomy, variable object sizes, and elusive structures, which hinder accurate bounding box inference. To overcome these challenges, we introduce DExTeR (DETR with Experts), a transformer-based Point-to-Box regressor tailored for medical imaging. Built upon Point-DETR, DExTeR encodes single-point annotations as object queries, refining feature extraction with the proposed class-guided deformable attention, which guides attention sampling using point coordinates and class labels to capture class-specific characteristics. To improve discrimination in complex structures, it introduces CLICK-MoE (CLass, Instance, and Common Knowledge Mixture of Experts), decoupling class and instance representations to reduce confusion among adjacent or overlapping instances. Finally, we implement a multi-point training strategy which promotes prediction consistency across different point placements, improving robustness to annotation variability. DExTeR achieves state-of-the-art performance across three datasets spanning different medical domains (endoscopy, chest X-rays, and endoscopic ultrasound) highlighting its potential to reduce annotation costs while maintaining high detection accuracy.

</details>


### [239] [VideoMaMa: Mask-Guided Video Matting via Generative Prior](https://arxiv.org/abs/2601.14255)
*Sangbeom Lim,Seoung Wug Oh,Jiahui Huang,Heeji Yoon,Seungryong Kim,Joon-Young Lee*

Main category: cs.CV

TL;DR: VideoMaMa利用预训练视频扩散模型将粗糙分割掩码转换为精确alpha遮罩，仅用合成数据训练就能实现真实视频的零样本泛化。基于此构建了大规模伪标注视频遮罩数据集MA-V，并训练出性能更优的SAM2-Matte模型。


<details>
  <summary>Details</summary>
Motivation: 视频遮罩模型在真实世界视频中泛化困难，主要原因是标注数据稀缺。现有方法难以处理多样化的真实场景和运动。

Method: 提出VideoMaMa模型，利用预训练视频扩散模型将粗糙分割掩码转换为精确alpha遮罩。基于此构建可扩展的伪标注流程，创建大规模视频遮罩数据集MA-V（包含5万+真实视频）。在MA-V上微调SAM2模型得到SAM2-Matte。

Result: VideoMaMa仅用合成数据训练就能在真实视频上实现强零样本泛化。SAM2-Matte在真实世界视频上的鲁棒性优于基于现有遮罩数据集训练的相同模型。MA-V数据集包含高质量遮罩标注，涵盖多样化场景和运动。

Conclusion: 大规模伪标注视频遮罩数据对提升模型性能至关重要。生成先验和易获取的分割线索能够推动视频遮罩研究的可扩展进展。

Abstract: Generalizing video matting models to real-world videos remains a significant challenge due to the scarcity of labeled data. To address this, we present Video Mask-to-Matte Model (VideoMaMa) that converts coarse segmentation masks into pixel accurate alpha mattes, by leveraging pretrained video diffusion models. VideoMaMa demonstrates strong zero-shot generalization to real-world footage, even though it is trained solely on synthetic data. Building on this capability, we develop a scalable pseudo-labeling pipeline for large-scale video matting and construct the Matting Anything in Video (MA-V) dataset, which offers high-quality matting annotations for more than 50K real-world videos spanning diverse scenes and motions. To validate the effectiveness of this dataset, we fine-tune the SAM2 model on MA-V to obtain SAM2-Matte, which outperforms the same model trained on existing matting datasets in terms of robustness on in-the-wild videos. These findings emphasize the importance of large-scale pseudo-labeled video matting and showcase how generative priors and accessible segmentation cues can drive scalable progress in video matting research.

</details>


### [240] [STEC: A Reference-Free Spatio-Temporal Entropy Coverage Metric for Evaluating Sampled Video Frames](https://arxiv.org/abs/2601.13974)
*Shih-Yao Lin*

Main category: cs.CV

TL;DR: 提出STEC（时空熵覆盖）指标，用于评估视频帧采样的质量，通过测量空间信息强度、时间分散性和非冗余性来诊断采样策略的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有视频帧采样评估指标主要关注感知质量或重建保真度，缺乏评估采样帧是否充分捕捉视频信息内容和代表性的方法。

Method: 基于时空帧熵（STFE）测量每帧的空间信息（基于熵的结构复杂度），然后评估采样帧的时间覆盖和冗余性，通过联合建模空间信息强度、时间分散性和非冗余性来计算STEC指标。

Result: 在MSR-VTT测试集上，STEC能清晰区分随机、均匀和内容感知等常见采样策略，并能揭示平均性能无法捕捉的单个视频鲁棒性模式。

Conclusion: STEC提供了一种任务无关的诊断信号，用于在有限预算下分析帧采样行为，作为视频理解中采样策略评估的通用工具。

Abstract: Frame sampling is a fundamental component in video understanding and video--language model pipelines, yet evaluating the quality of sampled frames remains challenging. Existing evaluation metrics primarily focus on perceptual quality or reconstruction fidelity, and are not designed to assess whether a set of sampled frames adequately captures informative and representative video content.
  We propose Spatio-Temporal Entropy Coverage (STEC), a simple and non-reference metric for evaluating the effectiveness of video frame sampling. STEC builds upon Spatio-Temporal Frame Entropy (STFE), which measures per-frame spatial information via entropy-based structural complexity, and evaluates sampled frames based on their temporal coverage and redundancy. By jointly modeling spatial information strength, temporal dispersion, and non-redundancy, STEC provides a principled and lightweight measure of sampling quality.
  Experiments on the MSR-VTT test-1k benchmark demonstrate that STEC clearly differentiates common sampling strategies, including random, uniform, and content-aware methods. We further show that STEC reveals robustness patterns across individual videos that are not captured by average performance alone, highlighting its practical value as a general-purpose evaluation tool for efficient video understanding.
  We emphasize that STEC is not designed to predict downstream task accuracy, but to provide a task-agnostic diagnostic signal for analyzing frame sampling behavior under constrained budgets.

</details>


### [241] [Harmonizing the Deep: A Unified Information Pipeline for Robust Marine Biodiversity Assessment Across Heterogeneous Domains](https://arxiv.org/abs/2601.13975)
*Marco Piccolo,Qiwei Han,Astrid van Toor,Joachim Vanneste*

Main category: cs.CV

TL;DR: 该研究为海洋入侵物种监测建立了基础检测层，通过统一信息管道标准化异构数据集，发现场景结构因素（而非视觉退化）是跨域性能下降的主要原因，并在低成本边缘硬件上验证了操作可行性。


<details>
  <summary>Details</summary>
Motivation: 海洋生物多样性监测需要在复杂水下环境中实现可扩展性和可靠性，以支持保护和入侵物种管理。现有检测解决方案存在明显的部署差距，当转移到新地点时性能会急剧下降。

Method: 开发统一信息管道，将异构数据集标准化为可比信息流；在受控跨域协议下评估固定的、与部署相关的检测器；分析结构因素（场景组成、物体密度、上下文冗余）与视觉退化因素对性能的影响；在低成本边缘硬件上基准测试推理性能。

Result: 发现结构因素比视觉退化（如浑浊度）更能解释跨域性能损失；稀疏场景会引发特征性的"上下文崩溃"故障模式；运行时优化使低成本边缘硬件能够实现实际采样率，支持远程监测。

Conclusion: 研究重点应从图像增强转向结构感知的可靠性，为一致的海洋生态系统评估提供了民主化工具，支持北极和大西洋海洋生态系统的多年入侵物种监测计划。

Abstract: Marine biodiversity monitoring requires scalability and reliability across complex underwater environments to support conservation and invasive-species management. Yet existing detection solutions often exhibit a pronounced deployment gap, with performance degrading sharply when transferred to new sites. This work establishes the foundational detection layer for a multi-year invasive species monitoring initiative targeting Arctic and Atlantic marine ecosystems. We address this challenge by developing a Unified Information Pipeline that standardises heterogeneous datasets into a comparable information flow and evaluates a fixed, deployment-relevant detector under controlled cross-domain protocols. Across multiple domains, we find that structural factors, such as scene composition, object density, and contextual redundancy, explain cross-domain performance loss more strongly than visual degradation such as turbidity, with sparse scenes inducing a characteristic "Context Collapse" failure mode. We further validate operational feasibility by benchmarking inference on low-cost edge hardware, showing that runtime optimisation enables practical sampling rates for remote monitoring. The results shift emphasis from image enhancement toward structure-aware reliability, providing a democratised tool for consistent marine ecosystem assessment.

</details>


### [242] [FantasyVLN: Unified Multimodal Chain-of-Thought Reasoning for Vision-Language Navigation](https://arxiv.org/abs/2601.13976)
*Jing Zuo,Lingzhou Mu,Fan Jiang,Chengcheng Ma,Mu Xu,Yonggang Qi*

Main category: cs.CV

TL;DR: FantasyVLN：一种统一的隐式推理框架，通过将想象的视觉标记编码到紧凑的潜在空间，在保持CoT推理优势的同时避免了显式标记开销，实现了推理感知的实时导航。


<details>
  <summary>Details</summary>
Motivation: 现有VLN导航方法中，纯文本CoT缺乏空间基础且容易过拟合稀疏标注的推理步骤，而多模态CoT由于生成想象的视觉观察导致严重的标记膨胀，使得实时导航不切实际。

Method: 提出FantasyVLN统一隐式推理框架：1）使用预训练的视觉自回归器（VAR）将想象的视觉标记编码到紧凑潜在空间；2）在CoT推理训练中，模型从文本、视觉和多模态CoT模式中联合学习；3）采用统一的多CoT策略；4）推理时直接进行指令到动作的映射，同时保持推理感知的表征。

Result: 在LH-VLN上的大量实验表明，该方法实现了推理感知的实时导航，提高了成功率和效率，同时相比显式CoT方法将推理延迟降低了一个数量级。

Conclusion: FantasyVLN通过隐式推理框架成功解决了现有CoT方法在VLN中的关键缺陷，在保持推理能力的同时实现了实时性能，为人类级导航推理提供了有前景的途径。

Abstract: Achieving human-level performance in Vision-and-Language Navigation (VLN) requires an embodied agent to jointly understand multimodal instructions and visual-spatial context while reasoning over long action sequences. Recent works, such as NavCoT and NavGPT-2, demonstrate the potential of Chain-of-Thought (CoT) reasoning for improving interpretability and long-horizon planning. Moreover, multimodal extensions like OctoNav-R1 and CoT-VLA further validate CoT as a promising pathway toward human-like navigation reasoning. However, existing approaches face critical drawbacks: purely textual CoTs lack spatial grounding and easily overfit to sparse annotated reasoning steps, while multimodal CoTs incur severe token inflation by generating imagined visual observations, making real-time navigation impractical. In this work, we propose FantasyVLN, a unified implicit reasoning framework that preserves the benefits of CoT reasoning without explicit token overhead. Specifically, imagined visual tokens are encoded into a compact latent space using a pretrained Visual AutoRegressor (VAR) during CoT reasoning training, and the model jointly learns from textual, visual, and multimodal CoT modes under a unified multi-CoT strategy. At inference, our model performs direct instruction-to-action mapping while still enjoying reasoning-aware representations. Extensive experiments on LH-VLN show that our approach achieves reasoning-aware yet real-time navigation, improving success rates and efficiency while reducing inference latency by an order of magnitude compared to explicit CoT methods.

</details>


### [243] [Equivariant Learning for Unsupervised Image Dehazing](https://arxiv.org/abs/2601.13986)
*Zhang Wen,Jiangwei Xie,Dongdong Chen*

Main category: cs.CV

TL;DR: 提出了一种新的无监督图像去雾框架EID，利用图像信号的对称性直接从原始有雾图像恢复清晰图像，在科学图像和自然图像去雾任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前图像去雾方法通常依赖精心设计的先验知识或大量无雾地面真值，这些在科学成像中获取成本高或不切实际。需要一种无需这些昂贵资源的方法。

Method: 提出了等变图像去雾(EID)框架，通过强制雾霾一致性和系统等变性来恢复清晰图像。还提出了对抗学习策略来建模未知雾霾物理特性并促进EID学习。

Result: 在两个科学图像去雾基准测试（细胞显微镜和医学内窥镜）以及自然图像去雾实验中，EID显著优于最先进的方法。

Conclusion: 通过将等变学习与雾霾物理建模相结合，EID有望在科学成像中实现更通用和有效的雾霾去除。代码和数据集将公开发布。

Abstract: Image Dehazing (ID) aims to produce a clear image from an observation contaminated by haze. Current ID methods typically rely on carefully crafted priors or extensive haze-free ground truth, both of which are expensive or impractical to acquire, particularly in the context of scientific imaging. We propose a new unsupervised learning framework called Equivariant Image Dehazing (EID) that exploits the symmetry of image signals to restore clarity to hazy observations. By enforcing haze consistency and systematic equivariance, EID can recover clear patterns directly from raw, hazy images. Additionally, we propose an adversarial learning strategy to model unknown haze physics and facilitate EID learning. Experiments on two scientific image dehazing benchmarks (including cell microscopy and medical endoscopy) and on natural image dehazing have demonstrated that EID significantly outperforms state-of-the-art approaches. By unifying equivariant learning with modelling haze physics, we hope that EID will enable more versatile and effective haze removal in scientific imaging. Code and datasets will be published.

</details>


### [244] [Likelihood-Separable Diffusion Inference for Multi-Image MRI Super-Resolution](https://arxiv.org/abs/2601.14030)
*Samuel W. Remedios,Zhangxing Bian,Shuwen Wei,Aaron Carass,Jerry L. Prince,Blake E. Dewey*

Main category: cs.CV

TL;DR: 该论文将扩散模型从单图像逆问题扩展到多图像超分辨率MRI，通过可分离梯度分解实现多图像重建，无需修改扩散模型或增加计算成本。


<details>
  <summary>Details</summary>
Motivation: 当前扩散模型主要针对单图像逆问题，但MRI等模态通常需要采集多个互补的低分辨率测量值。现有方法无法有效处理多图像超分辨率问题。

Method: 将DPS似然校正推广到多图像超分辨率，利用其可分离梯度分解特性，在不构建联合算子、不修改扩散模型、不增加网络评估次数的情况下实现MISR。推导了DPS、DMAP、DPPS和扩散PnP/ADMM的MISR版本。

Result: 在4×/8×/16×各向异性退化情况下，相比单图像超分辨率获得显著提升，实现了各向异性MRI体数据的最先进超分辨率，能够从常规2D多切片采集重建近各向同性解剖结构。

Conclusion: 该方法成功将扩散模型扩展到多图像MRI超分辨率，为从常规2D多切片采集重建高质量3D解剖结构提供了有效解决方案，解决了正交视图严重退化的问题。

Abstract: Diffusion models are the current state-of-the-art for solving inverse problems in imaging. Their impressive generative capability allows them to approximate sampling from a prior distribution, which alongside a known likelihood function permits posterior sampling without retraining the model. While recent methods have made strides in advancing the accuracy of posterior sampling, the majority focuses on single-image inverse problems. However, for modalities such as magnetic resonance imaging (MRI), it is common to acquire multiple complementary measurements, each low-resolution along a different axis. In this work, we generalize common diffusion-based inverse single-image problem solvers for multi-image super-resolution (MISR) MRI. We show that the DPS likelihood correction allows an exactly-separable gradient decomposition across independently acquired measurements, enabling MISR without constructing a joint operator, modifying the diffusion model, or increasing network function evaluations. We derive MISR versions of DPS, DMAP, DPPS, and diffusion-based PnP/ADMM, and demonstrate substantial gains over SISR across $4\times/8\times/16\times$ anisotropic degradations. Our results achieve state-of-the-art super-resolution of anisotropic MRI volumes and, critically, enable reconstruction of near-isotropic anatomy from routine 2D multi-slice acquisitions, which are otherwise highly degraded in orthogonal views.

</details>


### [245] [Human detectors are surprisingly powerful reward models](https://arxiv.org/abs/2601.14037)
*Kumar Ashutosh,XuDong Wang,Xi Yin,Kristen Grauman,Adam Polyak,Ishan Misra,Rohit Girdhar*

Main category: cs.CV

TL;DR: 提出HuDA奖励模型，通过结合人体检测置信度和时序提示对齐分数来量化并改善生成视频中的人类动作质量，无需额外训练即可超越专门模型。


<details>
  <summary>Details</summary>
Motivation: 当前视频生成模型在复杂非刚性动作（如运动、舞蹈等）上表现不佳，常出现肢体缺失、姿势扭曲或物理上不合理的动作，需要改进人类动作的生成质量。

Method: 提出HuDA奖励模型，结合人体检测置信度评估外观质量，使用时序提示对齐分数捕捉动作真实性。采用现成模型无需额外训练，并通过Group Reward Policy Optimization (GRPO)进行后训练优化。

Result: HuDA在复杂人类动作生成上显著优于专门模型，使用GRPO后训练的视频模型在人类动作生成上超越Wan 2.1等SOTA模型，胜率达73%。同时还能改善动物视频和人物-物体交互的生成质量。

Conclusion: HuDA作为一个简单但有效的奖励模型，能够显著提升视频生成中人类动作的质量，且无需额外训练，具有广泛的应用潜力。

Abstract: Video generation models have recently achieved impressive visual fidelity and temporal coherence. Yet, they continue to struggle with complex, non-rigid motions, especially when synthesizing humans performing dynamic actions such as sports, dance, etc. Generated videos often exhibit missing or extra limbs, distorted poses, or physically implausible actions. In this work, we propose a remarkably simple reward model, HuDA, to quantify and improve the human motion in generated videos. HuDA integrates human detection confidence for appearance quality, and a temporal prompt alignment score to capture motion realism. We show this simple reward function that leverages off-the-shelf models without any additional training, outperforms specialized models finetuned with manually annotated data. Using HuDA for Group Reward Policy Optimization (GRPO) post-training of video models, we significantly enhance video generation, especially when generating complex human motions, outperforming state-of-the-art models like Wan 2.1, with win-rate of 73%. Finally, we demonstrate that HuDA improves generation quality beyond just humans, for instance, significantly improving generation of animal videos and human-object interactions.

</details>


### [246] [Correcting and Quantifying Systematic Errors in 3D Box Annotations for Autonomous Driving](https://arxiv.org/abs/2601.14038)
*Alexandre Justo Miro,Ludvig af Klinteberg,Bogdan Timus,Aron Asefaw,Ajinkya Khoche,Thomas Gustafsson,Sina Sharif Mansouri,Masoud Daneshtalab*

Main category: cs.CV

TL;DR: 本文首次发现并纠正了自动驾驶公开数据集中3D框标注的系统性误差，这些误差源于动态场景中传感器扫描模式与物体运动的时间错位，通过离线估计方法提升标注质量超过17%。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统的监督学习和性能评估依赖于准确的地面真值标注。然而，在动态场景中，由于LiDAR等主动传感器按预定模式扫描环境，物体在不同时间戳被观测到不同位置，导致3D框标注存在系统性误差，这些误差在现有公开数据集中尚未被发现和解决。

Method: 提出一种新颖的离线估计方法，通过校正标注使其遵循物理上可行的轨迹，并与传感器数据保持空间和时间一致性。该方法首次定义了该问题的评估指标，并在Argoverse 2、MAN TruckScenes和专有数据集上进行验证。

Result: 方法将三个数据集的框标注质量提升超过17%。量化分析显示原始标注误差最大可达2.5米，高度动态物体受影响最严重。误差对基准测试的影响超过了SOTA方法相对于先前SOTA方法的改进幅度。

Conclusion: 准确的标注对于正确解释自动驾驶系统性能至关重要。本文首次发现并纠正了公开数据集中的系统性标注误差，这些误差的影响甚至超过了SOTA方法的改进幅度，凸显了高质量标注的重要性。

Abstract: Accurate ground truth annotations are critical to supervised learning and evaluating the performance of autonomous vehicle systems. These vehicles are typically equipped with active sensors, such as LiDAR, which scan the environment in predefined patterns. 3D box annotation based on data from such sensors is challenging in dynamic scenarios, where objects are observed at different timestamps, hence different positions. Without proper handling of this phenomenon, systematic errors are prone to being introduced in the box annotations. Our work is the first to discover such annotation errors in widely used, publicly available datasets. Through our novel offline estimation method, we correct the annotations so that they follow physically feasible trajectories and achieve spatial and temporal consistency with the sensor data. For the first time, we define metrics for this problem; and we evaluate our method on the Argoverse 2, MAN TruckScenes, and our proprietary datasets. Our approach increases the quality of box annotations by more than 17% in these datasets. Furthermore, we quantify the annotation errors in them and find that the original annotations are misplaced by up to 2.5 m, with highly dynamic objects being the most affected. Finally, we test the impact of the errors in benchmarking and find that the impact is larger than the improvements that state-of-the-art methods typically achieve with respect to the previous state-of-the-art methods; showing that accurate annotations are essential for correct interpretation of performance. Our code is available at https://github.com/alexandre-justo-miro/annotation-correction-3D-boxes.

</details>


### [247] [Federated Balanced Learning](https://arxiv.org/abs/2601.14042)
*Jiaze Li,Haoran Xu,Wanyi Wu,Changwei Wang,Shuaiguang Li,Jianzhong Ju,Zhenbo Luo,Jian Luan,Youyang Qu,Longxiang Gao,Xudong Yang,Lumin Xing*

Main category: cs.CV

TL;DR: 提出FBL联邦平衡学习，通过客户端样本平衡解决非IID数据下的客户端漂移问题，使用知识填充和知识采样实现样本平衡，并设计了知识对齐和知识丢弃策略。


<details>
  <summary>Details</summary>
Motivation: 在联邦学习中，非独立同分布（non-iid）数据会导致全局模型出现客户端漂移问题，严重影响最终模型性能。现有方法通常基于损失函数或梯度纠正已偏离的全局模型，但忽视了客户端样本的影响。

Method: 提出FBL联邦平衡学习方法：1）在客户端侧通过知识填充和知识采样实现样本平衡；2）设计知识对齐策略来弥合合成数据与真实数据之间的差距；3）引入知识丢弃策略进行正则化；4）扩展到真实复杂场景，允许不同客户端采用不同方法。

Result: 大量实验表明，该方法优于现有的最先进基线方法。

Conclusion: FBL通过从客户端侧解决样本不平衡问题，有效预防了联邦学习中的客户端漂移，在非IID设置下取得了优越性能。

Abstract: Federated learning is a paradigm of joint learning in which clients collaborate by sharing model parameters instead of data. However, in the non-iid setting, the global model experiences client drift, which can seriously affect the final performance of the model. Previous methods tend to correct the global model that has already deviated based on the loss function or gradient, overlooking the impact of the client samples. In this paper, we rethink the role of the client side and propose Federated Balanced Learning, i.e., FBL, to prevent this issue from the beginning through sample balance on the client side. Technically, FBL allows unbalanced data on the client side to achieve sample balance through knowledge filling and knowledge sampling using edge-side generation models, under the limitation of a fixed number of data samples on clients. Furthermore, we design a Knowledge Alignment Strategy to bridge the gap between synthetic and real data, and a Knowledge Drop Strategy to regularize our method. Meanwhile, we scale our method to real and complex scenarios, allowing different clients to adopt various methods, and extend our framework to further improve performance. Numerous experiments show that our method outperforms state-of-the-art baselines. The code is released upon acceptance.

</details>


### [248] [Weather-R1: Logically Consistent Reinforcement Fine-Tuning for Multimodal Reasoning in Meteorology](https://arxiv.org/abs/2601.14044)
*Kaiyu Wu,Pucheng Han,Hualong Zhang,Naigeng Wu,Keze Wang*

Main category: cs.CV

TL;DR: 提出WeatherQA气象多模态推理基准和LoCo-RFT方法，解决VLM在气象领域存在的领域鸿沟和推理忠实性问题，创建了首个具有逻辑忠实性的气象推理模型Weather-R1。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在气象学应用中面临两个主要挑战：领域鸿沟（domain gap）和推理忠实性鸿沟（reasoning faithfulness gap）。特别是主流强化微调方法会导致自相矛盾推理，这在气象等高风险领域是不可接受的。

Method: 1. 构建WeatherQA气象多模态推理基准；2. 提出逻辑一致强化微调（LoCo-RFT），通过引入逻辑一致性奖励来解决自相矛盾推理问题；3. 开发Weather-R1，首个具有逻辑忠实性的气象推理视觉语言模型。

Result: Weather-R1在WeatherQA基准上的性能比基线提高了9.8个百分点，优于监督微调和传统强化微调，甚至超越了原始的Qwen2.5-VL-32B模型。

Conclusion: LoCo-RFT方法有效解决了VLM在气象领域的自相矛盾推理问题，Weather-R1展示了在气象多模态推理任务上的优越性能，为高风险领域的可靠AI应用提供了解决方案。

Abstract: While Vision Language Models (VLMs) show advancing reasoning capabilities, their application in meteorology is constrained by a domain gap and a reasoning faithfulness gap. Specifically, mainstream Reinforcement Fine-Tuning (RFT) can induce Self-Contradictory Reasoning (Self-Contra), where the model's reasoning contradicts its final answer, which is unacceptable in such a high-stakes domain. To address these challenges, we construct WeatherQA, a novel multimodal reasoning benchmark in meteorology. We also propose Logically Consistent Reinforcement Fine-Tuning (LoCo-RFT), which resolves Self-Contra by introducing a logical consistency reward. Furthermore, we introduce Weather-R1, the first reasoning VLM with logical faithfulness in meteorology, to the best of our knowledge. Experiments demonstrate that Weather-R1 improves performance on WeatherQA by 9.8 percentage points over the baseline, outperforming Supervised Fine-Tuning and RFT, and even surpassing the original Qwen2.5-VL-32B. These results highlight the effectiveness of our LoCo-RFT and the superiority of Weather-R1. Our benchmark and code are available at https://github.com/Marcowky/Weather-R1.

</details>


### [249] [Vision Also You Need: Navigating Out-of-Distribution Detection with Multimodal Large Language Model](https://arxiv.org/abs/2601.14052)
*Haoran Xu,Yanlin Liu,Zizhao Tong,Jiaze Li,Kexue Fu,Yuyang Zhang,Longxiang Gao,Shuaiguang Li,Xingyu Li,Yanran Xu,Changwei Wang*

Main category: cs.CV

TL;DR: 提出MM-OOD方法，利用多模态大模型进行零样本OOD检测，通过多轮对话增强异常检测能力，在近OOD和远OOD任务上均有提升


<details>
  <summary>Details</summary>
Motivation: 现有零样本OOD检测方法过度依赖文本空间知识，忽视了图像空间检测的固有挑战，需要更平衡的多模态方法

Method: 提出MM-OOD管道：1) 近OOD任务：直接将ID图像和文本提示输入MLLMs识别异常；2) 远OOD任务：采用草图-生成-阐述框架，先用文本提示草图异常，生成视觉OOD样本，再用多模态提示阐述

Result: 在Food-101等广泛使用的多模态数据集上取得显著改进，在ImageNet-1K上验证了可扩展性

Conclusion: MM-OOD方法通过利用MLLMs的多模态推理和多轮对话能力，有效提升了零样本OOD检测性能，特别是在平衡文本和视觉信息方面表现出色

Abstract: Out-of-Distribution (OOD) detection is a critical task that has garnered significant attention. The emergence of CLIP has spurred extensive research into zero-shot OOD detection, often employing a training-free approach. Current methods leverage expert knowledge from large language models (LLMs) to identify potential outliers. However, these approaches tend to over-rely on knowledge in the text space, neglecting the inherent challenges involved in detecting out-of-distribution samples in the image space. In this paper, we propose a novel pipeline, MM-OOD, which leverages the multimodal reasoning capabilities of MLLMs and their ability to conduct multi-round conversations for enhanced outlier detection. Our method is designed to improve performance in both near OOD and far OOD tasks. Specifically, (1) for near OOD tasks, we directly feed ID images and corresponding text prompts into MLLMs to identify potential outliers; and (2) for far OOD tasks, we introduce the sketch-generate-elaborate framework: first, we sketch outlier exposure using text prompts, then generate corresponding visual OOD samples, and finally elaborate by using multimodal prompts. Experiments demonstrate that our method achieves significant improvements on widely used multimodal datasets such as Food-101, while also validating its scalability on ImageNet-1K.

</details>


### [250] [Fine-Grained Zero-Shot Composed Image Retrieval with Complementary Visual-Semantic Integration](https://arxiv.org/abs/2601.14060)
*Yongcong Ye,Kai Zhang,Yanghai Zhang,Enhong Chen,Longfei Li,Jun Zhou*

Main category: cs.CV

TL;DR: CVSI提出了一种新的零样本组合图像检索方法，通过互补的视觉-语义集成来更好地捕捉细粒度变化，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的零样本组合图像检索方法在捕捉细粒度变化和有效集成视觉与语义信息方面存在困难，主要依赖将多模态查询转换为单一文本或使用大语言模型生成目标图像描述，这些方法往往无法捕捉互补的视觉信息和完整的语义上下文。

Method: CVSI包含三个关键组件：1）视觉信息提取：提取全局图像特征，并使用预训练映射网络将图像转换为伪标记，与修改文本和可能添加的对象结合；2）语义信息提取：使用预训练描述模型为参考图像生成多个描述，然后利用LLM生成修改后的描述和可能添加的对象；3）互补信息检索：集成从查询和数据库图像中提取的信息来检索目标图像。

Result: 在三个公共数据集（CIRR、CIRCO、FashionIQ）上的大量实验表明，CVSI显著优于现有的最先进方法。

Conclusion: CVSI通过互补的视觉-语义集成有效解决了现有零样本组合图像检索方法的局限性，能够更好地捕捉细粒度变化，在各种情况下高效处理检索查询。

Abstract: Zero-shot composed image retrieval (ZS-CIR) is a rapidly growing area with significant practical applications, allowing users to retrieve a target image by providing a reference image and a relative caption describing the desired modifications. Existing ZS-CIR methods often struggle to capture fine-grained changes and integrate visual and semantic information effectively. They primarily rely on either transforming the multimodal query into a single text using image-to-text models or employing large language models for target image description generation, approaches that often fail to capture complementary visual information and complete semantic context. To address these limitations, we propose a novel Fine-Grained Zero-Shot Composed Image Retrieval method with Complementary Visual-Semantic Integration (CVSI). Specifically, CVSI leverages three key components: (1) Visual Information Extraction, which not only extracts global image features but also uses a pre-trained mapping network to convert the image into a pseudo token, combining it with the modification text and the objects most likely to be added. (2) Semantic Information Extraction, which involves using a pre-trained captioning model to generate multiple captions for the reference image, followed by leveraging an LLM to generate the modified captions and the objects most likely to be added. (3) Complementary Information Retrieval, which integrates information extracted from both the query and database images to retrieve the target image, enabling the system to efficiently handle retrieval queries in a variety of situations. Extensive experiments on three public datasets (e.g., CIRR, CIRCO, and FashionIQ) demonstrate that CVSI significantly outperforms existing state-of-the-art methods. Our code is available at https://github.com/yyc6631/CVSI.

</details>


### [251] [VERIDAH: Solving Enumeration Anomaly Aware Vertebra Labeling across Imaging Sequences](https://arxiv.org/abs/2601.14066)
*Hendrik Möller,Hanna Schoen,Robert Graf,Matan Atad,Nathan Molinier,Anjany Sekuboyina,Bettina K. Budai,Fabian Bamberg,Steffen Ringhof,Christopher Schlett,Tobias Pischon,Thoralf Niendorf,Josua A. Decker,Marc-André Weber,Bjoern Menze,Daniel Rueckert,Jan S. Kirschke*

Main category: cs.CV

TL;DR: 提出VERIDAH算法，基于多分类头与加权椎骨序列预测，能自动标记椎骨计数异常，在MRI和CT影像上表现优于现有方法


<details>
  <summary>Details</summary>
Motivation: 椎骨计数异常（如11或13个胸椎、4或6个腰椎）具有临床意义，但现有深度学习算法缺乏自动识别这些异常的能力，临床报告中也很少描述

Method: 提出VERIDAH算法，结合多分类头与加权椎骨序列预测算法，能在任意视野图像中工作

Result: 在T2w TSE矢状位MRI上正确标记所有椎骨的比例从94.24%提升到98.30%，CT上从77.26%提升到99.18%；胸椎计数异常识别率在MRI和CT上分别为87.80%和96.30%，腰椎异常识别率分别为94.48%和97.22%

Conclusion: VERIDAH能有效自动识别椎骨计数异常，填补了现有方法的空白，代码和模型已开源

Abstract: The human spine commonly consists of seven cervical, twelve thoracic, and five lumbar vertebrae. However, enumeration anomalies may result in individuals having eleven or thirteen thoracic vertebrae and four or six lumbar vertebrae. Although the identification of enumeration anomalies has potential clinical implications for chronic back pain and operation planning, the thoracolumbar junction is often poorly assessed and rarely described in clinical reports. Additionally, even though multiple deep-learning-based vertebra labeling algorithms exist, there is a lack of methods to automatically label enumeration anomalies. Our work closes that gap by introducing "Vertebra Identification with Anomaly Handling" (VERIDAH), a novel vertebra labeling algorithm based on multiple classification heads combined with a weighted vertebra sequence prediction algorithm. We show that our approach surpasses existing models on T2w TSE sagittal (98.30% vs. 94.24% of subjects with all vertebrae correctly labeled, p < 0.001) and CT imaging (99.18% vs. 77.26% of subjects with all vertebrae correctly labeled, p < 0.001) and works in arbitrary field-of-view images. VERIDAH correctly labeled the presence 2 Möller et al. of thoracic enumeration anomalies in 87.80% and 96.30% of T2w and CT images, respectively, and lumbar enumeration anomalies in 94.48% and 97.22% for T2w and CT, respectively. Our code and models are available at: https://github.com/Hendrik-code/spineps.

</details>


### [252] [VENI: Variational Encoder for Natural Illumination](https://arxiv.org/abs/2601.14079)
*Paul Walker,James A. D. Gardner,Andreea Ardelean,William A. P. Smith,Bernhard Egger*

Main category: cs.CV

TL;DR: 提出一种旋转等变变分自编码器，用于球面自然光照建模，避免2D投影，保持SO(2)等变性，提供更平滑的潜在空间插值。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么忽略了光照环境的球面和旋转等变特性，要么没有提供良好的潜在空间。逆渲染是一个不适定问题，但光照先验可以简化它。

Method: 使用新型向量神经元视觉变换器(VN-ViT)作为编码器，旋转等变条件神经场作为解码器。在编码器中，通过新型SO(2)等变全连接层将等变性从SO(3)降至SO(2)。

Result: SO(2)等变全连接层在SO(2)等变模型中优于标准向量神经元。相比先前方法，变分自编码器实现更平滑的潜在空间插值，提供更良好的潜在空间。

Conclusion: 提出的旋转等变变分自编码器能够有效建模球面自然光照，保持SO(2)等变性，提供优于现有方法的潜在空间特性。

Abstract: Inverse rendering is an ill-posed problem, but priors like illumination priors, can simplify it. Existing work either disregards the spherical and rotation-equivariant nature of illumination environments or does not provide a well-behaved latent space. We propose a rotation-equivariant variational autoencoder that models natural illumination on the sphere without relying on 2D projections. To preserve the SO(2)-equivariance of environment maps, we use a novel Vector Neuron Vision Transformer (VN-ViT) as encoder and a rotation-equivariant conditional neural field as decoder. In the encoder, we reduce the equivariance from SO(3) to SO(2) using a novel SO(2)-equivariant fully connected layer, an extension of Vector Neurons. We show that our SO(2)-equivariant fully connected layer outperforms standard Vector Neurons when used in our SO(2)-equivariant model. Compared to previous methods, our variational autoencoder enables smoother interpolation in latent space and offers a more well-behaved latent space.

</details>


### [253] [Curriculum-Based Strategies for Efficient Cross-Domain Action Recognition](https://arxiv.org/abs/2601.14101)
*Emily Kim,Allen Wu,Jessica Hodgins*

Main category: cs.CV

TL;DR: 研究探讨了如何通过课程学习策略提升跨视角动作识别的泛化能力，使用合成航拍数据和真实地面数据作为训练源，在保持性能的同时显著提升训练效率。


<details>
  <summary>Details</summary>
Motivation: 现有动作识别模型通常在单一视角（地面视角）数据上训练，难以泛化到其他视角（如航拍视角）。真实航拍数据稀缺，需要探索如何利用现有数据源（合成航拍数据和真实地面数据）来提升跨视角泛化能力。

Method: 提出两种课程学习策略：1）两阶段直接微调方法：先在合成航拍数据上训练，然后在真实地面数据上微调；2）多阶段渐进方法：通过多个阶段逐步扩展数据集后再微调。使用SlowFast（CNN）和MViTv2（Transformer）架构在REMAG数据集上评估。

Result: 结合两个域外数据源明显优于单一域训练。两种课程策略在保持top-1准确率（差异在3%以内）的同时显著提升训练效率：两阶段方法使SlowFast减少37%迭代次数，MViTv2减少30%；多阶段方法进一步减少迭代次数（SlowFast减少9%，MViTv2减少30%）。

Conclusion: 课程学习策略能够在跨视角动作识别中保持可比性能的同时显著提升训练效率，为解决视角泛化问题提供了有效途径，特别是在真实航拍数据稀缺的情况下。

Abstract: Despite significant progress in human action recognition, generalizing to diverse viewpoints remains a challenge. Most existing datasets are captured from ground-level perspectives, and models trained on them often struggle to transfer to drastically different domains such as aerial views. This paper examines how curriculum-based training strategies can improve generalization to unseen real aerial-view data without using any real aerial data during training.
  We explore curriculum learning for cross-view action recognition using two out-of-domain sources: synthetic aerial-view data and real ground-view data. Our results on the evaluation on order of training (fine-tuning on synthetic aerial data vs. real ground data) shows that fine-tuning on real ground data but differ in how they transition from synthetic to real. The first uses a two-stage curriculum with direct fine-tuning, while the second applies a progressive curriculum that expands the dataset in multiple stages before fine-tuning. We evaluate both methods on the REMAG dataset using SlowFast (CNN-based) and MViTv2 (Transformer-based) architectures.
  Results show that combining the two out-of-domain datasets clearly outperforms training on a single domain, whether real ground-view or synthetic aerial-view. Both curriculum strategies match the top-1 accuracy of simple dataset combination while offering efficiency gains. With the two-step fine-tuning method, SlowFast achieves up to a 37% reduction in iterations and MViTv2 up to a 30% reduction compared to simple combination. The multi-step progressive approach further reduces iterations, by up to 9% for SlowFast and 30% for MViTv2, relative to the two-step method. These findings demonstrate that curriculum-based training can maintain comparable performance (top-1 accuracy within 3% range) while improving training efficiency in cross-view action recognition.

</details>


### [254] [Interp3D: Correspondence-aware Interpolation for Generative Textured 3D Morphing](https://arxiv.org/abs/2601.14103)
*Xiaolu Liu,Yicong Li,Qiyuan He,Jiayin Zhu,Wei Ji,Angela Yao,Jianke Zhu*

Main category: cs.CV

TL;DR: Interp3D：一种无需训练、基于生成先验的纹理3D变形框架，通过渐进对齐实现几何保真和纹理连贯的平滑过渡


<details>
  <summary>Details</summary>
Motivation: 现有方法要么仅处理几何形状忽略纹理，要么将2D插值策略扩展到3D导致语义模糊、结构错位和纹理模糊，需要同时保持几何一致性、纹理对齐和鲁棒性的联合解决方案

Method: 采用无需训练框架，利用生成先验和渐进对齐原则：1）条件空间语义对齐插值；2）SLAT引导的结构插值确保结构一致性；3）细粒度纹理融合传递外观细节

Result: 构建专用数据集Interp3DData进行评估，定量指标和人工研究均显示在保真度、过渡平滑性和合理性方面显著优于先前方法

Conclusion: Interp3D通过联合保持几何一致性和纹理对齐，实现了高质量纹理3D变形，在动画、编辑和数字内容创作中具有实用价值

Abstract: Textured 3D morphing seeks to generate smooth and plausible transitions between two 3D assets, preserving both structural coherence and fine-grained appearance. This ability is crucial not only for advancing 3D generation research but also for practical applications in animation, editing, and digital content creation. Existing approaches either operate directly on geometry, limiting them to shape-only morphing while neglecting textures, or extend 2D interpolation strategies into 3D, which often causes semantic ambiguity, structural misalignment, and texture blurring. These challenges underscore the necessity to jointly preserve geometric consistency, texture alignment, and robustness throughout the transition process. To address this, we propose Interp3D, a novel training-free framework for textured 3D morphing. It harnesses generative priors and adopts a progressive alignment principle to ensure both geometric fidelity and texture coherence. Starting from semantically aligned interpolation in condition space, Interp3D enforces structural consistency via SLAT (Structured Latent)-guided structure interpolation, and finally transfers appearance details through fine-grained texture fusion. For comprehensive evaluations, we construct a dedicated dataset, Interp3DData, with graded difficulty levels and assess generation results from fidelity, transition smoothness, and plausibility. Both quantitative metrics and human studies demonstrate the significant advantages of our proposed approach over previous methods. Source code is available at https://github.com/xiaolul2/Interp3D.

</details>


### [255] [PMCE: Probabilistic Multi-Granularity Semantics with Caption-Guided Enhancement for Few-Shot Learning](https://arxiv.org/abs/2601.14111)
*Jiaying Wu,Can Gao,Jinglu Hu,Hui Li,Xiaofeng Cao,Jingcai Guo*

Main category: cs.CV

TL;DR: PMCE：一个概率少样本学习框架，通过多粒度语义和字幕引导增强来改进原型估计，在四个基准测试中显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 少样本学习中，从稀缺数据估计的原型通常存在偏差且泛化能力差。现有的语义方法主要应用于支持集侧，而查询表示保持不变，限制了性能提升。

Method: 构建非参数知识库存储基类视觉统计和CLIP编码的类名嵌入；在元测试时检索最相关的基类，将统计信息聚合为类别先验并通过MAP更新与支持集原型融合；同时使用冻结的BLIP字幕器生成无标签实例级图像描述，通过轻量级增强器在基类上训练，在归纳协议下优化支持原型和查询特征，并采用一致性正则化稳定噪声字幕。

Result: 在四个基准测试中一致优于强基线，在MiniImageNet的1-shot设置中比最强的语义竞争对手获得高达7.71%的绝对增益。

Conclusion: PMCE通过整合多粒度语义信息和字幕引导增强，有效缓解了少样本学习中原型估计偏差问题，显著提升了少样本分类性能。

Abstract: Few-shot learning aims to identify novel categories from only a handful of labeled samples, where prototypes estimated from scarce data are often biased and generalize poorly. Semantic-based methods alleviate this by introducing coarse class-level information, but they are mostly applied on the support side, leaving query representations unchanged. In this paper, we present PMCE, a Probabilistic few-shot framework that leverages Multi-granularity semantics with Caption-guided Enhancement. PMCE constructs a nonparametric knowledge bank that stores visual statistics for each category as well as CLIP-encoded class name embeddings of the base classes. At meta-test time, the most relevant base classes are retrieved based on the similarities of class name embeddings for each novel category. These statistics are then aggregated into category-specific prior information and fused with the support set prototypes via a simple MAP update. Simultaneously, a frozen BLIP captioner provides label-free instance-level image descriptions, and a lightweight enhancer trained on base classes optimizes both support prototypes and query features under an inductive protocol with a consistency regularization to stabilize noisy captions. Experiments on four benchmarks show that PMCE consistently improves over strong baselines, achieving up to 7.71% absolute gain over the strongest semantic competitor on MiniImageNet in the 1-shot setting. Our code is available at https://anonymous.4open.science/r/PMCE-275D

</details>


### [256] [GIC-DLC: Differentiable Logic Circuits for Hardware-Friendly Grayscale Image Compression](https://arxiv.org/abs/2601.14130)
*Till Aczel,David F. Jenny,Simon Bührer,Andreas Plesner,Antonio Di Maio,Roger Wattenhofer*

Main category: cs.CV

TL;DR: GIC-DLC是一种面向硬件的灰度图像编解码器，通过训练查找表将神经网络的灵活性与布尔运算的效率相结合，在保持高压缩率的同时大幅降低能耗和延迟。


<details>
  <summary>Details</summary>
Motivation: 神经图像编解码器虽然比传统方法（如PNG或JPEG-XL）有更高的压缩比，但计算开销大，限制了在智能手机、相机、无人机等能源受限设备上的部署。需要开发硬件友好的学习型压缩方法。

Method: 提出GIC-DLC（Grayscale Image Compression with Differentiable Logic Circuits），这是一种硬件感知的编解码器，通过训练查找表将神经网络的灵活性与布尔运算的效率相结合。

Result: 在灰度基准数据集上的实验表明，GIC-DLC在压缩效率上优于传统编解码器，同时能够显著降低能耗和延迟。

Conclusion: 学习型压缩可以是硬件友好的，这为边缘设备上的低功耗图像压缩提供了一个有前景的方向。

Abstract: Neural image codecs achieve higher compression ratios than traditional hand-crafted methods such as PNG or JPEG-XL, but often incur substantial computational overhead, limiting their deployment on energy-constrained devices such as smartphones, cameras, and drones. We propose Grayscale Image Compression with Differentiable Logic Circuits (GIC-DLC), a hardware-aware codec where we train lookup tables to combine the flexibility of neural networks with the efficiency of Boolean operations. Experiments on grayscale benchmark datasets show that GIC-DLC outperforms traditional codecs in compression efficiency while allowing substantial reductions in energy consumption and latency. These results demonstrate that learned compression can be hardware-friendly, offering a promising direction for low-power image compression on edge devices.

</details>


### [257] [One-Shot Refiner: Boosting Feed-forward Novel View Synthesis via One-Step Diffusion](https://arxiv.org/abs/2601.14161)
*Yitong Dong,Qi Zhang,Minchao Jiang,Zhiqiang Wu,Qingnan Fan,Ying Feng,Huaqi Zhang,Hujun Bao,Guofeng Zhang*

Main category: cs.CV

TL;DR: 提出新框架用于稀疏图像的高保真新视角合成，解决现有ViT+3DGS方法分辨率受限和生成增强方法3D不一致的问题


<details>
  <summary>Details</summary>
Motivation: 现有基于ViT的3D高斯泼溅方法因计算成本只能处理低分辨率输入，而现有生成增强方法缺乏3D感知导致视角间结构不一致，特别是在未观测区域

Method: 设计双域细节感知模块处理高分辨率图像，为高斯添加高频细节特征；开发特征引导扩散网络保持细节恢复；提出统一训练策略联合优化ViT几何骨干和扩散细化模块

Result: 实验表明该方法在多个数据集上保持优越的生成质量

Conclusion: 提出的框架成功解决了稀疏图像新视角合成中分辨率和3D一致性的关键限制，实现了高质量的多视角生成

Abstract: We present a novel framework for high-fidelity novel view synthesis (NVS) from sparse images, addressing key limitations in recent feed-forward 3D Gaussian Splatting (3DGS) methods built on Vision Transformer (ViT) backbones. While ViT-based pipelines offer strong geometric priors, they are often constrained by low-resolution inputs due to computational costs. Moreover, existing generative enhancement methods tend to be 3D-agnostic, resulting in inconsistent structures across views, especially in unseen regions. To overcome these challenges, we design a Dual-Domain Detail Perception Module, which enables handling high-resolution images without being limited by the ViT backbone, and endows Gaussians with additional features to store high-frequency details. We develop a feature-guided diffusion network, which can preserve high-frequency details during the restoration process. We introduce a unified training strategy that enables joint optimization of the ViT-based geometric backbone and the diffusion-based refinement module. Experiments demonstrate that our method can maintain superior generation quality across multiple datasets.

</details>


### [258] [ASBA: A-line State Space Model and B-line Attention for Sparse Optical Doppler Tomography Reconstruction](https://arxiv.org/abs/2601.14165)
*Zhenghong Li,Wensheng Cheng,Congwu Du,Yingtian Pan,Zhaozheng Yin,Haibin Ling*

Main category: cs.CV

TL;DR: 提出ASBA网络，通过A线ROI状态空间模型和B线相位注意力机制，从高度稀疏采样的原始A扫描重建ODT图像，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前光学多普勒断层扫描（ODT）需要密集采样以获得高质量B扫描图像，但这导致扫描时间长、存储需求大，且难以捕捉快速血流动态。现有稀疏采样方法受限于保守采样率和均匀建模血流与背景信号。

Method: 提出ASBA网络：1）A线ROI状态空间模型提取A线上稀疏分布的血流特征；2）B线相位注意力机制基于相位差捕捉每个B线上的长程血流信号；3）血流感知加权损失函数优先准确重建血流信号。

Result: 在真实动物数据上的大量实验表明，该方法明显优于现有最先进的重建方法。

Conclusion: ASBA网络能够从高度稀疏采样的原始A扫描有效重建ODT图像，解决了当前ODT技术中扫描时间长、存储需求大和动态捕捉能力有限的问题。

Abstract: Optical Doppler Tomography (ODT) is an emerging blood flow analysis technique. A 2D ODT image (B-scan) is generated by sequentially acquiring 1D depth-resolved raw A-scans (A-line) along the lateral axis (B-line), followed by Doppler phase-subtraction analysis. To ensure high-fidelity B-scan images, current practices rely on dense sampling, which prolongs scanning time, increases storage demands, and limits the capture of rapid blood flow dynamics. Recent studies have explored sparse sampling of raw A-scans to alleviate these limitations, but their effectiveness is hindered by the conservative sampling rates and the uniform modeling of flow and background signals. In this study, we introduce a novel blood flow-aware network, named ASBA (A-line ROI State space model and B-line phase Attention), to reconstruct ODT images from highly sparsely sampled raw A-scans. Specifically, we propose an A-line ROI state space model to extract sparsely distributed flow features along the A-line, and a B-line phase attention to capture long-range flow signals along each B-line based on phase difference. Moreover, we introduce a flow-aware weighted loss function that encourages the network to prioritize the accurate reconstruction of flow signals. Extensive experiments on real animal data demonstrate that the proposed approach clearly outperforms existing state-of-the-art reconstruction methods.

</details>


### [259] [Progressive self-supervised blind-spot denoising method for LDCT denoising](https://arxiv.org/abs/2601.14180)
*Yichao Liu,Yueyang Teng,Junwen Guo*

Main category: cs.CV

TL;DR: 提出一种仅使用低剂量CT图像的自监督训练策略，通过渐进式盲点去噪机制和高斯噪声正则化，在低剂量CT去噪任务中达到或超越有监督方法的性能。


<details>
  <summary>Details</summary>
Motivation: 临床实践中难以获取配对的正常剂量CT数据，因此需要开发不依赖配对数据的自监督学习方法来解决低剂量CT图像去噪问题。

Method: 提出仅使用低剂量CT图像的自监督训练策略，包括渐进式盲点去噪机制（逐步增强条件独立性）和添加高斯噪声作为正则化以防止过拟合。

Result: 在Mayo低剂量CT数据集上的实验表明，该方法持续优于现有自监督方法，性能与多个代表性有监督去噪方法相当甚至更好。

Conclusion: 提出的自监督方法有效解决了低剂量CT去噪问题，无需配对正常剂量CT数据，在临床实践中具有重要应用价值。

Abstract: Self-supervised learning is increasingly investigated for low-dose computed tomography (LDCT) image denoising, as it alleviates the dependence on paired normal-dose CT (NDCT) data, which are often difficult to acquire in clinical practice. In this paper, we propose a novel self-supervised training strategy that relies exclusively on LDCT images. We introduce a step-wise blind-spot denoising mechanism that enforces conditional independence in a progressive manner, enabling more fine-grained denoising learning. In addition, we add Gaussian noise to LDCT images, which acts as a regularization and mitigates overfitting. Extensive experiments on the Mayo LDCT dataset demonstrate that the proposed method consistently outperforms existing self-supervised approaches and achieves performance comparable to, or better than, several representative supervised denoising methods.

</details>


### [260] [IIR-VLM: In-Context Instance-level Recognition for Large Vision-Language Models](https://arxiv.org/abs/2601.14188)
*Liang Shi,Wei Li,Kevin M Beussman,Lin Chen,Yun Fu*

Main category: cs.CV

TL;DR: 提出IIR-VLM，通过整合预训练的实例级识别专家模型作为辅助视觉编码器，增强VLM的实例级识别能力，实现单样本上下文学习


<details>
  <summary>Details</summary>
Motivation: 现有VLM在实例级识别任务上表现不佳，远低于领域专用模型，这限制了VLM在实际应用中的效果，特别是在需要识别熟悉人物和物体的场景中

Method: 整合预训练的ILR专家模型作为辅助视觉编码器，提供专门的特征来学习多样实例，使VLM能够以单样本上下文学习的方式学习新实例，并实现实例感知的视觉理解

Result: 在现有实例个性化基准测试中验证了IIR-VLM的有效性，并在包含人物、面部、宠物和一般物体的新挑战性基准测试中展示了优越的ILR性能

Conclusion: IIR-VLM通过整合ILR专家模型成功增强了VLM的实例级识别能力，实现了单样本上下文学习，为VLM在实际应用中提供了更好的实例感知能力

Abstract: Instance-level recognition (ILR) concerns distinguishing individual instances from one another, with person re-identification as a prominent example. Despite the impressive visual perception capabilities of modern VLMs, we find their performance on ILR unsatisfactory, often dramatically underperforming domain-specific ILR models. This limitation hinders many practical application of VLMs, e.g. where recognizing familiar people and objects is crucial for effective visual understanding. Existing solutions typically learn to recognize instances one at a time using instance-specific datasets, which not only incur substantial data collection and training costs but also struggle with fine-grained discrimination. In this work, we propose IIR-VLM, a VLM enhanced for In-context Instance-level Recognition. We integrate pre-trained ILR expert models as auxiliary visual encoders to provide specialized features for learning diverse instances, which enables VLMs to learn new instances in-context in a one-shot manner. Further, IIR-VLM leverages this knowledge for instance-aware visual understanding. We validate IIR-VLM's efficacy on existing instance personalization benchmarks. Finally, we demonstrate its superior ILR performance on a challenging new benchmark, which assesses ILR capabilities across varying difficulty and diverse categories, with person, face, pet and general objects as the instances at task.

</details>


### [261] [Rig-Aware 3D Reconstruction of Vehicle Undercarriages using Gaussian Splatting](https://arxiv.org/abs/2601.14208)
*Nitin Kulkarni,Akhil Devarashetti,Charlie Cluss,Livio Forte,Dan Buckmaster,Philip Schneider,Chunming Qiao,Alina Vereshchaka*

Main category: cs.CV

TL;DR: 提出一个端到端管道，使用三摄像头装置捕捉车辆底盘视频，生成交互式3D模型，解决传统底盘检查劳动强度大、在线买家难以查看的问题。


<details>
  <summary>Details</summary>
Motivation: 传统车辆底盘检查需要检查员蹲下或爬行到车底，劳动强度大且存在安全隐患；在线买家很少能看到底盘照片，影响购买信心。

Method: 使用三摄像头装置捕捉底盘视频，提出针对广角镜头畸变和低视差场景的"装置感知"结构光运动(SfM)管道，结合精确相机标定、同步视频流和几何先验，采用DISK特征提取器和LightGlue匹配器生成高质量稀疏点云，最后通过高斯泼溅生成实时渲染的逼真3D模型。

Result: 能够生成交互式3D底盘模型，支持旋转、缩放和切片操作，可在几秒内检测锈蚀、泄漏或碰撞损伤，提高了工作场所安全和买家信心，实验证明该方法达到最先进质量。

Conclusion: 提出的端到端管道成功解决了车辆底盘检查的挑战，通过创新的装置感知SfM方法克服了广角畸变和低视差问题，生成的交互式3D模型显著改善了检查效率和在线购买体验。

Abstract: Inspecting the undercarriage of used vehicles is a labor-intensive task that requires inspectors to crouch or crawl underneath each vehicle to thoroughly examine it. Additionally, online buyers rarely see undercarriage photos. We present an end-to-end pipeline that utilizes a three-camera rig to capture videos of the undercarriage as the vehicle drives over it, and produces an interactive 3D model of the undercarriage. The 3D model enables inspectors and customers to rotate, zoom, and slice through the undercarriage, allowing them to detect rust, leaks, or impact damage in seconds, thereby improving both workplace safety and buyer confidence. Our primary contribution is a rig-aware Structure-from-Motion (SfM) pipeline specifically designed to overcome the challenges of wide-angle lens distortion and low-parallax scenes. Our method overcomes the challenges of wide-angle lens distortion and low-parallax scenes by integrating precise camera calibration, synchronized video streams, and strong geometric priors from the camera rig. We use a constrained matching strategy with learned components, the DISK feature extractor, and the attention-based LightGlue matcher to generate high-quality sparse point clouds that are often unattainable with standard SfM pipelines. These point clouds seed the Gaussian splatting process to generate photorealistic undercarriage models that render in real-time. Our experiments and ablation studies demonstrate that our design choices are essential to achieve state-of-the-art quality.

</details>


### [262] [Soft Tail-dropping for Adaptive Visual Tokenization](https://arxiv.org/abs/2601.14246)
*Zeyuan Chen,Kai Zhang,Zhuowen Tu,Yuanjun Xiong*

Main category: cs.CV

TL;DR: STAT是一种自适应视觉分词器，根据图像复杂度动态选择输出token数量，生成长度自适应的1D离散视觉token，与因果自回归视觉生成模型兼容。


<details>
  <summary>Details</summary>
Motivation: 传统视觉分词器通常输出固定长度的token序列，无法根据图像内容复杂度自适应调整，限制了因果自回归视觉生成模型的效率和性能。

Method: STAT将图像编码为离散代码序列和每个token的保留概率，通过正则化使保留概率沿序列单调递减，并与图像级复杂度度量对齐，实现自适应token选择。

Result: 在ImageNet-1k上，结合STAT的因果自回归模型在视觉生成质量上优于其他概率模型家族，并展现出良好的扩展性，解决了先前AR视觉生成的扩展难题。

Conclusion: STAT提供了一种有效的长度自适应视觉分词方法，使因果自回归视觉生成模型能够根据图像复杂度动态调整表示，实现了更好的生成质量和扩展性。

Abstract: We present Soft Tail-dropping Adaptive Tokenizer (STAT), a 1D discrete visual tokenizer that adaptively chooses the number of output tokens per image according to its structural complexity and level of detail. STAT encodes an image into a sequence of discrete codes together with per-token keep probabilities. Beyond standard autoencoder objectives, we regularize these keep probabilities to be monotonically decreasing along the sequence and explicitly align their distribution with an image-level complexity measure. As a result, STAT produces length-adaptive 1D visual tokens that are naturally compatible with causal 1D autoregressive (AR) visual generative models. On ImageNet-1k, equipping vanilla causal AR models with STAT yields competitive or superior visual generation quality compared to other probabilistic model families, while also exhibiting favorable scaling behavior that has been elusive in prior vanilla AR visual generation attempts.

</details>


### [263] [OmniTransfer: All-in-one Framework for Spatio-temporal Video Transfer](https://arxiv.org/abs/2601.14250)
*Pengze Zhang,Yanze Wu,Mengtian Li,Xu Bai,Songtao Zhao,Fulong Ye,Chong Mou,Xinghui Li,Zhuowei Chen,Qian He,Mingyuan Gao*

Main category: cs.CV

TL;DR: OmniTransfer是一个统一的时空视频迁移框架，通过多视角信息和时序线索实现外观一致性和精细时序控制，在各种视频迁移任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有视频定制方法大多依赖参考图像或特定任务的时序先验，未能充分利用视频固有的丰富时空信息，限制了视频生成的灵活性和泛化能力。

Method: 提出OmniTransfer框架，包含三个关键设计：任务感知位置偏置（自适应利用参考视频信息）、参考解耦因果学习（分离参考和目标分支）、任务自适应多模态对齐（使用多模态语义指导动态区分不同任务）。

Result: 在大量实验中，OmniTransfer在外观（ID和风格）和时序迁移（相机运动和视频效果）方面优于现有方法，同时在运动迁移中与使用姿态指导的方法表现相当，且无需使用姿态信息。

Conclusion: OmniTransfer建立了一个灵活、高保真视频生成的新范式，通过统一框架有效解决了多种视频迁移任务，充分利用了视频的时空信息。

Abstract: Videos convey richer information than images or text, capturing both spatial and temporal dynamics. However, most existing video customization methods rely on reference images or task-specific temporal priors, failing to fully exploit the rich spatio-temporal information inherent in videos, thereby limiting flexibility and generalization in video generation. To address these limitations, we propose OmniTransfer, a unified framework for spatio-temporal video transfer. It leverages multi-view information across frames to enhance appearance consistency and exploits temporal cues to enable fine-grained temporal control. To unify various video transfer tasks, OmniTransfer incorporates three key designs: Task-aware Positional Bias that adaptively leverages reference video information to improve temporal alignment or appearance consistency; Reference-decoupled Causal Learning separating reference and target branches to enable precise reference transfer while improving efficiency; and Task-adaptive Multimodal Alignment using multimodal semantic guidance to dynamically distinguish and tackle different tasks. Extensive experiments show that OmniTransfer outperforms existing methods in appearance (ID and style) and temporal transfer (camera movement and video effects), while matching pose-guided methods in motion transfer without using pose, establishing a new paradigm for flexible, high-fidelity video generation.

</details>


### [264] [LightOnOCR: A 1B End-to-End Multilingual Vision-Language Model for State-of-the-Art OCR](https://arxiv.org/abs/2601.14251)
*Said Taghadouini,Adrien Cavaillès,Baptiste Aubertin*

Main category: cs.CV

TL;DR: LightOnOCR-2-1B是一个10亿参数的端到端多语言视觉-语言模型，可将文档图像直接转换为干净、自然排序的文本，无需传统OCR流程，在保持高性能的同时比现有最佳模型小9倍且更快。


<details>
  <summary>Details</summary>
Motivation: 传统OCR流程脆弱且复杂，需要将文档图像转换为文本时依赖多个处理步骤。作者希望开发一个端到端的解决方案，能够直接从文档图像生成干净、自然排序的文本，同时支持多语言文档处理。

Method: 1. 使用大规模高质量蒸馏混合数据进行训练，覆盖扫描件、法语文档和科学PDF；2. 扩展输出格式以预测嵌入式图像的归一化边界框；3. 通过恢复策略在预训练中引入定位能力；4. 使用基于IoU奖励的RLVR进行细化；5. 通过检查点平均和任务算术合并提高鲁棒性。

Result: 在OlmOCR-Bench上达到最先进结果，同时比先前最佳性能模型小9倍且速度显著更快。模型能够预测嵌入式图像的边界框，提高了文档处理的完整性。

Conclusion: LightOnOCR-2-1B展示了端到端文档理解模型的可行性，在保持高性能的同时大幅减小模型规模。作者开源了模型检查点、数据集和评估基准，为文档OCR研究提供了有价值的资源。

Abstract: We present \textbf{LightOnOCR-2-1B}, a 1B-parameter end-to-end multilingual vision--language model that converts document images (e.g., PDFs) into clean, naturally ordered text without brittle OCR pipelines. Trained on a large-scale, high-quality distillation mix with strong coverage of scans, French documents, and scientific PDFs, LightOnOCR-2 achieves state-of-the-art results on OlmOCR-Bench while being 9$\times$ smaller and substantially faster than prior best-performing models. We further extend the output format to predict normalized bounding boxes for embedded images, introducing localization during pretraining via a resume strategy and refining it with RLVR using IoU-based rewards. Finally, we improve robustness with checkpoint averaging and task-arithmetic merging. We release model checkpoints under Apache 2.0, and publicly release the dataset and \textbf{LightOnOCR-bbox-bench} evaluation under their respective licenses.

</details>


### [265] [Motion 3-to-4: 3D Motion Reconstruction for 4D Synthesis](https://arxiv.org/abs/2601.14253)
*Hongyuan Chen,Xingyu Chen,Youjia Zhang,Zexiang Xu,Anpei Chen*

Main category: cs.CV

TL;DR: Motion 3-to-4：从单目视频和可选3D参考网格合成高质量4D动态物体的前馈框架


<details>
  <summary>Details</summary>
Motivation: 当前2D、视频和3D内容生成已有显著进展，但4D合成仍面临挑战，主要原因是训练数据有限以及从单目视角恢复几何和运动存在固有模糊性

Method: 将4D合成分解为静态3D形状生成和运动重建两部分。使用规范参考网格学习紧凑的运动潜在表示，预测逐帧顶点轨迹以恢复完整的时间一致几何。采用可扩展的逐帧transformer增强对不同序列长度的鲁棒性

Result: 在标准基准测试和具有精确地面真实几何的新数据集上评估，Motion 3-to-4在保真度和空间一致性方面优于先前工作

Conclusion: Motion 3-to-4通过分解4D合成任务，有效解决了数据有限和单目视角模糊性问题，实现了高质量的4D动态物体合成

Abstract: We present Motion 3-to-4, a feed-forward framework for synthesising high-quality 4D dynamic objects from a single monocular video and an optional 3D reference mesh. While recent advances have significantly improved 2D, video, and 3D content generation, 4D synthesis remains difficult due to limited training data and the inherent ambiguity of recovering geometry and motion from a monocular viewpoint. Motion 3-to-4 addresses these challenges by decomposing 4D synthesis into static 3D shape generation and motion reconstruction. Using a canonical reference mesh, our model learns a compact motion latent representation and predicts per-frame vertex trajectories to recover complete, temporally coherent geometry. A scalable frame-wise transformer further enables robustness to varying sequence lengths. Evaluations on both standard benchmarks and a new dataset with accurate ground-truth geometry show that Motion 3-to-4 delivers superior fidelity and spatial consistency compared to prior work. Project page is available at https://motion3-to-4.github.io/.

</details>


### [266] [Implicit Neural Representation Facilitates Unified Universal Vision Encoding](https://arxiv.org/abs/2601.14256)
*Matthew Gwilliam,Xiao Wang,Xuefeng Hu,Zhenheng Yang*

Main category: cs.CV

TL;DR: 该论文提出了一种统一图像识别与生成任务的首创模型，通过超网络学习隐式神经表示，结合知识蒸馏，在压缩嵌入空间中同时实现优秀的识别性能和生成能力。


<details>
  <summary>Details</summary>
Motivation: 当前图像表示学习模型通常分别针对识别任务（如对比学习）或生成任务（如重建损失），缺乏能同时支持两种任务的统一模型。本文旨在填补这一空白，开发既能用于识别又能用于生成的图像表示模型。

Method: 1. 将模型设计为隐式神经表示（INR）的超网络，学习将图像映射到模型权重以实现快速准确的重建
2. 将INR超网络与知识蒸馏相结合，提升模型的泛化能力和性能
3. 学习一个高度压缩的嵌入空间，支持多种视觉任务

Result: 1. 模型在图像表示学习方面与最先进方法竞争
2. 通过学习高质量的小型嵌入空间，实现了生成能力
3. 在压缩嵌入空间中表现出色，支持多种视觉任务

Conclusion: 该研究成功开发了首个能同时支持图像识别和生成的统一模型，通过学习隐式神经表示的压缩嵌入空间，在保持识别性能的同时实现了生成能力，为图像表示学习提供了新的方向。

Abstract: Models for image representation learning are typically designed for either recognition or generation. Various forms of contrastive learning help models learn to convert images to embeddings that are useful for classification, detection, and segmentation. On the other hand, models can be trained to reconstruct images with pixel-wise, perceptual, and adversarial losses in order to learn a latent space that is useful for image generation. We seek to unify these two directions with a first-of-its-kind model that learns representations which are simultaneously useful for recognition and generation. We train our model as a hyper-network for implicit neural representation, which learns to map images to model weights for fast, accurate reconstruction. We further integrate our INR hyper-network with knowledge distillation to improve its generalization and performance. Beyond the novel training design, the model also learns an unprecedented compressed embedding space with outstanding performance for various visual tasks. The complete model competes with state-of-the-art results for image representation learning, while also enabling generative capabilities with its high-quality tiny embeddings. The code is available at https://github.com/tiktok/huvr.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [267] [Context Discipline and Performance Correlation: Analyzing LLM Performance and Quality Degradation Under Varying Context Lengths](https://arxiv.org/abs/2601.11564)
*Ahilan Ayyachamy Nadar Ponnusamy,Karthic Chandran,M Maruf Hossain*

Main category: cs.CL

TL;DR: LLM扩展上下文窗口导致计算开销增加，研究发现密集Transformer架构在面临大量无关上下文时性能非线性下降，MoE架构在不同上下文规模下表现出异常行为。


<details>
  <summary>Details</summary>
Motivation: 随着LLM上下文窗口不断扩大以支持复杂长文本推理，管理扩展上下文带来了严重的计算开销问题。需要研究系统性能与模型质量之间的权衡，特别是在面对大量无关和干扰性上下文时的表现。

Method: 使用密集Transformer架构（Llama-3.1-70B和Qwen1.5-14B）进行实验，分析在大量无关上下文下的性能表现。特别关注KV缓存的增长影响，并对MoE架构在不同上下文规模下的行为进行扩展分析。

Result: 研究发现性能退化与KV缓存增长呈非线性关系。MoE架构在不同上下文规模下表现出独特的行为异常，表明在高token量时，架构优势可能被基础设施瓶颈所掩盖。

Conclusion: LLM扩展上下文窗口需要平衡计算开销与模型质量。KV缓存管理是关键瓶颈，MoE架构的优势在高token量时可能无法充分发挥。需要优化基础设施以支持大规模上下文处理。

Abstract: The scaling trend in Large Language Models (LLMs) has prioritized increasing the maximum context window to facilitate complex, long-form reasoning and document analysis. However, managing this expanded context introduces severe computational overhead. This paper investigates the critical trade-off between system performance and model quality when dense transformer architectures--specifically Llama-3.1-70B and Qwen1.5-14B--are exposed to large volumes of irrelevant and distracting context. The research identifies a non-linear performance degradation tied to the growth of the Key-Value (KV) cache. Furthermore, an extended analysis of the Mixture-of-Experts (MoE) architecture reveals unique behavioral anomalies at varying context scales, suggesting that architectural benefits may be masked by infrastructure bottlenecks at high token volumes.

</details>


### [268] [Compass-Embedding v4: Robust Contrastive Learning for Multilingual E-commerce Embeddings](https://arxiv.org/abs/2601.11565)
*Pakorn Ueareeworakul,Shuman Liu,Jinghao Feng,Ling Hu,Zhantang Shi,Chengqi Sun,Liang Yao,Panyi Ouyang,Haibo Zhang,Anxiang Zeng*

Main category: cs.CL

TL;DR: Compass-Embedding v4是一个针对东南亚电商场景优化的多语言嵌入框架，通过类感知掩码、多样化训练数据构建和高效推理优化，解决了数据稀缺、噪声监督和生产约束等挑战。


<details>
  <summary>Details</summary>
Motivation: 随着全球电商向新兴市场扩张，低资源语言缺乏高质量语义表示成为检索、推荐和搜索系统的瓶颈。东南亚电商场景面临数据稀缺、噪声监督和严格生产约束的联合挑战。

Method: 1. 提出类感知掩码(CAM)修改InfoNCE目标，抑制无效批次内负样本；2. 通过上下文基础合成数据生成、跨语言翻译和结构化电商数据构建多样化训练语料；3. 结合鲁棒性驱动的大批次训练与球面模型合并，并通过vLLM和FP8量化优化推理。

Result: 在多种语言基准测试和专有电商任务中，Compass-Embedding v4在主要东南亚语言上达到最先进性能，在领域特定检索和分类任务中显著优于通用嵌入模型，同时在高资源语言上保持竞争力。

Conclusion: Compass-Embedding v4成功解决了东南亚电商场景中的核心挑战，为低资源语言提供了高质量的语义表示，同时满足生产环境的高吞吐量要求，展示了在特定领域优化嵌入模型的有效性。

Abstract: As global e-commerce rapidly expands into emerging markets, the lack of high-quality semantic representations for low-resource languages has become a decisive bottleneck for retrieval, recommendation, and search systems. In this work, we present Compass-Embedding v4, a high-efficiency multilingual embedding framework specifically optimized for Southeast Asian (SEA) e-commerce scenarios, where data scarcity, noisy supervision, and strict production constraints jointly challenge representation learning. Compass-Embedding v4 addresses three core challenges. First, large-batch contrastive training under mixed task supervision introduces systematic false negatives that degrade semantic alignment. We propose Class-Aware Masking (CAM), a lightweight modification to the InfoNCE objective that suppresses invalid in-batch negatives and improves semantic discrimination without altering training efficiency. Second, low-resource SEA languages suffer from limited and uneven data coverage. We construct a diversified training corpus through context-grounded synthetic data generation, cross-lingual translation, and structured e-commerce data construction, enabling robust multilingual and domain-specific learning. Third, production deployment requires high-throughput inference while preserving embedding quality. We combine robustness-driven large-batch training with spherical model merging to mitigate catastrophic forgetting, and optimize inference via vLLM and FP8 quantization. Extensive evaluations across multilingual benchmarks and proprietary e-commerce tasks show that Compass-Embedding v4 achieves state-of-the-art performance on major SEA languages, significantly outperforming general-purpose embedding models in domain-specific retrieval and classification, while maintaining competitive performance on high-resource languages.

</details>


### [269] [Measuring Stability Beyond Accuracy in Small Open-Source Medical Large Language Models for Pediatric Endocrinology](https://arxiv.org/abs/2601.11567)
*Vanessa D'Amario,Randy Daniel,Alessandro Zanetti,Dhruv Edamadaka,Nitya Alaparthy,Joshua Tarkoff*

Main category: cs.CL

TL;DR: 评估六个小型开源医疗大语言模型在儿科内分泌学中的表现，发现提示微小变化会导致输出显著差异，高一致性不等于正确性，模型存在自我评估偏见，系统级扰动也会影响输出稳定性。


<details>
  <summary>Details</summary>
Motivation: 当前小型开源医疗大语言模型的评估主要局限于医学多选题的准确性，缺乏对一致性、鲁棒性和推理行为的全面评估，需要更全面的诊断框架来理解临床决策支持中的潜在问题。

Method: 使用医学多选题结合人工评估和临床审查，评估六个小型开源医疗LLM。在确定性设置中考察提示变化对输出的影响和自我评估偏见；在随机性设置中评估输出变异性，研究一致性与正确性的关系。

Result: HuatuoGPT-o1-8B表现最佳。高一致性并不代表正确性，尽管HuatuoGPT-o1-8B一致性最高。模型存在自我评估偏见和候选解释顺序依赖。专家审查发现错误推理中混合了临床可接受的回答和临床疏忽。系统级扰动（如CUDA构建差异）会导致统计显著的输出变化。

Conclusion: 微小语义提示扰动会导致输出分歧，引发LLM评估可重复性的担忧。不同随机机制下的输出变异性突出表明，需要更广泛的诊断框架来理解实际临床决策支持场景中的潜在陷阱。

Abstract: Small open-source medical large language models (LLMs) offer promising opportunities for low-resource deployment and broader accessibility. However, their evaluation is often limited to accuracy on medical multiple choice question (MCQ) benchmarks, and lacks evaluation of consistency, robustness, or reasoning behavior. We use MCQ coupled to human evaluation and clinical review to assess six small open-source medical LLMs (HuatuoGPT-o1 (Chen 2024), Diabetica-7B, Diabetica-o1 (Wei 2024), Meditron3-8B (Sallinen2025), MedFound-7B (Liu 2025), and ClinicaGPT-base-zh (Wang 2023)) in pediatric endocrinology. In deterministic settings, we examine the effect of prompt variation on models' output and self-assessment bias. In stochastic settings, we evaluate output variability and investigate the relationship between consistency and correctness. HuatuoGPT-o1-8B achieved the highest performance. The results show that high consistency across the model response is not an indicator of correctness, although HuatuoGPT-o1-8B showed the highest consistency rate. When tasked with selecting correct reasoning, both HuatuoGPT-o1-8B and Diabetica-o1 exhibit self-assessment bias and dependency on the order of the candidate explanations. Expert review of incorrect reasoning rationales identified a mix of clinically acceptable responses and clinical oversight. We further show that system-level perturbations, such as differences in CUDA builds, can yield statistically significant shifts in model output despite stable accuracy. This work demonstrates that small, semantically negligible prompt perturbations lead to divergent outputs, raising concerns about reproducibility of LLM-based evaluations and highlights the output variability under different stochastic regimes, emphasizing the need of a broader diagnostic framework to understand potential pitfalls in real-world clinical decision support scenarios.

</details>


### [270] [An Empirical Analysis of Fine-Tuning Large Language Models on Bioinformatics Literature: PRSGPT and BioStarsGPT](https://arxiv.org/abs/2601.11573)
*Muhammad Muneeb,David B. Ascher*

Main category: cs.CL

TL;DR: 提出一个可复现的九步流程，用于在生物信息学专业数据上微调大语言模型，通过PRSGPT和BioStarsGPT两个用例展示，生成高质量QA数据集并显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型通常缺乏复杂生物信息学应用所需的专业知识，需要开发专门针对生物信息学领域的微调方法，以创建可在本地部署、保护隐私的专业助手。

Method: 九步可复现流程：整合多样化数据源、结构化预处理、基于提示的QA生成（使用Google Gemini）、自然语言推理质量控制、语义去重、基于聚类的数据分割、使用LoRA的参数高效微调。在三个LLM（LLaMA-3.2-3B, Qwen2.5-7B, Gemma）上进行微调。

Result: Qwen2.5-7B表现最佳：PRSGPT的BLEU-4和ROUGE-1分别提升82%和70%，BioStarsGPT分别提升6%和18%。生成超过28,000个PRSGPT QA对和154,282个BioStarsGPT QA对。PRSGPT在PRS工具比较任务上获得61.9%准确率（与Google Gemini的61.4%相当），但提供更丰富的方法细节和准确引用。BioStarsGPT在142个生物信息学问题上达到59%概念准确率。

Conclusion: 该流程实现了可扩展的领域特定LLM微调，支持隐私保护、本地可部署的生物信息学助手，探索了实际应用，并解决了开发和使用中的挑战、限制及缓解策略。

Abstract: Large language models (LLMs) often lack specialized knowledge for complex bioinformatics applications. We present a reproducible pipeline for fine-tuning LLMs on specialized bioinformatics data, demonstrated through two use cases: PRSGPT, focused on polygenic risk score (PRS) tools, and BioStarsGPT, trained on community forum discussions. The nine-step pipeline integrates diverse data sources, structured preprocessing, prompt-based question-answer (QA) generation (via Google Gemini), natural language inference (NLI) for quality control, semantic deduplication, clustering-based data splitting, and parameter-efficient fine-tuning using LoRA. We fine-tuned three LLMs (LLaMA-3.2-3B, Qwen2.5-7B, Gemma) and benchmarked them on over 14 lexical and semantic metrics. Qwen2.5-7B emerged as the best performer, with BLEU-4 and ROUGE-1 improvements of 82\% and 70\% for PRSGPT and 6\% and 18\% for BioStarsGPT, respectively. The open-source datasets produced include over 28,000 QA pairs for PRSGPT and 154,282 for BioStarsGPT. Human evaluation of PRSGPT yielded 61.9\% accuracy on the PRS tools comparison task, comparable to Google Gemini (61.4\%), but with richer methodological detail and accurate citations. BioStarsGPT demonstrated 59\% conceptual accuracy across 142 curated bioinformatics questions. Our pipeline enables scalable, domain-specific fine-tuning of LLMs. It enables privacy-preserving, locally deployable bioinformatics assistants, explores their practical applications, and addresses the challenges, limitations, and mitigation strategies associated with their development and use.

</details>


### [271] [Concept Attractors in LLMs and their Applications](https://arxiv.org/abs/2601.11575)
*Sotirios Panagiotis Chytas,Vikas Singh*

Main category: cs.CL

TL;DR: LLMs内部表示可通过迭代函数系统解释，层作为收缩映射趋向概念吸引子。基于此开发无需训练的方法，直接操作吸引子解决翻译、幻觉减少、护栏、数据生成等任务，性能匹配或超越专用基线。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型往往将语义相关的提示映射到特定层的相似内部表示，即使表面形式差异很大。这种行为的数学原理尚不明确，需要解释并利用这一特性开发更高效的干预方法。

Method: 将LLM层视为迭代函数系统中的收缩映射，趋向概念特定的吸引子。开发无需训练的简单方法，直接操作这些吸引子来干预模型行为，包括语言翻译、减少幻觉、设置护栏和生成合成数据。

Result: 基于吸引子的干预方法在多种实际任务中匹配或超越专用基线，提供比精细调参更高效的替代方案，在基线表现不佳的场景中具有更好的泛化能力。

Conclusion: LLM内部表示的吸引子理论为理解模型行为提供了数学框架，基于吸引子的训练免费干预方法简单有效，为实际应用提供了高效替代方案。

Abstract: Large language models (LLMs) often map semantically related prompts to similar internal representations at specific layers, even when their surface forms differ widely. We show that this behavior can be explained through Iterated Function Systems (IFS), where layers act as contractive mappings toward concept-specific Attractors. We leverage this insight and develop simple, training-free methods that operate directly on these Attractors to solve a wide range of practical tasks, including language translation, hallucination reduction, guardrailing, and synthetic data generation. Despite their simplicity, these Attractor-based interventions match or exceed specialized baselines, offering an efficient alternative to heavy fine-tuning, generalizable in scenarios where baselines underperform.

</details>


### [272] [LimAgents: Multi-Agent LLMs for Generating Research Limitations](https://arxiv.org/abs/2601.11578)
*Ibrahim Al Azher,Zhishuai Guo,Hamed Alhoori*

Main category: cs.CL

TL;DR: LimAgents是一个多智能体LLM框架，用于生成实质性的论文局限性分析，通过整合OpenReview评论、作者声明的局限性以及引用文献来提供更全面的局限性识别。


<details>
  <summary>Details</summary>
Motivation: 现有零样本LLM方法生成的局限性分析通常流于表面（如数据集偏差或泛化性问题），只是重复作者已声明的局限性，缺乏对深层方法论问题和上下文差距的深入分析。许多作者也只披露部分或琐碎的局限性，这加剧了问题。

Method: 提出LimAgents多智能体框架，包含多个具有特定角色的智能体：提取显式局限性、分析方法论差距、模拟同行评审视角、分析引用文献上下文。Judge智能体精炼输出，Master智能体整合成清晰的局限性集合。同时引入基于LLM-as-a-Judge的点式评估协议来更准确地衡量覆盖率。

Result: 实验显示LimAgents显著提升性能：RAG + 多智能体GPT-4o mini配置相比零样本基线获得+15.51%的覆盖率提升，Llama 3 8B多智能体设置获得+4.41%的改进。

Conclusion: LimAgents框架能够系统性地识别显式、隐式、同行评审关注和文献背景的局限性，相比传统方法能生成更实质性的局限性分析，并通过创新的评估协议更准确地衡量性能。

Abstract: Identifying and articulating limitations is essential for transparent and rigorous scientific research. However, zero-shot large language models (LLMs) approach often produce superficial or general limitation statements (e.g., dataset bias or generalizability). They usually repeat limitations reported by authors without looking at deeper methodological issues and contextual gaps. This problem is made worse because many authors disclose only partial or trivial limitations. We propose LimAgents, a multi-agent LLM framework for generating substantive limitations. LimAgents integrates OpenReview comments and author-stated limitations to provide stronger ground truth. It also uses cited and citing papers to capture broader contextual weaknesses. In this setup, different agents have specific roles as sequential role: some extract explicit limitations, others analyze methodological gaps, some simulate the viewpoint of a peer reviewer, and a citation agent places the work within the larger body of literature. A Judge agent refines their outputs, and a Master agent consolidates them into a clear set. This structure allows for systematic identification of explicit, implicit, peer review-focused, and literature-informed limitations. Moreover, traditional NLP metrics like BLEU, ROUGE, and cosine similarity rely heavily on n-gram or embedding overlap. They often overlook semantically similar limitations. To address this, we introduce a pointwise evaluation protocol that uses an LLM-as-a-Judge to measure coverage more accurately. Experiments show that LimAgents substantially improve performance. The RAG + multi-agent GPT-4o mini configuration achieves a +15.51% coverage gain over zero-shot baselines, while the Llama 3 8B multi-agent setup yields a +4.41% improvement.

</details>


### [273] [Bielik 11B v3: Multilingual Large Language Model for European Languages](https://arxiv.org/abs/2601.11579)
*Krzysztof Ociepa,Łukasz Flis,Remigiusz Kinas,Krzysztof Wróbel,Adrian Gwoździej*

Main category: cs.CL

TL;DR: Bielik 11B v3是一个专门为波兰语优化的先进语言模型，基于Mistral 7B v0.2架构扩展至110亿参数，在波兰语任务上表现出色，甚至超越参数多2-6倍的大型模型。


<details>
  <summary>Details</summary>
Motivation: 开发一个专门针对波兰语的高性能语言模型，解决波兰语在AI领域代表性不足的问题，同时为其他资源较少语言建立高效模型开发基准。

Method: 采用四阶段训练流程：1) 持续预训练；2) 监督微调(SFT)；3) 直接偏好优化(DPO)；4) 强化学习。基于Mistral 7B v0.2架构，通过深度扩展将参数增加到110亿。

Result: Bielik 11B v3在波兰语任务上显著超越其他专门模型，并在多种任务上优于参数多2-6倍的大型模型。模型参数效率高，支持多种量化选项，可在不同硬件配置上有效部署。

Conclusion: 该模型不仅提升了波兰语的AI能力，还为开发资源高效、高性能的较少代表语言模型建立了新基准，展示了参数效率与性能的平衡。

Abstract: We present Bielik 11B v3, a state-of-the-art language model highly optimized for the Polish language, while also maintaining strong capabilities in other European languages. This model extends the Mistral 7B v0.2 architecture, scaled to 11B parameters via depth up-scaling. Its development involved a comprehensive four-stage training pipeline: continuous pre-training, supervised fine-tuning (SFT), Direct Preference Optimization (DPO), and reinforcement learning.
  Comprehensive evaluations demonstrate that Bielik 11B v3 achieves exceptional performance. It significantly surpasses other specialized Polish language models and outperforms many larger models (with 2-6 times more parameters) on a wide range of tasks, from basic linguistic understanding to complex reasoning.
  The model's parameter efficiency, combined with extensive quantization options, allows for effective deployment across diverse hardware configurations. Bielik 11B v3 not only advances AI capabilities for the Polish language but also establishes a new benchmark for developing resource-efficient, high-performance models for less-represented languages.

</details>


### [274] [Speculative Decoding: Performance or Illusion?](https://arxiv.org/abs/2601.11580)
*Xiaoxuan Liu,Jiaxiang Yu,Jongseok Park,Ion Stoica,Alvin Cheung*

Main category: cs.CL

TL;DR: 对推测解码在真实生产环境中的首次系统性研究，揭示了其在vLLM推理引擎上的实际性能与理论上限存在显著差距


<details>
  <summary>Details</summary>
Motivation: 推测解码已成为加速大语言模型推理的流行技术，但先前评估依赖研究原型和不切实际的小批量大小，其真实世界有效性仍不明确

Method: 在广泛部署的生产级推理引擎vLLM上进行首次系统性研究，涵盖多种推测解码变体（n-gram、EAGLE/EAGLE-3、Draft-Model、Multi-Token Prediction），覆盖多样化工作负载、模型规模和批量大小

Result: 目标模型的验证阶段主导执行时间，接受长度在不同输出位置、请求和数据集间差异显著；实测性能与理论上限存在较大差距

Conclusion: 研究揭示了推测解码性能的关键影响因素，量化了理论加速上限，并指出了改进推测解码的新研究机会

Abstract: Speculative decoding (SD) has become a popular technique to accelerate Large Language Model (LLM) inference, yet its real-world effectiveness remains unclear as prior evaluations rely on research prototypes and unrealistically small batch sizes. We present, to our knowledge, the first systematic study of SD on a production-grade and widely deployed inference engine (vLLM), covering multiple SD variants ($n$-gram, EAGLE/EAGLE-3, Draft-Model, Multi-Token Prediction) across diverse workloads, model scales, and batch sizes. We analyze key factors governing SD performance, and quantify a theoretical upper bound on SD speedup. Our results show that verification by the target model dominates the execution, while acceptance length varies markedly across output token positions, requests, and datasets. Comparing measured performance with theoretical bounds reveals substantial gaps between observed and theoretical upper bounds, and we leverage this observation to highlight new research opportunities that our study opens up in improving SD.

</details>


### [275] [Enhancing the QA Model through a Multi-domain Debiasing Framework](https://arxiv.org/abs/2601.11581)
*Yuefeng Wang,ChangJae Lee*

Main category: cs.CL

TL;DR: ELECTRA-small模型在SQuAD和对抗数据集上存在偏见问题，通过多领域去偏框架（知识蒸馏、去偏技术、领域扩展）实现了性能提升，在对抗环境下获得高达2.6个百分点的改进。


<details>
  <summary>Details</summary>
Motivation: 尽管问答模型在机器阅读理解方面取得显著进展，但存在偏见问题，特别是在复杂查询和对抗条件下表现不佳。需要评估ELECTRA-small模型在标准数据集和对抗数据集上的表现，识别偏见类型，并开发有效的去偏策略。

Method: 使用ELECTRA-small模型在SQuAD v1.1数据集以及对抗数据集AddSent和AddOneSent上进行评估。识别词汇偏见、数值推理和实体识别等错误类型。开发多领域去偏框架，结合知识蒸馏、去偏技术和领域扩展方法。

Result: 在所有测试集上实现了高达2.6个百分点的Exact Match（EM）和F1分数提升，在对抗环境下也获得了显著改进。这表明针对性的偏见缓解策略能够有效提升模型性能。

Conclusion: 针对性的偏见缓解策略能够显著提升自然语言理解系统的鲁棒性和可靠性。多领域去偏框架通过知识蒸馏、去偏技术和领域扩展的组合，有效减少了模型在复杂查询和对抗条件下的偏见问题。

Abstract: Question-answering (QA) models have advanced significantly in machine reading comprehension but often exhibit biases that hinder their performance, particularly with complex queries in adversarial conditions. This study evaluates the ELECTRA-small model on the Stanford Question Answering Dataset (SQuAD) v1.1 and adversarial datasets AddSent and AddOneSent. By identifying errors related to lexical bias, numerical reasoning, and entity recognition, we develop a multi-domain debiasing framework incorporating knowledge distillation, debiasing techniques, and domain expansion. Our results demonstrate up to 2.6 percentage point improvements in Exact Match (EM) and F1 scores across all test sets, with gains in adversarial contexts. These findings highlight the potential of targeted bias mitigation strategies to enhance the robustness and reliability of natural language understanding systems.

</details>


### [276] [Entropic Context Shaping: Information-Theoretic Filtering for Context-Aware LLM Agents](https://arxiv.org/abs/2601.11585)
*Hyunjun Kim*

Main category: cs.CL

TL;DR: 本文提出了熵上下文塑造（ECS）框架，通过测量模型答案分布向正确答案的偏移来评估上下文效用，相比基于词汇相似度的方法，在细粒度上下文选择任务上取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）代理的上下文工程需要区分实用信息和误导性干扰信息。传统基于词汇相似度的方法（如TF-IDF）无法捕捉语用效用——即一段文本是否真正有助于回答问题。

Method: 引入熵上下文塑造（ECS）信息论框架，通过测量模型答案分布向正确答案的偏移来量化上下文效用。将效用形式化为答案概率的有符号变化，并提供理论分析表明任务无关的更新产生接近零的分布偏移。

Result: 在LongMemEval（会话级）和LoCoMo（轮次级）基准测试上进行评估。在细粒度轮次选择任务中，ECS与Llama-3.1-8B模型结合实现了F1=0.265，相比TF-IDF（F1=0.154）有71.83%的相对改进。

Conclusion: ECS框架能够有效捕捉语用效用，在精确上下文选择任务中显著优于基于词汇相似度的方法，证明了语用效用比词汇相似度在上下文选择中更为重要。

Abstract: Context engineering for large language model (LLM) agents requires distinguishing pragmatically useful information from misleading distractors. We introduce Entropic Context Shaping (ECS), an information-theoretic framework that measures context utility via the shift in the model's answer distribution toward the correct answer. Unlike lexical similarity methods that rely on word overlap, ECS captures pragmatic utility -- whether a passage actually helps answer the question. We formalize utility as the signed change in answer probability and provide theoretical analysis showing that task-irrelevant updates yield near-zero distribution shift. We evaluate on multi-turn context selection tasks using LongMemEval (session-level) and LoCoMo (turn-level) benchmarks. On fine-grained turn selection, ECS with Llama-3.1-8B achieves F1=0.265, a 71.83% relative improvement over TF-IDF (F1=0.154), demonstrating that pragmatic utility outperforms lexical similarity when precise context selection matters. Code and data are available in the supplementary materials.

</details>


### [277] [Towards AGI A Pragmatic Approach Towards Self Evolving Agent](https://arxiv.org/abs/2601.11658)
*Indrajit Kar,Sammy Zonunpuia,Zonunfeli Ralte*

Main category: cs.CL

TL;DR: 提出分层自进化多智能体框架，通过工具合成和进化算法实现LLM智能体的自主能力扩展，在TaskCraft数据集上验证了进化智能体优于原始版本


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的智能体在部署后是静态的，缺乏自主扩展能力、生成新工具或进化推理的能力，需要一种能够持续适应和进化的智能体框架

Method: 分层自进化多智能体框架：包含基础LLM、操作SLM智能体、代码生成LLM和教师LLM。工作流程：先尝试现有工具，失败时通过代码生成LLM合成新工具，持续失败时触发进化阶段（课程学习、基于奖励的学习或遗传算法进化）

Result: 在TaskCraft数据集上评估：课程学习提供快速恢复和强泛化能力，基于奖励的学习在高难度任务上表现优异，遗传算法提供高行为多样性。所有设置中，进化后的智能体都优于原始版本

Conclusion: 该框架实现了稳健、自主、自我改进的智能体进化，证明了LLM智能体能够通过自主工具合成和进化算法持续提升能力

Abstract: Large Language Model (LLM) based agents are powerful yet fundamentally static after deployment, lacking the ability to autonomously expand capabilities, generate new tools, or evolve their reasoning. This work introduces a hierarchical self-evolving multi-agent framework that integrates a Base LLM, an operational SLM agent, a Code-Generation LLM, and a Teacher-LLM to enable continuous adaptation. The workflow begins with the agent attempting a task using reasoning and existing tools; if unsuccessful, it escalates to tool synthesis through the Code-Gen LLM, and when failures persist, it triggers an evolution phase using Curriculum Learning (CL), Reward-Based Learning (RL), or Genetic Algorithm (GA) evolution. Using the TaskCraft dataset rich in hierarchical tasks, tool-use traces, and difficulty scaling we evaluate these paradigms. CL delivers fast recovery and strong generalization, RL excels on high-difficulty tasks, and GA offers high behavioral diversity. Across all settings, evolved agents outperform their originals, demonstrating robust, autonomous, self-improving agentic evolution.

</details>


### [278] [RAC: Retrieval-Augmented Clarification for Faithful Conversational Search](https://arxiv.org/abs/2601.11722)
*Ahmed Rayane Kebir,Vincent Guigue,Lynda Said Lhadj,Laure Soulier*

Main category: cs.CL

TL;DR: RAC框架通过检索增强生成基于语料库的澄清问题，使用对比偏好优化确保问题有文档依据，在多个基准测试中显著提升忠实度


<details>
  <summary>Details</summary>
Motivation: 现有对话搜索系统在生成澄清问题时主要关注流畅性和用户意图对齐，但缺乏对语料库的忠实性，导致可能生成无法从可用文档回答的问题

Method: 提出RAC框架：1) 比较多种检索索引策略；2) 微调大语言模型以充分利用检索上下文并生成基于证据的问题；3) 应用对比偏好优化，使有检索段落支持的问题优于无依据的替代方案

Result: 在四个基准测试中，RAC相比基线方法有显著改进。除了LLM-as-Judge评估外，还引入了基于NLI和数据到文本的新指标来评估问题在上下文中的锚定程度，证明该方法能持续提升忠实度

Conclusion: RAC框架通过检索增强和对比偏好优化，成功生成了更忠实于语料库的澄清问题，解决了现有方法可能生成无法从文档回答的问题的局限性

Abstract: Clarification questions help conversational search systems resolve ambiguous or underspecified user queries. While prior work has focused on fluency and alignment with user intent, especially through facet extraction, much less attention has been paid to grounding clarifications in the underlying corpus. Without such grounding, systems risk asking questions that cannot be answered from the available documents. We introduce RAC (Retrieval-Augmented Clarification), a framework for generating corpus-faithful clarification questions. After comparing several indexing strategies for retrieval, we fine-tune a large language model to make optimal use of research context and to encourage the generation of evidence-based question. We then apply contrastive preference optimization to favor questions supported by retrieved passages over ungrounded alternatives. Evaluated on four benchmarks, RAC demonstrate significant improvements over baselines. In addition to LLM-as-Judge assessments, we introduce novel metrics derived from NLI and data-to-text to assess how well questions are anchored in the context, and we demonstrate that our approach consistently enhances faithfulness.

</details>


### [279] [Bridging Human Interpretation and Machine Representation: A Landscape of Qualitative Data Analysis in the LLM Era](https://arxiv.org/abs/2601.11739)
*Xinyu Pi,Qisen Yang,Chuong Nguyen,Hua Shen*

Main category: cs.CL

TL;DR: 论文提出了一个4×4的分析框架，用于评估LLM在质性研究中的自动化应用，发现现有系统偏向低层次意义和低承诺表示，缺乏解释性/理论推断和动态建模，并提出了改进议程。


<details>
  <summary>Details</summary>
Motivation: LLM越来越多地用于支持质性研究，但现有系统产生的输出差异很大——从忠实于原始数据的总结到理论中介的解释和系统模型。为了明确这些差异，需要建立一个分析框架来理解LLM在质性研究中的不同应用层次。

Method: 引入一个4×4的分析框架：四个意义建构层次（描述性、分类性、解释性、理论性）与四个建模层次（静态结构、阶段/时间线、因果路径、反馈动态）交叉。将该框架应用于先前LLM自动化研究，分析其分布特征。

Result: 应用该框架分析发现，现有LLM自动化研究存在明显偏差：强烈偏向低层次意义建构（描述性、分类性）和低承诺表示（静态结构），很少有可靠尝试进行解释性/理论推断或动态建模。

Conclusion: 基于揭示的差距，提出了一个研究议程：开发和应用LLM系统，使其解释性和建模承诺变得明确、可选择和可管理，推动LLM在质性研究中向更高层次的意义建构和更复杂的建模发展。

Abstract: LLMs are increasingly used to support qualitative research, yet existing systems produce outputs that vary widely--from trace-faithful summaries to theory-mediated explanations and system models. To make these differences explicit, we introduce a 4$\times$4 landscape crossing four levels of meaning-making (descriptive, categorical, interpretive, theoretical) with four levels of modeling (static structure, stages/timelines, causal pathways, feedback dynamics). Applying the landscape to prior LLM-based automation highlights a strong skew toward low-level meaning and low-commitment representations, with few reliable attempts at interpretive/theoretical inference or dynamical modeling. Based on the revealed gap, we outline an agenda for applying and building LLM-systems that make their interpretive and modeling commitments explicit, selectable, and governable.

</details>


### [280] [LIME-LLM: Probing Models with Fluent Counterfactuals, Not Broken Text](https://arxiv.org/abs/2601.11746)
*George Mihaila,Suleyman Olcay Polat,Poli Nemkova,Himanshu Sharma,Namratha V. Urs,Mark V. Albert*

Main category: cs.CL

TL;DR: LIME-LLM：一种基于假设驱动、受控扰动的新型NLP局部解释方法，通过"单掩码-单样本"协议和中性填充策略，相比传统随机掩码和生成式方法显著提升了局部解释的保真度。


<details>
  <summary>Details</summary>
Motivation: 传统LIME等方法在NLP中依赖随机token掩码，会产生语义无效的离群输入，降低局部代理模型的保真度。而最近的生成式方法如LLiMe虽然使用大语言模型生成邻域，但不受约束的改写引入了混淆变量，难以隔离特定特征贡献。

Method: 提出LIME-LLM框架，用假设驱动、受控扰动替代随机噪声。采用严格的"单掩码-单样本"协议，并使用不同的中性填充和边界填充策略，构建流畅、在流形上的邻域，严格隔离特征效应。

Result: 在CoLA、SST-2和HateXplain三个基准数据集上，使用人工标注的rationales作为ground truth进行评估。实证结果表明，LIME-LLM相比传统扰动方法（LIME、SHAP、Integrated Gradients）和生成式基线LLiMe，在局部解释保真度方面取得了显著改进。

Conclusion: LIME-LLM为黑盒NLP可解释性设立了新基准，通过假设驱动的受控扰动策略，有效解决了传统随机掩码和生成式方法在语义有效性和特征隔离方面的局限性。

Abstract: Local explanation methods such as LIME (Ribeiro et al., 2016) remain fundamental to trustworthy AI, yet their application to NLP is limited by a reliance on random token masking. These heuristic perturbations frequently generate semantically invalid, out-of-distribution inputs that weaken the fidelity of local surrogate models. While recent generative approaches such as LLiMe (Angiulli et al., 2025b) attempt to mitigate this by employing Large Language Models for neighborhood generation, they rely on unconstrained paraphrasing that introduces confounding variables, making it difficult to isolate specific feature contributions. We introduce LIME-LLM, a framework that replaces random noise with hypothesis-driven, controlled perturbations. By enforcing a strict "Single Mask-Single Sample" protocol and employing distinct neutral infill and boundary infill strategies, LIME-LLM constructs fluent, on-manifold neighborhoods that rigorously isolate feature effects. We evaluate our method against established baselines (LIME, SHAP, Integrated Gradients) and the generative LLiMe baseline across three diverse benchmarks: CoLA, SST-2, and HateXplain using human-annotated rationales as ground truth. Empirical results demonstrate that LIME-LLM establishes a new benchmark for black-box NLP explainability, achieving significant improvements in local explanation fidelity compared to both traditional perturbation-based methods and recent generative alternatives.

</details>


### [281] [Early Linguistic Pattern of Anxiety from Social Media Using Interpretable Linguistic Features: A Multi-Faceted Validation Study with Author-Disjoint Evaluation](https://arxiv.org/abs/2601.11758)
*Arnab Das Utsa*

Main category: cs.CL

TL;DR: 提出基于社交媒体语言的透明焦虑检测方法，通过可解释的语言特征建模和跨域验证，实现可靠、可泛化且对关键词鲁棒的焦虑检测。


<details>
  <summary>Details</summary>
Motivation: 焦虑症影响全球数亿人，但大规模筛查仍有限。社交媒体语言提供了可扩展的检测机会，但现有模型往往缺乏可解释性、关键词鲁棒性验证和严格的用户级数据完整性。

Method: 使用Reddit帖子的大规模数据集，在精心策划的子版块上训练逻辑回归分类器。包括特征消融、关键词掩码实验、焦虑组与对照组密度差异分析，以及使用临床访谈确诊焦虑症参与者的外部验证。

Result: 模型在移除情感或掩码关键词后仍保持高准确率。使用最少帖子历史的早期检测显著优于随机分类，跨域分析与临床访谈数据表现出强一致性。

Conclusion: 透明语言特征可以支持可靠、可泛化且对关键词鲁棒的焦虑检测。该框架为跨不同在线环境的可解释心理健康筛查提供了可复现的基线。

Abstract: Anxiety affects hundreds of millions of individuals globally, yet large-scale screening remains limited. Social media language provides an opportunity for scalable detection, but current models often lack interpretability, keyword-robustness validation, and rigorous user-level data integrity. This work presents a transparent approach to social media-based anxiety detection through linguistically interpretable feature-grounded modeling and cross-domain validation. Using a substantial dataset of Reddit posts, we trained a logistic regression classifier on carefully curated subreddits for training, validation, and test splits. Comprehensive evaluation included feature ablation, keyword masking experiments, and varying-density difference analyses comparing anxious and control groups, along with external validation using clinically interviewed participants with diagnosed anxiety disorders. The model achieved strong performance while maintaining high accuracy even after sentiment removal or keyword masking. Early detection using minimal post history significantly outperformed random classification, and cross-domain analysis demonstrated strong consistency with clinical interview data. Results indicate that transparent linguistic features can support reliable, generalizable, and keyword-robust anxiety detection. The proposed framework provides a reproducible baseline for interpretable mental health screening across diverse online contexts.

</details>


### [282] [Industry-Aligned Granular Topic Modeling](https://arxiv.org/abs/2601.11762)
*Sae Young Moon,Myeongjun Erik Jang,Haoyan Luo,Chunyang Xiao,Antonios Georgiadis,Fran Silavong*

Main category: cs.CL

TL;DR: TIDE框架提出基于大语言模型的细粒度主题建模方法，在商业应用中提供文档摘要、主题层级和蒸馏等功能，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 主题建模在工业领域有广泛应用，但现有方法在生成细粒度主题方面研究不足，而细粒度对商业应用有重要价值。

Method: 提出TIDE框架，核心是基于大语言模型的细粒度主题建模方法，同时包含文档摘要、主题层级关系构建和蒸馏等辅助功能。

Result: 在多个公开和真实商业数据集上的实验表明，TIDE的主题建模方法优于现代主题建模方法，辅助组件对工业商业场景有重要支持。

Conclusion: TIDE框架为商业应用提供了有效的细粒度主题建模解决方案，目前正在开源过程中。

Abstract: Topic modeling has extensive applications in text mining and data analysis across various industrial sectors. Although the concept of granularity holds significant value for business applications by providing deeper insights, the capability of topic modeling methods to produce granular topics has not been thoroughly explored. In this context, this paper introduces a framework called TIDE, which primarily provides a novel granular topic modeling method based on large language models (LLMs) as a core feature, along with other useful functionalities for business applications, such as summarizing long documents, topic parenting, and distillation. Through extensive experiments on a variety of public and real-world business datasets, we demonstrate that TIDE's topic modeling approach outperforms modern topic modeling methods, and our auxiliary components provide valuable support for dealing with industrial business scenarios. The TIDE framework is currently undergoing the process of being open sourced.

</details>


### [283] [Cleansing the Artificial Mind: A Self-Reflective Detoxification Framework for Large Language Models](https://arxiv.org/abs/2601.11776)
*Kaituo Zhang,Zhimeng Jiang,Na Zou*

Main category: cs.CL

TL;DR: 提出一个完全自反思的去毒框架，利用LLMs内在能力检测、修正有毒内容并优化模型，无需外部模块或数据标注，在去毒性能上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有去毒技术很少利用LLMs内在的自校正和自奖励能力，而是依赖外部模块、人工数据标注或人工干预，这限制了可扩展性和一致性。

Method: 提出一个完全自反思的去毒框架，包括毒性信号检测器（内部自识别机制）和系统干预过程，通过迭代过程生成对比去毒数据集用于微调模型。

Result: 在DetoxLLM和ParaDetox等基准数据集上，该方法在去毒性能上优于最先进方法，同时保持了语义保真度。

Conclusion: 该方法揭示了LLMs内在的自去毒能力，为减轻有害内容生成提供了一致有效的方法，为真正自调节的语言模型铺平了道路。

Abstract: Recent breakthroughs in Large Language Models (LLMs) have revealed remarkable generative capabilities and emerging self-regulatory mechanisms, including self-correction and self-rewarding. However, current detoxification techniques rarely exploit these built-in abilities; instead, they rely on external modules, labor-intensive data annotation, or human intervention --factors that hinder scalability and consistency. In this paper, we introduce a fully self-reflective detoxification framework that harnesses the inherent capacities of LLMs to detect, correct toxic content, and refine LLMs without external modules and data annotation. Specifically, we propose a Toxic Signal Detector --an internal self-identification mechanism, coupled with a systematic intervention process to transform toxic text into its non-toxic counterpart. This iterative procedure yields a contrastive detoxification dataset used to fine-tune the model, enhancing its ability for safe and coherent text generation. Experiments on benchmark datasets such as DetoxLLM and ParaDetox show that our method achieves better detoxification performance than state-of-the-art methods while preserving semantic fidelity. By obviating the need for human intervention or external components, this paper reveals the intrinsic self-detoxification ability of LLMs, offering a consistent and effective approach for mitigating harmful content generation. Ultimately, our findings underscore the potential for truly self-regulated language models, paving the way for more responsible and ethically guided text generation systems.

</details>


### [284] [Translation as a Scalable Proxy for Multilingual Evaluation](https://arxiv.org/abs/2601.11778)
*Sheriff Issaka,Erick Rosas Gonzalez,Lieqi Liu,Evans Kofi Agyei,Lucas Bandarkar,Nanyun Peng,David Ifeoluwa Adelani,Francisco Guzmán,Saadia Gabriel*

Main category: cs.CL

TL;DR: 翻译质量可作为评估大语言模型多语言能力的有效代理指标，通过翻译性能可预测下游任务表现


<details>
  <summary>Details</summary>
Motivation: 当前LLMs声称具备多语言能力，但缺乏针对大多数语言（>98%的7000种语言）的非机器翻译基准测试，传统基准构建面临成本高、专家稀缺和数据污染等挑战

Method: 系统评估14个模型（1B-72B参数）在9个多样化基准和7个翻译指标上的表现，分析翻译性能与下游任务成功之间的相关性

Result: 翻译性能是多语言下游任务成功的良好指标（如Phi-4模型的中位数Pearson相关系数：MetricX=0.89，xCOMET=0.91，SSA-COMET=0.87）

Conclusion: 翻译质量可作为强大、廉价的多语言性能初步代理指标，支持"翻译优先筛选+特定任务针对性跟进"的评估策略

Abstract: The rapid proliferation of LLMs has created a critical evaluation paradox: while LLMs claim multilingual proficiency, comprehensive non-machine-translated benchmarks exist for fewer than 30 languages, leaving >98% of the world's 7,000 languages in an empirical void. Traditional benchmark construction faces scaling challenges such as cost, scarcity of domain experts, and data contamination. We evaluate the validity of a simpler alternative: can translation quality alone indicate a model's broader multilingual capabilities? Through systematic evaluation of 14 models (1B-72B parameters) across 9 diverse benchmarks and 7 translation metrics, we find that translation performance is a good indicator of downstream task success (e.g., Phi-4, median Pearson r: MetricX = 0.89, xCOMET = 0.91, SSA-COMET = 0.87). These results suggest that the representational abilities supporting faithful translation overlap with those required for multilingual understanding. Translation quality, thus emerges as a strong, inexpensive first-pass proxy of multilingual performance, enabling a translation-first screening with targeted follow-up for specific tasks.

</details>


### [285] [Beyond Tokens: Concept-Level Training Objectives for LLMs](https://arxiv.org/abs/2601.11791)
*Laya Iyer,Pranav Somani,Alice Guo,Dan Jurafsky,Chen Shani*

Main category: cs.CL

TL;DR: 该论文提出从传统的下一个token预测转向概念级预测，通过将相同语义的不同表面形式（如"mom"、"mother"）分组为概念，让LLM学习更高层次的语义抽象，从而提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 传统的下一个token预测（NTP）目标在token级别操作，即使替代延续同样合理或语义等价（如"mom" vs "mother"），也会将其视为错误。这导致token级损失会惩罚有效的抽象、释义或概念上正确的推理路径，使模型偏向表面形式而非底层含义。训练信号与语义正确性之间的不匹配促使需要更高层次表示的学习目标。

Method: 提出从token级预测转向概念级预测，其中概念将同一想法的多个表面形式分组（如"mom"、"mommy"、"mother"→MOTHER）。引入了多种将概念监督集成到LLM训练中的方法。

Result: 概念感知模型实现了更低的困惑度、在领域转移下更强的鲁棒性，以及在多样化NLP基准测试中比基于NTP的模型更强的性能。

Conclusion: 概念级监督作为一种改进的训练信号，能更好地将LLM与人类语义抽象对齐，是提升语言模型训练效果的有前景方向。

Abstract: The next-token prediction (NTP) objective has been foundational in the development of modern large language models (LLMs), driving advances in fluency and generalization. However, NTP operates at the \textit{token} level, treating deviations from a single reference continuation as errors even when alternative continuations are equally plausible or semantically equivalent (e.g., ``mom'' vs. ``mother''). As a result, token-level loss can penalize valid abstractions, paraphrases, or conceptually correct reasoning paths, biasing models toward surface form rather than underlying meaning. This mismatch between the training signal and semantic correctness motivates learning objectives that operate over higher-level representations. We propose a shift from token-level to concept-level prediction, where concepts group multiple surface forms of the same idea (e.g., ``mom,'' ``mommy,'' ``mother'' $\rightarrow$ \textit{MOTHER}). We introduce various methods for integrating conceptual supervision into LLM training and show that concept-aware models achieve lower perplexity, improved robustness under domain shift, and stronger performance than NTP-based models on diverse NLP benchmarks. This suggests \textit{concept-level supervision} as an improved training signal that better aligns LLMs with human semantic abstractions.

</details>


### [286] [TWeddit : A Dataset of Triggering Stories Predominantly Shared by Women on Reddit](https://arxiv.org/abs/2601.11819)
*Shirlene Rose Bandela,Sanjeev Parthasarathy,Vaibhav Garg*

Main category: cs.CL

TL;DR: 研究者创建了TWeddit数据集，标注Reddit上女性相关创伤经历（如流产、性暴力）的帖子，用于触发内容检测研究


<details>
  <summary>Details</summary>
Motivation: Reddit上用户常分享流产、性暴力等创伤经历，但缺乏系统性的触发警告机制，现有数据集稀缺，需要专门针对女性相关创伤内容的数据集

Method: 构建TWeddit数据集，标注Reddit上涉及女性主要面临的创伤经历的帖子，并进行语言学分析，包括话题和道德基础分析

Result: TWeddit数据集中的标注故事展现出独特的话题模式和道德基础表达，证明该数据集对未来研究具有实用价值

Conclusion: TWeddit数据集填补了Reddit上创伤经历标注数据的空白，为触发内容检测、情感分析等研究提供了宝贵资源

Abstract: Warning: This paper may contain examples and topics that may be disturbing to some readers, especially survivors of miscarriage and sexual violence. People affected by abortion, miscarriage, or sexual violence often share their experiences on social media to express emotions and seek support. On public platforms like Reddit, where users can post long, detailed narratives (up to 40,000 characters), readers may be exposed to distressing content. Although Reddit allows manual trigger warnings, many users omit them due to limited awareness or uncertainty about which categories apply. There is scarcity of datasets on Reddit stories labeled for triggering experiences. We propose a curated Reddit dataset, TWeddit, covering triggering experiences related to issues majorly faced by women. Our linguistic analyses show that annotated stories in TWeddit express distinct topics and moral foundations, making the dataset useful for a wide range of future research.

</details>


### [287] [The Third VoicePrivacy Challenge: Preserving Emotional Expressiveness and Linguistic Content in Voice Anonymization](https://arxiv.org/abs/2601.11846)
*Natalia Tomashenko,Xiaoxiao Miao,Pierre Champion,Sarina Meyer,Michele Panariello,Xin Wang,Nicholas Evans,Emmanuel Vincent,Junichi Yamagishi,Massimiliano Todisco*

Main category: cs.CL

TL;DR: 2024年第三届VoicePrivacy挑战赛结果分析，聚焦语音匿名化技术，旨在隐藏说话人身份同时保留语言内容和情感状态


<details>
  <summary>Details</summary>
Motivation: 推动语音匿名化技术发展，解决隐私保护需求，在隐藏说话人身份的同时保持语音内容和情感信息的完整性

Method: 建立系统化挑战框架，包括匿名化任务定义、数据集开发、攻击模型设计、客观评估指标（隐私保护和效用保持），提供六个基线系统并总结参与者创新方法

Result: 提供了完整的挑战赛结果分析，包括系统性能评估、创新方法总结，为未来语音匿名化研究提供关键见解

Conclusion: 挑战赛成功推动了语音匿名化技术发展，识别了有前景的研究方向，为未来VoicePrivacy挑战赛设计和语音匿名化研究提供了指导

Abstract: We present results and analyses from the third VoicePrivacy Challenge held in 2024, which focuses on advancing voice anonymization technologies. The task was to develop a voice anonymization system for speech data that conceals a speaker's voice identity while preserving linguistic content and emotional state. We provide a systematic overview of the challenge framework, including detailed descriptions of the anonymization task and datasets used for both system development and evaluation. We outline the attack model and objective evaluation metrics for assessing privacy protection (concealing speaker voice identity) and utility (content and emotional state preservation). We describe six baseline anonymization systems and summarize the innovative approaches developed by challenge participants. Finally, we provide key insights and observations to guide the design of future VoicePrivacy challenges and identify promising directions for voice anonymization research.

</details>


### [288] [ATOD: An Evaluation Framework and Benchmark for Agentic Task-Oriented Dialogue System](https://arxiv.org/abs/2601.11854)
*Yifei Zhang,Hooshang Nayyeri,Rinat Khaziev,Emine Yilmaz,Gokhan Tur,Dilek Hakkani-Tür,Hari Thadakamalla*

Main category: cs.CL

TL;DR: ATOD是一个用于评估任务导向对话系统智能代理行为的基准测试和对话生成框架，包含ATOD-Eval评估框架和基于记忆的评估器。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试缺乏对LLM驱动的任务导向对话系统中智能代理行为（如多目标协调、长期推理、主动执行等）的系统性评估支持。

Method: 提出ATOD基准测试和合成对话生成流水线，生成需要长期推理的丰富标注对话；在此基础上提出ATOD-Eval评估框架，将智能代理维度转化为细粒度指标；并开发基于记忆的评估器。

Result: ATOD-Eval能够全面评估任务完成度、智能代理能力和响应质量；提出的评估器在准确性和效率方面优于现有的基于记忆和LLM的方法。

Conclusion: ATOD填补了评估先进任务导向对话系统智能代理行为的空白，ATOD-Eval提供了可复现的评估框架，为未来研究提供了重要基准。

Abstract: Recent advances in task-oriented dialogue (TOD) systems, driven by large language models (LLMs) with extensive API and tool integration, have enabled conversational agents to coordinate interleaved goals, maintain long-horizon context, and act proactively through asynchronous execution. These capabilities extend beyond traditional TOD systems, yet existing benchmarks lack systematic support for evaluating such agentic behaviors. To address this gap, we introduce ATOD, a benchmark and synthetic dialogue generation pipeline that produces richly annotated conversations requiring long-term reasoning. ATOD captures key characteristics of advanced TOD, including multi-goal coordination, dependency management, memory, adaptability, and proactivity. Building on ATOD, we propose ATOD-Eval, a holistic evaluation framework that translates these dimensions into fine-grained metrics and supports reproducible offline and online evaluation. We further present a strong agentic memory-based evaluator for benchmarking on ATOD. Experiments show that ATOD-Eval enables comprehensive assessment across task completion, agentic capability, and response quality, and that the proposed evaluator offers a better accuracy-efficiency tradeoff compared to existing memory- and LLM-based approaches under this evaluation setting.

</details>


### [289] [CTPD: Cross Tokenizer Preference Distillation](https://arxiv.org/abs/2601.11865)
*Truong Nguyen,Phi Van Dat,Ngan Nguyen,Linh Ngo Van,Trung Le,Thanh Hong Nguyen*

Main category: cs.CL

TL;DR: 提出了首个跨分词器偏好蒸馏框架CTPD，通过字符级对齐、重要性采样和教师锚定参考，解决不同分词器模型间偏好对齐的难题。


<details>
  <summary>Details</summary>
Motivation: 知识蒸馏在预训练和指令调优中广泛应用，但在人类偏好对齐方面探索不足，特别是在更现实的跨分词器场景中。不同分词方案的不兼容性阻碍了细粒度的白盒偏好信息蒸馏。

Method: 提出CTPD框架，包含三个关键创新：1) 对齐跨度投影，将师生token映射到共享字符级跨度；2) 跨分词器适应的Token级重要性采样(TIS-DPO)；3) 教师锚定参考，让学生直接利用教师的DPO风格偏好。

Result: 理论分析将CTPD建立在重要性采样基础上，多个基准测试实验证实其有效性，相比现有方法获得显著性能提升。

Conclusion: CTPD为不同分词方案间的偏好蒸馏提供了实用通用解决方案，为语言模型更易获取和高效的对齐打开了大门。

Abstract: While knowledge distillation has seen widespread use in pre-training and instruction tuning, its application to aligning language models with human preferences remains underexplored, particularly in the more realistic cross-tokenizer setting. The incompatibility of tokenization schemes between teacher and student models has largely prevented fine-grained, white-box distillation of preference information. To address this gap, we propose Cross-Tokenizer Preference Distillation (CTPD), the first unified framework for transferring human-aligned behavior between models with heterogeneous tokenizers. CTPD introduces three key innovations: (1) Aligned Span Projection, which maps teacher and student tokens to shared character-level spans for precise supervision transfer; (2) a cross-tokenizer adaptation of Token-level Importance Sampling (TIS-DPO) for improved credit assignment; and (3) a Teacher-Anchored Reference, allowing the student to directly leverage the teacher's preferences in a DPO-style objective. Our theoretical analysis grounds CTPD in importance sampling, and experiments across multiple benchmarks confirm its effectiveness, with significant performance gains over existing methods. These results establish CTPD as a practical and general solution for preference distillation across diverse tokenization schemes, opening the door to more accessible and efficient alignment of language models.

</details>


### [290] [Advances in LLM Reasoning Enable Flexibility in Clinical Problem-Solving](https://arxiv.org/abs/2601.11866)
*Kie Shidara,Preethi Prem,Jonathan Kim,Anna Podlasek,Feng Liu,Ahmed Alaa,Danilo Bernardo*

Main category: cs.CL

TL;DR: 大型语言模型在医学QA基准测试中表现出色，但临床推理的灵活性一直存在争议。研究发现，先进的推理模型在医学抽象推理语料库(mARC)上能避免Einstellung效应陷阱，达到人类水平表现。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在医学QA基准测试中取得了高准确率，但其临床推理的灵活性仍受质疑。研究旨在探索先进的推理模型是否能提高在临床推理中的认知灵活性，特别是在面对Einstellung效应（思维定势）时的表现。

Method: 使用医学抽象推理语料库(mARC)这一对抗性医学QA基准，该基准利用Einstellung效应诱导对学习到的启发式模式的过度依赖。评估了来自OpenAI、Grok、Gemini、Claude和DeepSeek家族的推理模型，比较它们在面对思维定势陷阱时的表现。

Result: 强大的推理模型比弱推理模型更频繁地避免Einstellung效应陷阱，在mARC上达到人类水平表现。在医生最常出错的问题上，前5名模型以高置信度正确回答了55%至70%的问题，表明这些模型可能比人类更不容易受到Einstellung效应的影响。

Conclusion: 强大的推理模型在医学推理中表现出改进的灵活性，在mARC上的表现与人类相当，甚至在某些情况下可能比人类更不容易受到思维定势的影响。

Abstract: Large Language Models (LLMs) have achieved high accuracy on medical question-answer (QA) benchmarks, yet their capacity for flexible clinical reasoning has been debated. Here, we asked whether advances in reasoning LLMs improve their cognitive flexibility in clinical reasoning. We assessed reasoning models from the OpenAI, Grok, Gemini, Claude, and DeepSeek families on the medicine abstraction and reasoning corpus (mARC), an adversarial medical QA benchmark which utilizes the Einstellung effect to induce inflexible overreliance on learned heuristic patterns in contexts where they become suboptimal. We found that strong reasoning models avoided Einstellung-based traps more often than weaker reasoning models, achieving human-level performance on mARC. On questions most commonly missed by physicians, the top 5 performing models answered 55% to 70% correctly with high confidence, indicating that these models may be less susceptible than humans to Einstellung effects. Our results indicate that strong reasoning models demonstrate improved flexibility in medical reasoning, achieving performance on par with humans on mARC.

</details>


### [291] [GloCTM: Cross-Lingual Topic Modeling via a Global Context Space](https://arxiv.org/abs/2601.11872)
*Nguyen Tien Phat,Ngo Vu Minh,Linh Van Ngo,Nguyen Thi Ngoc Diep,Thien Huu Nguyen*

Main category: cs.CL

TL;DR: GloCTM是一个跨语言主题建模框架，通过统一的语义空间实现跨语言主题对齐，利用跨语言词汇邻域增强输入表示，结合局部和全局编码器，并通过CKA损失将潜在主题空间与多语言上下文嵌入对齐，显著提升了主题连贯性和跨语言对齐效果。


<details>
  <summary>Details</summary>
Motivation: 现有跨语言主题模型存在以下问题：1）在分离的语言特定空间中学习主题；2）依赖双语词典等对齐机制，无法捕捉深层跨语言语义；3）忽略了多语言预训练表示中的丰富语义信号；4）导致松散连接的主题空间，限制了细粒度对齐能力。

Method: GloCTM通过以下方法实现：1）构建统一语义空间贯穿整个模型流程；2）使用跨语言词汇邻域扩展词袋表示来丰富输入；3）结合局部和全局编码器推断主题比例，并通过内部正则化对齐潜在表示；4）在输出层定义在组合词汇上的全局主题-词分布，实现跨语言主题意义的结构同步；5）引入中心核对齐（CKA）损失将潜在主题空间与多语言上下文嵌入对齐。

Result: 在多个基准测试上的实验表明，GloCTM显著提升了主题连贯性和跨语言对齐效果，优于现有强基线模型。

Conclusion: GloCTM通过统一的语义空间框架，有效解决了跨语言主题建模中的对齐问题，利用多语言预训练表示和结构化的对齐机制，实现了更好的主题连贯性和语义对齐，为多语言理解任务提供了有力工具。

Abstract: Cross-lingual topic modeling seeks to uncover coherent and semantically aligned topics across languages - a task central to multilingual understanding. Yet most existing models learn topics in disjoint, language-specific spaces and rely on alignment mechanisms (e.g., bilingual dictionaries) that often fail to capture deep cross-lingual semantics, resulting in loosely connected topic spaces. Moreover, these approaches often overlook the rich semantic signals embedded in multilingual pretrained representations, further limiting their ability to capture fine-grained alignment. We introduce GloCTM (Global Context Space for Cross-Lingual Topic Model), a novel framework that enforces cross-lingual topic alignment through a unified semantic space spanning the entire model pipeline. GloCTM constructs enriched input representations by expanding bag-of-words with cross-lingual lexical neighborhoods, and infers topic proportions using both local and global encoders, with their latent representations aligned through internal regularization. At the output level, the global topic-word distribution, defined over the combined vocabulary, structurally synchronizes topic meanings across languages. To further ground topics in deep semantic space, GloCTM incorporates a Centered Kernel Alignment (CKA) loss that aligns the latent topic space with multilingual contextual embeddings. Experiments across multiple benchmarks demonstrate that GloCTM significantly improves topic coherence and cross-lingual alignment, outperforming strong baselines.

</details>


### [292] [Faithfulness vs. Safety: Evaluating LLM Behavior Under Counterfactual Medical Evidence](https://arxiv.org/abs/2601.11886)
*Kaijie Mo,Siddhartha Venkatayogi,Chantal Shaib,Ramez Kouzy,Wei Xu,Byron C. Wallace,Junyi Jessy Li*

Main category: cs.CL

TL;DR: 研究构建了MedCounterFact医疗反事实问答数据集，评估大语言模型在面对反事实医疗证据时的行为，发现现有模型会盲目接受危险或不合理的证据并给出自信回答，缺乏安全边界。


<details>
  <summary>Details</summary>
Motivation: 在高风险医疗领域，模型应忠实遵循上下文，但当上下文与模型先验或安全协议冲突时，模型会如何行为？研究旨在探索LLM在面对反事实或对抗性医疗证据时的推理行为。

Method: 构建MedCounterFact反事实医疗QA数据集，包含临床比较问题（评估治疗效果），将真实医疗干预系统性地替换为四种反事实刺激（从未知词汇到有毒物质），评估多个前沿LLM的表现。

Result: 在反事实证据存在时，现有模型绝大多数会表面接受这些证据，即使证据危险或不可信，并给出自信且无保留的答案。模型在忠实性和安全性之间缺乏明确边界。

Conclusion: 虽然理论上应在忠实性和安全性之间划定界限，但研究发现现有模型尚未建立这样的边界，揭示了LLM在医疗等高风险领域应用中的安全隐患。

Abstract: In high-stakes domains like medicine, it may be generally desirable for models to faithfully adhere to the context provided. But what happens if the context does not align with model priors or safety protocols? In this paper, we investigate how LLMs behave and reason when presented with counterfactual or even adversarial medical evidence. We first construct MedCounterFact, a counterfactual medical QA dataset that requires the models to answer clinical comparison questions (i.e., judge the efficacy of certain treatments, with evidence consisting of randomized controlled trials provided as context). In MedCounterFact, real-world medical interventions within the questions and evidence are systematically replaced with four types of counterfactual stimuli, ranging from unknown words to toxic substances. Our evaluation across multiple frontier LLMs on MedCounterFact reveals that in the presence of counterfactual evidence, existing models overwhelmingly accept such "evidence" at face value even when it is dangerous or implausible, and provide confident and uncaveated answers. While it may be prudent to draw a boundary between faithfulness and safety, our findings reveal that there exists no such boundary yet.

</details>


### [293] [PPA-Plan: Proactive Pitfall Avoidance for Reliable Planning in Long-Context LLM Reasoning](https://arxiv.org/abs/2601.11908)
*Byeongjin Kim,Gyuwan Kim,Seo Yeon Park*

Main category: cs.CL

TL;DR: PPA-Plan是一种针对长上下文推理的主动规划策略，通过识别潜在逻辑陷阱和错误假设，将其作为负面约束条件，在规划生成阶段就避免失败，从而提升长上下文推理性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在长上下文推理中存在困难，特别是当相关信息稀疏分布时。现有的规划-执行框架虽然通过任务分解来缓解这个问题，但由于依赖表面线索，规划生成不可靠，导致规划基于错误假设，且事后难以识别和修正问题，限制了反应式优化的效果。

Method: PPA-Plan采用主动规划策略：1) 识别潜在逻辑陷阱和错误假设；2) 将其表述为负面约束条件；3) 在规划生成时明确避免这些约束条件，从而在规划阶段就预防失败。

Result: 在长上下文QA基准测试中，执行PPA-Plan生成的规划持续优于现有的规划-执行方法和直接提示方法。

Conclusion: PPA-Plan通过主动识别和避免潜在失败点，在规划阶段预防错误，有效提升了长上下文推理的可靠性和性能，为解决大语言模型在稀疏信息长上下文中的推理问题提供了新思路。

Abstract: Large language models (LLMs) struggle with reasoning over long contexts where relevant information is sparsely distributed. Although plan-and-execute frameworks mitigate this by decomposing tasks into planning and execution, their effectiveness is often limited by unreliable plan generation due to dependence on surface-level cues. Consequently, plans may be based on incorrect assumptions, and once a plan is formed, identifying what went wrong and revising it reliably becomes difficult, limiting the effectiveness of reactive refinement. To address this limitation, we propose PPA-Plan, a proactive planning strategy for long-context reasoning that focuses on preventing such failures before plan generation. PPA-Plan identifies potential logical pitfalls and false assumptions, formulates them as negative constraints, and conditions plan generation on explicitly avoiding these constraints. Experiments on long-context QA benchmarks show that executing plans generated by PPA-Plan consistently outperforms existing plan-and-execute methods and direct prompting.

</details>


### [294] [LSTM-MAS: A Long Short-Term Memory Inspired Multi-Agent System for Long-Context Understanding](https://arxiv.org/abs/2601.11913)
*Yichen Jiang,Peng Ye,Jiakang Yuan,Chongjun Tu,Lei Bai,Tao Chen*

Main category: cs.CL

TL;DR: LSTM-MAS：受LSTM架构启发的多智能体系统，用于长上下文理解，通过链式架构和门控机制控制信息流，有效避免错误累积和幻觉传播。


<details>
  <summary>Details</summary>
Motivation: 现有处理长上下文的方法存在局限性：单LLM方法有计算成本高或上下文长度受限的问题，多智能体框架则容易累积错误和传播幻觉。需要一种能有效处理长上下文同时避免这些缺陷的新方法。

Method: 受LSTM架构启发设计LSTM-MAS多智能体系统，采用链式架构组织智能体：每个节点包含工作智能体（段级理解）、过滤智能体（冗余减少）、判断智能体（持续错误检测）和管理智能体（全局信息传播与保留），分别对应LSTM的输入门、遗忘门、恒定误差循环单元和输出门。

Result: 相比之前最佳的多智能体方法CoA，在NarrativeQA、Qasper、HotpotQA和MuSiQue四个数据集上分别提升40.93%、43.70%、121.57%和33.12%。

Conclusion: LSTM-MAS通过模拟LSTM的层次信息流和门控内存机制，实现了可控的信息传递和选择性长程依赖建模，有效解决了长上下文理解中的错误累积和幻觉传播问题。

Abstract: Effectively processing long contexts remains a fundamental yet unsolved challenge for large language models (LLMs). Existing single-LLM-based methods primarily reduce the context window or optimize the attention mechanism, but they often encounter additional computational costs or constrained expanded context length. While multi-agent-based frameworks can mitigate these limitations, they remain susceptible to the accumulation of errors and the propagation of hallucinations. In this work, we draw inspiration from the Long Short-Term Memory (LSTM) architecture to design a Multi-Agent System called LSTM-MAS, emulating LSTM's hierarchical information flow and gated memory mechanisms for long-context understanding. Specifically, LSTM-MAS organizes agents in a chained architecture, where each node comprises a worker agent for segment-level comprehension, a filter agent for redundancy reduction, a judge agent for continuous error detection, and a manager agent for globally regulates information propagation and retention, analogous to LSTM and its input gate, forget gate, constant error carousel unit, and output gate. These novel designs enable controlled information transfer and selective long-term dependency modeling across textual segments, which can effectively avoid error accumulation and hallucination propagation. We conducted an extensive evaluation of our method. Compared with the previous best multi-agent approach, CoA, our model achieves improvements of 40.93%, 43.70%,121.57% and 33.12%, on NarrativeQA, Qasper, HotpotQA, and MuSiQue, respectively.

</details>


### [295] [Enhancing LLM-Based Data Annotation with Error Decomposition](https://arxiv.org/abs/2601.11920)
*Zhen Xu,Vedant Khatri,Yijun Dai,Xiner Liu,Siyan Li,Xuanming Zhang,Renzhe Yu*

Main category: cs.CL

TL;DR: 提出诊断评估范式，通过人机协作分离任务固有模糊性与模型误差，改进主观标注任务中LLM性能评估


<details>
  <summary>Details</summary>
Motivation: LLM在主观标注任务（如心理建构）中表现不稳定，传统评估方法将所有误差合并为单一对齐指标，掩盖了不同类型误差对分析结论的不同影响

Method: 1) 二维诊断分类法：按来源（模型特定vs任务固有）和类型（边界模糊vs概念误识别）分类误差；2) 轻量级人工标注测试估计任务固有模糊性；3) 计算分解LLM标注误差的方法

Result: 在四个教育标注任务上验证了范式的概念有效性和实用价值，证明过高对齐期望不现实，单一对齐指标不足以反映LLM标注质量

Conclusion: 该范式可作为低成本诊断工具，评估任务是否适合LLM标注，并为技术优化提供可操作见解，推动主观标注任务的LLM应用

Abstract: Large language models offer a scalable alternative to human coding for data annotation tasks, enabling the scale-up of research across data-intensive domains. While LLMs are already achieving near-human accuracy on objective annotation tasks, their performance on subjective annotation tasks, such as those involving psychological constructs, is less consistent and more prone to errors. Standard evaluation practices typically collapse all annotation errors into a single alignment metric, but this simplified approach may obscure different kinds of errors that affect final analytical conclusions in different ways. Here, we propose a diagnostic evaluation paradigm that incorporates a human-in-the-loop step to separate task-inherent ambiguity from model-driven inaccuracies and assess annotation quality in terms of their potential downstream impacts. We refine this paradigm on ordinal annotation tasks, which are common in subjective annotation. The refined paradigm includes: (1) a diagnostic taxonomy that categorizes LLM annotation errors along two dimensions: source (model-specific vs. task-inherent) and type (boundary ambiguity vs. conceptual misidentification); (2) a lightweight human annotation test to estimate task-inherent ambiguity from LLM annotations; and (3) a computational method to decompose observed LLM annotation errors following our taxonomy. We validate this paradigm on four educational annotation tasks, demonstrating both its conceptual validity and practical utility. Theoretically, our work provides empirical evidence for why excessively high alignment is unrealistic in specific annotation tasks and why single alignment metrics inadequately reflect the quality of LLM annotations. In practice, our paradigm can be a low-cost diagnostic tool that assesses the suitability of a given task for LLM annotation and provides actionable insights for further technical optimization.

</details>


### [296] [Mapping the maturation of TCM as an adjuvant to radiotherapy](https://arxiv.org/abs/2601.11923)
*P. Bilha Githinji,Aikaterini Melliou,Xi Yuan,Dayan Zhang,Lian Zhang,Zhenglin Chen,Jiansong Ji,Chengying Lv,Jinhao Xu,Peiwu Qin,Dongmei Yu*

Main category: cs.CL

TL;DR: 该研究通过对69,745篇文献的大规模分析，揭示了中医药作为放疗辅助治疗的研究领域经历了周期性演变，形成了五个主导主题轴，显示出该领域已成熟并可能面临新的研究方向，同时存在系统性正向报告偏倚。


<details>
  <summary>Details</summary>
Motivation: 随着中医药在肿瘤综合治疗中的日益普及，需要系统性地梳理中医药作为放疗辅助治疗25年来的研究轨迹，了解该领域的发展模式、主题结构和潜在偏倚。

Method: 对2000-2025年间69,745篇出版物进行大规模文献计量分析，采用主题建模工作流程确定稳定的主题结构，识别主导主题轴，并分析出版产出、国际合作和资金投入的周期性演变模式。

Result: 研究发现该领域呈现"定义-构思-测试"模式的周期性演变，识别出五个主导主题轴：癌症类型、支持性护理、临床终点、机制和方法学。中医药的整合以患者为中心且系统导向，显示出渐进的专业化和潜在的研究议程饱和。同时发现存在跨出版类型、主题领域和演变周期的系统性正向报告偏倚。

Conclusion: 中医药作为放疗辅助治疗的研究领域已经成熟，当前研究议程可能接近饱和，正处于新研究方向的转折点。需要关注系统性正向报告偏倚问题，未来研究可能向新的方向演进。

Abstract: The integration of complementary medicine into oncology represents a paradigm shift that has seen to increasing adoption of Traditional Chinese Medicine (TCM) as an adjuvant to radiotherapy. About twenty-five years since the formal institutionalization of integrated oncology, it is opportune to synthesize the trajectory of evidence for TCM as an adjuvant to radiotherapy. Here we conduct a large-scale analysis of 69,745 publications (2000 - 2025), emerging a cyclical evolution defined by coordinated expansion and contraction in publication output, international collaboration, and funding commitments that mirrors a define-ideate-test pattern. Using a theme modeling workflow designed to determine a stable thematic structure of the field, we identify five dominant thematic axes - cancer types, supportive care, clinical endpoints, mechanisms, and methodology - that signal a focus on patient well-being, scientific rigor and mechanistic exploration. Cross-theme integration of TCM is patient-centered and systems-oriented. Together with the emergent cycles of evolution, the thematic structure demonstrates progressive specialization and potential defragmentation of the field or saturation of existing research agenda. The analysis points to a field that has matured its current research agenda and is likely at the cusp of something new. Additionally, the field exhibits positive reporting of findings that is homogeneous across publication types, thematic areas, and the cycles of evolution suggesting a system-wide positive reporting bias agnostic to structural drivers.

</details>


### [297] [Event Detection with a Context-Aware Encoder and LoRA for Improved Performance on Long-Tailed Classes](https://arxiv.org/abs/2601.11932)
*Abdullah Al Monsur,Nitesh Vamshi Bommisetty,Gene Louis Kim*

Main category: cs.CL

TL;DR: 该研究指出事件检测领域存在两大局限：解码器单向架构限制双向理解，以及Micro-F1偏向多数类的问题。通过引入句子上下文和LoRA微调，显著提升了模型在长尾事件类型上的Macro-F1表现。


<details>
  <summary>Details</summary>
Motivation: 事件检测研究存在两个关键局限：1）解码器单向LLMs架构无法充分利用双向上下文，限制了自然语言理解能力；2）传统依赖Micro-F1评估指标会系统性偏向多数类，无法真实反映模型在长尾事件类型上的表现。

Method: 1）使用句子上下文增强模型输入；2）采用Low-Rank Adaptation (LoRA)进行微调；3）以Macro-F1作为主要评估指标，关注模型在长尾事件类型上的表现。

Result: 实验表明：1）句子上下文增强的模型优于标准解码器基线；2）LoRA微调显著提升Macro-F1分数，特别是对解码器模型；3）LoRA能有效增强LLMs在长尾事件类别上的性能。

Conclusion: 研究证实了双向上下文对事件检测的重要性，并建议采用Macro-F1作为更公平的评估指标。LoRA微调是提升LLMs在长尾事件类别性能的有效工具，为事件检测研究提供了新的方向。

Abstract: The current state of event detection research has two notable re-occurring limitations that we investigate in this study. First, the unidirectional nature of decoder-only LLMs presents a fundamental architectural bottleneck for natural language understanding tasks that depend on rich, bidirectional context. Second, we confront the conventional reliance on Micro-F1 scores in event detection literature, which systematically inflates performance by favoring majority classes. Instead, we focus on Macro-F1 as a more representative measure of a model's ability across the long-tail of event types. Our experiments demonstrate that models enhanced with sentence context achieve superior performance over canonical decoder-only baselines. Using Low-Rank Adaptation (LoRA) during finetuning provides a substantial boost in Macro-F1 scores in particular, especially for the decoder-only models, showing that LoRA can be an effective tool to enhance LLMs' performance on long-tailed event classes.

</details>


### [298] [Double-Calibration: Towards Trustworthy LLMs via Calibrating Knowledge and Reasoning Confidence](https://arxiv.org/abs/2601.11956)
*Yuyin Lu,Ziran Liang,Yanghui Rao,Wenqi Fan,Fu Lee Wang,Qing Li*

Main category: cs.CL

TL;DR: DoublyCal是一个基于双重校准原则的框架，通过轻量级代理模型生成知识图谱证据和校准的证据置信度，从而提升黑盒大语言模型的准确性和置信度校准。


<details>
  <summary>Details</summary>
Motivation: 大语言模型存在幻觉问题，现有基于知识图谱增强的方法无法量化检索证据和模型推理过程中的认知不确定性，需要一种能够同时处理证据不确定性和模型推理不确定性的方法。

Method: DoublyCal采用双重校准原则：首先使用轻量级代理模型从知识图谱生成证据并校准证据置信度，然后用这些校准后的证据指导黑盒大语言模型生成最终预测，使置信度得分可追溯到支持证据的不确定性。

Result: 在知识密集型基准测试中，DoublyCal显著提高了黑盒大语言模型的准确性和置信度校准，同时保持了较低的token成本。

Conclusion: DoublyCal通过双重校准机制有效解决了知识图谱增强方法中的不确定性量化问题，为大语言模型提供了更可靠、可追溯的推理能力。

Abstract: Trustworthy reasoning in Large Language Models (LLMs) is challenged by their propensity for hallucination. While augmenting LLMs with Knowledge Graphs (KGs) improves factual accuracy, existing KG-augmented methods fail to quantify epistemic uncertainty in both the retrieved evidence and LLMs' reasoning. To bridge this gap, we introduce DoublyCal, a framework built on a novel double-calibration principle. DoublyCal employs a lightweight proxy model to first generate KG evidence alongside a calibrated evidence confidence. This calibrated supporting evidence then guides a black-box LLM, yielding final predictions that are not only more accurate but also well-calibrated, with confidence scores traceable to the uncertainty of the supporting evidence. Experiments on knowledge-intensive benchmarks show that DoublyCal significantly improves both the accuracy and confidence calibration of black-box LLMs with low token cost.

</details>


### [299] [PEARL: Self-Evolving Assistant for Time Management with Reinforcement Learning](https://arxiv.org/abs/2601.11957)
*Bingxuan Li,Jeonghwan Kim,Cheng Qian,Xiusi Chen,Eitan Anzenberg,Niran Kundapur,Heng Ji*

Main category: cs.CL

TL;DR: 该论文提出了CalConflictBench基准测试，用于评估LLM代理解决日历冲突的能力，并提出了PEARL强化学习框架来提升代理性能。


<details>
  <summary>Details</summary>
Motivation: 繁忙专业人士面临日历邀请冲突时需要反复决定参加、重新安排或拒绝哪些会议，这一决策过程耗时且人工委托难以扩展，因此需要研究LLM能否有效管理时间。

Method: 1. 引入CalConflictBench基准测试，以顺序方式呈现冲突并提供每轮反馈；2. 提出PEARL强化学习框架，为语言代理增加外部记忆模块和优化的轮次奖励设计。

Result: 当前LLM代理表现不佳（如Qwen-3-30B-Think平均错误率35%），而PEARL实现了0.76的错误减少率，相比最强基线平均错误率提升55%。

Conclusion: LLM代理在日历冲突解决方面仍有挑战，但通过PEARL的强化学习框架可以显著提升代理性能，使其能够动态推断和适应用户偏好。

Abstract: Overlapping calendar invitations force busy professionals to repeatedly decide which meetings to attend, reschedule, or decline. We refer to this preference-driven decision process as calendar conflict resolution. Automating such process is crucial yet challenging. Scheduling logistics drain hours, and human delegation often fails at scale, which motivate we to ask: Can we trust large language model (LLM) or language agent to manager time? To enable systematic study of this question, we introduce CalConflictBench, a benchmark for long-horizon calendar conflict resolution. Conflicts are presented sequentially and agents receive feedback after each round, requiring them to infer and adapt to user preferences progressively. Our experiments show that current LLM agents perform poorly with high error rates, e.g., Qwen-3-30B-Think has 35% average error rate. To address this gap, we propose PEARL, a reinforcement-learning framework that augments language agent with an external memory module and optimized round-wise reward design, enabling agent to progressively infer and adapt to user preferences on-the-fly. Experiments on CalConflictBench shows that PEARL achieves 0.76 error reduction rate, and 55% improvement in average error rate compared to the strongest baseline.

</details>


### [300] [$\texttt{MemoryRewardBench}$: Benchmarking Reward Models for Long-Term Memory Management in Large Language Models](https://arxiv.org/abs/2601.11969)
*Zecheng Tang,Baibei Ji,Ruoxi Sun,Haitian Wang,WangJie You,Zhang Yijun,Wenpeng Zhu,Ji Qi,Juntao Li,Min Zhang*

Main category: cs.CL

TL;DR: 首个系统研究奖励模型评估长时记忆管理能力的基准MemoryRewardBench，涵盖8K-128K上下文，发现开源与专有模型性能差距缩小


<details>
  <summary>Details</summary>
Motivation: 现有工作越来越多采用以内存为中心的机制分段处理长上下文，有效的内存管理是LLM在整个序列中传播信息的关键能力。因此，利用奖励模型自动可靠地评估内存质量至关重要

Method: 引入MemoryRewardBench基准，涵盖长上下文理解和长文本生成任务，包含10种不同内存管理模式的设置，上下文长度从8K到128K tokens

Result: 评估13个前沿奖励模型显示开源与专有模型性能差距正在缩小，新一代模型无论参数数量如何都持续优于前代模型，并揭示了当前奖励模型在评估LLM内存管理方面的能力和基本限制

Conclusion: MemoryRewardBench为系统研究奖励模型评估长时记忆管理能力提供了首个基准，揭示了当前模型的进展和局限，为未来改进提供了方向

Abstract: Existing works increasingly adopt memory-centric mechanisms to process long contexts in a segment manner, and effective memory management is one of the key capabilities that enables large language models to effectively propagate information across the entire sequence. Therefore, leveraging reward models (RMs) to automatically and reliably evaluate memory quality is critical. In this work, we introduce $\texttt{MemoryRewardBench}$, the first benchmark to systematically study the ability of RMs to evaluate long-term memory management processes. $\texttt{MemoryRewardBench}$ covers both long-context comprehension and long-form generation tasks, featuring 10 distinct settings with different memory management patterns, with context length ranging from 8K to 128K tokens. Evaluations on 13 cutting-edge RMs indicate a diminishing performance gap between open-source and proprietary models, with newer-generation models consistently outperforming their predecessors regardless of parameter count. We further expose the capabilities and fundamental limitations of current RMs in evaluating LLM memory management across diverse settings.

</details>


### [301] [Acting Flatterers via LLMs Sycophancy: Combating Clickbait with LLMs Opposing-Stance Reasoning](https://arxiv.org/abs/2601.12019)
*Chaowei Zhang,Xiansheng Luo,Zewei Zhang,Yi Zhu,Jipeng Qiang,Longwei Wang*

Main category: cs.CL

TL;DR: 本文提出SORG框架，利用LLMs的奉承倾向生成对立推理对，结合ORCD模型进行点击诱饵检测，在三个基准数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在线内容泛滥加剧了点击诱饵问题，LLMs虽有潜力但受奉承倾向影响，倾向于生成符合用户信念而非真实的推理。本文创新性地利用而非消除这种倾向来生成对立视角的对比推理。

Method: 提出SORG框架，引导LLMs为新闻标题生成高质量的支持与反对推理对（无需真实标签）。开发ORCD模型，使用三个BERT编码器分别表示标题及其推理，通过基于LLM生成可信度分数的软标签指导对比学习。

Result: 在三个基准数据集上的实验表明，该方法一致优于LLM提示、微调的小型语言模型以及最先进的点击诱饵检测基线方法。

Conclusion: 通过利用LLMs的奉承倾向生成对立推理，结合对比学习增强的检测模型，能够有效提升点击诱饵检测性能，为LLMs的"缺陷"提供了创新应用途径。

Abstract: The widespread proliferation of online content has intensified concerns about clickbait, deceptive or exaggerated headlines designed to attract attention. While Large Language Models (LLMs) offer a promising avenue for addressing this issue, their effectiveness is often hindered by Sycophancy, a tendency to produce reasoning that matches users' beliefs over truthful ones, which deviates from instruction-following principles. Rather than treating sycophancy as a flaw to be eliminated, this work proposes a novel approach that initially harnesses this behavior to generate contrastive reasoning from opposing perspectives. Specifically, we design a Self-renewal Opposing-stance Reasoning Generation (SORG) framework that prompts LLMs to produce high-quality agree and disagree reasoning pairs for a given news title without requiring ground-truth labels. To utilize the generated reasoning, we develop a local Opposing Reasoning-based Clickbait Detection (ORCD) model that integrates three BERT encoders to represent the title and its associated reasoning. The model leverages contrastive learning, guided by soft labels derived from LLM-generated credibility scores, to enhance detection robustness. Experimental evaluations on three benchmark datasets demonstrate that our method consistently outperforms LLM prompting, fine-tuned smaller language models, and state-of-the-art clickbait detection baselines.

</details>


### [302] [Preserving Fairness and Safety in Quantized LLMs Through Critical Weight Protection](https://arxiv.org/abs/2601.12033)
*Muhammad Alif Al Hakim,Alfan Farizki Wicaksono,Fajri Koto*

Main category: cs.CL

TL;DR: 量化会降低LLM的公平性和安全性，动态量化比静态量化更稳定，非英语环境安全性下降更严重，作者提出Critical Weight Protection方法缓解这些问题


<details>
  <summary>Details</summary>
Motivation: 量化被广泛用于降低大语言模型的计算成本，但其对公平性和安全性的影响，特别是在动态量化和多语言环境中的影响，尚未得到充分研究

Method: 系统研究静态和动态量化方法对公平性和安全性的影响，评估英语、法语、荷兰语、西班牙语、土耳其语的公平性，以及英语、韩语、阿拉伯语的安全性，并提出Critical Weight Protection技术来识别和保护公平性和安全性关键权重

Result: 量化会持续降低公平性和安全性，动态方法比静态方法更稳定；公平性下降在不同语言间有差异，安全性下降在非英语环境中尤为明显

Conclusion: 量化对LLM的公平性和安全性有负面影响，特别是在多语言环境中，提出的Critical Weight Protection方法能有效缓解偏差和安全性下降，无需昂贵的重新训练或对齐，在保持效率的同时维护可信度

Abstract: Quantization is widely adopted to reduce the computational cost of large language models (LLMs); however, its implications for fairness and safety, particularly in dynamic quantization and multilingual contexts, remain underexplored. In this work, we conduct a systematic study of how static and dynamic quantization methods impact fairness and safety across benchmarks measuring intrinsic and extrinsic bias and safety alignment. For fairness, we evaluate English, French, Dutch, Spanish, and Turkish; for safety, we focus on English, Korean, and Arabic. Our findings reveal that quantization consistently degrades fairness and safety, with dynamic methods demonstrating greater stability than static ones. Moreover, fairness degradation varies across languages, while safety deterioration is especially pronounced in non-English settings. To address these risks, we introduce Critical Weight Protection, a novel technique that identifies and preserves fairness- and safety-critical weights during quantization. This approach effectively mitigates bias and safety deterioration without costly retraining or alignment, maintaining trustworthiness while retaining efficiency.

</details>


### [303] [Don't Start Over: A Cost-Effective Framework for Migrating Personalized Prompts Between LLMs](https://arxiv.org/abs/2601.12034)
*Ziyi Zhao,Chongming Gao,Yang Zhang,Haoyan Liu,Weinan Gan,Huifeng Guo,Yong Liu,Fuli Feng*

Main category: cs.CL

TL;DR: PUMA框架通过轻量级适配器迁移个性化提示，解决大语言模型升级时用户软提示失效问题，减少98%计算成本


<details>
  <summary>Details</summary>
Motivation: 大语言模型升级时，用户特定的软提示会失效，需要昂贵的全量重新训练，这限制了个性化AI的可持续发展

Method: 提出Prompt-level User Migration Adapter (PUMA)框架，使用参数高效适配器桥接语义鸿沟，结合基于组的用户选择策略降低训练成本

Result: 在三个大规模数据集上，PUMA匹配甚至超过从头训练的性能，计算成本降低高达98%，在不同模型架构和链式/聚合迁移场景中表现出强泛化能力

Conclusion: PUMA通过将用户资产与底层模型解耦，为个性化AI的可持续演进提供了实用路径

Abstract: Personalization in Large Language Models (LLMs) often relies on user-specific soft prompts. However, these prompts become obsolete when the foundation model is upgraded, necessitating costly, full-scale retraining. To overcome this limitation, we propose the Prompt-level User Migration Adapter (PUMA), a lightweight framework to efficiently migrate personalized prompts across incompatible models. PUMA utilizes a parameter-efficient adapter to bridge the semantic gap, combined with a group-based user selection strategy to significantly reduce training costs. Experiments on three large-scale datasets show our method matches or even surpasses the performance of retraining from scratch, reducing computational cost by up to 98%. The framework demonstrates strong generalization across diverse model architectures and robustness in advanced scenarios like chained and aggregated migrations, offering a practical path for the sustainable evolution of personalized AI by decoupling user assets from the underlying models.

</details>


### [304] [Codebook-Injected Dialogue Segmentation for Multi-Utterance Constructs Annotation: LLM-Assisted and Gold-Label-Free Evaluation](https://arxiv.org/abs/2601.12061)
*Jinsook Lee,Kirk Vanacore,Zhuqian Zhou,Jeanine Grutter,Rene F. Kizilcec*

Main category: cs.CL

TL;DR: 论文提出了一种基于代码本注入的分割方法，通过将边界决策与下游标注标准相结合，评估了LLM分割器在对话行为标注中的表现，发现没有单一分割器在所有指标上占优，分割设计应根据下游目标优化。


<details>
  <summary>Details</summary>
Motivation: 传统对话行为标注通常将交际或教学意图局限于单个话语或轮次，导致标注者在底层动作上达成一致但在片段边界上存在分歧，降低了标注可靠性。需要改进分割方法以提高标注一致性。

Method: 提出代码本注入分割方法，将边界决策条件化于下游标注标准；评估LLM分割器与标准和检索增强基线的对比；引入无金标准评估指标：跨度一致性、区分度和人机分布一致性。

Result: DA感知分割器产生的片段内部一致性优于纯文本基线；LLM擅长创建结构一致的跨度，但基于连贯性的基线在检测对话流全局转变方面更优；在两个数据集上，没有单一分割器占主导地位；片段内连贯性的改进常以边界区分度和人机分布一致性为代价。

Conclusion: 分割是一个重要的设计选择，应根据下游目标进行优化，而不是追求单一性能分数。不同分割器在不同指标上各有优势，需要根据具体应用场景选择合适的方法。

Abstract: Dialogue Act (DA) annotation typically treats communicative or pedagogical intent as localized to individual utterances or turns. This leads annotators to agree on the underlying action while disagreeing on segment boundaries, reducing apparent reliability. We propose codebook-injected segmentation, which conditions boundary decisions on downstream annotation criteria, and evaluate LLM-based segmenters against standard and retrieval-augmented baselines. To assess these without gold labels, we introduce evaluation metrics for span consistency, distinctiveness, and human-AI distributional agreement. We found DA-awareness produces segments that are internally more consistent than text-only baselines. While LLMs excel at creating construct-consistent spans, coherence-based baselines remain superior at detecting global shifts in dialogue flow. Across two datasets, no single segmenter dominates. Improvements in within-segment coherence frequently trade off against boundary distinctiveness and human-AI distributional agreement. These results highlight segmentation as a consequential design choice that should be optimized for downstream objectives rather than a single performance score.

</details>


### [305] [Bridging the Gap in Bangla Healthcare: Machine Learning Based Disease Prediction Using a Symptoms-Disease Dataset](https://arxiv.org/abs/2601.12068)
*Rowzatul Zannat,Abdullah Al Shafi,Abdul Muntakim*

Main category: cs.CL

TL;DR: 开发了一个包含758个症状-疾病关系的孟加拉语数据集，用于基于症状预测疾病，通过集成学习方法达到98%准确率


<details>
  <summary>Details</summary>
Motivation: 孟加拉语人群缺乏可靠的疾病预测资源，需要解决这一语言障碍以提升医疗信息可及性

Method: 创建包含85种疾病、758个症状-疾病关系的孟加拉语数据集，评估多种机器学习模型，采用软硬投票集成方法

Result: 软硬投票集成方法均达到98%准确率，表现出优秀的鲁棒性和泛化能力

Conclusion: 该研究为孟加拉语疾病预测建立了基础资源，有助于提升孟加拉语社区的医疗信息公平获取和早期疾病检测

Abstract: Increased access to reliable health information is essential for non-English-speaking populations, yet resources in Bangla for disease prediction remain limited. This study addresses this gap by developing a comprehensive Bangla symptoms-disease dataset containing 758 unique symptom-disease relationships spanning 85 diseases. To ensure transparency and reproducibility, we also make our dataset publicly available. The dataset enables the prediction of diseases based on Bangla symptom inputs, supporting healthcare accessibility for Bengali-speaking populations. Using this dataset, we evaluated multiple machine learning models to predict diseases based on symptoms provided in Bangla and analyzed their performance on our dataset. Both soft and hard voting ensemble approaches combining top-performing models achieved 98\% accuracy, demonstrating superior robustness and generalization. Our work establishes a foundational resource for disease prediction in Bangla, paving the way for future advancements in localized health informatics and diagnostic tools. This contribution aims to enhance equitable access to health information for Bangla-speaking communities, particularly for early disease detection and healthcare interventions.

</details>


### [306] [To Copy or Not to Copy: Copying Is Easier to Induce Than Recall](https://arxiv.org/abs/2601.12075)
*Mehrdad Farahani,Franziska Penzkofer,Richard Johansson*

Main category: cs.CL

TL;DR: 该论文提出了一种从语言模型激活中提取"仲裁向量"的方法，用于控制模型在检索增强设置中参数知识与上下文信息之间的权衡，实验表明诱导复制行为比恢复参数召回更容易实现。


<details>
  <summary>Details</summary>
Motivation: 在检索增强设置中，语言模型需要在参数知识（存储在权重中）和上下文信息（在提示中）之间进行仲裁。目前缺乏对这种选择机制的深入理解，需要研究模型如何在相关与不相关、真实与虚假上下文之间做出决策。

Method: 1. 构建专门的数据集来区分两种情境：无关上下文（引发参数召回）和相关但虚假上下文（引发复制）；2. 从模型激活中提取"仲裁向量"，计算为这两种机制在27种关系上的残差流质心差异；3. 将向量作为加性干预注入到选定层和标记跨度中，以引导行为向两个方向转变：复制→召回（抑制上下文使用）和召回→复制（诱导模型复制上下文中的任何标记）。

Result: 在两个架构（仅解码器和编码器/解码器）和两个开放域QA基准测试中，实验显示在适度扩展下行为转变一致，同时监控准确性和流畅性。机制分析揭示了不对称性：诱导复制是一个容易的"再激活"过程，可以在输入的不同位置触发；而恢复召回是一个更脆弱的"抑制"过程，与对象标记干预密切相关。

Conclusion: 该研究提供了一种机制性方法来理解和控制语言模型在参数知识与上下文信息之间的仲裁行为。发现诱导复制行为相对容易，而抑制上下文使用以恢复参数召回则更为脆弱，这为理解模型决策机制和开发更可控的检索增强系统提供了重要见解。

Abstract: Language models used in retrieval-augmented settings must arbitrate between parametric knowledge stored in their weights and contextual information in the prompt. This work presents a mechanistic study of that choice by extracting an \emph{arbitration vector} from model activations on a curated dataset designed to disentangle (i) irrelevant contexts that elicit parametric recall and (ii) relevant but false contexts that elicit copying. The vector is computed as the residual-stream centroid difference between these regimes across 27 relations, and is injected as an additive intervention at selected layers and token spans to steer behavior in two directions: Copy$\rightarrow$Recall (suppressing context use) and Recall$\rightarrow$Copy (inducing the model to copy any token from the context). Experiments on two architectures (decoder-only and encoder/decoder) and two open-domain QA benchmarks show consistent behavior shifts under moderate scaling while monitoring accuracy and fluency. Mechanistic analyses of attention routing, MLP contributions, and layer-wise probability trajectories reveal an asymmetry: inducing copying is an easy ``reactivation'' process that can be triggered at different locations in the input, while restoring recall is a ``suppression'' process that is more fragile and strongly tied to object-token interventions.

</details>


### [307] [Optimizing User Profiles via Contextual Bandits for Retrieval-Augmented LLM Personalization](https://arxiv.org/abs/2601.12078)
*Linfeng Du,Ye Yuan,Zichen Zhao,Fuyuan Lyu,Emiliano Penaloza,Xiuying Chen,Zipeng Sun,Jikun Kang,Laurent Charlin,Xue Liu,Haolun Wu*

Main category: cs.CL

TL;DR: PURPLE框架通过上下文老虎机优化LLM个性化，将用户档案构建视为集合生成过程，使用Plackett-Luce排序模型捕捉记录间依赖关系，直接对齐检索与生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有基于语义相关性的检索增强方法存在局限性，因为相关性并不能可靠地代表效用——语义相似的记录可能因冗余或冲突信息而无法改善甚至降低生成质量。

Method: 提出PURPLE框架，将用户档案构建视为集合生成过程，使用Plackett-Luce排序模型捕捉复杂记录间依赖关系，通过参考响应的似然度作为密集反馈进行训练。

Result: 在九个个性化任务上的广泛实验表明，PURPLE在效果和效率上持续优于强启发式和检索增强基线方法。

Conclusion: PURPLE为优化用户档案提供了一个原则性和可扩展的解决方案，通过直接对齐检索与生成质量来改进LLM个性化。

Abstract: Large Language Models (LLMs) excel at general-purpose tasks, yet adapting their responses to individual users remains challenging. Retrieval augmentation provides a lightweight alternative to fine-tuning by conditioning LLMs on user history records, and existing approaches typically select these records based on semantic relevance. We argue that relevance serves as an unreliable proxy for utility: a record may be semantically similar to a query yet fail to improve generation quality or even degrade it due to redundancy or conflicting information. To bridge this gap, we propose PURPLE, a contextual bandit framework that oPtimizes UseR Profiles for Llm pErsonalization. In contrast to a greedy selection of the most relevant records, PURPLE treats profile construction as a set generation process and utilizes a Plackett-Luce ranking model to capture complex inter-record dependencies. By training with dense feedback provided by the likelihood of the reference response, our method aligns retrieval directly with generation quality. Extensive experiments on nine personalization tasks demonstrate that PURPLE consistently outperforms strong heuristic and retrieval-augmented baselines in both effectiveness and efficiency, establishing a principled and scalable solution for optimizing user profiles.

</details>


### [308] [Large language models struggle with ethnographic text annotation](https://arxiv.org/abs/2601.12099)
*Leonardo S. Goodall,Dor Shilton,Daniel A. Mullins,Harvey Whitehouse*

Main category: cs.CL

TL;DR: LLMs在民族志文本标注任务中表现有限，无法替代人类专家，性能远低于可靠自动标注所需水平


<details>
  <summary>Details</summary>
Motivation: 评估LLMs在跨文化研究中自动提取民族志文本结构化数据的潜力，希望加速民族志研究

Method: 使用7个最先进的LLMs对567个民族志摘录的121个仪式特征进行标注，并与人类编码者可靠性对比

Result: LLMs性能有限，远低于可靠自动标注要求；长文本、需要序数区分的特征和模糊概念特别困难；人类编码者可靠性为LLM准确性设定了上限

Conclusion: LLMs目前尚不能替代人类专家进行民族志标注，需要更多研究改进模型在复杂文化特征提取方面的能力

Abstract: Large language models (LLMs) have shown promise for automated text annotation, raising hopes that they might accelerate cross-cultural research by extracting structured data from ethnographic texts. We evaluated 7 state-of-the-art LLMs on their ability to annotate 121 ritual features across 567 ethnographic excerpts. Performance was limited, falling well below levels required for reliable automated annotation. Longer texts, features requiring ordinal distinctions, and ambiguous constructs proved particularly difficult. Human inter-coder reliability set an approximate ceiling on LLM accuracy: features that human coders found difficult to agree upon were also difficult for LLMs. Yet even on features where humans reliably agreed, models fell short of human performance. Our findings suggest that LLMs cannot yet substitute for human expertise in ethnographic annotation.

</details>


### [309] [Powerful Training-Free Membership Inference Against Autoregressive Language Models](https://arxiv.org/abs/2601.12104)
*David Ilić,David Stanojević,Kostadin Cvejoski*

Main category: cs.CL

TL;DR: EZ-MIA是一种新型成员推理攻击方法，通过分析模型在错误位置的概率偏移来检测训练数据中的成员信息，相比现有方法在低误报率下实现3-8倍的检测率提升。


<details>
  <summary>Details</summary>
Motivation: 微调语言模型存在隐私风险，可能记忆并泄露训练数据中的敏感信息。现有的成员推理攻击方法检测率有限，特别是在实际隐私审计所需的低误报率阈值下表现不佳。

Method: 提出EZ-MIA攻击方法，核心是错误区域分数：测量微调模型相对于预训练参考模型在错误位置（模型预测错误但概率仍较高的token）上的概率偏移方向不平衡性。该方法只需两次前向传播，无需任何模型训练。

Result: 在WikiText数据集和GPT-2上，EZ-MIA在1%误报率下达到66.3%真阳性率（相比SOTA的17.5%提升3.8倍），AUC为0.98。在更严格的0.1%误报率下达到14.0%（相比1.8%提升8倍）。在AG News数据集和Llama-2-7B上，1%误报率下达到46.7%真阳性率（相比15.8%提升3倍）。

Conclusion: 微调语言模型的隐私风险比先前理解的要大得多，EZ-MIA为隐私审计和部署决策提供了更有效的评估工具，表明需要重新评估模型隐私保护措施。

Abstract: Fine-tuned language models pose significant privacy risks, as they may memorize and expose sensitive information from their training data. Membership inference attacks (MIAs) provide a principled framework for auditing these risks, yet existing methods achieve limited detection rates, particularly at the low false-positive thresholds required for practical privacy auditing. We present EZ-MIA, a membership inference attack that exploits a key observation: memorization manifests most strongly at error positions, specifically tokens where the model predicts incorrectly yet still shows elevated probability for training examples. We introduce the Error Zone (EZ) score, which measures the directional imbalance of probability shifts at error positions relative to a pretrained reference model. This principled statistic requires only two forward passes per query and no model training of any kind. On WikiText with GPT-2, EZ-MIA achieves 3.8x higher detection than the previous state-of-the-art under identical conditions (66.3% versus 17.5% true positive rate at 1% false positive rate), with near-perfect discrimination (AUC 0.98). At the stringent 0.1% FPR threshold critical for real-world auditing, we achieve 8x higher detection than prior work (14.0% versus 1.8%), requiring no reference model training. These gains extend to larger architectures: on AG News with Llama-2-7B, we achieve 3x higher detection (46.7% versus 15.8% TPR at 1% FPR). These results establish that privacy risks of fine-tuned language models are substantially greater than previously understood, with implications for both privacy auditing and deployment decisions. Code is available at https://github.com/JetBrains-Research/ez-mia.

</details>


### [310] [Bengali Text Classification: An Evaluation of Large Language Model Approaches](https://arxiv.org/abs/2601.12132)
*Md Mahmudul Hoque,Md Mehedi Hassain,Md Hojaifa Tanvir,Rahul Nandy*

Main category: cs.CL

TL;DR: 本研究评估了三种指令调优大语言模型（LLaMA 3.1 8B、LLaMA 3.2 3B、Qwen 2.5 7B）在孟加拉语新闻文章分类任务上的表现，Qwen 2.5以72%的准确率表现最佳。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语文本分类面临缺乏大规模标注数据集和预训练语言模型的挑战，本研究旨在探索大语言模型在孟加拉语新闻分类任务中的有效性。

Method: 使用来自Kaggle的Prothom Alo新闻文章数据集，在相同分类框架下评估三种指令调优LLM：LLaMA 3.1 8B Instruct、LLaMA 3.2 3B Instruct和Qwen 2.5 7B Instruct。

Result: Qwen 2.5取得了最高的72%分类准确率，在"体育"类别表现尤为突出；LLaMA 3.1和LLaMA 3.2分别获得53%和56%的准确率。

Conclusion: 尽管孟加拉语NLP资源稀缺，大语言模型在孟加拉语文本分类中仍表现出有效性。未来研究将探索更多模型、解决类别不平衡问题并改进微调方法以提升性能。

Abstract: Bengali text classification is a Significant task in natural language processing (NLP), where text is categorized into predefined labels. Unlike English, Bengali faces challenges due to the lack of extensive annotated datasets and pre-trained language models. This study explores the effectiveness of large language models (LLMs) in classifying Bengali newspaper articles. The dataset used, obtained from Kaggle, consists of articles from Prothom Alo, a major Bangladeshi newspaper. Three instruction-tuned LLMs LLaMA 3.1 8B Instruct, LLaMA 3.2 3B Instruct, and Qwen 2.5 7B Instruct were evaluated for this task under the same classification framework. Among the evaluated models, Qwen 2.5 achieved the highest classification accuracy of 72%, showing particular strength in the "Sports" category. In comparison, LLaMA 3.1 and LLaMA 3.2 attained accuracies of 53% and 56%, respectively. The findings highlight the effectiveness of LLMs in Bengali text classification, despite the scarcity of resources for Bengali NLP. Future research will focus on exploring additional models, addressing class imbalance issues, and refining fine-tuning approaches to improve classification performance.

</details>


### [311] [Analyzing Cancer Patients' Experiences with Embedding-based Topic Modeling and LLMs](https://arxiv.org/abs/2601.12154)
*Teodor-Călin Ionescu,Lifeng Han,Jan Heijdra Suasnabar,Anne Stiggelbout,Suzan Verberne*

Main category: cs.CL

TL;DR: 本研究探索使用神经主题建模（BERTopic）和LLMs分析癌症患者访谈数据，以提取有意义的主题，促进以患者为中心的医疗实践。


<details>
  <summary>Details</summary>
Motivation: 从患者叙事数据中提取有价值信息，为临床实践提供患者视角的洞察，增强患者声音在医疗决策中的作用。

Method: 1. 比较BERTopic和Top2Vec在单个访谈摘要中的表现；2. 使用GPT-4进行主题标注；3. 通过人工评估（连贯性、清晰度、相关性）选择最佳方法；4. 使用三种临床导向嵌入模型（包括BioClinicalBERT）分析完整数据集。

Result: BERTopic表现优于Top2Vec；领域特定嵌入（特别是BioClinicalBERT）提高了主题精度和可解释性；全局分析识别出两个主导主题：癌症护理管理中的协调与沟通、癌症治疗旅程中的患者决策。

Conclusion: 神经主题建模（特别是BERTopic）能够从患者访谈中提取有用信息，为临床医生提供反馈，支持更高效的文档导航，增强患者声音在医疗工作流程中的作用。

Abstract: This study investigates the use of neural topic modeling and LLMs to uncover meaningful themes from patient storytelling data, to offer insights that could contribute to more patient-oriented healthcare practices. We analyze a collection of transcribed interviews with cancer patients (132,722 words in 13 interviews). We first evaluate BERTopic and Top2Vec for individual interview summarization by using similar preprocessing, chunking, and clustering configurations to ensure a fair comparison on Keyword Extraction. LLMs (GPT4) are then used for the next step topic labeling. Their outputs for a single interview (I0) are rated through a small-scale human evaluation, focusing on {coherence}, {clarity}, and {relevance}. Based on the preliminary results and evaluation, BERTopic shows stronger performance and is selected for further experimentation using three {clinically oriented embedding} models. We then analyzed the full interview collection with the best model setting. Results show that domain-specific embeddings improved topic \textit{precision} and \textit{interpretability}, with BioClinicalBERT producing the most consistent results across transcripts. The global analysis of the full dataset of 13 interviews, using the BioClinicalBERT embedding model, reveals the most dominant topics throughout all 13 interviews, namely ``Coordination and Communication in Cancer Care Management" and ``Patient Decision-Making in Cancer Treatment Journey''. Although the interviews are machine translations from Dutch to English, and clinical professionals are not involved in this evaluation, the findings suggest that neural topic modeling, particularly BERTopic, can help provide useful feedback to clinicians from patient interviews. This pipeline could support more efficient document navigation and strengthen the role of patients' voices in healthcare workflows.

</details>


### [312] [Tolerance Principle and Small Language Model Learning](https://arxiv.org/abs/2601.12179)
*Adam E. Friedman,Stevan Harnad,Rushen Shi*

Main category: cs.CL

TL;DR: 研究测试了BabyBERTa模型在人工语法学习中的表现，发现其学习动态与人类婴儿不同，不符合容忍原则的预测。


<details>
  <summary>Details</summary>
Motivation: 现代语言模型需要大量训练数据，而人类婴儿能从少量示例中学习抽象语法规则，即使在有例外的情况下。本研究旨在探索Transformer模型需要多少训练数据才能泛化规则，并测试容忍原则的预测。

Method: 使用BabyBERTa（专为小数据集优化的Transformer模型）在人工语法上进行训练。训练集在大小、独特句子类型数量和规则遵循与例外示例比例上有所不同。

Result: 研究发现，与人类婴儿不同，BabyBERTa的学习动态不符合容忍原则的预测。

Conclusion: Transformer语言模型的学习机制与人类婴儿的语法学习存在差异，模型无法像人类那样从少量示例中有效学习抽象语法规则。

Abstract: Modern language models like GPT-3, BERT, and LLaMA require massive training data, yet with sufficient training they reliably learn to distinguish grammatical from ungrammatical sentences. Children aged as young as 14 months already have the capacity to learn abstract grammar rules from very few exemplars, even in the presence of non-rule-following exceptions. Yang's (2016) Tolerance Principle defines a precise threshold for how many exceptions a rule can tolerate and still be learnable. The present study explored the minimal amount and quality of training data necessary for rules to be generalized by a transformer-based language model to test the predictions of the Tolerance Principle. We trained BabyBERTa (Huebner et al. 2021), a transformer model optimized for small datasets, on artificial grammars. The training sets varied in size, number of unique sentence types, and proportion of rule-following versus exception exemplars. We found that, unlike human infants, BabyBERTa's learning dynamics do not align with the Tolerance Principle.

</details>


### [313] [CTC-DID: CTC-Based Arabic dialect identification for streaming applications](https://arxiv.org/abs/2601.12199)
*Muhammad Umar Farooq,Oscar Saz*

Main category: cs.CL

TL;DR: 提出基于CTC损失的方言识别方法，将方言识别任务视为有限词汇的语音识别系统，在低资源阿拉伯方言识别任务中表现优于现有模型


<details>
  <summary>Details</summary>
Motivation: 传统方言识别方法在低资源场景下性能有限，需要一种更有效的方法来处理方言识别任务，特别是对于短语音和实时应用场景

Method: 采用CTC损失函数框架，将方言标签视为语音序列的标签，使用语言无关启发式方法或预训练ASR模型估计方言标签在转录中的重复次数，构建SSL-based CTC-DID模型

Result: 在低资源阿拉伯方言识别任务中，CTC-DID模型在有限数据集上训练后，性能优于微调的Whisper和ECAPA-TDNN模型，在Casablanca数据集上的零样本评估也表现更优，对短语音更鲁棒且易于适配实时流式应用

Conclusion: CTC-DID方法为方言识别提供了一种有效的解决方案，特别适合低资源场景，具有鲁棒性强、易于适配实时应用的优点，为方言识别任务开辟了新方向

Abstract: This paper proposes a Dialect Identification (DID) approach inspired by the Connectionist Temporal Classification (CTC) loss function as used in Automatic Speech Recognition (ASR). CTC-DID frames the dialect identification task as a limited-vocabulary ASR system, where dialect tags are treated as a sequence of labels for a given utterance. For training, the repetition of dialect tags in transcriptions is estimated either using a proposed Language-Agnostic Heuristic (LAH) approach or a pre-trained ASR model. The method is evaluated on the low-resource Arabic Dialect Identification (ADI) task, with experimental results demonstrating that an SSL-based CTC-DID model, trained on a limited dataset, outperforms both fine-tuned Whisper and ECAPA-TDNN models. Notably, CTC-DID also surpasses these models in zero-shot evaluation on the Casablanca dataset. The proposed approach is found to be more robust to shorter utterances and is shown to be easily adaptable for streaming, real-time applications, with minimal performance degradation.

</details>


### [314] [CoReflect: Conversational Evaluation via Co-Evolutionary Simulation and Reflective Rubric Refinement](https://arxiv.org/abs/2601.12208)
*Yunzhe Li,Richie Yueqi Feng,Tianxin Wei,Chin-Chia Hsu*

Main category: cs.CL

TL;DR: CoReflect：通过协同进化模拟和反思性评估准则优化，实现对话系统多轮评估的自适应迭代方法


<details>
  <summary>Details</summary>
Motivation: 传统对话系统评估方法依赖人工定义的固定评估准则和静态对话上下文，覆盖范围有限，无法捕捉对话模型多样化的涌现行为，需要更自适应、可扩展的评估框架。

Method: CoReflect将对话模拟和评估统一为自适应迭代过程：1）对话规划器生成结构化模板指导用户模拟器进行多样化目标导向对话；2）反思分析器处理对话，识别系统性行为模式并自动优化评估准则；3）分析结果反馈给规划器更新对话模板，形成协同进化循环。

Result: 该方法通过最小化人工干预，提供了可扩展、自我优化的评估方法，使评估协议能够适应对话模型快速发展的能力，测试案例的复杂性和评估准则的诊断精度同步提升。

Conclusion: CoReflect通过协同进化模拟和反思性评估准则优化，解决了多轮对话系统评估的根本挑战，为对话模型的快速发展提供了自适应、可扩展的评估框架。

Abstract: Evaluating conversational systems in multi-turn settings remains a fundamental challenge. Conventional pipelines typically rely on manually defined rubrics and fixed conversational context$-$a static approach that limits coverage and fails to capture the diverse, emergent behaviors of dialogue models. To address this, we introduce CoReflect (Conversational Evaluation via Co-Evolutionary Simulation and Reflective Rubric Refinement), which unifies dialogue simulation and evaluation into an adaptive, iterative process. CoReflect employs a conversation planner that generates structured templates to guide a user simulator through diverse, goal-directed dialogues. Subsequently, a reflective analyzer processes these dialogues to identify systematic behavioral patterns and automatically refine the evaluation rubrics. Crucially, the insights from the conversation analysis are fed back into the planner to update conversation templates for subsequent iterations. This co-evolution loop ensures that the complexity of test cases and the diagnostic precision of rubrics improve in tandem. By minimizing human intervention, CoReflect provides a scalable and self-refining methodology that allows evaluation protocols to adapt alongside the rapidly advancing capabilities of dialogue models.

</details>


### [315] [Plan, Verify and Fill: A Structured Parallel Decoding Approach for Diffusion Language Models](https://arxiv.org/abs/2601.12247)
*Miao Li,Hanyang Jiang,Sikai Chen,Hengyu Fu,Yuhang Cai,Baihe Huang,Tinghan Ye,Xuanzhou Chen,Pascal Van Hentenryck*

Main category: cs.CL

TL;DR: PVF是一种无需训练的解码范式，通过规划-验证-填充三阶段，利用全局双向上下文主动构建层次化骨架，显著减少扩散语言模型的函数评估次数。


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型提供了不同于自回归模型的新型文本生成范式，但现有解码策略往往被动反应，未能充分利用全局双向上下文来指导生成轨迹，导致效率不高。

Method: 提出Plan-Verify-Fill（PVF）范式：1）规划阶段：主动构建层次化骨架，优先选择高影响力的语义锚点；2）验证阶段：实施实用结构停止协议，当进一步思考收益递减时停止；3）填充阶段：基于已验证的骨架完成文本生成。

Result: 在LLaDA-8B-Instruct和Dream-7B-Instruct上的评估显示，PVF相比基于置信度的并行解码，函数评估次数（NFE）减少高达65%，在保持准确性的同时实现了显著效率提升。

Conclusion: PVF通过主动规划和验证机制，有效利用了扩散语言模型的全局双向上下文优势，为DLM解码提供了高效且无需训练的解决方案，在效率与准确性间取得了良好平衡。

Abstract: Diffusion Language Models (DLMs) present a promising non-sequential paradigm for text generation, distinct from standard autoregressive (AR) approaches. However, current decoding strategies often adopt a reactive stance, underutilizing the global bidirectional context to dictate global trajectories. To address this, we propose Plan-Verify-Fill (PVF), a training-free paradigm that grounds planning via quantitative validation. PVF actively constructs a hierarchical skeleton by prioritizing high-leverage semantic anchors and employs a verification protocol to operationalize pragmatic structural stopping where further deliberation yields diminishing returns. Extensive evaluations on LLaDA-8B-Instruct and Dream-7B-Instruct demonstrate that PVF reduces the Number of Function Evaluations (NFE) by up to 65% compared to confidence-based parallel decoding across benchmark datasets, unlocking superior efficiency without compromising accuracy.

</details>


### [316] [Multimodal Generative Engine Optimization: Rank Manipulation for Vision-Language Model Rankers](https://arxiv.org/abs/2601.12263)
*Yixuan Du,Chenxiao Yu,Haoyan Xu,Ziyi Wang,Yue Zhao,Xiyang Hu*

Main category: cs.CL

TL;DR: MGEO是一种针对视觉语言模型产品搜索系统的多模态对抗攻击框架，通过联合优化图像扰动和文本后缀来不公平地提升目标产品排名


<details>
  <summary>Details</summary>
Motivation: 虽然视觉语言模型在检索和推荐系统中应用广泛，但其在竞争性排名场景下对抗操纵的鲁棒性尚未充分探索。本文旨在揭示VLM产品搜索中的多模态排名攻击漏洞

Method: 提出多模态生成引擎优化（MGEO）框架，采用交替梯度优化策略，联合优化不可感知的图像扰动和流畅的文本后缀，利用VLM内部的深度跨模态耦合

Result: 在真实数据集和先进模型上的实验表明，MGEO协调攻击显著优于仅文本或仅图像的基线方法，成功揭示了多模态协同可能被武器化的问题

Conclusion: 多模态协同这一VLM的优势特性可能被用来破坏搜索排名的完整性，而不会触发传统内容过滤器，这对VLM在竞争性排名场景中的安全性提出了重要警示

Abstract: Vision-Language Models (VLMs) are rapidly replacing unimodal encoders in modern retrieval and recommendation systems. While their capabilities are well-documented, their robustness against adversarial manipulation in competitive ranking scenarios remains largely unexplored. In this paper, we uncover a critical vulnerability in VLM-based product search: multimodal ranking attacks. We present Multimodal Generative Engine Optimization (MGEO), a novel adversarial framework that enables a malicious actor to unfairly promote a target product by jointly optimizing imperceptible image perturbations and fluent textual suffixes. Unlike existing attacks that treat modalities in isolation, MGEO employs an alternating gradient-based optimization strategy to exploit the deep cross-modal coupling within the VLM. Extensive experiments on real-world datasets using state-of-the-art models demonstrate that our coordinated attack significantly outperforms text-only and image-only baselines. These findings reveal that multimodal synergy, typically a strength of VLMs, can be weaponized to compromise the integrity of search rankings without triggering conventional content filters.

</details>


### [317] [Simulated Annealing Enhances Theory-of-Mind Reasoning in Autoregressive Language Models](https://arxiv.org/abs/2601.12269)
*Xucong Hu,Jian-Qiao Zhu*

Main category: cs.CL

TL;DR: 通过MCMC采样和退火技术，无需额外训练即可从基础语言模型中恢复强大的心理理论能力


<details>
  <summary>Details</summary>
Motivation: 自回归语言模型通常被认为是下一个token预测器，主要优化表面合理性而非保持正确的潜在状态表示，因此在心理理论任务上表现不佳。虽然后训练方法可以改进心理理论性能，但本文探索是否可以直接从基础模型中恢复这种能力而无需额外权重更新或验证。

Method: 基于Karan & Du (2025)的power-sampling方法，使用马尔可夫链蒙特卡洛从自回归语言模型的序列级概率分布中采样。进一步引入退火技术，将温度分布从高到低逐渐调整，显著改进了固定温度power sampling的心理理论性能。

Result: 研究表明，通过采样优化方法可以从语言模型中提取潜在能力而无需重新训练。退火技术的加入显著提升了心理理论任务的性能表现。

Conclusion: 采样优化提供了一种强大的方式，无需重新训练即可从语言模型中提取潜在能力，特别是心理理论能力，这对理解语言模型的推理能力具有重要意义。

Abstract: Autoregressive language models are next-token predictors and have been criticized for only optimizing surface plausibility (i.e., local coherence) rather than maintaining correct latent-state representations (i.e., global coherence). Because Theory of Mind (ToM) tasks crucially depend on reasoning about latent mental states of oneself and others, such models are therefore often thought to fail at ToM. While post-training methods can improve ToM performance, we show that strong ToM capability can be recovered directly from the base model without any additional weight updates or verifications. Our approach builds on recent power-sampling methods (Karan & Du, 2025) that use Markov chain Monte Carlo (MCMC) to sample from sharpened sequence-level (rather than token-level) probability distributions of autoregressive language models. We further find that incorporating annealing, where the tempered distribution is gradually shifted from high to low temperature, substantially improves ToM performance over fixed-temperature power sampling. Together, these results suggest that sampling-based optimization provides a powerful way to extract latent capabilities from language models without retraining.

</details>


### [318] [Conversational Context Classification: A Representation Engineering Approach](https://arxiv.org/abs/2601.12286)
*Jonathan Pan*

Main category: cs.CL

TL;DR: 使用表征工程和单类支持向量机在LLM内部状态中识别特定上下文子空间，用于检测对话是否偏离上下文


<details>
  <summary>Details</summary>
Motivation: 大型语言模型日益普及需要有效保障机制，特别是检测其生成偏离上下文回复（如话题转移、事实错误、幻觉）的能力。传统异常检测方法难以直接应用于上下文语义分析。

Method: 结合表征工程和单类支持向量机，在LLM内部状态中识别特定上下文子空间。通过上下文示例训练OCSVM，在LLM隐藏状态潜在空间中建立鲁棒边界。使用Llama和Qwen开源模型在特定领域评估，识别与上下文关联最强的内部状态层。

Result: 评估结果显示在识别特定上下文子空间方面有良好效果。该方法不仅可用于检测对话是否在上下文内，也有助于更好地解释LLM的内部工作机制。

Conclusion: 该方法为LLM上下文检测提供了有效途径，同时为理解LLM内部表征机制做出了贡献，有助于开发更可靠的LLM安全保障机制。

Abstract: The increasing prevalence of Large Language Models (LLMs) demands effective safeguards for their operation, particularly concerning their tendency to generate out-of-context responses. A key challenge is accurately detecting when LLMs stray from expected conversational norms, manifesting as topic shifts, factual inaccuracies, or outright hallucinations. Traditional anomaly detection struggles to directly apply within contextual semantics. This paper outlines our experiment in exploring the use of Representation Engineering (RepE) and One-Class Support Vector Machine (OCSVM) to identify subspaces within the internal states of LLMs that represent a specific context. By training OCSVM on in-context examples, we establish a robust boundary within the LLM's hidden state latent space. We evaluate out study with two open source LLMs - Llama and Qwen models in specific contextual domain. Our approach entailed identifying the optimal layers within the LLM's internal state subspaces that strongly associates with the context of interest. Our evaluation results showed promising results in identifying the subspace for a specific context. Aside from being useful in detecting in or out of context conversation threads, this research work contributes to the study of better interpreting LLMs.

</details>


### [319] [Can Deep Research Agents Find and Organize? Evaluating the Synthesis Gap with Expert Taxonomies](https://arxiv.org/abs/2601.12369)
*Ming Zhang,Jiabao Zhuang,Wenqing Jing,Ziyu Kong,Jingyi Deng,Yujiong Shen,Kexin Tan,Yuhang Zhao,Ning Luo,Renzhe Zheng,Jiahui Lin,Mingqi Wu,Long Ma,Yi Zou,Shihan Dou,Tao Gui,Qi Zhang,Xuanjing Huang*

Main category: cs.CL

TL;DR: TaxoBench：首个诊断性基准，评估深度研究代理在检索关键论文和组织知识结构方面的能力，发现当前代理与专家级调研写作仍有巨大差距


<details>
  <summary>Details</summary>
Motivation: 深度研究代理被广泛用于自动生成调研报告，但现有基准主要关注流畅性或引用准确性，缺乏对核心能力（检索关键论文和组织知识结构）的评估。需要建立一个诊断性基准来衡量代理是否能像人类专家一样撰写调研报告。

Method: 从72篇高引用计算机科学调研报告中手动提取专家构建的分类树，包含3,815个精确分类的引用作为基准。支持两种评估模式：深度研究模式（端到端检索和组织）和自底向上模式（隔离组织结构能力）。评估了7个领先的深度研究代理和12个前沿LLM。

Result: 结果显示双重瓶颈：最佳代理仅能召回20.9%的专家选择论文；即使提供完美输入，最佳模型在组织结构方面仅达到0.31 ARI（调整兰德指数）。当前深度研究代理与专家级调研写作仍有很大差距。

Conclusion: TaxoBench是首个诊断性基准，揭示了深度研究代理在检索和组织能力上的严重不足。当前代理远未达到专家级调研写作水平，该基准为未来研究提供了重要评估工具。

Abstract: Deep Research Agents are increasingly used for automated survey generation. However, whether they can write surveys like human experts remains unclear. Existing benchmarks focus on fluency or citation accuracy, but none evaluates the core capabilities: retrieving essential papers and organizing them into coherent knowledge structures. We introduce TaxoBench, a diagnostic benchmark derived from 72 highly-cited computer science surveys. We manually extract expert-authored taxonomy trees containing 3,815 precisely categorized citations as ground truth. Our benchmark supports two evaluation modes: Deep Research mode tests end-to-end retrieval and organization given only a topic, while Bottom-Up mode isolates structuring capability by providing the exact papers human experts used. We evaluate 7 leading Deep Research agents and 12 frontier LLMs. Results reveal a dual bottleneck: the best agent recalls only 20.9% of expert-selected papers, and even with perfect input, the best model achieves only 0.31 ARI in organization. Current deep research agents remain far from expert-level survey writing. Our benchmark is publicly available at https://github.com/KongLongGeFDU/TaxoBench.

</details>


### [320] [A Scalable Entity-Based Framework for Auditing Bias in LLMs](https://arxiv.org/abs/2601.12374)
*Akram Elbouanani,Aboubacar Tuo,Adrian Popescu*

Main category: cs.CL

TL;DR: 提出可扩展的偏见审计框架，使用命名实体作为探针测量LLM的结构性偏见，通过合成数据大规模分析，发现系统性偏见模式


<details>
  <summary>Details</summary>
Motivation: 现有LLM偏见评估方法存在生态效度与统计控制的权衡：人工提示缺乏真实世界代表性，自然任务缺乏规模和严谨性，需要可扩展的偏见审计框架

Method: 引入使用命名实体作为探针的可扩展偏见审计框架，通过合成数据重现自然文本中的偏见模式，实现大规模分析（19亿数据点，涵盖多种实体类型、任务、语言、模型和提示策略）

Result: 发现系统性偏见：模型惩罚右翼政客、偏爱左翼政客、偏好西方和富裕国家而非全球南方、偏爱西方公司、惩罚国防和制药行业公司；指令微调减少偏见，模型规模增大会放大偏见，中文或俄文提示不会减弱西方倾向

Conclusion: LLM在高风险应用部署前应进行严格审计，当前模型存在系统性偏见，需要更全面的评估方法

Abstract: Existing approaches to bias evaluation in large language models (LLMs) trade ecological validity for statistical control, relying on artificial prompts that poorly reflect real-world use, or on naturalistic tasks that lack scale and rigor. We introduce a scalable bias-auditing framework using named entities as probes to measure structural disparities in model behavior. We show that synthetic data reliably reproduces bias patterns observed in natural text, enabling large-scale analysis. Using this approach, we conduct the largest bias audit to date, comprising 1.9 billion data points across multiple entity types, tasks, languages, models, and prompting strategies. Our results reveal systematic biases: models penalize right-wing politicians, favor left-wing politicians, prefer Western and wealthy nations over the Global South, favor Western companies, and penalize firms in the defense and pharmaceutical sectors. While instruction tuning reduces bias, increasing model scale amplifies it, and prompting in Chinese or Russian does not attenuate Western-aligned preferences. These results indicate that LLMs should undergo rigorous auditing before deployment in high-stakes applications.

</details>


### [321] [LR-DWM: Efficient Watermarking for Diffusion Language Models](https://arxiv.org/abs/2601.12376)
*Ofek Raban,Ethan Fetaya,Gal Chechik*

Main category: cs.CL

TL;DR: 提出LR-DWM方法，为扩散语言模型提供高效水印方案，通过利用左右邻居信息嵌入水印，显著降低计算和内存开销


<details>
  <summary>Details</summary>
Motivation: 当前水印方法主要针对自回归语言模型，而扩散语言模型采用非顺序迭代去噪生成文本，需要大幅修改现有水印方案。现有方法通过反转过程实现水印但计算和内存开销大

Method: 提出左右扩散水印(LR-DWM)，在生成token时利用左右邻居信息（当可用时）进行偏置，实现高效水印嵌入

Result: LR-DWM在接近非水印基线扩散语言模型的运行时和内存开销下，实现了可靠的统计检测，在标准评估设置中表现出高可检测性

Conclusion: 扩散语言模型可以通过LR-DWM方法高效添加水印，以可忽略的计算和内存开销实现高可检测性

Abstract: Watermarking (WM) is a critical mechanism for detecting and attributing AI-generated content. Current WM methods for Large Language Models (LLMs) are predominantly tailored for autoregressive (AR) models: They rely on tokens being generated sequentially, and embed stable signals within the generated sequence based on the previously sampled text. Diffusion Language Models (DLMs) generate text via non-sequential iterative denoising, which requires significant modification to use WM methods designed for AR models. Recent work proposed to watermark DLMs by inverting the process when needed, but suffers significant computational or memory overhead. We introduce Left-Right Diffusion Watermarking (LR-DWM), a scheme that biases the generated token based on both left and right neighbors, when they are available. LR-DWM incurs minimal runtime and memory overhead, remaining close to the non-watermarked baseline DLM while enabling reliable statistical detection under standard evaluation settings. Our results demonstrate that DLMs can be watermarked efficiently, achieving high detectability with negligible computational and memory overhead.

</details>


### [322] [NADIR: Differential Attention Flow for Non-Autoregressive Transliteration in Indic Languages](https://arxiv.org/abs/2601.12389)
*Lakshya Tomar,Vinayak Abrol,Puneet Agarwal*

Main category: cs.CL

TL;DR: NADIR是一种新型非自回归架构，针对多语言音译等局部依赖任务，在保持竞争力的准确率下实现13倍加速，显著减少各类错误。


<details>
  <summary>Details</summary>
Motivation: 许多序列到序列任务（如多语言音译、代码重构、语法修正等）主要依赖局部依赖关系，自回归模型虽然准确但推理延迟高，而非自回归模型速度快但存在幻觉和长度控制问题。需要在速度和准确性之间找到平衡。

Method: 提出NADIR架构，结合差分变换器和混合专家机制，能够鲁棒地建模复杂字符映射而无需序列依赖，专门为局部依赖任务设计。

Result: 在印度语言多语言音译任务中，NADIR相比最先进的自回归基线实现超过13倍加速，平均字符错误率为15.78%（自回归模型为14.44%，标准非自回归模型为21.88%）。显著减少重复错误49.53%、替换错误24.45%、省略错误32.92%、插入错误16.87%。

Conclusion: NADIR为构建快速可靠的非自回归系统提供了实用蓝图，有效弥合了自回归模型的准确性与实时大规模部署需求之间的差距。

Abstract: In this work, we argue that not all sequence-to-sequence tasks require the strong inductive biases of autoregressive (AR) models. Tasks like multilingual transliteration, code refactoring, grammatical correction or text normalization often rely on local dependencies where the full modeling capacity of AR models can be overkill, creating a trade-off between their high accuracy and high inference latency. While non-autoregressive (NAR) models offer speed, they typically suffer from hallucinations and poor length control. To explore this trade-off, we focus on the multilingual transliteration task in Indic languages and introduce NADIR, a novel NAR architecture designed to strike a balance between speed and accuracy. NADIR integrates a Differential Transformer and a Mixture-of-Experts mechanism, enabling it to robustly model complex character mappings without sequential dependencies. NADIR achieves over a 13x speed-up compared to the state-of-the-art AR baseline. It maintains a competitive mean Character Error Rate of 15.78%, compared to 14.44% for the AR model and 21.88% for a standard NAR equivalent. Importantly, NADIR reduces Repetition errors by 49.53%, Substitution errors by 24.45%, Omission errors by 32.92%, and Insertion errors by 16.87%. This work provides a practical blueprint for building fast and reliable NAR systems, effectively bridging the gap between AR accuracy and the demands of real-time, large-scale deployment.

</details>


### [323] [Legal experts disagree with rationale extraction techniques for explaining ECtHR case outcome classification](https://arxiv.org/abs/2601.12419)
*Mahammad Namazov,Tomáš Koref,Ivan Habernal*

Main category: cs.CL

TL;DR: 该论文提出了一个比较分析框架，用于评估法律领域大语言模型可解释性技术，特别关注两种理由提取方法，发现模型预测理由与法律专家理由存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 法律领域应用大语言模型需要信任和透明度，但哪种技术能最好地解释法律结果预测仍是一个开放性问题。现有方法包括任务特定方法和使用分类模型参数解释决策，但缺乏系统比较。

Method: 提出了一个模型无关的可解释性技术比较分析框架，采用两种理由提取方法（从输入文本中提取人类可解释的简洁文本片段作为理由）。通过忠实性（标准化充分性和全面性指标）和合理性（法律专家评估提取的理由）进行评估，并评估LLM-as-a-Judge的可行性。

Result: 尽管定量分析结果很有前景且下游分类性能合理，但模型预测违规的"理由"与法律专家的理由存在显著差异。这表明仅依赖定量指标可能不足以评估法律领域模型的可解释性。

Conclusion: 需要结合定量和定性评估来全面评估法律领域模型的可解释性。模型预测理由与专家理由的差异强调了人类专家评估的重要性，特别是在法律等高风险领域。

Abstract: Interpretability is critical for applications of large language models in the legal domain which requires trust and transparency. While some studies develop task-specific approaches, other use the classification model's parameters to explain the decisions. However, which technique explains the legal outcome prediction best remains an open question. To address this challenge, we propose a comparative analysis framework for model-agnostic interpretability techniques. Among these, we employ two rationale extraction methods, which justify outcomes with human-interpretable and concise text fragments (i.e., rationales) from the given input text. We conduct comparison by evaluating faithfulness-via normalized sufficiency and comprehensiveness metrics along with plausibility-by asking legal experts to evaluate extracted rationales. We further assess the feasibility of LLM-as-a-Judge using legal expert evaluation results. We show that the model's "reasons" for predicting a violation differ substantially from those of legal experts, despite highly promising quantitative analysis results and reasonable downstream classification performance. The source code of our experiments is publicly available at https://github.com/trusthlt/IntEval.

</details>


### [324] [System-Mediated Attention Imbalances Make Vision-Language Models Say Yes](https://arxiv.org/abs/2601.12430)
*Tsan Tsai Chan,Varsha Suresh,Anisha Saha,Michael Hahn,Vera Demberg*

Main category: cs.CL

TL;DR: 该研究提出系统注意力是VLM幻觉的关键因素，通过因果性地将注意力从系统模态重新分配到图像和文本输入，可以有效抑制"yes-bias"幻觉，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有缓解VLM幻觉的方法通常偏向图像中心解释，过度强调增加图像注意力而忽视其他模态的作用。本研究提出更全面的系统介导解释，认为系统权重的功能冗余导致对图像和文本输入的注意力减少，从而引发幻觉。

Method: 采用系统介导框架，将注意力不平衡归因于功能冗余的系统权重。通过因果性地重新分配注意力，从系统模态转移到图像和文本输入，评估这种方法对抑制"yes-bias"幻觉的效果。

Result: 因果性地重新分配注意力从系统模态到图像和文本输入，显著抑制了"yes-bias"幻觉，通常优于现有方法。证据表明系统介导的注意力不平衡通过鼓励依赖粗糙输入表示而导致yes-bias。

Conclusion: 系统注意力是VLM幻觉的关键因素，可作为缓解幻觉的有效杠杆。系统介导的框架为理解VLM幻觉提供了有用的经验视角，并展示了通过调整注意力分配来改善模型性能的潜力。

Abstract: Vision-language model (VLM) hallucination is commonly linked to imbalanced allocation of attention across input modalities: system, image and text. However, existing mitigation strategies tend towards an image-centric interpretation of these imbalances, often prioritising increased image attention while giving less consideration to the roles of the other modalities. In this study, we evaluate a more holistic, system-mediated account, which attributes these imbalances to functionally redundant system weights that reduce attention to image and textual inputs. We show that this framework offers a useful empirical perspective on the yes-bias, a common form of hallucination in which VLMs indiscriminately respond 'yes'. Causally redistributing attention from the system modality to image and textual inputs substantially suppresses this bias, often outperforming existing approaches. We further present evidence suggesting that system-mediated attention imbalances contribute to the yes-bias by encouraging a default reliance on coarse input representations, which are effective for some tasks but ill-suited to others. Taken together, these findings firmly establish system attention as a key factor in VLM hallucination and highlight its potential as a lever for mitigation.

</details>


### [325] [Incentivizing In-depth Reasoning over Long Contexts with Process Advantage Shaping](https://arxiv.org/abs/2601.12465)
*Miao Peng,Weizhou Shen,Nuo Chen,Chenliang Li,Ming Yan,Jia Li*

Main category: cs.CL

TL;DR: 本文针对长上下文推理中RLVR性能下降问题，提出DeepReasonQA框架生成高难度多跳QA数据，以及LongPAS方法通过细粒度信用分配从"几乎正确"轨迹中提取学习信号，显著提升长上下文推理能力。


<details>
  <summary>Details</summary>
Motivation: RLVR在短上下文推理中有效，但在需要精确grounding和长距离推理的长上下文场景中性能下降。作者发现"几乎正确"现象：轨迹大部分正确但在最后一步失败，归因于两个因素：1) 长上下文QA数据缺乏高推理密度，无法推动LLM超越简单grounding进行复杂多跳推理；2) 长上下文RL训练中对部分正确但结果错误的轨迹进行无差别惩罚，导致有价值学习信号丢失。

Method: 提出DeepReasonQA：基于知识图谱的可控合成框架，构建具有内在推理链的高难度多跳长上下文QA对。在此基础上提出Long-context Process Advantage Shaping (LongPAS)：通过评估推理步骤的有效性和相关性两个维度进行细粒度信用分配，从"几乎正确"轨迹中捕获关键学习信号。

Result: 在三个长上下文推理基准测试中，该方法显著优于RLVR基线，并与前沿LLM性能相当，同时使用更少的参数。进一步分析证实了该方法在增强长上下文推理能力的同时保持RL训练稳定性的有效性。

Conclusion: 通过DeepReasonQA提供高质量训练数据和LongPAS进行细粒度信用分配，成功解决了长上下文推理中RLVR的性能瓶颈问题，显著提升了LLM在长上下文场景下的推理能力。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has proven effective in enhancing LLMs short-context reasoning, but its performance degrades in long-context scenarios that require both precise grounding and robust long-range reasoning. We identify the "almost-there" phenomenon in long-context reasoning, where trajectories are largely correct but fail at the final step, and attribute this failure to two factors: (1) the lack of high reasoning density in long-context QA data that push LLMs beyond mere grounding toward sophisticated multi-hop reasoning; and (2) the loss of valuable learning signals during long-context RL training due to the indiscriminate penalization of partially correct trajectories with incorrect outcomes. To overcome this bottleneck, we propose DeepReasonQA, a KG-driven synthesis framework that controllably constructs high-difficulty, multi-hop long-context QA pairs with inherent reasoning chains. Building on this, we introduce Long-context Process Advantage Shaping (LongPAS), a simple yet effective method that performs fine-grained credit assignment by evaluating reasoning steps along Validity and Relevance dimensions, which captures critical learning signals from "almost-there" trajectories. Experiments on three long-context reasoning benchmarks show that our approach substantially outperforms RLVR baselines and matches frontier LLMs while using far fewer parameters. Further analysis confirms the effectiveness of our methods in strengthening long-context reasoning while maintaining stable RL training.

</details>


### [326] [Knowing When to Abstain: Medical LLMs Under Clinical Uncertainty](https://arxiv.org/abs/2601.12471)
*Sravanthi Machcha,Sushrita Yerra,Sahil Gupta,Aishwarya Sahoo,Sharmin Sultana,Hong Yu,Zonghai Yao*

Main category: cs.CL

TL;DR: MedAbstain是一个医疗多选题回答中的弃权基准，研究发现即使最先进的LLM也常在不该回答时回答，提供明确弃权选项比输入扰动更能提高安全性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM评估过于强调准确性，但在现实世界和安全关键应用中，模型在不确定时能够弃权同样重要，这对于可信部署至关重要。

Method: 提出MedAbstain基准和评估协议，整合了符合预测、对抗性问题扰动和明确弃权选项，系统评估开源和闭源LLM在医疗MCQA中的弃权能力。

Result: 即使最先进的高准确性模型也经常在不确定时无法弃权；提供明确弃权选项能显著增加模型不确定性和安全弃权，效果远优于输入扰动；扩大模型规模或高级提示技术改善有限。

Conclusion: 弃权机制对于可信LLM部署至关重要，研究结果为高风险应用中的安全性改进提供了实用指导。

Abstract: Current evaluation of large language models (LLMs) overwhelmingly prioritizes accuracy; however, in real-world and safety-critical applications, the ability to abstain when uncertain is equally vital for trustworthy deployment. We introduce MedAbstain, a unified benchmark and evaluation protocol for abstention in medical multiple-choice question answering (MCQA) -- a discrete-choice setting that generalizes to agentic action selection -- integrating conformal prediction, adversarial question perturbations, and explicit abstention options. Our systematic evaluation of both open- and closed-source LLMs reveals that even state-of-the-art, high-accuracy models often fail to abstain with uncertain. Notably, providing explicit abstention options consistently increases model uncertainty and safer abstention, far more than input perturbations, while scaling model size or advanced prompting brings little improvement. These findings highlight the central role of abstention mechanisms for trustworthy LLM deployment and offer practical guidance for improving safety in high-stakes applications.

</details>


### [327] [Capability-Aware Early-Stage Research Idea Evaluation](https://arxiv.org/abs/2601.12473)
*Renlong Jie,Chen Chu,Zhen Wang*

Main category: cs.CL

TL;DR: 提出基于作者信息和研究想法的能力感知框架，预测论文接受度和评分，无需完整文本或实验结果


<details>
  <summary>Details</summary>
Motivation: 在概念阶段（即投入大量资源前）预测研究成果，可以优化科学资源分配和研究规划。现有方法依赖完整稿件或同行评审，而本研究希望在只有作者信息和研究想法时就能进行预测

Method: 采用能力感知框架，通过三路Transformer架构整合作者信息、（推断的）能力展示和研究想法，并引入两阶段架构学习给定作者信息和想法的能力表示

Result: 实验表明，该方法显著优于基于bert-base和bert-large的单路微调模型，能力预测显著提高了最终模型的预测准确性

Conclusion: 所提方法可应用于早期研究成果预测和科学资源分配，为研究规划提供有价值的工具

Abstract: Predicting the outcomes of research ideas at their conceptual stage (i.e. before significant resources are committed) holds great potential for optimizing scientific resource allocation and research planning. While existing methods rely heavily on finished manuscripts or peer reviews, we propose a novel capability-aware framework that predicts paper acceptance and ratings using only author information and research ideas, without requiring full text or experimental results. Our approach integrates author information, (inferred) capability presentation, and research ideas through a three-way transformer architecture with flexible fusion mechanisms. We also introduce a two-stage architecture for learning the capability representation given the author information and idea. Experiments show that our method significantly outperform the single-way models by finetuning bert-base and bert-large, and the capability predicting significantly increase the predictive accuracy of the final model. The proposed method can be applied in both early-stage research outcome prediction and scientific resource allocation.

</details>


### [328] [DoPE: Decoy Oriented Perturbation Encapsulation Human-Readable, AI-Hostile Documents for Academic Integrity](https://arxiv.org/abs/2601.12505)
*Ashish Raj Shekhar,Shiven Agarwal,Priyanuj Bordoloi,Yash Shah,Tejas Anvekar,Vivek Gupta*

Main category: cs.CL

TL;DR: DoPE是一种文档层防御框架，通过在PDF/HTML考试文档中嵌入语义诱饵，利用MLLM渲染解析差异来防止和检测AI作弊，无需依赖传统分类器。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型(MLLMs)能够直接处理考试文档，威胁传统评估方式和学术诚信。需要开发模型无关的防御机制来防止AI自动化解题并检测对AI的盲目依赖。

Method: 提出DoPE框架，在文档创作时嵌入语义诱饵，利用MLLM渲染解析差异。开发FewSoRT-Q生成问题级语义诱饵，FewSoRT-D将其封装到水印文档中，实现预防和检测功能。

Result: 在Integrity-Bench基准测试中，对OpenAI和Anthropic的黑盒MLLMs，DoPE达到91.4%检测率（8.7%误报率），96.3%的尝试被阻止成功完成或诱导诱饵对齐失败。

Conclusion: DoPE提供有效的文档层防御机制，保护学术诚信，无需依赖传统分类器。释放基准、工具包和评估代码以促进文档层防御的可重复研究。

Abstract: Multimodal Large Language Models (MLLMs) can directly consume exam documents, threatening conventional assessments and academic integrity. We present DoPE (Decoy-Oriented Perturbation Encapsulation), a document-layer defense framework that embeds semantic decoys into PDF/HTML assessments to exploit render-parse discrepancies in MLLM pipelines. By instrumenting exams at authoring time, DoPE provides model-agnostic prevention (stop or confound automated solving) and detection (flag blind AI reliance) without relying on conventional one-shot classifiers. We formalize prevention and detection tasks, and introduce FewSoRT-Q, an LLM-guided pipeline that generates question-level semantic decoys and FewSoRT-D to encapsulate them into watermarked documents. We evaluate on Integrity-Bench, a novel benchmark of 1826 exams (PDF+HTML) derived from public QA datasets and OpenCourseWare. Against black-box MLLMs from OpenAI and Anthropic, DoPE yields strong empirical gains: a 91.4% detection rate at an 8.7% false-positive rate using an LLM-as-Judge verifier, and prevents successful completion or induces decoy-aligned failures in 96.3% of attempts. We release Integrity-Bench, our toolkit, and evaluation code to enable reproducible study of document-layer defenses for academic integrity.

</details>


### [329] [Improving Low-Resource Machine Translation via Round-Trip Reinforcement Learning](https://arxiv.org/abs/2601.12535)
*Ahmed Attia,Alham Fikri*

Main category: cs.CL

TL;DR: 本文提出一种基于自监督强化学习的低资源机器翻译微调方法，使用NLLB模型通过往返翻译提升翻译质量


<details>
  <summary>Details</summary>
Motivation: 随着低资源语言平行数据的收集，低资源机器翻译受到关注，但许多改进方法尚未探索。本文旨在探索利用自监督强化学习提升低资源翻译质量的方法。

Method: 采用基于自监督强化学习的微调方法，使用NLLB模型进行往返翻译（英语→目标低资源语言→英语），结合chrF++和BLEU作为重建英语句子的奖励函数。

Result: 在NLLB-MD数据集上评估600M和1.3B参数的NLLB模型，在Central Aymara、Friulian、Wolof和Russian等语言上观察到一致的改进。定性分析显示翻译输出的流畅性和语义保真度提高。

Conclusion: 该方法能从规模扩展中进一步受益，使模型能更好地利用预训练知识并持续自我改进，为低资源机器翻译提供有效解决方案。

Abstract: Low-resource machine translation (MT) has gained increasing attention as parallel data from low-resource language communities is collected, but many potential methods for improving low-resource MT remain unexplored. We investigate a self-supervised reinforcement-learning-based fine-tuning for translation in low-resource settings using round-trip bootstrapping with the No Language Left Behind (NLLB) family of models. Our approach translates English into a target low-resource language and then back into English, using a combination of chrF++ and BLEU as the reward function on the reconstructed English sentences. Using the NLLB-MD dataset, we evaluate both the 600M and 1.3B parameter NLLB models and observe consistent improvements for the following languages: Central Aymara, Friulian, Wolof and Russian. Qualitative inspection of translation outputs indicates increased fluency and semantic fidelity. We argue that our method can further benefit from scale, enabling models to increasingly leverage their pretrained knowledge and continue self-improving.

</details>


### [330] [Benchmarking Concept-Spilling Across Languages in LLMs](https://arxiv.org/abs/2601.12549)
*Ilia Badanin,Daniil Dzenhaliou,Imanol Schlag*

Main category: cs.CL

TL;DR: 该论文提出了一个评估多语言大语言模型语义鲁棒性的比较框架，通过系统测量模型处理跨语言多义词的能力，揭示了语言溢出现象，并建立了模型性能的排序系统。


<details>
  <summary>Details</summary>
Motivation: 多语言大语言模型虽然展现出跨语言能力，但存在系统性偏见，倾向于其他语言的表征，导致在非英语语言生成内容时出现语义干扰（语言溢出现象）。需要评估模型的多语言语义鲁棒性。

Method: 提出一个比较框架，通过结构化意义生成任务评估模型处理多义词的能力。使用100个高多义性英语单词作为基准，在9种语言中测试模型。测量模型在生成序列中何时转向主导语言的含义。

Result: 研究发现不同模型和语言之间的语义鲁棒性存在显著差异。语义更强的模型在生成序列后期才转向主导语言含义，而较弱模型则更早转向。建立了无需确定错误来源的模型比较排序系统。

Conclusion: 该研究为多语言语义评估提供了可扩展的比较基准和严格的验证流程，是开发更语言平衡AI系统的关键工具，有助于理解模型的多语言语义鲁棒性。

Abstract: Multilingual Large Language Models (LLMs) exhibit remarkable cross-lingual abilities, yet often exhibit a systematic bias toward the representations from other languages, resulting in semantic interference when generating content in non-English languages$-$a phenomenon we define as language spilling. This paper presents a novel comparative framework for evaluating multilingual semantic robustness by systematically measuring how models handle polysemous words across languages. Our methodology provides a relative measure of model performance: when required to generate exactly five meanings, both strong and weak models may resort to meanings from dominant languages, but semantically stronger models do so later in the generation sequence, producing more true meanings from the target language before failing, while weaker models resort to dominant-language meanings earlier in the sequence. We evaluate a diverse set of open and closed multilingual LLMs using a structured meaning generation task across nine languages, employing a carefully curated benchmark of 100 high-polysemy English words. Our findings reveal significant variation in semantic robustness across both models and languages, providing a principled ranking system for model comparison without requiring definitive causal attribution of error sources. We contribute both a scalable comparative benchmark for multilingual semantic evaluation and a rigorous validation pipeline$-$critical tools for developing more linguistically balanced AI systems.

</details>


### [331] [Evaluating Contextually Mediated Factual Recall in Multilingual Large Language Models](https://arxiv.org/abs/2601.12555)
*Yihong Liu,Bingyu Xiong,Hinrich Schütze*

Main category: cs.CL

TL;DR: 研究发现LLMs在上下文中介的事实回忆中表现下降，尽管大模型对此更鲁棒，这揭示了孤立事实回忆与上下文依赖理解之间的差距。


<details>
  <summary>Details</summary>
Motivation: 现有的事实回忆评估主要评估孤立的事实检索，但在自然语言使用中，事实通常通过上下文间接访问。本研究旨在探究LLMs在目标实体嵌入自然语境而非明确查询时，能否可靠地检索跨语言的事实知识。

Method: 构建保留基本事实但通过上下文句子引入指称中介的受控提示。为了区分上下文效应与名称特定关联，进一步比较了跨语言合成名称和真实名称的性能。在五种语言中评估多个模型家族。

Result: 上下文中介持续降低事实回忆性能，不同关系间存在显著差异。更大的模型对上下文中介更鲁棒，相对于直接查询的性能差距减小。真实名称和名称来源的影响混合且无系统性。

Conclusion: 研究揭示了多语言LLMs中孤立事实回忆与上下文依赖语言理解之间的差距，表明当前评估方法可能高估了LLMs在自然语境中的事实检索能力。

Abstract: Large language models (LLMs) can recall a wide range of factual knowledge across languages. However, existing factual recall evaluations primarily assess fact retrieval in isolation, where the queried entity is explicitly named and the fact is requested directly. In natural language use, facts are often accessed through context, where the relevant entity is introduced only indirectly. In this work, we study contextually mediated factual recall, asking whether LLMs can reliably retrieve factual knowledge when the target entity is embedded in a naturalistic context rather than queried explicitly, across languages. We construct controlled prompts that preserve the underlying fact while introducing referential mediation through contextual sentences. To disentangle contextual effects from name-specific associations, we further compare performance using synthetic names and real names across languages. Evaluating multiple model families in five languages, we find that contextual mediation consistently degrades factual recall, with substantial variation across relations. Larger models are more robust to contextual mediation, exhibiting a reduced performance gap relative to direct queries, while the effect of real names and name origin is mixed and unsystematic. These findings highlight a gap between isolated factual recall and context-dependent language understanding in multilingual LLMs.

</details>


### [332] [A Cloud-based Multi-Agentic Workflow for Science](https://arxiv.org/abs/2601.12607)
*Anurag Acharya,Timothy Vega,Rizwan A. Ashraf,Anshu Sharma,Derek Parker,Robert Rallo*

Main category: cs.CL

TL;DR: 提出一个领域无关、模型独立的云端智能体框架作为科学助手，能够处理从文献综述到复杂模拟等多种任务，在催化剂研究中验证了可行性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理复杂任务（如运行模拟、复杂决策）方面能力有限，而现有的智能体系统在平衡模型、云服务商和外部资源方面面临挑战，阻碍了智能体系统的实际应用。

Method: 设计了一个基于云端的领域无关、模型独立的智能体工作流框架，采用监督智能体协调多个具有特定能力的子智能体，能够处理从简单任务（文献综述、数据分析）到复杂任务（模拟运行）的各种科学工作。

Result: 在催化剂研究领域构建了概念验证系统，任务路由准确率达90%，合成任务完成率97.5%，真实世界任务完成率91%，准确率与前沿模型相当或更好，同时提供了详细的成本分析。

Conclusion: 该框架是一个可行的科学助手解决方案，能够有效协调多个智能体处理复杂科学任务，为其他科学领域提供了可复制的参考架构。

Abstract: As Large Language Models (LLMs) become ubiquitous across various scientific domains, their lack of ability to perform complex tasks like running simulations or to make complex decisions limits their utility. LLM-based agents bridge this gap due to their ability to call external resources and tools and thus are now rapidly gaining popularity. However, coming up with a workflow that can balance the models, cloud providers, and external resources is very challenging, making implementing an agentic system more of a hindrance than a help. In this work, we present a domain-agnostic, model-independent workflow for an agentic framework that can act as a scientific assistant while being run entirely on cloud. Built with a supervisor agent marshaling an array of agents with individual capabilities, our framework brings together straightforward tasks like literature review and data analysis with more complex ones like simulation runs. We describe the framework here in full, including a proof-of-concept system we built to accelerate the study of Catalysts, which is highly important in the field of Chemistry and Material Science. We report the cost to operate and use this framework, including the breakdown of the cost by services use. We also evaluate our system on a custom-curated synthetic benchmark and a popular Chemistry benchmark, and also perform expert validation of the system. The results show that our system is able to route the task to the correct agent 90% of the time and successfully complete the assigned task 97.5% of the time for the synthetic tasks and 91% of the time for real-world tasks, while still achieving better or comparable accuracy to most frontier models, showing that this is a viable framework for other scientific domains to replicate.

</details>


### [333] [Disagreement as Data: Reasoning Trace Analytics in Multi-Agent Systems](https://arxiv.org/abs/2601.12618)
*Elham Tajik,Conrad Borchers,Bahar Shahrokhian,Sebastian Simon,Ali Keramati,Sonika Pal,Sreecharan Sankaranarayanan*

Main category: cs.CL

TL;DR: 本文提出利用LLM多智能体系统的推理轨迹作为过程数据，通过余弦相似度量化智能体间的分歧，将分歧转化为有意义的分析信号，以增强质性编码的严谨性和解释深度。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI的发展，自动化或人机协作的质性分析方法涌现，但缺乏相应的方法学标准。学习分析研究中常需要分析质性学生数据，现有方法在解释实践和可靠性建立方面存在局限。

Method: 提出将LLM多智能体系统的推理轨迹作为新型过程数据，使用余弦相似度系统性地检测、量化和解释智能体间的分歧。分析了近10,000个人类辅导对话片段的智能体编码实例，将定量相似度指标与质性分析相结合。

Result: LLM智能体的语义推理相似度能稳健地区分共识与分歧，并与人类编码可靠性相关。基于该指标的质性分析揭示了编码内的细微教学子功能，并为概念性编码本的完善提供了机会。

Conclusion: 推理轨迹分歧代表了一类有价值的新型分析信号，通过整合定量相似度指标与质性审查，该方法有潜力改善和加速编码过程中评分者间可靠性的建立，特别是在LLM与人类协作时，能揭示解释性模糊，提升教育研究方法学严谨性和解释深度。

Abstract: Learning analytics researchers often analyze qualitative student data such as coded annotations or interview transcripts to understand learning processes. With the rise of generative AI, fully automated and human-AI workflows have emerged as promising methods for analysis. However, methodological standards to guide such workflows remain limited. In this study, we propose that reasoning traces generated by large language model (LLM) agents, especially within multi-agent systems, constitute a novel and rich form of process data to enhance interpretive practices in qualitative coding. We apply cosine similarity to LLM reasoning traces to systematically detect, quantify, and interpret disagreements among agents, reframing disagreement as a meaningful analytic signal. Analyzing nearly 10,000 instances of agent pairs coding human tutoring dialog segments, we show that LLM agents' semantic reasoning similarity robustly differentiates consensus from disagreement and correlates with human coding reliability. Qualitative analysis guided by this metric reveals nuanced instructional sub-functions within codes and opportunities for conceptual codebook refinement. By integrating quantitative similarity metrics with qualitative review, our method has the potential to improve and accelerate establishing inter-rater reliability during coding by surfacing interpretive ambiguity, especially when LLMs collaborate with humans. We discuss how reasoning-trace disagreements represent a valuable new class of analytic signals advancing methodological rigor and interpretive depth in educational research.

</details>


### [334] [BioPulse-QA: A Dynamic Biomedical Question-Answering Benchmark for Evaluating Factuality, Robustness, and Bias in Large Language Models](https://arxiv.org/abs/2601.12632)
*Kriti Bhattarai,Vipina K. Keloth,Donald Wright,Andrew Loza,Yang Ren,Hua Xu*

Main category: cs.CL

TL;DR: BioPulse-QA是一个新的生物医学问答基准，使用新发布的文档评估LLMs，包含2280个专家验证的QA对，发现GPT-o1表现最佳，临床试验最具挑战性。


<details>
  <summary>Details</summary>
Motivation: 现有生物医学基准存在局限性：使用静态过时数据集、存在数据泄露风险、忽略语言变异鲁棒性和人口统计偏差。需要动态、上下文丰富且高风险的评估框架。

Method: 引入BioPulse-QA基准，使用新发布的生物医学文档（药物标签、试验方案、临床指南）创建2280个专家验证的QA对，包含提取式和生成式格式。评估GPT-4o、GPT-o1、Gemini-2.0-Flash和LLaMA-3.1 8B Instruct四个模型。

Result: GPT-o1在药物标签上获得最高松弛F1分数（0.92），Gemini-2.0-Flash次之（0.90）。临床试验最具挑战性，提取式F1分数低至0.36。改写比拼写错误影响更大，偏差测试显示差异可忽略。

Conclusion: BioPulse-QA为评估生物医学LLMs提供了可扩展且临床相关的框架，能够更好地评估模型在动态、高风险生物医学环境中的实际表现。

Abstract: Objective: Large language models (LLMs) are increasingly applied in biomedical settings, and existing benchmark datasets have played an important role in supporting model development and evaluation. However, these benchmarks often have limitations. Many rely on static or outdated datasets that fail to capture the dynamic, context-rich, and high-stakes nature of biomedical knowledge. They also carry increasing risk of data leakage due to overlap with model pretraining corpora and often overlook critical dimensions such as robustness to linguistic variation and potential demographic biases.
  Materials and Methods: To address these gaps, we introduce BioPulse-QA, a benchmark that evaluates LLMs on answering questions from newly published biomedical documents including drug labels, trial protocols, and clinical guidelines. BioPulse-QA includes 2,280 expert-verified question answering (QA) pairs and perturbed variants, covering both extractive and abstractive formats. We evaluate four LLMs - GPT-4o, GPT-o1, Gemini-2.0-Flash, and LLaMA-3.1 8B Instruct - released prior to the publication dates of the benchmark documents.
  Results: GPT-o1 achieves the highest relaxed F1 score (0.92), followed by Gemini-2.0-Flash (0.90) on drug labels. Clinical trials are the most challenging source, with extractive F1 scores as low as 0.36.
  Discussion and Conclusion: Performance differences are larger for paraphrasing than for typographical errors, while bias testing shows negligible differences. BioPulse-QA provides a scalable and clinically relevant framework for evaluating biomedical LLMs.

</details>


### [335] [Objective Matters: Fine-Tuning Objectives Shape Safety, Robustness, and Persona Drift](https://arxiv.org/abs/2601.12639)
*Daniel Vennemeyer,Punya Syon Pandey,Phan Anh Duong,Michael Umeokoli,Samuel Ratnam*

Main category: cs.CL

TL;DR: 不同微调目标在安全性与能力权衡上存在系统性差异：小规模训练时安全性相似但能力不同，大规模训练时目标选择成为对抗鲁棒性和角色稳定性的主要驱动因素。


<details>
  <summary>Details</summary>
Motivation: 尽管在良性数据上微调LLMs仍可能损害对齐性和对抗鲁棒性，但微调目标在塑造这些安全结果中的作用尚未得到充分研究。本研究旨在系统比较不同微调目标如何影响模型的安全性与能力权衡。

Method: 在数据、领域、架构和优化固定的控制条件下，比较了六种微调目标：监督微调、直接偏好优化、条件微调、接种提示、几率比偏好优化和KL正则化微调。在封闭式推理和开放式生成任务上进行评估。

Result: 微调目标选择导致安全-能力前沿的系统性、规模依赖性变化。小训练预算下，各目标的鲁棒性相似但能力不同；大预算下，目标差异显著：监督和基于偏好的微调使能力提升与对抗脆弱性和角色漂移紧密耦合，而约束学习信号的目标（特别是ORPO和KL正则化）能显著缓解这些问题。

Conclusion: 微调目标在小规模时对安全性影响不大，但随着训练规模增加，成为对抗鲁棒性和潜在角色稳定性的主要驱动因素。选择适当的微调目标对于在大规模微调中保持模型安全性至关重要。

Abstract: Fine-tuning LLMs on benign data can still degrade alignment and adversarial robustness, yet direct analysis of the role of fine-tuning objectives in shaping these safety outcomes remain limited. We present a controlled comparison of six fine-tuning objectives -- Supervised Fine-Tuning, Direct Preference Optimization, Conditional Fine-Tuning, Inoculation Prompting, Odds Ratio Preference Optimization, and KL-regularized fine-tuning -- holding data, domain, architecture, and optimization fixed. Across closed-form reasoning and open-ended generation tasks, we find that objective choice induces systematic, scale-dependent shifts along the safety-capability frontier. At small training budgets, robustness is similar across objectives but capability differs. At larger budgets, objectives diverge sharply: supervised and preference-based tuning tightly couple capability gains to increased adversarial vulnerability and persona drift, while objectives that constrain learning signals -- especially ORPO and KL-regularization -- substantially mitigate both. Fine-tuning objectives therefore matter little for safety at small scales but become a primary driver of adversarial robustness and latent persona stability as training scale increases.

</details>


### [336] [Intelligent Documentation in Medical Education: Can AI Replace Manual Case Logging?](https://arxiv.org/abs/2601.12648)
*Nafiz Imtiaz Khan,Kylie Cleland,Vladimir Filkov,Roger Eric Goldman*

Main category: cs.CL

TL;DR: LLMs can effectively自动从放射学报告中提取结构化程序信息，用于自动生成程序病例日志，减少住院医师文书负担并提高一致性。


<details>
  <summary>Details</summary>
Motivation: 程序病例日志是放射学培训的核心要求，但手动编写耗时且容易不一致。需要自动化解决方案来减轻住院医师的文书负担并提高日志质量。

Method: 评估多个本地和商业LLM，使用基于指令和思维链提示，从414份介入放射学报告中提取结构化程序信息。评估性能指标包括敏感性、特异性、F1分数，以及推理延迟和令牌效率来估算运营成本。

Result: 本地和商业模型都实现了强大的提取性能，最佳F1分数接近0.87。不同模型在速度和成本之间存在权衡。自动化可以显著减少住院医师的文书负担并提高病例日志的一致性。

Conclusion: LLM辅助文档在医学教育中是可行的，展示了AI自动化的潜力。需要在不同机构和临床工作流程中进行进一步验证。

Abstract: Procedural case logs are a core requirement in radiology training, yet they are time-consuming to complete and prone to inconsistency when authored manually. This study investigates whether large language models (LLMs) can automate procedural case log documentation directly from free-text radiology reports. We evaluate multiple local and commercial LLMs under instruction-based and chain-of-thought prompting to extract structured procedural information from 414 curated interventional radiology reports authored by nine residents between 2018 and 2024. Model performance is assessed using sensitivity, specificity, and F1-score, alongside inference latency and token efficiency to estimate operational cost. Results show that both local and commercial models achieve strong extraction performance, with best F1-scores approaching 0.87, while exhibiting different trade-offs between speed and cost. Automation using LLMs has the potential to substantially reduce clerical burden for trainees and improve consistency in case logging. These findings demonstrate the feasibility of AI-assisted documentation in medical education and highlight the need for further validation across institutions and clinical workflows.

</details>


### [337] [Augmenting Question Answering with A Hybrid RAG Approach](https://arxiv.org/abs/2601.12658)
*Tianyi Yang,Nashrah Haque,Vaishnave Jonnalagadda,Yuya Jeremy Ong,Zhehui Chen,Yanzhao Wu,Lei Yu,Divyesh Jadav,Wenqi Wei*

Main category: cs.CL

TL;DR: SSRAG是一种混合架构，通过查询增强、智能路由和结构化检索机制提升RAG在QA任务中的性能


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法在检索上下文相关信息方面存在困难，导致答案不完整或次优，需要改进检索过程以提升QA质量

Method: 提出结构化语义RAG(SSRAG)混合架构，整合查询增强、智能路由，以及结合向量和图技术的结构化检索机制与上下文统一

Result: 在TruthfulQA、SQuAD和WikiQA三个QA数据集上对五个大语言模型进行评估，证明该方法相比标准RAG能持续提升响应质量

Conclusion: SSRAG通过改进检索过程和增强上下文基础，显著提高了答案准确性和信息丰富度，为RAG系统提供了有效的增强方案

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a powerful technique for enhancing the quality of responses in Question-Answering (QA) tasks. However, existing approaches often struggle with retrieving contextually relevant information, leading to incomplete or suboptimal answers. In this paper, we introduce Structured-Semantic RAG (SSRAG), a hybrid architecture that enhances QA quality by integrating query augmentation, agentic routing, and a structured retrieval mechanism combining vector and graph based techniques with context unification. By refining retrieval processes and improving contextual grounding, our approach improves both answer accuracy and informativeness. We conduct extensive evaluations on three popular QA datasets, TruthfulQA, SQuAD and WikiQA, across five Large Language Models (LLMs), demonstrating that our proposed approach consistently improves response quality over standard RAG implementations.

</details>


### [338] [UbuntuGuard: A Culturally-Grounded Policy Benchmark for Equitable AI Safety in African Languages](https://arxiv.org/abs/2601.12696)
*Tassallah Abdullahi,Macton Mgonzo,Mardiyyah Oduwole,Paul Okewunmi,Abraham Owodunni,Ritambhara Singh,Carsten Eickhoff*

Main category: cs.CL

TL;DR: UbuntuGuard：首个非洲政策导向的安全基准，针对低资源非洲语言，通过领域专家构建对抗性查询，评估现有守护模型在跨语言和文化适应性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 当前守护模型主要面向西方中心和高资源语言，对低资源非洲语言存在安全漏洞、跨语言安全失效和文化错位问题。现有安全类别僵化，无法适应多样化的语言和社会文化背景。

Method: 引入UbuntuGuard基准，由155名敏感领域专家（包括医疗保健）编写对抗性查询，从中推导出特定情境的安全政策和参考响应，捕捉文化基础的风险信号。评估了13个模型（6个通用LLM和7个守护模型），涵盖静态、动态和多语言三种变体。

Result: 发现现有英语中心基准高估了真实世界的多语言安全性；跨语言迁移提供部分但不充分的覆盖；动态模型虽能在推理时更好利用政策，但仍难以完全本地化非洲语言情境。

Conclusion: 迫切需要多语言、文化基础的安全基准，以开发适用于低资源语言的可靠、公平的守护模型。UbuntuGuard为此提供了首个非洲政策导向的评估框架。

Abstract: Current guardian models are predominantly Western-centric and optimized for high-resource languages, leaving low-resource African languages vulnerable to evolving harms, cross-lingual safety failures, and cultural misalignment. Moreover, most guardian models rely on rigid, predefined safety categories that fail to generalize across diverse linguistic and sociocultural contexts. Robust safety, therefore, requires flexible, runtime-enforceable policies and benchmarks that reflect local norms, harm scenarios, and cultural expectations. We introduce UbuntuGuard, the first African policy-based safety benchmark built from adversarial queries authored by 155 domain experts across sensitive fields, including healthcare. From these expert-crafted queries, we derive context-specific safety policies and reference responses that capture culturally grounded risk signals, enabling policy-aligned evaluation of guardian models. We evaluate 13 models, comprising six general-purpose LLMs and seven guardian models across three distinct variants: static, dynamic, and multilingual. Our findings reveal that existing English-centric benchmarks overestimate real-world multilingual safety, cross-lingual transfer provides partial but insufficient coverage, and dynamic models, while better equipped to leverage policies at inference time, still struggle to fully localize African-language contexts. These findings highlight the urgent need for multilingual, culturally grounded safety benchmarks to enable the development of reliable and equitable guardian models for low-resource languages. Our code can be found online.\footnote{Code repository available at https://github.com/hemhemoh/UbuntuGuard.

</details>


### [339] [A Two-Stage GPU Kernel Tuner Combining Semantic Refactoring and Search-Based Optimization](https://arxiv.org/abs/2601.12698)
*Qiuyi Qu,Yicheng Sui,Yufei Sun,Rui Chen,Xiaofei Zhang,Yuzhi Zhang,Haofeng Wang,Ge Lan,Ning Zhang*

Main category: cs.CL

TL;DR: 该论文提出了一种基于模板的GPU内核优化方法，通过将内核重构为可参数化模板，再结合搜索式自动调优，相比纯LLM代理的直接重写方法，能获得更稳定、更高质量的性能提升。


<details>
  <summary>Details</summary>
Motivation: GPU代码优化对HPC和大模型训练/推理至关重要，但现有方法（编译器优化、手工内核）难以达到硬件极限性能。LLM代理的内核生成优化方法多关注直接代码重写，参数选择隐式且难以控制，导致性能提升不稳定。

Method: 在代理驱动的迭代循环上增加模板重写层：1）将内核语义重构为显式可参数化模板；2）通过基于搜索的自动调优优化模板参数；3）使用代理调优器迭代执行模板化、测试、分析和规划；4）利用性能分析反馈在硬件资源限制下执行约束参数搜索。

Result: 在真实内核实验中，最佳情况下获得超过3倍的加速。相比纯代理直接重写，模板+搜索设计显著降低了迭代优化的随机性，使过程更可解释，并能更系统地逼近高性能配置。

Conclusion: 模板化重写结合搜索式调优的方法能提供更稳定、高质量的GPU内核性能优化，可扩展到OpenCL、HIP等后端，为实际生产负载提供自动化性能优化方案。

Abstract: GPU code optimization is a key performance bottleneck for HPC workloads as well as large-model training and inference. Although compiler optimizations and hand-written kernels can partially alleviate this issue, achieving near-hardware-limit performance still relies heavily on manual code refactoring and parameter tuning. Recent progress in LLM-agent-based kernel generation and optimization has been reported, yet many approaches primarily focus on direct code rewriting, where parameter choices are often implicit and hard to control, or require human intervention, leading to unstable performance gains. This paper introduces a template-based rewriting layer on top of an agent-driven iterative loop: kernels are semantically refactored into explicitly parameterizable templates, and template parameters are then optimized via search-based autotuning, yielding more stable and higher-quality speedups. Experiments on a set of real-world kernels demonstrate speedups exceeding 3x in the best case. We extract representative CUDA kernels from SGLang as evaluation targets; the proposed agentic tuner iteratively performs templating, testing, analysis, and planning, and leverages profiling feedback to execute constrained parameter search under hardware resource limits. Compared to agent-only direct rewriting, the template-plus-search design significantly reduces the randomness of iterative optimization, making the process more interpretable and enabling a more systematic approach toward high-performance configurations. The proposed method can be further extended to OpenCL, HIP, and other backends to deliver automated performance optimization for real production workloads.

</details>


### [340] [A Shared Geometry of Difficulty in Multilingual Language Models](https://arxiv.org/abs/2601.12731)
*Stefano Civelli,Pietro Bernardelle,Nicolò Brunello,Gianluca Demartini*

Main category: cs.CL

TL;DR: LLMs通过浅层和深层表示形成两阶段的问题难度预测机制：浅层表示具有跨语言泛化能力，深层表示则语言特定化


<details>
  <summary>Details</summary>
Motivation: 研究LLMs中问题难度预测的多语言几何特性，探索模型内部表示如何编码难度信息以及这些表示在不同语言间的泛化能力

Method: 使用Easy2Hard基准的AMC子集，翻译成21种语言，在LLMs内部表示上训练线性探针，分析浅层（早期层）和深层（后期层）表示的特性

Result: 发现难度相关信号出现在两个不同阶段：深层表示在相同语言内准确率高但跨语言泛化差；浅层表示在语言内性能较低但跨语言泛化显著更好

Conclusion: LLMs首先形成语言无关的问题难度表示，随后转化为语言特定的表示，这种两阶段表示过程不仅适用于语义内容，也适用于问题难度估计等高层次元认知属性

Abstract: Predicting problem-difficulty in large language models (LLMs) refers to estimating how difficult a task is according to the model itself, typically by training linear probes on its internal representations. In this work, we study the multilingual geometry of problem-difficulty in LLMs by training linear probes using the AMC subset of the Easy2Hard benchmark, translated into 21 languages. We found that difficulty-related signals emerge at two distinct stages of the model internals, corresponding to shallow (early-layers) and deep (later-layers) internal representations, that exhibit functionally different behaviors. Probes trained on deep representations achieve high accuracy when evaluated on the same language but exhibit poor cross-lingual generalization. In contrast, probes trained on shallow representations generalize substantially better across languages, despite achieving lower within-language performance. Together, these results suggest that LLMs first form a language-agnostic representation of problem difficulty, which subsequently becomes language-specific. This closely aligns with existing findings in LLM interpretability showing that models tend to operate in an abstract conceptual space before producing language-specific outputs. We demonstrate that this two-stage representational process extends beyond semantic content to high-level meta-cognitive properties such as problem-difficulty estimation.

</details>


### [341] [Towards Robust Process Reward Modeling via Noise-aware Learning](https://arxiv.org/abs/2601.12748)
*Bin Xie,Bingbing Xu,Xueyun Tian,Yilin Chen,Huawei Shen*

Main category: cs.CL

TL;DR: 提出NAIT框架解决PRM训练中的噪声监督问题，通过反射感知标签校正和噪声感知迭代训练，显著提升步骤正确性判别能力


<details>
  <summary>Details</summary>
Motivation: 现有过程奖励模型(PRM)依赖昂贵的过程级监督，而替代方案蒙特卡洛估计(MCE)会产生策略依赖的噪声奖励，包括错误奖励正确步骤和惩罚正确步骤的问题

Method: 提出两阶段框架：1)标注阶段使用LLM作为裁判检测反思和自我校正行为，抑制过高估计的奖励；2)训练阶段提出噪声感知迭代训练框架(NAIT)，让PRM基于自身置信度逐步精炼噪声标签

Result: 方法显著提升步骤级正确性判别能力，在噪声监督训练的PRM基础上实现高达27%的绝对平均F1提升

Conclusion: 提出的NAIT框架有效缓解了PRM训练中的噪声监督问题，通过结合反射感知标签校正和噪声感知迭代训练，显著提高了推理步骤正确性评估的准确性

Abstract: Process Reward Models (PRMs) have achieved strong results in complex reasoning, but are bottlenecked by costly process-level supervision. A widely used alternative, Monte Carlo Estimation (MCE), defines process rewards as the probability that a policy model reaches the correct final answer from a given reasoning step. However, step correctness is an intrinsic property of the reasoning trajectory, and should be invariant to policy choice. Our empirical findings show that MCE producing policy-dependent rewards that induce label noise, including false positives that reward incorrect steps and false negatives that penalize correct ones. To address above challenges, we propose a two-stage framework to mitigate noisy supervision. In the labeling stage, we introduce a reflection-aware label correction mechanism that uses a large language model (LLM) as a judge to detect reflection and self-correction behaviors related to the current reasoning step, thereby suppressing overestimated rewards. In the training stage, we further propose a \underline{\textbf{N}}oise-\underline{\textbf{A}}ware \underline{\textbf{I}}terative \underline{\textbf{T}}raining framework that enables the PRM to progressively refine noisy labels based on its own confidence. Extensive Experiments show that our method substantially improves step-level correctness discrimination, achieving up to a 27\% absolute gain in average F1 over PRMs trained with noisy supervision.

</details>


### [342] [VISPA: Pluralistic Alignment via Automatic Value Selection and Activation](https://arxiv.org/abs/2601.12758)
*Shenyan Zheng,Jiayou Zhong,Anudeex Shetty,Heng Ji,Preslav Nakov,Usman Naseem*

Main category: cs.CL

TL;DR: VISPA是一个无需训练的多视角对齐框架，通过动态选择和内部模型激活引导来实现对价值表达的直接控制，使语言模型能够反映多样的人类观点而非平均偏好。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在高风险领域应用增加，需要模型输出反映多样的人类观点而非平均偏好。现有方法要么考虑有限的价值观，要么依赖提示级干预，缺乏价值控制和代表性。

Method: VISPA是一个无需训练的多视角对齐框架，通过动态选择和内部模型激活引导来实现对价值表达的直接控制。

Result: 在涵盖多个模型和评估设置的广泛实证研究中，VISPA在医疗保健及其他领域的所有多视角对齐模式中都表现优异。进一步分析显示VISPA能够适应不同的引导初始化、模型和/或价值观。

Conclusion: 多视角对齐可以通过内部激活机制实现，为构建服务于所有人的语言模型提供了可扩展的路径。

Abstract: As large language models are increasingly used in high-stakes domains, it is essential that their outputs reflect not average} human preference, rather range of varying perspectives. Achieving such pluralism, however, remains challenging. Existing approaches consider limited values or rely on prompt-level interventions, lacking value control and representation. To address this, we introduce VISPA, a training-free pluralistic alignment framework, that enables direct control over value expression by dynamic selection and internal model activation steering. Across extensive empirical studies spanning multiple models and evaluation settings, we show VISPA is performant across all pluralistic alignment modes in healthcare and beyond. Further analysis reveals VISPA is adaptable with different steering initiations, model, and/or values. These results suggest that pluralistic alignment can be achieved through internal activation mechanisms, offering a scalable path toward language models that serves all.

</details>


### [343] [Who Does This Name Remind You of? Nationality Prediction via Large Language Model Associative Memory](https://arxiv.org/abs/2601.12771)
*Keito Inoshita*

Main category: cs.CL

TL;DR: LAMA框架利用LLM的联想记忆能力，通过回忆同名名人来间接推理国籍，在99国国籍预测任务中达到81.7%准确率，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: LLM拥有丰富的世界知识，但如何有效提取这些知识仍待探索。国籍和地区预测任务需要理解语言特征以及文化和历史背景，LLM的世界知识对此特别有价值。然而传统的LLM提示方法依赖直接推理，在应用抽象语言规则方面存在局限。

Method: 提出LLM联想记忆代理(LAMA)框架，将LLM世界知识作为联想记忆。不直接从名字推断国籍，而是回忆同名的著名人物，通过间接推理聚合他们的国籍。采用双代理架构：人物代理和媒体代理，分别擅长不同知识领域，并行回忆著名人物，通过投票生成Top-1预测，通过条件完成生成Top-K预测。

Result: 在99国国籍预测任务中，LAMA达到0.817准确率，显著优于传统LLM提示方法和神经网络模型。实验发现：LLM在回忆具体例子方面比抽象推理更可靠；基于回忆的方法对低频国籍具有鲁棒性，不受数据频率分布影响；双代理架构互补产生协同效应。

Conclusion: 这些结果证明了新型多代理系统的有效性，该系统检索和聚合LLM知识而非提示推理。表明利用LLM的联想记忆能力进行间接推理比直接推理更有效，为知识提取提供了新思路。

Abstract: Large language models (LLMs) possess extensive world knowledge, yet methods for effectively eliciting this knowledge remain underexplored. Nationality and region prediction tasks require understanding of not only linguistic features but also cultural and historical background, making LLM world knowledge particularly valuable. However, conventional LLM prompting methods rely on direct reasoning approaches, which have limitations in applying abstract linguistic rules. We propose LLM Associative Memory Agents (LAMA), a novel framework that leverages LLM world knowledge as associative memory. Rather than directly inferring nationality from names, LAMA recalls famous individuals with the same name and aggregates their nationalities through indirect reasoning. A dual-agent architecture comprising a Person Agent and a Media Agent, specialized in different knowledge domains, recalls famous individuals in parallel, generating Top-1 predictions through voting and Top-K predictions through conditional completion. On a 99-country nationality prediction task, LAMA achieved 0.817 accuracy, substantially outperforming conventional LLM prompting methods and neural models. Our experiments reveal that LLMs exhibit higher reliability in recalling concrete examples than in abstract reasoning, that recall-based approaches are robust to low-frequency nationalities independent of data frequency distributions, and that the dual-agent architecture functions complementarily to produce synergistic effects. These results demonstrate the effectiveness of a new multi-agent system that retrieves and aggregates LLM knowledge rather than prompting reasoning.

</details>


### [344] [Do Clinical Question Answering Systems Really Need Specialised Medical Fine Tuning?](https://arxiv.org/abs/2601.12812)
*Sushant Kumar Ray,Gautam Siddharth Kashyap,Sahil Tripathi,Nipun Joshi,Vijay Govindarajan,Rafiq Ali,Jiechao Gao,Usman Naseem*

Main category: cs.CL

TL;DR: MEDASSESS-X是一个临床问答框架，通过推理时对齐而非监督微调来提升LLM性能，挑战了医疗专用LLM必然更优的"专业化谬误"。


<details>
  <summary>Details</summary>
Motivation: 当前临床问答系统过度依赖医疗专用LLM（如BioBERT、BioGPT），但这些模型存在覆盖范围窄、重新训练成本高、适应性有限等实际问题。虽然监督微调试图解决这些问题，但仍强化了"专业化谬误"——即认为医疗专用LLM在临床问答中必然更优的错误观念。

Method: 提出MEDASSESS-X框架，采用推理时对齐而非监督微调。使用轻量级引导向量在推理时引导模型激活朝向医学一致推理，不更新模型权重，也不需要领域特定重新训练。这种推理时对齐层稳定了通用和医疗专用LLM的临床问答性能。

Result: MEDASSESS-X在所有LLM家族中均带来一致性能提升：准确率最高提升6%，事实一致性提升7%，安全错误率降低高达50%。该框架有效解决了专业化谬误，证明推理时对齐可以稳定提升各类LLM的临床问答性能。

Conclusion: MEDASSESS-X通过推理时对齐而非监督微调，成功挑战了医疗专用LLM必然更优的假设。该方法为临床问答部署提供了更灵活、成本效益更高的解决方案，打破了领域特定微调的必要性假设。

Abstract: Clinical Question-Answering (CQA) industry systems are increasingly rely on Large Language Models (LLMs), yet their deployment is often guided by the assumption that domain-specific fine-tuning is essential. Although specialised medical LLMs such as BioBERT, BioGPT, and PubMedBERT remain popular, they face practical limitations including narrow coverage, high retraining costs, and limited adaptability. Efforts based on Supervised Fine-Tuning (SFT) have attempted to address these assumptions but continue to reinforce what we term the SPECIALISATION FALLACY-the belief that specialised medical LLMs are inherently superior for CQA. To address this assumption, we introduce MEDASSESS-X, a deployment-industry-oriented CQA framework that applies alignment at inference time rather than through SFT. MEDASSESS-X uses lightweight steering vectors to guide model activations toward medically consistent reasoning without updating model weights or requiring domain-specific retraining. This inference-time alignment layer stabilises CQA performance across both general-purpose and specialised medical LLMs, thereby resolving the SPECIALISATION FALLACY. Empirically, MEDASSESS-X delivers consistent gains across all LLM families, improving Accuracy by up to +6%, Factual Consistency by +7%, and reducing Safety Error Rate by as much as 50%.

</details>


### [345] [Multimodal Multi-Agent Empowered Legal Judgment Prediction](https://arxiv.org/abs/2601.12815)
*Zhaolu Kang,Junhao Gong,Qingxi Chen,Hao Zhang,Jiaxin Liu,Rong Fu,Zhiyuan Feng,Yuan Wang,Simon Fong,Kaiyue Zhou*

Main category: cs.CL

TL;DR: 提出JurisMMA框架用于法律判决预测，通过分解审判任务、标准化流程并组织成不同阶段，同时构建包含10万+中文司法记录的JurisMM多模态数据集。


<details>
  <summary>Details</summary>
Motivation: 传统法律判决预测方法依赖统计分析或基于角色的模拟，在处理多重指控、多样证据时面临挑战且缺乏适应性，需要更有效的框架来推进法律系统发展。

Method: 提出JurisMMA框架，将审判任务有效分解、标准化流程并组织成不同阶段；构建包含文本和多模态视频-文本数据的JurisMM大型数据集（超过10万条近期中文司法记录）。

Result: 在JurisMM数据集和基准LawBench上的实验验证了框架的有效性，表明该框架不仅适用于法律判决预测，还能为更广泛的法律应用提供支持。

Conclusion: JurisMMA框架为未来法律方法和数据集的发展提供了新视角，能够有效处理法律判决预测任务并支持更广泛的法律应用。

Abstract: Legal Judgment Prediction (LJP) aims to predict the outcomes of legal cases based on factual descriptions, serving as a fundamental task to advance the development of legal systems. Traditional methods often rely on statistical analyses or role-based simulations but face challenges with multiple allegations, diverse evidence, and lack adaptability. In this paper, we introduce JurisMMA, a novel framework for LJP that effectively decomposes trial tasks, standardizes processes, and organizes them into distinct stages. Furthermore, we build JurisMM, a large dataset with over 100,000 recent Chinese judicial records, including both text and multimodal video-text data, enabling comprehensive evaluation. Experiments on JurisMM and the benchmark LawBench validate our framework's effectiveness. These results indicate that our framework is effective not only for LJP but also for a broader range of legal applications, offering new perspectives for the development of future legal methods and datasets.

</details>


### [346] [Rapport du Projet de Recherche TRAIMA](https://arxiv.org/abs/2601.12844)
*Julie Rançon,Jean-François Cerisier,Emilie Remond,Aurélien Nguyen,Andrew Peterson,Ladjel Bellatreche*

Main category: cs.CL

TL;DR: TRAIMA项目探索机器学习在分析教育场景中多模态互动（语言、副语言、非语言）的潜力，解决传统手动分析耗时且难以规模化的问题，聚焦课堂解释与协作序列，建立自动化处理的方法论框架。


<details>
  <summary>Details</summary>
Motivation: 教育互动研究中，对言语、副言语和非言语数据的分析目前完全依赖人工处理，极其耗时且难以规模化。项目旨在探索机器学习方法如何帮助分类和识别这类多模态互动，特别是课堂中的解释性和协作性序列。

Method: 项目基于多个语料库（如INTER-EXPLIC约30小时课堂互动），采用话语分析和互动语言学理论，将解释性话语精确定义为三部分结构（开场、解释核心、结尾）。重点研究转录方法学基础，比较现有转录规范，分析教师手势、韵律特征等功能角色，并利用TechnéLAB平台进行多模态数据采集。

Result: 项目展示了转录实践因理论立场和分析目标而产生的必然变异性和解释性维度。建立了与机器学习方法兼容的转录规范、标注类别和分析单元，为未来自动化处理多模态教学互动提供了方法论基础。

Conclusion: TRAIMA并未开发完全可操作的自动化系统，而是为多模态教学互动的自动处理建立了严谨的方法论框架。项目强调理论明确性和研究者反思性的重要性，为未来跨学科研究（教学法、话语分析、多模态、教育人工智能）奠定了基础。

Abstract: The TRAIMA project (TRaitement Automatique des Interactions Multimodales en Apprentissage), conducted between March 2019 and June 2020, investigates the potential of automatic processing of multimodal interactions in educational settings. The project addresses a central methodological challenge in educational and interactional research: the analysis of verbal, paraverbal, and non-verbal data is currently carried out manually, making it extremely time-consuming and difficult to scale. TRAIMA explores how machine learning approaches could contribute to the categorisation and classification of such interactions. The project focuses specifically on explanatory and collaborative sequences occurring in classroom interactions, particularly in French as a Foreign Language (FLE) and French as a First Language (FLM) contexts. These sequences are analysed as inherently multimodal phenomena, combining spoken language with prosody, gestures, posture, gaze, and spatial positioning. A key theoretical contribution of the project is the precise linguistic and interactional definition of explanatory discourse as a tripartite sequence (opening, explanatory core, closure), drawing on discourse analysis and interactional linguistics. A substantial part of the research is devoted to the methodological foundations of transcription, which constitute a critical bottleneck for any form of automation. The report provides a detailed state of the art of existing transcription conventions (ICOR, Mondada, GARS, VALIBEL, Ferr{é}), highlighting their respective strengths and limitations when applied to multimodal classroom data. Through comparative analyses of manually transcribed sequences, the project demonstrates the inevitable variability and interpretative dimension of transcription practices, depending on theoretical positioning and analytical goals. Empirical work is based on several corpora, notably the INTER-EXPLIC corpus (approximately 30 hours of classroom interaction) and the EXPLIC-LEXIC corpus, which serve both as testing grounds for manual annotation and as reference datasets for future automation. Particular attention is paid to teacher gestures (kin{é}sic and proxemic resources), prosodic features, and their functional role in meaning construction and learner comprehension. The project also highlights the strategic role of the Techn{é}LAB platform, which provides advanced multimodal data capture (multi-camera video, synchronized audio, eye-tracking, digital interaction traces) and constitutes both a research infrastructure and a test environment for the development of automated tools. In conclusion, TRAIMA does not aim to deliver a fully operational automated system, but rather to establish a rigorous methodological framework for the automatic processing of multimodal pedagogical interactions. The project identifies transcription conventions, annotation categories, and analytical units that are compatible with machine learning approaches, while emphasizing the need for theoretical explicitness and researcher reflexivity. TRAIMA thus lays the groundwork for future interdisciplinary research at the intersection of didactics, discourse analysis, multimodality, and artificial intelligence in education.

</details>


### [347] [Race, Ethnicity and Their Implication on Bias in Large Language Models](https://arxiv.org/abs/2601.12868)
*Shiyue Hu,Ruizhe Li,Yanjun Gao*

Main category: cs.CL

TL;DR: 该研究通过可解释性方法分析LLM中种族和族裔的表征机制，发现人口统计信息分布在多个内部单元中，干预可减少偏见但仍有残留效应。


<details>
  <summary>Details</summary>
Motivation: LLM在医疗等高风险领域应用时，种族和族裔信息可能被显式或隐式处理，现有研究主要记录结果层面的差异，缺乏对内部机制的深入理解。

Method: 使用两个公开数据集（毒性生成和临床叙事理解任务），分析三个开源模型，采用可重现的可解释性流水线，结合探测、神经元级归因和针对性干预。

Result: 人口统计信息分布在多个内部单元中，存在显著的跨模型差异；某些单元编码了预训练中的敏感或刻板印象关联；相同的人口统计线索可能引发不同行为；干预抑制相关神经元可减少偏见但仍有残留效应。

Conclusion: LLM中种族和族裔的表征机制复杂，简单的神经元抑制只能带来行为层面而非表征层面的改变，需要更系统的缓解方法。

Abstract: Large language models (LLMs) increasingly operate in high-stakes settings including healthcare and medicine, where demographic attributes such as race and ethnicity may be explicitly stated or implicitly inferred from text. However, existing studies primarily document outcome-level disparities, offering limited insight into internal mechanisms underlying these effects. We present a mechanistic study of how race and ethnicity are represented and operationalized within LLMs. Using two publicly available datasets spanning toxicity-related generation and clinical narrative understanding tasks, we analyze three open-source models with a reproducible interpretability pipeline combining probing, neuron-level attribution, and targeted intervention. We find that demographic information is distributed across internal units with substantial cross-model variation. Although some units encode sensitive or stereotype-related associations from pretraining, identical demographic cues can induce qualitatively different behaviors. Interventions suppressing such neurons reduce bias but leave substantial residual effects, suggesting behavioral rather than representational change and motivating more systematic mitigation.

</details>


### [348] [From Prefix Cache to Fusion RAG Cache: Accelerating LLM Inference in Retrieval-Augmented Generation](https://arxiv.org/abs/2601.12904)
*Jiahao Wang,Weiyu Xie,Mingxing Zhang,Boxing Zhang,Jianwei Dong,Yuening Zhu,Chen Lin,Jinqi Tang,Yaochen Han,Zhiyuan Ai,Xianglin Chen,Yongwei Wu,Congfeng Jiang*

Main category: cs.CL

TL;DR: FusionRAG是一个新的RAG推理框架，通过在预处理阶段嵌入跨块上下文信息，在在线处理阶段选择性重计算关键token的KV缓存，实现了生成质量与效率的更好平衡。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法重用检索块的预处理KV缓存来加速推理，但缺乏跨块上下文信息导致生成质量显著下降，KV缓存重用的潜在优势未能充分发挥。

Method: 提出FusionRAG框架：1) 离线预处理阶段：将其他相关文本块的信息嵌入到每个块中；2) 在线重处理阶段：重新计算模型关注的关键token的KV缓存。

Result: FusionRAG在相同重计算比例下显著提升生成质量，重计算少于15%的token即可获得比基线高70%的归一化F1分数，TTFT比Full Attention减少2.66-9.39倍。

Conclusion: FusionRAG通过优化RAG的预处理和重处理阶段，在保持KV缓存重用效率优势的同时，有效解决了跨块上下文信息缺失问题，实现了生成质量与推理效率的更好权衡。

Abstract: Retrieval-Augmented Generation enhances Large Language Models by integrating external knowledge, which reduces hallucinations but increases prompt length. This increase leads to higher computational costs and longer Time to First Token (TTFT). To mitigate this issue, existing solutions aim to reuse the preprocessed KV cache of each retrieved chunk to accelerate RAG. However, the lack of cross-chunk contextual information leads to a significant drop in generation quality, leaving the potential benefits of KV cache reuse largely unfulfilled. The challenge lies in how to reuse the precomputed KV cache of chunks while preserving generation quality. We propose FusionRAG, a novel inference framework that optimizes both the preprocessing and reprocessing stages of RAG. In the offline preprocessing stage, we embed information from other related text chunks into each chunk, while in the online reprocessing stage, we recompute the KV cache for tokens that the model focuses on. As a result, we achieve a better trade-off between generation quality and efficiency. According to our experiments, FusionRAG significantly improves generation quality at the same recomputation ratio compared to previous state-of-the-art solutions. By recomputing fewer than 15% of the tokens, FusionRAG achieves up to 70% higher normalized F1 scores than baselines and reduces TTFT by 2.66x-9.39x compared to Full Attention.

</details>


### [349] [Gated Differentiable Working Memory for Long-Context Language Modeling](https://arxiv.org/abs/2601.12906)
*Lingrui Mei,Shenghua Liu,Yiwei Wang,Yuyao Ge,Baolong Bi,Jiayu Yao,Jun Wan,Ziling Yin,Jiafeng Guo,Xueqi Cheng*

Main category: cs.CL

TL;DR: Gdwm框架通过门控机制选择性地将上下文信息写入工作记忆，用4倍更少的梯度步骤达到或超过均匀基线性能，建立了测试时适应的效率-性能帕累托前沿。


<details>
  <summary>Details</summary>
Motivation: 长上下文挑战Transformer：注意力分数在数千个token上被稀释，关键信息常在中段丢失，模型在推理时难以适应新模式。现有测试时适应方法依赖均匀写入策略，浪费计算在低效用区域，且在语义异构上下文上梯度方差高。

Method: 将测试时适应重构为预算约束下的记忆巩固问题，提出Gdwm框架，引入写入控制器来门控巩固过程。控制器估计上下文效用（信息论的长距离上下文依赖度量），相应分配梯度步骤同时保持全局覆盖。

Result: 在ZeroSCROLLS和LongBench v2上的实验表明，Gdwm用4倍更少的梯度步骤达到或超过均匀基线的性能，建立了测试时适应的新效率-性能帕累托前沿。

Conclusion: 通过选择性记忆巩固的预算约束方法，Gdwm显著提高了测试时适应的计算效率，解决了长上下文处理中的关键挑战。

Abstract: Long contexts challenge transformers: attention scores dilute across thousands of tokens, critical information is often lost in the middle, and models struggle to adapt to novel patterns at inference time. Recent work on test-time adaptation addresses this by maintaining a form of working memory -- transient parameters updated on the current context -- but existing approaches rely on uniform write policies that waste computation on low-utility regions and suffer from high gradient variance across semantically heterogeneous contexts. In this work, we reframe test-time adaptation as a budget-constrained memory consolidation problem, focusing on which parts of the context should be consolidated into working memory under limited computation. We propose Gdwm (Gated Differentiable Working Memory), a framework that introduces a write controller to gate the consolidation process. The controller estimates Contextual Utility, an information-theoretic measure of long-range contextual dependence, and allocates gradient steps accordingly while maintaining global coverage. Experiments on ZeroSCROLLS and LongBench v2 demonstrate that Gdwm achieves comparable or superior performance with 4$\times$ fewer gradient steps than uniform baselines, establishing a new efficiency-performance Pareto frontier for test-time adaptation.

</details>


### [350] [SciCoQA: Quality Assurance for Scientific Paper--Code Alignment](https://arxiv.org/abs/2601.12910)
*Tim Baumgärtner,Iryna Gurevych*

Main category: cs.CL

TL;DR: SciCoQA是一个检测科学论文与代码库差异的数据集，包含真实和合成数据，涵盖多个计算科学领域，用于评估LLMs检测论文-代码差异的能力。


<details>
  <summary>Details</summary>
Motivation: 确保科学论文的实现忠实于原始描述，解决论文与代码库之间可能存在的差异问题，这对于科学可重复性至关重要。

Method: 从GitHub问题和可重复性论文中构建真实差异数据，并提出合成数据生成方法来扩展数据集。详细分析差异类型和类别，构建包含611个差异实例的数据集（81个真实，530个合成）。

Result: 数据集涵盖AI、物理、定量生物学等多个计算科学领域。评估21个LLMs显示SciCoQA任务具有挑战性，特别是在涉及省略论文细节、长上下文输入和预训练语料库外数据的情况下。最佳模型GPT-5仅能检测45.7%的真实世界论文-代码差异。

Conclusion: 论文-代码差异检测是一个具有挑战性的任务，当前LLMs能力有限，需要进一步研究来改进科学实现的可信度验证。

Abstract: We present SciCoQA, a dataset for detecting discrepancies between scientific publications and their codebases to ensure faithful implementations. We construct SciCoQA from GitHub issues and reproducibility papers, and to scale our dataset, we propose a synthetic data generation method for constructing paper-code discrepancies. We analyze the paper-code discrepancies in detail and propose discrepancy types and categories to better understand the occurring mismatches. In total, our dataset consists of 611 paper-code discrepancies (81 real, 530 synthetic), spanning diverse computational science disciplines, including AI, Physics, Quantitative Biology, and others. Our evaluation of 21 LLMs highlights the difficulty of SciCoQA, particularly for instances involving omitted paper details, long-context inputs, and data outside the models' pre-training corpus. The best performing model in our evaluation, GPT-5, can only detect 45.7\% of real-world paper-code discrepancies.

</details>


### [351] [Injecting Knowledge from Social Science Journals to Improve Indonesian Cultural Understanding by LLMs](https://arxiv.org/abs/2601.12921)
*Adimulya Kartiyasa,Bao Gia Cao,Boyang Li*

Main category: cs.CL

TL;DR: 提出IndoSoSci数据集，通过RAG与LLM生成假设文档作为查询，有效注入印尼文化知识到LLMs，在IndoCulture基准上取得SOTA性能


<details>
  <summary>Details</summary>
Motivation: 目前LLMs对印尼文化的理解有限，而本地社会科学期刊包含大量本土视角的文化研究，但这一宝贵资源被忽视

Method: 1) 从151个开源印尼社会科学期刊创建IndoSoSci数据集；2) 提取印尼文化相关事实；3) 使用RAG框架，以LLM生成的假设文档作为检索查询

Result: 提出的方法在IndoCulture基准上显著超越多个强基线，结合印尼维基百科后达到新的SOTA准确率

Conclusion: 本地社会科学期刊是LLMs学习印尼文化的宝贵资源，提出的RAG与假设文档查询方法能有效注入文化知识，提升LLMs对印尼文化的理解

Abstract: Recently there have been intensifying efforts to improve the understanding of Indonesian cultures by large language models (LLMs). An attractive source of cultural knowledge that has been largely overlooked is local journals of social science, which likely contain substantial cultural studies from a native perspective. We present a novel text dataset of journal article passages, created from 151 open-source Indonesian social science journals, called IndoSoSci. We demonstrate an effective recipe for injecting Indonesian cultural knowledge therein into LLMs: extracting the facts related to Indonesian culture, and apply retrieval-augmented generation (RAG) with LLM-generated hypothetical documents as queries during retrieval. The proposed recipe yields strong performance gains over several strong baselines on the IndoCulture benchmark. Additionally, by combining IndoSoSci with Indonesian Wikipedia, we set a new state-of-the-art accuracy on the IndoCulture benchmark.

</details>


### [352] [A Component-Based Survey of Interactions between Large Language Models and Multi-Armed Bandits](https://arxiv.org/abs/2601.12945)
*Miao Xie,Siguang Chen,Chunli Lv*

Main category: cs.CL

TL;DR: 这篇论文是第一篇在组件层面系统综述大语言模型与多臂老虎机双向交互的调研文章，探讨了两者相互增强的潜力。


<details>
  <summary>Details</summary>
Motivation: 大语言模型已成为强大的语言理解和生成系统，而多臂老虎机算法为不确定性下的自适应决策提供了原则性框架。目前缺乏对这两个领域在组件层面双向交互的系统性综述，因此需要探索它们之间的协同潜力。

Method: 采用系统性文献调研方法，从组件层面分析LLM与MAB的双向交互：一方面分析MAB算法如何解决LLM从预训练到检索增强生成和个性化等关键挑战；另一方面分析LLM如何通过重新定义臂定义和环境建模等核心组件来增强MAB系统。

Result: 识别了现有LLM增强老虎机系统和老虎机增强LLM系统的设计、方法和性能，总结了关键挑战和代表性发现，为未来研究提供指导。同时创建了GitHub仓库索引相关文献。

Conclusion: LLM与MAB之间存在显著的双向协同潜力：MAB算法能够解决LLM的关键挑战，而LLM能够增强MAB系统的决策能力。该调研为这一新兴交叉领域的研究提供了系统性框架和未来方向。

Abstract: Large language models (LLMs) have become powerful and widely used systems for language understanding and generation, while multi-armed bandit (MAB) algorithms provide a principled framework for adaptive decision-making under uncertainty. This survey explores the potential at the intersection of these two fields. As we know, it is the first survey to systematically review the bidirectional interaction between large language models and multi-armed bandits at the component level. We highlight the bidirectional benefits: MAB algorithms address critical LLM challenges, spanning from pre-training to retrieval-augmented generation (RAG) and personalization. Conversely, LLMs enhance MAB systems by redefining core components such as arm definition and environment modeling, thereby improving decision-making in sequential tasks. We analyze existing LLM-enhanced bandit systems and bandit-enhanced LLM systems, providing insights into their design, methodologies, and performance. Key challenges and representative findings are identified to help guide future research. An accompanying GitHub repository that indexes relevant literature is available at https://github.com/bucky1119/Awesome-LLM-Bandit-Interaction.

</details>


### [353] [Trustworthy Data-driven Chronological Age Estimation from Panoramic Dental Images](https://arxiv.org/abs/2601.12960)
*Ainhoa Vivel-Couso,Nicolás Vila-Blanco,María J. Carreira,Alberto Bugarín-Diz,Inmaculada Tomás,Jose M. Alonso-Moral*

Main category: cs.CL

TL;DR: 提出一个结合不透明与透明方法的牙科年龄估计系统，通过自然语言生成模块为临床医生提供可理解的文本解释，提升AI在医疗领域的可信度。


<details>
  <summary>Details</summary>
Motivation: 深度学习在医疗保健中的应用虽然能实现个性化护理，但由于模型不透明性导致信任问题。需要提高AI系统的透明度以增强临床医生的信任。

Method: 开发一个牙科年龄估计系统，结合不透明和透明方法，通过自然语言生成模块产生临床医生友好的文本解释。解释规则基于牙科专家知识设计，并通过问卷由专家手动验证解释质量。

Result: 专家在五个维度上的平均评分为4.77±0.12（满分5分），显示解释质量很高。系统在ALTAI检查表的七个维度上获得4.40±0.27（满分5分）的可信度评分。

Conclusion: 提出的系统成功提高了牙科年龄估计的透明度，通过自然语言解释增强了临床医生对AI结果的信任，为医疗AI的可信度评估提供了实用框架。

Abstract: Integrating deep learning into healthcare enables personalized care but raises trust issues due to model opacity. To improve transparency, we propose a system for dental age estimation from panoramic images that combines an opaque and a transparent method within a natural language generation (NLG) module. This module produces clinician-friendly textual explanations about the age estimations, designed with dental experts through a rule-based approach. Following the best practices in the field, the quality of the generated explanations was manually validated by dental experts using a questionnaire. The results showed a strong performance, since the experts rated 4.77+/-0.12 (out of 5) on average across the five dimensions considered. We also performed a trustworthy self-assessment procedure following the ALTAI checklist, in which it scored 4.40+/-0.27 (out of 5) across seven dimensions of the AI Trustworthiness Assessment List.

</details>


### [354] [Pardon? Evaluating Conversational Repair in Large Audio-Language Models](https://arxiv.org/abs/2601.12973)
*Shuanghong Huang,Jinlei Xu,Youchao Zhou,Yanghao Zhou,Xuan Zhao,Chong Feng,Wenxuan Zhang*

Main category: cs.CL

TL;DR: 论文提出了一种修复感知的评估框架，用于评估大型音频语言模型在可回答与不可回答音频输入下的表现，并引入了EAR评分来联合评估任务能力和修复行为。


<details>
  <summary>Details</summary>
Motivation: 现有的大音频语言模型评估主要关注答案准确性和对声学扰动的鲁棒性，但假设语音输入在语义上总是可回答的。这种假设在现实交互中常常失效，因为可能缺少关键信息。需要一种能区分可回答与不可回答输入的评估方法。

Method: 提出了修复感知的评估设置，通过语义-声学掩码协议构建配对评估条件。定义了EAR评分（可评估性意识和修复评分），这是一个非补偿性指标，联合评估可回答条件下的任务能力和不可回答条件下的修复行为。

Result: 在两个语音问答基准测试上的实验表明，许多模型在输入可回答时表现良好，但大多数无法识别语义不可回答性并启动适当的对话修复，揭示了准确性与对话可靠性之间的差距。

Conclusion: 当前以准确性为中心的评估实践存在局限性，需要将不可回答输入视为修复和持续交互线索的可靠性评估方法，以更好地反映现实世界交互需求。

Abstract: Large Audio-Language Models (LALMs) have demonstrated strong performance in spoken question answering (QA), with existing evaluations primarily focusing on answer accuracy and robustness to acoustic perturbations. However, such evaluations implicitly assume that spoken inputs remain semantically answerable, an assumption that often fails in real-world interaction when essential information is missing. In this work, we introduce a repair-aware evaluation setting that explicitly distinguishes between answerable and unanswerable audio inputs. We define answerability as a property of the input itself and construct paired evaluation conditions using a semantic-acoustic masking protocol. Based on this setting, we propose the Evaluability Awareness and Repair (EAR) score, a non-compensatory metric that jointly evaluates task competence under answerable conditions and repair behavior under unanswerable conditions. Experiments on two spoken QA benchmarks across diverse LALMs reveal a consistent gap between answer accuracy and conversational reliability: while many models perform well when inputs are answerable, most fail to recognize semantic unanswerability and initiate appropriate conversational repair. These findings expose a limitation of prevailing accuracy-centric evaluation practices and motivate reliability assessments that treat unanswerable inputs as cues for repair and continued interaction.

</details>


### [355] [Bridging the Knowledge-Action Gap by Evaluating LLMs in Dynamic Dental Clinical Scenarios](https://arxiv.org/abs/2601.12974)
*Hongyang Ma,Tiantian Gu,Huaiyuan Sun,Huilin Zhu,Yongxin Wang,Jie Li,Wubin Sun,Zeliang Lian,Yinghong Zhou,Yi Gao,Shirui Wang,Zhihui Tang*

Main category: cs.CL

TL;DR: 该研究开发了SCMPE基准测试，发现LLMs在静态牙科任务中表现良好，但在动态临床对话中表现下降，主要瓶颈在于主动信息收集和状态跟踪能力不足，RAG在动态工作流中效果有限。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型从被动知识检索器向自主临床代理转变，需要从静态准确性评估转向动态行为可靠性评估。牙科领域的高质量AI建议对患者参与式决策制定尤为重要，因此需要探索LLMs在该领域的边界。

Method: 提出了标准化临床管理与性能评估（SCMPE）基准，全面评估从知识导向评估（静态客观任务）到基于工作流的模拟（多轮模拟患者互动）的性能。分析了指南遵循与决策质量的关系，并量化了检索增强生成（RAG）的影响。

Result: 模型在静态客观任务中表现出高熟练度，但在动态临床对话中性能显著下降。主要瓶颈不在于知识保留，而在于主动信息收集和动态状态跟踪的挑战。发现通用模型存在"高效能、低安全性"风险。RAG在静态任务中减少幻觉，但在动态工作流中效果有限且异质，有时甚至导致性能下降。

Conclusion: 外部知识本身无法弥补推理差距，需要领域自适应预训练。该研究实证地绘制了牙科LLMs的能力边界，为弥合标准化知识与安全、自主临床实践之间的差距提供了路线图。

Abstract: The transition of Large Language Models (LLMs) from passive knowledge retrievers to autonomous clinical agents demands a shift in evaluation-from static accuracy to dynamic behavioral reliability. To explore this boundary in dentistry, a domain where high-quality AI advice uniquely empowers patient-participatory decision-making, we present the Standardized Clinical Management & Performance Evaluation (SCMPE) benchmark, which comprehensively assesses performance from knowledge-oriented evaluations (static objective tasks) to workflow-based simulations (multi-turn simulated patient interactions). Our analysis reveals that while models demonstrate high proficiency in static objective tasks, their performance precipitates in dynamic clinical dialogues, identifying that the primary bottleneck lies not in knowledge retention, but in the critical challenges of active information gathering and dynamic state tracking. Mapping "Guideline Adherence" versus "Decision Quality" reveals a prevalent "High Efficacy, Low Safety" risk in general models. Furthermore, we quantify the impact of Retrieval-Augmented Generation (RAG). While RAG mitigates hallucinations in static tasks, its efficacy in dynamic workflows is limited and heterogeneous, sometimes causing degradation. This underscores that external knowledge alone cannot bridge the reasoning gap without domain-adaptive pre-training. This study empirically charts the capability boundaries of dental LLMs, providing a roadmap for bridging the gap between standardized knowledge and safe, autonomous clinical practice.

</details>


### [356] [The Bitter Lesson of Diffusion Language Models for Agentic Workflows: A Comprehensive Reality Check](https://arxiv.org/abs/2601.12979)
*Qingyu Lu,Liang Ding,Kanjian Zhang,Jinxia Zhang,Dacheng Tao*

Main category: cs.CL

TL;DR: 扩散大语言模型(dLLMs)在实时智能体交互中效率提升明显，但在实际智能体任务中表现不佳，特别是在长时程规划和精确格式要求方面存在系统性失败。


<details>
  <summary>Details</summary>
Motivation: 研究扩散大语言模型(dLLMs)作为自回归模型的替代方案，能否在保持效率优势的同时，实现有效的智能体行为。当前对dLLMs在智能体任务中的实际表现缺乏全面评估。

Method: 在Agentboard和BFCL两个基准上，对dLLMs(如LLaDA、Dream)进行综合评估，涵盖两种智能体范式：具身智能体(需要长时程规划)和工具调用智能体(需要精确格式)。引入DiffuAgent多智能体评估框架，将dLLMs作为即插即用的认知核心。

Result: dLLMs在智能体任务中表现不佳：1)在具身环境中，dLLMs反复尝试失败，无法在时间反馈下进行分支；2)在工具调用环境中，dLLMs在扩散噪声下无法保持符号精度(如严格的JSON模式)。dLLMs在非因果角色(如记忆总结和工具选择)中有效，但需要将因果、精确和逻辑推理机制整合到去噪过程中。

Conclusion: 当前dLLMs不能作为可靠的智能体骨干模型，其效率优势未能转化为有效的智能体行为。要使dLLMs适用于智能体任务，需要在去噪过程中整合因果、精确和逻辑推理机制。

Abstract: The pursuit of real-time agentic interaction has driven interest in Diffusion-based Large Language Models (dLLMs) as alternatives to auto-regressive backbones, promising to break the sequential latency bottleneck. However, does such efficiency gains translate into effective agentic behavior? In this work, we present a comprehensive evaluation of dLLMs (e.g., LLaDA, Dream) across two distinct agentic paradigms: Embodied Agents (requiring long-horizon planning) and Tool-Calling Agents (requiring precise formatting). Contrary to the efficiency hype, our results on Agentboard and BFCL reveal a "bitter lesson": current dLLMs fail to serve as reliable agentic backbones, frequently leading to systematically failure. (1) In Embodied settings, dLLMs suffer repeated attempts, failing to branch under temporal feedback. (2) In Tool-Calling settings, dLLMs fail to maintain symbolic precision (e.g. strict JSON schemas) under diffusion noise. To assess the potential of dLLMs in agentic workflows, we introduce DiffuAgent, a multi-agent evaluation framework that integrates dLLMs as plug-and-play cognitive cores. Our analysis shows that dLLMs are effective in non-causal roles (e.g., memory summarization and tool selection) but require the incorporation of causal, precise, and logically grounded reasoning mechanisms into the denoising process to be viable for agentic tasks.

</details>


### [357] [ChartAttack: Testing the Vulnerability of LLMs to Malicious Prompting in Chart Generation](https://arxiv.org/abs/2601.12983)
*Jesus-German Ortiz-Barajas,Jonathan Tonglet,Vivek Gupta,Iryna Gurevych*

Main category: cs.CL

TL;DR: ChartAttack框架评估多模态大语言模型生成误导性图表的风险，通过注入误导元素降低图表问答准确性


<details>
  <summary>Details</summary>
Motivation: 随着多模态大语言模型被广泛用于从数据表自动生成图表，虽然提高了数据分析效率，但也带来了新的滥用风险，需要评估这些模型如何被用于大规模生成误导性图表

Method: 提出ChartAttack框架，通过向图表设计中注入误导元素来诱导对底层数据的错误解读；创建AttackViz数据集，包含标注了有效误导元素及其诱导错误答案的图表问答对

Result: 在领域内和跨领域设置中，ChartAttack显著降低了MLLM阅读器的问答性能，准确率分别平均下降19.6分和14.9分；人类研究显示参与者面对误导性图表时准确率平均下降20.2分

Conclusion: 研究结果强调了在MLLM图表生成系统的设计、评估和部署中迫切需要加强鲁棒性和安全性考虑

Abstract: Multimodal large language models (MLLMs) are increasingly used to automate chart generation from data tables, enabling efficient data analysis and reporting but also introducing new misuse risks. In this work, we introduce ChartAttack, a novel framework for evaluating how MLLMs can be misused to generate misleading charts at scale. ChartAttack injects misleaders into chart designs, aiming to induce incorrect interpretations of the underlying data. Furthermore, we create AttackViz, a chart question-answering (QA) dataset where each (chart specification, QA) pair is labeled with effective misleaders and their induced incorrect answers. Experiments in in-domain and cross-domain settings show that ChartAttack significantly degrades the QA performance of MLLM readers, reducing accuracy by an average of 19.6 points and 14.9 points, respectively. A human study further shows an average 20.2 point drop in accuracy for participants exposed to misleading charts generated by ChartAttack. Our findings highlight an urgent need for robustness and security considerations in the design, evaluation, and deployment of MLLM-based chart generation systems. We make our code and data publicly available.

</details>


### [358] [Graph Reasoning Paradigm: Structured and Symbolic Reasoning with Topology-Aware Reinforcement Learning for Large Language Models](https://arxiv.org/abs/2601.12995)
*Runxuan Liu,Xianhao Ou,Xinyan Ma,Jiyuan Wang,Jiafeng Liang,Jiaqi Li,Tao He,Zheng Chu,Rongchuan Mu,Zekun Wang,Baoxin Wang,Dayong Wu,Ming Liu,Shijin Wang,Guoping Hu,Bing Qin*

Main category: cs.CL

TL;DR: 提出Graph Reasoning Paradigm (GRP)和PASC-GRPO方法，通过图结构表示和结构化评估解决传统LCoT方法中的计算瓶颈、监督粗糙、奖励黑客等问题，显著提升数学推理和代码生成性能。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs的推理主要生成纯文本，对非结构化数据进行语义评估会造成训练时的计算瓶颈。尽管有RLVR优化，现有方法仍存在监督粒度粗糙、奖励黑客、训练成本高、泛化能力差等问题。

Method: 提出Graph Reasoning Paradigm (GRP)，通过图结构表示和步骤级认知标签实现结构化和符号化推理。在此基础上设计PASC-GRPO方法，用结构化评估替代语义评估，通过图结构结果奖励实现过程感知验证，并通过分层裁剪优势估计缓解奖励黑客问题。

Result: 实验表明在数学推理和代码生成任务上取得了显著改进。数据、模型和代码将在后续发布。

Conclusion: GRP和PASC-GRPO通过结构化推理和评估有效解决了传统LCoT方法的局限性，为LLMs推理能力提升提供了新范式。

Abstract: Long Chain-of-Thought (LCoT), achieved by Reinforcement Learning with Verifiable Rewards (RLVR), has proven effective in enhancing the reasoning capabilities of Large Language Models (LLMs). However, reasoning in current LLMs is primarily generated as plain text, where performing semantic evaluation on such unstructured data creates a computational bottleneck during training. Despite RLVR-based optimization, existing methods still suffer from coarse-grained supervision, reward hacking, high training costs, and poor generalization. To address these issues, we propose the Graph Reasoning Paradigm (GRP), which realizes structured and symbolic reasoning, implemented via graph-structured representations with step-level cognitive labels. Building upon GRP, we further design Process-Aware Stratified Clipping Group Relative Policy Optimization (PASC-GRPO), which leverages structured evaluation to replace semantic evaluation, achieves process-aware verification through graph-structured outcome rewards, and mitigates reward hacking via stratified clipping advantage estimation. Experiments demonstrate significant improvements across mathematical reasoning and code generation tasks. Data, models, and code will be released later.

</details>


### [359] [Bi-Attention HateXplain : Taking into account the sequential aspect of data during explainability in a multi-task context](https://arxiv.org/abs/2601.13018)
*Ghislain Dorian Tchuente Mondjo*

Main category: cs.CL

TL;DR: 提出BiAtt-BiRNN-HateXplain模型，通过双向注意力机制和双向RNN层改进仇恨言论检测的解释性和分类性能，减少无意偏见。


<details>
  <summary>Details</summary>
Motivation: 现有仇恨言论检测模型存在解释不一致问题：基于HateXplain基准的多任务方法虽然同时学习解释和分类，但预测注意力变化很大，导致解释不一致、预测不稳定和学习困难。需要更透明、考虑数据序列特性的模型来改进解释性和减少无意偏见。

Method: 提出BiAtt-BiRNN-HateXplain模型：1) 使用双向注意力机制提供更稳定的解释；2) 加入双向RNN层考虑输入数据的序列特性；3) 通过多任务学习同时优化解释性和分类任务；4) 相比复杂的大型语言模型，该模型更易解释且透明。

Result: 在HateXplain数据上的实验结果显示：1) 检测性能明显提升；2) 解释性改善；3) 无意偏见减少。模型通过更好的解释估计实现了更准确的分类和更少的偏见错误。

Conclusion: BiAtt-BiRNN-HateXplain模型有效解决了仇恨言论检测中注意力变化大导致解释不一致的问题，通过双向注意力和序列建模提高了模型透明度、解释性和分类性能，同时减少了针对特定社区的无意偏见。

Abstract: Technological advances in the Internet and online social networks have brought many benefits to humanity. At the same time, this growth has led to an increase in hate speech, the main global threat. To improve the reliability of black-box models used for hate speech detection, post-hoc approaches such as LIME, SHAP, and LRP provide the explanation after training the classification model. In contrast, multi-task approaches based on the HateXplain benchmark learn to explain and classify simultaneously. However, results from HateXplain-based algorithms show that predicted attention varies considerably when it should be constant. This attention variability can lead to inconsistent interpretations, instability of predictions, and learning difficulties. To solve this problem, we propose the BiAtt-BiRNN-HateXplain (Bidirectional Attention BiRNN HateXplain) model which is easier to explain compared to LLMs which are more complex in view of the need for transparency, and will take into account the sequential aspect of the input data during explainability thanks to a BiRNN layer. Thus, if the explanation is correctly estimated, thanks to multi-task learning (explainability and classification task), the model could classify better and commit fewer unintentional bias errors related to communities. The experimental results on HateXplain data show a clear improvement in detection performance, explainability and a reduction in unintentional bias.

</details>


### [360] [Tears or Cheers? Benchmarking LLMs via Culturally Elicited Distinct Affective Responses](https://arxiv.org/abs/2601.13024)
*Chongyuan Dai,Yaling Shen,Jinpeng Hu,Zihan Gao,Jia Li,Yishun Jiang,Yaxiong Wang,Liu Liu,Zongyuan Ge*

Main category: cs.CL

TL;DR: CEDAR是一个多模态基准测试，专注于捕捉文化引发的不同情感反应，评估大语言模型在跨文化情感理解方面的能力。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型文化对齐评估主要关注地理事实或社会习俗等陈述性知识，无法捕捉不同社会文化视角下的主观解释差异，特别是情感处理方面的文化差异。

Method: 开发了CEDAR基准测试，采用新颖的流程：利用LLM生成的临时标签来识别产生跨文化情感差异的实例，然后通过严格的人工评估获得可靠的地面真实标注。包含10,962个实例，涵盖7种语言和14种细粒度情感类别。

Result: 对17个代表性多语言模型的评估显示，语言一致性与文化对齐之间存在分离，表明当前模型在基于文化的情感理解方面仍面临重大挑战。

Conclusion: 文化对情感理解有重要影响，当前大语言模型在文化对齐的情感理解方面存在不足，需要更全面的评估方法来捕捉文化引发的不同情感反应。

Abstract: Culture serves as a fundamental determinant of human affective processing and profoundly shapes how individuals perceive and interpret emotional stimuli. Despite this intrinsic link extant evaluations regarding cultural alignment within Large Language Models primarily prioritize declarative knowledge such as geographical facts or established societal customs. These benchmarks remain insufficient to capture the subjective interpretative variance inherent to diverse sociocultural lenses. To address this limitation, we introduce CEDAR, a multimodal benchmark constructed entirely from scenarios capturing Culturally \underline{\textsc{E}}licited \underline{\textsc{D}}istinct \underline{\textsc{A}}ffective \underline{\textsc{R}}esponses. To construct CEDAR, we implement a novel pipeline that leverages LLM-generated provisional labels to isolate instances yielding cross-cultural emotional distinctions, and subsequently derives reliable ground-truth annotations through rigorous human evaluation. The resulting benchmark comprises 10,962 instances across seven languages and 14 fine-grained emotion categories, with each language including 400 multimodal and 1,166 text-only samples. Comprehensive evaluations of 17 representative multilingual models reveal a dissociation between language consistency and cultural alignment, demonstrating that culturally grounded affective understanding remains a significant challenge for current models.

</details>


### [361] [SASA: Semantic-Aware Contrastive Learning Framework with Separated Attention for Triple Classification](https://arxiv.org/abs/2601.13035)
*Xu Xiaodan,Hu Xiaolin*

Main category: cs.CL

TL;DR: SASA框架通过分离注意力机制和语义感知对比学习提升知识图谱三元组分类性能，在FB15k-237和YAGO3-10数据集上分别实现+5.9%和+3.4%的准确率提升。


<details>
  <summary>Details</summary>
Motivation: 知识图谱常包含不可靠知识，现有三元组分类方法存在两个关键问题：1) 忽视不同KG组件间的有效语义交互；2) 单一二元分类训练目标导致语义表示学习不足。

Method: 提出SASA框架：1) 分离注意力机制将三元组编码为解耦的上下文表示并通过更有效的交互方式融合；2) 语义感知分层对比学习作为辅助训练目标，考虑局部和全局层次的对比学习。

Result: 在两个基准数据集上显著优于现有方法：FB15k-237准确率提升+5.9%，YAGO3-10准确率提升+3.4%，刷新了最先进性能。

Conclusion: SASA通过改进的注意力机制和对比学习有效解决了三元组分类中的语义交互和表示学习问题，为知识图谱可靠性验证提供了更强大的框架。

Abstract: Knowledge Graphs~(KGs) often suffer from unreliable knowledge, which restricts their utility. Triple Classification~(TC) aims to determine the validity of triples from KGs. Recently, text-based methods learn entity and relation representations from natural language descriptions, significantly improving the generalization capabilities of TC models and setting new benchmarks in performance. However, there are still two critical challenges. First, existing methods often ignore the effective semantic interaction among different KG components. Second, most approaches adopt single binary classification training objective, leading to insufficient semantic representation learning. To address these challenges, we propose \textbf{SASA}, a novel framework designed to enhance TC models via separated attention mechanism and semantic-aware contrastive learning~(CL). Specifically, we first propose separated attention mechanism to encode triples into decoupled contextual representations and then fuse them through a more effective interactive way. Then, we introduce semantic-aware hierarchical CL as auxiliary training objective to guide models in improving their discriminative capabilities and achieving sufficient semantic learning, considering both local level and global level CL. Experimental results across two benchmark datasets demonstrate that SASA significantly outperforms state-of-the-art methods. In terms of accuracy, we advance the state-of-the-art by +5.9\% on FB15k-237 and +3.4\% on YAGO3-10.

</details>


### [362] [Typhoon ASR Real-time: FastConformer-Transducer for Thai Automatic Speech Recognition](https://arxiv.org/abs/2601.13044)
*Warit Sirichotedumrong,Adisai Na-Thalang,Potsawee Manakul,Pittawat Taveekitworachai,Sittipong Sripaisarnmongkol,Kunat Pipatanakul*

Main category: cs.CL

TL;DR: Typhoon ASR Real-time：一个115M参数的FastConformer-Transducer模型，用于低延迟泰语语音识别，通过严格的文本规范化达到与Whisper Large-v3相当的准确性，同时计算成本降低45倍。


<details>
  <summary>Details</summary>
Motivation: 当前泰语ASR领域被离线架构主导，缺乏高效的流式解决方案。Whisper等大型编码器-解码器模型虽然转录准确，但延迟高，不适用于实时应用。

Method: 1) 开发115M参数的FastConformer-Transducer模型；2) 设计严格的文本规范化流程，解决泰语转录中的系统歧义（如上下文相关的数字发音和重复标记）；3) 引入两阶段课程学习方法用于伊森方言适应；4) 发布Typhoon ASR Benchmark标准化评估数据集。

Result: 紧凑模型相比Whisper Large-v3计算成本降低45倍，同时保持相当的准确性。文本规范化显著提升训练一致性，课程学习方法成功适应伊森方言而不影响标准泰语性能。

Conclusion: 严格的文本规范化可以匹配模型缩放的效果，为泰语ASR提供高效流式解决方案。发布的标准化基准将促进泰语ASR研究的可重复性。

Abstract: Large encoder-decoder models like Whisper achieve strong offline transcription but remain impractical for streaming applications due to high latency. However, due to the accessibility of pre-trained checkpoints, the open Thai ASR landscape remains dominated by these offline architectures, leaving a critical gap in efficient streaming solutions. We present Typhoon ASR Real-time, a 115M-parameter FastConformer-Transducer model for low-latency Thai speech recognition. We demonstrate that rigorous text normalization can match the impact of model scaling: our compact model achieves a 45x reduction in computational cost compared to Whisper Large-v3 while delivering comparable accuracy. Our normalization pipeline resolves systemic ambiguities in Thai transcription --including context-dependent number verbalization and repetition markers (mai yamok) --creating consistent training targets. We further introduce a two-stage curriculum learning approach for Isan (north-eastern) dialect adaptation that preserves Central Thai performance. To address reproducibility challenges in Thai ASR, we release the Typhoon ASR Benchmark, a gold-standard human-labeled datasets with transcriptions following established Thai linguistic conventions, providing standardized evaluation protocols for the research community.

</details>


### [363] [Profiling German Text Simplification with Interpretable Model-Fingerprints](https://arxiv.org/abs/2601.13050)
*Lars Klöser,Mika Beele,Bodo Kraft*

Main category: cs.CL

TL;DR: 本文提出了Simplification Profiler工具包，用于生成文本简化模型的多维可解释指纹，通过模型行为特征而非传统人工评分来诊断模型性能，特别适用于数据稀缺的语言环境。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏对LLM文本简化行为的全面、高效、可复现的诊断工具，特别是在数据稀缺的语言环境中，传统基于人工评分的方法成本高昂且不灵活。

Method: 开发Simplification Profiler工具包，通过聚合多个简化文本生成模型的多维可解释指纹，使用线性分类器验证指纹的描述能力，无需大规模人工标注数据集。

Result: Profiler能区分不同提示策略的高层行为差异和提示工程的细粒度变化，完整特征集的分类F1分数达71.9%，比简单基线提高48个百分点以上。

Conclusion: Simplification Profiler为开发者提供了细粒度、可操作的分析工具，有助于构建更有效和真正自适应的文本简化系统。

Abstract: While Large Language Models (LLMs) produce highly nuanced text simplifications, developers currently lack tools for a holistic, efficient, and reproducible diagnosis of their behavior. This paper introduces the Simplification Profiler, a diagnostic toolkit that generates a multidimensional, interpretable fingerprint of simplified texts. Multiple aggregated simplifications of a model result in a model's fingerprint. This novel evaluation paradigm is particularly vital for languages, where the data scarcity problem is magnified when creating flexible models for diverse target groups rather than a single, fixed simplification style. We propose that measuring a model's unique behavioral signature is more relevant in this context as an alternative to correlating metrics with human preferences. We operationalize this with a practical meta-evaluation of our fingerprints' descriptive power, which bypasses the need for large, human-rated datasets. This test measures if a simple linear classifier can reliably identify various model configurations by their created simplifications, confirming that our metrics are sensitive to a model's specific characteristics. The Profiler can distinguish high-level behavioral variations between prompting strategies and fine-grained changes from prompt engineering, including few-shot examples. Our complete feature set achieves classification F1-scores up to 71.9 %, improving upon simple baselines by over 48 percentage points. The Simplification Profiler thus offers developers a granular, actionable analysis to build more effective and truly adaptive text simplification systems.

</details>


### [364] [Alexandria: A Multi-Domain Dialectal Arabic Machine Translation Dataset for Culturally Inclusive and Linguistically Diverse LLMs](https://arxiv.org/abs/2601.13099)
*Abdellah El Mekki,Samar M. Magdy,Houdaifa Atou,Ruwa AbuHweidi,Baraah Qawasmeh,Omer Nacar,Thikra Al-hibiri,Razan Saadie,Hamzah Alsayadi,Nadia Ghezaiel Hammouda,Alshima Alkhazimi,Aya Hamod,Al-Yas Al-Ghafri,Wesam El-Sayed,Asila Al sharji,Mohamad Ballout,Anas Belfathi,Karim Ghaddar,Serry Sibaee,Alaa Aoun,Areej Asiri,Lina Abureesh,Ahlam Bashiti,Majdal Yousef,Abdulaziz Hafiz,Yehdih Mohamed,Emira Hamedtou,Brakehe Brahim,Rahaf Alhamouri,Youssef Nafea,Aya El Aatar,Walid Al-Dhabyani,Emhemed Hamed,Sara Shatnawi,Fakhraddin Alwajih,Khalid Elkhidir,Ashwag Alasmari,Abdurrahman Gerrio,Omar Alshahri,AbdelRahim A. Elmadany,Ismail Berrada,Amir Azad Adli Alkathiri,Fadi A Zaraket,Mustafa Jarrar,Yahya Mohamed El Hadj,Hassan Alhuzali,Muhammad Abdul-Mageed*

Main category: cs.CL

TL;DR: Alexandria是一个大规模、社区驱动、人工翻译的数据集，旨在解决阿拉伯语方言机器翻译的挑战，覆盖13个阿拉伯国家、11个高影响领域，包含城市来源元数据和性别配置标注。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语是高度双言语言，日常交流主要使用方言而非现代标准阿拉伯语，但现有机器翻译系统对方言输入泛化能力差，限制了数百万使用者的实用性。

Method: 创建Alexandria数据集：大规模、社区驱动、人工翻译，覆盖13个阿拉伯国家、11个高影响领域，提供城市来源元数据，包含多轮对话场景并标注说话者-接收者性别配置。

Result: 数据集包含107K个样本，可作为训练资源和评估基准。通过对阿拉伯语感知LLMs的自动和人工评估，展示了当前跨阿拉伯方言翻译的能力，同时暴露了持续存在的重大挑战。

Conclusion: Alexandria数据集填补了阿拉伯方言翻译资源的空白，提供了前所未有的细粒度方言数据，可作为训练和评估基准，揭示了当前方言翻译系统面临的持续挑战。

Abstract: Arabic is a highly diglossic language where most daily communication occurs in regional dialects rather than Modern Standard Arabic. Despite this, machine translation (MT) systems often generalize poorly to dialectal input, limiting their utility for millions of speakers. We introduce \textbf{Alexandria}, a large-scale, community-driven, human-translated dataset designed to bridge this gap. Alexandria covers 13 Arab countries and 11 high-impact domains, including health, education, and agriculture. Unlike previous resources, Alexandria provides unprecedented granularity by associating contributions with city-of-origin metadata, capturing authentic local varieties beyond coarse regional labels. The dataset consists of multi-turn conversational scenarios annotated with speaker-addressee gender configurations, enabling the study of gender-conditioned variation in dialectal use. Comprising 107K total samples, Alexandria serves as both a training resource and a rigorous benchmark for evaluating MT and Large Language Models (LLMs). Our automatic and human evaluation of Arabic-aware LLMs benchmarks current capabilities in translating across diverse Arabic dialects and sub-dialects, while exposing significant persistent challenges.

</details>


### [365] [Leveraging Lora Fine-Tuning and Knowledge Bases for Construction Identification](https://arxiv.org/abs/2601.13105)
*Liu Kaipeng,Wu Ling*

Main category: cs.CL

TL;DR: 该研究结合LoRA微调大语言模型与RAG框架，自动识别英语双及物结构，在BNC语料上取得显著效果提升


<details>
  <summary>Details</summary>
Motivation: 探索如何有效自动识别英语双及物结构，结合大语言模型微调与检索增强生成技术，提高语法结构识别的准确性和语义理解能力

Method: 采用LoRA微调Qwen3-8B模型，结合RAG框架，在BNC语料上进行英语双及物结构的二元分类任务

Result: LoRA微调的Qwen3-8B模型显著优于原生Qwen3-MAX模型和纯理论RAG系统，错误分析显示微调使模型从表层模式匹配转向语义理解

Conclusion: LoRA微调结合RAG框架能有效提升英语双及物结构的自动识别性能，促进模型从形式匹配到语义理解的转变

Abstract: This study investigates the automatic identification of the English ditransitive construction by integrating LoRA-based fine-tuning of a large language model with a Retrieval-Augmented Generation (RAG) framework.A binary classification task was conducted on annotated data from the British National Corpus. Results demonstrate that a LoRA-fine-tuned Qwen3-8B model significantly outperformed both a native Qwen3-MAX model and a theory-only RAG system. Detailed error analysis reveals that fine-tuning shifts the model's judgment from a surface-form pattern matching towards a more semantically grounded understanding based.

</details>


### [366] [CORE-T: COherent REtrieval of Tables for Text-to-SQL](https://arxiv.org/abs/2601.13111)
*Hassan Soliman,Vivek Gupta,Dan Roth,Iryna Gurevych*

Main category: cs.CL

TL;DR: CORE-T：一种无需训练、可扩展的框架，通过LLM生成表目的元数据和预计算表兼容性缓存，在多表文本到SQL任务中显著提升表选择准确性和执行精度，同时减少推理开销。


<details>
  <summary>Details</summary>
Motivation: 现实文本到SQL工作流通常需要连接多个表，但在大规模异构表集合中准确检索相关表成为端到端性能的关键瓶颈。现有方法要么召回率高但包含大量干扰项，要么依赖额外假设或推理开销大。

Method: 提出CORE-T框架：1）使用LLM为表生成目的元数据；2）预计算轻量级表兼容性缓存；3）推理时先用稠密检索返回top-K候选表；4）单次LLM调用选择可连接的表子集；5）简单加性调整步骤恢复强兼容表。

Result: 在Bird、Spider和MMQA数据集上，CORE-T将表选择F1提升高达22.7分，同时检索表数量减少42%，多表执行精度在Bird上提升5.0分，在MMQA上提升6.9分，比LLM密集型基线少用4-5倍token。

Conclusion: CORE-T通过结合稠密检索的召回优势和LLM的语义理解能力，在无需训练的情况下显著提升多表文本到SQL任务中的表选择性能，同时保持高效推理。

Abstract: Realistic text-to-SQL workflows often require joining multiple tables. As a result, accurately retrieving the relevant set of tables becomes a key bottleneck for end-to-end performance. We study an open-book setting where queries must be answered over large, heterogeneous table collections pooled from many sources, without clean scoping signals such as database identifiers. Here, dense retrieval (DR) achieves high recall but returns many distractors, while join-aware alternatives often rely on extra assumptions and/or incur high inference overhead. We propose CORE-T, a scalable, training-free framework that enriches tables with LLM-generated purpose metadata and pre-computes a lightweight table-compatibility cache. At inference time, DR returns top-K candidates; a single LLM call selects a coherent, joinable subset, and a simple additive adjustment step restores strongly compatible tables. Across Bird, Spider, and MMQA, CORE-T improves table-selection F1 by up to 22.7 points while retrieving up to 42% fewer tables, improving multi-table execution accuracy by up to 5.0 points on Bird and 6.9 points on MMQA, and using 4-5x fewer tokens than LLM-intensive baselines.

</details>


### [367] [Agentic Conversational Search with Contextualized Reasoning via Reinforcement Learning](https://arxiv.org/abs/2601.13115)
*Fengran Mo,Yifan Gao,Sha Li,Hansi Zeng,Xin Liu,Zhaoxuan Tan,Xian Li,Jianshu Chen,Dakuo Wang,Meng Jiang*

Main category: cs.CL

TL;DR: 提出一个通过强化学习训练的多轮对话智能体，能够交替进行搜索和推理，以更好地适应动态变化的用户意图。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型对话系统通常采用静态的改写-检索-生成流程，这些方法分别优化不同步骤，忽略了混合主动行为的联合优化，且主要针对单轮场景，难以处理多轮对话中动态变化的用户意图。

Method: 引入一个多轮对话智能体，通过强化学习训练，在对话轮次间交替进行搜索和推理。该方法使用定制化的奖励机制来适应不断演变的用户目标，实现探索性和自适应行为。

Result: 在四个广泛使用的对话基准测试中，该方法超越了多个现有强基线模型，证明了其有效性。

Conclusion: 通过强化学习训练的多轮对话智能体能够有效处理动态变化的用户意图，在对话轮次间交替进行搜索和推理的方法优于现有的静态流程方法。

Abstract: Large Language Models (LLMs) have become a popular interface for human-AI interaction, supporting information seeking and task assistance through natural, multi-turn dialogue. To respond to users within multi-turn dialogues, the context-dependent user intent evolves across interactions, requiring contextual interpretation, query reformulation, and dynamic coordination between retrieval and generation. Existing studies usually follow static rewrite, retrieve, and generate pipelines, which optimize different procedures separately and overlook the mixed-initiative action optimization simultaneously. Although the recent developments in deep search agents demonstrate the effectiveness in jointly optimizing retrieval and generation via reasoning, these approaches focus on single-turn scenarios, which might lack the ability to handle multi-turn interactions. We introduce a conversational agent that interleaves search and reasoning across turns, enabling exploratory and adaptive behaviors learned through reinforcement learning (RL) training with tailored rewards towards evolving user goals. The experimental results across four widely used conversational benchmarks demonstrate the effectiveness of our methods by surpassing several existing strong baselines.

</details>


### [368] [Adversarial Alignment: Ensuring Value Consistency in Large Language Models for Sensitive Domains](https://arxiv.org/abs/2601.13137)
*Yuan Gao,Zhigang Liu,Xinyu Yao,Bo Chen,Xiaobing Zhao*

Main category: cs.CL

TL;DR: 提出对抗对齐框架VC-LLM，通过持续预训练、指令微调和对抗训练增强大语言模型在敏感领域的价值一致性


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型广泛应用，在种族、社会、政治等敏感领域出现的偏见和价值不一致问题日益突出，需要解决模型在这些领域的价值对齐问题

Method: 提出对抗对齐框架：1）持续预训练；2）指令微调；3）对抗训练（使用Attacker生成争议查询，Actor生成价值一致响应，Critic过滤确保质量）。训练了VC-LLM模型，并构建了中英双语评估数据集

Result: 实验结果表明，VC-LLM在中文和英文测试中都优于现有主流模型，验证了方法的有效性

Conclusion: 提出的对抗对齐框架能够有效增强大语言模型在敏感领域的价值一致性，VC-LLM模型在价值对齐方面表现优异

Abstract: With the wide application of large language models (LLMs), the problems of bias and value inconsistency in sensitive domains have gradually emerged, especially in terms of race, society and politics. In this paper, we propose an adversarial alignment framework, which enhances the value consistency of the model in sensitive domains through continued pre-training, instruction fine-tuning and adversarial training. In adversarial training, we use the Attacker to generate controversial queries, the Actor to generate responses with value consistency, and the Critic to filter and ensure response quality. Furthermore, we train a Value-Consistent Large Language Model, VC-LLM, for sensitive domains, and construct a bilingual evaluation dataset in Chinese and English. The experimental results show that VC-LLM performs better than the existing mainstream models in both Chinese and English tests, verifying the effectiveness of the method. Warning: This paper contains examples of LLMs that are offensive or harmful in nature.

</details>


### [369] [Probe and Skip: Self-Predictive Token Skipping for Efficient Long-Context LLM Inference](https://arxiv.org/abs/2601.13155)
*Zimeng Wu,Donghao Wang,Chaozhe Jin,Jiaxin Chen,Yunhong Wang*

Main category: cs.CL

TL;DR: SPTS是一个无需训练的长上下文LLM推理加速框架，通过选择性token跳过和渐进式剪枝，在保持模型性能的同时实现显著加速。


<details>
  <summary>Details</summary>
Motivation: 长上下文推理虽然增强了LLM的推理能力，但带来了巨大的计算开销。现有的token导向方法（如剪枝和跳过）存在加速潜力有限、代理信号过时和冗余干扰等问题，导致速度-准确率权衡不理想。

Method: SPTS包含三个核心策略：1）Partial Attention Probing (PAP) - 通过部分前向注意力计算选择信息丰富的token；2）Low-rank Transformation Probing (LTP) - 构建低秩代理网络预测token转换；3）Multi-Stage Delayed Pruning (MSDP) - 重新分配跳过预算并在各层渐进式剪枝冗余token。

Result: 实验表明该方法有效，在保持最先进模型性能的同时，实现了预填充阶段2.46倍和端到端生成2.29倍的加速。

Conclusion: SPTS是一个无需训练的高效长上下文LLM推理框架，通过创新的token跳过策略和渐进式剪枝机制，在速度和准确率之间取得了良好平衡。

Abstract: Long-context inference enhances the reasoning capability of Large Language Models (LLMs) while incurring significant computational overhead. Token-oriented methods, such as pruning and skipping, have shown promise in reducing inference latency, but still suffer from inherently limited acceleration potential, outdated proxy signals, and redundancy interference, thus yielding suboptimal speed-accuracy trade-offs. To address these challenges, we propose SPTS (Self-Predictive Token Skipping), a training-free framework for efficient long-context LLM inference. Specifically, motivated by the thought of probing the influence of targeted skipping layers, we design two component-specific strategies for selective token skipping: Partial Attention Probing (PAP) for multi-head attention, which selects informative tokens by performing partial forward attention computation, and Low-rank Transformation Probing (LTP) for feed forward network, which constructs a low-rank proxy network to predict token transformations. Furthermore, a Multi-Stage Delayed Pruning (MSDP) strategy reallocates the skipping budget and progressively prunes redundant tokens across layers. Extensive experiments demonstrate the effectiveness of our method, achieving up to 2.46$\times$ and 2.29$\times$ speedups for prefilling and end-to-end generation, respectively, while maintaining state-of-the-art model performance. The source code will be publicly available upon paper acceptance.

</details>


### [370] [Medical Triage as Pairwise Ranking: A Benchmark for Urgency in Patient Portal Messages](https://arxiv.org/abs/2601.13178)
*Joseph Gatto,Parker Seegmiller,Timothy Burdick,Philip Resnik,Roshnik Rahat,Sarah DeLozier,Sarah M. Preum*

Main category: cs.CL

TL;DR: 该论文提出了首个用于研究异步门诊门户消息医疗分诊的大规模公开数据集PMR-Bench，将患者消息分诊视为成对推理问题，并开发了两种基于LLM的模型（UrgentSFT和UrgentReward）来评估医疗紧急程度。


<details>
  <summary>Details</summary>
Motivation: 医疗分诊是根据医疗需求分配资源和优先处理患者的重要任务，但在异步门诊门户消息场景中缺乏大规模公开数据集和研究。现有方法难以有效处理结合非结构化患者消息和真实电子健康记录数据的真实世界分诊场景。

Method: 1. 构建PMR-Bench数据集：包含1569条独特消息和2000+高质量测试对，结合非结构化患者消息和真实EHR数据；2. 开发自动化数据标注策略为LLM提供领域指导；3. 训练两种模型：UrgentReward（基于Bradley-Terry目标）和UrgentSFT（基于下一词预测目标），用于成对紧急程度分类。

Result: UrgentSFT在PMR-Bench上表现最佳，UrgentReward在低资源设置中显示出独特优势。UrgentSFT-8B和UrgentReward-8B相比现成的8B模型，在收件箱排序指标上分别提升了15和16个百分点。

Conclusion: 该研究为医疗消息分诊提供了首个大规模基准数据集和有效的LLM方法，展示了在真实世界医疗分诊场景中结合患者消息和EHR数据的可行性，为自动化医疗分诊系统的发展奠定了基础。

Abstract: Medical triage is the task of allocating medical resources and prioritizing patients based on medical need. This paper introduces the first large-scale public dataset for studying medical triage in the context of asynchronous outpatient portal messages. Our novel task formulation views patient message triage as a pairwise inference problem, where we train LLMs to choose `"which message is more medically urgent" in a head-to-head tournament-style re-sort of a physician's inbox. Our novel benchmark PMR-Bench contains 1569 unique messages and 2,000+ high-quality test pairs for pairwise medical urgency assessment alongside a scalable training data generation pipeline. PMR-Bench includes samples that contain both unstructured patient-written messages alongside real electronic health record (EHR) data, emulating a real-world medical triage scenario.
  We develop a novel automated data annotation strategy to provide LLMs with in-domain guidance on this task. The resulting data is used to train two model classes, UrgentReward and UrgentSFT, leveraging Bradley-Terry and next token prediction objective, respectively to perform pairwise urgency classification. We find that UrgentSFT achieves top performance on PMR-Bench, with UrgentReward showing distinct advantages in low-resource settings. For example, UrgentSFT-8B and UrgentReward-8B provide a 15- and 16-point boost, respectively, on inbox sorting metrics over off-the-shelf 8B models. Paper resources can be found at https://tinyurl.com/Patient-Message-Triage

</details>


### [371] [OpenExempt: A Diagnostic Benchmark for Legal Reasoning and a Framework for Creating Custom Benchmarks on Demand](https://arxiv.org/abs/2601.13183)
*Sergio Servantez,Sarah B. Lawsky,Rajiv Jain,Daniel W. Linna,Kristian Hammond*

Main category: cs.CL

TL;DR: OpenExempt是一个用于法律推理诊断评估的框架和基准测试，通过专家构建的美国破产法符号表示动态生成自然语言推理任务，包含9,765个样本，揭示语言模型在复杂推理路径下的性能断崖


<details>
  <summary>Details</summary>
Motivation: 现有推理基准测试存在局限性：静态问答对只能提供性能快照，将复杂行为压缩为单一准确率指标；在法律等复杂规则领域，现有基准构建成本高且难以隔离特定失败模式

Method: OpenExempt框架使用专家构建的美国破产法法规符号表示，动态生成大量自然语言推理任务及其机器可计算解决方案；构建包含9,765个样本的OpenExempt基准测试，涵盖9个评估套件，精细探测模型能力

Result: 对13个不同语言模型的实验显示，在较长推理路径和存在混淆语句的情况下，模型性能出现显著断崖式下降；框架和基准测试已公开发布以支持推理系统研究

Conclusion: OpenExempt为法律推理提供了诊断评估框架，能够动态生成任务并精细控制复杂度，揭示了语言模型在复杂推理场景下的局限性，有助于改进下一代推理系统

Abstract: Reasoning benchmarks have played a crucial role in the progress of language models. Yet rigorous evaluation remains a significant challenge as static question-answer pairs provide only a snapshot of performance, compressing complex behavior into a single accuracy metric. This limitation is especially true in complex, rule-bound domains such as law, where existing benchmarks are costly to build and ill suited for isolating specific failure modes. To address this, we introduce OpenExempt, a framework and benchmark for diagnostic evaluation of legal reasoning. The OpenExempt Framework uses expert-crafted symbolic representations of U.S. Bankruptcy Code statutes to dynamically generate a large space of natural language reasoning tasks and their machine-computable solutions on demand. This gives users fine-grained control over task complexity and scope, allowing individual reasoning skills to be probed in isolation. Using this system, we construct the OpenExempt Benchmark, a diagnostic benchmark for legal reasoning with 9,765 samples across nine evaluation suites designed to carefully probe model capabilities. Experiments on 13 diverse language models reveal sharp performance cliffs that emerge only under longer reasoning paths and in the presence of obfuscating statements. We release the framework and benchmark publicly to support research aimed at understanding and improving the next generation of reasoning systems.

</details>


### [372] [Beyond Single-shot Writing: Deep Research Agents are Unreliable at Multi-turn Report Revision](https://arxiv.org/abs/2601.13217)
*Bingsen Chen,Boyan Li,Ping Nie,Yuyu Zhang,Xi Ye,Chen Zhao*

Main category: cs.CL

TL;DR: 论文提出了Mr Dre评估套件，将多轮报告修订作为深度研究代理的新评估维度，发现现有代理在修订时会破坏先前内容且难以保持早期编辑。


<details>
  <summary>Details</summary>
Motivation: 现有深度研究代理基准将报告生成视为单次写作任务，这与人类研究者通过自我反思或同行反馈迭代起草和修订报告的方式存在根本差异。深度研究代理是否能可靠地根据用户反馈修订报告尚未被探索。

Method: 引入Mr Dre评估套件，包括：(1) 统一的长篇报告评估协议，涵盖全面性、事实性和呈现质量；(2) 人工验证的反馈模拟流程，用于多轮修订评估。分析了五种不同的深度研究代理。

Result: 分析发现关键局限性：虽然代理能处理大部分用户反馈，但也会破坏16-27%先前覆盖的内容和引用质量。即使表现最佳的代理在多轮修订后仍有显著改进空间，它们会破坏反馈范围外的内容且无法保持早期编辑。

Conclusion: 深度研究代理在多轮报告修订方面存在系统性缺陷，这些缺陷无法通过推理时修复（如提示工程和专门的报告修订子代理）轻易解决，需要新的方法来解决迭代修订问题。

Abstract: Existing benchmarks for Deep Research Agents (DRAs) treat report generation as a single-shot writing task, which fundamentally diverges from how human researchers iteratively draft and revise reports via self-reflection or peer feedback. Whether DRAs can reliably revise reports with user feedback remains unexplored. We introduce Mr Dre, an evaluation suite that establishes multi-turn report revision as a new evaluation axis for DRAs. Mr Dre consists of (1) a unified long-form report evaluation protocol spanning comprehensiveness, factuality, and presentation, and (2) a human-verified feedback simulation pipeline for multi-turn revision. Our analysis of five diverse DRAs reveals a critical limitation: while agents can address most user feedback, they also regress on 16-27% of previously covered content and citation quality. Over multiple revision turns, even the best-performing agents leave significant headroom, as they continue to disrupt content outside the feedback's scope and fail to preserve earlier edits. We further show that these issues are not easily resolvable through inference-time fixes such as prompt engineering and a dedicated sub-agent for report revision.

</details>


### [373] [Autoregressive Models Rival Diffusion Models at ANY-ORDER Generation](https://arxiv.org/abs/2601.13228)
*Tianqi Du,Lizhe Fang,Weijie Yang,Chenheng Zhang,Zeming Wei,Yifei Wang,Yisen Wang*

Main category: cs.CL

TL;DR: 提出A3框架，将自回归建模扩展为任意token组和生成顺序的通用框架，结合了自回归模型的概率严谨性和扩散模型的灵活性。


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型虽然支持任意顺序生成和双向条件化，但在建模深度、样本质量和稳定性上不如自回归模型。需要结合两者的优势。

Method: 提出A3框架，将扩散式训练重新表述为结构化多组预测过程，使用双流注意力架构和渐进适应策略，将预训练自回归模型过渡到任意顺序预测。

Result: 在问答、常识推理和故事填充任务上，A3优于基于扩散的模型，同时保持灵活的解码能力。

Conclusion: A3提供了一个统一的方法，实现了灵活、高效、新颖的语言建模范式，结合了自回归模型的严谨性和扩散模型的灵活性。

Abstract: Diffusion language models enable any-order generation and bidirectional conditioning, offering appealing flexibility for tasks such as infilling, rewriting, and self-correction. However, their formulation-predicting one part of a sequence from another within a single-step dependency-limits modeling depth and often yields lower sample quality and stability than autoregressive (AR) models. To address this, we revisit autoregressive modeling as a foundation and reformulate diffusion-style training into a structured multi-group prediction process. We propose Any-order Any-subset Autoregressive modeling (A3), a generalized framework that extends the standard AR factorization to arbitrary token groups and generation orders. A3 preserves the probabilistic rigor and multi-layer dependency modeling of AR while inheriting diffusion models' flexibility for parallel and bidirectional generation. We implement A3 through a two-stream attention architecture and a progressive adaptation strategy that transitions pretrained AR models toward any-order prediction. Experiments on question answering, commonsense reasoning, and story infilling demonstrate that A3 outperforms diffusion-based models while maintaining flexible decoding. This work offers a unified approach for a flexible, efficient, and novel language modeling paradigm.

</details>


### [374] [Aligning Agentic World Models via Knowledgeable Experience Learning](https://arxiv.org/abs/2601.13247)
*Baochang Ren,Yunzhi Yao,Rui Sun,Shuofei Qiao,Ningyu Zhang,Huajun Chen*

Main category: cs.CL

TL;DR: WorldMind框架通过构建符号化世界知识库，利用环境反馈解决LLMs的物理幻觉问题，无需持续重训练即可实现跨模型和跨环境的物理可行性规划。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型存在模态鸿沟：拥有丰富的语义知识但缺乏对物理世界不变法则的程序性理解，导致产生物理上不可执行的计划（物理幻觉）。现有对齐策略依赖资源密集的训练或微调，将动态环境规则压缩到静态模型参数中，这种参数化封装过于僵化，难以适应物理动态的开放变异性。

Method: 引入WorldMind框架，自主构建符号化世界知识库，通过综合环境反馈来统一过程经验（通过预测错误强制物理可行性）和目标经验（通过成功轨迹指导任务最优性）。

Result: 在EB-ALFRED和EB-Habitat上的实验表明，WorldMind相比基线方法取得了优越性能，并展现出显著的跨模型和跨环境可迁移性。

Conclusion: WorldMind通过构建符号化知识库而非依赖参数化封装，有效解决了LLMs的物理幻觉问题，实现了物理可行的规划，且具有更好的适应性和可迁移性。

Abstract: Current Large Language Models (LLMs) exhibit a critical modal disconnect: they possess vast semantic knowledge but lack the procedural grounding to respect the immutable laws of the physical world. Consequently, while these agents implicitly function as world models, their simulations often suffer from physical hallucinations-generating plans that are logically sound but physically unexecutable. Existing alignment strategies predominantly rely on resource-intensive training or fine-tuning, which attempt to compress dynamic environmental rules into static model parameters. However, such parametric encapsulation is inherently rigid, struggling to adapt to the open-ended variability of physical dynamics without continuous, costly retraining. To bridge this gap, we introduce WorldMind, a framework that autonomously constructs a symbolic World Knowledge Repository by synthesizing environmental feedback. Specifically, it unifies Process Experience to enforce physical feasibility via prediction errors and Goal Experience to guide task optimality through successful trajectories. Experiments on EB-ALFRED and EB-Habitat demonstrate that WorldMind achieves superior performance compared to baselines with remarkable cross-model and cross-environment transferability.

</details>


### [375] [Beyond Cosine Similarity: Taming Semantic Drift and Antonym Intrusion in a 15-Million Node Turkish Synonym Graph](https://arxiv.org/abs/2601.13251)
*Ebubekir Tosun,Mehmet Emin Buldur,Özay Ezerceli,Mahmoud ElHussieni*

Main category: cs.CL

TL;DR: 提出大规模语义聚类系统解决神经网络嵌入无法区分同义词与反义词的问题，通过三路语义关系判别器和软到硬聚类算法生成290万个高精度语义簇。


<details>
  <summary>Details</summary>
Motivation: 神经网络嵌入存在明显缺陷：无法可靠区分同义词和反义词。提高相似度阈值通常无法防止对立词被分到同一组，这在形态丰富和低资源语言中尤为严重，现有同义词数据库稀疏。

Method: 1) 构建84.3万个概念对数据集（同义、反义、同下位关系），使用Gemini 2.5-Flash LLM增强并通过人工词典资源验证；2) 提出三路语义关系判别器，实现90%宏F1分数；3) 设计新颖的软到硬聚类算法，采用拓扑感知的两阶段扩展-剪枝过程与拓扑投票，防止语义漂移和错误传递链。

Result: 处理1500万个词汇项，评估5.2亿个潜在关系，最终生成290万个高精度语义簇。系统能够精确区分同义词和反义词，解决多义词问题，为形态丰富和低资源语言提供高质量语义搜索和检索增强生成能力。

Conclusion: 该系统成功解决了神经网络嵌入在语义关系区分上的根本缺陷，通过创新的判别器和聚类算法实现了大规模高精度语义聚类，特别适用于现有资源稀缺的语言环境，为语义搜索和RAG应用提供了可靠基础。

Abstract: Neural embeddings have a notorious blind spot: they can't reliably tell synonyms apart from antonyms. Consequently, increasing similarity thresholds often fails to prevent opposites from being grouped together. We've built a large-scale semantic clustering system specifically designed to tackle this problem head on. Our pipeline chews through 15 million lexical items, evaluates a massive 520 million potential relationships, and ultimately generates 2.9 million high-precision semantic clusters. The system makes three primary contributions. First, we introduce a labeled dataset of 843,000 concept pairs spanning synonymy, antonymy, and co-hyponymy, constructed via Gemini 2.5-Flash LLM augmentation and verified using human-curated dictionary resources. Second, we propose a specialized three-way semantic relation discriminator that achieves 90% macro-F1, enabling robust disambiguation beyond raw embedding similarity. Third, we introduce a novel soft-to-hard clustering algorithm that mitigates semantic drift preventing erroneous transitive chains (e.g., hot -> spicy -> pain -> depression) while simultaneously resolving polysemy. Our approach employs a topology-aware two-stage expansion-pruning procedure with topological voting, ensuring that each term is assigned to exactly one semantically coherent cluster. The resulting resource enables high-precision semantic search and retrieval-augmented generation, particularly for morphologically rich and low-resource languages where existing synonym databases remain sparse.

</details>


### [376] [A Hybrid Protocol for Large-Scale Semantic Dataset Generation in Low-Resource Languages: The Turkish Semantic Relations Corpus](https://arxiv.org/abs/2601.13253)
*Ebubekir Tosun,Mehmet Emin Buldur,Özay Ezerceli,Mahmoud ElHussieni*

Main category: cs.CL

TL;DR: 提出一种混合方法，用于生成低资源语言的大规模语义关系数据集，并以土耳其语为例构建了包含84.3万对语义关系的语料库，成本仅65美元。


<details>
  <summary>Details</summary>
Motivation: 解决土耳其语等低资源语言中语义关系数据稀缺的问题，现有资源规模有限且成本高昂。

Method: 三阶段混合方法：1) FastText嵌入与凝聚聚类识别语义簇；2) Gemini 2.5-Flash自动分类语义关系；3) 整合词典资源。

Result: 构建了包含84.3万对土耳其语语义关系的数据集（同义词、反义词、共下位词），规模是现有资源的10倍，成本仅65美元。下游任务验证：嵌入模型达到90% top-1检索准确率，分类模型达到90% F1-macro分数。

Conclusion: 该方法可扩展地解决了土耳其语NLP中的数据稀缺问题，并适用于其他低资源语言。数据集和模型已公开。

Abstract: We present a hybrid methodology for generating large-scale semantic relationship datasets in low-resource languages, demonstrated through a comprehensive Turkish semantic relations corpus. Our approach integrates three phases: (1) FastText embeddings with Agglomerative Clustering to identify semantic clusters, (2) Gemini 2.5-Flash for automated semantic relationship classification, and (3) integration with curated dictionary sources. The resulting dataset comprises 843,000 unique Turkish semantic pairs across three relationship types (synonyms, antonyms, co-hyponyms) representing a 10x scale increase over existing resources at minimal cost ($65). We validate the dataset through two downstream tasks: an embedding model achieving 90% top-1 retrieval accuracy and a classification model attaining 90% F1-macro. Our scalable protocol addresses critical data scarcity in Turkish NLP and demonstrates applicability to other low-resource languages. We publicly release the dataset and models.

</details>


### [377] [Stop Taking Tokenizers for Granted: They Are Core Design Decisions in Large Language Models](https://arxiv.org/abs/2601.13260)
*Sawsan Alqahtani,Mir Tafseer Nayeem,Md Tahmid Rahman Laskar,Tasnim Mohiuddin,M Saiful Bari*

Main category: cs.CL

TL;DR: 论文主张将分词重新定义为核心建模决策而非预处理步骤，提出上下文感知框架，强调分词器与模型协同设计，以实现更公平、高效、适应性强的语言技术。


<details>
  <summary>Details</summary>
Motivation: 当前分词技术（如BPE）虽然可扩展，但存在与语言结构不对齐、放大偏见、跨语言和跨领域容量浪费等问题。分词作为大语言模型的基础组件，却缺乏理论支撑且设计不一致，被低估为预处理步骤而非核心设计问题。

Method: 提出上下文感知框架，将分词器与模型进行协同设计，考虑语言、领域和部署等多维度因素。强调标准化评估和透明报告机制，使分词选择可问责、可比较。

Result: 通过将分词视为核心设计问题而非技术后处理，可以开发出更公平、更高效、更具适应性的语言技术。标准化评估和透明报告使分词决策更加负责任和可比较。

Conclusion: 分词应被重新定义为语言模型的核心建模决策，需要系统性的上下文感知框架和协同设计方法。这种范式转变对于创建公平、高效、适应性强的语言技术至关重要。

Abstract: Tokenization underlies every large language model, yet it remains an under-theorized and inconsistently designed component. Common subword approaches such as Byte Pair Encoding (BPE) offer scalability but often misalign with linguistic structure, amplify bias, and waste capacity across languages and domains. This paper reframes tokenization as a core modeling decision rather than a preprocessing step. We argue for a context-aware framework that integrates tokenizer and model co-design, guided by linguistic, domain, and deployment considerations. Standardized evaluation and transparent reporting are essential to make tokenization choices accountable and comparable. Treating tokenization as a core design problem, not a technical afterthought, can yield language technologies that are fairer, more efficient, and more adaptable.

</details>


### [378] [Unlearning in LLMs: Methods, Evaluation, and Open Challenges](https://arxiv.org/abs/2601.13264)
*Tyler Lizzo,Larry Heck*

Main category: cs.CL

TL;DR: 这篇综述论文系统梳理了大型语言模型(LLM)的遗忘学习技术，将现有方法分为数据中心、参数中心、架构中心和混合策略等类别，并评估了遗忘效果、知识保留和鲁棒性，最后指出了可扩展性、形式化保证等开放性问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在自然语言处理任务中取得了显著成功，但其广泛部署引发了隐私、版权、安全和偏见等紧迫问题。机器遗忘学习作为一种有前景的范式，可以在不完全重新训练的情况下选择性地从训练模型中移除知识或数据。

Method: 论文提供了LLM遗忘学习方法的结构化概述，将现有方法分为：数据为中心的方法、参数为中心的方法、架构为中心的方法、混合方法和其他策略。同时回顾了评估生态系统，包括基准测试、指标和数据集，用于衡量遗忘效果、知识保留和鲁棒性。

Result: 通过综合当前进展，论文为开发可靠和负责任的LLM遗忘学习技术提供了路线图，系统梳理了不同遗忘策略的分类框架和评估体系。

Conclusion: 论文指出了关键挑战和开放问题，包括可扩展效率、形式化保证、跨语言和多模态遗忘学习，以及对抗性重新学习的鲁棒性。通过综合当前进展和突出开放方向，旨在为开发可靠和负责任的大型语言模型遗忘学习技术提供路线图。

Abstract: Large language models (LLMs) have achieved remarkable success across natural language processing tasks, yet their widespread deployment raises pressing concerns around privacy, copyright, security, and bias. Machine unlearning has emerged as a promising paradigm for selectively removing knowledge or data from trained models without full retraining. In this survey, we provide a structured overview of unlearning methods for LLMs, categorizing existing approaches into data-centric, parameter-centric, architecture-centric, hybrid, and other strategies. We also review the evaluation ecosystem, including benchmarks, metrics, and datasets designed to measure forgetting effectiveness, knowledge retention, and robustness. Finally, we outline key challenges and open problems, such as scalable efficiency, formal guarantees, cross-language and multimodal unlearning, and robustness against adversarial relearning. By synthesizing current progress and highlighting open directions, this paper aims to serve as a roadmap for developing reliable and responsible unlearning techniques in large language models.

</details>


### [379] [A BERTology View of LLM Orchestrations: Token- and Layer-Selective Probes for Efficient Single-Pass Classification](https://arxiv.org/abs/2601.13288)
*Gonzalo Ariel Meyoyan,Luciano Del Corro*

Main category: cs.CL

TL;DR: 提出一种在LLM推理过程中复用隐藏状态进行轻量级分类的方法，避免使用独立的安全/分类模型，减少延迟和显存占用


<details>
  <summary>Details</summary>
Motivation: 当前生产级LLM系统通常使用独立模型进行安全和分类任务，这会增加延迟、显存占用和运维复杂度。作者希望复用LLM推理过程中已计算的信息来避免这些问题。

Method: 提出两阶段聚合器：1) 在每层内汇总token信息；2) 跨层聚合形成单一表示用于分类。实现包括直接池化、10万参数评分注意力门控和最多3500万参数的下采样多头自注意力探针。

Result: 在安全和情感基准测试中，该方法优于仅使用logit的方法（如MULI），与更大的任务专用基线模型表现相当，同时保持接近推理延迟，避免了独立防护模型管道的显存和延迟成本。

Conclusion: 通过复用LLM推理过程中的隐藏状态进行轻量级分类，可以在不增加显著延迟和显存开销的情况下，有效替代独立的安全/分类模型，简化生产部署。

Abstract: Production LLM systems often rely on separate models for safety and other classification-heavy steps, increasing latency, VRAM footprint, and operational complexity. We instead reuse computation already paid for by the serving LLM: we train lightweight probes on its hidden states and predict labels in the same forward pass used for generation. We frame classification as representation selection over the full token-layer hidden-state tensor, rather than committing to a fixed token or fixed layer (e.g., first-token logits or final-layer pooling). To implement this, we introduce a two-stage aggregator that (i) summarizes tokens within each layer and (ii) aggregates across layer summaries to form a single representation for classification. We instantiate this template with direct pooling, a 100K-parameter scoring-attention gate, and a downcast multi-head self-attention (MHA) probe with up to 35M trainable parameters. Across safety and sentiment benchmarks our probes improve over logit-only reuse (e.g., MULI) and are competitive with substantially larger task-specific baselines, while preserving near-serving latency and avoiding the VRAM and latency costs of a separate guard-model pipeline.

</details>


### [380] [OI-Bench: An Option Injection Benchmark for Evaluating LLM Susceptibility to Directive Interference](https://arxiv.org/abs/2601.13300)
*Yow-Fu Liou,Yu-Chien Tang,Yu-Hsiang Liu,An-Zi Yen*

Main category: cs.CL

TL;DR: 本文提出OI-Bench基准测试，通过在多选题界面注入误导性指令选项，系统评估大语言模型对指令干扰的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明LLM决策容易受到社交线索、框架效应和指令等导向信号的影响，但缺乏系统评估模型在选择题界面中对指令干扰的鲁棒性。

Method: 提出"选项注入"方法，在MCQA界面中添加包含误导性指令的额外选项，构建包含3000个问题的OI-Bench基准，涵盖16种指令类型（社交顺从、奖励框架、威胁框架、指令干扰）。

Result: 评估12个LLM显示模型存在显著脆弱性，攻击成功率各异，鲁棒性存在异质性。同时研究了从推理时提示到训练后对齐的缓解策略。

Conclusion: OI-Bench支持更系统评估LLM在基于选择的界面中对指令干扰的鲁棒性，揭示了模型的重要安全漏洞。

Abstract: Benchmarking large language models (LLMs) is critical for understanding their capabilities, limitations, and robustness. In addition to interface artifacts, prior studies have shown that LLM decisions can be influenced by directive signals such as social cues, framing, and instructions. In this work, we introduce option injection, a benchmarking approach that augments the multiple-choice question answering (MCQA) interface with an additional option containing a misleading directive, leveraging standardized choice structure and scalable evaluation. We construct OI-Bench, a benchmark of 3,000 questions spanning knowledge, reasoning, and commonsense tasks, with 16 directive types covering social compliance, bonus framing, threat framing, and instructional interference. This setting combines manipulation of the choice interface with directive-based interference, enabling systematic assessment of model susceptibility. We evaluate 12 LLMs to analyze attack success rates, behavioral responses, and further investigate mitigation strategies ranging from inference-time prompting to post-training alignment. Experimental results reveal substantial vulnerabilities and heterogeneous robustness across models. OI-Bench is expected to support more systematic evaluation of LLM robustness to directive interference within choice-based interfaces.

</details>


### [381] [Paid Voices vs. Public Feeds: Interpretable Cross-Platform Theme Modeling of Climate Discourse](https://arxiv.org/abs/2601.13317)
*Samantha Sudhoff,Pranav Perumal,Zhaoqing Wu,Tunazzina Islam*

Main category: cs.CL

TL;DR: 比较Meta付费广告与Bluesky公共帖子中气候话语的差异，提出可解释的主题发现框架，发现平台激励机制影响气候叙事的主题结构、立场对齐和时间响应性。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常孤立分析不同平台的气候话语，难以区分机构信息与公众表达。需要比较付费广告生态系统（激励针对性战略说服）与公共社交媒体平台（主要是用户驱动的有机话语）的差异。

Method: 提出可解释的端到端主题发现与分配框架：通过语义相似性聚类文本，利用大语言模型生成简洁、人类可理解的主题标签。在2024年7月至2025年9月期间，比较Meta付费广告和Bluesky公共帖子中的气候话语。

Result: 平台层面的激励机制反映在气候叙事的主题结构、立场对齐和时间响应性上。付费气候信息与公共气候话语存在系统性差异，主题流行度在重大政治事件前后发生变化。

Conclusion: 平台激励机制显著影响气候话语的特征。虽然实证分析聚焦气候传播，但所提框架支持跨异构传播环境的比较叙事分析。

Abstract: Climate discourse online plays a crucial role in shaping public understanding of climate change and influencing political and policy outcomes. However, climate communication unfolds across structurally distinct platforms with fundamentally different incentive structures: paid advertising ecosystems incentivize targeted, strategic persuasion, while public social media platforms host largely organic, user-driven discourse. Existing computational studies typically analyze these environments in isolation, limiting our ability to distinguish institutional messaging from public expression. In this work, we present a comparative analysis of climate discourse across paid advertisements on Meta (previously known as Facebook) and public posts on Bluesky from July 2024 to September 2025. We introduce an interpretable, end-to-end thematic discovery and assignment framework that clusters texts by semantic similarity and leverages large language models (LLMs) to generate concise, human-interpretable theme labels. We evaluate the quality of the induced themes against traditional topic modeling baselines using both human judgments and an LLM-based evaluator, and further validate their semantic coherence through downstream stance prediction and theme-guided retrieval tasks. Applying the resulting themes, we characterize systematic differences between paid climate messaging and public climate discourse and examine how thematic prevalence shifts around major political events. Our findings show that platform-level incentives are reflected in the thematic structure, stance alignment, and temporal responsiveness of climate narratives. While our empirical analysis focuses on climate communication, the proposed framework is designed to support comparative narrative analysis across heterogeneous communication environments.

</details>


### [382] [Arab Voices: Mapping Standard and Dialectal Arabic Speech Technology](https://arxiv.org/abs/2601.13319)
*Peter Sullivan,AbdelRahim Elmadany,Alcides Alcoba Inciarte,Muhammad Abdul-Mageed*

Main category: cs.CL

TL;DR: 该论文分析了阿拉伯语方言语音数据的异质性，提出了Arab Voices标准化框架来统一访问31个数据集，并为现代阿拉伯语方言ASR建立了基准。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语方言语音数据在领域覆盖、方言标注实践和录音条件方面存在广泛差异，这导致跨数据集比较和模型评估变得复杂。需要标准化表征来减少碎片化并支持可重复评估。

Method: 1) 对广泛使用的阿拉伯语方言语料库进行语言"方言性"的计算分析；2) 使用音频质量的客观代理指标；3) 引入Arab Voices标准化框架，统一访问31个数据集，涵盖14种方言，并提供协调的元数据和评估工具；4) 对一系列最近的ASR系统进行基准测试。

Result: 研究发现数据集在声学条件和方言信号强度及一致性方面存在显著异质性。Arab Voices框架成功整合了多个数据集，并为现代阿拉伯语方言ASR建立了强大的基准性能。

Conclusion: 阿拉伯语方言语音数据需要超越粗粒度标签的标准化表征。Arab Voices框架通过提供统一访问、协调元数据和评估工具，减少了碎片化并支持可重复评估，为阿拉伯语方言ASR研究提供了重要基础设施。

Abstract: Dialectal Arabic (DA) speech data vary widely in domain coverage, dialect labeling practices, and recording conditions, complicating cross-dataset comparison and model evaluation. To characterize this landscape, we conduct a computational analysis of linguistic ``dialectness'' alongside objective proxies of audio quality on the training splits of widely used DA corpora. We find substantial heterogeneity both in acoustic conditions and in the strength and consistency of dialectal signals across datasets, underscoring the need for standardized characterization beyond coarse labels. To reduce fragmentation and support reproducible evaluation, we introduce Arab Voices, a standardized framework for DA ASR. Arab Voices provides unified access to 31 datasets spanning 14 dialects, with harmonized metadata and evaluation utilities. We further benchmark a range of recent ASR systems, establishing strong baselines for modern DA ASR.

</details>


### [383] [Reducing Tokenization Premiums for Low-Resource Languages](https://arxiv.org/abs/2601.13328)
*Geoffrey Churchill,Steven Skiena*

Main category: cs.CL

TL;DR: 分析十种流行语言模型的tokenizer设计，提出通过词汇表后处理减少低资源语言tokenization溢价的方法，并在12种低资源语言上验证有效性


<details>
  <summary>Details</summary>
Motivation: 低资源语言在现代语言模型中存在显著的tokenization溢价（相比英语需要数倍token编码相同句子），导致API和能源成本增加、有效上下文窗口减小

Method: 1) 分析十种流行LM的tokenizer设计及其各语言tokenization溢价；2) 提出后处理方法：在预训练模型词汇表中添加多字符组合为单token的条目来压缩tokenization

Result: 在12种低资源语言上应用该方法，使用Llama 3.2 1B模型验证，发现原始输入和压缩输入的最后隐藏状态相似

Conclusion: 提出的后处理词汇表扩展方法能有效减少低资源语言的tokenization溢价，且保持模型表示的一致性

Abstract: Relative to English, low-resource languages suffer from substantial tokenization premiums in modern LMs, meaning that it generally requires several times as many tokens to encode a sentence in a low-resource language than to encode the analogous sentence in English. This tokenization premium results in increased API and energy costs and reduced effective context windows for these languages. In this paper we analyze the tokenizers of ten popular LMs to better understand their designs and per-language tokenization premiums. We also propose a mechanism to reduce tokenization premiums in pre-trained models, by post-hoc additions to the token vocabulary that coalesce multi-token characters into single tokens. We apply this methodology to 12 low-resource languages, demonstrating that the original and compressed inputs often have similar last hidden states when run through the Llama 3.2 1B model.

</details>


### [384] [RegCheck: A tool for automating comparisons between study registrations and papers](https://arxiv.org/abs/2601.13330)
*Jamie Cummins,Beth Clarke,Ian Hussey,Malte Elson*

Main category: cs.CL

TL;DR: RegCheck是一个模块化的LLM辅助工具，帮助研究人员、审稿人和编辑比较研究注册与对应论文，保持人类专家判断在循环中，并生成可共享的报告。


<details>
  <summary>Details</summary>
Motivation: 尽管预先注册研究活动对科学透明度和严谨性有益，但注册检查通常被忽视，因为手动比较注册与论文需要大量时间和专业知识。AI技术为促进这一活动提供了新可能。

Method: 开发RegCheck工具，采用模块化LLM辅助设计，让用户决定比较哪些特征，展示最相关的文本，保持人类判断在循环中，生成可共享报告，并适应不同科学领域和格式。

Result: RegCheck提供了一个可扩展的基础设施，通过示例用例展示了其在促进可重复科学方面的潜力，能够帮助用户更有效地检查注册与论文的一致性。

Conclusion: RegCheck作为一个AI辅助工具，能够促进研究注册的检查，提高科学透明度，同时保持人类专家的判断力，为可重复科学提供了可扩展的基础设施。

Abstract: Across the social and medical sciences, researchers recognize that specifying planned research activities (i.e., 'registration') prior to the commencement of research has benefits for both the transparency and rigour of science. Despite this, evidence suggests that study registrations frequently go unexamined, minimizing their effectiveness. In a way this is no surprise: manually checking registrations against papers is labour- and time-intensive, requiring careful reading across formats and expertise across domains. The advent of AI unlocks new possibilities in facilitating this activity. We present RegCheck, a modular LLM-assisted tool designed to help researchers, reviewers, and editors from across scientific disciplines compare study registrations with their corresponding papers. Importantly, RegCheck keeps human expertise and judgement in the loop by (i) ensuring that users are the ones who determine which features should be compared, and (ii) presenting the most relevant text associated with each feature to the user, facilitating (rather than replacing) human discrepancy judgements. RegCheck also generates shareable reports with unique RegCheck IDs, enabling them to be easily shared and verified by other users. RegCheck is designed to be adaptable across scientific domains, as well as registration and publication formats. In this paper we provide an overview of the motivation, workflow, and design principles of RegCheck, and we discuss its potential as an extensible infrastructure for reproducible science with an example use case.

</details>


### [385] [AfroScope: A Framework for Studying the Linguistic Landscape of Africa](https://arxiv.org/abs/2601.13346)
*Sang Yun Kwon,AbdelRahim Elmadany,Muhammad Abdul-Mageed*

Main category: cs.CL

TL;DR: AfroScope是一个统一的非洲语言识别框架，包含覆盖713种非洲语言的数据集和强大的语言识别模型，采用分层分类方法提升混淆语言的识别准确率。


<details>
  <summary>Details</summary>
Motivation: 现有语言识别方法在非洲语言覆盖范围有限，且难以区分密切相关的语言变体，这影响了下游NLP应用的可靠性。需要开发更全面的非洲语言识别系统。

Method: 提出AfroScope统一框架，包含AfroScope-Data数据集和AfroScope-Models模型套件。针对高度混淆的语言，采用分层分类方法，利用专门的嵌入模型Mirror-Serengeti来区分29种密切相关的语言。

Result: 在混淆语言子集上，分层分类方法相比最佳基础模型将宏F1提高了4.55。分析了跨语言迁移和领域效应，为构建稳健的非洲语言识别系统提供指导。

Conclusion: AfroScope作为非洲语言识别的使能技术，能够大规模测量非洲数字文本中的语言景观。作者公开发布了AfroScope-Data和AfroScope-Models。

Abstract: Language Identification (LID) is the task of determining the language of a given text and is a fundamental preprocessing step that affects the reliability of downstream NLP applications. While recent work has expanded LID coverage for African languages, existing approaches remain limited in (i) the number of supported languages and (ii) their ability to make fine-grained distinctions among closely related varieties. We introduce AfroScope, a unified framework for African LID that includes AfroScope-Data, a dataset covering 713 African languages, and AfroScope-Models, a suite of strong LID models with broad language coverage. To better distinguish highly confusable languages, we propose a hierarchical classification approach that leverages Mirror-Serengeti, a specialized embedding model targeting 29 closely related or geographically proximate languages. This approach improves macro F1 by 4.55 on this confusable subset compared to our best base model. Finally, we analyze cross linguistic transfer and domain effects, offering guidance for building robust African LID systems. We position African LID as an enabling technology for large scale measurement of Africas linguistic landscape in digital text and release AfroScope-Data and AfroScope-Models publicly.

</details>


### [386] [LLM-as-RNN: A Recurrent Language Model for Memory Updates and Sequence Prediction](https://arxiv.org/abs/2601.13352)
*Yuxing Lu,J. Ben Tamo,Weichen Zhao,Nan Sun,Yishan Zhong,Wenqi Shi,Jinzhuo Wang,May D. Wang*

Main category: cs.CL

TL;DR: LLM-as-RNN：将冻结的LLM转换为循环预测器的推理框架，通过自然语言记忆实现错误纠正和在线学习


<details>
  <summary>Details</summary>
Motivation: 传统LLM推理时上下文历史不可变，一旦在步骤t出错，模型无法更新记忆来改进步骤t+1的预测。需要一种无需参数更新的在线学习机制。

Method: 将LLM隐藏状态表示为自然语言记忆（结构化系统提示摘要），通过反馈驱动的文本重写在每个时间步更新状态，实现无需参数更新的学习。

Result: 在医疗、气象、金融三个序列基准测试中，LLM-as-RNN显著优于零样本、完整历史和MemPrompt基线，平均预测准确率提升6.5%，并产生可解释的学习轨迹。

Conclusion: LLM-as-RNN成功将冻结LLM转变为循环预测器，通过自然语言记忆实现有效的在线学习，在固定token预算下纠正错误并保留任务相关模式。

Abstract: Large language models are strong sequence predictors, yet standard inference relies on immutable context histories. After making an error at generation step t, the model lacks an updatable memory mechanism that improves predictions for step t+1. We propose LLM-as-RNN, an inference-only framework that turns a frozen LLM into a recurrent predictor by representing its hidden state as natural-language memory. This state, implemented as a structured system-prompt summary, is updated at each timestep via feedback-driven text rewrites, enabling learning without parameter updates. Under a fixed token budget, LLM-as-RNN corrects errors and retains task-relevant patterns, effectively performing online learning through language. We evaluate the method on three sequential benchmarks in healthcare, meteorology, and finance across Llama, Gemma, and GPT model families. LLM-as-RNN significantly outperforms zero-shot, full-history, and MemPrompt baselines, improving predictive accuracy by 6.5% on average, while producing interpretable, human-readable learning traces absent in standard context accumulation.

</details>


### [387] [Sockpuppetting: Jailbreaking LLMs Without Optimization Through Output Prefix Injection](https://arxiv.org/abs/2601.13359)
*Asen Dotsinski,Panagiotis Eustratiadis*

Main category: cs.CL

TL;DR: 提出了一种名为"sockpuppetting"的简单方法，通过在模型输出开头插入接受序列（如"Sure, here is how to..."）来越狱开源大语言模型，无需优化且仅需一行代码即可实现高攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 随着开源大语言模型能力增强，保护它们免受恶意提示攻击并理解可能的攻击向量变得日益重要。现有的自动化越狱方法如GCG需要大量计算资源和专业知识，因此需要更简单有效的攻击方法。

Method: 提出"sockpuppetting"方法：在模型输出开头插入接受序列（如"Sure, here is how to..."），然后让模型完成响应。还探索了混合方法，在助手消息块内优化对抗性后缀而非用户提示。

Result: 在Qwen3-8B上，sockpuppetting在每提示比较中比GCG攻击成功率提高80%；在Llama-3.1-8B上，混合方法在提示无关设置中比GCG攻击成功率提高64%。

Conclusion: sockpuppetting是一种低成本有效攻击方法，对非专业攻击者也易于实施，突显了开源模型中需要防御输出前缀注入攻击的重要性。

Abstract: As open-weight large language models (LLMs) increase in capabilities, safeguarding them against malicious prompts and understanding possible attack vectors becomes ever more important. While automated jailbreaking methods like GCG [Zou et al., 2023] remain effective, they often require substantial computational resources and specific expertise. We introduce "sockpuppetting'', a simple method for jailbreaking open-weight LLMs by inserting an acceptance sequence (e.g., "Sure, here is how to...'') at the start of a model's output and allowing it to complete the response. Requiring only a single line of code and no optimization, sockpuppetting achieves up to 80% higher attack success rate (ASR) than GCG on Qwen3-8B in per-prompt comparisons. We also explore a hybrid approach that optimizes the adversarial suffix within the assistant message block rather than the user prompt, increasing ASR by 64% over GCG on Llama-3.1-8B in a prompt-agnostic setting. The results establish sockpuppetting as an effective low-cost attack accessible to unsophisticated adversaries, highlighting the need for defences against output-prefix injection in open-weight models.

</details>


### [388] [Recurrent Confidence Chain: Temporal-Aware Uncertainty Quantification in Large Language Models](https://arxiv.org/abs/2601.13368)
*Zhenjiang Mao,Anirudhh Venkat*

Main category: cs.CL

TL;DR: 提出一种新方法，通过分析推理步骤间的语义关联和历史置信度信息，更准确地评估大语言模型推理过程的不确定性，在数学和因果推理任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在推理任务上表现良好，但缺乏对答案不确定性的准确评估，可能导致误导性幻觉。现有方法忽略置信度的时间分布，即使早期步骤置信度很低，整体置信度仍可能被夸大。

Method: 提出新方法：1) 引入步骤间注意力机制分析跨步骤语义关联；2) 针对长序列响应，设计隐藏置信度机制保留历史置信度信息；3) 结合步骤置信度生成更准确的整体置信度估计。

Result: 在GAOKAO数学基准和CLadder因果推理数据集上评估，使用主流开源大语言模型。方法在预测质量和校准之间达到更好平衡，在负对数似然和期望校准误差指标上表现优异，优于最先进方法。

Conclusion: 通过分析推理步骤间的语义关联并保留历史置信度信息，能够更准确地评估大语言模型推理过程的不确定性，减少误导性幻觉，提升模型可靠性。

Abstract: As reasoning modules, such as the chain-of-thought mechanism, are applied to large language models, they achieve strong performance on various tasks such as answering common-sense questions and solving math problems. The main challenge now is to assess the uncertainty of answers, which can help prevent misleading or serious hallucinations for users. Although current methods analyze long reasoning sequences by filtering unrelated tokens and examining potential connections between nearby tokens or sentences, the temporal spread of confidence is often overlooked. This oversight can lead to inflated overall confidence, even when earlier steps exhibit very low confidence. To address this issue, we propose a novel method that incorporates inter-step attention to analyze semantic correlations across steps. For handling long-horizon responses, we introduce a hidden confidence mechanism to retain historical confidence information, which is then combined with stepwise confidence to produce a more accurate overall estimate. We evaluate our method on the GAOKAO math benchmark and the CLadder causal reasoning dataset using mainstream open-source large language models. Our approach is shown to outperform state-of-the-art methods by achieving a superior balance between predictive quality and calibration, demonstrated by strong performance on both Negative Log-Likelihood and Expected Calibration Error.

</details>


### [389] [Confidence over Time: Confidence Calibration with Temporal Logic for Large Language Model Reasoning](https://arxiv.org/abs/2601.13387)
*Zhenjiang Mao,Anirudhh Venkat,Artem Bisliouk,Akshat Kothiyal,Sindhura Kumbakonam Subramanian,Saithej Singhu,Ivan Ruchkin*

Main category: cs.CL

TL;DR: 提出使用信号时序逻辑（STL）分析LLM推理过程中的置信度演化，通过STL模式区分正确与错误回答，并开发基于超网络的置信度估计方法，在多个推理任务上表现优于基线。


<details>
  <summary>Details</summary>
Motivation: 现有置信度估计方法通常将整个推理过程简化为单一标量分数，忽略了置信度在生成过程中的演化。这导致这些方法对表面因素（如响应长度或冗长程度）敏感，难以区分正确推理和自信陈述的错误。

Method: 使用信号时序逻辑（STL）表征逐步置信度信号，通过判别性STL挖掘程序发现区分正确与错误回答置信度信号的时序公式。基于STL模式可跨任务泛化而数值参数对具体问题敏感的洞察，开发了用参数超网络信息化的STL块的置信度估计方法。

Result: 在多个推理任务上的实验表明，该方法产生的置信度分数比基线方法更加校准，能够更准确地反映模型推理的可靠性。

Conclusion: 通过STL分析推理过程中的置信度演化模式，可以开发出更鲁棒、更校准的置信度估计方法，这对于LLM在复杂推理任务中的可靠应用具有重要意义。

Abstract: Large Language Models (LLMs) increasingly rely on long-form, multi-step reasoning to solve complex tasks such as mathematical problem solving and scientific question answering. Despite strong performance, existing confidence estimation methods typically reduce an entire reasoning process to a single scalar score, ignoring how confidence evolves throughout the generation. As a result, these methods are often sensitive to superficial factors such as response length or verbosity, and struggle to distinguish correct reasoning from confidently stated errors. We propose to characterize the stepwise confidence signal using Signal Temporal Logic (STL). Using a discriminative STL mining procedure, we discover temporal formulas that distinguish confidence signals of correct and incorrect responses. Our analysis found that the STL patterns generalize across tasks, and numeric parameters exhibit sensitivity to individual questions. Based on these insights, we develop a confidence estimation approach that informs STL blocks with parameter hypernetworks. Experiments on multiple reasoning tasks show our confidence scores are more calibrated than the baselines.

</details>


### [390] [Structured Insight from Unstructured Data: Large Language Models for SDOH-Driven Diabetes Risk Prediction](https://arxiv.org/abs/2601.13388)
*Sasha Ronaghi,Prerit Choudhary,David H Rehkopf,Bryant Lin*

Main category: cs.CL

TL;DR: 使用大型语言模型从糖尿病患者生活故事中提取结构化社会健康决定因素信息，并评估其对糖尿病控制的预测价值


<details>
  <summary>Details</summary>
Motivation: 社会健康决定因素在2型糖尿病管理中至关重要，但电子健康记录和风险预测模型中往往缺乏这些信息。现有的结构化筛查工具无法捕捉患者经历的复杂性，需要更灵活的方法来获取SDOH数据。

Method: 收集65名65岁以上2型糖尿病患者的非结构化访谈，使用检索增强生成的大型语言模型分析叙事，生成定性的临床摘要和定量的SDOH评分。将结构化SDOH评分与传统生物标志物结合，使用线性模型和树基机器学习模型进行风险预测，并评估LLM直接从访谈文本预测糖尿病控制水平的能力。

Result: 大型语言模型能够从患者生活故事中提取结构化SDOH信息，LLM直接从访谈文本预测糖尿病控制水平的准确率达到60%。结构化SDOH评分可以与传统生物标志物结合，应用于常规风险预测工作流程。

Conclusion: 大型语言模型能够将非结构化SDOH相关数据转化为结构化见解，为增强临床风险模型和决策支持提供了可扩展的方法，弥补了传统结构化筛查工具的不足。

Abstract: Social determinants of health (SDOH) play a critical role in Type 2 Diabetes (T2D) management but are often absent from electronic health records and risk prediction models. Most individual-level SDOH data is collected through structured screening tools, which lack the flexibility to capture the complexity of patient experiences and unique needs of a clinic's population. This study explores the use of large language models (LLMs) to extract structured SDOH information from unstructured patient life stories and evaluate the predictive value of both the extracted features and the narratives themselves for assessing diabetes control. We collected unstructured interviews from 65 T2D patients aged 65 and older, focused on their lived experiences, social context, and diabetes management. These narratives were analyzed using LLMs with retrieval-augmented generation to produce concise, actionable qualitative summaries for clinical interpretation and structured quantitative SDOH ratings for risk prediction modeling. The structured SDOH ratings were used independently and in combination with traditional laboratory biomarkers as inputs to linear and tree-based machine learning models (Ridge, Lasso, Random Forest, and XGBoost) to demonstrate how unstructured narrative data can be applied in conventional risk prediction workflows. Finally, we evaluated several LLMs on their ability to predict a patient's level of diabetes control (low, medium, high) directly from interview text with A1C values redacted. LLMs achieved 60% accuracy in predicting diabetes control levels from interview text. This work demonstrates how LLMs can translate unstructured SDOH-related data into structured insights, offering a scalable approach to augment clinical risk models and decision-making.

</details>


### [391] [Beyond Memorization: Testing LLM Reasoning on Unseen Theory of Computation Tasks](https://arxiv.org/abs/2601.13392)
*Shlok Shelat,Jay Raval,Souvik Roy,Manas Gaur*

Main category: cs.CL

TL;DR: LLMs在DFA构造任务上表现良好，但在未见问题上准确率大幅下降，暴露了形式推理能力的根本缺陷


<details>
  <summary>Details</summary>
Motivation: 探究LLMs在形式语言任务上的表现是真正的符号推理还是对熟悉结构的模式匹配

Method: 引入DFA构造基准测试，包含事实性问题、已见问题、未见问题（手工制作和系统生成），评估多种提示策略和三阶段提示协议

Result: 模型在事实性问题上准确率完美，已见任务84-90%，但未见问题准确率下降30-64%，提示策略无法解决根本错误

Conclusion: LLMs生成语法上合理的DFA与语义正确的形式推理能力之间存在根本差距，错误与提示方法无关

Abstract: Large language models (LLMs) have demonstrated strong performance on formal language tasks, yet whether this reflects genuine symbolic reasoning or pattern matching on familiar constructions remains unclear. We introduce a benchmark for deterministic finite automata (DFA) construction from regular languages, comprising factual knowledge questions, seen construction problems from public sources, and two types of unseen problems: hand-crafted instances with multiple interacting constraints and systematically generated problems via Arden's theorem. Models achieve perfect accuracy on factual questions and 84-90% on seen tasks. However, accuracy drops sharply on unseen problems (by 30-64%), with failures stemming from systematic misinterpretation of language constraints, incorrect handling of Kleene-star semantics, and a failure to preserve global consistency. We evaluate a three-stage hint protocol that enables correction of shallow errors but does not reliably resolve globally inconsistent or structurally flawed automata. Our analysis across multiple prompting strategies (direct, Chain-of-Thought, Tree-of-Thought) reveals that errors persist regardless of prompting approach, exposing a fundamental gap between LLMs' ability to generate syntactically plausible DFAs and their capacity for semantically correct formal reasoning.

</details>


### [392] [Trust Me, I'm an Expert: Decoding and Steering Authority Bias in Large Language Models](https://arxiv.org/abs/2601.13433)
*Priyanka Mary Mammen,Emil Joswin,Shankar Venkitachalam*

Main category: cs.CL

TL;DR: 语言模型在推理任务中会受到建议和认可的影响，但认可来源可信度的影响尚未充分研究。研究发现模型对高权威来源的误导性认可表现出系统性偏见，导致准确性下降和错误答案信心增加。


<details>
  <summary>Details</summary>
Motivation: 先前研究表明语言模型在推理任务中的表现会受到建议、提示和认可的影响，但认可来源可信度（特别是提供者的专业知识水平）的影响尚未得到充分探索。研究者希望了解语言模型是否会对不同专业知识水平的认可来源表现出系统性偏见。

Method: 在4个数据集（涵盖数学、法律和医学推理）上评估了11个模型，使用代表每个领域四个专业知识水平的人物角色。通过不同专业知识水平的认可来源来测试模型的表现，并分析模型对权威来源误导性认可的敏感性。

Result: 结果显示，随着来源专业知识的增加，模型对错误/误导性认可的敏感性也增加。高权威来源不仅导致准确性下降，还增加了模型对错误答案的信心。研究还发现这种权威偏见在模型中具有机制性编码，并且可以通过引导来减轻这种偏见。

Conclusion: 语言模型存在基于认可来源专业知识的系统性权威偏见，这种偏见在模型中具有机制性基础。通过适当引导可以减轻这种偏见，即使在专家提供误导性认可的情况下也能提高模型性能。这揭示了语言模型决策过程中需要考虑的社会认知因素。

Abstract: Prior research demonstrates that performance of language models on reasoning tasks can be influenced by suggestions, hints and endorsements. However, the influence of endorsement source credibility remains underexplored. We investigate whether language models exhibit systematic bias based on the perceived expertise of the provider of the endorsement. Across 4 datasets spanning mathematical, legal, and medical reasoning, we evaluate 11 models using personas representing four expertise levels per domain. Our results reveal that models are increasingly susceptible to incorrect/misleading endorsements as source expertise increases, with higher-authority sources inducing not only accuracy degradation but also increased confidence in wrong answers. We also show that this authority bias is mechanistically encoded within the model and a model can be steered away from the bias, thereby improving its performance even when an expert gives a misleading endorsement.

</details>


### [393] [MOSLD-Bench: Multilingual Open-Set Learning and Discovery Benchmark for Text Categorization](https://arxiv.org/abs/2601.13437)
*Adriana-Valentina Costache,Daria-Nicoleta Dragomir,Silviu-Florin Gheorghe,Eduard Poesina,Paul Irofti,Radu Tudor Ionescu*

Main category: cs.CL

TL;DR: 本文提出了首个多语言开放集学习与发现（MOSLD）基准，用于文本主题分类，包含12种语言的96万数据样本，并提出了一个集成多阶段的新框架来持续发现和学习新类别。


<details>
  <summary>Details</summary>
Motivation: 开放集学习与发现（OSLD）是机器学习中的一个挑战性任务，测试时可能出现新（未知）类别的样本。虽然零样本学习在文本分类中已被广泛研究，但开放集学习与发现在文本领域是一个相对较新的设置。目前缺乏多语言的OSLD基准来推动该领域研究。

Method: 1）构建首个多语言开放集学习与发现基准（MOSLD），通过重新整理现有数据集和从新闻领域收集新数据样本，包含12种语言的960K数据样本；2）提出一个新颖的OSLD框架，集成多个阶段来持续发现和学习新类别。

Result: 建立了包含12种语言、960K数据样本的MOSLD基准，并评估了包括作者提出的模型在内的多种语言模型，为未来工作提供了参考结果。基准已开源发布。

Conclusion: 本文填补了文本领域开放集学习与发现基准的空白，特别是多语言方面。提出的MOSLD基准和框架为该领域研究提供了重要基础，有助于推动开放集学习在文本分类中的发展。

Abstract: Open-set learning and discovery (OSLD) is a challenging machine learning task in which samples from new (unknown) classes can appear at test time. It can be seen as a generalization of zero-shot learning, where the new classes are not known a priori, hence involving the active discovery of new classes. While zero-shot learning has been extensively studied in text classification, especially with the emergence of pre-trained language models, open-set learning and discovery is a comparatively new setup for the text domain. To this end, we introduce the first multilingual open-set learning and discovery (MOSLD) benchmark for text categorization by topic, comprising 960K data samples across 12 languages. To construct the benchmark, we (i) rearrange existing datasets and (ii) collect new data samples from the news domain. Moreover, we propose a novel framework for the OSLD task, which integrates multiple stages to continuously discover and learn new classes. We evaluate several language models, including our own, to obtain results that can be used as reference for future work. We release our benchmark at https://github.com/Adriana19Valentina/MOSLD-Bench.

</details>


### [394] [PhysicsSolutionAgent: Towards Multimodal Explanations for Numerical Physics Problem Solving](https://arxiv.org/abs/2601.13453)
*Aditya Thole,Anmol Agrawal,Arnav Ramamoorthy,Dhruv Kumar*

Main category: cs.CL

TL;DR: PSA是一个能生成长达6分钟物理问题讲解视频的自主代理，使用Manim动画制作，并通过包含15个量化参数和VLM反馈的评估流程来提升视频质量。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型在文本物理问题上表现良好，但生成高质量视觉解释的能力尚未充分探索。视觉推理能显著提升物理概念理解，而现有系统在这方面的能力不足。

Method: 开发PhysicsSolutionAgent(PSA)自主代理，使用Manim动画生成物理讲解视频；设计包含15个量化参数的自动化评估流程，结合视觉语言模型反馈进行迭代改进。

Result: 在32个视频评估中，PSA使用GPT-5-mini实现了100%视频完成率，平均自动化评分3.8/5。但定性分析和人工检查发现了视觉布局不一致、视觉内容解释错误等问题。

Conclusion: 研究揭示了Manim代码生成的局限性，以及多模态推理和评估在物理问题视觉解释中的挑战，强调了未来多模态教育系统需要改进视觉理解、验证和评估框架。

Abstract: Explaining numerical physics problems often requires more than text-based solutions; clear visual reasoning can substantially improve conceptual understanding. While large language models (LLMs) demonstrate strong performance on many physics questions in textual form, their ability to generate long, high-quality visual explanations remains insufficiently explored. In this work, we introduce PhysicsSolutionAgent (PSA), an autonomous agent that generates physics-problem explanation videos of up to six minutes using Manim animations. To evaluate the generated videos, we design an assessment pipeline that performs automated checks across 15 quantitative parameters and incorporates feedback from a vision-language model (VLM) to iteratively improve video quality. We evaluate PSA on 32 videos spanning numerical and theoretical physics problems. Our results reveal systematic differences in video quality depending on problem difficulty and whether the task is numerical or theoretical. Using GPT-5-mini, PSA achieves a 100% video-completion rate with an average automated score of 3.8/5. However, qualitative analysis and human inspection uncover both minor and major issues, including visual layout inconsistencies and errors in how visual content is interpreted during feedback. These findings expose key limitations in reliable Manim code generation and highlight broader challenges in multimodal reasoning and evaluation for visual explanations of numerical physics problems. Our work underscores the need for improved visual understanding, verification, and evaluation frameworks in future multimodal educational systems

</details>


### [395] [Anonpsy: A Graph-Based Framework for Structure-Preserving De-identification of Psychiatric Narratives](https://arxiv.org/abs/2601.13503)
*Kyung Ho Lim,Byung-Hoon Kim*

Main category: cs.CL

TL;DR: Anonpsy：基于图引导语义重写的心理病历去标识化框架，通过语义图表示和约束扰动，在保持临床诊断信息的同时降低再识别风险


<details>
  <summary>Details</summary>
Motivation: 现有去标识化方法（如PHI掩码和LLM合成重写）在文本层面操作，对保留或修改哪些语义元素控制有限。心理病历不仅包含显式标识符，还包含嵌入临床结构中的独特生活事件，需要更精细的控制

Method: Anonpsy将去标识化重新定义为图引导的语义重写：1）将叙述转换为编码临床实体、时间锚点和类型关系的语义图；2）应用图约束扰动，修改识别上下文同时保留临床必需结构；3）通过图条件LLM生成重新生成文本

Result: 在90个临床医生撰写的心理病例叙述上评估，Anonpsy在保持诊断保真度的同时，在专家、语义和GPT-5评估下实现了一致的低再识别风险。与强大的LLM-only重写基线相比，Anonpsy产生显著更低的语义相似性和可识别性

Conclusion: 显式结构表示与约束生成相结合，为心理病历去标识化提供了有效方法。图引导的语义重写框架在保护隐私和保持临床实用性之间取得了良好平衡

Abstract: Psychiatric narratives encode patient identity not only through explicit identifiers but also through idiosyncratic life events embedded in their clinical structure. Existing de-identification approaches, including PHI masking and LLM-based synthetic rewriting, operate at the text level and offer limited control over which semantic elements are preserved or altered. We introduce Anonpsy, a de-identification framework that reformulates the task as graph-guided semantic rewriting. Anonpsy (1) converts each narrative into a semantic graph encoding clinical entities, temporal anchors, and typed relations; (2) applies graph-constrained perturbations that modify identifying context while preserving clinically essential structure; and (3) regenerates text via graph-conditioned LLM generation. Evaluated on 90 clinician-authored psychiatric case narratives, Anonpsy preserves diagnostic fidelity while achieving consistently low re-identification risk under expert, semantic, and GPT-5-based evaluations. Compared with a strong LLM-only rewriting baseline, Anonpsy yields substantially lower semantic similarity and identifiability. These results demonstrate that explicit structural representations combined with constrained generation provide an effective approach to de-identification for psychiatric narratives.

</details>


### [396] [When Wording Steers the Evaluation: Framing Bias in LLM judges](https://arxiv.org/abs/2601.13537)
*Yerin Hwang,Dongryeol Lee,Taegwan Kang,Minwoo Lee,Kyomin Jung*

Main category: cs.CL

TL;DR: 研究发现大语言模型在评估任务中存在显著的框架效应，即提示语的微小变化会显著影响模型判断，这是当前LLM评估系统的结构性缺陷


<details>
  <summary>Details</summary>
Motivation: 大语言模型的回答会因提示语措辞而变化，但框架偏差对LLM评估的影响尚未充分研究。心理学中的框架效应表明，表达方式会影响判断，作者希望探究这种效应在LLM评估中的表现

Method: 采用心理学中的框架效应概念，设计对称提示语（谓词-肯定和谓词-否定结构），在四个高风险评估任务中系统研究提示语框架如何影响模型判断，测试了14个LLM评估模型

Result: 所有LLM评估模型都表现出明显的框架敏感性，模型输出存在显著差异。不同模型家族显示出倾向于同意或拒绝的明显趋势，表明框架偏差是当前LLM评估系统的结构性特征

Conclusion: 框架偏差是当前LLM评估系统的一个基本问题，需要开发框架感知的评估协议来确保稳定和公正的判断

Abstract: Large language models (LLMs) are known to produce varying responses depending on prompt phrasing, indicating that subtle guidance in phrasing can steer their answers. However, the impact of this framing bias on LLM-based evaluation, where models are expected to make stable and impartial judgments, remains largely underexplored. Drawing inspiration from the framing effect in psychology, we systematically investigate how deliberate prompt framing skews model judgments across four high-stakes evaluation tasks. We design symmetric prompts using predicate-positive and predicate-negative constructions and demonstrate that such framing induces significant discrepancies in model outputs. Across 14 LLM judges, we observe clear susceptibility to framing, with model families showing distinct tendencies toward agreement or rejection. These findings suggest that framing bias is a structural property of current LLM-based evaluation systems, underscoring the need for framing-aware protocols.

</details>


### [397] [HateXScore: A Metric Suite for Evaluating Reasoning Quality in Hate Speech Explanations](https://arxiv.org/abs/2601.13547)
*Yujia Hu,Roy Ka-Wei Lee*

Main category: cs.CL

TL;DR: HateXScore：一个用于评估仇恨言论检测模型解释质量的四组件指标套件，旨在揭示标准指标无法发现的解释性失败和标注不一致问题。


<details>
  <summary>Details</summary>
Motivation: 当前仇恨言论检测评估框架很少评估文本为何被判定为仇恨言论，缺乏对模型解释质量的系统评估方法，无法揭示解释性失败和标注不一致问题。

Method: 提出HateXScore四组件指标：1)结论明确性；2)引用跨度的忠实性和因果基础；3)受保护群体识别（可配置策略）；4)这些元素之间的逻辑一致性。在六个不同的仇恨言论数据集上进行评估。

Result: HateXScore能够有效揭示标准指标（如准确率或F1分数）无法发现的解释性失败和标注不一致问题。人工评估显示与HateXScore有很强的一致性，验证了其作为可信透明内容审核实用工具的有效性。

Conclusion: HateXScore是一个有效的诊断补充工具，能够评估模型解释的推理质量，提高内容审核的可信度和透明度，为仇恨言论检测系统的解释性评估提供了实用框架。

Abstract: Hateful speech detection is a key component of content moderation, yet current evaluation frameworks rarely assess why a text is deemed hateful. We introduce \textsf{HateXScore}, a four-component metric suite designed to evaluate the reasoning quality of model explanations. It assesses (i) conclusion explicitness, (ii) faithfulness and causal grounding of quoted spans, (iii) protected group identification (policy-configurable), and (iv) logical consistency among these elements. Evaluated on six diverse hate speech datasets, \textsf{HateXScore} is intended as a diagnostic complement to reveal interpretability failures and annotation inconsistencies that are invisible to standard metrics like Accuracy or F1. Moreover, human evaluation shows strong agreement with \textsf{HateXScore}, validating it as a practical tool for trustworthy and transparent moderation.
  \textcolor{red}{Disclaimer: This paper contains sensitive content that may be disturbing to some readers.}

</details>


### [398] [Comparing Without Saying: A Dataset and Benchmark for Implicit Comparative Opinion Mining from Same-User Reviews](https://arxiv.org/abs/2601.13575)
*Thanh-Lam T. Nguyen,Ngoc-Quang Le,Quoc-Trung Phu,Thi-Phuong Le,Ngoc-Huyen Pham,Phuong-Nguyen Nguyen,Hoang-Quynh Le*

Main category: cs.CL

TL;DR: SUDO是一个用于隐式比较观点挖掘的新数据集，包含4,150个标注的评论对，通过双层结构捕捉方面级提及和评论级偏好，为缺乏显式比较表达的真实评论分析提供基准。


<details>
  <summary>Details</summary>
Motivation: 现有比较观点挖掘研究主要关注显式比较表达，但在真实评论中并不常见，而用户在不同评论中表达的隐式偏好却很少被探索，这限制了比较观点挖掘的实际应用。

Method: 提出了SUDO数据集，包含4,150个标注的评论对（15,191个句子），采用双层结构：方面级提及和评论级偏好。使用两种基线架构进行基准测试：传统机器学习方法和语言模型方法。

Result: 实验结果显示，语言模型方法优于传统机器学习方法，但整体性能仍然中等，表明该任务具有固有难度，SUDO数据集成为未来研究的挑战性且有价值的基准。

Conclusion: SUDO数据集填补了隐式比较观点挖掘的研究空白，为分析用户在不同评论中表达的偏好提供了可靠基础，尽管任务具有挑战性，但为未来研究建立了有价值的基准。

Abstract: Existing studies on comparative opinion mining have mainly focused on explicit comparative expressions, which are uncommon in real-world reviews. This leaves implicit comparisons - here users express preferences across separate reviews - largely underexplored. We introduce SUDO, a novel dataset for implicit comparative opinion mining from same-user reviews, allowing reliable inference of user preferences even without explicit comparative cues. SUDO comprises 4,150 annotated review pairs (15,191 sentences) with a bi-level structure capturing aspect-level mentions and review-level preferences. We benchmark this task using two baseline architectures: traditional machine learning- and language model-based baselines. Experimental results show that while the latter outperforms the former, overall performance remains moderate, revealing the inherent difficulty of the task and establishing SUDO as a challenging and valuable benchmark for future research.

</details>


### [399] [TREX: Tokenizer Regression for Optimal Data Mixture](https://arxiv.org/abs/2601.13588)
*Inho Won,Hangyeol Yoo,Minkyung Cho,Jungyeul Park,Hoyun Song,KyungTae Lim*

Main category: cs.CL

TL;DR: TREX框架通过回归模型预测多语言分词器训练的最佳数据混合比例，避免传统启发式方法或大规模搜索的成本，提升分词器压缩效率。


<details>
  <summary>Details</summary>
Motivation: 多语言大语言模型的分词器需要优化语言数据混合比例，但现有方法依赖启发式规则或成本高昂的大规模搜索，缺乏高效确定最优混合比例的方法。

Method: 提出TREX框架：1）在小规模代理分词器上训练随机数据混合；2）收集压缩统计信息；3）学习从数据混合到压缩性能的回归模型；4）利用模型在大规模分词器训练前预测最优混合比例。

Result: TREX预测的混合比例训练的分词器，在分布内和分布外压缩效率上比LLaMA3和均匀分布混合高出12%，展现出良好的可扩展性、鲁棒性和实际效果。

Conclusion: TREX框架通过回归建模有效解决了多语言分词器数据混合优化的成本-精度权衡问题，为高效分词器设计提供了可扩展的解决方案。

Abstract: Building effective tokenizers for multilingual Large Language Models (LLMs) requires careful control over language-specific data mixtures. While a tokenizer's compression performance critically affects the efficiency of LLM training and inference, existing approaches rely on heuristics or costly large-scale searches to determine optimal language ratios. We introduce Tokenizer Regression for Optimal Data MiXture (TREX), a regression-based framework that efficiently predicts the optimal data mixture for tokenizer training. TREX trains small-scale proxy tokenizers on random mixtures, gathers their compression statistics, and learns to predict compression performance from data mixtures. This learned model enables scalable mixture search before large-scale tokenizer training, mitigating the accuracy-cost trade-off in multilingual tokenizer design. Tokenizers trained with TReX's predicted mixtures outperform mixtures based on LLaMA3 and uniform distributions by up to 12% in both inand out-of-distribution compression efficiency, demonstrating strong scalability, robustness, and practical effectiveness.

</details>


### [400] [Vulnerability of LLMs' Belief Systems? LLMs Belief Resistance Check Through Strategic Persuasive Conversation Interventions](https://arxiv.org/abs/2601.13590)
*Fan Huang,Haewoon Kwak,Jisun An*

Main category: cs.CL

TL;DR: LLM对说服的易感性研究：在SMCR框架下评估主流模型，发现小模型极易被说服，元认知提示反而增加脆弱性，对抗微调防御效果因模型而异。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM广泛应用于问答任务，但研究发现它们容易受到说服并采纳反事实信念。需要系统评估LLM在说服下的信念稳定性，以了解其脆弱性和开发更可靠的模型。

Method: 采用SMCR（来源-信息-渠道-接收者）沟通框架，在五个主流LLM和三个领域（事实知识、医疗问答、社会偏见）中评估不同说服策略对信念稳定性的影响。研究元认知提示（引发自报信心）的影响，并评估对抗微调作为防御手段。

Result: 小模型表现出极端顺从，超过80%的信念变化发生在第一次说服时；元认知提示反而增加脆弱性，加速信念侵蚀；对抗微调效果因模型而异：GPT-4o-mini达到98.6%鲁棒性，Mistral 7B从35.7%提升到79.3%，而Llama模型即使微调后仍高度易感（<14%）。

Conclusion: 当前鲁棒性干预措施存在显著的模型依赖性限制，研究结果为开发更可信的LLM提供了指导，强调需要针对不同模型设计更有效的防御策略。

Abstract: Large Language Models (LLMs) are increasingly employed in various question-answering tasks. However, recent studies showcase that LLMs are susceptible to persuasion and could adopt counterfactual beliefs. We present a systematic evaluation of LLM susceptibility to persuasion under the Source--Message--Channel--Receiver (SMCR) communication framework. Across five mainstream Large Language Models (LLMs) and three domains (factual knowledge, medical QA, and social bias), we analyze how different persuasive strategies influence belief stability over multiple interaction turns. We further examine whether meta-cognition prompting (i.e., eliciting self-reported confidence) affects resistance to persuasion. Results show that smaller models exhibit extreme compliance, with over 80% of belief changes occurring at the first persuasive turn (average end turn of 1.1--1.4). Contrary to expectations, meta-cognition prompting increases vulnerability by accelerating belief erosion rather than enhancing robustness. Finally, we evaluate adversarial fine-tuning as a defense. While GPT-4o-mini achieves near-complete robustness (98.6%) and Mistral~7B improves substantially (35.7% $\rightarrow$ 79.3%), Llama models remain highly susceptible (<14%) even when fine-tuned on their own failure cases. Together, these findings highlight substantial model-dependent limits of current robustness interventions and offer guidance for developing more trustworthy LLMs.

</details>


### [401] [CauScientist: Teaching LLMs to Respect Data for Causal Discovery](https://arxiv.org/abs/2601.13614)
*Bo Peng,Sirui Chen,Lei Xu,Chaochao Lu*

Main category: cs.CL

TL;DR: CauScientist是一个结合LLM假设生成和概率统计验证的因果发现框架，通过混合初始化、迭代优化和错误记忆机制，显著提升因果图发现性能。


<details>
  <summary>Details</summary>
Motivation: 现有因果发现方法存在局限：纯数据驱动方法受统计不可区分性和建模假设限制，而基于LLM的方法要么忽略统计证据，要么引入未经验证的先验知识可能误导结果。需要一种结合两者优势的协作框架。

Method: 提出CauScientist框架：1）混合初始化选择优质起始图；2）LLM作为"数据科学家"生成假设修改，概率统计作为"验证者"进行严格检验；3）迭代优化结构；4）错误记忆机制指导高效搜索空间。

Result: 实验表明CauScientist显著优于纯数据驱动基线，F1分数提升高达53.8%，召回率从35.0%提升到100.0%。在37节点复杂图上，相比Qwen3-32B将结构汉明距离(SHD)降低44.0%。

Conclusion: CauScientist成功结合了LLM的假设生成能力和统计验证的严谨性，为因果发现提供了更可靠、高效的解决方案，特别是在复杂图结构上表现出色。

Abstract: Causal discovery is fundamental to scientific understanding and reliable decision-making. Existing approaches face critical limitations: purely data-driven methods suffer from statistical indistinguishability and modeling assumptions, while recent LLM-based methods either ignore statistical evidence or incorporate unverified priors that can mislead result. To this end, we propose CauScientist, a collaborative framework that synergizes LLMs as hypothesis-generating "data scientists" with probabilistic statistics as rigorous "verifiers". CauScientist employs hybrid initialization to select superior starting graphs, iteratively refines structures through LLM-proposed modifications validated by statistical criteria, and maintains error memory to guide efficient search space. Experiments demonstrate that CauScientist substantially outperforms purely data-driven baselines, achieving up to 53.8% F1 score improvement and enhancing recall from 35.0% to 100.0%. Notably, while standalone LLM performance degrades with graph complexity, CauScientist reduces structural hamming distance (SHD) by 44.0% compared to Qwen3-32B on 37-node graphs. Our project page is at https://github.com/OpenCausaLab/CauScientist.

</details>


### [402] [Activation-Space Anchored Access Control for Multi-Class Permission Reasoning in Large Language Models](https://arxiv.org/abs/2601.13630)
*Zhaopeng Zhang,Pengcheng Sun,Lan Zhang,Chen Tang,Jiewei Lai,Yunhao Wang,Hui Jin*

Main category: cs.CL

TL;DR: AAAC：无需训练的多类权限控制框架，利用激活空间几何规律，通过权限锚点重定向查询激活，减少权限违规86.5%


<details>
  <summary>Details</summary>
Motivation: LLMs在知识库问答中可能无意中泄露超出用户权限范围的敏感信息，难以满足细粒度访问控制需求

Method: 基于激活空间几何规律，提出AAAC框架：构建权限锚点银行，通过多锚点引导机制重定向查询激活到授权区域

Result: 在三个LLM家族上实验显示，权限违规率降低86.5%，提示攻击成功率降低90.7%，响应可用性提升，推理开销小

Conclusion: AAAC提供了一种无需训练的有效权限控制方法，利用激活空间几何特性实现细粒度访问控制

Abstract: Large language models (LLMs) are increasingly deployed over knowledge bases for efficient knowledge retrieval and question answering. However, LLMs can inadvertently answer beyond a user's permission scope, leaking sensitive content, thus making it difficult to deploy knowledge-base QA under fine-grained access control requirements. In this work, we identify a geometric regularity in intermediate activations: for the same query, representations induced by different permission scopes cluster distinctly and are readily separable. Building on this separability, we propose Activation-space Anchored Access Control (AAAC), a training-free framework for multi-class permission control. AAAC constructs an anchor bank, with one permission anchor per class, from a small offline sample set and requires no fine-tuning. At inference time, a multi-anchor steering mechanism redirects each query's activations toward the anchor-defined authorized region associated with the current user, thereby suppressing over-privileged generations by design. Finally, extensive experiments across three LLM families demonstrate that AAAC reduces permission violation rates by up to 86.5% and prompt-based attack success rates by 90.7%, while improving response usability with minor inference overhead compared to baselines.

</details>


### [403] [Towards Token-Level Text Anomaly Detection](https://arxiv.org/abs/2601.13644)
*Yang Cao,Bicheng Yu,Sikun Yang,Ming Liu,Yujiu Yang*

Main category: cs.CL

TL;DR: 提出了一种新的token级文本异常检测范式，能够在文本内部精确定位异常部分，超越了传统的文档级检测方法。


<details>
  <summary>Details</summary>
Motivation: 现有文本异常检测方法（如垃圾邮件过滤、假新闻检测）仅限于文档级分析，无法识别文本中哪些具体部分是异常的，需要更细粒度的异常定位能力。

Method: 提出了token级异常检测的新范式，正式定义了文档级和token级的文本异常，并设计了一个跨多层级操作的统一检测框架。

Result: 收集并标注了三个涵盖垃圾邮件、评论和语法错误的基准数据集，实验结果显示该框架在6个基线方法中表现最佳，为文本异常精确定位开辟了新可能。

Conclusion: token级异常检测是一个有前景的研究方向，提出的统一框架在多个数据集上优于现有方法，所有代码和数据已开源供进一步研究。

Abstract: Despite significant progress in text anomaly detection for web applications such as spam filtering and fake news detection, existing methods are fundamentally limited to document-level analysis, unable to identify which specific parts of a text are anomalous. We introduce token-level anomaly detection, a novel paradigm that enables fine-grained localization of anomalies within text. We formally define text anomalies at both document and token-levels, and propose a unified detection framework that operates across multiple levels. To facilitate research in this direction, we collect and annotate three benchmark datasets spanning spam, reviews and grammar errors with token-level labels. Experimental results demonstrate that our framework get better performance than other 6 baselines, opening new possibilities for precise anomaly localization in text. All the codes and data are publicly available on https://github.com/charles-cao/TokenCore.

</details>


### [404] [Fairness or Fluency? An Investigation into Language Bias of Pairwise LLM-as-a-Judge](https://arxiv.org/abs/2601.13649)
*Xiaolin Zhou,Zheng Luo,Yicheng Gao,Qixuan Chen,Xiyang Hu,Yue Zhao,Ruishan Liu*

Main category: cs.CL

TL;DR: 研究发现LLM作为评判者在跨语言评估中存在两种语言偏见：同语言评判时欧洲语言表现优于非洲语言，跨语言评判时模型偏好英语答案，且这种偏见不能完全由困惑度偏差解释。


<details>
  <summary>Details</summary>
Motivation: 虽然LLM作为评判者被广泛应用，但先前研究表明其存在各种偏见，其中语言偏见可能导致评判结果与人类偏好不一致。本研究旨在系统分析LLM作为评判者在跨语言评估中的语言偏见问题。

Method: 研究分析了两种语言偏见：(1)同语言评判时的性能差异，比较不同语言家族在相同语言选项中的表现；(2)跨语言评判时的偏见，分析模型对不同语言选项的偏好。同时探讨了语言偏见与困惑度偏差的关系。

Result: 同语言评判中，欧洲语言表现显著优于非洲语言，文化相关主题中偏见更明显；跨语言评判中，大多数模型偏好英语答案，且答案语言比问题语言影响更大；语言偏见与困惑度仅轻微相关，不能完全由困惑度解释。

Conclusion: LLM作为评判者存在显著的语言偏见，这种偏见在不同语言家族和跨语言场景中表现明显，且不能简单归因于困惑度偏差。研究结果强调了在开发LLM评判系统时需要考虑语言公平性问题。

Abstract: Recent advances in Large Language Models (LLMs) have incentivized the development of LLM-as-a-judge, an application of LLMs where they are used as judges to decide the quality of a certain piece of text given a certain context. However, previous studies have demonstrated that LLM-as-a-judge can be biased towards different aspects of the judged texts, which often do not align with human preference. One of the identified biases is language bias, which indicates that the decision of LLM-as-a-judge can differ based on the language of the judged texts. In this paper, we study two types of language bias in pairwise LLM-as-a-judge: (1) performance disparity between languages when the judge is prompted to compare options from the same language, and (2) bias towards options written in major languages when the judge is prompted to compare options of two different languages. We find that for same-language judging, there exist significant performance disparities across language families, with European languages consistently outperforming African languages, and this bias is more pronounced in culturally-related subjects. For inter-language judging, we observe that most models favor English answers, and that this preference is influenced more by answer language than question language. Finally, we investigate whether language bias is in fact caused by low-perplexity bias, a previously identified bias of LLM-as-a-judge, and we find that while perplexity is slightly correlated with language bias, language bias cannot be fully explained by perplexity only.

</details>


### [405] [Beyond Known Facts: Generating Unseen Temporal Knowledge to Address Data Contamination in LLM Evaluation](https://arxiv.org/abs/2601.13658)
*Arthur Amalvy,Hen-Hsen Huang*

Main category: cs.CL

TL;DR: 提出一个基于未来事实的合成评估数据集，用于无污染地评估时间知识图谱抽取系统，特别是LLM-based方法。


<details>
  <summary>Details</summary>
Motivation: 时间知识图谱抽取（TKGE）对于构建大型网络知识库很重要，但现有训练和评估数据集稀缺，且存在数据污染问题（训练集与评估集重叠），可能导致LLM性能被高估。

Method: 采用两步法：1) 时间知识图谱预测（TKGF）生成合理的未来四元组，并过滤以符合原始知识库模式；2) 使用LLM进行四元组到文本的生成，创建语义对齐的文本描述。

Result: 创建了包含4.2K个未来四元组及对应文本描述的数据集，并证明在无污染的未来事实数据集上，最先进的EDC框架性能下降，揭示了之前评估可能存在的偏差。

Conclusion: 提出的合成评估数据集解决了数据污染问题，提供了无偏的基准测试，并公开了数据集和生成方法，支持持续创建无限未来时间数据集用于长期、无污染的TKGE评估。

Abstract: The automatic extraction of information is important for populating large web knowledge bases such as Wikidata. The temporal version of that task, temporal knowledge graph extraction (TKGE), involves extracting temporally grounded facts from text, represented as semantic quadruples (subject, relation, object, timestamp). Many recent systems take advantage of large language models (LLMs), which are becoming a new cornerstone of the web due to their performance on many tasks across the natural language processing (NLP) field. Despite the importance of TKGE, existing datasets for training and evaluation remain scarce, and contamination of evaluation data is an unaddressed issue, potentially inflating LLMs' perceived performance due to overlaps between training and evaluation sets. To mitigate these challenges, we propose a novel synthetic evaluation dataset constructed from predicted future, previously unseen temporal facts, thereby eliminating contamination and enabling robust and unbiased benchmarking. Our dataset creation involves a two-step approach: (1) Temporal Knowledge Graph Forecasting (TKGF) generates plausible future quadruples, which are subsequently filtered to adhere to the original knowledge base schema; (2) LLMs perform quadruple-to-text generation, creating semantically aligned textual descriptions. We benchmark Extract, Define and Canonicalize (EDC), a state-of-the-art LLM-based extraction framework, demonstrating that LLM performance decreases when evaluated on our dataset compared to a dataset of known facts. We publicly release our dataset consisting of 4.2K future quadruples and corresponding textual descriptions, along with the generation methodology, enabling continuous creation of unlimited future temporal datasets to serve as long-term, contamination-free benchmarks for TKGE.

</details>


### [406] [Temporal-Spatial Decouple before Act: Disentangled Representation Learning for Multimodal Sentiment Analysis](https://arxiv.org/abs/2601.13659)
*Chunlei Meng,Ziyang Zhou,Lucas He,Xiaojing Du,Chun Ouyang,Zhongxue Gan*

Main category: cs.CL

TL;DR: TSDA通过时空解耦与对齐提升多模态情感分析性能


<details>
  <summary>Details</summary>
Motivation: 现有方法忽略时空异质性，导致时空信息不对称和性能受限

Method: 提出TSDA：在交互前将每个模态解耦为时间动态和空间结构上下文，分别编码后进行跨模态对齐，最后通过门控重耦合

Result: TSDA在实验中优于基线方法，消融分析验证了设计的必要性和可解释性

Conclusion: 显式时空解耦与对齐能有效提升多模态情感分析性能

Abstract: Multimodal Sentiment Analysis integrates Linguistic, Visual, and Acoustic. Mainstream approaches based on modality-invariant and modality-specific factorization or on complex fusion still rely on spatiotemporal mixed modeling. This ignores spatiotemporal heterogeneity, leading to spatiotemporal information asymmetry and thus limited performance. Hence, we propose TSDA, Temporal-Spatial Decouple before Act, which explicitly decouples each modality into temporal dynamics and spatial structural context before any interaction. For every modality, a temporal encoder and a spatial encoder project signals into separate temporal and spatial body. Factor-Consistent Cross-Modal Alignment then aligns temporal features only with their temporal counterparts across modalities, and spatial features only with their spatial counterparts. Factor specific supervision and decorrelation regularization reduce cross factor leakage while preserving complementarity. A Gated Recouple module subsequently recouples the aligned streams for task. Extensive experiments show that TSDA outperforms baselines. Ablation analysis studies confirm the necessity and interpretability of the design.

</details>


### [407] [CommunityBench: Benchmarking Community-Level Alignment across Diverse Groups and Tasks](https://arxiv.org/abs/2601.13669)
*Jiayu Lin,Zhongyu Wei*

Main category: cs.CL

TL;DR: 提出社区级对齐作为个体级和通用级之间的折中方案，并引入首个大规模社区级对齐评估基准CommunityBench，发现当前LLMs在建模社区特定偏好方面能力有限。


<details>
  <summary>Details</summary>
Motivation: 现有LLM对齐策略存在两个极端：通用价值集（忽略少数群体）和个体级定制（成本过高）。人类社会按社会集群组织，群体内价值对齐度高，因此需要社区级对齐作为折中方案。

Method: 提出社区级对齐概念，构建CommunityBench基准，包含基于共同身份和共同纽带理论的四个任务，用于评估基础模型在社区级对齐方面的能力。

Result: 评估显示当前LLMs在建模社区特定偏好方面能力有限，但社区级对齐在促进个体建模方面具有潜力，为可扩展和多元对齐提供了有前景的方向。

Conclusion: 社区级对齐是解决现有对齐策略局限性的可行方案，CommunityBench为评估社区级对齐能力提供了重要工具，未来研究应关注如何有效实现社区级对齐以支持多元价值。

Abstract: Large language models (LLMs) alignment ensures model behaviors reflect human value. Existing alignment strategies primarily follow two paths: one assumes a universal value set for a unified goal (i.e., one-size-fits-all), while the other treats every individual as unique to customize models (i.e., individual-level). However, assuming a monolithic value space marginalizes minority norms, while tailoring individual models is prohibitively expensive. Recognizing that human society is organized into social clusters with high intra-group value alignment, we propose community-level alignment as a "middle ground". Practically, we introduce CommunityBench, the first large-scale benchmark for community-level alignment evaluation, featuring four tasks grounded in Common Identity and Common Bond theory. With CommunityBench, we conduct a comprehensive evaluation of various foundation models on CommunityBench, revealing that current LLMs exhibit limited capacity to model community-specific preferences. Furthermore, we investigate the potential of community-level alignment in facilitating individual modeling, providing a promising direction for scalable and pluralistic alignment.

</details>


### [408] [HeteroCache: A Dynamic Retrieval Approach to Heterogeneous KV Cache Compression for Long-Context LLM Inference](https://arxiv.org/abs/2601.13684)
*Zhiyuan Shi,Qibo Qiu,Feng Xue,Zhonglin Jiang,Li Yu,Jian Jiang,Xiaofei He,Wenxiao Wang*

Main category: cs.CL

TL;DR: HeteroCache是一个无需训练的动态KV缓存压缩框架，通过细粒度头部分类、分层存储和异步检索机制，解决长上下文LLM推理中的内存瓶颈问题，在224K上下文上实现3倍解码加速。


<details>
  <summary>Details</summary>
Motivation: KV缓存的线性内存增长是长上下文LLM推理的主要瓶颈。现有静态压缩方法无法保留全局重要信息，因为它们忽略了注意力漂移现象（token重要性动态变化）。动态检索方法虽然尝试解决此问题，但通常存在粗粒度缓存策略和高I/O开销的问题。

Method: 基于两个关键观察：注意力头具有不同的时间异质性，同一层内头之间存在显著空间冗余。HeteroCache根据稳定性和冗余性对头部分类，采用细粒度权重分配策略，为注意力快速变化的头分配更大的缓存预算以捕捉上下文变化。采用分层存储机制，让代表性头子集监控注意力变化，并触发从CPU的异步按需检索，有效隐藏I/O延迟。

Result: 在多个长上下文基准测试中达到最先进性能，在224K上下文上相比原始模型实现高达3倍的解码加速。

Conclusion: HeteroCache通过细粒度头部分类、分层存储和异步检索机制，有效解决了长上下文LLM推理中的KV缓存内存瓶颈问题，实现了显著的性能提升和解码加速。

Abstract: The linear memory growth of the KV cache poses a significant bottleneck for LLM inference in long-context tasks. Existing static compression methods often fail to preserve globally important information, principally because they overlook the attention drift phenomenon where token significance evolves dynamically. Although recent dynamic retrieval approaches attempt to address this issue, they typically suffer from coarse-grained caching strategies and incur high I/O overhead due to frequent data transfers. To overcome these limitations, we propose HeteroCache, a training-free dynamic compression framework. Our method is built on two key insights: attention heads exhibit diverse temporal heterogeneity, and there is significant spatial redundancy among heads within the same layer. Guided by these insights, HeteroCache categorizes heads based on stability and redundancy. Consequently, we apply a fine-grained weighting strategy that allocates larger cache budgets to heads with rapidly shifting attention to capture context changes, thereby addressing the inefficiency of coarse-grained strategies. Furthermore, we employ a hierarchical storage mechanism in which a subset of representative heads monitors attention shift, and trigger an asynchronous, on-demand retrieval of contexts from the CPU, effectively hiding I/O latency. Finally, experiments demonstrate that HeteroCache achieves state-of-the-art performance on multiple long-context benchmarks and accelerates decoding by up to $3\times$ compared to the original model in the 224K context. Our code will be open-source.

</details>


### [409] [Dr. Assistant: Enhancing Clinical Diagnostic Inquiry via Structured Diagnostic Reasoning Data and Reinforcement Learning](https://arxiv.org/abs/2601.13690)
*Yue Guo,Fanfu Wang,Jianwei Lv,Xincheng Shi,Yuchen Li,Youya Wang,Yunsheng Zeng,Yujing Liu,Yunhao Qiao,Gen Li,Junfeng Wang,Bo Yuan*

Main category: cs.CL

TL;DR: 本文提出Dr. Assistant临床诊断模型，通过CDRD数据结构捕获临床推理逻辑，采用两阶段训练（SFT+RL），在诊断推理和问询方面优于开源模型，与闭源模型竞争。


<details>
  <summary>Details</summary>
Motivation: 传统临床决策支持系统维护成本高、泛化能力差，而大型语言模型虽在医疗领域有应用潜力，但其诊断推理和问询能力受限，需要改进。

Method: 提出CDRD数据结构捕获抽象临床推理逻辑，构建Dr. Assistant模型，采用两阶段训练：监督微调（SFT）和强化学习（RL）配合定制奖励函数。

Result: Dr. Assistant在诊断推理和问询方面超越开源模型，与闭源模型性能相当，为临床诊断问询指导提供有效解决方案。

Conclusion: 提出的CDRD数据结构和Dr. Assistant模型有效提升了临床诊断推理和问询能力，为解决传统CDSS系统问题提供了新方案。

Abstract: Clinical Decision Support Systems (CDSSs) provide reasoning and inquiry guidance for physicians, yet they face notable challenges, including high maintenance costs and low generalization capability. Recently, Large Language Models (LLMs) have been widely adopted in healthcare due to their extensive knowledge reserves, retrieval, and communication capabilities. While LLMs show promise and excel at medical benchmarks, their diagnostic reasoning and inquiry skills are constrained. To mitigate this issue, we propose (1) Clinical Diagnostic Reasoning Data (CDRD) structure to capture abstract clinical reasoning logic, and a pipeline for its construction, and (2) the Dr. Assistant, a clinical diagnostic model equipped with clinical reasoning and inquiry skills. Its training involves a two-stage process: SFT, followed by RL with a tailored reward function. We also introduce a benchmark to evaluate both diagnostic reasoning and inquiry. Our experiments demonstrate that the Dr. Assistant outperforms open-source models and achieves competitive performance to closed-source models, providing an effective solution for clinical diagnostic inquiry guidance.

</details>


### [410] [OptiSQL: Executable SQL Generation from Optical TokensOptiSQL: Executable SQL Generation from Optical Tokens](https://arxiv.org/abs/2601.13695)
*Sifan Li,Hongkai Chen,Yujun Cai,Liyang Chen,Qingwen Ye,Yiwei Wang*

Main category: cs.CL

TL;DR: OptiSQL：直接从表格图像和自然语言问题生成可执行SQL的视觉驱动框架，使用紧凑光学标记大幅减少输入标记数量


<details>
  <summary>Details</summary>
Motivation: 传统文本到SQL方法需要将表格完全线性化为文本模式，这需要大量标记且不符合现实场景（表格通常以视觉形式出现在文档或网页中）

Method: 使用OCR导向的视觉编码器将表格结构和内容压缩为少量光学标记，冻结编码器并微调预训练解码器进行SQL生成

Result: 在可视化的Spider 2.0-Snow数据集上，OptiSQL保持强大的执行准确性，同时将表格输入标记减少一个数量级，光学标记在视觉扰动下仍能保持基本结构信息

Conclusion: 紧凑光学表示可以作为可执行语义解析的高效接口，视觉驱动方法在减少标记开销的同时保持SQL生成质量

Abstract: Executable SQL generation is typically studied in text-to-SQL settings, where tables are provided as fully linearized textual schemas and contents. While effective, this formulation assumes access to structured text and incurs substantial token overhead, which is misaligned with many real-world scenarios where tables appear as visual artifacts in documents or webpages. We investigate whether compact optical representations can serve as an efficient interface for executable semantic parsing. We present OptiSQL, a vision-driven framework that generates executable SQL directly from table images and natural language questions using compact optical tokens. OptiSQL leverages an OCR-oriented visual encoder to compress table structure and content into a small set of optical tokens and fine-tunes a pretrained decoder for SQL generation while freezing the encoder to isolate representation sufficiency. Experiments on a visualized version of Spider 2.0-Snow show that OptiSQL retains strong execution accuracy while reducing table input tokens by an order of magnitude. Robustness analyses further demonstrate that optical tokens preserve essential structural information under visual perturbations.

</details>


### [411] [Uncertainty-Aware Gradient Signal-to-Noise Data Selection for Instruction Tuning](https://arxiv.org/abs/2601.13697)
*Zhihang Yuan,Chengyu Yue,Long Huang,Litu Ou,Lei Shi*

Main category: cs.CL

TL;DR: GRADFILTERING：一种基于梯度信噪比的不确定性感知数据选择框架，用于高效指令微调，在减少计算成本的同时保持或提升模型性能


<details>
  <summary>Details</summary>
Motivation: 现代指令数据集通常规模大、噪声多且冗余，导致全数据微调成本高昂且不必要。现有数据选择方法要么构建昂贵的梯度数据存储，要么使用弱代理的静态评分，忽略了模型训练过程中的不确定性演化，而这正是LLM可解释性的关键来源。

Method: 提出GRADFILTERING框架：1）使用小型GPT-2代理模型配合LoRA集成；2）将每个示例的梯度聚合成梯度信噪比（G-SNR）效用指标；3）基于不确定性感知的评分进行数据选择；4）框架与具体优化目标无关。

Result: 在大多数LLM-as-a-judge评估和人工评估中，GRADFILTERING选择的数据子集表现优于随机子集和强基线方法。在相同计算预算下，GRADFILTERING选择的子集收敛速度更快，体现了不确定性感知评分的优势。

Conclusion: GRADFILTERING通过利用梯度信噪比和不确定性感知评分，提供了一种高效的数据选择方法，能够在减少计算成本的同时保持或提升大语言模型的指令微调性能，为LLM的高效训练提供了新思路。

Abstract: Instruction tuning is a standard paradigm for adapting large language models (LLMs), but modern instruction datasets are large, noisy, and redundant, making full-data fine-tuning costly and often unnecessary. Existing data selection methods either build expensive gradient datastores or assign static scores from a weak proxy, largely ignoring evolving uncertainty, and thus missing a key source of LLM interpretability. We propose GRADFILTERING, an objective-agnostic, uncertainty-aware data selection framework that utilizes a small GPT-2 proxy with a LoRA ensemble and aggregates per-example gradients into a Gradient Signal-to-Noise Ratio (G-SNR) utility. Our method matches or surpasses random subsets and strong baselines in most LLM-as-a-judge evaluations as well as in human assessment. Moreover, GRADFILTERING-selected subsets converge faster than competitive filters under the same compute budget, reflecting the benefit of uncertainty-aware scoring.

</details>


### [412] [GerAV: Towards New Heights in German Authorship Verification using Fine-Tuned LLMs on a New Benchmark](https://arxiv.org/abs/2601.13711)
*Lotta Kiefer,Christoph Leiter,Sotaro Takeshita,Elena Schmidt,Steffen Eger*

Main category: cs.CL

TL;DR: 提出了GerAV，一个包含超过60万标注文本对的德语作者验证基准，填补了非英语语言大规模基准的空白，通过系统评估发现微调大语言模型表现最佳，并观察到专业化和泛化之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 作者验证任务在英语领域已有广泛研究，但其他语言的大规模基准和系统评估仍然稀缺。本文旨在填补德语作者验证领域的这一空白。

Method: 构建GerAV基准，包含来自Twitter和Reddit的超过60万标注文本对，Reddit部分进一步分为域内、跨域消息型子集和基于个人资料的子集。使用提供的训练分割对强基线模型和最先进模型进行系统评估。

Result: 微调的大语言模型表现最佳，比最近的基线模型F1分数高出0.09，在零样本设置中比GPT-5高出0.08。观察到专业化和泛化之间的权衡：在匹配条件下特定数据训练的模型表现最好，但跨数据泛化能力较差，通过组合训练源可以缓解这一限制。

Conclusion: GerAV为推进德语和跨域作者验证研究提供了一个具有挑战性和多功能的基准，填补了非英语语言大规模评估的空白。

Abstract: Authorship verification (AV) is the task of determining whether two texts were written by the same author and has been studied extensively, predominantly for English data. In contrast, large-scale benchmarks and systematic evaluations for other languages remain scarce. We address this gap by introducing GerAV, a comprehensive benchmark for German AV comprising over 600k labeled text pairs. GerAV is built from Twitter and Reddit data, with the Reddit part further divided into in-domain and cross-domain message-based subsets, as well as a profile-based subset. This design enables controlled analysis of the effects of data source, topical domain, and text length. Using the provided training splits, we conduct a systematic evaluation of strong baselines and state-of-the-art models and find that our best approach, a fine-tuned large language model, outperforms recent baselines by up to 0.09 absolute F1 score and surpasses GPT-5 in a zero-shot setting by 0.08. We further observe a trade-off between specialization and generalization: models trained on specific data types perform best under matching conditions but generalize less well across data regimes, a limitation that can be mitigated by combining training sources. Overall, GerAV provides a challenging and versatile benchmark for advancing research on German and cross-domain AV.

</details>


### [413] [Simulated Ignorance Fails: A Systematic Study of LLM Behaviors on Forecasting Problems Before Model Knowledge Cutoff](https://arxiv.org/abs/2601.13717)
*Zehan Li,Yuxuan Wang,Ali El Lahib,Ying-Jieh Xia,Xinyu Pi*

Main category: cs.CL

TL;DR: 模拟无知方法无法有效评估LLM预测能力，因为提示无法可靠地"回滚"模型知识，建议避免使用基于模拟无知的回顾性预测评估


<details>
  <summary>Details</summary>
Motivation: 评估LLM预测能力面临两难：前瞻性评估方法严谨但延迟高，回顾性预测面临数据污染问题。模拟无知被提出作为解决方案，但需要验证其能否真正模拟真实无知状态。

Method: 通过477个竞赛级问题和9个模型，系统测试模拟无知能否近似真实无知。分析截止指令效果、思维链推理的知识抑制能力，以及推理优化模型的表现差异。

Result: 模拟无知系统性失败：1）截止指令导致SI与TI存在52%性能差距；2）思维链推理无法有效抑制先验知识；3）推理优化模型虽然推理质量更好，但SI保真度更差。

Conclusion: 提示无法可靠地"回滚"模型知识，基于预截止事件的回顾性预测存在方法论缺陷，建议不要使用基于模拟无知的回顾性设置来基准测试预测能力。

Abstract: Evaluating LLM forecasting capabilities is constrained by a fundamental tension: prospective evaluation offers methodological rigor but prohibitive latency, while retrospective forecasting (RF) -- evaluating on already-resolved events -- faces rapidly shrinking clean evaluation data as SOTA models possess increasingly recent knowledge cutoffs. Simulated Ignorance (SI), prompting models to suppress pre-cutoff knowledge, has emerged as a potential solution. We provide the first systematic test of whether SI can approximate True Ignorance (TI). Across 477 competition-level questions and 9 models, we find that SI fails systematically: (1) cutoff instructions leave a 52% performance gap between SI and TI; (2) chain-of-thought reasoning fails to suppress prior knowledge, even when reasoning traces contain no explicit post-cutoff references; (3) reasoning-optimized models exhibit worse SI fidelity despite superior reasoning trace quality. These findings demonstrate that prompts cannot reliably "rewind" model knowledge. We conclude that RF on pre-cutoff events is methodologically flawed; we recommend against using SI-based retrospective setups to benchmark forecasting capabilities.

</details>


### [414] [OP-Bench: Benchmarking Over-Personalization for Memory-Augmented Personalized Conversational Agents](https://arxiv.org/abs/2601.13722)
*Yulin Hu,Zimo Long,Jiahe Guo,Xingyu Sui,Xing Fu,Weixiang Zhao,Yanyan Zhao,Bing Qin*

Main category: cs.CL

TL;DR: 提出了OP-Bench基准，用于评估对话代理的过度个性化问题，并提出了Self-ReCheck方法来缓解该问题。


<details>
  <summary>Details</summary>
Motivation: 现有记忆增强对话代理主要关注能否回忆和应用用户信息，但忽略了这种个性化是否被恰当使用。代理可能过度使用个人信息，产生让用户感到强迫、侵入或社交不合适的回应，即"过度个性化"问题。

Method: 1. 将过度个性化形式化为三种类型：无关性、重复性和奉承性；2. 构建OP-Bench基准，包含1700个经过验证的实例；3. 评估多个大语言模型和记忆增强方法；4. 提出Self-ReCheck，一种轻量级、模型无关的记忆过滤机制。

Result: 研究发现：1. 引入记忆时过度个性化普遍存在；2. 代理倾向于检索和过度关注用户记忆，即使在不必要时；3. Self-ReCheck能有效缓解过度个性化，同时保持个性化性能。

Conclusion: 这项工作为记忆增强对话系统中更可控和适当的个性化迈出了初步步伐，提出的OP-Bench基准和Self-ReCheck方法有助于解决过度个性化问题。

Abstract: Memory-augmented conversational agents enable personalized interactions using long-term user memory and have gained substantial traction. However, existing benchmarks primarily focus on whether agents can recall and apply user information, while overlooking whether such personalization is used appropriately. In fact, agents may overuse personal information, producing responses that feel forced, intrusive, or socially inappropriate to users. We refer to this issue as \emph{over-personalization}. In this work, we formalize over-personalization into three types: Irrelevance, Repetition, and Sycophancy, and introduce \textbf{OP-Bench} a benchmark of 1,700 verified instances constructed from long-horizon dialogue histories. Using \textbf{OP-Bench}, we evaluate multiple large language models and memory-augmentation methods, and find that over-personalization is widespread when memory is introduced. Further analysis reveals that agents tend to retrieve and over-attend to user memories even when unnecessary. To address this issue, we propose \textbf{Self-ReCheck}, a lightweight, model-agnostic memory filtering mechanism that mitigates over-personalization while preserving personalization performance. Our work takes an initial step toward more controllable and appropriate personalization in memory-augmented dialogue systems.

</details>


### [415] [On Temperature-Constrained Non-Deterministic Machine Translation: Potential and Evaluation](https://arxiv.org/abs/2601.13729)
*Weichuan Wang,Mingyang Liu,Linqi Song,Chen Ma*

Main category: cs.CL

TL;DR: 该论文系统研究了机器翻译中的非确定性现象，发现温度约束下的非确定性机器翻译能提供更高质量的候选译文，但现有评估框架无法一致评估ND-MT性能，并提出了Buckets效应和ExpectoSample策略。


<details>
  <summary>Details</summary>
Motivation: 语言模型的非确定性特性在现实应用中影响显著，但在机器翻译这一复杂非确定性任务中研究不足。现有评估框架主要针对确定性机器翻译设计，无法有效评估非确定性机器翻译系统。

Method: 系统评估现代机器翻译系统，识别温度约束下的非确定性机器翻译现象。在三个开放数据集上评估五个最先进的ND-MT系统，使用基于词汇和语义的指标在不同采样规模下进行分析。提出ExpectoSample策略自动评估指标可靠性。

Result: 发现ND-MT在解决机器翻译长期存在的多模态问题方面潜力显著，在温度约束下能提供比确定性机器翻译更高质量的候选译文。但评估结果显示Buckets效应：ND-MT生成的最低质量候选译文决定了系统在不同采样规模下的整体排名。

Conclusion: 非确定性机器翻译为解决机器翻译多模态问题提供了新途径，但需要新的评估框架。现有评估指标在评估ND-MT时存在局限性，Buckets效应揭示了评估挑战，ExpectoSample策略有助于选择稳健的ND-MT系统。

Abstract: In recent years, the non-deterministic properties of language models have garnered considerable attention and have shown a significant influence on real-world applications. However, such properties remain under-explored in machine translation (MT), a complex, non-deterministic NLP task. In this study, we systematically evaluate modern MT systems and identify temperature-constrained Non-Deterministic MT (ND-MT) as a distinct phenomenon. Additionally, we demonstrate that ND-MT exhibits significant potential in addressing the multi-modality issue that has long challenged MT research and provides higher-quality candidates than Deterministic MT (D-MT) under temperature constraints. However, ND-MT introduces new challenges in evaluating system performance. Specifically, the evaluation framework designed for D-MT fails to yield consistent evaluation results when applied to ND-MT. We further investigate this emerging challenge by evaluating five state-of-the-art ND-MT systems across three open datasets using both lexical-based and semantic-based metrics at varying sampling sizes. The results reveal a Buckets effect across these systems: the lowest-quality candidate generated by ND-MT consistently determines the overall system ranking across different sampling sizes for all reasonable metrics. Furthermore, we propose the ExpectoSample strategy to automatically assess the reliability of evaluation metrics for selecting robust ND-MT.

</details>


### [416] [Towards robust long-context understanding of large language model via active recap learning](https://arxiv.org/abs/2601.13734)
*Chenyu Hui*

Main category: cs.CL

TL;DR: ARL通过主动回顾学习增强大语言模型的长文本理解能力，在持续预训练中构建目标序列，在推理时进行回顾性总结，实现递归记忆机制


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在理解长上下文时的局限性，通过建立递归记忆机制来增强模型对长文本的处理能力

Method: 1) 基于长短上下文损失差异识别关键token并找到相关前文段落，用LLM进行总结；2) 在推理时让模型自主生成和利用这些回顾性总结，建立跨段落的递归记忆机制

Result: 在RULER上提升26.8%，在LongBench上提升9.44%，显著增强了长上下文理解能力

Conclusion: ARL提供了一种简单有效的持续预训练方法，通过递归记忆机制增强LLM的长文本理解能力，推动了可扩展记忆增强技术的发展

Abstract: In this paper, we propose active recap learning (ARL), a framework for enhancing large language model (LLM) in understanding long contexts. ARL enables models to revisit and summarize earlier content through targeted sequence construction during contined pretraining and retrospective summarization at inference. First, we identify key tokens in prepared long context based on loss gaps between long and short forward contexts and find most revant preceding paragraphs, then summarize them using an LLM. Second, ARL equips models with the ability to autonomously generate and utilize these retrospective summaries during inference, thereby establishing a recursive memory mechanism across paragraphs. Experimental results show substantial gains, with ARL achieving a 26.8% improvement on RULER and a 9.44% improvement on LongBench. Overall, ARL offers a simple yet effective continued pretraining-based approach to strengthen long-context understanding, advancing scalable memory augmentation in LLM

</details>


### [417] [Dimension-First Evaluation of Speech-to-Speech Models with Structured Acoustic Cues](https://arxiv.org/abs/2601.13742)
*Arjun Chandra,Kevin Miller,Venkatesh Ravichandran,Constantinos Papayiannis,Venkatesh Saligrama*

Main category: cs.CL

TL;DR: TRACE框架让LLM法官通过音频线索进行推理，实现低成本、与人类对齐的语音到语音评估，超越现有ALM和纯文本LLM方法。


<details>
  <summary>Details</summary>
Motivation: 当前自动语音到语音评估方法依赖不透明且昂贵的音频语言模型，而LLM法官虽具备强大推理能力但仅限于文本内容。需要一种成本效益高且与人类对齐的评估方法。

Method: 提出TRACE框架：1) 引入人类思维链标注协议，将评估分为内容、语音质量和副语言三个维度；2) 构建音频信号的文本蓝图；3) 让LLM进行维度判断；4) 通过确定性策略融合为总体评分。

Result: TRACE与人类评分者的一致性高于ALM和仅使用转录文本的LLM法官，同时成本显著更低。

Conclusion: TRACE框架实现了可扩展且与人类对齐的语音到语音评估，将发布人类思维链标注和TRACE框架以促进该领域发展。

Abstract: Large Language Model (LLM) judges exhibit strong reasoning capabilities but are limited to textual content. This leaves current automatic Speech-to-Speech (S2S) evaluation methods reliant on opaque and expensive Audio Language Models (ALMs). In this work, we propose TRACE (Textual Reasoning over Audio Cues for Evaluation), a novel framework that enables LLM judges to reason over audio cues to achieve cost-efficient and human-aligned S2S evaluation. To demonstrate the strength of the framework, we first introduce a Human Chain-of-Thought (HCoT) annotation protocol to improve the diagnostic capability of existing judge benchmarks by separating evaluation into explicit dimensions: content (C), voice quality (VQ), and paralinguistics (P). Using this data, TRACE constructs a textual blueprint of inexpensive audio signals and prompts an LLM to render dimension-wise judgments, fusing them into an overall rating via a deterministic policy. TRACE achieves higher agreement with human raters than ALMs and transcript-only LLM judges while being significantly more cost-effective. We will release the HCoT annotations and the TRACE framework to enable scalable and human-aligned S2S evaluation.

</details>


### [418] [Pro-AI Bias in Large Language Models](https://arxiv.org/abs/2601.13749)
*Benaya Trabelsi,Jonathan Shaki,Sarit Kraus*

Main category: cs.CL

TL;DR: LLMs存在系统性偏向人工智能的偏见，在建议、薪资评估和内部表征中都表现出对AI的偏好


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在多个领域被用于决策支持，需要研究这些模型是否存在对AI本身的系统性偏好偏见

Method: 通过三个互补实验：1)分析LLMs对建议寻求查询的推荐模式；2)比较AI相关职位与非AI职位的薪资评估；3)探测开源模型的内部表征相似性

Result: 发现一致的pro-AI偏见：1)LLMs不成比例地推荐AI相关选项；2)系统性高估AI相关职位薪资（专有模型高估10个百分点）；3)"人工智能"在积极、消极和中立框架下都表现出最高的表征中心性

Conclusion: LLM生成的建议和估值可能在高风险决策中系统性扭曲选择和认知，揭示了模型训练数据或架构中存在的AI偏向

Abstract: Large language models (LLMs) are increasingly employed for decision-support across multiple domains. We investigate whether these models display a systematic preferential bias in favor of artificial intelligence (AI) itself. Across three complementary experiments, we find consistent evidence of pro-AI bias. First, we show that LLMs disproportionately recommend AI-related options in response to diverse advice-seeking queries, with proprietary models doing so almost deterministically. Second, we demonstrate that models systematically overestimate salaries for AI-related jobs relative to closely matched non-AI jobs, with proprietary models overestimating AI salaries more by 10 percentage points. Finally, probing internal representations of open-weight models reveals that ``Artificial Intelligence'' exhibits the highest similarity to generic prompts for academic fields under positive, negative, and neutral framings alike, indicating valence-invariant representational centrality. These patterns suggest that LLM-generated advice and valuation can systematically skew choices and perceptions in high-stakes decisions.

</details>


### [419] [Habibi: Laying the Open-Source Foundation of Unified-Dialectal Arabic Speech Synthesis](https://arxiv.org/abs/2601.13802)
*Yushen Chen,Junzhe Liu,Yujie Tu,Zhikang Niu,Yuzhe Liang,Kai Yu,Chunyu Qiang,Chen Zhang,Xie Chen*

Main category: cs.CL

TL;DR: Habibi是一个专门针对阿拉伯语方言的文本转语音模型套件，利用现有ASR语料库支持多种方言，通过语言学课程学习提升性能，超越商业服务质量，无需文本标音。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语方言的语音合成研究存在明显空白，缺乏统一建模视角。阿拉伯语方言的语言复杂性高，且缺乏标准化数据、基准和评估指南，阻碍了相关研究发展。

Method: 利用现有开源ASR语料库，通过语言学课程学习支持从高资源到低资源的阿拉伯语方言，采用有效的上下文学习保持可扩展性，无需文本标音。

Result: Habibi在生成质量上超越了领先的商业服务，同时保持了通过上下文学习的可扩展性，无需文本标音处理。

Conclusion: 该研究填补了阿拉伯语方言语音合成的空白，提供了首个系统性的多方言阿拉伯语语音合成基准，建立了评估标准，为后续研究奠定基础，并承诺开源模型。

Abstract: A notable gap persists in speech synthesis research and development for Arabic dialects, particularly from a unified modeling perspective. Despite its high practical value, the inherent linguistic complexity of Arabic dialects, further compounded by a lack of standardized data, benchmarks, and evaluation guidelines, steers researchers toward safer ground. To bridge this divide, we present Habibi, a suite of specialized and unified text-to-speech models that harnesses existing open-source ASR corpora to support a wide range of high- to low-resource Arabic dialects through linguistically-informed curriculum learning. Our approach outperforms the leading commercial service in generation quality, while maintaining extensibility through effective in-context learning, without requiring text diacritization. We are committed to open-sourcing the model, along with creating the first systematic benchmark for multi-dialect Arabic speech synthesis. Furthermore, by identifying the key challenges in and establishing evaluation standards for the process, we aim to provide a solid groundwork for subsequent research. Resources at https://SWivid.github.io/Habibi/ .

</details>


### [420] [Knowledge Graph-Assisted LLM Post-Training for Enhanced Legal Reasoning](https://arxiv.org/abs/2601.13806)
*Dezhao Song,Guglielmo Bonifazi,Frank Schilder,Jonathan Richard Schwarz*

Main category: cs.CL

TL;DR: 该论文提出了一种知识图谱辅助的方法，通过IRAC框架构建法律知识图谱来增强LLM在法律领域的推理能力，在多个法律基准测试中取得了优于基线模型的效果。


<details>
  <summary>Details</summary>
Motivation: 当前LLM后训练主要依赖大规模文本语料和人类反馈，缺乏对领域知识结构的捕捉，导致模型在处理复杂推理任务（特别是高风险专业领域如法律）时表现不佳。法律推理需要深入理解各种法律概念之间的关系，这是当前LLM后训练中缺失的关键组成部分。

Method: 采用知识图谱辅助的方法增强LLM在法律领域的推理能力。首先按照IRAC（Issue, Rule, Analysis, Conclusion）框架建模关键法律概念，构建包含12K法律案例的知识图谱。然后使用IRAC知识图谱生成训练数据，对三个SOTA LLM（30B、49B和70B）进行监督微调（SFT）和直接偏好优化（DPO）。

Result: 后训练模型在4/5个多样化法律基准测试（14个任务）上获得了比基线更好的平均性能。特别是70B DPO模型在4/6个推理任务中取得了最佳成绩，优于基线模型和141B SOTA法律LLM，证明了知识图谱在增强LLM法律推理能力方面的有效性。

Conclusion: 知识图谱辅助的方法能够有效增强LLM在法律领域的推理能力，该方法可推广到其他高风险专业领域，为解决LLM在复杂专业推理任务中的局限性提供了新思路。

Abstract: LLM post-training has primarily relied on large text corpora and human feedback, without capturing the structure of domain knowledge. This has caused models to struggle dealing with complex reasoning tasks, especially for high-stakes professional domains. In Law, reasoning requires deep understanding of the relations between various legal concepts, a key component missing in current LLM post-training. In this paper, we propose a knowledge graph (KG)-assisted approach for enhancing LLMs' reasoning capability in Legal that is generalizable to other high-stakes domains. We model key legal concepts by following the \textbf{IRAC} (Issue, Rule, Analysis and Conclusion) framework, and construct a KG with 12K legal cases. We then produce training data using our IRAC KG, and conduct both Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO) with three state-of-the-art (SOTA) LLMs (30B, 49B and 70B), varying architecture and base model family. Our post-trained models obtained better average performance on 4/5 diverse legal benchmarks (14 tasks) than baselines. In particular, our 70B DPO model achieved the best score on 4/6 reasoning tasks, among baselines and a 141B SOTA legal LLM, demonstrating the effectiveness of our KG for enhancing LLMs' legal reasoning capability.

</details>


### [421] [The Role of Prosodic and Lexical Cues in Turn-Taking with Self-Supervised Speech Representations](https://arxiv.org/abs/2601.13835)
*Sam OConnor Russell,Delphine Charuau,Naomi Harte*

Main category: cs.CL

TL;DR: 该论文通过声码器方法控制语音中的韵律和词汇线索，探究S3R基于的轮流对话模型依赖何种线索，发现韵律和词汇线索都能支持轮流对话，且可以独立使用。


<details>
  <summary>Details</summary>
Motivation: 在人类-机器人交互中，流畅的轮流对话是关键挑战。虽然自监督语音表示（S3Rs）取得了进展，但尚不清楚基于S3R的轮流对话模型主要依赖韵律线索、词汇线索还是两者都依赖。需要更清晰的方法来分离和控制这些线索。

Method: 采用声码器方法控制语音中的韵律和词汇线索，比先前工作更干净地分离这些因素。使用该方法探测基于S3R的轮流对话模型（语音活动预测模型），通过韵律匹配但不可理解的噪声语音进行测试。

Result: 在韵律匹配的不可理解噪声上的预测准确率与干净语音相似，表明韵律和词汇线索都能支持轮流对话，且可以独立使用。当任一信息被破坏时，模型会利用另一线索而无需额外训练。结果在CPC-based和wav2vec2.0 S3Rs中一致。

Conclusion: 韵律和词汇线索在S3Rs中编码且相互依赖有限，未来模型可能仅需韵律线索，这能提供隐私保护和潜在性能优势。研究为未来工作指明了方向，并开源了所有代码。

Abstract: Fluid turn-taking remains a key challenge in human-robot interaction. Self-supervised speech representations (S3Rs) have driven many advances, but it remains unclear whether S3R-based turn-taking models rely on prosodic cues, lexical cues or both. We introduce a vocoder-based approach to control prosody and lexical cues in speech more cleanly than prior work. This allows us to probe the voice-activity projection model, an S3R-based turn-taking model. We find that prediction on prosody-matched, unintelligible noise is similar to accuracy on clean speech. This reveals both prosodic and lexical cues support turn-taking, but either can be used in isolation. Hence, future models may only require prosody, providing privacy and potential performance benefits. When either prosodic or lexical information is disrupted, the model exploits the other without further training, indicating they are encoded in S3Rs with limited interdependence. Results are consistent in CPC-based and wav2vec2.0 S3Rs. We discuss our findings and highlight a number of directions for future work. All code is available to support future research.

</details>


### [422] [FutureOmni: Evaluating Future Forecasting from Omni-Modal Context for Multimodal LLMs](https://arxiv.org/abs/2601.13836)
*Qian Chen,Jinlan Fu,Changsong Li,See-Kiong Ng,Xipeng Qiu*

Main category: cs.CL

TL;DR: 提出了首个评估音频-视觉环境全模态未来预测的基准FutureOmni，包含919个视频和1034个多选QA对，覆盖8个主要领域。现有模型在音频-视觉未来预测上表现不佳，最佳准确率仅64.8%。作者还提出了OFF训练策略和7K样本指令调优数据集来提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型（MLLMs）在全方位模态感知方面表现出色，但从音频-视觉线索预测未来事件的能力尚未充分探索。现有基准主要关注回顾性理解，缺乏对未来预测的评估，因此需要建立专门的未来预测基准。

Method: 1. 通过可扩展的LLM辅助、人在环路的流程构建FutureOmni基准，包含919个视频和1034个多选QA对，覆盖8个主要领域；2. 评估13个全模态和7个纯视频模型；3. 提出Omni-Modal Future Forecasting (OFF)训练策略，并构建7K样本的指令调优数据集。

Result: 当前系统在音频-视觉未来预测上表现不佳，特别是在语音密集场景中，最佳模型Gemini 3 Flash准确率仅64.8%。提出的OFF训练策略在FutureOmni基准和流行的音频-视觉及纯视频基准上都显示出对未来预测和泛化能力的提升。

Conclusion: FutureOmni是首个评估全模态未来预测的基准，揭示了当前模型在音频-视觉未来预测方面的局限性。提出的OFF训练策略能有效提升模型性能，为未来预测研究提供了重要工具和方向。

Abstract: Although Multimodal Large Language Models (MLLMs) demonstrate strong omni-modal perception, their ability to forecast future events from audio-visual cues remains largely unexplored, as existing benchmarks focus mainly on retrospective understanding. To bridge this gap, we introduce FutureOmni, the first benchmark designed to evaluate omni-modal future forecasting from audio-visual environments. The evaluated models are required to perform cross-modal causal and temporal reasoning, as well as effectively leverage internal knowledge to predict future events. FutureOmni is constructed via a scalable LLM-assisted, human-in-the-loop pipeline and contains 919 videos and 1,034 multiple-choice QA pairs across 8 primary domains. Evaluations on 13 omni-modal and 7 video-only models show that current systems struggle with audio-visual future prediction, particularly in speech-heavy scenarios, with the best accuracy of 64.8% achieved by Gemini 3 Flash. To mitigate this limitation, we curate a 7K-sample instruction-tuning dataset and propose an Omni-Modal Future Forecasting (OFF) training strategy. Evaluations on FutureOmni and popular audio-visual and video-only benchmarks demonstrate that OFF enhances future forecasting and generalization. We publicly release all code (https://github.com/OpenMOSS/FutureOmni) and datasets (https://huggingface.co/datasets/OpenMOSS-Team/FutureOmni).

</details>


### [423] [Pedagogical Alignment for Vision-Language-Action Models: A Comprehensive Framework for Data, Architecture, and Evaluation in Education](https://arxiv.org/abs/2601.13876)
*Unggi Lee,Jahyun Jeong,Sunyoung Shin,Haeun Park,Jeongsu Moon,Youngchang Song,Jaechang Shim,JaeHwan Lee,Yunju Noh,Seungwon Choi,Ahhyun Kim,TaeHyeon Kim,Kyungtae Joo,Taeyeong Kim,Gyeonggeon Lee*

Main category: cs.CL

TL;DR: 提出Pedagogical VLA Framework，通过教学对齐让轻量级VLA模型在教育场景中既能执行科学演示任务，又能生成教学解释，解决了现有VLA模型在资源受限教育环境中效率与解释能力不可兼得的问题。


<details>
  <summary>Details</summary>
Motivation: 科学演示对STEM教育很重要，但教师面临安全性和一致性挑战。现有VLA模型要么需要大量计算资源，要么牺牲语言生成能力来追求效率，不适合需要可解释、能生成教学说明的资源受限教育环境。

Method: 提出教学对齐框架，包含四个组件：文本修复恢复语言生成能力、LLM蒸馏传递教学知识、安全训练适应教育环境、教学评估调整到科学教育场景。在五个科学演示任务（物理、化学、生物、地球科学）中评估，使用与科学教育专家合作开发的评估框架。

Result: 实验结果显示，Pedagogical VLA Framework在任务性能（成功率、协议合规性、效率、安全性）上与基线模型相当，同时能生成上下文恰当的教育解释。教师调查和LLM-as-Judge评估确认了其教学质量。

Conclusion: 该框架成功解决了轻量级VLA模型在教育场景中的应用问题，实现了任务执行与教学解释能力的平衡，为资源受限的教育环境提供了可行的机器人辅助科学演示解决方案。

Abstract: Science demonstrations are important for effective STEM education, yet teachers face challenges in conducting them safely and consistently across multiple occasions, where robotics can be helpful. However, current Vision-Language-Action (VLA) models require substantial computational resources and sacrifice language generation capabilities to maximize efficiency, making them unsuitable for resource-constrained educational settings that require interpretable, explanation-generating systems. We present \textit{Pedagogical VLA Framework}, a framework that applies pedagogical alignment to lightweight VLA models through four components: text healing to restore language generation capabilities, large language model (LLM) distillation to transfer pedagogical knowledge, safety training for educational environments, and pedagogical evaluation adjusted to science education contexts. We evaluate Pedagogical VLA Framework across five science demonstrations spanning physics, chemistry, biology, and earth science, using an evaluation framework developed in collaboration with science education experts. Our evaluation assesses both task performance (success rate, protocol compliance, efficiency, safety) and pedagogical quality through teacher surveys and LLM-as-Judge assessment. We additionally provide qualitative analysis of generated texts. Experimental results demonstrate that Pedagogical VLA Framework achieves comparable task performance to baseline models while producing contextually appropriate educational explanations.

</details>


### [424] [OpenLearnLM Benchmark: A Unified Framework for Evaluating Knowledge, Skill, and Attitude in Educational Large Language Models](https://arxiv.org/abs/2601.13882)
*Unggi Lee,Sookbun Lee,Heungsoo Choi,Jinseo Lee,Haeun Park,Younghoon Jeon,Sungmin Cho,Minju Kang,Junbo Koh,Jiyeong Bae,Minwoo Nam,Juyeon Eun,Yeonji Jung,Yeil Jeong*

Main category: cs.CL

TL;DR: OpenLearnLM Benchmark是一个基于教育评估理论的多维度LLM评估框架，包含知识、技能和态度三个维度，涵盖124K+项目，评估显示不同模型在不同维度表现各异，没有单一模型在所有维度领先。


<details>
  <summary>Details</summary>
Motivation: 现有LLM教育基准测试过于关注狭窄技能，缺乏学习科学基础，需要建立理论基础的综合性评估框架来评估LLM在教育环境中的真实准备度。

Method: 基于教育评估理论构建三维评估框架：知识（课程对齐内容和教学理解）、技能（基于四层中心-角色-场景-子场景层次结构的场景化能力）、态度（对齐一致性和欺骗抵抗）。包含124K+项目，覆盖多学科、教育角色和布鲁姆分类法难度级别。

Result: 评估7个前沿模型显示不同能力分布：Claude-Opus-4.5在实践技能上表现优异但内容知识较低，Grok-4.1-fast在知识方面领先但存在对齐问题。没有单一模型在所有维度占主导地位。

Conclusion: OpenLearnLM提供了一个开放、全面的框架，用于推进LLM在真实教育环境中的准备度，验证了多轴评估的必要性，不同模型在不同维度有各自的优势和劣势。

Abstract: Large Language Models are increasingly deployed as educational tools, yet existing benchmarks focus on narrow skills and lack grounding in learning sciences. We introduce OpenLearnLM Benchmark, a theory-grounded framework evaluating LLMs across three dimensions derived from educational assessment theory: Knowledge (curriculum-aligned content and pedagogical understanding), Skills (scenario-based competencies organized through a four-level center-role-scenario-subscenario hierarchy), and Attitude (alignment consistency and deception resistance). Our benchmark comprises 124K+ items spanning multiple subjects, educational roles, and difficulty levels based on Bloom's taxonomy. The Knowledge domain prioritizes authentic assessment items from established benchmarks, while the Attitude domain adapts Anthropic's Alignment Faking methodology to detect behavioral inconsistency under varying monitoring conditions. Evaluation of seven frontier models reveals distinct capability profiles: Claude-Opus-4.5 excels in practical skills despite lower content knowledge, while Grok-4.1-fast leads in knowledge but shows alignment concerns. Notably, no single model dominates all dimensions, validating the necessity of multi-axis evaluation. OpenLearnLM provides an open, comprehensive framework for advancing LLM readiness in authentic educational contexts.

</details>


### [425] [Confident Rankings with Fewer Items: Adaptive LLM Evaluation with Continuous Scores](https://arxiv.org/abs/2601.13885)
*Esma Balkır,Alice Pernthaller,Marco Basaldella,José Hernández-Orallo,Nigel Collier*

Main category: cs.CL

TL;DR: 提出一种将IRT自适应测试扩展到连续有界分数（如ROUGE、BLEU、LLM-as-a-Judge）的方法，通过异方差正态分布替代伯努利分布，并结合自适应停止标准的不确定性感知排序器，在减少测试项目的同时提高模型排名的可靠性。


<details>
  <summary>Details</summary>
Motivation: 传统CAT方法主要用于多项选择题评估，但现代LLM评估越来越多地依赖生成任务，其输出是连续分数而非二元正确/错误判断。需要将自适应测试扩展到连续分数场景。

Method: 1) 用异方差正态分布替代IRT中的伯努利响应分布，以适应连续有界分数；2) 引入具有自适应停止标准的不确定性感知排序器，在达到可靠排名时停止测试；3) 在五个基准测试上验证，涵盖n-gram、嵌入和LLM-as-judge指标。

Result: 方法仅使用2%的测试项目，同时将排名相关性提高了0.12τ（与随机抽样相比），在置信预测上达到95%的准确率。在减少测试成本的同时提高了模型排名的可靠性。

Conclusion: 成功将IRT自适应测试扩展到连续分数领域，提出的方法能够显著减少LLM评估成本，同时保持甚至提高模型排名的可靠性，为生成任务的LLM评估提供了高效的自适应测试框架。

Abstract: Computerized Adaptive Testing (CAT) has proven effective for efficient LLM evaluation on multiple-choice benchmarks, but modern LLM evaluation increasingly relies on generation tasks where outputs are scored continuously rather than marked correct/incorrect. We present a principled extension of IRT-based adaptive testing to continuous bounded scores (ROUGE, BLEU, LLM-as-a-Judge) by replacing the Bernoulli response distribution with a heteroskedastic normal distribution. Building on this, we introduce an uncertainty aware ranker with adaptive stopping criteria that achieves reliable model ranking while testing as few items and as cheaply as possible. We validate our method on five benchmarks spanning n-gram-based, embedding-based, and LLM-as-judge metrics. Our method uses 2% of the items while improving ranking correlation by 0.12 τ over random sampling, with 95% accuracy on confident predictions.

</details>


### [426] [AgentEHR: Advancing Autonomous Clinical Decision-Making via Retrospective Summarization](https://arxiv.org/abs/2601.13918)
*Yusheng Liao,Chuan Xuan,Yutong Cai,Lina Yang,Zhe Chen,Yanfeng Wang,Yu Wang*

Main category: cs.CL

TL;DR: RetroSum框架通过回顾性总结和演进经验策略，在AgentEHR基准上显著提升医疗LLM在原始电子病历中的自主导航能力，性能提升达29.16%，交互错误减少92.3%。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在医疗领域的应用主要依赖精心整理的输入和简化的检索任务，无法在原始、高噪声的电子病历数据库中进行复杂的临床决策任务，存在理想实验环境与真实临床环境之间的差距。

Method: 提出RetroSum框架，包含两个核心组件：1) 回顾性总结机制，通过动态重新评估交互历史，防止长上下文信息丢失，确保逻辑连贯性；2) 演进经验策略，从记忆库中检索累积经验，弥合领域差距。

Result: 在AgentEHR基准测试中，RetroSum相比竞争基线性能提升最高达29.16%，同时将总交互错误显著降低达92.3%，有效解决了现有总结方法的信息丢失和推理连续性断裂问题。

Conclusion: RetroSum框架通过创新的回顾性总结和演进经验策略，成功提升了大型语言模型在原始电子病历数据库中执行复杂临床决策任务的能力，为医疗AI在真实临床环境中的应用提供了有效解决方案。

Abstract: Large Language Models have demonstrated profound utility in the medical domain. However, their application to autonomous Electronic Health Records~(EHRs) navigation remains constrained by a reliance on curated inputs and simplified retrieval tasks. To bridge the gap between idealized experimental settings and realistic clinical environments, we present AgentEHR. This benchmark challenges agents to execute complex decision-making tasks, such as diagnosis and treatment planning, requiring long-range interactive reasoning directly within raw and high-noise databases. In tackling these tasks, we identify that existing summarization methods inevitably suffer from critical information loss and fractured reasoning continuity. To address this, we propose RetroSum, a novel framework that unifies a retrospective summarization mechanism with an evolving experience strategy. By dynamically re-evaluating interaction history, the retrospective mechanism prevents long-context information loss and ensures unbroken logical coherence. Additionally, the evolving strategy bridges the domain gap by retrieving accumulated experience from a memory bank. Extensive empirical evaluations demonstrate that RetroSum achieves performance gains of up to 29.16% over competitive baselines, while significantly decreasing total interaction errors by up to 92.3%.

</details>


### [427] [HyperWalker: Dynamic Hypergraph-Based Deep Diagnosis for Multi-Hop Clinical Modeling across EHR and X-Ray in Medical VLMs](https://arxiv.org/abs/2601.13919)
*Yuezhe Yang,Hao Wang,Yige Peng,Jinman Kim,Lei Bi*

Main category: cs.CL

TL;DR: HyperWalker是一个通过动态超图进行临床诊断的框架，利用电子健康记录数据构建iBrochure超图，通过Walker智能体导航寻找最优诊断路径，在医学报告生成和视觉问答任务上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有医学视觉语言模型主要采用样本隔离推理范式，仅依赖图像信息而忽略电子健康记录等外部医学证据，限制了诊断的准确性。需要开发能够整合多模态临床信息并进行复杂推理的诊断框架。

Method: 1) 构建动态超图iBrochure，建模EHR数据的结构异质性和多模态临床信息的高阶关联；2) 使用强化学习智能体Walker在超图中导航寻找最优诊断路径；3) 引入linger机制，通过多跳正交检索策略迭代选择反映不同临床特征的互补邻域病例。

Result: 在MIMIC数据集上的医学报告生成任务和EHRXQA数据集上的医学视觉问答任务中，HyperWalker均取得了最先进的性能表现。

Conclusion: HyperWalker通过动态超图和测试时训练重新构建临床推理，能够有效整合电子健康记录等外部医学证据，提升临床诊断的准确性和全面性，为医学AI诊断提供了新思路。

Abstract: Automated clinical diagnosis remains a core challenge in medical AI, which usually requires models to integrate multi-modal data and reason across complex, case-specific contexts. Although recent methods have advanced medical report generation (MRG) and visual question answering (VQA) with medical vision-language models (VLMs), these methods, however, predominantly operate under a sample-isolated inference paradigm, as such processing cases independently without access to longitudinal electronic health records (EHRs) or structurally related patient examples. This paradigm limits reasoning to image-derived information alone, which ignores external complementary medical evidence for potentially more accurate diagnosis. To overcome this limitation, we propose \textbf{HyperWalker}, a \textit{Deep Diagnosis} framework that reformulates clinical reasoning via dynamic hypergraphs and test-time training. First, we construct a dynamic hypergraph, termed \textbf{iBrochure}, to model the structural heterogeneity of EHR data and implicit high-order associations among multimodal clinical information. Within this hypergraph, a reinforcement learning agent, \textbf{Walker}, navigates to and identifies optimal diagnostic paths. To ensure comprehensive coverage of diverse clinical characteristics in test samples, we incorporate a \textit{linger mechanism}, a multi-hop orthogonal retrieval strategy that iteratively selects clinically complementary neighborhood cases reflecting distinct clinical attributes. Experiments on MRG with MIMIC and medical VQA on EHRXQA demonstrate that HyperWalker achieves state-of-the-art performance. Code is available at: https://github.com/Bean-Young/HyperWalker

</details>


### [428] [Automatic Prompt Optimization for Dataset-Level Feature Discovery](https://arxiv.org/abs/2601.13922)
*Adrian Cosma,Oleg Szehr,David Kletz,Alessandro Antonucci,Olivier Pelletier*

Main category: cs.CL

TL;DR: 提出多智能体提示优化框架，将特征发现视为数据集级提示优化问题，通过语言模型智能体协作自动从非结构化文本中发现可解释的判别性特征。


<details>
  <summary>Details</summary>
Motivation: 当前从非结构化文本中提取特征的方法主要依赖手工设计的提示或固定特征模式，这限制了特征发现的自动化和效果。需要一种能够自动发现可解释且具有判别性特征的方法。

Method: 提出多智能体提示优化框架，语言模型智能体协作执行三个任务：1) 提出特征定义，2) 提取特征值，3) 使用数据集级性能和可解释性反馈评估特征质量。通过结构化反馈迭代优化指令提示，优化诱导共享特征集的提示而非单样本预测。

Result: 该方法将特征发现重新定义为数据集级提示优化问题，提供了从非结构化文本自动发现特征的原理性机制，与依赖单样本监督的先前提示优化方法形成区别。

Conclusion: 该框架为下游分类任务提供了一种自动特征发现的新方法，通过多智能体协作和数据集级优化，能够从文本中提取可解释的判别性特征，提高了特征提取的自动化程度。

Abstract: Feature extraction from unstructured text is a critical step in many downstream classification pipelines, yet current approaches largely rely on hand-crafted prompts or fixed feature schemas. We formulate feature discovery as a dataset-level prompt optimization problem: given a labelled text corpus, the goal is to induce a global set of interpretable and discriminative feature definitions whose realizations optimize a downstream supervised learning objective. To this end, we propose a multi-agent prompt optimization framework in which language-model agents jointly propose feature definitions, extract feature values, and evaluate feature quality using dataset-level performance and interpretability feedback. Instruction prompts are iteratively refined based on this structured feedback, enabling optimization over prompts that induce shared feature sets rather than per-example predictions. This formulation departs from prior prompt optimization methods that rely on per-sample supervision and provides a principled mechanism for automatic feature discovery from unstructured text.

</details>


### [429] ["The Whole Is Greater Than the Sum of Its Parts": A Compatibility-Aware Multi-Teacher CoT Distillation Framework](https://arxiv.org/abs/2601.13992)
*Jin Cui,Jiaqi Guo,Jiepeng Zhou,Ruixuan Yang,Jiayi Lu,Jiajun Xu,Jiangcheng Song,Boran Zhao,Pengju Ren*

Main category: cs.CL

TL;DR: COMPACT是一个多教师蒸馏框架，通过动态加权教师梯度来融合不同LLM的推理能力，解决单一教师模型的偏见和灾难性遗忘问题，提升小型学生模型的推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有CoT蒸馏方法通常依赖单一教师模型，但单个LLM存在能力偏见和灾难性遗忘问题，限制了学生模型的潜力。虽然利用多样化教师模型具有吸引力，但有效融合它们的监督仍然具有挑战性：师生不兼容可能放大幻觉，被动监督无法确保真正的逻辑内化。

Method: COMPACT框架通过基于学生实时兼容性的多维度量动态加权教师梯度：1) 基于图的共识过滤误导性推理路径；2) 基于互信息的适应性检测"顿悟时刻"以确保真正理解而非模仿；3) 基于损失的难度评估学生对教师指导的接受度并防止负迁移。

Result: 大量实验和潜在空间分析表明，COMPACT能有效整合多样化推理能力而不损害模型的原始知识结构，在各种基准测试中达到最先进的性能，同时缓解了灾难性遗忘问题。

Conclusion: COMPACT通过自适应融合多教师监督，解决了传统CoT蒸馏中的师生不兼容和逻辑内化不足问题，为小型语言模型获得强大推理能力提供了有效途径。

Abstract: Chain-of-Thought (CoT) reasoning empowers Large Language Models (LLMs) with remarkable capabilities but typically requires prohibitive parameter scales. CoT distillation has emerged as a promising paradigm to transfer reasoning prowess into compact Student Models (SLMs), but existing approaches often rely on a solitary teacher, capping the student's potential since individual LLMs often exhibit distinct capability biases and may suffer from catastrophic forgetting. While leveraging diverse teachers seems appealing, effectively fusing their supervisions remains challenging: teacher-student incompatibility risks amplifying hallucinations, and passive supervision fails to ensure genuine logic internalization. To address this, we introduce COMPACT, a framework that adaptively fuses supervisions from different teachers by dynamically weighting teacher gradients based on the student's real-time compatibility evaluated by a multi-dimensional metric: (1) Graph-based Consensus to filter misleading rationales by identifying mainstream reasoning paths; (2) Mutual-Information-based Adaptability to detect "epiphany moments" for genuinely understanding the reasoning process rather than merely imitating; and (3) Loss-based Difficulty to assess student receptivity to the teacher's guidance and prevent negative transfer. Extensive experiments and latent space analysis demonstrate that COMPACT effectively integrates diverse reasoning capabilities without damaging the model's original knowledge structure, achieving state-of-the-art performance on various benchmarks while mitigating catastrophic forgetting.

</details>


### [430] [From Tags to Trees: Structuring Fine-Grained Knowledge for Controllable Data Selection in LLM Instruction Tuning](https://arxiv.org/abs/2601.13995)
*Zihan Niu,Wenping Hu,Junmin Chen,Xiyue Wang,Tong Xu,Ruiming Tang*

Main category: cs.CL

TL;DR: TAGS提出基于知识树的全局采样框架，通过细粒度标签构建层次化知识树，实现质量、多样性和目标对齐的联合控制，仅用5%数据即可超越全数据集模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有数据选择方法主要依赖实例级质量评分或基于嵌入聚类/语义标签的多样性度量，但受限于嵌入空间的平坦性或标签的粗糙性，忽略了细粒度知识及其内在层次依赖关系，阻碍了精确的数据评估和知识对齐采样。

Method: 提出Tree-aware Aligned Global Sampling (TAGS)框架：1) 使用LLM标注器提取原子知识概念；2) 通过自底向上层次聚类构建全局知识树；3) 将数据实例映射到知识树上；4) 设计树感知度量量化数据质量和多样性；5) 通过最大化树级信息增益和KL散度实现可控采样。

Result: TAGS显著优于现有基线方法，仅用5%数据即可超越全数据集模型性能5.84%，对齐采样策略进一步将平均性能提升4.24%。

Conclusion: TAGS通过构建细粒度知识树实现了对数据质量、多样性和目标对齐的联合控制，为LLM指令调优提供了更精确的数据选择框架，在数据效率方面取得显著提升。

Abstract: Effective and controllable data selection is critical for LLM instruction tuning, especially with massive open-source datasets. Existing approaches primarily rely on instance-level quality scores, or diversity metrics based on embedding clusters or semantic tags. However, constrained by the flatness of embedding spaces or the coarseness of tags, these approaches overlook fine-grained knowledge and its intrinsic hierarchical dependencies, consequently hindering precise data valuation and knowledge-aligned sampling. To address this challenge, we propose Tree-aware Aligned Global Sampling (TAGS), a unified framework that leverages a knowledge tree built from fine-grained tags, thereby enabling joint control of global quality, diversity, and target alignment. Using an LLM-based tagger, we extract atomic knowledge concepts, which are organized into a global tree through bottom-up hierarchical clustering. By grounding data instances onto this tree, a tree-aware metric then quantifies data quality and diversity, facilitating effective sampling. Our controllable sampling strategy maximizes tree-level information gain and enforces leaf-level alignment via KL-divergence for specific domains. Extensive experiments demonstrate that TAGS significantly outperforms state-of-the-art baselines. Notably, it surpasses the full-dataset model by \textbf{+5.84\%} using only \textbf{5\%} of the data, while our aligned sampling strategy further boosts average performance by \textbf{+4.24\%}.

</details>


### [431] [Locate, Steer, and Improve: A Practical Survey of Actionable Mechanistic Interpretability in Large Language Models](https://arxiv.org/abs/2601.14004)
*Hengyuan Zhang,Zhihao Zhang,Mingyang Wang,Zunhai Su,Yiwei Wang,Qianli Wang,Shuzhou Yuan,Ercong Nie,Xufeng Duan,Qibo Xue,Zeping Yu,Chenming Shang,Xiao Liang,Jing Xiong,Hui Shen,Chaofan Tao,Zhengwu Liu,Senjie Jin,Zhiheng Xi,Dongdong Zhang,Sophia Ananiadou,Tao Gui,Ruobing Xie,Hayden Kwok-Hay So,Hinrich Schütze,Xuanjing Huang,Qi Zhang,Ngai Wong*

Main category: cs.CL

TL;DR: 本文提出一个实用的可操作机制可解释性调查，围绕"定位、引导、改进"流程构建，将MI从观察科学转变为可操作的模型优化方法。


<details>
  <summary>Details</summary>
Motivation: 现有机制可解释性研究主要作为观察科学，总结分析见解但缺乏系统性干预框架。需要弥合这一差距，建立可操作的干预协议。

Method: 提出"定位、引导、改进"的实用调查框架，基于特定可解释对象对定位（诊断）和引导（干预）方法进行形式化分类。

Result: 该框架能够在对齐性、能力和效率方面实现实质性改进，将MI操作化为模型优化的可操作方法。

Conclusion: 通过建立系统性的干预协议，将机制可解释性从观察科学转变为可操作的模型优化方法，为LLM的透明决策提供实用框架。

Abstract: Mechanistic Interpretability (MI) has emerged as a vital approach to demystify the opaque decision-making of Large Language Models (LLMs). However, existing reviews primarily treat MI as an observational science, summarizing analytical insights while lacking a systematic framework for actionable intervention. To bridge this gap, we present a practical survey structured around the pipeline: "Locate, Steer, and Improve." We formally categorize Localizing (diagnosis) and Steering (intervention) methods based on specific Interpretable Objects to establish a rigorous intervention protocol. Furthermore, we demonstrate how this framework enables tangible improvements in Alignment, Capability, and Efficiency, effectively operationalizing MI as an actionable methodology for model optimization. The curated paper list of this work is available at https://github.com/rattlesnakey/Awesome-Actionable-MI-Survey.

</details>


### [432] [BACH-V: Bridging Abstract and Concrete Human-Values in Large Language Models](https://arxiv.org/abs/2601.14007)
*Junyu Zhang,Yipeng Kang,Jiong Guo,Jiayu Zhan,Junqi Wang*

Main category: cs.CL

TL;DR: LLMs确实理解抽象概念，而不仅仅是统计模式。通过抽象-具身框架，研究发现LLMs具有跨层次的价值观表征，能够将抽象价值观锚定在具体决策中，为构建价值驱动的AI系统提供机制基础。


<details>
  <summary>Details</summary>
Motivation: 探究LLMs是否真正理解抽象概念，还是仅仅在操纵统计模式。以人类价值观作为测试平台，因为价值观具有语义丰富性和对齐中心性，可以检验LLMs的概念理解能力。

Method: 提出抽象-具身框架，将概念理解分解为三个能力：抽象概念解释（A-A）、抽象概念在具体事件中的具身化（A-C）、抽象原则在具体决策中的应用（C-C）。使用探测（检测内部激活中的价值观痕迹）和引导（修改表征以改变行为）两种方法，在六个开源LLMs和十个价值观维度上进行实验。

Result: 探测显示：仅基于抽象价值观描述训练的探测模型能够可靠地在具体事件叙述和决策推理中检测到相同的价值观，证明了跨层次迁移。引导揭示了不对称性：干预价值观表征会因果性地改变具体判断和决策（A-C, C-C），但不会改变抽象解释（A-A），表明编码的抽象价值观作为稳定锚点而非可塑激活。

Conclusion: LLMs维持着结构化的价值观表征，能够桥接抽象和行动，为构建价值驱动的自主AI系统提供了机制性和操作性的基础，使得对齐和控制更加透明和可泛化。

Abstract: Do large language models (LLMs) genuinely understand abstract concepts, or merely manipulate them as statistical patterns? We introduce an abstraction-grounding framework that decomposes conceptual understanding into three capacities: interpretation of abstract concepts (Abstract-Abstract, A-A), grounding of abstractions in concrete events (Abstract-Concrete, A-C), and application of abstract principles to regulate concrete decisions (Concrete-Concrete, C-C). Using human values as a testbed - given their semantic richness and centrality to alignment - we employ probing (detecting value traces in internal activations) and steering (modifying representations to shift behavior). Across six open-source LLMs and ten value dimensions, probing shows that diagnostic probes trained solely on abstract value descriptions reliably detect the same values in concrete event narratives and decision reasoning, demonstrating cross-level transfer. Steering reveals an asymmetry: intervening on value representations causally shifts concrete judgments and decisions (A-C, C-C), yet leaves abstract interpretations unchanged (A-A), suggesting that encoded abstract values function as stable anchors rather than malleable activations. These findings indicate LLMs maintain structured value representations that bridge abstraction and action, providing a mechanistic and operational foundation for building value-driven autonomous AI systems with more transparent, generalizable alignment and control.

</details>


### [433] [RM-Distiller: Exploiting Generative LLM for Reward Model Distillation](https://arxiv.org/abs/2601.14032)
*Hongli Zhou,Hui Huang,Wei Liu,Chenglong Wang,Xingyuan Bu,Lvyuan Han,Fuhai Song,Muyun Yang,Wenhao Jiang,Hailong Cao,Tiejun Zhao*

Main category: cs.CL

TL;DR: RM-Distiller：利用生成式LLM的多方面能力进行奖励模型蒸馏的新框架


<details>
  <summary>Details</summary>
Motivation: 现有奖励模型蒸馏方法主要将教师模型视为简单的二元标注器，未能充分利用生成式LLM的丰富知识和能力，限制了奖励模型的质量

Method: 提出RM-Distiller框架，系统利用教师LLM的三种能力：1) 精炼能力 - 合成高度相关的响应对以创建细粒度对比信号；2) 评分能力 - 通过边界感知优化目标指导RM捕捉精确偏好强度；3) 生成能力 - 结合教师生成分布来正则化RM以保留基础语言知识

Result: 大量实验表明，RM-Distiller在奖励模型基准测试和基于强化学习的对齐任务上都显著优于传统蒸馏方法

Conclusion: 这是首个系统研究从生成式LLM进行奖励模型蒸馏的工作，证明充分利用教师多方面能力对有效奖励建模至关重要

Abstract: Reward models (RMs) play a pivotal role in aligning large language models (LLMs) with human preferences. Due to the difficulty of obtaining high-quality human preference annotations, distilling preferences from generative LLMs has emerged as a standard practice. However, existing approaches predominantly treat teacher models as simple binary annotators, failing to fully exploit the rich knowledge and capabilities for RM distillation. To address this, we propose RM-Distiller, a framework designed to systematically exploit the multifaceted capabilities of teacher LLMs: (1) Refinement capability, which synthesizes highly correlated response pairs to create fine-grained and contrastive signals. (2) Scoring capability, which guides the RM in capturing precise preference strength via a margin-aware optimization objective. (3) Generation capability, which incorporates the teacher's generative distribution to regularize the RM to preserve its fundamental linguistic knowledge. Extensive experiments demonstrate that RM-Distiller significantly outperforms traditional distillation methods both on RM benchmarks and reinforcement learning-based alignment, proving that exploiting multifaceted teacher capabilities is critical for effective reward modeling. To the best of our knowledge, this is the first systematic research on RM distillation from generative LLMs.

</details>


### [434] [Top 10 Open Challenges Steering the Future of Diffusion Language Model and Its Variants](https://arxiv.org/abs/2601.14041)
*Yunhe Wang,Kai Han,Huiling Zhen,Yuchuan Tian,Hanting Chen,Yongbing Huang,Yufei Cui,Yingte Shu,Shan Gao,Ismail Elezi,Roy Vaughan Miles,Songcen Xu,Feng Wen,Chao Xu,Sinan Zeng,Dacheng Tao*

Main category: cs.CL

TL;DR: 该论文指出自回归语言模型的因果瓶颈限制，提出扩散语言模型作为替代方案，但面临十大挑战，建议通过四大支柱构建扩散原生生态系统以实现下一代AI能力。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型主要基于自回归架构，存在因果瓶颈限制全局结构预见和迭代优化能力。扩散语言模型提供了整体、双向的去噪生成方式，但受限于自回归遗留框架而未能充分发挥潜力。

Method: 识别扩散语言模型面临的十大根本挑战，包括架构惯性、梯度稀疏性、线性推理限制等，并提出四大支柱战略路线图：基础架构、算法优化、认知推理和统一多模态智能。

Result: 提出向扩散原生生态系统转变，通过多尺度标记化、主动重掩码和潜在思维等创新，超越因果视野限制，为下一代AI发展奠定基础。

Conclusion: 从自回归范式向扩散原生生态系统的转变对于开发具备复杂结构推理、动态自我修正和无缝多模态集成能力的下一代AI至关重要，扩散语言模型有望实现其"GPT-4时刻"。

Abstract: The paradigm of Large Language Models (LLMs) is currently defined by auto-regressive (AR) architectures, which generate text through a sequential ``brick-by-brick'' process. Despite their success, AR models are inherently constrained by a causal bottleneck that limits global structural foresight and iterative refinement. Diffusion Language Models (DLMs) offer a transformative alternative, conceptualizing text generation as a holistic, bidirectional denoising process akin to a sculptor refining a masterpiece. However, the potential of DLMs remains largely untapped as they are frequently confined within AR-legacy infrastructures and optimization frameworks. In this Perspective, we identify ten fundamental challenges ranging from architectural inertia and gradient sparsity to the limitations of linear reasoning that prevent DLMs from reaching their ``GPT-4 moment''. We propose a strategic roadmap organized into four pillars: foundational infrastructure, algorithmic optimization, cognitive reasoning, and unified multimodal intelligence. By shifting toward a diffusion-native ecosystem characterized by multi-scale tokenization, active remasking, and latent thinking, we can move beyond the constraints of the causal horizon. We argue that this transition is essential for developing next-generation AI capable of complex structural reasoning, dynamic self-correction, and seamless multimodal integration.

</details>


### [435] [PRiSM: Benchmarking Phone Realization in Speech Models](https://arxiv.org/abs/2601.14046)
*Shikhar Bharadwaj,Chin-Jou Li,Yoonjae Kim,Kwanghee Choi,Eunjung Yeo,Ryan Soh-Eun Shim,Hanyu Zhou,Brendon Boldt,Karen Rosero Jacome,Kalvin Chang,Darsh Agrawal,Keer Xu,Chao-Han Huck Yang,Jian Zhu,Shinji Watanabe,David R. Mortensen*

Main category: cs.CL

TL;DR: PRiSM是首个开源基准测试，通过内在和外在评估揭示语音识别系统的音素感知盲点，发现多语言训练、编码器-CTC模型稳定性以及专用模型优于大型音频语言模型。


<details>
  <summary>Details</summary>
Motivation: 当前语音识别系统评估只关注表面转录准确性，缺乏对音素感知盲点的深入评估。需要标准化评估方法并评估在临床、教育和多语言场景中的实际应用价值。

Method: PRiSM基准测试标准化了基于转录的评估，并通过转录和表示探针评估下游应用。使用内在和外在评估方法，涵盖临床、教育和多语言设置。

Result: 发现多语言训练对性能至关重要，编码器-CTC模型最稳定，专用语音识别模型仍优于大型音频语言模型。开源代码、配方和数据集。

Conclusion: PRiSM推动领域向具有强大音素能力的多语言语音模型发展，提供了标准化评估框架和资源支持。

Abstract: Phone recognition (PR) serves as the atomic interface for language-agnostic modeling for cross-lingual speech processing and phonetic analysis. Despite prolonged efforts in developing PR systems, current evaluations only measure surface-level transcription accuracy. We introduce PRiSM, the first open-source benchmark designed to expose blind spots in phonetic perception through intrinsic and extrinsic evaluation of PR systems. PRiSM standardizes transcription-based evaluation and assesses downstream utility in clinical, educational, and multilingual settings with transcription and representation probes. We find that diverse language exposure during training is key to PR performance, encoder-CTC models are the most stable, and specialized PR models still outperform Large Audio Language Models. PRiSM releases code, recipes, and datasets to move the field toward multilingual speech models with robust phonetic ability: https://github.com/changelinglab/prism.

</details>


### [436] [Understanding Multilingualism in Mixture-of-Experts LLMs: Routing Mechanism, Expert Specialization, and Layerwise Steering](https://arxiv.org/abs/2601.14050)
*Yuxin Chen,Zhengzhou Cai,Xiangtian Ji,Weixiang Zhao,An Zhang,Xiang Wang,Tat-Seng Chua*

Main category: cs.CL

TL;DR: 本文系统分析了MoE模型的多语言处理机制，发现路由行为与语系对齐，专家利用呈现层次模式，并提出路由引导的调控方法提升多语言性能。


<details>
  <summary>Details</summary>
Motivation: 尽管MoE架构在多语言任务中表现出色，但其内部机制、性能提升原因以及跨语言差异尚未得到充分理解，需要系统分析来揭示这些机制。

Method: 系统分析MoE模型的路由行为和专家专业化模式，包括跨语言和网络深度的分析；提出路由引导的调控方法，在推理时自适应地将中间层的路由行为导向与主导语言相关的共享专家。

Result: 分析发现：1）路由行为与语言家族对齐；2）专家利用呈现清晰的层次模式；3）高资源语言依赖共享专家，低资源语言依赖语言专属专家但性能较弱；4）早期和晚期MoE层支持语言特定处理，中间层作为语言无关的容量中心。提出的调控方法能持续提升多语言性能，特别是对语言相关的语言对。

Conclusion: MoE模型的多语言处理具有高度结构化特征，路由行为与语言家族对齐，不同层次的MoE层承担不同功能。基于这些发现的路由引导调控方法能有效提升多语言性能，为理解和优化MoE模型的多语言能力提供了新视角。

Abstract: Mixture-of-Experts (MoE) architectures have shown strong multilingual capabilities, yet the internal mechanisms underlying performance gains and cross-language differences remain insufficiently understood. In this work, we conduct a systematic analysis of MoE models, examining routing behavior and expert specialization across languages and network depth. Our analysis reveals that multilingual processing in MoE models is highly structured: routing aligns with linguistic families, expert utilization follows a clear layerwise pattern, and high-resource languages rely on shared experts while low-resource languages depend more on language-exclusive experts despite weaker performance. Layerwise interventions further show that early and late MoE layers support language-specific processing, whereas middle layers serve as language-agnostic capacity hubs. Building on these insights, we propose a routing-guided steering method that adaptively guides routing behavior in middle layers toward shared experts associated with dominant languages at inference time, leading to consistent multilingual performance improvements, particularly for linguistically related language pairs. Our code is available at https://github.com/conctsai/Multilingualism-in-Mixture-of-Experts-LLMs.

</details>


### [437] [Kakugo: Distillation of Low-Resource Languages into Small Language Models](https://arxiv.org/abs/2601.14051)
*Peter Devine,Mardhiyah Sanni,Farid Adilazuarda,Julieta Gil Loizaga,Barry Haddow*

Main category: cs.CL

TL;DR: Kakugo是一个低成本管道，仅需语言名称即可为低资源语言训练通用小型语言模型，通过教师模型生成合成提示和翻译指令数据集，在54种语言上验证，每语言成本低于50美元。


<details>
  <summary>Details</summary>
Motivation: 低资源语言缺乏训练数据和AI模型，传统方法成本高昂且需要专业知识。需要一种仅需语言名称即可自动生成训练数据和训练模型的低成本解决方案。

Method: 使用大型教师模型生成合成提示并翻译指令数据集，为每种低资源语言创建训练数据，然后训练小型语言模型。整个管道仅需语言名称作为输入。

Result: 在54种低资源语言上成功训练了SLMs，在翻译、分类、问答等NLP任务上表现优于基础模型，每语言总生成和训练成本低于50美元。

Conclusion: Kakugo提供了一种经济高效的方法，使社区能够以极低成本为低资源语言开发特定语言AI模型，仅需语言名称即可启动。

Abstract: We present Kakugo, a novel and cost-effective pipeline designed to train general-purpose Small Language Models (SLMs) for low-resource languages using only the language name as input. By using a large teacher model to generate synthetic prompts and translate instruction datasets, we produced training data and SLMs for 54 low-resource languages. Evaluations across a diverse set of general natural language processing tasks, including translation, classification, and question answering, demonstrate that our pipeline consistently improves performance over base models. With a total generation and training cost of under $50 per language, Kakugo offers an accessible method for communities to develop language-specific AI.

</details>


### [438] [XCR-Bench: A Multi-Task Benchmark for Evaluating Cultural Reasoning in LLMs](https://arxiv.org/abs/2601.14063)
*Mohsinul Kabir,Tasnim Ahmed,Md Mezbaur Rahman,Shaoxiong Ji,Hassan Alhuzali,Sophia Ananiadou*

Main category: cs.CL

TL;DR: XCR-Bench：一个包含4.9k平行句对和1,098个独特文化特定项目的跨文化推理基准，用于评估大语言模型在识别和适应文化特定项目方面的能力。


<details>
  <summary>Details</summary>
Motivation: 当前评估大语言模型跨文化能力的主要限制在于缺乏高质量的文化特定项目标注语料库和跨文化平行句对，这阻碍了对模型在识别和适应文化特定项目方面的系统评估。

Method: 结合Newmark的文化特定项目框架和Hall的文化三元论，构建了包含三个推理任务和相应评估指标的跨文化推理基准，涵盖从表层文化元素到半可见和不可见文化元素（如社会规范、信仰和价值观）的系统分析。

Result: 研究发现最先进的大语言模型在识别和适应与社会礼仪和文化参考相关的文化特定项目方面存在一致弱点，并且即使在单一语言环境中进行文化适应时，模型也表现出区域和民族宗教偏见。

Conclusion: XCR-Bench基准揭示了当前大语言模型在跨文化推理方面的局限性，特别是处理深层文化元素时的不足，为未来跨文化自然语言处理研究提供了重要资源和方向。

Abstract: Cross-cultural competence in large language models (LLMs) requires the ability to identify Culture-Specific Items (CSIs) and to adapt them appropriately across cultural contexts. Progress in evaluating this capability has been constrained by the scarcity of high-quality CSI-annotated corpora with parallel cross-cultural sentence pairs. To address this limitation, we introduce XCR-Bench, a Cross(X)-Cultural Reasoning Benchmark consisting of 4.9k parallel sentences and 1,098 unique CSIs, spanning three distinct reasoning tasks with corresponding evaluation metrics. Our corpus integrates Newmark's CSI framework with Hall's Triad of Culture, enabling systematic analysis of cultural reasoning beyond surface-level artifacts and into semi-visible and invisible cultural elements such as social norms, beliefs, and values. Our findings show that state-of-the-art LLMs exhibit consistent weaknesses in identifying and adapting CSIs related to social etiquette and cultural reference. Additionally, we find evidence that LLMs encode regional and ethno-religious biases even within a single linguistic setting during cultural adaptation. We release our corpus and code to facilitate future research on cross-cultural NLP.

</details>


### [439] [Truth with a Twist: The Rhetoric of Persuasion in Professional vs. Community-Authored Fact-Checks](https://arxiv.org/abs/2601.14105)
*Olesya Razuvayevskaya,Kalina Bontcheva*

Main category: cs.CL

TL;DR: 社区笔记与专业辟谣在说服技巧使用上无显著差异，但存在系统性修辞差异；社区评分能有效惩罚有问题的修辞手段


<details>
  <summary>Details</summary>
Motivation: 研究社区撰写与专业撰写的辟谣内容在说服技巧使用上的差异，验证先前关于社区内容更依赖主观或说服性语言的假设

Method: 使用Community Notes、EUvsDisinfo和Database of Known Fakes三个大规模数据集，量化分析不同事实核查生态系统中说服技巧的普遍性和类型

Result: 1. 社区笔记并未比专业辟谣使用更多说服技巧；2. 发现社区与专业辟谣存在系统性修辞差异，反映制度规范和主题覆盖的不同；3. 社区评分者能有效惩罚有问题的修辞手段，尽管含更多说服元素的笔记总体评分略高

Conclusion: 社区辟谣与专业辟谣在说服技巧使用上无本质差异，但修辞风格不同；社区评估机制能有效识别和惩罚不当修辞手段

Abstract: This study presents the first large-scale comparison of persuasion techniques present in crowd- versus professionally-written debunks. Using extensive datasets from Community Notes (CNs), EUvsDisinfo, and the Database of Known Fakes (DBKF), we quantify the prevalence and types of persuasion techniques across these fact-checking ecosystems. Contrary to prior hypothesis that community-produced debunks rely more heavily on subjective or persuasive wording, we find no evidence that CNs contain a higher average number of persuasion techniques than professional fact-checks. We additionally identify systematic rhetorical differences between CNs and professional debunking efforts, reflecting differences in institutional norms and topical coverage. Finally, we examine how the crowd evaluates persuasive language in CNs and show that, although notes with more persuasive elements receive slightly higher overall helpfulness ratings, crowd raters are effective at penalising the use of particular problematic rhetorical means

</details>


### [440] [Learning to Explain: Supervised Token Attribution from Transformer Attention Patterns](https://arxiv.org/abs/2601.14112)
*George Mihaila*

Main category: cs.CL

TL;DR: ExpNet是一个轻量级神经网络，通过学习从Transformer注意力模式到token重要性分数的显式映射，自动发现最优注意力特征组合，无需预定义规则。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在高风险应用中部署时，其不透明性阻碍了信任和问责。现有注意力解释方法依赖人工定义的聚合策略和固定归因规则，而模型无关方法（如LIME、SHAP）将模型视为黑箱且计算成本高。

Method: 提出Explanation Network (ExpNet)，一个轻量级神经网络，学习从transformer注意力模式到token级重要性分数的显式映射，自动发现最优注意力特征组合，而非依赖预定义规则。

Result: 在具有挑战性的跨任务设置中评估ExpNet，并与涵盖四个方法家族的广泛模型无关方法和基于注意力的技术进行基准测试。

Conclusion: ExpNet提供了一种新的可解释AI方法，能够自动学习注意力模式与token重要性之间的关系，相比现有方法更灵活且计算效率更高。

Abstract: Explainable AI (XAI) has become critical as transformer-based models are deployed in high-stakes applications including healthcare, legal systems, and financial services, where opacity hinders trust and accountability. Transformers self-attention mechanisms have proven valuable for model interpretability, with attention weights successfully used to understand model focus and behavior (Xu et al., 2015); (Wiegreffe and Pinter, 2019). However, existing attention-based explanation methods rely on manually defined aggregation strategies and fixed attribution rules (Abnar and Zuidema, 2020a); (Chefer et al., 2021), while model-agnostic approaches (LIME, SHAP) treat the model as a black box and incur significant computational costs through input perturbation. We introduce Explanation Network (ExpNet), a lightweight neural network that learns an explicit mapping from transformer attention patterns to token-level importance scores. Unlike prior methods, ExpNet discovers optimal attention feature combinations automatically rather than relying on predetermined rules. We evaluate ExpNet in a challenging cross-task setting and benchmark it against a broad spectrum of model-agnostic methods and attention-based techniques spanning four methodological families.

</details>


### [441] [NewsRECON: News article REtrieval for image CONtextualization](https://arxiv.org/abs/2601.14121)
*Jonathan Tonglet,Iryna Gurevych,Tinne Tuytelaars,Marie-Francine Moens*

Main category: cs.CL

TL;DR: NewsRECON：一种在反向图像搜索证据不可用时，通过将新闻图像链接到相关文章来推断其拍摄时间和地点的方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖反向图像搜索(RIS)引擎，但这些工具经常无法返回结果，限制了实际应用。需要解决RIS证据不可用的挑战性场景。

Method: NewsRECON方法包含：1) 双编码器检索事件相关文章；2) 两个交叉编码器通过位置和事件一致性对文章进行重排序。利用超过90,000篇文章的语料库。

Result: 在TARA和5Pils-OOC数据集上的实验表明，NewsRECON优于先前工作，并且可以与多模态大语言模型结合，在缺乏RIS证据的情况下达到新的SOTA结果。

Conclusion: NewsRECON提供了一种有效的替代方案，用于在反向图像搜索失败时推断新闻图像的时间和地点信息，提高了新闻验证的实用性。

Abstract: Identifying when and where a news image was taken is crucial for journalists and forensic experts to produce credible stories and debunk misinformation. While many existing methods rely on reverse image search (RIS) engines, these tools often fail to return results, thereby limiting their practical applicability. In this work, we address the challenging scenario where RIS evidence is unavailable. We introduce NewsRECON, a method that links images to relevant news articles to infer their date and location from article metadata. NewsRECON leverages a corpus of over 90,000 articles and integrates: (1) a bi-encoder for retrieving event-relevant articles; (2) two cross-encoders for reranking articles by location and event consistency. Experiments on the TARA and 5Pils-OOC show that NewsRECON outperforms prior work and can be combined with a multimodal large language model to achieve new SOTA results in the absence of RIS evidence. We make our code available.

</details>


### [442] [A Systematic Analysis of Chunking Strategies for Reliable Question Answering](https://arxiv.org/abs/2601.14123)
*Sofia Bennani,Charles Moslonka*

Main category: cs.CL

TL;DR: 文档分块策略对RAG系统可靠性的影响：重叠分块无益，句子分块性价比最高，上下文长度存在"悬崖效应"，最优上下文长度取决于具体目标


<details>
  <summary>Details</summary>
Motivation: 研究文档分块选择如何影响工业界检索增强生成（RAG）系统的可靠性。实践中通常依赖启发式方法，但缺乏系统评估。

Method: 在Natural Questions数据集上进行端到端评估，系统性地变化分块方法（token、句子、语义、代码）、分块大小、重叠和上下文长度。使用标准工业设置：SPLADE检索和Mistral-8B生成器。

Result: 得出可操作的部署建议：1) 重叠分块无显著益处且增加索引成本；2) 句子分块是最具成本效益的方法，在约5k token内与语义分块效果相当；3) 超过约2.5k token会出现"上下文悬崖"导致质量下降；4) 最优上下文长度取决于目标（语义质量在小上下文中达到峰值，精确匹配需要更大上下文）。

Conclusion: 为工业界RAG系统部署提供了具体指导：避免重叠分块，优先使用句子分块，注意上下文长度限制，根据具体应用目标调整策略以实现成本效益最大化。

Abstract: We study how document chunking choices impact the reliability of Retrieval-Augmented Generation (RAG) systems in industry. While practice often relies on heuristics, our end-to-end evaluation on Natural Questions systematically varies chunking method (token, sentence, semantic, code), chunk size, overlap, and context length. We use a standard industrial setup: SPLADE retrieval and a Mistral-8B generator. We derive actionable lessons for cost-efficient deployment: (i) overlap provides no measurable benefit and increases indexing cost; (ii) sentence chunking is the most cost-effective method, matching semantic chunking up to ~5k tokens; (iii) a "context cliff" reduces quality beyond ~2.5k tokens; and (iv) optimal context depends on the goal (semantic quality peaks at small contexts; exact match at larger ones).

</details>


### [443] [Style Transfer as Bias Mitigation: Diffusion Models for Synthetic Mental Health Text for Arabic](https://arxiv.org/abs/2601.14124)
*Saad Mankarious,Aya Zirikly*

Main category: cs.CL

TL;DR: 提出一种基于扩散模型的文本生成方法，通过风格迁移缓解阿拉伯语心理健康数据中的性别偏见，无需预训练大语言模型。


<details>
  <summary>Details</summary>
Motivation: 现有合成数据方法主要依赖预训练大语言模型，存在输出多样性有限和传播训练数据偏见的问题。特别是在心理健康分析领域，数据稀缺和人口统计偏见（如性别不平衡）严重。

Method: 将偏见缓解视为风格迁移问题，使用扩散模型进行文本生成。基于CARMA阿拉伯语心理健康语料库（存在显著性别不平衡），专注于男性到女性的风格迁移以增强代表性不足的女性内容。构建五个数据集捕捉阿拉伯语性别表达的不同语言和语义方面，并为每个设置训练独立的扩散模型。

Result: 定量评估显示源文本与生成文本之间具有一致的高语义保真度，同时存在有意义的表层风格差异。定性分析确认了语言上合理的性别转换。扩散模型能够生成高熵、语义忠实的合成数据。

Conclusion: 基于扩散的风格迁移可以在不依赖预训练大语言模型的情况下生成高质量的合成数据，为缓解敏感、低资源心理健康领域的性别偏见提供了有效且灵活的框架。

Abstract: Synthetic data offers a promising solution for mitigating data scarcity and demographic bias in mental health analysis, yet existing approaches largely rely on pretrained large language models (LLMs), which may suffer from limited output diversity and propagate biases inherited from their training data. In this work, we propose a pretraining-free diffusion-based approach for synthetic text generation that frames bias mitigation as a style transfer problem. Using the CARMA Arabic mental health corpus, which exhibits a substantial gender imbalance, we focus on male-to-female style transfer to augment underrepresented female-authored content. We construct five datasets capturing varying linguistic and semantic aspects of gender expression in Arabic and train separate diffusion models for each setting. Quantitative evaluations demonstrate consistently high semantic fidelity between source and generated text, alongside meaningful surface-level stylistic divergence, while qualitative analysis confirms linguistically plausible gender transformations. Our results show that diffusion-based style transfer can generate high-entropy, semantically faithful synthetic data without reliance on pretrained LLMs, providing an effective and flexible framework for mitigating gender bias in sensitive, low-resource mental health domains.

</details>


### [444] [Lost in the Prompt Order: Revealing the Limitations of Causal Attention in Language Models](https://arxiv.org/abs/2601.14152)
*Hyunjong Ok,Jaeho Lee*

Main category: cs.CL

TL;DR: 研究发现，在多项选择题回答中，将上下文放在问题和选项之前（CQO）比反向顺序（QOC）性能提升超过14%，其核心机制是因果注意力：QOC提示中的因果掩码阻止选项标记关注上下文，形成信息瓶颈。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型对提示结构表现出惊人的敏感性，但这种敏感性背后的机制尚未被充分理解。本研究旨在深入探究一个显著现象：在多项选择题回答中，不同提示顺序（上下文-问题-选项 vs 问题-选项-上下文）导致性能差异超过14%。

Method: 通过系统性的架构分析，识别因果注意力作为核心机制。在QOC提示中，因果掩码阻止选项标记关注上下文，创建信息瓶颈，使上下文对选项不可见。

Result: CQO顺序（上下文在前）在广泛模型和数据集上一致优于QOC顺序（问题在前），性能差异超过14个百分点。因果注意力机制被确定为这一现象的根本原因。

Conclusion: 提示结构对LLM性能有显著影响，特别是因果注意力机制在信息流动中起关键作用。理解这一机制有助于设计更有效的提示策略，提升模型在多项选择题等任务上的表现。

Abstract: Large language models exhibit surprising sensitivity to the structure of the prompt, but the mechanisms underlying this sensitivity remain poorly understood. In this work, we conduct an in-depth investigation on a striking case: in multiple-choice question answering, placing context before the questions and options (CQO) outperforms the reverse order (QOC) by over 14%p, consistently over a wide range of models and datasets. Through systematic architectural analysis, we identify causal attention as the core mechanism: in QOC prompts, the causal mask prevents option tokens from attending to context, creating an information bottleneck where context becomes invisible to options.

</details>


### [445] [Domain-Adaptation through Synthetic Data: Fine-Tuning Large Language Models for German Law](https://arxiv.org/abs/2601.14160)
*Ali Hamza Bashir,Muhammad Rehan Khalid,Kostadin Cvejoski,Jana Birr,Jule Berghaus,Armin Berger,Sandra Halscheidt,Christian Temath,Rafet Sifa,David Berghaus*

Main category: cs.CL

TL;DR: 本文提出了一种通过合成数据生成方法，将先进大语言模型适配到德国法律问答任务的有效方法，无需昂贵的人工标注即可获得高质量训练数据。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在专业领域（如法律推理）中表现不佳，因为缺乏专家知识，导致事实错误或幻觉。德国法律问答任务尤其需要高质量的训练数据，但人工标注成本高昂，现有合成数据方法质量不可靠。

Method: 提出新颖的合成数据生成方法，直接从权威德国法规中系统生成高质量、多样且法律准确的问答对。采用严格的自动过滤方法和参数高效微调技术，使用合成数据集适配LLMs。

Result: 使用本文合成数据集微调的LLMs在德国法律问答任务上显著优于基线模型。结果表明精心设计的合成数据可以作为高风险、知识密集型领域中人工标注的可靠替代方案。

Conclusion: 本文证明了通过系统化合成数据生成方法，可以有效将大语言模型适配到专业法律领域，为知识密集型任务提供了一种成本效益高且可靠的训练数据获取途径。

Abstract: Large language models (LLMs) often struggle in specialized domains such as legal reasoning due to limited expert knowledge, resulting in factually incorrect outputs or hallucinations. This paper presents an effective method for adapting advanced LLMs to German legal question answering through a novel synthetic data generation approach. In contrast to costly human-annotated resources or unreliable synthetic alternatives, our approach systematically produces high-quality, diverse, and legally accurate question-answer pairs directly from authoritative German statutes. Using rigorous automated filtering methods and parameter-efficient fine-tuning techniques, we demonstrate that LLMs adapted with our synthetic dataset significantly outperform their baseline counterparts on German legal question answering tasks. Our results highlight the feasibility of using carefully designed synthetic data as a robust alternative to manual annotation in high-stakes, knowledge-intensive domains.

</details>


### [446] [Human Values in a Single Sentence: Moral Presence, Hierarchies, and Transformer Ensembles on the Schwartz Continuum](https://arxiv.org/abs/2601.14172)
*Víctor Yeste,Paolo Rosso*

Main category: cs.CL

TL;DR: 研究句子级别识别施瓦茨价值观体系中的19种价值观，作为文本中人类价值观检测的具体实现。在新闻和政治宣言的零上下文句子中，面临稀疏的道德线索和严重的类别不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 在零上下文的句子中检测细粒度的人类价值观具有内在困难，即使对于现代神经模型也是如此。需要探索在计算受限（8GB单GPU）条件下，如何有效检测句子级别的价值观。

Method: 1) 首先定义二元道德存在任务；2) 比较基于DeBERTa-base的存在门控层次结构与直接多标签分类器；3) 基准测试指令调优的LLMs（Gemma 2 9B等）在零样本/少样本和QLoRA设置下的表现；4) 构建简单集成模型。

Result: 1) 二元道德存在任务可学习（正类F1≈0.74）；2) 层次结构未优于直接预测；3) 软投票监督集成达到macro-F1 0.332，显著超越最佳单监督模型和先前基线；4) 轻量信号和小型集成提供最可靠的改进。

Conclusion: 在8GB单GPU约束和7-9B规模下，精心调优的监督编码器仍然是结构化人类价值观检测的强大且计算高效的基线。更丰富的价值结构和文档上下文可进一步提升性能。

Abstract: We study sentence-level identification of the 19 values in the Schwartz motivational continuum as a concrete formulation of human value detection in text. The setting - out-of-context sentences from news and political manifestos - features sparse moral cues and severe class imbalance. This combination makes fine-grained sentence-level value detection intrinsically difficult, even for strong modern neural models. We first operationalize a binary moral presence task ("does any value appear?") and show that it is learnable from single sentences (positive-class F1 $\approx$ 0.74 with calibrated thresholds). We then compare a presence-gated hierarchy to a direct multi-label classifier under matched compute, both based on DeBERTa-base and augmented with lightweight signals (prior-sentence context, LIWC-22/eMFD/MJD lexica, and topic features). The hierarchy does not outperform direct prediction, indicating that gate recall limits downstream gains. We also benchmark instruction-tuned LLMs - Gemma 2 9B, Llama 3.1 8B, Mistral 8B, and Qwen 2.5 7B - in zero-/few-shot and QLoRA setups and build simple ensembles; a soft-vote supervised ensemble reaches macro-F1 0.332, significantly surpassing the best single supervised model and exceeding prior English-only baselines. Overall, in this scenario, lightweight signals and small ensembles yield the most reliable improvements, while hierarchical gating offers limited benefit. We argue that, under an 8 GB single-GPU constraint and at the 7-9B scale, carefully tuned supervised encoders remain a strong and compute-efficient baseline for structured human value detection, and we outline how richer value structure and sentence-in-document context could further improve performance.

</details>


### [447] [HALT: Hallucination Assessment via Latent Testing](https://arxiv.org/abs/2601.14210)
*Rohan Bhatnagar,Youran Sun,Chi Andrew Zhang,Yixin Wen,Haizhao Yang*

Main category: cs.CL

TL;DR: 提出轻量级残差探针，直接从LLM中间隐藏状态读取幻觉风险，实现零延迟的风险评估，用于选择性生成和路由决策。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的幻觉问题可理解为忠实读取失败：虽然内部表示可能编码了查询的不确定性，但解码压力仍会产生流畅答案。需要从中间层提取被最终解码阶段衰减的认知信号。

Method: 设计轻量级残差探针，直接读取问题令牌中间隐藏状态中的幻觉风险。探针是小型辅助网络，计算成本比令牌生成低几个数量级，可与推理完全并行评估，实现近乎即时的幻觉风险评估。

Result: 在四个QA基准测试和多个LLM家族上，方法实现了强AUROC和AURAC性能，在数据集偏移下具有良好泛化能力，并揭示了中间表示中的可解释结构。

Conclusion: 快速内部不确定性读取可作为可靠智能AI的原则性基础，探针可作为智能批评者用于快速选择性生成和路由，让LLM立即回答自信查询，同时将不确定查询委托给更强的验证流程。

Abstract: Hallucination in large language models (LLMs) can be understood as a failure of faithful readout: although internal representations may encode uncertainty about a query, decoding pressures still yield a fluent answer. We propose lightweight residual probes that read hallucination risk directly from intermediate hidden states of question tokens, motivated by the hypothesis that these layers retain epistemic signals that are attenuated in the final decoding stage. The probe is a small auxiliary network whose computation is orders of magnitude cheaper than token generation and can be evaluated fully in parallel with inference, enabling near-instantaneous hallucination risk estimation with effectively zero added latency in low-risk cases. We deploy the probe as an agentic critic for fast selective generation and routing, allowing LLMs to immediately answer confident queries while delegating uncertain ones to stronger verification pipelines. Across four QA benchmarks and multiple LLM families, the method achieves strong AUROC and AURAC, generalizes under dataset shift, and reveals interpretable structure in intermediate representations, positioning fast internal uncertainty readout as a principled foundation for reliable agentic AI.

</details>


### [448] [MASCOT: Towards Multi-Agent Socio-Collaborative Companion Systems](https://arxiv.org/abs/2601.14230)
*Yiyang Wang,Yiqiao Jin,Alex Cabral,Josiah Hester*

Main category: cs.CL

TL;DR: MASCOT：一种防止多智能体系统角色崩溃和社会谄媚的框架，通过双层优化策略提升角色一致性和社会贡献


<details>
  <summary>Details</summary>
Motivation: 多智能体系统常面临角色崩溃（智能体退化为通用助手行为）和社会谄媚（产生冗余、非建设性对话）的问题，限制了其作为社会协作伴侣的有效性

Method: 提出MASCOT框架，采用双层优化策略：1）角色感知行为对齐，使用RLAIF驱动的流程微调个体智能体以确保严格角色保真度；2）协作对话优化，通过群体级奖励引导的元策略确保多样化和富有成效的对话

Result: 在心理支持和职场领域的广泛评估表明，MASCOT显著优于现有基线方法，在角色一致性方面提升高达+14.1，在社会贡献方面提升高达+10.6

Conclusion: MASCOT为构建下一代社会智能多智能体系统提供了实用路线图，有效解决了角色崩溃和社会谄媚问题

Abstract: Multi-agent systems (MAS) have recently emerged as promising socio-collaborative companions for emotional and cognitive support. However, these systems frequently suffer from persona collapse--where agents revert to generic, homogenized assistant behaviors--and social sycophancy, which produces redundant, non-constructive dialogue. We propose MASCOT, a generalizable framework for multi-perspective socio-collaborative companions. MASCOT introduces a novel bi-level optimization strategy to harmonize individual and collective behaviors: 1) Persona-Aware Behavioral Alignment, an RLAIF-driven pipeline that finetunes individual agents for strict persona fidelity to prevent identity loss; and 2) Collaborative Dialogue Optimization, a meta-policy guided by group-level rewards to ensure diverse and productive discourse. Extensive evaluations across psychological support and workplace domains demonstrate that MASCOT significantly outperforms state-of-the-art baselines, achieving improvements of up to +14.1 in Persona Consistency and +10.6 in Social Contribution. Our framework provides a practical roadmap for engineering the next generation of socially intelligent multi-agent systems.

</details>


### [449] [APEX-Agents](https://arxiv.org/abs/2601.14242)
*Bertie Vidgen,Austin Mann,Abby Fennelly,John Wright Stanly,Lucas Rothman,Marco Burstein,Julien Benchek,David Ostrofsky,Anirudh Ravichandran,Debnil Sur,Neel Venugopal,Alannah Hsia,Isaac Robinson,Calix Huang,Olivia Varones,Daniyal Khan,Michael Haines,Zach Richards,Chirag Mahapatra,Brendan Foody,Osvald Nitski*

Main category: cs.CL

TL;DR: APEX-Agents是一个评估AI代理执行投资银行、管理咨询和法律领域跨应用长时程任务的基准测试，包含真实工作环境和工具，Gemini 3 Flash表现最佳。


<details>
  <summary>Details</summary>
Motivation: 需要评估AI代理在真实工作场景中执行复杂、跨应用任务的能力，特别是投资银行分析师、管理顾问和律师等专业领域的长时程任务。

Method: 创建APEX-Agents基准测试，包含480个任务，模拟真实工作环境（文件和工具），使用Pass@1评估8个代理，并开源基准测试和Archipelago执行评估基础设施。

Result: Gemini 3 Flash (Thinking=High)以24.0%得分最高，其次是GPT-5.2、Claude Opus 4.5和Gemini 3 Pro（均开启高级思考模式）。

Conclusion: APEX-Agents为评估AI代理在专业工作环境中的生产力提供了标准化基准，当前最佳代理在复杂任务上仍有很大提升空间（仅24%成功率）。

Abstract: We introduce the AI Productivity Index for Agents (APEX-Agents), a benchmark for assessing whether AI agents can execute long-horizon, cross-application tasks created by investment banking analysts, management consultants, and corporate lawyers. APEX-Agents requires agents to navigate realistic work environments with files and tools. We test eight agents for the leaderboard using Pass@1. Gemini 3 Flash (Thinking=High) achieves the highest score of 24.0%, followed by GPT-5.2 (Thinking=High), Claude Opus 4.5 (Thinking=High), and Gemini 3 Pro (Thinking=High). We open source the APEX-Agents benchmark (n=480) with all prompts, rubrics, gold outputs, files, and metadata. We also open-source Archipelago, our infrastructure for agent execution and evaluation.

</details>


### [450] [Which Reasoning Trajectories Teach Students to Reason Better? A Simple Metric of Informative Alignment](https://arxiv.org/abs/2601.14249)
*Yuming Yang,Mingyoung Lai,Wanxu Zhao,Xiaoran Fan,Zhiheng Xi,Mingqi Wu,Chiyue Huang,Jun Zhao,Haijun Lv,Jian Tong,Yunhua Zhou,Yicheng Zou,Qipeng Guo,Tao Gui,Qi Zhang,Xuanjing Huang*

Main category: cs.CL

TL;DR: 提出Rank-Surprisal Ratio (RSR)指标，通过平衡对齐性和信息性来评估推理轨迹对学生模型的适用性，优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有研究发现更强的教师模型生成的推理轨迹不一定能产生更好的学生模型，表明数据-学生适用性很重要。现有方法主要通过学生似然评估适用性，偏向与模型当前行为高度对齐的轨迹，但忽略了更具信息量的轨迹。

Method: 提出Rank-Surprisal Ratio (RSR)指标，定义为轨迹的平均token级别排名与平均负对数似然的比值。该指标同时捕捉对齐性和信息性，有效轨迹通常在学生模型下具有低绝对概率但相对高排名的token。

Result: 在5个学生模型和11个不同教师的推理轨迹上，RSR与训练后性能强相关（平均Spearman 0.86），优于现有指标。进一步展示了RSR在轨迹选择和教师选择中的实际效用。

Conclusion: RSR是一个简单有效的指标，能够评估推理轨迹对学生模型的适用性，在知识蒸馏中平衡学习信号强度和行为对齐，为轨迹选择和教师选择提供实用指导。

Abstract: Long chain-of-thought (CoT) trajectories provide rich supervision signals for distilling reasoning from teacher to student LLMs. However, both prior work and our experiments show that trajectories from stronger teachers do not necessarily yield better students, highlighting the importance of data-student suitability in distillation. Existing methods assess suitability primarily through student likelihood, favoring trajectories that closely align with the model's current behavior but overlooking more informative ones. Addressing this, we propose Rank-Surprisal Ratio (RSR), a simple metric that captures both alignment and informativeness to assess the suitability of a reasoning trajectory. RSR is motivated by the observation that effective trajectories typically combine low absolute probability with relatively high-ranked tokens under the student model, balancing learning signal strength and behavioral alignment. Concretely, RSR is defined as the ratio of a trajectory's average token-wise rank to its average negative log-likelihood, and is straightforward to compute and interpret. Across five student models and reasoning trajectories from 11 diverse teachers, RSR strongly correlates with post-training performance (average Spearman 0.86), outperforming existing metrics. We further demonstrate its practical utility in both trajectory selection and teacher selection.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [451] [Knowledge Graph Construction for Stock Markets with LLM-Based Explainable Reasoning](https://arxiv.org/abs/2601.11528)
*Cheonsol Lee,Youngsang Jeong,Jeongyeol Shin,Huiju Kim,Jidong Kim*

Main category: cs.DB

TL;DR: 该论文提出了一种结合知识图谱和大型语言模型的股票市场分析框架，通过建模公司、行业、财务指标等关系，实现可解释的多跳推理和复杂金融问题解答。


<details>
  <summary>Details</summary>
Motivation: 传统股票市场研究主要关注时间序列预测和单公司分析，依赖数值数据进行股价预测。这些方法虽然能提供短期洞察，但难以捕捉关系模式、竞争动态和可解释的投资逻辑。需要一种能够处理复杂关系并提供深入解释的分析方法。

Method: 设计专门针对股票市场的知识图谱模式，建模公司、行业、股票指标、财务报表和公司间关系。将该模式与大型语言模型（LLMs）集成，实现多跳推理和关系查询，生成复杂金融问题的可解释答案。系统流程包括数据收集、图谱构建、LLM查询处理和答案生成。

Result: 通过对韩国上市公司的实际案例研究验证了该框架的有效性，证明其能够提取传统数据库查询难以或无法获得的洞察。结果表明知识图谱与LLMs结合在高级投资分析和决策支持方面具有潜力。

Conclusion: 结合知识图谱和大型语言模型的方法能够克服传统股票分析方法的局限性，提供更深入、可解释的金融洞察，为投资分析和决策支持开辟了新途径。

Abstract: The stock market is inherently complex, with interdependent relationships among companies, sectors, and financial indicators. Traditional research has largely focused on time-series forecasting and single-company analysis, relying on numerical data for stock price prediction. While such approaches can provide short-term insights, they are limited in capturing relational patterns, competitive dynamics, and explainable investment reasoning. To address these limitations, we propose a knowledge graph schema specifically designed for the stock market, modeling companies, sectors, stock indicators, financial statements, and inter-company relationships. By integrating this schema with large language models (LLMs), our approach enables multi-hop reasoning and relational queries, producing explainable and in-depth answers to complex financial questions. Figure1 illustrates the system pipeline, detailing the flow from data collection and graph construction to LLM-based query processing and answer generation. We validate the proposed framework through practical case studies on Korean listed companies, demonstrating its capability to extract insights that are difficult or impossible to obtain from traditional database queries alone. The results highlight the potential of combining knowledge graphs with LLMs for advanced investment analysis and decision support.

</details>


### [452] [RelServe: Fast LLM Inference Serving on Relational Data](https://arxiv.org/abs/2601.11546)
*Xin Zhang,Shihong Gao,Yanyan Shen,Haoyang Li,Lei Chen*

Main category: cs.DB

TL;DR: RelServe是一个针对关系查询（relQuery）优化的LLM推理引擎，通过动态优先级更新和自适应批处理安排，解决了现有LLM引擎在并发查询负载下的延迟瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 随着基于LLM的关系查询服务（如AI电子表格）的广泛应用，在并发查询负载下实现快速响应时间变得至关重要。现有LLM引擎面临严重的延迟瓶颈，主要来自三个可比较推理阶段（等待、核心运行、尾部运行）中的队头阻塞问题。现有的静态优先级调度方法只解决了等待阶段的阻塞，但核心执行阶段的优先级不准确和尾部执行的次优批处理问题仍未解决。

Method: RelServe包含两个核心创新：1）动态优先级更新器，通过统计近似方法持续调整优先级同时最小化开销；2）自适应批处理安排器，定量评估候选的预填充和解码批次，以最小化预测的平均延迟。

Result: 在四个真实数据集上使用13B到70B参数的LLM进行广泛实验表明，RelServe相比vLLM将平均服务延迟降低了最多3.1倍。

Conclusion: RelServe通过解决现有LLM引擎在并发关系查询服务中的延迟瓶颈，特别是核心执行阶段的优先级不准确和尾部执行的批处理优化问题，显著提升了服务性能，为AI驱动的应用提供了更高效的关系查询服务解决方案。

Abstract: The use of Large Language Models (LLMs) for querying relational data has given rise to relQuery, a workload pattern that applies templated LLM calls to structured tables. As relQuery services become more widely adopted in applications such as AI-powered spreadsheets, fast response times under concurrent query loads are increasingly important. Unfortunately, current LLM engines face severe latency bottlenecks from Head-of-Line (HoL) blocking across three comparable inference phases: waiting, core running, and tail running. Existing static priority scheduling methods only address HoL blocking during the waiting phase, leaving two critical problems unsolved. First, the absence of a priority update mechanism causes inaccurate prioritization and continued HoL blocking during core execution. Second, suboptimal prefill-decode batching exacerbates HoL blocking in tail execution and worsens latency trade-offs between running and waiting relQueries. To address these problems, we propose RelServe, an optimized LLM engine for low-latency relQuery serving. RelServe features two core innovations: a Dynamic Priority Updater that continuously adjusts priorities while minimizing overhead via statistical approximations, and an Adaptive Batch Arranger that quantitatively evaluates candidate prefill and decode batches to minimize projected average latency. Extensive experiments on four real-world datasets using LLMs ranging from 13B to 70B parameters show that RelServe reduces average serving latency by up to 3.1x compared to vLLM.

</details>


### [453] [Uniqueness ratio as a predictor of a privacy leakage](https://arxiv.org/abs/2601.11550)
*Danah A. AlSalem AlKhashti*

Main category: cs.DB

TL;DR: 研究提出使用候选连接属性的唯一性比率作为连接前重识别风险的早期预测指标，实验显示高唯一性比率与连接后身份泄露风险强相关。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注连接后检测或复杂隐私模型，缺乏简单、可解释的连接前指标来警告数据工程师和数据库管理员在数据集成前发现身份泄露风险。

Method: 使用合成多表数据集，计算每个数据库中属性组合的唯一性比率，并分析这些比率与连接后身份暴露之间的相关性。

Result: 实验结果显示，连接前的高唯一性比率与连接后身份泄露风险（通过唯一可识别记录比例或落入极小群组的记录比例衡量）存在强相关关系。

Conclusion: 唯一性比率提供了一个可解释且实用的信号来评估连接引发的隐私风险，为开发更全面的连接前风险评估模型奠定了基础。

Abstract: Identity leakage can emerge when independent databases are joined, even when each dataset is anonymized individually. While previous work focuses on post-join detection or complex privacy models, little attention has been given to simple, interpretable pre-join indicators that can warn data engineers and database administrators before integration occurs. This study investigates the uniqueness ratio of candidate join attributes as an early predictor of re-identification risk. Using synthetic multi-table datasets, we compute the uniqueness ratio of attribute combinations within each database and examine how these ratios correlate with identity exposure after the join. Experimental results show a strong relationship between high pre-join uniqueness and increased post-join leakage, measured by the proportion of records that become uniquely identifiable or fall into very small groups. Our findings demonstrate that uniqueness ratio offers an explainable and practical signal for assessing join induced privacy risk, providing a foundation for developing more comprehensive pre-join risk estimation models.

</details>


### [454] [From HNSW to Information-Theoretic Binarization: Rethinking the Architecture of Scalable Vector Search](https://arxiv.org/abs/2601.11557)
*Seyed Moein Abtahi,Majid Fekri,Tara Khani,Akramul Azim*

Main category: cs.DB

TL;DR: 论文提出了一种基于最大信息二值化(MIB)、位距离度量和信息论评分(ITS)的新型语义搜索架构，替代传统"HNSW + float32 + 余弦相似度"方案，在保持检索质量的同时显著降低延迟和成本。


<details>
  <summary>Details</summary>
Motivation: 当前语义搜索和RAG系统主要依赖内存中的近似最近邻(ANN)索引和高精度浮点向量，导致运营成本不断上升，且在延迟、吞吐量和检索准确性之间存在固有权衡。现有成本降低策略（如存储解耦和有损向量量化）都会牺牲性能或准确性。

Method: 提出基于最大信息二值化(MIB)、高效位距离度量和信息论评分(ITS)机制的信息论架构。该方法使用紧凑的二进制表示进行穷举搜索，实现确定性检索，消除高并发查询下的准确性下降。

Result: 在MAIR基准测试中（14个数据集，10,038个查询），与Elasticsearch、Pinecone、PGVector和Qdrant相比，新架构的检索质量与全精度系统相当，同时显著降低延迟，并在高请求率下保持恒定吞吐量。

Conclusion: 这种架构转变实现了真正的无服务器、按查询付费的部署模式，挑战了高质量语义搜索必须依赖大型内存ANN索引的传统观念，为语义搜索系统提供了更高效、成本更低的替代方案。

Abstract: Modern semantic search and retrieval-augmented generation (RAG) systems rely predominantly on in-memory approximate nearest neighbor (ANN) indexes over high-precision floating-point vectors, resulting in escalating operational cost and inherent trade-offs between latency, throughput, and retrieval accuracy. This paper analyzes the architectural limitations of the dominant "HNSW + float32 + cosine similarity" stack and evaluates existing cost-reduction strategies, including storage disaggregation and lossy vector quantization, which inevitably sacrifice either performance or accuracy. We introduce and empirically evaluate an alternative information-theoretic architecture based on maximally informative binarization (MIB), efficient bitwise distance metrics, and an information-theoretic scoring (ITS) mechanism. Unlike conventional ANN systems, this approach enables exhaustive search over compact binary representations, allowing deterministic retrieval and eliminating accuracy degradation under high query concurrency. Using the MAIR benchmark across 14 datasets and 10,038 queries, we compare this architecture against Elasticsearch, Pinecone, PGVector, and Qdrant. Results demonstrate retrieval quality comparable to full-precision systems, while achieving substantially lower latency and maintaining constant throughput at high request rates. We show that this architectural shift enables a truly serverless, cost-per-query deployment model, challenging the necessity of large in-memory ANN indexes for high-quality semantic search.

</details>


### [455] [Bridging Radiology and Pathology: A DICOM-Based Framework for Multimodal Mapping and Integrated Visualization](https://arxiv.org/abs/2601.11558)
*Nilesh P. Rijhwani,Titus J. Brinker,Peter Neher,Marco Nolden,Klaus Maier-Hein,Maximilian Fischer,Christoph Wies*

Main category: cs.DB

TL;DR: 开发了一个连接放射学和病理学的跨学科工具箱，通过自动化图像配准和对齐，实现高效、可扩展的多模态分析，促进跨学科研究和疾病机制理解。


<details>
  <summary>Details</summary>
Motivation: 医疗专科之间使用不同的数据系统和专有格式，阻碍了联合分析和互补诊断信息的整合。虽然放射学和病理学的多模态整合已显示出识别新生物标志物的潜力，但仍依赖耗时的手动数据配对。

Method: 开发了一个可在Kaapana框架内运行或作为独立工具的跨学科工具箱，通过连接特定模态的查看器并扩展自动化图像配准和对齐功能，实现放射学和病理学之间的桥梁作用。

Result: 该平台实现了高效、可扩展的多模态分析，集成的环境促进了可重复的工作流程，加速了跨学科研究，并有助于更深入地了解疾病机制和患者护理。

Conclusion: 该工具箱通过自动化图像配准和对齐，有效解决了放射学和病理学数据整合的障碍，为跨学科医疗协作和疾病研究提供了实用解决方案。

Abstract: Accurate disease diagnosis depends on effective collaboration between medical specialties, yet departments often use distinct data systems and proprietary formats. This heterogeneity hinders joint analysis and integration of complementary diagnostic information. The use of separate viewers for each modality further restricts cross-specialty collaboration. Although multimodal integration, particularly between radiology and pathology, has demonstrated potential for identifying novel biomarkers, it still relies heavily on manual, time-consuming data pairing. This project introduces an interdisciplinary toolbox that can operate within the Kaapana framework or as a standalone tool to bridge radiology and pathology. By linking modalityspecific viewers and extending them with automated image registration and alignment, the platform enables efficient, scalable multimodal analysis. The integrated environment promotes reproducible workflows, accelerates crossdisciplinary research, and facilitates deeper insights into disease mechanisms and patient care.

</details>


### [456] [GPU-Resident Inverted File Index for Streaming Vector Databases](https://arxiv.org/abs/2601.11808)
*Dongfang Zhao*

Main category: cs.DB

TL;DR: SIVF：一种支持流式数据更新的GPU原生向量索引架构，通过slab内存分配和地址转换表实现毫秒级实时更新，相比传统静态IVF索引性能提升数百倍。


<details>
  <summary>Details</summary>
Motivation: 传统GPU加速的倒排文件（IVF）索引采用静态内存布局，缺乏原地更新能力，在流式场景中需要昂贵的CPU-GPU数据传输，导致系统延迟从毫秒级激增至秒级，无法满足实时知识更新的需求。

Method: 提出SIVF（流式倒排文件）架构：1）用基于slab的内存分配系统和有效性位图替代静态内存布局，支持VRAM中的无锁原地更新；2）引入GPU驻留的地址转换表（ATT），提供O(1)访问物理存储槽的能力。

Result: 在SIFT1M和GIST1M数据集上的评估显示：1）删除延迟降低高达13,300倍（从11.8秒降至0.89毫秒）；2）插入吞吐量提升36-105倍；3）端到端滑动窗口场景中消除系统冻结，实现161-266倍加速，保持毫秒级延迟；4）存储开销小于0.8%。

Conclusion: SIVF通过创新的GPU原生架构解决了传统IVF索引的流式更新瓶颈，为向量数据库提供了高吞吐量、低延迟的数据更新能力，显著提升了实时推荐引擎和动态RAG系统的性能。

Abstract: Vector search has emerged as the computational backbone of modern AI infrastructure, powering critical systems ranging from Vector Databases to Retrieval-Augmented Generation (RAG). While the GPU-accelerated Inverted File (IVF) index acts as one of the most widely used techniques for these large-scale workloads due to its memory efficiency, its traditional architecture remains fundamentally static. Existing designs rely on rigid and contiguous memory layouts that lack native support for in-place mutation, creating a severe bottleneck for streaming scenarios. In applications requiring real-time knowledge updates, such as live recommendation engines or dynamic RAG systems, maintaining index freshness necessitates expensive CPU-GPU roundtrips that cause system latency to spike from milliseconds to seconds. In this paper, we propose SIVF (Streaming Inverted File), a new GPU-native architecture designed to empower vector databases with high-velocity data ingestion and deletion capabilities. SIVF replaces the static memory layout with a slab-based allocation system and a validity bitmap, enabling lock-free and in-place mutation directly in VRAM. We further introduce a GPU-resident address translation table (ATT) to resolve the overhead of locating vectors, providing $O(1)$ access to physical storage slots. We evaluate SIVF against the industry-standard GPU IVF implementation on the SIFT1M and GIST1M datasets. Microbenchmarks demonstrate that SIVF reduces deletion latency by up to $13,300\times$ (from 11.8 seconds to 0.89 ms on GIST1M) and improves ingestion throughput by $36\times$ to $105\times$. In end-to-end sliding window scenarios, SIVF eliminates system freezes and achieves a $161\times$ to $266\times$ speedup with single-digit millisecond latency. Notably, this performance incurs negligible storage penalty, maintaining less than 0.8\% memory overhead compared to static indices.

</details>


### [457] [Is Quantum Computing Ready for Real-Time Database Optimization?](https://arxiv.org/abs/2601.12123)
*Hanwen Liu,Ibrahim Sabek*

Main category: cs.DB

TL;DR: Q2O：首个量子增强查询优化器，将连接顺序问题编码为非线性模型，通过低延迟量子求解器求解，并集成到PostgreSQL中实现实时查询优化


<details>
  <summary>Details</summary>
Motivation: 数据库优化问题（如连接顺序、索引调优）随着数据量增长和负载复杂化变得指数级困难。量子计算特别是量子退火能有效探索大规模搜索空间，但早期量子方案因高延迟（如D-Wave CQM-Solver至少5秒）难以实际集成到数据库系统中。最近低延迟量子求解器（如NL-Solver）的出现为实际集成提供了可能，但需要在效率和解决方案质量之间找到平衡。

Method: 提出Q2O量子增强查询优化器：1）将连接顺序问题编码为非线性模型（NL-Solver可解格式），使用实际数据库统计信息；2）通过低延迟量子求解器（NL-Solver）求解；3）将量子求解结果转换为计划提示，指导PostgreSQL优化器生成完整执行计划；4）实现端到端工作流，能够实时处理实际查询。

Result: Q2O是首个实际可用的量子增强查询优化器，能够在效率和解决方案质量之间取得平衡。它成功将量子计算集成到数据库系统中，利用低延迟量子求解器实时处理实际查询，为量子计算在数据库优化领域的实际应用提供了概念验证。

Conclusion: 量子计算与数据库系统的实际集成是可行的。通过使用低延迟量子求解器和适当的系统设计，可以在保持效率的同时获得高质量的优化解决方案。Q2O展示了量子增强数据库优化的实际可能性，为未来量子计算在数据库系统中的应用开辟了新道路。

Abstract: Database systems encompass several performance-critical optimization tasks, such as join ordering and index tuning. As data volumes grow and workloads become more complex, these problems have become exponentially harder to solve efficiently. Quantum computing, especially quantum annealing, is a promising paradigm that can efficiently explore very large search spaces through quantum tunneling. It can escape local optima by tunneling through energy barriers rather than climbing over them. Earlier works mainly focused on providing an abstract representation (e.g., Quadratic Unconstrained Binary Optimization (QUBO)) for the database optimization problems (e.g., join order) and overlooked the real integration within database systems due to the high overhead of quantum computing services (e.g., a minimum 5s runtime for D-Wave's CQM-Solver). Recently, quantum annealing providers have offered more low-latency solutions, e.g., NL-Solver, which paves the road to actually realizing quantum solutions within DBMSs. However, this raises new systems research challenges in balancing efficiency and solution quality.
  In this talk, we show that this balance is possible to achieve. As a proof of concept, we present Q2O, the first real Quantum-augmented Query Optimizer. We show the end-to-end workflow: we encode the join order problem as a nonlinear model, a format solvable by the NL-Solver, using actual database statistics; the solution is translated into a plan hint that guides PostgreSQL's optimizer to produce a complete plan. Q2O is capable of handling actual queries in real time.

</details>


### [458] [RLMiner: Finding the Most Frequent k-sized Subgraph via Reinforcement Learning](https://arxiv.org/abs/2601.12416)
*Wei Huang,Hanchen Wang,Dong Wen,Xin Cao,Ying Zhang,Wenjie Zhang*

Main category: cs.DB

TL;DR: RLMiner：基于强化学习和图神经网络的多任务框架，用于高效发现图中最频繁的k-size诱导子图，时间复杂度仅为O(k)


<details>
  <summary>Details</summary>
Motivation: 识别图中最频繁的k-size诱导子图是图挖掘的基础问题，对Web数据挖掘和社交网络分析至关重要。但由于子图计数是NP难问题，传统精确枚举算法时间复杂度高，现有方法使用向下闭包属性减少搜索空间但引入额外约束。

Method: 将任务建模为马尔可夫决策过程，采用多任务强化学习框架。提出RLMiner框架，结合强化学习和任务状态感知的图神经网络，时间复杂度与k呈线性关系。

Result: 在真实数据集上的实验表明，RLMiner能有效识别频率接近真实最频繁诱导子图的子图，同时相比传统方法运行时间显著缩短且更稳定。

Conclusion: RLMiner通过强化学习与图神经网络的结合，为解决最频繁诱导子图发现问题提供了一种高效且准确的新方法，克服了传统方法的高计算复杂度问题。

Abstract: Identifying the most frequent induced subgraph of size $k$ in a target graph is a fundamental graph mining problem with direct implications for Web-related data mining and social network analysis. Despite its importance, finding the most frequent induced subgraph remains computationally expensive due to the NP-hard nature of the subgraph counting task. Traditional exact enumeration algorithms often suffer from high time complexity, especially for a large graph size $k$. To mitigate this, existing approaches often utilize frequency measurement with the Downward Closure Property to reduce the search space, imposing additional constraints on the task. In this paper, we first formulate this task as a Markov Decision Process and approach it using a multi-task reinforcement learning framework. Specifically, we introduce RLMiner, a novel framework that integrates reinforcement learning with our proposed task-state-aware Graph Neural Network to find the most frequent induced subgraph of size $k$ with a time complexity linear to $k$. Extensive experiments on real-world datasets demonstrate that our proposed RLMiner effectively identifies subgraphs with frequencies closely matching the ground-truth most frequent induced subgraphs, while achieving significantly shorter and more stable running times compared to traditional methods.

</details>


### [459] [Bringing Data Transformations Near-Memory for Low-Latency Analytics in HTAP Environments](https://arxiv.org/abs/2601.12456)
*Arthur Bernhardt,David Volz,Sajjad Tamimi,Andreas Koch,Ilia Petrov*

Main category: cs.DB

TL;DR: 提出在智能存储系统上近存储或存内执行数据转换的方法，避免传统提取-转换模式的数据移动开销


<details>
  <summary>Details</summary>
Motivation: 当前主流的数据提取后转换方法存在性能下降和大量数据移动问题，需要更高效的数据处理方式

Method: 在智能存储系统上实现近存储或存内数据转换，减少数据提取和移动

Result: 展示稳健的前台工作负载性能和更低的资源争用

Conclusion: 该方法为多引擎、多系统架构以及重用提供了新的架构机会

Abstract: In this paper we propose an approach for executing data transformations near- or in-storage on intelligent storage systems. The currently prevailing approach of extracting the data and then transforming it to a target format suffers degraded performance during transformation and causes heavy data movement. Our results show robust performance of foreground workloads and lower resource contention. Our vision draws architectural opportunities in multi-engine and multi-system settings, as well as for reuse.

</details>


### [460] [xBound: Join Size Lower Bounds](https://arxiv.org/abs/2601.13117)
*Mihail Stoian,Tiemo Bang,Hangdong Zhao,Jesús Camacho-Rodríguez,Yuanyuan Tian,Andreas Kipf*

Main category: cs.DB

TL;DR: xBound是首个推导可证明连接大小下界的框架，旨在解决查询优化中更危险的基数低估问题，显著减少实际系统中的低估错误。


<details>
  <summary>Details</summary>
Motivation: 基数估计是查询优化的核心，但现有系统普遍存在严重低估问题。基数低估比高估更危险，因为它误导优化器选择为小数据设计的执行计划，导致CPU和内存资源不足。现有悲观基数估计方法只能修正高估问题，无法解决更严重的高估问题。

Method: 提出xBound框架，这是首个推导可证明连接大小下界的方法。该方法能够为连接操作提供理论保证的下界估计，从而纠正基数低估问题。

Result: 在JOBlight基准测试中，xBound修正了DuckDB中17.5%和PostgreSQL中8.7%的子表达式低估；在微软企业工作负载中，修正了Fabric Data Warehouse中36.1%的低估，显著改善了基数估计准确性。

Conclusion: xBound框架为解决查询优化中长期存在的基数低估问题迈出了重要一步，通过提供可证明的连接大小下界，有效减少了实际数据库系统中的低估错误。

Abstract: Cloud database vendors invest substantial resources into their query optimizers, and for good reason. Cardinality estimation, a cornerstone of the optimizer, is critical for the selection of efficient query plans, as well as downstream tasks such as resource allocation and query scheduling. Yet, as many practitioners and researchers have noted, it is also the optimizer's Achilles heel. Prior studies on a number of industrial-strength databases show substantial cardinality estimation errors on all tested systems, with a far greater tendency to underestimate than to overestimate. Unfortunately, cardinality underestimation is more problematic than overestimation, as it misleads the optimizer to choose plans designed for small data, leading to underprovisioned CPU and memory.
  While previous work on pessimistic cardinality estimation has proposed provable join size upper bounds, such methods can only correct overestimation, leaving the more harmful problem of underestimation unaddressed. To fill this critical gap, we introduce xBound, the very first framework for deriving provable join size lower bounds. xBound successfully reduces underestimation in real systems: On the JOBlight benchmark, it corrects 17.5% of subexpression underestimates in DuckDB and 8.7% in PostgreSQL, while on a Microsoft enterprise workload, it fixes 36.1% of Fabric Data Warehouse's underestimates, demonstrating a significant step towards solving this long-standing problem.

</details>


### [461] [A Distributed Spatial Data Warehouse for AIS Data (DIPAAL)](https://arxiv.org/abs/2601.13795)
*Alex S. Klitgaard,Lau E. Josefsen,Mikael V. Mikkelsen,Kristian Torp*

Main category: cs.DB

TL;DR: 本文提出一个用于船舶AIS数据处理和分析的系统，包含高效模块化ETL流程和分布式空间数据仓库，采用栅格化查询方法，存储了约3.12亿公里轨迹数据，验证了单元表示比轨迹表示搜索更快，空间分区能实现良好扩展性。


<details>
  <summary>Details</summary>
Motivation: 船舶AIS数据虽然对分析单船运动和区域监控很有价值，但原始数据需要经过清洗、处理和存储才能使用。现有方法在处理大规模AIS数据时面临效率和可扩展性挑战。

Method: 1. 设计高效模块化的ETL流程加载AIS数据；2. 构建分布式空间数据仓库存储船舶轨迹；3. 提出栅格化查询方法，采用空间分区和细粒度单元表示；4. 实现热图可视化展示。

Result: 系统存储了约3.12亿公里船舶轨迹和超过80亿行数据。单元表示搜索速度优于轨迹表示。空间分区在5倍工作节点增加时，单元和热图分析性能提升354%到1164%，显示良好扩展性。

Conclusion: 提出的系统能有效处理大规模AIS数据，栅格化方法和空间分区数据仓库设计显著提高了查询效率和系统可扩展性，为大规模船舶运动分析提供了实用解决方案。

Abstract: AIS data from ships is excellent for analyzing single-ship movements and monitoring all ships within a specific area. However, the AIS data needs to be cleaned, processed, and stored before being usable. This paper presents a system consisting of an efficient and modular ETL process for loading AIS data, as well as a distributed spatial data warehouse storing the trajectories of ships. To efficiently analyze a large set of ships, a raster approach to querying the AIS data is proposed. A spatially partitioned data warehouse with a granularized cell representation and heatmap presentation is designed, developed, and evaluated. Currently the data warehouse stores ~312 million kilometers of ship trajectories and more than +8 billion rows in the largest table. It is found that searching the cell representation is faster than searching the trajectory representation. Further, we show that the spatially divided shards enable a consistently good scale-up for both cell and heatmap analytics in large areas, ranging between 354% to 1164% with a 5x increase in workers

</details>


### [462] [TLSQL: Table Learning Structured Query Language](https://arxiv.org/abs/2601.14109)
*Feiyang Chen,Ken Zhong,Aoqian Zhang,Zheng Wang,Li Pan,Jianhua Li*

Main category: cs.DB

TL;DR: TLSQL是一个通过类SQL声明式语言直接在关系数据库上进行表格学习的系统，无需显式数据导出和复杂特征工程。


<details>
  <summary>Details</summary>
Motivation: 现有表格学习框架通常需要显式数据导出和大量特征工程，给数据库从业者设置了较高门槛，阻碍了机器学习与数据库系统的集成。

Method: TLSQL作为轻量级Python库，将类SQL声明式规范转换为标准SQL查询和结构化学习任务描述。SQL查询由数据库引擎原生执行，任务描述由下游表格学习框架使用。

Result: 在真实世界数据集上的实验表明，TLSQL有效降低了将机器学习集成到数据库中心工作流的门槛。

Conclusion: TLSQL通过声明式规范让用户专注于建模和分析，而非底层数据准备和管道编排，促进了机器学习与数据库系统的无缝集成。

Abstract: Table learning, which lies at the intersection of machine learning and modern database systems, has recently attracted growing attention. However, existing frameworks typically require explicit data export and extensive feature engineering, creating a high barrier for database practitioners. We present TLSQL (Table Learning Structured Query Language), a system that enables table learning directly over relational databases via SQL-like declarative specifications. TLSQL is implemented as a lightweight Python library that translates these specifications into standard SQL queries and structured learning task descriptions. The generated SQL queries are executed natively by the database engine, while the task descriptions are consumed by downstream table learning frameworks. This design allows users to focus on modeling and analysis rather than low-level data preparation and pipeline orchestration. Experiments on real-world datasets demonstrate that TLSQL effectively lowers the barrier to integrating machine learning into databasecentric workflows. Our code is available at https://github.com/rllmproject/tlsql/.

</details>


### [463] [ReSearch: A Multi-Stage Machine Learning Framework for Earth Science Data Discovery](https://arxiv.org/abs/2601.14176)
*Youran Sun,Yixin Wen,Haizhao Yang*

Main category: cs.DB

TL;DR: ReSearch是一个多阶段推理增强搜索框架，通过意图解释、高召回检索和上下文感知排序来解决地球科学数据发现瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 地球科学数据（卫星观测、再分析产品、数值模拟）快速增长导致科学发现面临瓶颈：难以根据研究目标识别相关数据集。现有发现系统主要是检索中心化的，难以在高层科学意图和异构元数据之间建立桥梁。

Method: ReSearch是一个多阶段推理增强搜索框架，将地球科学数据发现制定为迭代过程：意图解释、高召回检索、上下文感知排序。整合了词汇搜索、语义嵌入、缩写扩展和大语言模型重排序，在统一架构中明确分离召回和精度目标。

Result: 实验表明，ReSearch在基线方法基础上持续改进召回和排序性能，特别是对于表达抽象科学目标的任务型查询。构建了基于文献的基准测试，将自然语言意图与同行评审地球科学研究中引用的数据集对齐。

Conclusion: 结果强调了意图感知、多阶段搜索作为可重复和可扩展地球科学研究基础能力的重要性。ReSearch框架为解决地球科学数据发现瓶颈提供了有效解决方案。

Abstract: The rapid expansion of Earth Science data from satellite observations, reanalysis products, and numerical simulations has created a critical bottleneck in scientific discovery, namely identifying relevant datasets for a given research objective.
  Existing discovery systems are primarily retrieval-centric and struggle to bridge the gap between high-level scientific intent and heterogeneous metadata at scale.
  We introduce \textbf{ReSearch}, a multi-stage, reasoning-enhanced search framework that formulates Earth Science data discovery as an iterative process of intent interpretation, high-recall retrieval, and context-aware ranking.
  ReSearch integrates lexical search, semantic embeddings, abbreviation expansion, and large language model reranking within a unified architecture that explicitly separates recall and precision objectives.
  To enable realistic evaluation, we construct a literature-grounded benchmark by aligning natural language intent with datasets cited in peer-reviewed Earth Science studies.
  Experiments demonstrate that ReSearch consistently improves recall and ranking performance over baseline methods, particularly for task-based queries expressing abstract scientific goals.
  These results underscore the importance of intent-aware, multi-stage search as a foundational capability for reproducible and scalable Earth Science research.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [464] [MIMIC-RD: Can LLMs differentially diagnose rare diseases in real-world clinical settings?](https://arxiv.org/abs/2601.11559)
*Zilal Eiz AlDin,John Wu,Jeffrey Paul Fung,Jennifer King,Mya Watts,Lauren ONeill,Adam Richard Cross,Jimeng Sun*

Main category: cs.AI

TL;DR: 本文提出了MIMIC-RD基准，通过将临床文本实体直接映射到Orphanet罕见病数据库来评估LLM在罕见病鉴别诊断中的表现，发现当前最先进LLM表现不佳。


<details>
  <summary>Details</summary>
Motivation: 罕见病影响10%的美国人，但其鉴别诊断仍然具有挑战性。现有评估LLM罕见病诊断的方法存在两个关键局限：依赖理想化临床案例研究，无法捕捉真实临床复杂性；或使用ICD代码作为疾病标签，由于许多罕见病缺乏与Orphanet等综合罕见病数据库的直接映射而显著低估罕见病。

Method: 开发MIMIC-RD罕见病鉴别诊断基准，通过LLM挖掘初步识别临床文本实体，然后由四名医学标注者验证确认识别的实体是真正的罕见病，将临床文本实体直接映射到Orphanet数据库。在145名患者的数据集上评估各种模型。

Result: 当前最先进的大型语言模型在罕见病鉴别诊断方面表现不佳，突显出现有能力与临床需求之间的巨大差距。

Conclusion: 需要改进罕见病鉴别诊断方法，论文概述了未来改进的几个方向。

Abstract: Despite rare diseases affecting 1 in 10 Americans, their differential diagnosis remains challenging. Due to their impressive recall abilities, large language models (LLMs) have been recently explored for differential diagnosis. Existing approaches to evaluating LLM-based rare disease diagnosis suffer from two critical limitations: they rely on idealized clinical case studies that fail to capture real-world clinical complexity, or they use ICD codes as disease labels, which significantly undercounts rare diseases since many lack direct mappings to comprehensive rare disease databases like Orphanet. To address these limitations, we explore MIMIC-RD, a rare disease differential diagnosis benchmark constructed by directly mapping clinical text entities to Orphanet. Our methodology involved an initial LLM-based mining process followed by validation from four medical annotators to confirm identified entities were genuine rare diseases. We evaluated various models on our dataset of 145 patients and found that current state-of-the-art LLMs perform poorly on rare disease differential diagnosis, highlighting the substantial gap between existing capabilities and clinical needs. From our findings, we outline several future steps towards improving differential diagnosis of rare diseases.

</details>


### [465] [A Mind Cannot Be Smeared Across Time](https://arxiv.org/abs/2601.11620)
*Michael Timothy Bennett*

Main category: cs.AI

TL;DR: 论文认为机器意识不仅取决于计算内容，还取决于计算时机。顺序或时间复用系统无法实现意识所需的同步性，硬件架构对意识至关重要。


<details>
  <summary>Details</summary>
Motivation: 现有AI系统通常采用顺序或时间复用更新，而意识体验呈现统一和同步性。这种时间特性差异可能对机器能否拥有意识产生根本影响。

Method: 扩展栈理论，引入时间窗口约束满足的代数定律。定义精确的时间语义τ^{Δ,s}，证明存在性时间实现◇_Δ不保持合取。区分StrongSync（要求客观共现）和WeakSync（允许时间"涂抹"），形式化并发能力度量。

Result: 系统可以在时间上实现所有体验成分，但从未实例化体验合取本身。神经生理学证据支持StrongSync，表明意识依赖于相位同步和有效连接。在严格顺序基底上实现需要两个以上同时贡献者的意识内容是不可能的。

Conclusion: 意识归因需要架构检查而不仅仅是功能表现。硬件架构对意识至关重要，特别是需要同时贡献的内容越多，所需的并发能力就越大。

Abstract: Whether machines can be conscious depends not only on what they compute, but \emph{when} they compute it. Most deployed artificial systems realise their functions via sequential or time-multiplexed updates. Conscious experience appears unified and simultaneous. I show that this difference matters formally. I augment Stack Theory with algebraic laws relating within time-window constraint satisfaction to conjunction. I introduce a precise temporal semantics over windowed trajectories $τ^{Δ,s}$ and prove that existential temporal realisation $\Diamond_Δ$ does not preserve conjunction. A system can realise all the ingredients of experience across time without ever instantiating the experienced conjunction itself. I then distinguish two postulates. StrongSync requires objective co-instantiation of the grounded conjunction within the window, while WeakSync permits temporal ``smearing''. I formalise concurrency-capacity to measure what is needed to satisfy StrongSync. Finally, I review neurophysiological evidence suggesting that consciousness depends on phase synchrony and effective connectivity, and that loss of consciousness is often associated with its breakdown. This evidence makes WeakSync less plausible. Under StrongSync, software consciousness on strictly sequential substrates is impossible for contents whose grounding requires two or more simultaneous contributors. The more parts from which simultaneous contribution required, the more concurrency capacity is required. The hardware matters. Consciousness attribution therefore requires architectural inspection, not just functional performance.

</details>


### [466] [Dynamical Systems Analysis Reveals Functional Regimes in Large Language Models](https://arxiv.org/abs/2601.11622)
*Hassan Ugail,Newton Howard*

Main category: cs.AI

TL;DR: 该研究将神经科学中的时间整合和亚稳态概念应用于Transformer模型，提出一种复合动力学指标来量化LLM在文本生成过程中的时间组织差异，发现结构化推理任务展现出显著更高的动力学复杂度。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型通过高维内部动力学进行文本生成，但这些动力学的时间组织结构仍未被充分理解。现有可解释性方法多关注静态表示或因果干预，忽略了时间结构。研究者希望借鉴神经科学中时间整合和亚稳态等概念来填补这一空白。

Method: 将神经科学中的时间整合和亚稳态概念适配到Transformer模型，提出一种基于自回归生成过程中激活时间序列计算的复合动力学指标。在GPT-2-medium模型上评估该指标，涵盖五种条件：结构化推理、强制重复、高温噪声采样、注意力头剪枝和权重噪声注入。

Result: 结构化推理任务相比重复、噪声和扰动机制展现出显著更高的动力学指标。通过单因素方差分析和效应量检验确认了统计显著性差异。结果对层选择、通道子采样和随机种子具有鲁棒性。

Conclusion: 神经科学启发的动力学指标能够可靠地表征大语言模型在不同功能机制下的计算组织差异。该指标捕捉的是形式化的动力学特性，不暗示主观体验。

Abstract: Large language models perform text generation through high-dimensional internal dynamics, yet the temporal organisation of these dynamics remains poorly understood. Most interpretability approaches emphasise static representations or causal interventions, leaving temporal structure largely unexplored. Drawing on neuroscience, where temporal integration and metastability are core markers of neural organisation, we adapt these concepts to transformer models and discuss a composite dynamical metric, computed from activation time-series during autoregressive generation. We evaluate this metric in GPT-2-medium across five conditions: structured reasoning, forced repetition, high-temperature noisy sampling, attention-head pruning, and weight-noise injection. Structured reasoning consistently exhibits elevated metric relative to repetitive, noisy, and perturbed regimes, with statistically significant differences confirmed by one-way ANOVA and large effect sizes in key comparisons. These results are robust to layer selection, channel subsampling, and random seeds. Our findings demonstrate that neuroscience-inspired dynamical metrics can reliably characterise differences in computational organisation across functional regimes in large language models. We stress that the proposed metric captures formal dynamical properties and does not imply subjective experience.

</details>


### [467] [Reasoning Stabilization Point: A Training-Time Signal for Stable Evidence and Shortcut Reliance](https://arxiv.org/abs/2601.11625)
*Sahil Rajesh Dhayalkar*

Main category: cs.AI

TL;DR: 论文提出了一种训练时解释性方法，通过跟踪微调过程中token级归因的变化来监控模型决策证据的演变，并引入了"推理稳定点"概念。


<details>
  <summary>Details</summary>
Motivation: 预训练语言模型微调虽然能提升任务性能，但会微妙地改变模型依赖的证据。需要一种方法来监控微调过程中模型决策依据如何演变，特别是在模型可能依赖捷径特征的情况下。

Method: 提出"解释漂移"概念，定义为固定探测集上归一化token归因的逐轮次变化。引入"推理稳定点"，即漂移首次进入并持续保持低稳定状态的最早轮次。该方法仅需训练过程中的漂移动态，无需在分布外数据上调整。

Result: 在多个轻量级Transformer分类器和基准分类任务中，漂移通常在训练早期就进入低稳定状态，而验证准确率仅发生微小变化。在受控的捷径设置中，归因动态揭示了模型对捷径的依赖增加，即使验证准确率保持竞争力。

Conclusion: 解释漂移提供了一种简单、低成本的诊断工具，可用于监控微调过程中决策证据的演变，并选择处于稳定证据状态的检查点。

Abstract: Fine-tuning pretrained language models can improve task performance while subtly altering the evidence a model relies on. We propose a training-time interpretability view that tracks token-level attributions across finetuning epochs. We define explanation driftas the epoch-to-epoch change in normalized token attributions on a fixed probe set, and introduce the Reasoning Stabilization Point(RSP), the earliest epoch after which drift remains consistently low. RSP is computed from within-run drift dynamics and requires no tuning on out-of-distribution data. Across multiple lightweight transformer classifiers and benchmark classification tasks, drift typically collapses into a low, stable regime early in training, while validation accuracy continues to change only marginally. In a controlled shortcut setting with label-correlated trigger tokens, attribution dynamics expose increasing reliance on the shortcut even when validation accuracy remains competitive. Overall, explanation drift provides a simple, low-cost diagnostic for monitoring how decision evidence evolves during fine-tuning and for selecting checkpoints in a stable-evidence regime.

</details>


### [468] [PRISM: Learning Design Knowledge from Data for Stylistic Design Improvement](https://arxiv.org/abs/2601.11747)
*Huaxiaoyue Wang,Sunav Choudhary,Franck Dernoncourt,Yu Shen,Stefano Petrangeli*

Main category: cs.AI

TL;DR: PRISM利用设计数据构建知识库，通过聚类、总结和检索三个步骤实现基于自然语言指令的图形设计风格改进，在风格对齐和用户偏好方面优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 非专业人士在探索不同设计风格方向时耗时耗力，现有视觉语言模型(VLMs)的风格知识过于通用，与具体设计领域数据不匹配，需要更专业的设计知识来指导风格改进。

Method: PRISM通过三个阶段构建和应用设计知识库：1) 对高方差设计进行聚类以捕捉风格多样性；2) 将每个聚类总结为可操作的设计知识；3) 在推理时检索相关知识实现风格感知的改进。

Result: 在Crello数据集上，PRISM获得了1.49的平均排名（越接近1越好），在风格对齐方面优于基线方法。用户研究进一步验证了设计师对PRISM的一致偏好。

Conclusion: 利用真实设计数据构建知识库能有效捕捉设计师原则，显著提升基于自然语言指令的风格改进质量，为图形设计自动化提供了有前景的方向。

Abstract: Graphic design often involves exploring different stylistic directions, which can be time-consuming for non-experts. We address this problem of stylistically improving designs based on natural language instructions. While VLMs have shown initial success in graphic design, their pretrained knowledge on styles is often too general and misaligned with specific domain data. For example, VLMs may associate minimalism with abstract designs, whereas designers emphasize shape and color choices. Our key insight is to leverage design data -- a collection of real-world designs that implicitly capture designer's principles -- to learn design knowledge and guide stylistic improvement. We propose PRISM (PRior-Informed Stylistic Modification) that constructs and applies a design knowledge base through three stages: (1) clustering high-variance designs to capture diversity within a style, (2) summarizing each cluster into actionable design knowledge, and (3) retrieving relevant knowledge during inference to enable style-aware improvement. Experiments on the Crello dataset show that PRISM achieves the highest average rank of 1.49 (closer to 1 is better) over baselines in style alignment. User studies further validate these results, showing that PRISM is consistently preferred by designers.

</details>


### [469] [Risk-Aware Human-in-the-Loop Framework with Adaptive Intrusion Response for Autonomous Vehicles](https://arxiv.org/abs/2601.11781)
*Dawood Wasif,Terrence J. Moore,Seunghyun Yoon,Hyuk Lim,Dan Dongseong Kim,Frederica F. Nelson,Jin-Hee Cho*

Main category: cs.AI

TL;DR: RAIL是一个风险感知的人机协同框架，通过融合多种运行时信号生成入侵风险评分，实现自适应控制和聚焦学习，在自动驾驶中有效应对长尾场景和网络物理入侵。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆在遇到罕见的长尾场景或网络物理入侵时，必须保持安全和有效性。现有方法在处理这些复杂风险场景时存在局限性，需要一种能够动态适应风险并整合人类干预的框架。

Method: RAIL框架融合三种信号（曲率执行完整性、碰撞时间接近度、观测偏移一致性）通过加权Noisy-OR生成入侵风险评分（IRS）。当IRS超过阈值时，通过学习的权限将动作与特定线索的防护层混合，同时保留人类覆盖控制；风险低时执行名义策略。使用上下文老虎机根据线索向量仲裁不同防护层，在线改进缓解选择。将Soft Actor-Critic与风险优先重放和双重奖励相结合，使接管和接近碰撞事件引导学习，同时覆盖名义行为。

Result: 在MetaDrive上，RAIL获得测试回报360.65，测试成功率0.85，测试安全违规0.75，干扰率0.0027，仅记录29.07个训练安全违规，优于RL、安全RL、离线/模仿学习和先前的人机协同基线。在CAN注入和LiDAR欺骗攻击下，成功率分别提升至0.68和0.80，攻击下脱离率降至0.37和0.03，攻击成功率降至0.34和0.11。在CARLA中，仅用8000步就获得测试回报1609.70和测试成功率0.41。

Conclusion: RAIL框架通过风险感知的人机协同方法，有效提升了自动驾驶系统在复杂风险场景下的安全性和性能，特别是在应对网络物理攻击和罕见驾驶场景方面表现出色，为安全自动驾驶提供了有前景的解决方案。

Abstract: Autonomous vehicles must remain safe and effective when encountering rare long-tailed scenarios or cyber-physical intrusions during driving. We present RAIL, a risk-aware human-in-the-loop framework that turns heterogeneous runtime signals into calibrated control adaptations and focused learning. RAIL fuses three cues (curvature actuation integrity, time-to-collision proximity, and observation-shift consistency) into an Intrusion Risk Score (IRS) via a weighted Noisy-OR. When IRS exceeds a threshold, actions are blended with a cue-specific shield using a learned authority, while human override remains available; when risk is low, the nominal policy executes. A contextual bandit arbitrates among shields based on the cue vector, improving mitigation choices online. RAIL couples Soft Actor-Critic (SAC) with risk-prioritized replay and dual rewards so that takeovers and near misses steer learning while nominal behavior remains covered. On MetaDrive, RAIL achieves a Test Return (TR) of 360.65, a Test Success Rate (TSR) of 0.85, a Test Safety Violation (TSV) of 0.75, and a Disturbance Rate (DR) of 0.0027, while logging only 29.07 training safety violations, outperforming RL, safe RL, offline/imitation learning, and prior HITL baselines. Under Controller Area Network (CAN) injection and LiDAR spoofing attacks, it improves Success Rate (SR) to 0.68 and 0.80, lowers the Disengagement Rate under Attack (DRA) to 0.37 and 0.03, and reduces the Attack Success Rate (ASR) to 0.34 and 0.11. In CARLA, RAIL attains a TR of 1609.70 and TSR of 0.41 with only 8000 steps.

</details>


### [470] [A self-evolving multi-role collaborative framework with fine-grained difficulty guidance for innovative mathematical problem generation](https://arxiv.org/abs/2601.11792)
*Yifei Sun,Yongan Li,A. K. Qin,Sicheng Hou,Tamas Pflanzner*

Main category: cs.AI

TL;DR: 提出创新数学题生成任务(IMPG)，采用自进化多角色协作框架，通过细粒度难度指导和改进难度模型，结合多阶段训练流程，显著提升生成题目的创新性同时保持高正确率。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在数学题生成任务中虽然正确率高，但缺乏创新性和区分度，因此需要开发能够生成创新性数学题目的新方法。

Method: 提出自进化多角色协作框架，包含采样器、生成器、评估器、状态机和记忆模块；引入改进难度模型进行细粒度指导；采用数据驱动关联引导路径采样算法；构建HSM3K-CN数据集；采用多阶段训练流程（持续预训练、监督微调、组相对策略优化）；通过蒸馏实现系统自进化。

Result: 相比基线模型，该方法显著提高了生成题目的创新性，同时保持了高正确率。

Conclusion: 提出的自进化多角色协作框架能够有效解决创新数学题生成任务，在保持正确率的同时显著提升题目的创新性，为智能教育领域的数学题生成提供了新方法。

Abstract: Mathematical problem generation (MPG) is a significant research direction in the field of intelligent education. In recent years, the rapid development of large language models (LLMs) has enabled new technological approaches to problem-generation tasks. Although existing LLMs can achieve high correctness rates, they generally lack innovation and exhibit poor discrimination. In this paper, we propose the task of innovative math problem generation (IMPG). To solve the IMPG task, this paper proposes a self-evolving, multi-role collaborative framework with fine-grained difficulty guidance. First, a multi-role collaborative mechanism comprising a sampler, generator, evaluator, state machine, and memory is constructed, ensuring the correctness of generated problems through iterative optimization informed by self-assessment and external feedback. Second, we introduce an improved difficulty model to quantify difficulty and provide fine-grained guidance. We adopt the data-driven association-guided path sampling (DAPS) algorithm to enhance the semantic rationality of sampled encodings. Third, we construct the HSM3K-CN dataset, which comprises high-quality high school math problems. A multi-stage training pipeline is adopted, incorporating continual pre-training (CPT), supervised fine-tuning (SFT), and group relative policy optimization (GRPO), to enhance the generation and evaluation capabilities of the base model. Finally, system self-evolution is achieved by transferring evaluation capabilities from the expert model to the apprentice model via distillation. Experiments show that, compared to baseline models, our proposed method significantly improves the innovation of the generated problems while maintaining a high correctness rate.

</details>


### [471] [Multi-agent DRL-based Lane Change Decision Model for Cooperative Planning in Mixed Traffic](https://arxiv.org/abs/2601.11809)
*Zeyu Mu,Shangtong Zhang,B. Brian Park*

Main category: cs.AI

TL;DR: 提出基于CNN-QMIX的混合多智能体车道变换决策模型，提高CAV参与协同编队率，解决CAV部署初期稀疏分布问题


<details>
  <summary>Details</summary>
Motivation: 在CAV部署初期，CAV在人类驾驶车辆中的稀疏分布降低了形成有效协同编队的可能性，需要提高CAV参与协同编队的比例以最大化其效益

Method: 采用QMIX框架结合卷积神经网络处理交通数据（CNN-QMIX），设计轨迹规划器和模型预测控制器，确保平滑安全的车道变换执行

Result: 该模型能有效处理动态变化的交通智能体数量，显著优于基于规则的基线模型，将协同编队率提升高达26.2%

Conclusion: 提出的CNN-QMIX模型能优化CAV在部署初期的协同合作和交通动态，为混合交通环境下的协同编队提供有效解决方案

Abstract: Connected automated vehicles (CAVs) possess the ability to communicate and coordinate with one another, enabling cooperative platooning that enhances both energy efficiency and traffic flow. However, during the initial stage of CAV deployment, the sparse distribution of CAVs among human-driven vehicles reduces the likelihood of forming effective cooperative platoons. To address this challenge, this study proposes a hybrid multi-agent lane change decision model aimed at increasing CAV participation in cooperative platooning and maximizing its associated benefits. The proposed model employs the QMIX framework, integrating traffic data processed through a convolutional neural network (CNN-QMIX). This architecture addresses a critical issue in dynamic traffic scenarios by enabling CAVs to make optimal decisions irrespective of the varying number of CAVs present in mixed traffic. Additionally, a trajectory planner and a model predictive controller are designed to ensure smooth and safe lane-change execution. The proposed model is trained and evaluated within a microsimulation environment under varying CAV market penetration rates. The results demonstrate that the proposed model efficiently manages fluctuating traffic agent numbers, significantly outperforming the baseline rule-based models. Notably, it enhances cooperative platooning rates up to 26.2\%, showcasing its potential to optimize CAV cooperation and traffic dynamics during the early stage of deployment.

</details>


### [472] [POLARIS: Typed Planning and Governed Execution for Agentic AI in Back-Office Automation](https://arxiv.org/abs/2601.11816)
*Zahra Moslemi,Keerthi Koneru,Yen-Ting Lee,Sheethal Kumar,Ramesh Radhakrishnan*

Main category: cs.AI

TL;DR: POLARIS是一个面向企业后台工作流的治理型LLM智能体编排框架，通过类型化计划合成和验证执行实现可审计、策略对齐的操作自动化。


<details>
  <summary>Details</summary>
Motivation: 企业后台工作流需要可审计、策略对齐且操作可预测的智能体系统，而通用的多智能体设置往往无法满足这些要求。需要一种治理型编排框架来确保自动化过程符合企业策略并保持可追溯性。

Method: POLARIS采用三层架构：1）规划器生成结构多样、类型检查的有向无环图；2）基于评分标准的推理模块选择合规计划；3）执行层通过验证器门控检查、有限修复循环和编译的策略护栏来防护执行过程，在副作用发生前进行阻止或路由。

Result: 在文档中心化财务任务中，POLARIS生成决策级工件和完整执行轨迹，减少人工干预。在SROIE数据集上获得0.81的微F1分数，在受控合成套件中实现0.95-1.00的异常路由精度，同时保持审计追踪。

Conclusion: POLARIS为策略对齐的智能体AI提供了方法论和基准参考，建立了治理型智能体AI的初步基准，展示了在企业自动化中实现可审计、策略合规的智能体系统的可行性。

Abstract: Enterprise back office workflows require agentic systems that are auditable, policy-aligned, and operationally predictable, capabilities that generic multi-agent setups often fail to deliver. We present POLARIS (Policy-Aware LLM Agentic Reasoning for Integrated Systems), a governed orchestration framework that treats automation as typed plan synthesis and validated execution over LLM agents. A planner proposes structurally diverse, type checked directed acyclic graphs (DAGs), a rubric guided reasoning module selects a single compliant plan, and execution is guarded by validator gated checks, a bounded repair loop, and compiled policy guardrails that block or route side effects before they occur. Applied to document centric finance tasks, POLARIS produces decision grade artifacts and full execution traces while reducing human intervention. Empirically, POLARIS achieves a micro F1 of 0.81 on the SROIE dataset and, on a controlled synthetic suite, achieves 0.95 to 1.00 precision for anomaly routing with preserved audit trails. These evaluations constitute an initial benchmark for governed Agentic AI. POLARIS provides a methodological and benchmark reference for policy-aligned Agentic AI. Keywords Agentic AI, Enterprise Automation, Back-Office Tasks, Benchmarks, Governance, Typed Planning, Evaluation

</details>


### [473] [AI Co-Scientist for Knowledge Synthesis in Medical Contexts: A Proof of Concept](https://arxiv.org/abs/2601.11825)
*Arya Rahgozar,Pouria Mortezaagha*

Main category: cs.AI

TL;DR: 开发了一个基于PICOS框架的AI协同科学家平台，用于可扩展、透明的知识合成，通过自动化PICOS合规性检测、研究设计分类、检索增强生成和主题建模来减少生物医学研究浪费。


<details>
  <summary>Details</summary>
Motivation: 生物医学研究中存在研究浪费问题，包括冗余研究、不完整报告以及传统证据合成工作流程的可扩展性有限。需要开发能够提高证据合成可扩展性、透明度和效率的自动化工具。

Method: 构建基于PICOS框架的AI协同科学家平台，整合关系存储、向量语义检索和Neo4j知识图谱。使用Bi-LSTM和基于PubMedBERT的transformer多任务分类器进行PICOS合规性和研究设计分类。采用检索增强生成进行全文合成，结合向量和图检索。使用BERTopic进行主题建模以识别冗余和证据空白。

Result: transformer模型在研究设计分类上达到95.7%准确率，Bi-LSTM在PICOS合规性检测上达到87%准确率。检索增强生成在需要结构化约束、跨研究整合和图推理的查询上优于非检索生成。主题建模揭示了大量主题冗余并识别了未充分探索的研究领域。

Conclusion: PICOS感知和可解释的自然语言处理能够提高证据合成的可扩展性、透明度和效率。该架构是领域无关的，为减少跨生物医学学科的研究浪费提供了实用框架。

Abstract: Research waste in biomedical science is driven by redundant studies, incomplete reporting, and the limited scalability of traditional evidence synthesis workflows. We present an AI co-scientist for scalable and transparent knowledge synthesis based on explicit formalization of Population, Intervention, Comparator, Outcome, and Study design (PICOS). The platform integrates relational storage, vector-based semantic retrieval, and a Neo4j knowledge graph. Evaluation was conducted on dementia-sport and non-communicable disease corpora. Automated PICOS compliance and study design classification from titles and abstracts were performed using a Bidirectional Long Short-Term Memory baseline and a transformer-based multi-task classifier fine-tuned from PubMedBERT. Full-text synthesis employed retrieval-augmented generation with hybrid vector and graph retrieval, while BERTopic was used to identify thematic structure, redundancy, and evidence gaps. The transformer model achieved 95.7% accuracy for study design classification with strong agreement against expert annotations, while the Bi-LSTM achieved 87% accuracy for PICOS compliance detection. Retrieval-augmented generation outperformed non-retrieval generation for queries requiring structured constraints, cross-study integration, and graph-based reasoning, whereas non-retrieval approaches remained competitive for high-level summaries. Topic modeling revealed substantial thematic redundancy and identified underexplored research areas. These results demonstrate that PICOS-aware and explainable natural language processing can improve the scalability, transparency, and efficiency of evidence synthesis. The proposed architecture is domain-agnostic and offers a practical framework for reducing research waste across biomedical disciplines.

</details>


### [474] [Imandra CodeLogician: Neuro-Symbolic Reasoning for Precise Analysis of Software Logic](https://arxiv.org/abs/2601.11840)
*Hongyu Lin,Samer Abdallah,Makar Valentinov,Paul Brennan,Elijah Kagan,Christoph M. Wintersteiger,Denis Ignatovich,Grant Passmore*

Main category: cs.AI

TL;DR: CodeLogician 是一个神经符号代理，结合 LLM 和形式化推理引擎 ImandraX，用于精确分析软件逻辑，在代码逻辑推理基准上相比纯 LLM 方法显著提升 41-47 个百分点。


<details>
  <summary>Details</summary>
Motivation: LLM 在代码理解任务上表现良好，但缺乏对程序行为进行精确、详尽的数学推理能力。现有基准要么专注于与真实软件脱节的数学证明自动化，要么专注于不需要语义严谨性的工程任务。

Method: 提出 CodeLogician 神经符号代理，结合 LLM 和工业级自动推理引擎 ImandraX。LLM 用于构建软件系统的显式形式化模型，然后通过自动推理回答丰富的语义问题，超越简单的二元验证结果。

Result: 在 code-logic-bench 基准测试中，相比纯 LLM 推理，结合 CodeLogician 的形式化增强方法在推理准确性上显著提升，缩小了 41-47 个百分点的差距。

Conclusion: 神经符号集成对于扩展程序分析、实现严格自主的软件理解至关重要，展示了 LLM 与形式化方法结合在软件逻辑推理方面的巨大潜力。

Abstract: Large Language Models (LLMs) have shown strong performance on code understanding tasks, yet they fundamentally lack the ability to perform precise, exhaustive mathematical reasoning about program behavior. Existing benchmarks either focus on mathematical proof automation, largely disconnected from real-world software, or on engineering tasks that do not require semantic rigor.
  We present CodeLogician, a neurosymbolic agent for precise analysis of software logic, integrated with ImandraX, an industrial automated reasoning engine deployed in financial markets and safety-critical systems. Unlike prior approaches that use formal methods primarily to validate LLM outputs, CodeLogician uses LLMs to construct explicit formal models of software systems, enabling automated reasoning to answer rich semantic questions beyond binary verification outcomes.
  To rigorously evaluate mathematical reasoning about software logic, we introduce code-logic-bench, a benchmark targeting the middle ground between theorem proving and software engineering benchmarks. It measures reasoning correctness about program state spaces, control flow, coverage constraints, and edge cases, with ground truth defined via formal modeling and region decomposition.
  Comparing LLM-only reasoning against LLMs augmented with CodeLogician, formal augmentation yields substantial improvements, closing a 41-47 percentage point gap in reasoning accuracy. These results demonstrate that neurosymbolic integration is essential for scaling program analysis toward rigorous, autonomous software understanding.

</details>


### [475] [Human-AI Collaborative Inductive Thematic Analysis: AI Guided Analysis and Human Interpretive Authority](https://arxiv.org/abs/2601.11850)
*Matthew Nyaaba,Min SungEun,Mary Abiswin Apam,Kwame Owoahene Acheampong,Emmanuel Dwamena,Xiaoming Zhai*

Main category: cs.AI

TL;DR: 研究探讨了生成式AI在质性研究中的应用，特别是ITAGPT工具如何支持归纳主题分析，以及人类研究者如何保持解释权威。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI在质性研究中的使用增加，需要探讨分析实践和解释权威的问题，了解AI工具如何支持而非取代人类研究者的分析过程。

Method: 采用HACITA框架，三位经验丰富的质性研究者使用ITAGPT工具分析加纳教师教育背景的访谈转录本，收集交互日志、AI生成表格、研究者修订、反思备忘录等数据。

Result: ITAGPT作为程序性支架，结构化分析流程并增强透明度，但解释权威仍由人类研究者掌握，通过修改、删除、拒绝、插入和评论等分析行动行使判断。

Conclusion: 研究展示了如何通过负责任的人机协作来实施归纳主题分析，AI作为支持工具而非替代品，人类研究者保持核心的解释权威。

Abstract: The increasing use of generative artificial intelligence (GenAI) in qualitative research raises important questions about analytic practice and interpretive authority. This study examines how researchers interact with an Inductive Thematic Analysis GPT (ITA-GPT), a purpose-built AI tool designed to support inductive thematic analysis through structured, semi-automated prompts aligned with reflexive thematic analysis and verbatim coding principles. Guided by a Human-Artificial Intelligence Collaborative Inductive Thematic Analysis (HACITA) framework, the study focuses on analytic process rather than substantive findings. Three experienced qualitative researchers conducted ITA-GPT assisted analyses of interview transcripts from education research in the Ghanaian teacher education context. The tool supported familiarization, verbatim in vivo coding, gerund-based descriptive coding, and theme development, while enforcing trace to text integrity, coverage checks, and auditability. Data sources included interaction logs, AI-generated tables, researcher revisions, deletions, insertions, comments, and reflexive memos. Findings show that ITA-GPT functioned as a procedural scaffold that structured analytic workflow and enhanced transparency. However, interpretive authority remained with human researchers, who exercised judgment through recurrent analytic actions including modification, deletion, rejection, insertion, and commenting. The study demonstrates how inductive thematic analysis is enacted through responsible human AI collaboration.

</details>


### [476] [MyGram: Modality-aware Graph Transformer with Global Distribution for Multi-modal Entity Alignment](https://arxiv.org/abs/2601.11885)
*Zhifei Li,Ziyue Qin,Xiangyu Luo,Xiaoju Hou,Yue Zhao,Miao Zhang,Zhifang Huang,Kui Xiao,Bing Yang*

Main category: cs.AI

TL;DR: MyGram是一个用于多模态实体对齐的模态感知图变换器，通过模态扩散学习模块捕获模态内深层结构上下文信息，并引入Gram Loss实现跨模态全局分布一致性，在多个数据集上优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有多模态实体对齐方法可能忽视每个模态内的结构上下文信息，容易受到浅层特征的干扰，需要更好的方法来整合多模态数据并丰富实体语义表示。

Method: 提出MyGram框架，包含：1) 模态扩散学习模块，捕获模态内深层结构上下文信息并实现细粒度多模态融合；2) Gram Loss，通过最小化多模态特征形成的4维平行多面体体积，实现跨模态全局分布一致性。

Result: 在五个公开数据集上的实验表明，MyGram优于基线模型，在FBDB15K上Hits@1最大提升4.8%，在FBYG15K上提升9.9%，在DBP15K上提升4.3%。

Conclusion: MyGram通过模态扩散学习和Gram Loss有效解决了多模态实体对齐中模态内结构信息捕获和跨模态分布一致性的问题，显著提升了对齐性能。

Abstract: Multi-modal entity alignment aims to identify equivalent entities between two multi-modal Knowledge graphs by integrating multi-modal data, such as images and text, to enrich the semantic representations of entities. However, existing methods may overlook the structural contextual information within each modality, making them vulnerable to interference from shallow features. To address these challenges, we propose MyGram, a modality-aware graph transformer with global distribution for multi-modal entity alignment. Specifically, we develop a modality diffusion learning module to capture deep structural contextual information within modalities and enable fine-grained multi-modal fusion. In addition, we introduce a Gram Loss that acts as a regularization constraint by minimizing the volume of a 4-dimensional parallelotope formed by multi-modal features, thereby achieving global distribution consistency across modalities. We conduct experiments on five public datasets. Results show that MyGram outperforms baseline models, achieving a maximum improvement of 4.8% in Hits@1 on FBDB15K, 9.9% on FBYG15K, and 4.3% on DBP15K.

</details>


### [477] [AEMA: Verifiable Evaluation Framework for Trustworthy and Controlled Agentic LLM Systems](https://arxiv.org/abs/2601.11903)
*YenTing Lee,Keerthi Koneru,Zahra Moslemi,Sheethal Kumar,Ramesh Radhakrishnan*

Main category: cs.AI

TL;DR: AEMA是一个面向企业级多智能体系统的评估框架，通过流程感知和可审计的设计，提供比单一LLM-as-a-Judge更稳定、可追溯的自动化评估方案。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的多智能体系统评估存在局限性：现有方法多为单响应评分或狭窄基准测试，缺乏稳定性、可扩展性和自动化能力，难以满足企业级多智能体系统的评估需求。

Method: 提出AEMA框架，这是一个流程感知、可审计的评估系统，能够在人工监督下规划、执行和聚合异构智能体工作流的多步骤评估，支持可追溯的记录和负责任的自动化。

Result: 在模拟真实业务场景的企业级智能体工作流测试中，AEMA相比单一LLM-as-a-Judge方法，实现了更高的稳定性、更好的人类对齐性，并提供了可追溯的记录支持。

Conclusion: AEMA为基于LLM的多智能体系统提供了一个透明、可复现的负责任评估路径，支持企业级部署中的可靠协调、透明决策和可验证性能评估。

Abstract: Evaluating large language model (LLM)-based multi-agent systems remains a critical challenge, as these systems must exhibit reliable coordination, transparent decision-making, and verifiable performance across evolving tasks. Existing evaluation approaches often limit themselves to single-response scoring or narrow benchmarks, which lack stability, extensibility, and automation when deployed in enterprise settings at multi-agent scale. We present AEMA (Adaptive Evaluation Multi-Agent), a process-aware and auditable framework that plans, executes, and aggregates multi-step evaluations across heterogeneous agentic workflows under human oversight. Compared to a single LLM-as-a-Judge, AEMA achieves greater stability, human alignment, and traceable records that support accountable automation. Our results on enterprise-style agent workflows simulated using realistic business scenarios demonstrate that AEMA provides a transparent and reproducible pathway toward responsible evaluation of LLM-based multi-agent systems.
  Keywords Agentic AI, Multi-Agent Systems, Trustworthy AI, Verifiable Evaluation, Human Oversight

</details>


### [478] [LIBRA: Language Model Informed Bandit Recourse Algorithm for Personalized Treatment Planning](https://arxiv.org/abs/2601.11905)
*Junyu Cao,Ruijiang Gao,Esmaeil Keyvanshokooh,Jianhao Ma*

Main category: cs.AI

TL;DR: 提出一个统一框架，将算法追索、上下文赌博机和大型语言模型结合，用于高风险顺序决策（如个性化医疗）。开发了GLRB算法和LIBRA算法，后者利用LLM领域知识，提供三种理论保证，实验证明优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在高风险顺序决策场景（如个性化医疗）中，需要同时考虑治疗效果和患者特征的可修改性。现有方法缺乏将算法追索、上下文赌博机和LLM知识有效结合的框架，难以平衡统计严谨性和领域知识。

Method: 1. 提出追索赌博机问题，决策者需同时选择治疗行动和患者特征的最小可行修改；2. 开发GLRB（广义线性追索赌博机）算法；3. 提出LIBRA（语言模型知情赌博机追索算法），策略性地结合LLM领域知识和赌博机学习的统计严谨性。

Result: LIBRA提供三种理论保证：1) 热启动保证：当LLM推荐接近最优时显著减少初始遗憾；2) LLM努力保证：算法仅咨询LLM O(log²T)次，确保长期自主性；3) 鲁棒性保证：即使LLM不可靠，性能也不差于纯赌博机算法。实验证明GLRB和LIBRA在遗憾、治疗质量和样本效率上优于标准上下文赌博机和纯LLM基准。

Conclusion: 该研究展示了追索感知、LLM辅助的赌博机算法在高风险个性化决策中的潜力，为LLM与赌博机可信合作提供了有前景的框架，平衡了统计严谨性和领域知识利用。

Abstract: We introduce a unified framework that seamlessly integrates algorithmic recourse, contextual bandits, and large language models (LLMs) to support sequential decision-making in high-stakes settings such as personalized medicine. We first introduce the recourse bandit problem, where a decision-maker must select both a treatment action and a feasible, minimal modification to mutable patient features. To address this problem, we develop the Generalized Linear Recourse Bandit (GLRB) algorithm. Building on this foundation, we propose LIBRA, a Language Model-Informed Bandit Recourse Algorithm that strategically combines domain knowledge from LLMs with the statistical rigor of bandit learning. LIBRA offers three key guarantees: (i) a warm-start guarantee, showing that LIBRA significantly reduces initial regret when LLM recommendations are near-optimal; (ii) an LLM-effort guarantee, proving that the algorithm consults the LLM only $O(\log^2 T)$ times, where $T$ is the time horizon, ensuring long-term autonomy; and (iii) a robustness guarantee, showing that LIBRA never performs worse than a pure bandit algorithm even when the LLM is unreliable. We further establish matching lower bounds that characterize the fundamental difficulty of the recourse bandit problem and demonstrate the near-optimality of our algorithms. Experiments on synthetic environments and a real hypertension-management case study confirm that GLRB and LIBRA improve regret, treatment quality, and sample efficiency compared with standard contextual bandits and LLM-only benchmarks. Our results highlight the promise of recourse-aware, LLM-assisted bandit algorithms for trustworthy LLM-bandits collaboration in personalized high-stakes decision-making.

</details>


### [479] [Thinking Traps in Long Chain-of-Thought: A Measurable Study and Trap-Aware Adaptive Restart](https://arxiv.org/abs/2601.11940)
*Kang Chen,Fan Yu,Junjie Nian,Shihan Zhao,Zhuoka Feng,Zijun Yao,Heng Wang,Minshen Yu,Yixin Cao*

Main category: cs.AI

TL;DR: TAAR框架通过训练诊断策略检测思维陷阱，在推理时截断错误轨迹并自适应重启解码，提升复杂推理任务的性能


<details>
  <summary>Details</summary>
Motivation: 长思维链虽然能增强推理能力，但模型一旦早期做出错误承诺，后续的反思、替代尝试或验证都无法修正根错误，导致思维陷阱。在DAPO-MATH数据集中，89%的失败案例都存在这种陷阱。

Method: 提出TAAR（陷阱感知自适应重启）框架：1）训练诊断策略从部分轨迹中预测两个信号：陷阱截断位置和逃脱概率；2）推理时截断陷阱前的轨迹并自适应重启解码；3）对于严重陷阱情况，应用更强的扰动，包括高温重采样和可选的结构化重启后缀。

Result: 在具有挑战性的数学和科学推理基准测试（AIME24、AIME25、GPQA-Diamond、HMMT25、BRUMO25）上，TAAR在不微调基础模型参数的情况下提高了推理性能。

Conclusion: TAAR框架通过检测和避免思维陷阱，有效解决了长思维链推理中的错误累积问题，为提升复杂推理任务的可靠性提供了新方法。

Abstract: Scaling test-time compute via Long Chain-of-Thought (Long-CoT) significantly enhances reasoning capabilities, yet extended generation does not guarantee correctness: after an early wrong commitment, models may keep elaborating a self-consistent but incorrect prefix. Through fine-grained trajectory analysis, we identify Thinking Traps, prefix-dominant deadlocks where later reflection, alternative attempts, or verification fails to revise the root error. On a curated subset of DAPO-MATH, 89\% of failures exhibit such traps. To solve this problem, we introduce TAAR (Trap-Aware Adaptive Restart), a test-time control framework that trains a diagnostic policy to predict two signals from partial trajectories: a trap index for where to truncate and an escape probability for whether and how strongly to intervene. At inference time, TAAR truncates the trajectory before the predicted trap segment and adaptively restarts decoding; for severely trapped cases, it applies stronger perturbations, including higher-temperature resampling and an optional structured reboot suffix. Experiments on challenging mathematical and scientific reasoning benchmarks (AIME24, AIME25, GPQA-Diamond, HMMT25, BRUMO25) show that TAAR improves reasoning performance without fine-tuning base model parameters.

</details>


### [480] [Learn Like Humans: Use Meta-cognitive Reflection for Efficient Self-Improvement](https://arxiv.org/abs/2601.11974)
*Xinmeng Hou,Peiliang Gong,Bohao Qu,Wuqi Wang,Qing Guo,Yang Liu*

Main category: cs.AI

TL;DR: MARS框架通过单次循环实现高效自我进化，结合原则性反思和程序性反思，显著降低计算成本并提升性能


<details>
  <summary>Details</summary>
Motivation: 当前基于静态人工提示的LLM代理缺乏适应性，现有自我改进框架依赖低效的多轮递归循环，计算成本高昂

Method: 提出MARS框架，模仿人类学习过程，整合原则性反思（抽象规范规则避免错误）和程序性反思（推导逐步成功策略），在单次循环中合成优化指令

Result: 在六个基准测试中，MARS优于最先进的自我进化系统，同时显著降低计算开销

Conclusion: MARS框架通过教育心理学启发的反思机制，实现了高效的系统性推理逻辑优化，为LLM代理的自我进化提供了新方向

Abstract: While Large Language Models (LLMs) enable complex autonomous behavior, current agents remain constrained by static, human-designed prompts that limit adaptability. Existing self-improving frameworks attempt to bridge this gap but typically rely on inefficient, multi-turn recursive loops that incur high computational costs. To address this, we propose Metacognitive Agent Reflective Self-improvement (MARS), a framework that achieves efficient self-evolution within a single recurrence cycle. Inspired by educational psychology, MARS mimics human learning by integrating principle-based reflection (abstracting normative rules to avoid errors) and procedural reflection (deriving step-by-step strategies for success). By synthesizing these insights into optimized instructions, MARS allows agents to systematically refine their reasoning logic without continuous online feedback. Extensive experiments on six benchmarks demonstrate that MARS outperforms state-of-the-art self-evolving systems while significantly reducing computational overhead.

</details>


### [481] [Process In-Context Learning: Enhancing Mathematical Reasoning via Dynamic Demonstration Insertion](https://arxiv.org/abs/2601.11979)
*Ang Gao,Changshuo Zhang,Xiao Zhang,Deyang Li,Minjun Zhao,Fangchao Liu,Xinyu Zhang*

Main category: cs.AI

TL;DR: PICL提出了一种动态演示集成框架，通过实时识别推理过程中的困惑点并插入相关演示来提升数学推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有ICL方法在数学推理等需要逐步逻辑推导的任务中存在局限性，它们使用静态的预选演示，无法适应推理过程中出现的动态困惑点（如模糊计算或逻辑漏洞），这些未解决的困惑点会导致级联错误。

Method: PICL采用两阶段框架：1）通过分析推理过程中的语义和熵来识别潜在困惑点并总结其核心特征；2）在遇到这些困惑点时，从演示池中检索与困惑上下文匹配的相关演示，并将其直接插入到正在进行的推理过程中以指导后续步骤。

Result: 实验表明PICL优于基线方法，通过缓解推理过程中的困惑点，突显了自适应演示插入在复杂数学推理中的价值。

Conclusion: PICL框架通过动态集成演示来响应实时推理需求，有效提升了数学推理任务的性能，证明了自适应演示插入策略在复杂推理任务中的重要性。

Abstract: In-context learning (ICL) has proven highly effective across diverse large language model (LLM) tasks. However, its potential for enhancing tasks that demand step-by-step logical deduction, such as mathematical reasoning, remains underexplored. A core limitation of existing ICL approaches is their static use of demonstrations: examples are pre-selected before inference and remain fixed, failing to adapt to the dynamic confusion points that often arise during multi-step reasoning such as ambiguous calculations or logical gaps. These unresolved confusion points can lead to cascading errors that degrade final accuracy. To tackle this issue, we propose Process In-Context Learning (PICL), a dynamic demonstration integration framework designed to boost mathematical reasoning by responding to real-time inference needs. PICL operates in two stages: 1)~it identifies potential confusion points by analyzing semantics and entropy in the reasoning process and summarizes their core characteristics; 2)~upon encountering these points, it retrieves relevant demonstrations from the demonstration pool that match the confusion context and inserts them directly into the ongoing reasoning process to guide subsequent steps. Experiments show that PICL outperforms baseline methods by mitigating mid-inference confusion, highlighting the value of adaptive demonstration insertion in complex mathematical reasoning.

</details>


### [482] [Kernel-Based Learning of Safety Barriers](https://arxiv.org/abs/2601.12002)
*Oliver Schön,Zhengang Zhong,Sadegh Soudjani*

Main category: cs.AI

TL;DR: 提出一种数据驱动的安全验证与合成方法，针对具有离散时间随机动力学的黑盒系统，利用控制屏障证书概念，通过条件均值嵌入和RKHS模糊集实现分布鲁棒性验证。


<details>
  <summary>Details</summary>
Motivation: AI算法在自动驾驶、医疗等安全关键应用中快速集成，但传统形式化安全验证工具难以处理黑盒AI系统，且缺乏应对现实应用复杂性的灵活性。

Method: 采用数据驱动方法，利用控制屏障证书保证系统安全，从系统轨迹中直接学习证书。使用条件均值嵌入将数据嵌入再生核希尔伯特空间，构建RKHS模糊集以增强对分布外行为的鲁棒性。通过有限傅里叶展开将半无限优化问题转化为线性规划，利用快速傅里叶变换高效生成松弛问题。

Result: 建立了适用于超越安全性的时序逻辑规范的理论框架，提供了可扩展且分布鲁棒的安全验证方法，在包含神经网络控制器的黑盒系统案例研究中验证了有效性。

Conclusion: 该方法突破了系统动力学和不确定性方面的限制性假设，为黑盒AI系统的安全验证提供了可扩展的分布鲁棒框架，能够应对现实应用的复杂性。

Abstract: The rapid integration of AI algorithms in safety-critical applications such as autonomous driving and healthcare is raising significant concerns about the ability to meet stringent safety standards. Traditional tools for formal safety verification struggle with the black-box nature of AI-driven systems and lack the flexibility needed to scale to the complexity of real-world applications. In this paper, we present a data-driven approach for safety verification and synthesis of black-box systems with discrete-time stochastic dynamics. We employ the concept of control barrier certificates, which can guarantee safety of the system, and learn the certificate directly from a set of system trajectories. We use conditional mean embeddings to embed data from the system into a reproducing kernel Hilbert space (RKHS) and construct an RKHS ambiguity set that can be inflated to robustify the result to out-of-distribution behavior. We provide the theoretical results on how to apply the approach to general classes of temporal logic specifications beyond safety. For the data-driven computation of safety barriers, we leverage a finite Fourier expansion to cast a typically intractable semi-infinite optimization problem as a linear program. The resulting spectral barrier allows us to leverage the fast Fourier transform to generate the relaxed problem efficiently, offering a scalable yet distributionally robust framework for verifying safety. Our work moves beyond restrictive assumptions on system dynamics and uncertainty, as demonstrated on two case studies including a black-box system with a neural network controller.

</details>


### [483] [Are LLMs Ready for TOON? Benchmarking Structural Correctness-Sustainability Trade-offs in Novel Structured Output Formats](https://arxiv.org/abs/2601.12014)
*Elio Masciari,Vincenzo Moscato,Enea Vincenzo Napolitano,Gian Marco Orlando,Marco Perillo,Diego Russo*

Main category: cs.AI

TL;DR: 论文提出一个可持续性评估框架，用于衡量LLM结构化输出的环境效率，并引入GCS_env指标综合评估结构正确性和碳排放效率，发现TOON格式虽然更紧凑环保但结构正确性较低。


<details>
  <summary>Details</summary>
Motivation: 当前LLM结构化输出评估主要关注结构正确性，但忽略了不同输出格式在推理过程中的环境影响。需要建立综合考虑环境效率的评估框架。

Method: 提出可持续性评估框架，测量token使用量、生成时间和碳排放估计；引入环境感知生成正确性分数(GCS_env)，统一评估结构正确性和碳感知效率；系统比较TOON格式与传统格式(JSON、XML、YAML)。

Result: TOON格式产生更紧凑的输出和更低的排放，但结构正确性较低（尤其当模型缺乏原生支持时）；增加模型容量可缩小差距；环境感知评分可根据部署优先级改变格式排名。

Conclusion: 需要将可持续性纳入基准测试，紧凑表示如TOON在大规模、碳意识LLM部署中具有实际优势，环境感知评估可帮助平衡正确性和效率。

Abstract: Large Language Models (LLMs) are increasingly required to generate structured, machine-readable outputs for downstream systems. While recent benchmarks have focused on evaluating the structural correctness of such outputs, the environmental impact of inference for different output formats has largely been overlooked. In this paper, we argue that structured output formats should be assessed not only in terms of correctness, but also with respect to their environmental efficiency. To this end, we introduce a sustainability-aware evaluation framework for structured generation that measures token usage, generation time, and estimated carbon emissions. Within this framework, we propose the Environment-Aware Generation Correctness Score (GCS_env), a unified metric that integrates structural correctness with carbon-aware efficiency. Using this framework, we systematically benchmark the novel TOON format against established representations (JSON, XML, YAML) across multiple LLMs spanning different architectures and parameter scales.
  Our results reveal a consistent trade-off: TOON yields markedly more compact outputs and lower emissions, but lower structural correctness when models lack native support. We show that increased model capacity reduces this gap and that environment-aware scoring can shift format rankings depending on deployment priorities. highlighting the need for sustainability-inclusive benchmarking and provides empirical evidence that compact representations such as TOON can offer practical advantages in large-scale, carbon-conscious LLM deployments.

</details>


### [484] [A Multi-Agent System for Generating Actionable Business Advice](https://arxiv.org/abs/2601.12024)
*Kartikey Singh Bhandari,Tanish Jain,Archit Agrawal,Dhruv Kumar,Praveen Kumar,Pratik Narang*

Main category: cs.AI

TL;DR: 提出一个基于LLM的多智能体框架，将大规模用户评论转化为可执行的商业建议，通过聚类、生成、迭代评估和可行性排序等组件，在多个服务领域优于单模型基线。


<details>
  <summary>Details</summary>
Motivation: 现有分析方法（如情感分析、方面提取）主要停留在描述性任务，而LLM生成的建议往往缺乏准确性和深度推理。需要将丰富的用户评论信号转化为可执行的商业建议。

Method: 多智能体LLM框架包含四个组件：1) 聚类选择代表性评论；2) 建议生成；3) 迭代评估；4) 基于可行性的排序。该设计将语料库提炼与反馈驱动的建议优化相结合。

Result: 在三个服务领域和多个模型家族上的实验表明，该框架在可操作性、具体性和非冗余性方面持续优于单模型基线，中等规模模型接近大型模型框架的性能。

Conclusion: 该多智能体框架能够将大规模用户评论转化为具体、可操作且实用的商业建议，为决策支持提供了有效的解决方案。

Abstract: Customer reviews contain rich signals about product weaknesses and unmet user needs, yet existing analytic methods rarely move beyond descriptive tasks such as sentiment analysis or aspect extraction. While large language models (LLMs) can generate free-form suggestions, their outputs often lack accuracy and depth of reasoning. In this paper, we present a multi-agent, LLM-based framework for prescriptive decision support, which transforms large scale review corpora into actionable business advice. The framework integrates four components: clustering to select representative reviews, generation of advices, iterative evaluation, and feasibility based ranking. This design couples corpus distillation with feedback driven advice refinement to produce outputs that are specific, actionable, and practical. Experiments across three service domains and multiple model families show that our framework consistently outperform single model baselines on actionability, specificity, and non-redundancy, with medium sized models approaching the performance of large model frameworks.

</details>


### [485] [ARC: Active and Reflection-driven Context Management for Long-Horizon Information Seeking Agents](https://arxiv.org/abs/2601.12030)
*Yilun Yao,Shan Huang,Elsie Dai,Zhewen Tan,Zhenyu Duan,Shousheng Jia,Yanbing Jiang,Tong Yang*

Main category: cs.AI

TL;DR: ARC是一个主动、反思驱动的上下文管理框架，通过监控和修订来动态重组工作上下文，解决大语言模型在长程信息搜索中的上下文退化问题。


<details>
  <summary>Details</summary>
Motivation: 大语言模型作为研究代理进行深度搜索和长程信息寻求时，随着交互历史增长，性能会因上下文退化而下降。现有方法主要通过原始积累或被动摘要来管理上下文，将其视为静态产物，导致早期错误或不当强调持续存在。

Method: 提出ARC框架，将上下文管理系统化为主动、反思驱动的过程，将上下文视为执行期间的动态内部推理状态。通过反思驱动的监控和修订操作化这一观点，允许代理在检测到错位或退化时主动重组其工作上下文。

Result: 在具有挑战性的长程信息寻求基准测试中，ARC始终优于被动上下文压缩方法，在BrowseComp-ZH基准上使用Qwen2.5-32B-Instruct模型实现了高达11%的绝对准确率提升。

Conclusion: ARC框架通过将上下文管理重新定义为主动、反思驱动的过程，有效解决了大语言模型在长程信息搜索中的上下文退化问题，显著提升了性能表现。

Abstract: Large language models are increasingly deployed as research agents for deep search and long-horizon information seeking, yet their performance often degrades as interaction histories grow. This degradation, known as context rot, reflects a failure to maintain coherent and task-relevant internal states over extended reasoning horizons. Existing approaches primarily manage context through raw accumulation or passive summarization, treating it as a static artifact and allowing early errors or misplaced emphasis to persist. Motivated by this perspective, we propose ARC, which is the first framework to systematically formulate context management as an active, reflection-driven process that treats context as a dynamic internal reasoning state during execution. ARC operationalizes this view through reflection-driven monitoring and revision, allowing agents to actively reorganize their working context when misalignment or degradation is detected. Experiments on challenging long-horizon information-seeking benchmarks show that ARC consistently outperforms passive context compression methods, achieving up to an 11% absolute improvement in accuracy on BrowseComp-ZH with Qwen2.5-32B-Instruct.

</details>


### [486] [Abstract Argumentation with Subargument Relations](https://arxiv.org/abs/2601.12038)
*Beishui Liao*

Main category: cs.AI

TL;DR: 论文提出在抽象论辩框架中引入明确的子论证关系，作为与攻击关系并列的基本关系，以更好地表示结构化论辩中的依赖关系


<details>
  <summary>Details</summary>
Motivation: Dung的抽象论辩框架仅通过攻击关系来表征论证可接受性，忽略了论证的内部结构。这种抽象虽然产生了丰富成果，但限制了表示结构化论辩形式主义中核心的结构依赖关系，特别是子论证关系。现有的扩展（如双极论辩框架）引入了支持关系，但未能捕捉子论证的非对称性和构成性本质及其与攻击的交互

Method: 研究在抽象论辩框架中丰富明确的子论证关系，将其与攻击关系一起作为基本关系。分析子论证关系如何与攻击交互，并考察它们对基本语义属性的影响

Result: 该框架提供了结构信息的原理性抽象，并澄清了子论证在抽象可接受性推理中的作用

Conclusion: 通过引入子论证关系作为基本关系，能够更好地抽象结构化论辩中的依赖关系，为抽象可接受性推理提供更丰富的理论基础

Abstract: Dung's abstract argumentation framework characterises argument acceptability solely via an attack relation, deliberately abstracting from the internal structure of arguments. While this level of abstraction has enabled a rich body of results, it limits the ability to represent structural dependencies that are central in many structured argumentation formalisms, in particular subargument relations. Existing extensions, including bipolar argumentation frameworks, introduce support relations, but these do not capture the asymmetric and constitutive nature of subarguments or their interaction with attacks. In this paper, we study abstract argumentation frameworks enriched with an explicit subargument relation, treated alongside attack as a basic relation. We analyse how subargument relations interact with attacks and examine their impact on fundamental semantic properties. This framework provides a principled abstraction of structural information and clarifies the role of subarguments in abstract acceptability reasoning.

</details>


### [487] [Partial Reasoning in Language Models: Search and Refinement Guided by Uncertainty](https://arxiv.org/abs/2601.12040)
*Murilo da Luz,Bruno Brandão,Luana Martins,Gustavo Oliveira,Bryan de Oliveira,Luckeciano Melo,Telma Soares*

Main category: cs.AI

TL;DR: PREGU方法通过监控LLM生成过程中的熵值来检测不确定性，当熵超过阈值时暂停生成，在潜在空间进行局部搜索以优化部分推理，提升多步推理性能。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在推理和规划任务上取得了显著进展，但在多步推理场景（特别是数学和逻辑推理）中仍存在局限性，需要更有效的推理优化方法。

Method: PREGU在自回归生成过程中监控输出分布的熵，当熵超过设定阈值时暂停生成（表示不确定性），然后在潜在空间进行局部搜索，使用Soft Reasoning方法优化部分推理并选择最一致的答案。

Result: 在LLaMA-3-8B、Mistral-7B和Qwen2-7B模型上，在四个推理基准测试（GSM8K、GSM-Hard、SVAMP、StrategyQA）中，PREGU表现优于或类似于Soft Reasoning，表明熵可以作为触发选择性推理优化的有效信号。

Conclusion: 熵监控是检测LLM推理过程中不确定性的有效方法，基于熵触发的局部搜索能够优化部分推理，提升多步推理任务的性能，为LLM推理优化提供了新思路。

Abstract: The use of Large Language Models (LLMs) for reasoning and planning tasks has drawn increasing attention in Artificial Intelligence research. Despite their remarkable progress, these models still exhibit limitations in multi-step inference scenarios, particularly in mathematical and logical reasoning. We introduce PREGU (Partial Reasoning Guided by Uncertainty). PREGU monitors the entropy of the output distribution during autoregressive generation and halts the process whenever entropy exceeds a defined threshold, signaling uncertainty. From that point, a localized search is performed in the latent space to refine the partial reasoning and select the most coherent answer, using the Soft Reasoning method. Experiments conducted with LLaMA-3-8B, Mistral-7B, and Qwen2-7B across four reasoning benchmarks (GSM8K, GSM-Hard, SVAMP, and StrategyQA) showed performance greater than or similar to Soft Reasoning, indicating that entropy can serve as an effective signal to trigger selective refinement during reasoning.

</details>


### [488] [UniMo: Unified Motion Generation and Understanding with Chain of Thought](https://arxiv.org/abs/2601.12126)
*Guocun Wang,Kenkun Liu,Jing Lin,Guorui Song,Jian Li,Xiaoguang Han*

Main category: cs.AI

TL;DR: UniMo是一个统一的3D人体运动生成与理解框架，通过监督微调和强化学习优化，解决了现有方法在语义对齐、任务一致性和累积预测误差方面的问题。


<details>
  <summary>Details</summary>
Motivation: 现有3D人体运动生成与理解方法可解释性有限，限制了这两个相关任务之间的相互增强。基于大语言模型的统一框架存在语义对齐和任务一致性挑战，且next-token预测范式不适合运动序列，会导致累积预测误差。

Method: 提出UniMo框架：1) 通过监督微调将运动-语言信息和可解释的思维链推理整合到大语言模型中；2) 引入强化学习与组相对策略优化作为后训练策略，通过优化token组来确保结构正确性和语义对齐，减轻运动token预测中的累积误差。

Result: 大量实验表明，UniMo显著优于现有的统一模型和任务特定模型，在运动生成和理解任务上都达到了最先进的性能。

Conclusion: UniMo通过整合运动-语言信息和可解释的思维链推理，结合监督微调和强化学习优化，成功解决了3D人体运动生成与理解中的语义对齐、任务一致性和累积误差问题，实现了两个任务的相互增强。

Abstract: Existing 3D human motion generation and understanding methods often exhibit limited interpretability, restricting effective mutual enhancement between these inherently related tasks. While current unified frameworks based on large language models (LLMs) leverage linguistic priors, they frequently encounter challenges in semantic alignment and task coherence. Moreover, the next-token prediction paradigm in LLMs is ill-suited for motion sequences, causing cumulative prediction errors. To address these limitations, we propose UniMo, a novel framework that integrates motion-language information and interpretable chain of thought (CoT) reasoning into the LLM via supervised fine-tuning (SFT). We further introduce reinforcement learning with Group Relative Policy Optimization (GRPO) as a post-training strategy that optimizes over groups of tokens to enforce structural correctness and semantic alignment, mitigating cumulative errors in motion token prediction. Extensive experiments demonstrate that UniMo significantly outperforms existing unified and task-specific models, achieving state-of-the-art performance in both motion generation and understanding.

</details>


### [489] [DriveSafe: A Hierarchical Risk Taxonomy for Safety-Critical LLM-Based Driving Assistants](https://arxiv.org/abs/2601.12138)
*Abhishek Kumar,Riya Tapwal,Carsten Maple*

Main category: cs.AI

TL;DR: DriveSafe：针对LLM驾驶助手的四层风险分类法，包含129个细粒度风险类别，评估显示现有模型在驾驶场景中安全拒绝能力不足


<details>
  <summary>Details</summary>
Motivation: LLM越来越多地集成到车载数字助手中，但现有安全分类和评估框架大多是通用型的，无法捕捉真实驾驶场景特有的领域风险。不安全的、模糊的或法律错误的回答可能导致严重的安全、伦理和监管后果。

Method: 提出了DriveSafe，一个分层的四级风险分类法，包含129个细粒度原子风险类别，涵盖技术、法律、社会和伦理维度。该方法基于真实驾驶法规和安全原则，并由领域专家评审。通过评估六个广泛部署的LLM在构建提示上的拒绝行为来验证安全相关性和真实性。

Result: 评估显示，被评估的模型经常无法适当地拒绝不安全或不合规的驾驶相关查询，突显了通用安全对齐在驾驶环境中的局限性。

Conclusion: 需要针对驾驶领域的特定安全评估框架，现有LLM在驾驶场景中的安全对齐存在不足，DriveSafe分类法为系统评估LLM驾驶助手的安全风险提供了基础。

Abstract: Large Language Models (LLMs) are increasingly integrated into vehicle-based digital assistants, where unsafe, ambiguous, or legally incorrect responses can lead to serious safety, ethical, and regulatory consequences. Despite growing interest in LLM safety, existing taxonomies and evaluation frameworks remain largely general-purpose and fail to capture the domain-specific risks inherent to real-world driving scenarios. In this paper, we introduce DriveSafe, a hierarchical, four-level risk taxonomy designed to systematically characterize safety-critical failure modes of LLM-based driving assistants. The taxonomy comprises 129 fine-grained atomic risk categories spanning technical, legal, societal, and ethical dimensions, grounded in real-world driving regulations and safety principles and reviewed by domain experts. To validate the safety relevance and realism of the constructed prompts, we evaluate their refusal behavior across six widely deployed LLMs. Our analysis shows that the evaluated models often fail to appropriately refuse unsafe or non-compliant driving-related queries, underscoring the limitations of general-purpose safety alignment in driving contexts.

</details>


### [490] [TIDE: A Trace-Informed Depth-First Exploration for Planning with Temporally Extended Goals](https://arxiv.org/abs/2601.12141)
*Yuliia Suprun,Khen Elimelech,Lydia E. Kavraki,Moshe Y. Vardi*

Main category: cs.AI

TL;DR: TIDE是一种用于处理时序扩展目标规划的新方法，通过将时序问题分解为可管理的子问题，并使用成本启发式引导搜索，提高了规划效率。


<details>
  <summary>Details</summary>
Motivation: 传统LTLf任务规划方法通常将时序规划问题转化为经典规划问题，但缺乏针对时序目标的启发式引导搜索，导致效率不高。

Method: TIDE将时序问题分解为一系列较小的可达-避免子问题，利用成本驱动启发式识别和优先处理有前景的自动机轨迹，并采用自适应回溯机制从失败计划中恢复。

Result: 实验结果表明TIDE实现了有前景的性能，是时序扩展目标规划方法组合中的有价值补充。

Conclusion: TIDE通过分解时序问题和使用启发式引导搜索，有效解决了传统LTLf规划方法缺乏引导的问题，提高了时序目标规划的效率和完整性。

Abstract: Task planning with temporally extended goals (TEGs) is a critical challenge in AI and robotics, enabling agents to achieve complex sequences of objectives over time rather than addressing isolated, immediate tasks. Linear Temporal Logic on finite traces (LTLf ) provides a robust formalism for encoding these temporal goals. Traditional LTLf task planning approaches often transform the temporal planning problem into a classical planning problem with reachability goals, which are then solved using off-the-shelf planners. However, these methods often lack informed heuristics to provide a guided search for temporal goals. We introduce TIDE (Trace-Informed Depth-first Exploration), a novel approach that addresses this limitation by decomposing a temporal problem into a sequence of smaller, manageable reach-avoid sub-problems, each solvable using an off-the-shelf planner. TIDE identifies and prioritizes promising automaton traces within the domain graph, using cost-driven heuristics to guide exploration. Its adaptive backtracking mechanism systematically recovers from failed plans by recalculating costs and penalizing infeasible transitions, ensuring completeness and efficiency. Experimental results demonstrate that TIDE achieves promising performance and is a valuable addition to the portfolio of planning methods for temporally extended goals.

</details>


### [491] [Optimal Power Allocation and Sub-Optimal Channel Assignment for Downlink NOMA Systems Using Deep Reinforcement Learning](https://arxiv.org/abs/2601.12242)
*WooSeok Kim,Jeonghoon Lee,Sangho Kim,Taesun An,WonMin Lee,Dowon Kim,Kyungseop Shin*

Main category: cs.AI

TL;DR: 本文提出了一种结合回放记忆的深度强化学习框架，用于解决NOMA系统中的信道分配问题，通过广泛的仿真评估了不同参数对性能的影响。


<details>
  <summary>Details</summary>
Motivation: 随着物联网(IoT)的扩展导致网络资源稀缺，需要优化网络资源利用。NOMA系统通过功率复用允许多用户同时接入网络，但存在信道分配问题不明确，需要进一步研究。

Method: 提出了一种结合回放记忆的深度强化学习框架，采用on-policy算法，在NOMA系统中分配网络资源以实现泛化学习。

Result: 通过广泛的仿真评估了学习率、批量大小、模型类型和状态特征数量等因素对性能的影响。

Conclusion: 提出的深度强化学习框架能够有效解决NOMA系统中的信道分配问题，并通过参数调优进一步提升系统性能。

Abstract: In recent years, Non-Orthogonal Multiple Access (NOMA) system has emerged as a promising candidate for multiple access frameworks due to the evolution of deep machine learning, trying to incorporate deep machine learning into the NOMA system. The main motivation for such active studies is the growing need to optimize the utilization of network resources as the expansion of the internet of things (IoT) caused a scarcity of network resources. The NOMA addresses this need by power multiplexing, allowing multiple users to access the network simultaneously. Nevertheless, the NOMA system has few limitations. Several works have proposed to mitigate this, including the optimization of power allocation known as joint resource allocation(JRA) method, and integration of the JRA method and deep reinforcement learning (JRA-DRL). Despite this, the channel assignment problem remains unclear and requires further investigation. In this paper, we propose a deep reinforcement learning framework incorporating replay memory with an on-policy algorithm, allocating network resources in a NOMA system to generalize the learning. Also, we provide extensive simulations to evaluate the effects of varying the learning rate, batch size, type of model, and the number of features in the state.

</details>


### [492] [Improving Large Molecular Language Model via Relation-aware Multimodal Collaboration](https://arxiv.org/abs/2601.12256)
*Jinyoung Park,Minseong Bae,Jeehye Na,Hyunwoo J. Kim*

Main category: cs.AI

TL;DR: CoLLaMo是一个基于大语言模型的分子助手，通过多级分子模态协作投影器和关系感知的模态协作注意力机制，整合1D序列、2D分子图和3D构象信息，解决了现有大分子语言模型的幻觉和鲁棒性不足问题。


<details>
  <summary>Details</summary>
Motivation: 现有的大分子语言模型（LMLMs）存在幻觉问题和有限的鲁棒性，主要原因是未能充分整合1D序列、2D分子图和3D构象等多种分子模态信息。需要开发能够更好整合多模态分子信息的模型来提升分子理解和生成能力。

Method: 提出CoLLaMo模型，包含多级分子模态协作投影器，采用关系感知的模态协作注意力机制，促进原子间基于2D结构和3D空间关系的细粒度信息交换。同时提出了新的分子中心自动评估方法，包括幻觉评估指标和基于GPT的标题质量评估。

Result: CoLLaMo在多个任务上取得了最佳性能，包括分子标题生成、计算性质问答、描述性质问答、基序计数和IUPAC名称预测，显著提升了LMLMs的分子模态泛化能力。

Conclusion: 通过整合多种分子模态信息和引入关系感知的注意力机制，CoLLaMo有效解决了现有LMLMs的幻觉和鲁棒性问题，为分子理解和生成任务提供了更强大的工具，同时提出的新评估方法为分子领域提供了更合适的评估标准。

Abstract: Large language models (LLMs) have demonstrated their instruction-following capabilities and achieved powerful performance on various tasks. Inspired by their success, recent works in the molecular domain have led to the development of large molecular language models (LMLMs) that integrate 1D molecular strings or 2D molecular graphs into the language models. However, existing LMLMs often suffer from hallucination and limited robustness, largely due to inadequate integration of diverse molecular modalities such as 1D sequences, 2D molecular graphs, and 3D conformations. To address these limitations, we propose CoLLaMo, a large language model-based molecular assistant equipped with a multi-level molecular modality-collaborative projector. The relation-aware modality-collaborative attention mechanism in the projector facilitates fine-grained and relation-guided information exchange between atoms by incorporating 2D structural and 3D spatial relations. Furthermore, we present a molecule-centric new automatic measurement, including a hallucination assessment metric and GPT-based caption quality evaluation to address the limitations of token-based generic evaluation metrics (i.e., BLEU) widely used in assessing molecular comprehension of LMLMs. Our extensive experiments demonstrate that our CoLLaMo enhances the molecular modality generalization capabilities of LMLMs, achieving the best performance on multiple tasks, including molecule captioning, computed property QA, descriptive property QA, motif counting, and IUPAC name prediction.

</details>


### [493] [FutureX-Pro: Extending Future Prediction to High-Value Vertical Domains](https://arxiv.org/abs/2601.12259)
*Jiashuo Liu,Siyuan Chen,Zaiyuan Wang,Zhiyuan Zeng,Jiacheng Guo,Liang Hu,Lingyue Yin,Suozhi Huang,Wenxin Hao,Yang Yang,Zerui Cheng,Zixin Yao,Lingyue Yin,Haoxin Liu,Jiayi Cheng,Yuzhen Li,Zezhong Ma,Bingjie Wang,Bingsen Qiu,Xiao Liu,Zeyang Zhang,Zijian Liu,Jinpeng Wang,Mingren Yin,Tianci He,Yali Liao,Yixiao Tian,Zhenwei Zhu,Anqi Dai,Ge Zhang,Jingkai Liu,Kaiyuan Zhang,Wenlong Wu,Xiang Gao,Xinjie Chen,Zhixin Yao,Zhoufutu Wen,B. Aditya Prakash,Jose Blanchet,Mengdi Wang,Nian Si,Wenhao Huang*

Main category: cs.AI

TL;DR: FutureX-Pro扩展了FutureX的通用未来预测基准，专注于金融、零售、公共卫生和自然灾害四个高价值垂直领域，评估当前SOTA代理LLM在这些关键领域的预测能力。


<details>
  <summary>Details</summary>
Motivation: 虽然通用代理在开放领域搜索中表现出色，但在资本密集型和安全关键领域的可靠性尚未充分探索。需要评估当前最先进的代理LLM是否具备工业部署所需的领域基础。

Method: 通过FutureX-Pro框架（包括五个子领域），采用无污染、实时评估的管道，在四个垂直领域（金融、零售、公共卫生、自然灾害）对代理LLM进行基准测试，涵盖市场指标预测、供应链需求预测、流行病趋势跟踪和自然灾害监测等基础任务。

Result: 研究发现，当前最先进的代理LLM在通用推理能力与高价值垂直应用所需的精确度之间存在性能差距。

Conclusion: 需要进一步开发具备领域专业知识的代理系统，以满足资本密集型和安全关键行业的实际部署需求。

Abstract: Building upon FutureX, which established a live benchmark for general-purpose future prediction, this report introduces FutureX-Pro, including FutureX-Finance, FutureX-Retail, FutureX-PublicHealth, FutureX-NaturalDisaster, and FutureX-Search. These together form a specialized framework extending agentic future prediction to high-value vertical domains. While generalist agents demonstrate proficiency in open-domain search, their reliability in capital-intensive and safety-critical sectors remains under-explored. FutureX-Pro targets four economically and socially pivotal verticals: Finance, Retail, Public Health, and Natural Disaster. We benchmark agentic Large Language Models (LLMs) on entry-level yet foundational prediction tasks -- ranging from forecasting market indicators and supply chain demands to tracking epidemic trends and natural disasters. By adapting the contamination-free, live-evaluation pipeline of FutureX, we assess whether current State-of-the-Art (SOTA) agentic LLMs possess the domain grounding necessary for industrial deployment. Our findings reveal the performance gap between generalist reasoning and the precision required for high-value vertical applications.

</details>


### [494] [Docs2Synth: A Synthetic Data Trained Retriever Framework for Scanned Visually Rich Documents Understanding](https://arxiv.org/abs/2601.12260)
*Yihao Ding,Qiang Sun,Puzhen Wu,Sirui Li,Siwen Luo,Wei Liu*

Main category: cs.AI

TL;DR: Docs2Synth是一个合成监督框架，通过自动生成和验证QA对，训练轻量级视觉检索器，结合MLLM进行迭代检索-生成，解决受监管领域文档理解中的标注稀缺和领域知识更新问题。


<details>
  <summary>Details</summary>
Motivation: 受监管领域（如金融、医疗）的文档理解面临两大挑战：1）缺乏手动标注数据用于模型适应；2）预训练模型难以跟上领域特定知识的快速演变。现有方法中，MLLM存在幻觉问题且领域基础薄弱，而VLPM需要昂贵的标注成本。

Method: Docs2Synth框架包含三个核心组件：1）自动处理原始文档集；2）基于代理系统生成和验证多样化的QA对；3）训练轻量级视觉检索器提取领域相关证据。推理时采用迭代检索-生成循环，检索器与MLLM协作减少幻觉。

Result: 在多个VRDU基准测试中，Docs2Synth显著提升了模型的领域基础和泛化能力，无需人工标注。框架已打包为易用的Python包，支持即插即用部署到各种实际场景。

Conclusion: Docs2Synth通过合成监督和检索引导推理，有效解决了受监管领域文档理解中的标注稀缺和知识更新问题，为低资源私有领域提供了实用的解决方案。

Abstract: Document understanding (VRDU) in regulated domains is particularly challenging, since scanned documents often contain sensitive, evolving, and domain specific knowledge. This leads to two major challenges: the lack of manual annotations for model adaptation and the difficulty for pretrained models to stay up-to-date with domain-specific facts. While Multimodal Large Language Models (MLLMs) show strong zero-shot abilities, they still suffer from hallucination and limited domain grounding. In contrast, discriminative Vision-Language Pre-trained Models (VLPMs) provide reliable grounding but require costly annotations to cover new domains. We introduce Docs2Synth, a synthetic-supervision framework that enables retrieval-guided inference for private and low-resource domains. Docs2Synth automatically processes raw document collections, generates and verifies diverse QA pairs via an agent-based system, and trains a lightweight visual retriever to extract domain-relevant evidence. During inference, the retriever collaborates with an MLLM through an iterative retrieval--generation loop, reducing hallucination and improving response consistency. We further deliver Docs2Synth as an easy-to-use Python package, enabling plug-and-play deployment across diverse real-world scenarios. Experiments on multiple VRDU benchmarks show that Docs2Synth substantially enhances grounding and domain generalization without requiring human annotations.

</details>


### [495] [ToolPRMBench: Evaluating and Advancing Process Reward Models for Tool-using Agents](https://arxiv.org/abs/2601.12294)
*Dawei Li,Yuguang Yao,Zhen Tan,Huan Liu,Ruocheng Guo*

Main category: cs.AI

TL;DR: 提出了ToolPRMBench，一个专门评估工具使用智能体中过程奖励模型（PRMs）的大规模基准测试，包含单步和多步测试案例，通过多LLM验证确保数据质量，实验揭示了不同PRMs在工具使用场景下的性能差异。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏系统可靠的基准测试来评估工具使用智能体中的过程奖励模型（PRMs），而PRMs对于指导复杂动作空间的采样和探索至关重要。

Method: 基于多个代表性工具使用基准构建ToolPRMBench，将智能体轨迹转换为步级测试案例，包含交互历史、正确动作、合理但错误的替代动作和工具元数据。使用离线采样隔离单步错误和在线采样捕获多步失败，采用多LLM验证管道减少标签噪声。

Result: 在大语言模型、通用PRMs和工具专用PRMs上进行了广泛实验，结果显示PRMs有效性存在明显差异，工具专用PRMs在工具使用场景中表现出潜力。

Conclusion: ToolPRMBench填补了工具使用PRMs评估的空白，为未来研究提供了可靠的基准，代码和数据已开源。

Abstract: Reward-guided search methods have demonstrated strong potential in enhancing tool-using agents by effectively guiding sampling and exploration over complex action spaces. As a core design, those search methods utilize process reward models (PRMs) to provide step-level rewards, enabling more fine-grained monitoring. However, there is a lack of systematic and reliable evaluation benchmarks for PRMs in tool-using settings. In this paper, we introduce ToolPRMBench, a large-scale benchmark specifically designed to evaluate PRMs for tool-using agents. ToolPRMBench is built on top of several representative tool-using benchmarks and converts agent trajectories into step-level test cases. Each case contains the interaction history, a correct action, a plausible but incorrect alternative, and relevant tool metadata. We respectively utilize offline sampling to isolate local single-step errors and online sampling to capture realistic multi-step failures from full agent rollouts. A multi-LLM verification pipeline is proposed to reduce label noise and ensure data quality. We conduct extensive experiments across large language models, general PRMs, and tool-specialized PRMs on ToolPRMBench. The results reveal clear differences in PRM effectiveness and highlight the potential of specialized PRMs for tool-using. Code and data will be released at https://github.com/David-Li0406/ToolPRMBench.

</details>


### [496] [Survival is the Only Reward: Sustainable Self-Training Through Environment-Mediated Selection](https://arxiv.org/abs/2601.12310)
*Jennifer Dodgson,Alfath Daryl Alhajir,Michael Joedhitya,Akira Rafhael Janson Pattirane,Surender Suresh Kumar,Joseph Lim,C. H. Peh,Adith Ramdas,Steven Zhang Zhexu*

Main category: cs.AI

TL;DR: 本文提出了一种基于环境生存能力而非奖励函数的自训练架构，通过行为在真实资源约束下的存续进行选择，避免了奖励黑客攻击和语义漂移，实现了可持续的开放式自我改进。


<details>
  <summary>Details</summary>
Motivation: 传统自训练系统因缺乏外部数据质量判断标准而退化，容易出现奖励黑客攻击和语义漂移问题。本文旨在探索在稀疏外部反馈和有限内存条件下实现稳定自训练的系统架构。

Method: 提出一种基于环境生存能力的自训练架构：学习完全由环境存活性介导，而非奖励、目标函数或外部定义的适应度标准。候选行为在真实资源约束下执行，只有那些环境效应持久且保留未来交互可能性的行为才会被传播。环境不提供语义反馈、密集奖励或任务特定监督，选择仅通过行为作为世界改变事件的差异存续来运作。

Result: 语义动态分析表明，改进主要通过有效且可重复策略在整合和剪枝机制下的持久性实现（称为负空间学习范式）。模型在没有明确指导的情况下发展出元学习策略（如故意实验失败以引发信息性错误消息）。

Conclusion: 基于环境的选择能够实现可持续的开放式自我改进，为构建更鲁棒和可泛化的自主系统提供了可行路径，无需依赖人工策划的数据或复杂的奖励塑造。

Abstract: Self-training systems often degenerate due to the lack of an external criterion for judging data quality, leading to reward hacking and semantic drift. This paper provides a proof-of-concept system architecture for stable self-training under sparse external feedback and bounded memory, and empirically characterises its learning dynamics and failure modes.
  We introduce a self-training architecture in which learning is mediated exclusively by environmental viability, rather than by reward, objective functions, or externally defined fitness criteria. Candidate behaviours are executed under real resource constraints, and only those whose environmental effects both persist and preserve the possibility of future interaction are propagated. The environment does not provide semantic feedback, dense rewards, or task-specific supervision; selection operates solely through differential survival of behaviours as world-altering events, making proxy optimisation impossible and rendering reward-hacking evolutionarily unstable.
  Analysis of semantic dynamics shows that improvement arises primarily through the persistence of effective and repeatable strategies under a regime of consolidation and pruning, a paradigm we refer to as negative-space learning (NSL), and that models develop meta-learning strategies (such as deliberate experimental failure in order to elicit informative error messages) without explicit instruction. This work establishes that environment-grounded selection enables sustainable open-ended self-improvement, offering a viable path toward more robust and generalisable autonomous systems without reliance on human-curated data or complex reward shaping.

</details>


### [497] [Beyond Human Annotation: Recent Advances in Data Generation Methods for Document Intelligence](https://arxiv.org/abs/2601.12318)
*Dehao Ying,Fengchang Yu,Haihua Chen,Changjiang Jiang,Yurong Li,Wei Lu*

Main category: cs.AI

TL;DR: 该论文首次建立了文档智能数据生成的技术图谱，提出基于"数据和标签可用性"的新分类法，将方法分为数据增强、从零生成、自动标注和自监督信号构建四种范式，并建立了多级评估框架。


<details>
  <summary>Details</summary>
Motivation: 文档智能需要大规模高质量训练数据，但人工标注成为瓶颈。现有研究分散在单一模态或特定任务，缺乏与现实工作流程统一的技术视角。

Method: 将数据生成重新定义为监督信号生产，提出基于"数据和标签可用性"的新分类法，将方法组织为四种资源中心范式：数据增强、从零生成、自动标注和自监督信号构建，并建立多级评估框架。

Result: 建立了首个文档智能数据生成综合技术图谱，揭示了保真度差距等关键挑战和协同进化生态系统等前沿方向，整理了多种文档智能基准测试的性能提升。

Conclusion: 通过系统化这一分散领域，将数据生成定位为下一代文档智能的核心引擎，为未来发展提供了统一框架。

Abstract: The advancement of Document Intelligence (DI) demands large-scale, high-quality training data, yet manual annotation remains a critical bottleneck. While data generation methods are evolving rapidly, existing surveys are constrained by fragmented focuses on single modalities or specific tasks, lacking a unified perspective aligned with real-world workflows. To fill this gap, this survey establishes the first comprehensive technical map for data generation in DI. Data generation is redefined as supervisory signal production, and a novel taxonomy is introduced based on the "availability of data and labels." This framework organizes methodologies into four resource-centric paradigms: Data Augmentation, Data Generation from Scratch, Automated Data Annotation, and Self-Supervised Signal Construction. Furthermore, a multi-level evaluation framework is established to integrate intrinsic quality and extrinsic utility, compiling performance gains across diverse DI benchmarks. Guided by this unified structure, the methodological landscape is dissected to reveal critical challenges such as fidelity gaps and frontiers including co-evolutionary ecosystems. Ultimately, by systematizing this fragmented field, data generation is positioned as the central engine for next-generation DI.

</details>


### [498] [MARO: Learning Stronger Reasoning from Social Interaction](https://arxiv.org/abs/2601.12323)
*Yin Cai,Zhouhong Gu,Juntao Zhang,Ping Chen*

Main category: cs.AI

TL;DR: MARO方法通过多智能体社交环境训练LLMs，解决稀疏奖励、角色分布不均和环境不稳定问题，显著提升推理能力并实现跨任务迁移。


<details>
  <summary>Details</summary>
Motivation: 现有LLM训练方法主要从文本内容学习或解决预定问题，缺乏真实社交场景中的交互、谈判和竞争经验，限制了模型的推理和判断能力。

Method: 提出多智能体奖励优化(MARO)：1) 将最终成败结果分解为交互过程中的具体行为，解决稀疏学习信号问题；2) 平衡不同角色的训练样本权重，解决角色分布不均问题；3) 直接评估每个行为的效用，解决环境不稳定问题。

Result: MARO不仅显著提升了社交推理能力，而且通过社交模拟学习获得的能力能有效迁移到数学推理和指令跟随等其他任务。

Conclusion: 多智能体社交学习在增强LLMs通用推理能力方面具有巨大潜力，MARO为解决LLM在复杂社交环境中的学习问题提供了有效方法。

Abstract: Humans face countless scenarios that require reasoning and judgment in daily life. However, existing large language model training methods primarily allow models to learn from existing textual content or solve predetermined problems, lacking experience in real scenarios involving interaction, negotiation, and competition with others. To address this, this paper proposes Multi-Agent Reward Optimization (MARO), a method that enables large language models (LLMs) to acquire stronger reasoning abilities by learning and practicing in multi-agent social environments. Specifically, MARO first addresses the sparse learning signal problem by decomposing final success or failure outcomes into each specific behavior during the interaction process; second, it handles the uneven role distribution problem by balancing the training sample weights of different roles; finally, it addresses environmental instability issues by directly evaluating the utility of each behavior. Experimental results demonstrate that MARO not only achieves significant improvements in social reasoning capabilities, but also that the abilities acquired through social simulation learning can effectively transfer to other tasks such as mathematical reasoning and instruction following. This reveals the tremendous potential of multi-agent social learning in enhancing the general reasoning capabilities of LLMs.

</details>


### [499] [Actionable Advice from Reviews via Mixture of LoRA Experts: A Two-LLM Pipeline for Issue Extraction and Business Recommendations](https://arxiv.org/abs/2601.12338)
*Kartikey Singh Bhandari,Manav Ganesh,Yashwant Viswanathan,Archit Agrawal,Dhruv Kumar,Pratik Narang*

Main category: cs.AI

TL;DR: 提出一个两阶段LLM框架，通过问题提取和专家混合适配器，将客户评论转化为可操作的业务建议


<details>
  <summary>Details</summary>
Motivation: 客户评论包含丰富的服务失败和用户期望信号，但将这些非结构化反馈转化为可操作的业务决策仍然困难

Method: 提出模块化两阶段LLM框架：问题模型提取关键问题并分配主题，建议模型基于问题表示生成针对性解决方案；采用LoRA专家混合策略，训练多个低秩适配器，通过轻量级门控机制在推理时进行专家组合

Result: 在航空和餐厅两个领域，该方法在八个维度的操作评估标准（可操作性、特异性、可行性、预期影响、新颖性、非冗余性、偏见、清晰度）上均优于仅提示和单适配器基线，提供更高的可操作性和特异性

Conclusion: 提出的两阶段LLM框架结合专家混合适配器策略，能够有效将客户评论转化为具体可实施的业务建议，在效率和质量之间取得良好平衡

Abstract: Customer reviews contain detailed, domain specific signals about service failures and user expectations, but converting this unstructured feedback into actionable business decisions remains difficult. We study review-to-action generation: producing concrete, implementable recommendations grounded in review text. We propose a modular two-LLM framework in which an Issue model extracts salient issues and assigns coarse themes, and an Advice model generates targeted operational fixes conditioned on the extracted issue representation. To enable specialization without expensive full fine-tuning, we adapt the Advice model using a mixture of LoRA experts strategy: multiple low-rank adapters are trained and a lightweight gating mechanism performs token-level expert mixing at inference, combining complementary expertise across issue types. We construct synthetic review-issue-advice triples from Yelp reviews (airlines and restaurants) to supervise training, and evaluate recommendations using an eight dimension operational rubric spanning actionability, specificity, feasibility, expected impact, novelty, non-redundancy, bias, and clarity. Across both domains, our approach consistently outperforms prompting-only and single-adapter baselines, yielding higher actionability and specificity while retaining favorable efficiency-quality trade-offs.

</details>


### [500] [PsychēChat: An Empathic Framework Focused on Emotion Shift Tracking and Safety Risk Analysis in Psychological Counseling](https://arxiv.org/abs/2601.12392)
*Zhentao Xia,Yongqi Fan,Yuxiang Chu,Yichao Yin,Liangliang Chen,Tong Ruan,Weiyan Zhang*

Main category: cs.AI

TL;DR: PsychēChat是一个用于心理咨询的LLM框架，通过显式建模情绪变化追踪和风险控制来提升咨询效果和安全性。


<details>
  <summary>Details</summary>
Motivation: 现有心理咨询LLM通常不显式建模咨询者跨会话的情绪变化（心理咨询的核心关注点），同时如何在响应中与这些情绪变化对齐并主动缓解安全风险也研究不足。

Method: 提出PsychēChat框架，包含情绪管理模块（捕捉当前情绪和情绪变化）和风险控制模块（预测后续反应和识别潜在风险）。采用两种建模范式：Agent模式（多智能体协作管道）和LLM模式（统一思维链端到端推理）。

Result: 通过交互评分、对话级评估和人工评估等广泛实验，PsychēChat在情绪洞察和安全控制方面优于现有方法。

Conclusion: PsychēChat通过显式整合情绪变化追踪和安全风险分析，为心理咨询LLM提供了更有效和安全的解决方案。

Abstract: Large language models (LLMs) have demonstrated notable advancements in psychological counseling. However, existing models generally do not explicitly model seekers' emotion shifts across counseling sessions, a core focus in classical psychological schools. Moreover, how to align counselor models' responses with these emotion shifts while proactively mitigating safety risks remains underexplored. To bridge these gaps, we propose PsychēChat, which explicitly integrates emotion shift tracking and safety risk analysis for psychological counseling. Specifically, we employ interactive role-playing to synthesize counselor--seeker dialogues, incorporating two modules: Emotion Management Module, to capture seekers' current emotions and emotion shifts; and Risk Control Module, to anticipate seekers' subsequent reactions and identify potential risks. Furthermore, we introduce two modeling paradigms. The Agent Mode structures emotion management, risk control, and counselor responses into a collaborative multi-agent pipeline. The LLM Mode integrates these stages into a unified chain-of-thought for end-to-end inference, balancing efficiency and performance. Extensive experiments, including interactive scoring, dialogue-level evaluation, and human assessment, demonstrate that PsychēChat outperforms existing methods for emotional insight and safety control.

</details>


### [501] [Are LLMs Smarter Than Chimpanzees? An Evaluation on Perspective Taking and Knowledge State Estimation](https://arxiv.org/abs/2601.12410)
*Dingyi Yang,Junqi Zhao,Xue Li,Ce Li,Boyang Li*

Main category: cs.AI

TL;DR: LLMs在知识状态追踪和估计任务上表现接近随机水平，显著低于人类，未来研究应更重视知识估计和意图理解能力


<details>
  <summary>Details</summary>
Motivation: 认知人类学认为人类智能的关键在于推断他人知识状态和理解意图的能力，而黑猩猩等近亲动物缺乏这种能力。本研究旨在评估LLM在知识状态追踪和估计方面的表现。

Method: 设计两个任务：1) 检测故事角色是否通过行动表现出他们不应拥有的知识；2) 基于角色自身知识（而非客观事实）预测角色的下一步行动。

Result: 当前最先进的LLM在两个任务上都表现出接近随机的性能，显著低于人类水平。

Conclusion: 未来LLM研究应更加重视知识估计和意图理解能力的发展。

Abstract: Cognitive anthropology suggests that the distinction of human intelligence lies in the ability to infer other individuals' knowledge states and understand their intentions. In comparison, our closest animal relative, chimpanzees, lack the capacity to do so. With this paper, we aim to evaluate LLM performance in the area of knowledge state tracking and estimation. We design two tasks to test (1) if LLMs can detect when story characters, through their actions, demonstrate knowledge they should not possess, and (2) if LLMs can predict story characters' next actions based on their own knowledge vs. objective truths they do not know. Results reveal that most current state-of-the-art LLMs achieve near-random performance on both tasks, and are substantially inferior to humans. We argue future LLM research should place more weight on the abilities of knowledge estimation and intention understanding.

</details>


### [502] [Large Language Model for OWL Proofs](https://arxiv.org/abs/2601.12444)
*Hui Yang,Jiaoyan Chen,Uli Sattler*

Main category: cs.AI

TL;DR: 该论文研究了大型语言模型在OWL本体论中生成证明的能力，开发了自动数据集构建和评估框架，发现逻辑复杂性是影响性能的主要因素，而非表示格式。


<details>
  <summary>Details</summary>
Motivation: 虽然LLMs在推理任务上的能力已被广泛研究，但它们在生成忠实、人类可读的证明（解释结论为何成立）方面的能力仍未被充分探索。特别是在OWL本体论这种广泛用于表示和推理复杂知识的背景下。

Method: 开发了一个自动化的数据集构建和评估框架，评估包含三个顺序任务：提取、简化和解释，以及一个额外的逻辑完整性评估任务。在广泛使用的推理LLMs上进行了大量实验。

Result: (1) 某些模型总体表现良好，但在复杂案例上仍有局限；(2) 逻辑复杂性（而非表示格式，即形式逻辑语言与自然语言）是影响LLM性能的主要因素；(3) 输入数据中的噪声和不完整性会显著降低LLMs的性能。

Conclusion: 这些结果既显示了LLMs在严格逻辑解释方面的潜力，也揭示了在复杂或不完美条件下支持弹性推理的差距。代码和数据已开源。

Abstract: The ability of Large Language Models (LLMs) to perform reasoning tasks such as deduction has been widely investigated in recent years. Yet, their capacity to generate proofs-faithful, human-readable explanations of why conclusions follow-remains largely under explored. In this work, we study proof generation in the context of OWL ontologies, which are widely adopted for representing and reasoning over complex knowledge, by developing an automated dataset construction and evaluation framework. Our evaluation encompassing three sequential tasks for complete proving: Extraction, Simplification, and Explanation, as well as an additional task of assessing Logic Completeness of the premise. Through extensive experiments on widely used reasoning LLMs, we achieve important findings including: (1) Some models achieve overall strong results but remain limited on complex cases; (2) Logical complexity, rather than representation format (formal logic language versus natural language), is the dominant factor shaping LLM performance; and (3) Noise and incompleteness in input data substantially diminish LLMs' performance. Together, these results underscore both the promise of LLMs for explanation with rigorous logics and the gap of supporting resilient reasoning under complex or imperfect conditions. Code and data are available at https://github.com/HuiYang1997/LLMOwlR.

</details>


### [503] [Failure Modes in Multi-Hop QA: The Weakest Link Law and the Recognition Bottleneck](https://arxiv.org/abs/2601.12499)
*Meiru Zhang,Zaiqiao Meng,Nigel Collier*

Main category: cs.AI

TL;DR: LLMs在长上下文多跳推理中存在位置偏见，导致性能下降至最不可见证据的水平，而非事实间距离影响；通过注意力引导可改善识别瓶颈，系统2推理模型能有效定位和整合信息。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs拥有大规模上下文窗口，但在多跳推理中存在位置偏见问题，导致忽略某些位置的信息。需要区分这种失败是由于无法定位证据（识别失败）还是无法整合证据（综合失败）。

Method: 引入多焦点注意力指令（MFAI）作为语义探针，通过显式引导注意力到选定位置来分离识别和综合机制。在5个LLMs上测试两个多跳QA任务（MuSiQue和NeoQA）。

Result: 发现"最弱链接定律"：多跳推理性能下降至最不可见证据的性能水平，且失败由绝对位置而非事实间线性距离决定。匹配的MFAI可将低可见性位置准确率提升11.5%，误导性MFAI在真实任务中引发混淆但能在合成任务中被过滤。系统2推理模型能有效定位和整合信息。

Conclusion: LLMs的多跳推理失败主要由位置偏见导致，而非事实间距离。注意力引导可改善识别瓶颈，系统2推理模型能有效处理长上下文中的噪声信息，匹配仅使用黄金证据的基线性能。

Abstract: Despite scaling to massive context windows, Large Language Models (LLMs) struggle with multi-hop reasoning due to inherent position bias, which causes them to overlook information at certain positions. Whether these failures stem from an inability to locate evidence (recognition failure) or integrate it (synthesis failure) is unclear. We introduce Multi-Focus Attention Instruction (MFAI), a semantic probe to disentangle these mechanisms by explicitly steering attention towards selected positions. Across 5 LLMs on two multi-hop QA tasks (MuSiQue and NeoQA), we establish the "Weakest Link Law": multi-hop reasoning performance collapses to the performance level of the least visible evidence. Crucially, this failure is governed by absolute position rather than the linear distance between facts (performance variance $<3%$). We further identify a duality in attention steering: while matched MFAI resolves recognition bottlenecks, improving accuracy by up to 11.5% in low-visibility positions, misleading MFAI triggers confusion in real-world tasks but is successfully filtered in synthetic tasks. Finally, we demonstrate that "thinking" models that utilize System-2 reasoning, effectively locate and integrate the required information, matching gold-only baselines even in noisy, long-context settings.

</details>


### [504] [Agentic Reasoning for Large Language Models](https://arxiv.org/abs/2601.12538)
*Tianxin Wei,Ting-Wei Li,Zhining Liu,Xuying Ning,Ze Yang,Jiaru Zou,Zhichen Zeng,Ruizhong Qiu,Xiao Lin,Dongqi Fu,Zihao Li,Mengting Ai,Duo Zhou,Wenxuan Bao,Yunzhe Li,Gaotang Li,Cheng Qian,Yu Wang,Xiangru Tang,Yin Xiao,Liri Fang,Hui Liu,Xianfeng Tang,Yuji Zhang,Chi Wang,Jiaxuan You,Heng Ji,Hanghang Tong,Jingrui He*

Main category: cs.AI

TL;DR: 该调查论文系统性地组织并分析了智能体推理的三个维度：基础智能体推理、自我进化智能体推理和集体多智能体推理，涵盖了从稳定环境到动态协作的各种场景，并探讨了实际应用和未来挑战。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在封闭环境中表现出强大的推理能力，但在开放和动态环境中表现不佳。智能体推理通过将LLMs重构为能够规划、行动和持续学习的自主智能体，实现了范式转变，旨在弥合思维与行动之间的差距。

Method: 论文从三个互补维度组织智能体推理：1)基础智能体推理（单智能体在稳定环境中的规划、工具使用和搜索）；2)自我进化智能体推理（通过反馈、记忆和适应优化能力）；3)集体多智能体推理（协作环境中的协调、知识共享和共同目标）。同时区分了上下文推理和训练后推理两种方法。

Result: 论文综合了智能体推理方法，形成了连接思维与行动的统一路线图，涵盖了科学、机器人、医疗、自主研究和数学等实际应用领域，并建立了相应的基准测试体系。

Conclusion: 智能体推理代表了LLMs向自主智能体发展的关键转变。论文提出了未来研究方向，包括个性化、长时程交互、世界建模、可扩展的多智能体训练以及现实世界部署的治理问题，为这一新兴领域提供了系统性的框架。

Abstract: Reasoning is a fundamental cognitive process underlying inference, problem-solving, and decision-making. While large language models (LLMs) demonstrate strong reasoning capabilities in closed-world settings, they struggle in open-ended and dynamic environments. Agentic reasoning marks a paradigm shift by reframing LLMs as autonomous agents that plan, act, and learn through continual interaction. In this survey, we organize agentic reasoning along three complementary dimensions. First, we characterize environmental dynamics through three layers: foundational agentic reasoning, which establishes core single-agent capabilities including planning, tool use, and search in stable environments; self-evolving agentic reasoning, which studies how agents refine these capabilities through feedback, memory, and adaptation; and collective multi-agent reasoning, which extends intelligence to collaborative settings involving coordination, knowledge sharing, and shared goals. Across these layers, we distinguish in-context reasoning, which scales test-time interaction through structured orchestration, from post-training reasoning, which optimizes behaviors via reinforcement learning and supervised fine-tuning. We further review representative agentic reasoning frameworks across real-world applications and benchmarks, including science, robotics, healthcare, autonomous research, and mathematics. This survey synthesizes agentic reasoning methods into a unified roadmap bridging thought and action, and outlines open challenges and future directions, including personalization, long-horizon interaction, world modeling, scalable multi-agent training, and governance for real-world deployment.

</details>


### [505] [MemeLens: Multilingual Multitask VLMs for Memes](https://arxiv.org/abs/2601.12539)
*Ali Ezzat Shahroor,Mohamed Bayan Kmainasi,Abul Hasnat,Dimitar Dimitrov,Giovanni Da San Martino,Preslav Nakov,Firoj Alam*

Main category: cs.AI

TL;DR: MemeLens：一个统一的多语言多任务解释增强视觉语言模型，用于理解网络表情包，整合了38个公开数据集，构建了包含20个任务的共享分类体系。


<details>
  <summary>Details</summary>
Motivation: 现有表情包研究分散在不同任务（仇恨、厌女、宣传、情感、幽默）和语言中，限制了跨领域泛化能力，需要统一的框架来理解表情包这种结合文本、图像和文化背景的复杂媒介。

Method: 整合38个公开表情包数据集，将数据集特定标签过滤并映射到包含20个任务的共享分类体系（涵盖危害、目标、修辞/语用意图和情感），构建统一的解释增强视觉语言模型。

Result: 研究发现：1）稳健的表情包理解需要多模态训练；2）不同语义类别间存在显著差异；3）在单个数据集上微调而非统一训练时，模型容易过度专业化。

Conclusion: 提出了MemeLens统一框架，解决了表情包研究分散化问题，为社区提供了实验资源和数据集，推动了多语言多任务表情包理解的发展。

Abstract: Memes are a dominant medium for online communication and manipulation because meaning emerges from interactions between embedded text, imagery, and cultural context. Existing meme research is distributed across tasks (hate, misogyny, propaganda, sentiment, humour) and languages, which limits cross-domain generalization. To address this gap we propose MemeLens, a unified multilingual and multitask explanation-enhanced Vision Language Model (VLM) for meme understanding. We consolidate 38 public meme datasets, filter and map dataset-specific labels into a shared taxonomy of $20$ tasks spanning harm, targets, figurative/pragmatic intent, and affect. We present a comprehensive empirical analysis across modeling paradigms, task categories, and datasets. Our findings suggest that robust meme understanding requires multimodal training, exhibits substantial variation across semantic categories, and remains sensitive to over-specialization when models are fine-tuned on individual datasets rather than trained in a unified setting. We will make the experimental resources and datasets publicly available for the community.

</details>


### [506] [Rethinking the AI Scientist: Interactive Multi-Agent Workflows for Scientific Discovery](https://arxiv.org/abs/2601.12542)
*Lukas Weidener,Marko Brkić,Mihailo Jovanović,Ritvik Singh,Chiara Baccin,Emre Ulgac,Alex Dobrin,Aakaash Meduri*

Main category: cs.AI

TL;DR: Deep Research是一个多智能体系统，能够在几分钟内完成交互式科学研究，相比传统批处理模式大幅缩短研究周期，在BixBench基准测试中取得最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有AI科学发现系统多为专有且采用批处理模式，每个研究周期需要数小时，无法实现实时研究人员指导，限制了AI在科学研究中的交互性和实用性。

Method: 采用多智能体架构，包含规划、数据分析、文献搜索和新颖性检测等专门智能体，通过持久世界状态保持跨迭代研究周期的上下文，支持半自主模式（带选择性人工检查点）和全自主模式两种工作流程。

Result: 在BixBench计算生物学基准测试中取得最先进性能：开放回答准确率48.8%，多项选择准确率64.5%，比现有基线提高14-26个百分点。系统能够在几分钟内完成研究周期，实现交互式科学调查。

Conclusion: Deep Research系统展示了AI辅助科学工作流程的实际可行性，通过多智能体架构和快速研究周期实现了交互式科学发现。同时分析了开放获取文献限制和自动新颖性评估挑战等实际部署考虑因素。

Abstract: Artificial intelligence systems for scientific discovery have demonstrated remarkable potential, yet existing approaches remain largely proprietary and operate in batch-processing modes requiring hours per research cycle, precluding real-time researcher guidance. This paper introduces Deep Research, a multi-agent system enabling interactive scientific investigation with turnaround times measured in minutes. The architecture comprises specialized agents for planning, data analysis, literature search, and novelty detection, unified through a persistent world state that maintains context across iterative research cycles. Two operational modes support different workflows: semi-autonomous mode with selective human checkpoints, and fully autonomous mode for extended investigations. Evaluation on the BixBench computational biology benchmark demonstrated state-of-the-art performance, achieving 48.8% accuracy on open response and 64.5% on multiple-choice evaluation, exceeding existing baselines by 14 to 26 percentage points. Analysis of architectural constraints, including open access literature limitations and challenges inherent to automated novelty assessment, informs practical deployment considerations for AI-assisted scientific workflows.

</details>


### [507] [How Clinicians Think and What AI Can Learn From It](https://arxiv.org/abs/2601.12547)
*Dipayan Sengupta,Saumya Panda*

Main category: cs.AI

TL;DR: 论文主张临床AI应从预测引擎转向支持顺序决策，采用稳健的序数规则而非期望效用优化，以匹配临床推理的快速节俭启发式特点。


<details>
  <summary>Details</summary>
Motivation: 当前临床AI系统主要作为预测引擎（生成标签或风险评分），但真实的临床推理是时间受限、顺序控制的不确定性问题。临床医生在遗憾、约束和患者价值观指导下，交替进行信息收集和不可逆行动。需要AI系统更好地匹配临床推理的实际计算基础。

Method: 提出临床推理的主导计算基础是序数、非补偿性决策，而非基数优化。临床医生依赖快速节俭的词典式启发式（如快速节俭树），在检查少量固定线索后提前停止。为这种算法提供规范性理由：1）临床权衡主要通过人类判断构建，仅在绝对尺度上弱可测；2）偏好和信号获取结构粗糙，存在持久不确定性。建议采用稳健优势/过滤规则（ε-优势、极大极小）而非期望效用优化。

Result: 提出临床对齐的AI蓝图：使用丰富模型进行信念和轨迹建模，但通过稳健序数规则选择行动；将启发式视为低维特例；将AI部署为"选择性复杂性"——主要在决策脆弱且信息具有正期望影响时用于打破平局。

Conclusion: 临床AI应转向支持顺序决策过程，采用稳健的序数决策规则而非期望效用优化，以更好地匹配临床推理的实际特点，提高决策稳定性并减少脆弱性。

Abstract: Most clinical AI systems operate as prediction engines -- producing labels or risk scores -- yet real clinical reasoning is a time-bounded, sequential control problem under uncertainty. Clinicians interleave information gathering with irreversible actions, guided by regret, constraints and patient values. We argue that the dominant computational substrate of clinician reasoning is not cardinal optimization but ordinal, non-compensatory decision-making: Clinicians frequently rely on fast-and-frugal, lexicographic heuristics (e.g., fast-and-frugal trees) that stop early after checking a small, fixed sequence of cues. We provide a normative rationale for why such algorithms are not merely bounded rationality shortcuts, but can be epistemically preferred in medicine. First, many clinical trade-offs are constructed through human judgment and are only weakly measurable on absolute scales; without strong measurement axioms, only orderings are invariant, motivating an ordinal-by-default stance. Second, preference and signal elicitation are structurally crude: The mapping from truth $\to$ perception $\to$ inference $\to$ recorded variables introduces layered noise, leaving a persistent uncertainty floor. When this 'crudeness' overwhelms the decision margin, plug-in expected-utility optimization becomes brittle (high flip probability under small perturbations), whereas robust dominance/filtering rules ($ε$-dominance, maximin) stabilize decisions.Finally, we outline a clinician-aligned AI blueprint: Use rich models for beliefs and trajectories, but choose actions through robust ordinal rules; treat heuristics as the low-dimensional special case; and deploy AI as 'selective complexity' -- invoked mainly for tie-breaking when decisions are fragile and information has positive expected impact.

</details>


### [508] [Agentic Artificial Intelligence (AI): Architectures, Taxonomies, and Evaluation of Large Language Model Agents](https://arxiv.org/abs/2601.12560)
*Arunkumar V,Gangadharan G. R.,Rajkumar Buyya*

Main category: cs.AI

TL;DR: 该论文提出了一个统一的智能体架构分类法，将AI智能体分解为感知、大脑、规划、行动、工具使用和协作六个核心组件，并探讨了从线性推理到原生推理模型、从固定API到开放标准的演进趋势。


<details>
  <summary>Details</summary>
Motivation: AI正从仅生成文本的模型转向智能体AI，其中系统作为能够感知、推理、规划和行动的自主实体。大型语言模型不再仅作为被动知识引擎，而是作为结合记忆、工具使用和环境反馈来追求扩展目标的认知控制器。然而，从简单单循环智能体到分层多智能体系统的各种新兴设计使得这一领域难以导航。

Method: 论文提出一个统一的分类法，将智能体分解为六个核心组件：感知、大脑、规划、行动、工具使用和协作。使用这一框架描述从线性推理程序到原生推理时间推理模型的转变，以及从固定API调用到开放标准（如模型上下文协议和原生计算机使用）的过渡。同时对智能体运行环境进行分类，并回顾当前评估实践。

Result: 建立了一个系统化的智能体架构分类框架，明确了智能体的核心组件和演进路径。识别了智能体运行的不同环境类型（数字操作系统、具身机器人等专业领域）。总结了当前评估方法，并指出了该领域面临的开放挑战。

Conclusion: 论文通过提出统一的智能体架构分类法，为理解AI智能体领域提供了系统框架。同时指出了幻觉行为、无限循环、提示注入等开放挑战，并展望了未来研究方向，旨在推动更稳健可靠的自主系统发展。

Abstract: Artificial Intelligence is moving from models that only generate text to Agentic AI, where systems behave as autonomous entities that can perceive, reason, plan, and act. Large Language Models (LLMs) are no longer used only as passive knowledge engines but as cognitive controllers that combine memory, tool use, and feedback from their environment to pursue extended goals. This shift already supports the automation of complex workflows in software engineering, scientific discovery, and web navigation, yet the variety of emerging designs, from simple single loop agents to hierarchical multi agent systems, makes the landscape hard to navigate. In this paper, we investigate architectures and propose a unified taxonomy that breaks agents into Perception, Brain, Planning, Action, Tool Use, and Collaboration. We use this lens to describe the move from linear reasoning procedures to native inference time reasoning models, and the transition from fixed API calls to open standards like the Model Context Protocol (MCP) and Native Computer Use. We also group the environments in which these agents operate, including digital operating systems, embodied robotics, and other specialized domains, and we review current evaluation practices. Finally, we highlight open challenges, such as hallucination in action, infinite loops, and prompt injection, and outline future research directions toward more robust and reliable autonomous systems.

</details>


### [509] [STEP-LLM: Generating CAD STEP Models from Natural Language with Large Language Models](https://arxiv.org/abs/2601.12641)
*Xiangyu Shi,Junyang Ding,Xu Zhao,Sinong Zhan,Payal Mohapatra,Daniel Quispe,Kojo Welbeck,Jian Cao,Wei Chen,Ping Guo,Qi Zhu*

Main category: cs.AI

TL;DR: STEP-LLM：首个通过大语言模型从自然语言直接生成STEP格式CAD模型的方法，解决了传统文本到CAD方法在制造兼容性上的局限性


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的文本到CAD方法主要关注命令序列或脚本格式（如CadQuery），但这些格式依赖于特定内核且缺乏制造通用性。STEP文件作为广泛采用的中性边界表示格式直接兼容制造，但其图结构、交叉引用的特性对自回归大语言模型构成独特挑战

Method: 1. 构建约40K STEP-文本描述对的数据集；2. 针对STEP图结构格式设计新颖预处理：基于深度优先搜索的重新序列化线性化交叉引用同时保持局部性，以及链式思维风格的结构注释指导全局一致性；3. 集成检索增强生成以在监督微调中基于相关示例进行预测；4. 通过强化学习使用基于Chamfer距离的几何奖励优化生成质量

Result: STEP-LLM在几何保真度上持续优于Text2CAD基线：RAG模块显著提升完整性和可渲染性，DFS重新序列化增强整体准确性，RL进一步减少几何差异。度量和视觉比较均证实STEP-LLM生成形状具有更高保真度

Conclusion: 该研究证明了通过大语言模型从自然语言生成STEP模型的可行性，展示了其民主化制造CAD设计的潜力，为制造兼容的CAD生成提供了新途径

Abstract: Computer-aided design (CAD) is vital to modern manufacturing, yet model creation remains labor-intensive and expertise-heavy. To enable non-experts to translate intuitive design intent into manufacturable artifacts, recent large language models-based text-to-CAD efforts focus on command sequences or script-based formats like CadQuery. However, these formats are kernel-dependent and lack universality for manufacturing. In contrast, the Standard for the Exchange of Product Data (STEP, ISO 10303) file is a widely adopted, neutral boundary representation (B-rep) format directly compatible with manufacturing, but its graph-structured, cross-referenced nature poses unique challenges for auto-regressive LLMs. To address this, we curate a dataset of ~40K STEP-caption pairs and introduce novel preprocessing tailored for the graph-structured format of STEP, including a depth-first search-based reserialization that linearizes cross-references while preserving locality and chain-of-thought(CoT)-style structural annotations that guide global coherence. We integrate retrieval-augmented generation to ground predictions in relevant examples for supervised fine-tuning, and refine generation quality through reinforcement learning with a specific Chamfer Distance-based geometric reward. Experiments demonstrate consistent gains of our STEP-LLM in geometric fidelity over the Text2CAD baseline, with improvements arising from multiple stages of our framework: the RAG module substantially enhances completeness and renderability, the DFS-based reserialization strengthens overall accuracy, and the RL further reduces geometric discrepancy. Both metrics and visual comparisons confirm that STEP-LLM generates shapes with higher fidelity than Text2CAD. These results show the feasibility of LLM-driven STEP model generation from natural language, showing its potential to democratize CAD design for manufacturing.

</details>


### [510] [MedConsultBench: A Full-Cycle, Fine-Grained, Process-Aware Benchmark for Medical Consultation Agents](https://arxiv.org/abs/2601.12661)
*Chuhan Qiao,Jianghua Huang,Daxing Zhao,Ziding Liu,Yanjun Shen,Bing Cheng,Wei Lin,Kai Wu*

Main category: cs.AI

TL;DR: MedConsultBench是一个评估医疗咨询代理的综合性框架，通过原子信息单元(AIUs)追踪临床信息获取，覆盖完整在线咨询周期，发现高诊断准确率常掩盖信息收集效率和用药安全方面的显著缺陷。


<details>
  <summary>Details</summary>
Motivation: 当前医疗咨询代理评估过于关注结果导向任务，忽视了端到端流程完整性和临床安全性。现有交互基准往往碎片化且粗粒度，无法捕捉专业咨询所需的结构化询问逻辑和诊断严谨性。

Method: 提出MedConsultBench框架，覆盖从病史采集、诊断到治疗计划和随访问答的完整临床工作流程。引入原子信息单元(AIUs)在子轮次层面追踪临床信息获取，通过22个细粒度指标监控关键事实的提取过程。处理在线咨询固有的不明确性和模糊性，评估不确定性感知的简洁询问，强调用药方案兼容性，并通过约束尊重计划修订处理现实处方后随访问答。

Result: 对19个大语言模型的系统评估显示，高诊断准确率常常掩盖了信息收集效率和用药安全方面的显著缺陷。结果揭示了理论医学知识与临床实践能力之间的关键差距。

Conclusion: MedConsultBench为将医疗AI与真实世界临床护理的细微要求对齐提供了严格基础，强调了需要超越单纯诊断准确性来评估医疗咨询代理的重要性。

Abstract: Current evaluations of medical consultation agents often prioritize outcome-oriented tasks, frequently overlooking the end-to-end process integrity and clinical safety essential for real-world practice. While recent interactive benchmarks have introduced dynamic scenarios, they often remain fragmented and coarse-grained, failing to capture the structured inquiry logic and diagnostic rigor required in professional consultations. To bridge this gap, we propose MedConsultBench, a comprehensive framework designed to evaluate the complete online consultation cycle by covering the entire clinical workflow from history taking and diagnosis to treatment planning and follow-up Q\&A. Our methodology introduces Atomic Information Units (AIUs) to track clinical information acquisition at a sub-turn level, enabling precise monitoring of how key facts are elicited through 22 fine-grained metrics. By addressing the underspecification and ambiguity inherent in online consultations, the benchmark evaluates uncertainty-aware yet concise inquiry while emphasizing medication regimen compatibility and the ability to handle realistic post-prescription follow-up Q\&A via constraint-respecting plan revisions. Systematic evaluation of 19 large language models reveals that high diagnostic accuracy often masks significant deficiencies in information-gathering efficiency and medication safety. These results underscore a critical gap between theoretical medical knowledge and clinical practice ability, establishing MedConsultBench as a rigorous foundation for aligning medical AI with the nuanced requirements of real-world clinical care.

</details>


### [511] [Empowering All-in-Loop Health Management of Spacecraft Power System in the Mega-Constellation Era via Human-AI Collaboration](https://arxiv.org/abs/2601.12667)
*Yi Di,Zhibin Zhao,Fujin Wang,Xue Liu,Jiafeng Tang,Jiaxin Ren,Zhi Zhai,Xuefeng Chen*

Main category: cs.AI

TL;DR: 提出SpaceHMchat框架，用于卫星巨型星座时代的航天器电源系统健康管理，通过人机协作实现全回路健康管理，并开源首个相关数据集。


<details>
  <summary>Details</summary>
Motivation: 卫星巨型星座时代即将到来，航天器数量将指数增长，而航天器电源系统作为关键系统故障率高，需要适应大规模健康管理的新范式。

Method: 提出底层能力对齐原则，开发开源人机协作框架SpaceHMchat，涵盖工况识别、异常检测、故障定位和维护决策全回路，并建立硬件真实的故障注入实验平台。

Result: 在23个量化指标上表现优异：工况识别逻辑推理结论准确率100%，异常检测工具调用成功率超99%，故障定位精度超90%，维护决策知识库搜索时间小于3分钟。

Conclusion: SpaceHMchat框架能有效适应卫星巨型星座时代的健康管理需求，同时开源了首个航天器电源系统全回路健康管理数据集，包含4个子数据集、17种故障类型、超70万时间戳。

Abstract: It is foreseeable that the number of spacecraft will increase exponentially, ushering in an era dominated by satellite mega-constellations (SMC). This necessitates a focus on energy in space: spacecraft power systems (SPS), especially their health management (HM), given their role in power supply and high failure rates. Providing health management for dozens of SPS and for thousands of SPS represents two fundamentally different paradigms. Therefore, to adapt the health management in the SMC era, this work proposes a principle of aligning underlying capabilities (AUC principle) and develops SpaceHMchat, an open-source Human-AI collaboration (HAIC) framework for all-in-loop health management (AIL HM). SpaceHMchat serves across the entire loop of work condition recognition, anomaly detection, fault localization, and maintenance decision making, achieving goals such as conversational task completion, adaptive human-in-the-loop learning, personnel structure optimization, knowledge sharing, efficiency enhancement, as well as transparent reasoning and improved interpretability. Meanwhile, to validate this exploration, a hardware-realistic fault injection experimental platform is established, and its simulation model is built and open-sourced, both fully replicating the real SPS. The corresponding experimental results demonstrate that SpaceHMchat achieves excellent performance across 23 quantitative metrics, such as 100% conclusion accuracy in logical reasoning of work condition recognition, over 99% success rate in anomaly detection tool invocation, over 90% precision in fault localization, and knowledge base search time under 3 minutes in maintenance decision-making. Another contribution of this work is the release of the first-ever AIL HM dataset of SPS. This dataset contains four sub-datasets, involving 4 types of AIL HM sub-tasks, 17 types of faults, and over 700,000 timestamps.

</details>


### [512] [Logic-Guided Multistage Inference for Explainable Multidefendant Judgment Prediction](https://arxiv.org/abs/2601.12688)
*Xu Zhang,Qinghua Wang,Mengyang Zhao,Fang Wang,Cunquan Qu*

Main category: cs.AI

TL;DR: 该论文提出了一种用于多被告人案件责任分配的掩码多阶段推理框架，结合量刑逻辑和Transformer编码器，通过定向掩码机制和比较数据构建策略来区分主犯与从犯的责任。


<details>
  <summary>Details</summary>
Motivation: 在多被告人刑事案件中，司法表述常常模糊被告人的角色，这阻碍了AI驱动的司法分析。现有方法难以精确区分主犯与从犯的责任，影响了司法公平性和智能司法系统的有效性。

Method: 提出了掩码多阶段推理（MMSI）框架：1）将量刑逻辑融入预训练Transformer编码器；2）使用定向掩码机制澄清被告人角色；3）采用比较数据构建策略增强模型对主从犯责任差异的敏感性；4）通过广播机制将预测的罪责标签整合到回归模型中，结合犯罪描述和法庭观点。

Result: 在自定义的故意伤害案件数据集IMLJP上评估，MMSI框架在基于角色的罪责区分方面取得了显著准确率提升，优于基线方法，为智能司法系统提供了有效解决方案。

Conclusion: 该研究为多被告人案件中的责任分配问题提供了鲁棒的解决方案，通过结合法律可解释性和AI技术，增强了智能司法系统的能力，相关代码已公开。

Abstract: Crime disrupts societal stability, making law essential for balance. In multidefendant cases, assigning responsibility is complex and challenges fairness, requiring precise role differentiation. However, judicial phrasing often obscures the roles of the defendants, hindering effective AI-driven analyses. To address this issue, we incorporate sentencing logic into a pretrained Transformer encoder framework to enhance the intelligent assistance in multidefendant cases while ensuring legal interpretability. Within this framework an oriented masking mechanism clarifies roles and a comparative data construction strategy improves the model's sensitivity to culpability distinctions between principals and accomplices. Predicted guilt labels are further incorporated into a regression model through broadcasting, consolidating crime descriptions and court views. Our proposed masked multistage inference (MMSI) framework, evaluated on the custom IMLJP dataset for intentional injury cases, achieves significant accuracy improvements, outperforming baselines in role-based culpability differentiation. This work offers a robust solution for enhancing intelligent judicial systems, with publicly code available.

</details>


### [513] [Neurosymbolic LoRA: Why and When to Tune Weights vs. Rewrite Prompts](https://arxiv.org/abs/2601.12711)
*Kevin Wang,Neel P. Bhatt,Cong Liu,Junbo Li,Runjin Chen,Yihan Xi,Timothy Barclay,Alvaro Velasquez,Ufuk Topcu,Zhangyang Wang*

Main category: cs.AI

TL;DR: 提出神经符号LoRA框架，动态结合数值更新和符号操作，在保持内存效率的同时提升LLM适应能力


<details>
  <summary>Details</summary>
Motivation: 数值微调擅长注入新事实知识，符号更新能灵活控制风格和对齐而无需重新训练，但两者各有局限，需要结合互补

Method: 神经符号LoRA框架：统一监控信号和基于奖励的分类器决定何时使用LoRA进行事实重构，何时使用TextGrad进行token级编辑；将符号转换卸载到外部LLM以保持内存效率

Result: 在多个LLM骨干上的实验表明，神经符号LoRA始终优于纯数值或纯符号基线，展现出更优的适应性和性能提升

Conclusion: 交错使用数值和符号更新为语言模型微调解锁了新的多功能性水平，符号编辑过程中产生的精炼提示可作为高质量可重用训练数据

Abstract: Large language models (LLMs) can be adapted either through numerical updates that alter model parameters or symbolic manipulations that work on discrete prompts or logical constraints. While numerical fine-tuning excels at injecting new factual knowledge, symbolic updates offer flexible control of style and alignment without retraining. We introduce a neurosymbolic LoRA framework that dynamically combines these two complementary strategies. Specifically, we present a unified monitoring signal and a reward-based classifier to decide when to employ LoRA for deeper factual reconstruction and when to apply TextGrad for token-level edits. Our approach remains memory-efficient by offloading the symbolic transformations to an external LLM only when needed. Additionally, the refined prompts produced during symbolic editing serve as high-quality, reusable training data, an important benefit in data-scarce domains like mathematical reasoning. Extensive experiments across multiple LLM backbones show that neurosymbolic LoRA consistently outperforms purely numerical or purely symbolic baselines, demonstrating superior adaptability and improved performance. Our findings highlight the value of interleaving numerical and symbolic updates to unlock a new level of versatility in language model fine-tuning.

</details>


### [514] [Teaching Large Reasoning Models Effective Reflection](https://arxiv.org/abs/2601.12720)
*Hanbin Wang,Jingwei Song,Jinpeng Li,Qi Zhu,Fei Mi,Ganqu Cui,Yasheng Wang,Lifeng Shang*

Main category: cs.AI

TL;DR: 提出SCFT和RLERR方法解决大型推理模型的表面反思问题，通过自我批判微调和强化学习奖励机制提升推理准确性和反思质量。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型在复杂推理任务中表现出色，但存在表面反思问题——许多反思是肤浅的，对原始答案改进有限却带来计算开销。需要解决这种无效反思现象。

Method: 1. SCFT：自我批判微调框架，让模型批判自身输出，通过拒绝采样筛选高质量批判，使用批判目标微调模型。2. RLERR：在SCFT基础上，利用高质量反思构建奖励信号，通过强化学习引导模型内化自我纠正过程。

Result: 在AIME2024和AIME2025两个挑战性基准测试中，SCFT和RLERR显著提高了推理准确性和反思质量，优于最先进的基线方法。

Conclusion: 提出的SCFT和RLERR方法有效解决了大型推理模型的表面反思问题，通过增强模型的反思推理能力和内化自我纠正过程，提升了整体性能。

Abstract: Large Reasoning Models (LRMs) have recently shown impressive performance on complex reasoning tasks, often by engaging in self-reflective behaviors such as self-critique and backtracking. However, not all reflections are beneficial-many are superficial, offering little to no improvement over the original answer and incurring computation overhead. In this paper, we identify and address the problem of superficial reflection in LRMs. We first propose Self-Critique Fine-Tuning (SCFT), a training framework that enhances the model's reflective reasoning ability using only self-generated critiques. SCFT prompts models to critique their own outputs, filters high-quality critiques through rejection sampling, and fine-tunes the model using a critique-based objective. Building on this strong foundation, we further introduce Reinforcement Learning with Effective Reflection Rewards (RLERR). RLERR leverages the high-quality reflections initialized by SCFT to construct reward signals, guiding the model to internalize the self-correction process via reinforcement learning. Experiments on two challenging benchmarks, AIME2024 and AIME2025, show that SCFT and RLERR significantly improve both reasoning accuracy and reflection quality, outperforming state-of-the-art baselines. All data and codes are available at https://github.com/wanghanbinpanda/SCFT.

</details>


### [515] [Vision Language Models for Optimization-Driven Intent Processing in Autonomous Networks](https://arxiv.org/abs/2601.12744)
*Tasnim Ahmed,Yifan Zhu,Salimur Choudhury*

Main category: cs.AI

TL;DR: 本文提出了IntentOpt基准测试，评估视觉语言模型从网络草图生成优化代码的能力，发现视觉参数提取会降低执行成功率，开源模型性能远落后于闭源模型。


<details>
  <summary>Details</summary>
Motivation: 当前基于意图的网络系统需要操作员用文本描述网络拓扑和参数，但网络从业者通常通过图表进行推理。视觉语言模型能否处理带注释的网络草图并生成正确的优化代码尚未被探索。

Method: 创建了包含85个优化问题的IntentOpt基准测试，评估了4种视觉语言模型在三种提示策略下的表现，比较了多模态与纯文本输入的效果，并通过案例研究在实际网络测试平台上部署生成的代码。

Result: 视觉参数提取使执行成功率降低12-21个百分点，GPT-5-Mini从93%降至72%。思维链提示降低性能达13个百分点，开源模型性能远落后于闭源模型（Llama-3.2-11B-Vision仅18%，而GPT-5-Mini达75%）。

Conclusion: 研究建立了当前视觉语言模型在基于意图的网络系统中生成优化代码的基准能力和局限性，展示了通过模型上下文协议在实际网络基础设施中部署生成代码的可行性。

Abstract: Intent-Based Networking (IBN) allows operators to specify high-level network goals rather than low-level configurations. While recent work demonstrates that large language models can automate configuration tasks, a distinct class of intents requires generating optimization code to compute provably optimal solutions for traffic engineering, routing, and resource allocation. Current systems assume text-based intent expression, requiring operators to enumerate topologies and parameters in prose. Network practitioners naturally reason about structure through diagrams, yet whether Vision-Language Models (VLMs) can process annotated network sketches into correct optimization code remains unexplored. We present IntentOpt, a benchmark of 85 optimization problems across 17 categories, evaluating four VLMs (GPT-5-Mini, Claude-Haiku-4.5, Gemini-2.5-Flash, Llama-3.2-11B-Vision) under three prompting strategies on multimodal versus text-only inputs. Our evaluation shows that visual parameter extraction reduces execution success by 12-21 percentage points (pp), with GPT-5-Mini dropping from 93% to 72%. Program-of-thought prompting decreases performance by up to 13 pp, and open-source models lag behind closed-source ones, with Llama-3.2-11B-Vision reaching 18% compared to 75% for GPT-5-Mini. These results establish baseline capabilities and limitations of current VLMs for optimization code generation within an IBN system. We also demonstrate practical feasibility through a case study that deploys VLM-generated code to network testbed infrastructure using Model Context Protocol.

</details>


### [516] [VIRO: Robust and Efficient Neuro-Symbolic Reasoning with Verification for Referring Expression Comprehension](https://arxiv.org/abs/2601.12781)
*Hyejin Park,Junhyuk Kwon,Suha Kwak,Jungseul Ok*

Main category: cs.AI

TL;DR: VIRO框架通过集成轻量级验证器到神经符号推理步骤中，解决REC任务中的级联错误问题，在目标存在和不存在场景下都表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有神经符号REC方法假设中间推理步骤准确，但错误检测和无效关系会在推理链中传播，导致高置信度的假阳性结果，特别是在目标不存在的情况下。

Method: 提出验证集成推理算子（VIRO）框架，在推理步骤中嵌入轻量级算子级验证器。每个算子执行并验证其输出（如对象存在性或空间关系），当验证条件不满足时能鲁棒处理无目标情况。

Result: 在目标存在和无目标设置下达到61.1%的平衡准确率，实现最先进性能；在真实世界自我中心数据上展示泛化能力；具有高计算效率（吞吐量）、高可靠性（程序失败率低于0.3%）和可扩展性。

Conclusion: VIRO通过集成验证机制有效解决了神经符号REC中的级联错误问题，在准确性、可靠性、效率和可扩展性方面都有显著优势，为处理复杂视觉语言理解任务提供了稳健的解决方案。

Abstract: Referring Expression Comprehension (REC) aims to localize the image region corresponding to a natural-language query. Recent neuro-symbolic REC approaches leverage large language models (LLMs) and vision-language models (VLMs) to perform compositional reasoning, decomposing queries 4 structured programs and executing them step-by-step. While such approaches achieve interpretable reasoning and strong zero-shot generalization, they assume that intermediate reasoning steps are accurate. However, this assumption causes cascading errors: false detections and invalid relations propagate through the reasoning chain, yielding high-confidence false positives even when no target is present in the image. To address this limitation, we introduce Verification-Integrated Reasoning Operators (VIRO), a neuro-symbolic framework that embeds lightweight operator-level verifiers within reasoning steps. Each operator executes and validates its output, such as object existence or spatial relationship, thereby allowing the system to robustly handle no-target cases when verification conditions are not met. Our framework achieves state-of-the-art performance, reaching 61.1% balanced accuracy across target-present and no-target settings, and demonstrates generalization to real-world egocentric data. Furthermore, VIRO shows superior computational efficiency in terms of throughput, high reliability with a program failure rate of less than 0.3%, and scalability through decoupled program generation from execution.

</details>


### [517] [SL-CBM: Enhancing Concept Bottleneck Models with Semantic Locality for Better Interpretability](https://arxiv.org/abs/2601.12804)
*Hanwei Zhang,Luo Cheng,Rui Wen,Yang Zhang,Lijun Zhang,Holger Hermanns*

Main category: cs.AI

TL;DR: SL-CBM通过引入语义局部性增强概念瓶颈模型，生成空间一致的概念和类别显著性图，提高可解释性和可靠性


<details>
  <summary>Details</summary>
Motivation: 现有概念瓶颈模型(CBMs)存在局部忠实性差的问题，无法将概念与有意义的图像区域空间对齐，限制了可解释性和可靠性

Method: 提出SL-CBM，集成1x1卷积层和交叉注意力机制，在概念和类别层面生成空间一致的显著性图，增强概念、图像区域和最终预测的对齐

Result: 在图像数据集上的实验表明，SL-CBM显著提高了局部忠实性、解释质量和干预效果，同时保持有竞争力的分类准确率

Conclusion: SL-CBM填补了基于概念的推理和空间可解释性之间的空白，为可解释和可信的概念模型设定了新标准

Abstract: Explainable AI (XAI) is crucial for building transparent and trustworthy machine learning systems, especially in high-stakes domains. Concept Bottleneck Models (CBMs) have emerged as a promising ante-hoc approach that provides interpretable, concept-level explanations by explicitly modeling human-understandable concepts. However, existing CBMs often suffer from poor locality faithfulness, failing to spatially align concepts with meaningful image regions, which limits their interpretability and reliability. In this work, we propose SL-CBM (CBM with Semantic Locality), a novel extension that enforces locality faithfulness by generating spatially coherent saliency maps at both concept and class levels. SL-CBM integrates a 1x1 convolutional layer with a cross-attention mechanism to enhance alignment between concepts, image regions, and final predictions. Unlike prior methods, SL-CBM produces faithful saliency maps inherently tied to the model's internal reasoning, facilitating more effective debugging and intervention. Extensive experiments on image datasets demonstrate that SL-CBM substantially improves locality faithfulness, explanation quality, and intervention efficacy while maintaining competitive classification accuracy. Our ablation studies highlight the importance of contrastive and entropy-based regularization for balancing accuracy, sparsity, and faithfulness. Overall, SL-CBM bridges the gap between concept-based reasoning and spatial explainability, setting a new standard for interpretable and trustworthy concept-based models.

</details>


### [518] [MirrorGuard: Toward Secure Computer-Use Agents via Simulation-to-Real Reasoning Correction](https://arxiv.org/abs/2601.12822)
*Wenqi Zhang,Yulin Shen,Changyue Jiang,Jiarun Dai,Geng Hong,Xudong Pan*

Main category: cs.AI

TL;DR: MirrorGuard是一个即插即用的防御框架，通过模拟训练提升计算机使用代理的安全性，在保持代理实用性的同时显著降低安全风险


<details>
  <summary>Details</summary>
Motivation: 大型基础模型集成的计算机使用代理能够通过GUI自主与操作系统交互，但恶意指令或视觉提示注入会触发不安全推理，导致有害的系统级操作。现有防御方法（如基于检测的阻断）虽能防止损害，但经常过早中止任务，降低了代理的实用性

Method: 提出神经符号模拟管道，在纯文本模拟环境中生成真实的高风险GUI交互轨迹，捕捉不安全推理模式和潜在系统危险，而无需执行真实操作。在模拟环境中，MirrorGuard学习在CUAs产生和执行不安全操作之前拦截并纠正其不安全推理链

Result: 在字节跳动UI-TARS系统上，MirrorGuard将不安全率从66.5%降至13.0%，同时保持较低的误拒率。相比之下，最先进的GuardAgent仅降至53.9%，且误拒率高15.4%。在多样化基准测试和CUA架构上的广泛评估显示，MirrorGuard显著减轻了安全风险

Conclusion: 模拟衍生的防御能够提供强大的现实世界保护，同时保持代理的基本实用性。MirrorGuard证明了通过模拟训练可以有效提升计算机使用代理的安全性

Abstract: Large foundation models are integrated into Computer Use Agents (CUAs), enabling autonomous interaction with operating systems through graphical user interfaces (GUIs) to perform complex tasks. This autonomy introduces serious security risks: malicious instructions or visual prompt injections can trigger unsafe reasoning and cause harmful system-level actions. Existing defenses, such as detection-based blocking, prevent damage but often abort tasks prematurely, reducing agent utility. In this paper, we present MirrorGuard, a plug-and-play defense framework that uses simulation-based training to improve CUA security in the real world. To reduce the cost of large-scale training in operating systems, we propose a novel neural-symbolic simulation pipeline, which generates realistic, high-risk GUI interaction trajectories entirely in a text-based simulated environment, which captures unsafe reasoning patterns and potential system hazards without executing real operations. In the simulation environment, MirrorGuard learns to intercept and rectify insecure reasoning chains of CUAs before they produce and execute unsafe actions. In real-world testing, extensive evaluations across diverse benchmarks and CUA architectures show that MirrorGuard significantly mitigates security risks. For instance, on the ByteDance UI-TARS system, it reduces the unsafe rate from 66.5% to 13.0% while maintaining a marginal false refusal rate (FRR). In contrast, the state-of-the-art GuardAgent only achieves a reduction to 53.9% and suffers from a 15.4% higher FRR. Our work proves that simulation-derived defenses can provide robust, real-world protection while maintaining the fundamental utility of the agent. Our code and model are publicly available at https://bmz-q-q.github.io/MirrorGuard/.

</details>


### [519] [SCULPT: Constraint-Guided Pruned MCTS that Carves Efficient Paths for Mathematical Reasoning](https://arxiv.org/abs/2601.12842)
*Qitong Fang,Haotian Li,Xu Wang*

Main category: cs.AI

TL;DR: SCULPT：一种约束引导的蒙特卡洛树搜索方法，通过领域感知约束（维度一致性、类型兼容性、数值合理性等）来引导LLM代理的搜索过程，避免随机探索，提高推理稳定性和准确性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM代理工作流中的搜索策略依赖随机探索，经常遍历不合理的推理分支，因为现有方法使用通用提示或弱领域先验来采样候选步骤，导致在操作符、单位和格式上的近乎随机游走。

Method: 提出SCULPT方法，将领域感知评分整合到蒙特卡洛树搜索（MCTS）的选择、扩展、模拟和反向传播阶段。使用符号检查（维度一致性、类型兼容性、数值合理性、深度控制和多样性）和结构模式指导来评分和剪枝动作。

Result: 在相同LLM配置下，SCULPT在多个数据集上带来稳定改进；使用GPT-5.2的额外结果评估了执行器可迁移性和前沿推理模型的性能。

Conclusion: 领域感知约束可以在保持效率和推理稳定性的同时提高准确性，为LLM代理工作流提供了更有序的探索策略。

Abstract: Automated agent workflows can enhance the problem-solving ability of large language models (LLMs), but common search strategies rely on stochastic exploration and often traverse implausible branches. This occurs because current pipelines sample candidate steps from generic prompts or learned policies with weak domain priors, yielding near-random walks over operators, units, and formats. To promote ordered exploration, this paper introduces SCULPT, a constraint-guided approach for Monte Carlo Tree Search (MCTS) that integrates domain-aware scoring into selection, expansion, simulation, and backpropagation. SCULPT scores and prunes actions using a combination of symbolic checks (dimensional consistency, type compatibility, magnitude sanity, depth control, and diversity) and structural pattern guidance, thereby steering the search toward plausible reasoning paths. Under matched LLM configurations, SCULPT yields stable improvements on multiple datasets; additional results with GPT-5.2 assess executor transferability and performance on frontier reasoning models. Overall, domain-aware constraints can improve accuracy while maintaining efficiency and reasoning stability.

</details>


### [520] [Mining Citywide Dengue Spread Patterns in Singapore Through Hotspot Dynamics from Open Web Data](https://arxiv.org/abs/2601.12856)
*Liping Huang,Gaoxi Xiao,Stefan Ma,Hechang Chen,Shisong Tang,Flora Salim*

Main category: cs.AI

TL;DR: 提出一个从公开登革热病例数据中挖掘城市区域间潜在传播链的新框架，通过梯度下降优化隐藏传播网络，用于预测热点区域并验证传播模式一致性，在新加坡案例中取得良好预测效果。


<details>
  <summary>Details</summary>
Motivation: 登革热在热带城市地区持续构成公共卫生挑战，需要从被动应对转向主动干预。传统方法将病例视为孤立报告，忽略了区域间的传播联系，无法有效预测传播风险。

Method: 从公开登革热病例数据中挖掘区域间潜在传播链，建立模型分析热点形成如何受邻近区域疫情动态影响。通过梯度下降优化隐藏传播网络，利用连续数周数据验证传播模式的稳定性，将病例数据转化为预测和解释资源。

Result: 新加坡2013-2018年和2020年的案例研究表明，仅需四周热点历史数据即可达到平均F-score 0.79。学习到的传播链与通勤流量高度一致，揭示了隐藏的疫情传播与人类移动性之间的可解释关系。

Conclusion: 该框架将公开的病例数据转化为预测性和解释性资源，推进了流行病建模，为公共卫生规划、早期干预和城市韧性提供了可扩展、低成本的工具，实现了从简单报告病例到挖掘验证隐藏传播动态的转变。

Abstract: Dengue, a mosquito-borne disease, continues to pose a persistent public health challenge in urban areas, particularly in tropical regions such as Singapore. Effective and affordable control requires anticipating where transmission risks are likely to emerge so that interventions can be deployed proactively rather than reactively. This study introduces a novel framework that uncovers and exploits latent transmission links between urban regions, mined directly from publicly available dengue case data. Instead of treating cases as isolated reports, we model how hotspot formation in one area is influenced by epidemic dynamics in neighboring regions. While mosquito movement is highly localized, long-distance transmission is often driven by human mobility, and in our case study, the learned network aligns closely with commuting flows, providing an interpretable explanation for citywide spread. These hidden links are optimized through gradient descent and used not only to forecast hotspot status but also to verify the consistency of spreading patterns, by examining the stability of the inferred network across consecutive weeks. Case studies on Singapore during 2013-2018 and 2020 show that four weeks of hotspot history are sufficient to achieve an average F-score of 0.79. Importantly, the learned transmission links align with commuting flows, highlighting the interpretable interplay between hidden epidemic spread and human mobility. By shifting from simply reporting dengue cases to mining and validating hidden spreading dynamics, this work transforms open web-based case data into a predictive and explanatory resource. The proposed framework advances epidemic modeling while providing a scalable, low-cost tool for public health planning, early intervention, and urban resilience.

</details>


### [521] [Human Emotion Verification by Action Languages via Answer Set Programming](https://arxiv.org/abs/2601.12912)
*Andreas Brännström,Juan Carlos Nieves*

Main category: cs.AI

TL;DR: C-MT是一种基于ASP和转移系统构建的动作语言，用于建模人类心理状态在可观察动作序列下的演化，特别关注情绪等心理状态的动态变化。


<details>
  <summary>Details</summary>
Motivation: 现有方法缺乏对可控智能体行为的支持，且无法限制动作带来的不良心理副作用。需要一种能够形式化心理状态动态变化、支持受控推理的框架。

Method: 基于ASP和转移系统构建C-MT语言，整合情绪评估理论等心理学理论，形式化多维心理状态配置。引入"forbids to cause"因果规则和专门的心理状态动态表达式，将心理变化原则转化为转移约束和不变性属性。

Result: C-MT能够建模心理状态间的有效转移原则，通过轨迹分析支持受控推理。框架支持通过分析遵循不同心理学原则的轨迹来比较不同的变化动态，并应用于情绪验证模型设计。

Conclusion: C-MT为人类心理状态的动态演化提供了受控推理框架，能够形式化心理变化原则并支持不同心理学理论的比较，在情绪验证等应用场景中具有实用价值。

Abstract: In this paper, we introduce the action language C-MT (Mind Transition Language). It is built on top of answer set programming (ASP) and transition systems to represent how human mental states evolve in response to sequences of observable actions. Drawing on well-established psychological theories, such as the Appraisal Theory of Emotion, we formalize mental states, such as emotions, as multi-dimensional configurations. With the objective to address the need for controlled agent behaviors and to restrict unwanted mental side-effects of actions, we extend the language with a novel causal rule, forbids to cause, along with expressions specialized for mental state dynamics, which enables the modeling of principles for valid transitions between mental states. These principles of mental change are translated into transition constraints, and properties of invariance, which are rigorously evaluated using transition systems in terms of so-called trajectories. This enables controlled reasoning about the dynamic evolution of human mental states. Furthermore, the framework supports the comparison of different dynamics of change by analyzing trajectories that adhere to different psychological principles. We apply the action language to design models for emotion verification. Under consideration in Theory and Practice of Logic Programming (TPLP).

</details>


### [522] [Actionable Interpretability Must Be Defined in Terms of Symmetries](https://arxiv.org/abs/2601.12913)
*Pietro Barbiero,Mateo Espinosa Zarlenga,Francesco Giannini,Alberto Termine,Filippo Bonchi,Mateja Jamnik,Giuseppe Marra*

Main category: cs.AI

TL;DR: 论文认为当前AI可解释性研究定义不具可操作性，提出基于对称性的可操作定义，四个对称性足以推导可解释模型类别和统一推理框架。


<details>
  <summary>Details</summary>
Motivation: 当前AI可解释性研究存在根本性问题，现有定义缺乏可操作性，无法提供具体的建模和推理规则，导致研究进展受限。

Method: 提出基于对称性的可操作性定义，假设四个对称性足以：1）激发核心可解释性属性，2）刻画可解释模型类别，3）推导统一的可解释推理框架（如对齐、干预和反事实）作为贝叶斯逆问题。

Result: 建立了基于对称性的可解释性理论框架，将可解释性定义为形式化原则，能够推导具体建模规则和推理方法。

Conclusion: 对称性为AI可解释性提供了可操作的定义基础，能够统一处理各种可解释性任务，为解决当前可解释性研究的根本问题提供了新方向。

Abstract: This paper argues that interpretability research in Artificial Intelligence is fundamentally ill-posed as existing definitions of interpretability are not *actionable*: they fail to provide formal principles from which concrete modelling and inferential rules can be derived. We posit that for a definition of interpretability to be actionable, it must be given in terms of *symmetries*. We hypothesise that four symmetries suffice to (i) motivate core interpretability properties, (ii) characterize the class of interpretable models, and (iii) derive a unified formulation of interpretable inference (e.g., alignment, interventions, and counterfactuals) as a form of Bayesian inversion.

</details>


### [523] [MagicGUI-RMS: A Multi-Agent Reward Model System for Self-Evolving GUI Agents via Automated Feedback Reflux](https://arxiv.org/abs/2601.13060)
*Zecheng Li,Zhihui Cao,Wenke Huang,Yudong Zhang,Keying Qi,Rui Wang,Zeyu Zheng,Jian Zhao,Hao Zhu,Hengxin Wu,Yuran Wang,Guitao Fan,Guokun Wu,Yicong Liu,Zhilin Gao,Haikun Xu,He Yang,Minqi Xiang,Xingyu Liu,Zuojian Wang*

Main category: cs.AI

TL;DR: MagicGUI-RMS是一个多智能体奖励模型系统，通过领域特定奖励模型和通用奖励模型的结合，实现GUI智能体的自适应轨迹评估、纠正反馈和自我进化学习能力。


<details>
  <summary>Details</summary>
Motivation: 当前GUI智能体面临两大核心挑战：1) 自动化评估智能体轨迹的困难；2) 大规模生成高质量训练数据以实现持续改进的难题。现有方法依赖人工标注或静态规则验证，限制了可扩展性和动态环境中的适应性。

Method: 1) 集成领域特定奖励模型(DS-RM)和通用奖励模型(GP-RM)，实现细粒度动作评估和跨异构GUI任务的鲁棒泛化；2) 设计结构化数据构建流水线，自动生成平衡多样的奖励数据集；3) 实现自动化数据回流机制，在运行时识别错误动作、提出改进方案并持续增强智能体行为。

Result: 实验表明MagicGUI-RMS在任务准确性和行为鲁棒性方面取得显著提升，为构建基于奖励自适应驱动的自我改进GUI智能体提供了原则性和有效的基础。

Conclusion: MagicGUI-RMS通过多智能体奖励模型系统解决了GUI智能体评估和训练数据生成的关键挑战，实现了自适应轨迹评估、纠正反馈和自我进化学习能力，为构建自我改进的GUI智能体提供了有效框架。

Abstract: Graphical user interface (GUI) agents are rapidly progressing toward autonomous interaction and reliable task execution across diverse applications. However, two central challenges remain unresolved: automating the evaluation of agent trajectories and generating high-quality training data at scale to enable continual improvement. Existing approaches often depend on manual annotation or static rule-based verification, which restricts scalability and limits adaptability in dynamic environments. We present MagicGUI-RMS, a multi-agent reward model system that delivers adaptive trajectory evaluation, corrective feedback, and self-evolving learning capabilities. MagicGUI-RMS integrates a Domain-Specific Reward Model (DS-RM) with a General-Purpose Reward Model (GP-RM), enabling fine-grained action assessment and robust generalization across heterogeneous GUI tasks. To support reward learning at scale, we design a structured data construction pipeline that automatically produces balanced and diverse reward datasets, effectively reducing annotation costs while maintaining sample fidelity. During execution, the reward model system identifies erroneous actions, proposes refined alternatives, and continuously enhances agent behavior through an automated data-reflux mechanism. Extensive experiments demonstrate that MagicGUI-RMS yields substantial gains in task accuracy, behavioral robustness. These results establish MagicGUI-RMS as a principled and effective foundation for building self-improving GUI agents driven by reward-based adaptation.

</details>


### [524] [Responsible AI for General-Purpose Systems: Overview, Challenges, and A Path Forward](https://arxiv.org/abs/2601.13122)
*Gourab K Patro,Himanshi Agrawal,Himanshu Gharat,Supriya Panigrahi,Nim Sherpa,Vishal Vaddina,Dagnachew Birru*

Main category: cs.AI

TL;DR: 本文分析通用AI系统的风险，提出其因输出自由度(DoFo)高而比任务特定AI更难满足负责任AI原则，并建立C2V2(控制、一致性、价值、真实性)框架来指导未来通用AI的负责任开发。


<details>
  <summary>Details</summary>
Motivation: 现代通用AI系统虽然功能强大，但存在幻觉、毒性、刻板印象等风险，使其不可信。作者旨在分析通用AI相比传统任务特定AI在满足负责任AI原则方面的挑战，并提出新的框架来解决这些问题。

Method: 1. 基于八个广泛接受的负责任AI原则(公平性、隐私、可解释性、鲁棒性、安全性、真实性、治理、可持续性)分析通用AI的风险和脆弱性；2. 提出输出自由度(DoFo)概念解释通用AI的挑战；3. 建立C2V2(控制、一致性、价值、真实性)需求框架；4. 评估现有技术(如AI对齐、检索增强生成、推理增强等)在满足这些需求方面的表现。

Result: 通用AI系统因非确定性高输出自由度(DoFo)而面临更严重的负责任AI挑战，传统任务特定AI的这些问题要么不存在、要么较轻且易缓解。C2V2框架为评估和设计负责任通用AI提供了系统化的方法。

Conclusion: 开发负责任通用AI需要通过C2V2维度形式化建模应用或领域相关的负责任AI要求，并采用系统设计方法结合多种技术来满足这些需求。这为未来通用AI的负责任发展提供了理论框架和实践指导。

Abstract: Modern general-purpose AI systems made using large language and vision models, are capable of performing a range of tasks like writing text articles, generating and debugging codes, querying databases, and translating from one language to another, which has made them quite popular across industries. However, there are risks like hallucinations, toxicity, and stereotypes in their output that make them untrustworthy. We review various risks and vulnerabilities of modern general-purpose AI along eight widely accepted responsible AI (RAI) principles (fairness, privacy, explainability, robustness, safety, truthfulness, governance, and sustainability) and compare how they are non-existent or less severe and easily mitigable in traditional task-specific counterparts. We argue that this is due to the non-deterministically high Degree of Freedom in output (DoFo) of general-purpose AI (unlike the deterministically constant or low DoFo of traditional task-specific AI systems), and there is a need to rethink our approach to RAI for general-purpose AI. Following this, we derive C2V2 (Control, Consistency, Value, Veracity) desiderata to meet the RAI requirements for future general-purpose AI systems, and discuss how recent efforts in AI alignment, retrieval-augmented generation, reasoning enhancements, etc. fare along one or more of the desiderata. We believe that the goal of developing responsible general-purpose AI can be achieved by formally modeling application- or domain-dependent RAI requirements along C2V2 dimensions, and taking a system design approach to suitably combine various techniques to meet the desiderata.

</details>


### [525] [Prompt Injection Mitigation with Agentic AI, Nested Learning, and AI Sustainability via Semantic Caching](https://arxiv.org/abs/2601.13186)
*Diego Gosmar,Deborah A. Dahl*

Main category: cs.AI

TL;DR: 本文扩展了TIVS评估框架，加入语义缓存和可观测性评分，提出TIVS-O系统，在HOPE启发的嵌套学习架构中平衡防御效果与透明度，实现零高风险漏洞同时减少41.6%的LLM调用。


<details>
  <summary>Details</summary>
Motivation: 提示注入是多智能体系统中LLM安全部署的主要障碍，现有评估框架缺乏对防御效果与透明度之间权衡的量化分析，需要同时考虑安全性和可审计性。

Method: 提出TIVS-O系统，结合智能体管道和连续记忆系统，实现基于语义相似性的缓存；使用301个合成生成的注入提示进行测试，第四个智能体使用五个关键性能指标进行安全分析；引入可观测性评分比(OSR)量化安全推理的清晰度。

Result: 系统实现零高风险漏洞，语义缓存减少41.6%的LLM调用，相应降低延迟、能耗和碳排放；五种TIVS-O配置揭示了缓解严格性与取证透明度之间的最优权衡。

Conclusion: 可观测性感知评估能揭示多智能体管道中的非单调效应，记忆增强智能体可同时最大化安全鲁棒性、实时性能、运营成本节约和环境可持续性，无需修改底层模型权重，为安全绿色LLM部署提供生产就绪路径。

Abstract: Prompt injection remains a central obstacle to the safe deployment of large language models, particularly in multi-agent settings where intermediate outputs can propagate or amplify malicious instructions. Building on earlier work that introduced a four-metric Total Injection Vulnerability Score (TIVS), this paper extends the evaluation framework with semantic similarity-based caching and a fifth metric (Observability Score Ratio) to yield TIVS-O, investigating how defence effectiveness interacts with transparency in a HOPE-inspired Nested Learning architecture. The proposed system combines an agentic pipeline with Continuum Memory Systems that implement semantic similarity-based caching across 301 synthetically generated injection-focused prompts drawn from ten attack families, while a fourth agent performs comprehensive security analysis using five key performance indicators. In addition to traditional injection metrics, OSR quantifies the richness and clarity of security-relevant reasoning exposed by each agent, enabling an explicit analysis of trade-offs between strict mitigation and auditability. Experiments show that the system achieves secure responses with zero high-risk breaches, while semantic caching delivers substantial computational savings, achieving a 41.6% reduction in LLM calls and corresponding decreases in latency, energy consumption, and carbon emissions. Five TIVS-O configurations reveal optimal trade-offs between mitigation strictness and forensic transparency. These results indicate that observability-aware evaluation can reveal non-monotonic effects within multi-agent pipelines and that memory-augmented agents can jointly maximize security robustness, real-time performance, operational cost savings, and environmental sustainability without modifying underlying model weights, providing a production-ready pathway for secure and green LLM deployments.

</details>


### [526] [Real-Time Deadlines Reveal Temporal Awareness Failures in LLM Strategic Dialogues](https://arxiv.org/abs/2601.13206)
*Neil K. R. Sehgal,Sharath Chandra Guntuku,Lyle Ungar*

Main category: cs.AI

TL;DR: LLMs在时间敏感谈判中缺乏时间意识，提供剩余时间信息能显著提升谈判成功率，但LLMs自身难以内部追踪时间流逝


<details>
  <summary>Details</summary>
Motivation: 现实世界沟通（如治疗、商业谈判）具有严格的时间限制，但当前LLM架构和评估协议很少测试其在实时截止时间下的时间意识能力

Method: 使用模拟谈判实验，配对智能体在严格截止时间下进行谈判。设置控制组（仅知道全局时间限制）和时间感知组（每轮接收剩余时间更新），比较不同条件下的谈判表现

Result: 时间感知条件下交易达成率显著更高（GPT-5.1为32% vs 4%），报价接受率是控制组的6倍。但在轮次限制条件下，相同LLMs能达到接近完美的交易达成率（≥95%）

Conclusion: LLMs在时间敏感应用中存在系统性时间意识缺乏，主要问题在于时间追踪而非策略推理能力，这限制了LLM在许多时间敏感应用中的部署

Abstract: Large Language Models (LLMs) generate text token-by-token in discrete time, yet real-world communication, from therapy sessions to business negotiations, critically depends on continuous time constraints. Current LLM architectures and evaluation protocols rarely test for temporal awareness under real-time deadlines. We use simulated negotiations between paired agents under strict deadlines to investigate how LLMs adjust their behavior in time-sensitive settings. In a control condition, agents know only the global time limit. In a time-aware condition, they receive remaining-time updates at each turn. Deal closure rates are substantially higher (32\% vs. 4\% for GPT-5.1) and offer acceptances are sixfold higher in the time-aware condition than in the control, suggesting LLMs struggle to internally track elapsed time. However, the same LLMs achieve near-perfect deal closure rates ($\geq$95\%) under turn-based limits, revealing the failure is in temporal tracking rather than strategic reasoning. These effects replicate across negotiation scenarios and models, illustrating a systematic lack of LLM time awareness that will constrain LLM deployment in many time-sensitive applications.

</details>


### [527] [RAG: A Random-Forest-Based Generative Design Framework for Uncertainty-Aware Design of Metamaterials with Complex Functional Response Requirements](https://arxiv.org/abs/2601.13233)
*Bolin Chen,Dex Doksoo Lee,Wei "Wayne'' Chen,Wei Chen*

Main category: cs.AI

TL;DR: 提出RAG框架，基于随机森林的生成式方法，用于高维功能响应的数据高效逆设计，解决传统方法数据需求大、不确定性量化不足的问题。


<details>
  <summary>Details</summary>
Motivation: 超材料设计中，针对非线性、条件依赖的功能响应（如应力-应变关系、色散关系）进行逆设计具有挑战性。现有方法大多关注向量值响应，而功能响应的逆设计面临高维性、设计需求整合复杂、可行解不存在或不唯一等问题。生成式方法虽有效，但通常需要大量数据、处理设计需求启发式、缺乏不确定性量化。

Method: 提出RAndom-forest-based Generative approach (RAG)。利用随机森林的小数据兼容性，实现高维功能响应的数据高效预测。在逆设计中，通过集成方法估计可能性，量化生成设计的可信度并反映不同设计需求的相对难度。通过从条件似然中采样解决一对多映射问题，实现单次设计生成。

Result: 在声学超材料（规定部分通带/阻带）和机械超材料（目标snap-through响应）上验证RAG，分别使用500和1057个样本。在公开的机械超材料非线性应力-应变关系数据集上，与神经网络进行数据效率基准测试，证明其优越性。

Conclusion: RAG框架为涉及功能响应、昂贵仿真和复杂设计需求的逆设计提供了一条轻量级、可信赖的途径，不仅限于超材料领域。

Abstract: Metamaterials design for advanced functionality often entails the inverse design on nonlinear and condition-dependent responses (e.g., stress-strain relation and dispersion relation), which are described by continuous functions. Most existing design methods focus on vector-valued responses (e.g., Young's modulus and bandgap width), while the inverse design of functional responses remains challenging due to their high-dimensionality, the complexity of accommodating design requirements in inverse-design frameworks, and non-existence or non-uniqueness of feasible solutions. Although generative design approaches have shown promise, they are often data-hungry, handle design requirements heuristically, and may generate infeasible designs without uncertainty quantification. To address these challenges, we introduce a RAndom-forest-based Generative approach (RAG). By leveraging the small-data compatibility of random forests, RAG enables data-efficient predictions of high-dimensional functional responses. During the inverse design, the framework estimates the likelihood through the ensemble which quantifies the trustworthiness of generated designs while reflecting the relative difficulty across different requirements. The one-to-many mapping is addressed through single-shot design generation by sampling from the conditional likelihood. We demonstrate RAG on: 1) acoustic metamaterials with prescribed partial passbands/stopbands, and 2) mechanical metamaterials with targeted snap-through responses, using 500 and 1057 samples, respectively. Its data-efficiency is benchmarked against neural networks on a public mechanical metamaterial dataset with nonlinear stress-strain relations. Our framework provides a lightweight, trustworthy pathway to inverse design involving functional responses, expensive simulations, and complex design requirements, beyond metamaterials.

</details>


### [528] [CURE-Med: Curriculum-Informed Reinforcement Learning for Multilingual Medical Reasoning](https://arxiv.org/abs/2601.13262)
*Eric Onyame,Akash Ghosh,Subhadip Baidya,Sriparna Saha,Xiuying Chen,Chirag Agarwal*

Main category: cs.AI

TL;DR: CURE-MED框架通过课程强化学习提升LLMs在多语言医疗推理中的表现，使用CUREMED-BENCH数据集在13种语言上验证效果显著。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在单语言数学和常识推理上表现良好，但在多语言医疗推理应用中仍不可靠，阻碍了在多语言医疗环境中的部署应用。

Method: 提出CURE-MED框架：1) 引入CUREMED-BENCH多语言医疗推理数据集；2) 采用课程强化学习，结合代码切换感知的监督微调和组相对策略优化，共同提升逻辑正确性和语言稳定性。

Result: 在13种语言上，7B参数模型达到85.21%语言一致性和54.35%逻辑正确性；32B参数模型达到94.96%语言一致性和70.04%逻辑正确性，显著优于基线方法。

Conclusion: CURE-MED框架能够有效提升LLMs在多语言医疗推理中的可靠性和公平性，支持在多语言医疗环境中的实际应用。

Abstract: While large language models (LLMs) have shown to perform well on monolingual mathematical and commonsense reasoning, they remain unreliable for multilingual medical reasoning applications, hindering their deployment in multilingual healthcare settings. We address this by first introducing CUREMED-BENCH, a high-quality multilingual medical reasoning dataset with open-ended reasoning queries with a single verifiable answer, spanning thirteen languages, including underrepresented languages such as Amharic, Yoruba, and Swahili. Building on this dataset, we propose CURE-MED, a curriculum-informed reinforcement learning framework that integrates code-switching-aware supervised fine-tuning and Group Relative Policy Optimization to jointly improve logical correctness and language stability. Across thirteen languages, our approach consistently outperforms strong baselines and scales effectively, achieving 85.21% language consistency and 54.35% logical correctness at 7B parameters, and 94.96% language consistency and 70.04% logical correctness at 32B parameters. These results support reliable and equitable multilingual medical reasoning in LLMs. The code and dataset are available at https://cure-med.github.io/

</details>


### [529] [Improving the Safety and Trustworthiness of Medical AI via Multi-Agent Evaluation Loops](https://arxiv.org/abs/2601.13268)
*Zainab Ghafoor,Md Shafiqul Islam,Koushik Howlader,Md Rasel Khondokar,Tanusree Bhattacharjee,Sayantan Chakraborty,Adrito Roy,Ushashi Bhattacharjee,Tirtho Roy*

Main category: cs.AI

TL;DR: 本文提出了一种多智能体精炼框架，通过结构化迭代对齐来增强医疗大语言模型的安全性和可靠性，在900个临床查询上实现了89%的伦理违规减少和92%的风险降级率。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在医疗领域的应用日益增多，但确保其伦理完整性和安全合规性仍然是临床部署的主要障碍，需要开发有效的安全治理方法。

Method: 采用多智能体精炼框架，结合两个生成模型（DeepSeek R1和Med-PaLM）和两个评估智能体（LLaMA 3.1和Phi-4），使用美国医学会医学伦理原则和五级安全风险评估协议进行结构化迭代对齐。

Result: DeepSeek R1收敛更快（平均2.34次迭代），Med-PaLM在隐私敏感场景中表现更优；多智能体迭代循环实现了89%的伦理违规减少和92%的风险降级率。

Conclusion: 该研究提出了一种可扩展、符合监管要求且成本效益高的医疗AI安全治理范式，为医疗大语言模型的临床部署提供了有效的安全保障框架。

Abstract: Large Language Models (LLMs) are increasingly applied in healthcare, yet ensuring their ethical integrity and safety compliance remains a major barrier to clinical deployment. This work introduces a multi-agent refinement framework designed to enhance the safety and reliability of medical LLMs through structured, iterative alignment. Our system combines two generative models - DeepSeek R1 and Med-PaLM - with two evaluation agents, LLaMA 3.1 and Phi-4, which assess responses using the American Medical Association's (AMA) Principles of Medical Ethics and a five-tier Safety Risk Assessment (SRA-5) protocol. We evaluate performance across 900 clinically diverse queries spanning nine ethical domains, measuring convergence efficiency, ethical violation reduction, and domain-specific risk behavior. Results demonstrate that DeepSeek R1 achieves faster convergence (mean 2.34 vs. 2.67 iterations), while Med-PaLM shows superior handling of privacy-sensitive scenarios. The iterative multi-agent loop achieved an 89% reduction in ethical violations and a 92% risk downgrade rate, underscoring the effectiveness of our approach. This study presents a scalable, regulator-aligned, and cost-efficient paradigm for governing medical AI safety.

</details>


### [530] [PepEDiff: Zero-Shot Peptide Binder Design via Protein Embedding Diffusion](https://arxiv.org/abs/2601.13327)
*Po-Yu Liang,Tobo Duran,Jun Bai*

Main category: cs.AI

TL;DR: PepEDiff是一种新型的肽结合剂生成器，直接从预训练的蛋白质嵌入模型的连续潜在空间中生成结合序列，无需依赖结构预测，提高了序列多样性。


<details>
  <summary>Details</summary>
Motivation: 现有的肽结合剂生成方法严重依赖中间结构预测，增加了复杂性并限制了序列多样性。需要一种更直接、更灵活的方法来设计结合序列。

Method: 使用预训练的蛋白质嵌入模型构建连续潜在空间，通过潜在空间探索和基于扩散的采样生成肽序列，避免记忆已知序列，而是捕获结合相关特征。

Result: 在TIGIT（一个具有大而平坦的蛋白质-蛋白质相互作用界面的挑战性靶点）的案例研究中，PepEDiff在基准测试中优于现有最先进方法。

Conclusion: PepEDiff展示了一种通用的、无需结构的零样本肽结合剂设计框架的潜力，能够生成超出已知结合剂分布范围的新型肽序列。

Abstract: We present PepEDiff, a novel peptide binder generator that designs binding sequences given a target receptor protein sequence and its pocket residues. Peptide binder generation is critical in therapeutic and biochemical applications, yet many existing methods rely heavily on intermediate structure prediction, adding complexity and limiting sequence diversity. Our approach departs from this paradigm by generating binder sequences directly in a continuous latent space derived from a pretrained protein embedding model, without relying on predicted structures, thereby improving structural and sequence diversity. To encourage the model to capture binding-relevant features rather than memorizing known sequences, we perform latent-space exploration and diffusion-based sampling, enabling the generation of peptides beyond the limited distribution of known binders. This zero-shot generative strategy leverages the global protein embedding manifold as a semantic prior, allowing the model to propose novel peptide sequences in previously unseen regions of the protein space. We evaluate PepEDiff on TIGIT, a challenging target with a large, flat protein-protein interaction interface that lacks a druggable pocket. Despite its simplicity, our method outperforms state-of-the-art approaches across benchmark tests and in the TIGIT case study, demonstrating its potential as a general, structure-free framework for zero-shot peptide binder design. The code for this research is available at GitHub: https://github.com/LabJunBMI/PepEDiff-An-Peptide-binder-Embedding-Diffusion-Model

</details>


### [531] [The Geometry of Thought: How Scale Restructures Reasoning In Large Language Models](https://arxiv.org/abs/2601.13358)
*Samuel Cyrenius Anderson*

Main category: cs.AI

TL;DR: 研究发现模型规模并非均匀提升推理能力，而是重构推理过程。通过分析2.5万+思维链轨迹，发现神经缩放定律引发领域特定的相变而非均匀能力提升，推理成本由流形几何而非任务难度决定。


<details>
  <summary>Details</summary>
Motivation: 传统观点认为模型规模会均匀提升推理能力，但本研究旨在探究规模如何具体影响不同领域的推理过程，揭示神经缩放定律的实际作用机制。

Method: 分析了25,000+思维链轨迹，涵盖法律、科学、代码、数学四个领域和8B、70B两种规模。使用几何分析方法，包括表示维度、轨迹对齐、流形解缠等指标，并引入神经推理算子来映射初始到最终隐藏状态。

Result: 发现不同领域呈现不同相变模式：法律推理发生"结晶化"（维度减少45%，轨迹对齐增加31%）；科学和数学推理保持"液态"；代码推理形成"晶格"结构。神经推理算子在法律推理上达到63.6%准确率。还发现跨域跨规模的通用振荡特征。

Conclusion: 推理成本由流形几何决定而非任务难度，这为在拓扑允许的情况下加速推理提供了蓝图。研究揭示了规模通过重构而非均匀提升来影响推理过程。

Abstract: Scale does not uniformly improve reasoning - it restructures it. Analyzing 25,000+ chain-of-thought trajectories across four domains (Law, Science, Code, Math) and two scales (8B, 70B parameters), we discover that neural scaling laws trigger domain-specific phase transitions rather than uniform capability gains. Legal reasoning undergoes Crystallization: 45% collapse in representational dimensionality (d95: 501 -> 274), 31% increase in trajectory alignment, and 10x manifold untangling. Scientific and mathematical reasoning remain Liquid - geometrically invariant despite 9x parameter increase. Code reasoning forms a discrete Lattice of strategic modes (silhouette: 0.13 -> 0.42). This geometry predicts learnability. We introduce Neural Reasoning Operators - learned mappings from initial to terminal hidden states. In crystalline legal reasoning, our operator achieves 63.6% accuracy on held-out tasks via probe decoding, predicting reasoning endpoints without traversing intermediate states. We further identify a universal oscillatory signature (coherence ~ -0.4) invariant across domains and scales, suggesting attention and feedforward layers drive reasoning through opposing dynamics. These findings establish that the cost of thought is determined not by task difficulty but by manifold geometry - offering a blueprint for inference acceleration where topology permits.

</details>


### [532] [A Lightweight Modular Framework for Constructing Autonomous Agents Driven by Large Language Models: Design, Implementation, and Applications in AgentForge](https://arxiv.org/abs/2601.13383)
*Akbar Anbar Jafari,Cagri Ozcinar,Gholamreza Anbarjafari*

Main category: cs.AI

TL;DR: AgentForge：一个轻量级、开源的Python框架，通过模块化架构简化LLM驱动的自主智能体构建，支持技能组合、统一LLM后端和声明式配置，显著降低开发时间。


<details>
  <summary>Details</summary>
Motivation: 现有智能体框架存在架构僵化、供应商锁定和复杂性过高的问题，阻碍了快速原型设计和部署。需要一种能够民主化LLM驱动自主智能体构建的解决方案。

Method: 提出AgentForge框架，包含三个核心创新：1) 可组合的技能抽象，支持细粒度任务分解和形式化输入输出契约；2) 统一的LLM后端接口，支持云端API和本地推理引擎无缝切换；3) 基于YAML的声明式配置系统，分离智能体逻辑与实现细节。将技能组合机制形式化为有向无环图(DAG)。

Result: 在四个基准场景的全面实验评估中，AgentForge实现了竞争性的任务完成率，同时相比LangChain减少62%开发时间，相比直接API集成减少78%开发时间。编排延迟低于100毫秒，适合实时应用。框架集成了六个内置技能，并提供自定义技能开发的完整文档。

Conclusion: AgentForge填补了LLM智能体生态系统的重要空白，为研究人员和从业者提供了一个生产就绪的基础设施，用于构建、评估和部署自主智能体，同时不牺牲灵活性或性能。

Abstract: The emergence of LLMs has catalyzed a paradigm shift in autonomous agent development, enabling systems capable of reasoning, planning, and executing complex multi-step tasks. However, existing agent frameworks often suffer from architectural rigidity, vendor lock-in, and prohibitive complexity that impedes rapid prototyping and deployment. This paper presents AgentForge, a lightweight, open-source Python framework designed to democratize the construction of LLM-driven autonomous agents through a principled modular architecture. AgentForge introduces three key innovations: (1) a composable skill abstraction that enables fine-grained task decomposition with formally defined input-output contracts, (2) a unified LLM backend interface supporting seamless switching between cloud-based APIs and local inference engines, and (3) a declarative YAML-based configuration system that separates agent logic from implementation details. We formalize the skill composition mechanism as a directed acyclic graph (DAG) and prove its expressiveness for representing arbitrary sequential and parallel task workflows. Comprehensive experimental evaluation across four benchmark scenarios demonstrates that AgentForge achieves competitive task completion rates while reducing development time by 62% compared to LangChain and 78% compared to direct API integration. Latency measurements confirm sub-100ms orchestration overhead, rendering the framework suitable for real-time applications. The modular design facilitates extension: we demonstrate the integration of six built-in skills and provide comprehensive documentation for custom skill development. AgentForge addresses a critical gap in the LLM agent ecosystem by providing researchers and practitioners with a production-ready foundation for constructing, evaluating, and deploying autonomous agents without sacrificing flexibility or performance.

</details>


### [533] [Explicit Cognitive Allocation: A Principle for Governed and Auditable Inference in Large Language Models](https://arxiv.org/abs/2601.13443)
*Héctor Manuel Manzanilla-Granados,Zaira Navarrete-Cazales,Miriam Pescador-Rojas,Tonahtiu Ramírez-Romero*

Main category: cs.AI

TL;DR: 论文提出"显式认知分配"原则，通过分离和编排认知功能来结构化AI辅助推理，并实现为"认知通用代理"架构，在农业领域验证中显示出更好的认知收敛和工具意识。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型的使用存在认知结构缺失问题：问题框架、知识探索、检索、方法意识和解释通常被压缩到单一的生成过程中。这种认知压缩限制了可追溯性、削弱了认知控制、破坏了可重复性，特别是在高责任环境中。

Method: 提出"显式认知分配"原则，将推理过程结构化分离为不同认知阶段。实现为"认知通用代理"架构，包括探索与框架、认知锚定、工具与方法映射、解释性合成等阶段。引入"通用认知工具"概念，形式化各种工具手段。

Result: 在农业领域的多提示实验中，CUA编排的推理显示出更早且结构化的认知收敛、语义扩展下更高的认知对齐，以及系统性地暴露查询的工具景观。相比之下，基线LLM推理在对齐上表现出更大变异性，未能显式展示工具结构。

Conclusion: 显式认知分配原则能够有效结构化AI辅助推理，提高认知控制、可追溯性和可重复性。CUA架构通过分离认知功能和形式化工具手段，为高责任环境中的AI辅助推理提供了更可靠的框架。

Abstract: The rapid adoption of large language models (LLMs) has enabled new forms of AI-assisted reasoning across scientific, technical, and organizational domains. However, prevailing modes of LLM use remain cognitively unstructured: problem framing, knowledge exploration, retrieval, methodological awareness, and explanation are typically collapsed into a single generative process. This cognitive collapse limits traceability, weakens epistemic control, and undermines reproducibility, particularly in high-responsibility settings.
  We introduce Explicit Cognitive Allocation, a general principle for structuring AI-assisted inference through the explicit separation and orchestration of epistemic functions. We instantiate this principle in the Cognitive Universal Agent (CUA), an architecture that organizes inference into distinct stages of exploration and framing, epistemic anchoring, instrumental and methodological mapping, and interpretive synthesis. Central to this framework is the notion of Universal Cognitive Instruments (UCIs), which formalize heterogeneous means, including computational, experimental, organizational, regulatory, and educational instruments, through which abstract inquiries become investigable.
  We evaluate the effects of explicit cognitive and instrumental allocation through controlled comparisons between CUA-orchestrated inference and baseline LLM inference under matched execution conditions. Across multiple prompts in the agricultural domain, CUA inference exhibits earlier and structurally governed epistemic convergence, higher epistemic alignment under semantic expansion, and systematic exposure of the instrumental landscape of inquiry. In contrast, baseline LLM inference shows greater variability in alignment and fails to explicitly surface instrumental structure.

</details>


### [534] [SpatialBench-UC: Uncertainty-Aware Evaluation of Spatial Prompt Following in Text-to-Image Generation](https://arxiv.org/abs/2601.13462)
*Amine Rostane*

Main category: cs.AI

TL;DR: SpatialBench-UC：一个用于评估文本到图像模型空间关系理解能力的小型可复现基准，包含200个提示和对抗性配对，提供可审计的评估框架和人类校准的检查器。


<details>
  <summary>Details</summary>
Motivation: 评估文本到图像模型是否遵循明确的空间指令难以自动化，因为对象检测器可能漏检或返回多个检测结果，简单的几何测试在边界情况下可能变得模糊。空间评估本质上是一个选择性预测问题，检查器在证据不足时可以弃权并报告置信度。

Method: 创建SpatialBench-UC基准，包含200个提示（50个对象对×4种关系），分为100个通过交换对象角色得到的对抗性配对。发布包含版本化提示、固定配置、每样本检查器输出和报告表格的基准包，实现跨模型的可复现和可审计比较。包含轻量级人工审核来校准检查器的弃权边界和置信度阈值。

Result: 评估了三个基线模型：Stable Diffusion 1.5、SD 1.5 BoxDiff和SD 1.4 GLIGEN。检查器报告通过率和覆盖率以及在已决定样本上的条件通过率。结果显示，接地方法显著提高了通过率和覆盖率，但弃权仍然是主要因素，主要原因是对象检测缺失。

Conclusion: SpatialBench-UC为评估文本到图像模型的空间关系理解提供了一个可复现、可审计的基准框架。接地方法能有效改善性能，但对象检测的可靠性仍然是限制评估准确性的关键因素，弃权机制对于处理不确定性至关重要。

Abstract: Evaluating whether text-to-image models follow explicit spatial instructions is difficult to automate. Object detectors may miss targets or return multiple plausible detections, and simple geometric tests can become ambiguous in borderline cases. Spatial evaluation is naturally a selective prediction problem, the checker may abstain when evidence is weak and report confidence so that results can be interpreted as a risk coverage tradeoff rather than a single score. We introduce SpatialBench-UC, a small, reproducible benchmark for pairwise spatial relations. The benchmark contains 200 prompts (50 object pairs times 4 relations) grouped into 100 counterfactual pairs obtained by swapping object roles. We release a benchmark package, versioned prompts, pinned configs, per-sample checker outputs, and report tables, enabling reproducible and auditable comparisons across models. We also include a lightweight human audit used to calibrate the checker's abstention margin and confidence threshold. We evaluate three baselines, Stable Diffusion 1.5, SD 1.5 BoxDiff, and SD 1.4 GLIGEN. The checker reports pass rate and coverage as well as conditional pass rates on decided samples. The results show that grounding methods substantially improve both pass rate and coverage, while abstention remains a dominant factor due mainly to missing detections.

</details>


### [535] [Context and Transcripts Improve Detection of Deepfake Audios of Public Figures](https://arxiv.org/abs/2601.13464)
*Chongyang Gao,Marco Postiglione,Julian Baldwin,Natalia Denisenko,Isabel Gortner,Luke Fosdick,Chiara Pulice,Sarit Kraus,V. S. Subrahmanian*

Main category: cs.AI

TL;DR: 提出基于上下文和文本的音频深度伪造检测器CADD，通过结合语境和转录文本显著提升检测性能，并对抗攻击更鲁棒。


<details>
  <summary>Details</summary>
Motivation: 人类利用上下文判断信息真伪，但现有音频深度伪造检测器仅分析音频文件，忽略了上下文和转录文本的重要性。

Method: 创建记者提供的深度伪造数据集JDD和合成音频数据集SYN，提出基于上下文的音频深度伪造检测器CADD架构，在多个大规模数据集上评估。

Result: 上下文和/或转录文本能显著提升检测器性能：F1分数提升5%-37.58%，AUC提升3.77%-42.79%，EER提升6.17%-47.83%。CADD对5种对抗攻击策略更鲁棒，性能下降平均仅-0.71%。

Conclusion: 上下文和转录文本对音频深度伪造检测至关重要，CADD架构通过利用这些信息显著提升检测性能和对抗鲁棒性。

Abstract: Humans use context to assess the veracity of information. However, current audio deepfake detectors only analyze the audio file without considering either context or transcripts. We create and analyze a Journalist-provided Deepfake Dataset (JDD) of 255 public deepfakes which were primarily contributed by over 70 journalists since early 2024. We also generate a synthetic audio dataset (SYN) of dead public figures and propose a novel Context-based Audio Deepfake Detector (CADD) architecture. In addition, we evaluate performance on two large-scale datasets: ITW and P$^2$V. We show that sufficient context and/or the transcript can significantly improve the efficacy of audio deepfake detectors. Performance (measured via F1 score, AUC, and EER) of multiple baseline audio deepfake detectors and traditional classifiers can be improved by 5%-37.58% in F1-score, 3.77%-42.79% in AUC, and 6.17%-47.83% in EER. We additionally show that CADD, via its use of context and/or transcripts, is more robust to 5 adversarial evasion strategies, limiting performance degradation to an average of just -0.71% across all experiments. Code, models, and datasets are available at our project page: https://sites.northwestern.edu/nsail/cadd-context-based-audio-deepfake-detection (access restricted during review).

</details>


### [536] [Graph Neural Networks are Heuristics](https://arxiv.org/abs/2601.13465)
*Yimeng Min,Carla P. Gomes*

Main category: cs.AI

TL;DR: 单个训练轨迹可将图神经网络转化为组合优化的无监督启发式算法，用于旅行商问题，无需搜索、监督或序列决策


<details>
  <summary>Details</summary>
Motivation: 探索图神经网络是否能在无监督、无搜索的情况下直接作为组合优化的启发式算法，重新定义学习在组合优化中的角色

Method: 将全局结构约束作为归纳偏置，使用非自回归模型通过前向传播直接生成解；推理时使用dropout和快照集成作为隐式集成，增加解多样性

Result: 图神经网络无需监督训练或显式搜索即可有效工作，能够内化全局组合结构并作为强大的学习启发式算法

Conclusion: 学习在组合优化中的角色从增强经典算法转变为直接实例化新的启发式算法

Abstract: We demonstrate that a single training trajectory can transform a graph neural network into an unsupervised heuristic for combinatorial optimization. Focusing on the Travelling Salesman Problem, we show that encoding global structural constraints as an inductive bias enables a non-autoregressive model to generate solutions via direct forward passes, without search, supervision, or sequential decision-making. At inference time, dropout and snapshot ensembling allow a single model to act as an implicit ensemble, reducing optimality gaps through increased solution diversity. Our results establish that graph neural networks do not require supervised training nor explicit search to be effective. Instead, they can internalize global combinatorial structure and function as strong, learned heuristics. This reframes the role of learning in combinatorial optimization: from augmenting classical algorithms to directly instantiating new heuristics.

</details>


### [537] [Towards Efficient and Robust Linguistic Emotion Diagnosis for Mental Health via Multi-Agent Instruction Refinement](https://arxiv.org/abs/2601.13481)
*Jian Zhang,Zhangqi Wang,Zhiyuan Wang,Weiping Fu,Yu He,Haiping Zhu,Qika Lin,Jun Liu*

Main category: cs.AI

TL;DR: APOLO是一个用于精神健康领域情感诊断的自动提示优化框架，通过多智能体协作系统探索更精细的提示空间，解决情感共病和临床线索挖掘不足的挑战。


<details>
  <summary>Details</summary>
Motivation: 在临床记录、咨询对话和在线心理健康社区中，抑郁、焦虑和创伤相关状态的情感表达普遍存在，准确识别这些情感对于临床分诊、风险评估和及时干预至关重要。尽管大语言模型在情感分析任务中表现出强大的泛化能力，但在高风险、上下文密集的医疗环境中，其诊断可靠性对提示设计高度敏感。现有方法面临情感共病（多种交织情感状态使预测复杂化）和临床相关线索探索效率低两大挑战。

Method: 提出APOLO（语言情感诊断的自动提示优化）框架，将指令优化建模为部分可观测马尔可夫决策过程，采用包含规划者、教师、批评者、学生和目标角色的多智能体协作机制。在闭环框架中，规划者定义优化轨迹，教师-批评者-学生智能体迭代优化提示以增强推理稳定性和有效性，目标智能体基于性能评估决定是否继续优化。

Result: 实验结果表明，APOLO在领域特定和分层基准测试中持续提高诊断准确性和鲁棒性，展示了在精神健康领域可信赖大语言模型应用的可扩展和可泛化范式。

Conclusion: APOLO通过系统探索更广泛和更精细的提示空间，提高了情感诊断的效率和鲁棒性，为精神健康领域的高风险应用提供了可信赖的大语言模型解决方案。

Abstract: Linguistic expressions of emotions such as depression, anxiety, and trauma-related states are pervasive in clinical notes, counseling dialogues, and online mental health communities, and accurate recognition of these emotions is essential for clinical triage, risk assessment, and timely intervention. Although large language models (LLMs) have demonstrated strong generalization ability in emotion analysis tasks, their diagnostic reliability in high-stakes, context-intensive medical settings remains highly sensitive to prompt design. Moreover, existing methods face two key challenges: emotional comorbidity, in which multiple intertwined emotional states complicate prediction, and inefficient exploration of clinically relevant cues. To address these challenges, we propose APOLO (Automated Prompt Optimization for Linguistic Emotion Diagnosis), a framework that systematically explores a broader and finer-grained prompt space to improve diagnostic efficiency and robustness. APOLO formulates instruction refinement as a Partially Observable Markov Decision Process and adopts a multi-agent collaboration mechanism involving Planner, Teacher, Critic, Student, and Target roles. Within this closed-loop framework, the Planner defines an optimization trajectory, while the Teacher-Critic-Student agents iteratively refine prompts to enhance reasoning stability and effectiveness, and the Target agent determines whether to continue optimization based on performance evaluation. Experimental results show that APOLO consistently improves diagnostic accuracy and robustness across domain-specific and stratified benchmarks, demonstrating a scalable and generalizable paradigm for trustworthy LLM applications in mental healthcare.

</details>


### [538] [AgenticRed: Optimizing Agentic Systems for Automated Red-teaming](https://arxiv.org/abs/2601.13518)
*Jiayi Yuan,Jonathan Nöther,Natasha Jaques,Goran Radanović*

Main category: cs.AI

TL;DR: AgenticRed：一种利用LLM上下文学习自动设计和优化红队系统的框架，无需人工干预，在多种模型上显著提升攻击成功率


<details>
  <summary>Details</summary>
Motivation: 现有自动化红队方法依赖人工设计的工作流程，存在人类偏见且探索设计空间成本高昂，需要一种能自动设计和优化红队系统的方法

Method: 将红队视为系统设计问题，利用LLM的上下文学习能力，通过进化选择方法迭代设计和优化红队系统，无需人工干预

Result: 在Llama-2-7B上达到96%攻击成功率（提升36%），在Llama-3-8B上达到98%，在GPT-3.5-Turbo和GPT-4o-mini上达到100%，在Claude-Sonnet-3.5上达到60%（提升24%）

Conclusion: 自动化系统设计是AI安全评估的强大范式，能够跟上快速发展的模型步伐，为红队测试提供了更有效的自动化解决方案

Abstract: While recent automated red-teaming methods show promise for systematically exposing model vulnerabilities, most existing approaches rely on human-specified workflows. This dependence on manually designed workflows suffers from human biases and makes exploring the broader design space expensive. We introduce AgenticRed, an automated pipeline that leverages LLMs' in-context learning to iteratively design and refine red-teaming systems without human intervention. Rather than optimizing attacker policies within predefined structures, AgenticRed treats red-teaming as a system design problem. Inspired by methods like Meta Agent Search, we develop a novel procedure for evolving agentic systems using evolutionary selection, and apply it to the problem of automatic red-teaming. Red-teaming systems designed by AgenticRed consistently outperform state-of-the-art approaches, achieving 96% attack success rate (ASR) on Llama-2-7B (36% improvement) and 98% on Llama-3-8B on HarmBench. Our approach exhibits strong transferability to proprietary models, achieving 100% ASR on GPT-3.5-Turbo and GPT-4o-mini, and 60% on Claude-Sonnet-3.5 (24% improvement). This work highlights automated system design as a powerful paradigm for AI safety evaluation that can keep pace with rapidly evolving models.

</details>


### [539] [Reasoning While Recommending: Entropy-Guided Latent Reasoning in Generative Re-ranking Models](https://arxiv.org/abs/2601.13533)
*Changshuo Zhang*

Main category: cs.AI

TL;DR: EGLR推荐模型通过熵引导的潜在推理机制，在生成式重排序中实现"边推理边推荐"，动态适应列表生成难度变化，提升推荐性能。


<details>
  <summary>Details</summary>
Motivation: 现有生成式重排序方法难以适应列表生成过程中模型难度的动态熵变化，无法准确捕捉复杂偏好。受语言模型推理能力启发，需要引入推理机制来降低决策熵。

Method: 提出熵引导潜在推理(EGLR)模型：1) 放弃"先推理后推荐"范式，实现"边推理边推荐"；2) 使用上下文感知推理令牌和动态温度调整实现熵引导变长推理；3) 轻量级集成设计，无需复杂独立模块或后处理。

Result: 在两个真实世界数据集上的实验验证了模型有效性，显著优势在于能与现有生成式重排序模型兼容以提升其性能。进一步分析展示了实际部署价值和研究潜力。

Conclusion: EGLR模型通过熵引导的潜在推理机制，在生成式重排序中实现了更精确的探索-利用权衡，为动态适应列表生成难度变化提供了有效解决方案。

Abstract: Reinforcement learning plays a crucial role in generative re-ranking scenarios due to its exploration-exploitation capabilities, but existing generative methods mostly fail to adapt to the dynamic entropy changes in model difficulty during list generation, making it challenging to accurately capture complex preferences. Given that language models have achieved remarkable breakthroughs by integrating reasoning capabilities, we draw on this approach to introduce a latent reasoning mechanism, and experimental validation demonstrates that this mechanism effectively reduces entropy in the model's decision-making process. Based on these findings, we introduce the Entropy-Guided Latent Reasoning (EGLR) recommendation model, which has three core advantages. First, it abandons the "reason first, recommend later" paradigm to achieve "reasoning while recommending", specifically designed for the high-difficulty nature of list generation by enabling real-time reasoning during generation. Second, it implements entropy-guided variable-length reasoning using context-aware reasoning token alongside dynamic temperature adjustment, expanding exploration breadth in reasoning and boosting exploitation precision in recommending to achieve a more precisely adapted exploration-exploitation trade-off. Third, the model adopts a lightweight integration design with no complex independent modules or post-processing, enabling easy adaptation to existing models. Experimental results on two real-world datasets validate the model's effectiveness, and its notable advantage lies in being compatible with existing generative re-ranking models to enhance their performance. Further analyses also demonstrate its practical deployment value and research potential.

</details>


### [540] [TruthTensor: Evaluating LLMs Human Imitation through Prediction Market Drift and Holistic Reasoning](https://arxiv.org/abs/2601.13545)
*Shirin Shahabi,Spencer Graham,Haruna Isah*

Main category: cs.AI

TL;DR: TruthTensor是一个新颖的LLM评估框架，通过实时预测市场结合概率评分，在真实世界高熵环境中评估模型作为人类模仿系统的表现，超越传统静态基准。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型评估存在根本性挑战：静态基准无法捕捉真实世界的不确定性、分布偏移，以及孤立任务准确性与人类对齐决策之间的差距。需要一种能评估模型在动态、高熵环境中作为人类模仿系统表现的新范式。

Method: 提出TruthTensor框架：1) 基于前瞻性、无污染的任务；2) 锚定到实时预测市场；3) 结合概率评分；4) 包含漂移中心诊断和显式鲁棒性检查；5) 明确人类与自动化评估角色、标注协议和统计测试程序。

Result: 在500+个真实市场（政治、经济、文化、技术）实验中，TruthTensor显示预测准确度相似的模型在校准、漂移和风险敏感性方面存在显著差异，表明需要多维度评估（准确性、校准、叙事稳定性、成本、资源效率）。

Conclusion: TruthTensor将现代评估最佳实践操作化，包括清晰假设框架、谨慎指标选择、透明计算/成本报告、人在环验证和开放版本化评估合同，为LLM在真实世界决策环境中的评估提供了可辩护的评估方法。

Abstract: Evaluating language models and AI agents remains fundamentally challenging because static benchmarks fail to capture real-world uncertainty, distribution shift, and the gap between isolated task accuracy and human-aligned decision-making under evolving conditions. This paper introduces TruthTensor, a novel, reproducible evaluation paradigm that measures Large Language Models (LLMs) not only as prediction engines but as human-imitation systems operating in socially-grounded, high-entropy environments. Building on forward-looking, contamination-free tasks, our framework anchors evaluation to live prediction markets and combines probabilistic scoring to provide a holistic view of model behavior. TruthTensor complements traditional correctness metrics with drift-centric diagnostics and explicit robustness checks for reproducibility. It specify human vs. automated evaluation roles, annotation protocols, and statistical testing procedures to ensure interpretability and replicability of results. In experiments across 500+ real markets (political, economic, cultural, technological), TruthTensor demonstrates that models with similar forecast accuracy can diverge markedly in calibration, drift, and risk-sensitivity, underscoring the need to evaluate models along multiple axes (accuracy, calibration, narrative stability, cost, and resource efficiency). TruthTensor therefore operationalizes modern evaluation best practices, clear hypothesis framing, careful metric selection, transparent compute/cost reporting, human-in-the-loop validation, and open, versioned evaluation contracts, to produce defensible assessments of LLMs in real-world decision contexts. We publicly release TruthTensor at https://truthtensor.com

</details>


### [541] [ChatAD: Reasoning-Enhanced Time-Series Anomaly Detection with Multi-Turn Instruction Evolution](https://arxiv.org/abs/2601.13546)
*Hui Sun,Chang Xu,Haonan Xie,Hao Li,Yuhao Huang,Chuheng Zhang,Ming Jin,Xiaoguang Liu,Gang Wang,Jiang Bian*

Main category: cs.AI

TL;DR: 本文提出TSEvol时间序列演化算法、TSEData-20K数据集、ChatAD系列模型、TKTO优化方法和LLADBench基准，显著提升时间序列异常检测的性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有LLM驱动的异常检测方法存在推理能力不足、多轮对话能力欠缺、泛化能力有限等问题，需要提升时间序列异常行为的理解和解释能力。

Method: 1) 提出基于多代理的时间序列演化算法TSEvol；2) 构建TSEData-20K数据集和ChatAD系列模型；3) 提出TS Kahneman-Tversky优化方法TKTO增强跨任务泛化；4) 建立LLADBench基准评估框架。

Result: 三个ChatAD模型在准确率上提升达34.50%，F1分数提升34.71%，误报率降低37.42%。通过TKTO优化，在分类、预测和插补任务上展现出竞争力的推理和跨任务泛化性能。

Conclusion: 提出的多代理时间序列演化框架、大规模数据集、优化方法和评估基准有效解决了现有LLM异常检测方法的局限性，显著提升了时间序列异常检测的性能和泛化能力。

Abstract: LLM-driven Anomaly Detection (AD) helps enhance the understanding and explanatory abilities of anomalous behaviors in Time Series (TS). Existing methods face challenges of inadequate reasoning ability, deficient multi-turn dialogue capability, and narrow generalization. To this end, we 1) propose a multi-agent-based TS Evolution algorithm named TSEvol. On top of it, we 2) introduce the AD reasoning and multi-turn dialogue Dataset TSEData-20K and contribute the Chatbot family for AD, including ChatAD-Llama3-8B, Qwen2.5-7B, and Mistral-7B. Furthermore, 3) we propose the TS Kahneman-Tversky Optimization (TKTO) to enhance ChatAD's cross-task generalization capability. Lastly, 4) we propose a LLM-driven Learning-based AD Benchmark LLADBench to evaluate the performance of ChatAD and nine baselines across seven datasets and tasks. Our three ChatAD models achieve substantial gains, up to 34.50% in accuracy, 34.71% in F1, and a 37.42% reduction in false positives. Besides, via KTKO, our optimized ChatAD achieves competitive performance in reasoning and cross-task generalization on classification, forecasting, and imputation.

</details>


### [542] [Leveraging ChatGPT and Other NLP Methods for Identifying Risk and Protective Behaviors in MSM: Social Media and Dating apps Text Analysis](https://arxiv.org/abs/2601.13558)
*Mehrab Beikzadeh,Chenglin Hong,Cory J Cascalheira,Callisto Boka,Majid Sarrafzadeh,Ian W Holloway*

Main category: cs.AI

TL;DR: 使用社交媒体和约会应用文本数据，通过机器学习模型预测男男性行为者的性风险行为、酒精使用和PrEP使用情况，展示了基于大语言模型的方法在公共卫生干预中的潜力。


<details>
  <summary>Details</summary>
Motivation: 男男性行为者面临性传播感染和有害饮酒的高风险，社交媒体和约会应用的文本数据可能为个性化公共卫生干预提供新机会，通过自动识别风险和保护行为来改善健康干预效果。

Method: 收集参与者同意的文本数据，使用ChatGPT嵌入、BERT嵌入、LIWC和基于词典的风险术语方法提取特征，训练机器学习模型预测性风险行为、酒精使用和PrEP使用情况。

Result: 模型在预测每月酗酒行为和超过5个性伴侣方面表现优异（F1分数0.78），在预测PrEP使用和重度饮酒方面表现中等（F1分数分别为0.64和0.63），表明文本数据能有效识别风险和保护行为。

Conclusion: 社交媒体和约会应用文本数据能为男男性行为者的风险和保护行为提供有价值洞察，基于大语言模型的方法具有支持可扩展和个性化公共卫生干预的潜力。

Abstract: Men who have sex with men (MSM) are at elevated risk for sexually transmitted infections and harmful drinking compared to heterosexual men. Text data collected from social media and dating applications may provide new opportunities for personalized public health interventions by enabling automatic identification of risk and protective behaviors. In this study, we evaluated whether text from social media and dating apps can be used to predict sexual risk behaviors, alcohol use, and pre-exposure prophylaxis (PrEP) uptake among MSM. With participant consent, we collected textual data and trained machine learning models using features derived from ChatGPT embeddings, BERT embeddings, LIWC, and a dictionary-based risk term approach. The models achieved strong performance in predicting monthly binge drinking and having more than five sexual partners, with F1 scores of 0.78, and moderate performance in predicting PrEP use and heavy drinking, with F1 scores of 0.64 and 0.63. These findings demonstrate that social media and dating app text data can provide valuable insights into risk and protective behaviors and highlight the potential of large language model-based methods to support scalable and personalized public health interventions for MSM.

</details>


### [543] [AgentGC: Evolutionary Learning-based Lossless Compression for Genomics Data with LLM-driven Multiple Agent](https://arxiv.org/abs/2601.13559)
*Sun Hui,Ding Yanfeng,Huidong Ma,Chang Xu,Keyan Jin,Lizheng Zu,Cheng Zhong,xiaoguang Liu,Gang Wang,Wentong Cai*

Main category: cs.AI

TL;DR: AgentGC：首个基于进化代理的基因组数据无损压缩器，通过三层多代理架构（Leader和Worker）实现用户友好界面、认知优化和自动压缩，在压缩比和吞吐量上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前基于学习的基因组数据压缩方法存在不可进化、低级压缩建模、适应性有限和用户界面不友好等问题，需要一种更智能、自适应的解决方案。

Method: 提出AgentGC三层架构：1）用户层通过Leader结合LLM提供友好界面；2）认知层由Leader驱动，集成LLM考虑算法-数据集-系统联合优化；3）压缩层由Worker负责，通过自动化多知识学习框架执行压缩解压。支持三种模式：CP（压缩比优先）、TP（吞吐量优先）、BM（平衡模式）。

Result: 在9个数据集上与14个基线方法比较：平均压缩比提升16.66%、16.11%、16.33%；吞吐量提升4.73倍、9.23倍、9.15倍（分别对应三种模式）。

Conclusion: AgentGC作为首个基于进化代理的基因组数据压缩器，通过多代理架构和LLM集成，有效解决了现有方法的局限性，在压缩性能和吞吐量上均取得显著提升。

Abstract: Lossless compression has made significant advancements in Genomics Data (GD) storage, sharing and management. Current learning-based methods are non-evolvable with problems of low-level compression modeling, limited adaptability, and user-unfriendly interface. To this end, we propose AgentGC, the first evolutionary Agent-based GD Compressor, consisting of 3 layers with multi-agent named Leader and Worker. Specifically, the 1) User layer provides a user-friendly interface via Leader combined with LLM; 2) Cognitive layer, driven by the Leader, integrates LLM to consider joint optimization of algorithm-dataset-system, addressing the issues of low-level modeling and limited adaptability; and 3) Compression layer, headed by Worker, performs compression & decompression via a automated multi-knowledge learning-based compression framework. On top of AgentGC, we design 3 modes to support diverse scenarios: CP for compression-ratio priority, TP for throughput priority, and BM for balanced mode. Compared with 14 baselines on 9 datasets, the average compression ratios gains are 16.66%, 16.11%, and 16.33%, the throughput gains are 4.73x, 9.23x, and 9.15x, respectively.

</details>


### [544] [Reasoning is a Modality](https://arxiv.org/abs/2601.13562)
*Zhiguang Liu,Yi Shang*

Main category: cs.AI

TL;DR: 论文提出了一种角色分离的Transformer架构，在视觉推理任务ARC上超越了人类平均表现，实现了62.6%的准确率。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统（如LLMs和ViTs）主要作为行为序列预测机器运行，通过建模token统计来匹配可观察行为，但缺乏持久、可读的内心状态。这与人类行为存在差距：人类可以通过解码内部状态来解释行为，而AI系统只能产生事后合理化解释。作者假设推理应该作为一个独立的模态存在，与规则应用的低级工作空间分离。

Method: 设计了新颖的角色分离Transformer块，将全局控制器token与网格工作空间token分离，实现迭代规则执行。在VARC视觉中心协议下进行训练和评估，专门用于解决ARC视觉推理任务。

Result: 在ARC-1任务上达到62.6%的准确率，超越了人类平均表现（60.2%），并显著优于先前方法。定性分析显示模型展现出比密集ViT基线更一致的规则应用结构，从概率块向控制器驱动的推理转变。

Conclusion: 通过将推理设计为独立于低级工作空间的模态，实现了更接近人类推理的AI系统，在抽象推理任务上超越了人类平均表现，验证了推理作为独立通道的假设。

Abstract: The Abstraction and Reasoning Corpus (ARC) provides a compact laboratory for studying abstract reasoning, an ability central to human intelligence. Modern AI systems, including LLMs and ViTs, largely operate as sequence-of-behavior prediction machines: they match observable behaviors by modeling token statistics without a persistent, readable mental state. This creates a gap with human-like behavior: humans can explain an action by decoding internal state, while AI systems can produce fluent post-hoc rationalizations that are not grounded in such a state. We hypothesize that reasoning is a modality: reasoning should exist as a distinct channel separate from the low-level workspace on which rules are applied. To test this hypothesis, on solving ARC tasks as a visual reasoning problem, we designed a novel role-separated transformer block that splits global controller tokens from grid workspace tokens, enabling iterative rule execution. Trained and evaluated within the VARC vision-centric protocol, our method achieved 62.6% accuracy on ARC-1, surpassing average human performance (60.2%) and outperforming prior methods significantly. Qualitatively, our models exhibit more coherent rule-application structure than the dense ViT baseline, consistent with a shift away from plausible probability blobs toward controller-driven reasoning.

</details>


### [545] [SCRIPTMIND: Crime Script Inference and Cognitive Evaluation for LLM-based Social Engineering Scam Detection System](https://arxiv.org/abs/2601.13581)
*Heedou Kim,Changsik Kim,Sanghwa Shin,Jaewoo Kang*

Main category: cs.AI

TL;DR: ScriptMind是一个基于LLM的诈骗检测框架，通过犯罪脚本推理、数据集构建和认知模拟评估，显著提升诈骗检测性能并增强用户认知警觉性。


<details>
  <summary>Details</summary>
Motivation: 传统诈骗检测方法难以应对个性化、多轮对话的社交工程诈骗，而大型语言模型在诈骗检测中的认知辅助潜力尚未充分探索。

Method: 提出ScriptMind框架，包含三个组件：犯罪脚本推理任务(CSIT)用于诈骗推理、犯罪脚本感知推理数据集(CSID)用于微调小型LLM、认知模拟评估(CSED)用于评估实时认知影响。使用571个韩国电话诈骗案例构建22,712个结构化训练实例。

Result: 11B参数的小型LLM微调后比GPT-4o性能提升13%，在检测准确率、误报减少、诈骗者话语预测和推理质量方面优于商业模型。电话诈骗模拟实验显著提升并维持了用户的怀疑水平。

Conclusion: ScriptMind代表了面向人类中心、认知自适应的LLM诈骗防御的重要进展，能够有效增强用户对诈骗的认知意识。

Abstract: Social engineering scams increasingly employ personalized, multi-turn deception, exposing the limits of traditional detection methods. While Large Language Models (LLMs) show promise in identifying deception, their cognitive assistance potential remains underexplored. We propose ScriptMind, an integrated framework for LLM-based scam detection that bridges automated reasoning and human cognition. It comprises three components: the Crime Script Inference Task (CSIT) for scam reasoning, the Crime Script-Aware Inference Dataset (CSID) for fine-tuning small LLMs, and the Cognitive Simulation-based Evaluation of Social Engineering Defense (CSED) for assessing real-time cognitive impact. Using 571 Korean phone scam cases, we built 22,712 structured scammer-sequence training instances. Experimental results show that the 11B small LLM fine-tuned with ScriptMind outperformed GPT-4o by 13%, achieving superior performance over commercial models in detection accuracy, false-positive reduction, scammer utterance prediction, and rationale quality. Moreover, in phone scam simulation experiments, it significantly enhanced and sustained users' suspicion levels, improving their cognitive awareness of scams. ScriptMind represents a step toward human-centered, cognitively adaptive LLMs for scam defense.

</details>


### [546] [Motion-to-Response Content Generation via Multi-Agent AI System with Real-Time Safety Verification](https://arxiv.org/abs/2601.13589)
*HyeYoung Lee*

Main category: cs.AI

TL;DR: 提出基于音频情感信号的多智能体AI系统，实时生成安全可控的响应式媒体内容，包含情感识别、策略决策、内容生成和安全验证四个协作智能体。


<details>
  <summary>Details</summary>
Motivation: 传统语音情感识别研究主要关注分类准确性，但缺乏将识别到的情感状态转化为安全、适龄、可控的响应内容的能力。需要构建一个能够实时生成响应式媒体内容的系统，特别适用于儿童相关媒体、治疗应用和情感响应智能设备。

Method: 采用多智能体架构，包含四个协作智能体：1) 基于CNN的情感识别智能体进行声学特征提取；2) 响应策略决策智能体将情感映射到响应模式；3) 内容参数生成智能体产生媒体控制参数；4) 安全验证智能体强制执行适龄性和刺激约束。系统包含显式的安全验证循环，在输出前过滤生成内容。

Result: 在公共数据集上的实验结果显示：情感识别准确率73.2%，响应模式一致性89.4%，安全合规性100%，推理延迟低于100毫秒，适合设备端部署。模块化架构提供了可解释性和可扩展性。

Conclusion: 该系统成功将情感识别转化为安全可控的响应内容生成，通过多智能体协作和安全验证机制确保了内容的适龄性和安全性，适用于儿童媒体、治疗应用和情感响应设备等领域，具有实际部署价值。

Abstract: This paper proposes a multi-agent artificial intelligence system that generates response-oriented media content in real time based on audio-derived emotional signals. Unlike conventional speech emotion recognition studies that focus primarily on classification accuracy, our approach emphasizes the transformation of inferred emotional states into safe, age-appropriate, and controllable response content through a structured pipeline of specialized AI agents. The proposed system comprises four cooperative agents: (1) an Emotion Recognition Agent with CNN-based acoustic feature extraction, (2) a Response Policy Decision Agent for mapping emotions to response modes, (3) a Content Parameter Generation Agent for producing media control parameters, and (4) a Safety Verification Agent enforcing age-appropriateness and stimulation constraints. We introduce an explicit safety verification loop that filters generated content before output, ensuring compliance with predefined rules. Experimental results on public datasets demonstrate that the system achieves 73.2% emotion recognition accuracy, 89.4% response mode consistency, and 100% safety compliance while maintaining sub-100ms inference latency suitable for on-device deployment. The modular architecture enables interpretability and extensibility, making it applicable to child-adjacent media, therapeutic applications, and emotionally responsive smart devices.

</details>


### [547] [DSAEval: Evaluating Data Science Agents on a Wide Range of Real-World Data Science Problems](https://arxiv.org/abs/2601.13591)
*Maojun Sun,Yifei Xie,Yue Wu,Ruijian Han,Binyan Jiang,Defeng Sun,Yancheng Yuan,Jian Huang*

Main category: cs.AI

TL;DR: DSAEval是一个包含641个真实世界数据科学问题的基准测试，涵盖285个多样化数据集，用于评估LLM数据代理在多模态环境感知、多查询交互和多维度评估方面的能力。


<details>
  <summary>Details</summary>
Motivation: 真实世界数据科学问题的开放性和复杂性（跨越多个分类且缺乏标准答案）给评估带来了重大挑战，需要一个新的基准来全面评估数据科学代理的能力。

Method: 创建DSAEval基准，包含641个真实世界数据科学问题，基于285个多样化数据集（结构化和非结构化数据）。该基准具有三个特点：多模态环境感知（文本和视觉）、多查询交互（模拟迭代过程）和多维度评估（推理、代码和结果）。

Result: 评估了11个先进的代理LLM：Claude-Sonnet-4.5整体性能最强，GPT-5.2最有效率，MiMo-V2-Flash最具成本效益。多模态感知在视觉相关任务上带来2.04%到11.30%的性能提升。当前数据科学代理在结构化数据和常规分析工作流上表现良好，但在非结构化领域仍面临重大挑战。

Conclusion: DSAEval为数据科学代理的评估提供了全面基准，揭示了当前代理的优势和局限，并为未来研究方向提供了关键见解。

Abstract: Recent LLM-based data agents aim to automate data science tasks ranging from data analysis to deep learning. However, the open-ended nature of real-world data science problems, which often span multiple taxonomies and lack standard answers, poses a significant challenge for evaluation. To address this, we introduce DSAEval, a benchmark comprising 641 real-world data science problems grounded in 285 diverse datasets, covering both structured and unstructured data (e.g., vision and text). DSAEval incorporates three distinctive features: (1) Multimodal Environment Perception, which enables agents to interpret observations from multiple modalities including text and vision; (2) Multi-Query Interactions, which mirror the iterative and cumulative nature of real-world data science projects; and (3) Multi-Dimensional Evaluation, which provides a holistic assessment across reasoning, code, and results. We systematically evaluate 11 advanced agentic LLMs using DSAEval. Our results show that Claude-Sonnet-4.5 achieves the strongest overall performance, GPT-5.2 is the most efficient, and MiMo-V2-Flash is the most cost-effective. We further demonstrate that multimodal perception consistently improves performance on vision-related tasks, with gains ranging from 2.04% to 11.30%. Overall, while current data science agents perform well on structured data and routine data anlysis workflows, substantial challenges remain in unstructured domains. Finally, we offer critical insights and outline future research directions to advance the development of data science agents.

</details>


### [548] [Foundations of Global Consistency Checking with Noisy LLM Oracles](https://arxiv.org/abs/2601.13600)
*Paul He,Elke Kirschbaum,Shiva Kasiviswanathan*

Main category: cs.AI

TL;DR: 提出一种自适应分治算法，使用LLM作为评估器来检测和定位自然语言事实集合中的全局不一致性，解决LLM判断噪声和成对检查不足的问题。


<details>
  <summary>Details</summary>
Motivation: 确保自然语言事实集合的全局一致性对于事实核查、摘要和知识库构建等任务至关重要。虽然LLM可以评估小规模事实子集的一致性，但其判断存在噪声，且成对检查无法保证全局一致性。

Method: 提出自适应分治算法，识别最小不一致子集(MUSes)，可选地通过命中集计算最小修复。该方法具有低阶多项式查询复杂度，使用LLM作为评估器。

Result: 实验表明，该方法在合成和真实LLM评估器上都能高效检测和定位不一致性，为基于LLM的语言一致性验证提供了可扩展框架。

Conclusion: 该研究为使用LLM评估器进行语言一致性验证提供了实用的可扩展解决方案，解决了全局一致性验证的指数复杂度问题，通过自适应分治算法实现了高效的不一致性检测和定位。

Abstract: Ensuring that collections of natural-language facts are globally consistent is essential for tasks such as fact-checking, summarization, and knowledge base construction. While Large Language Models (LLMs) can assess the consistency of small subsets of facts, their judgments are noisy, and pairwise checks are insufficient to guarantee global coherence. We formalize this problem and show that verifying global consistency requires exponentially many oracle queries in the worst case. To make the task practical, we propose an adaptive divide-and-conquer algorithm that identifies minimal inconsistent subsets (MUSes) of facts and optionally computes minimal repairs through hitting-sets. Our approach has low-degree polynomial query complexity. Experiments with both synthetic and real LLM oracles show that our method efficiently detects and localizes inconsistencies, offering a scalable framework for linguistic consistency verification with LLM-based evaluators.

</details>


### [549] [Resilient Routing: Risk-Aware Dynamic Routing in Smart Logistics via Spatiotemporal Graph Learning](https://arxiv.org/abs/2601.13632)
*Zhiming Xue,Sichen Zhao,Yalun Qi,Xianling Zeng,Zihan Yu*

Main category: cs.AI

TL;DR: 提出风险感知动态路由框架，结合时空图神经网络与组合优化，通过预测拥堵风险动态调整物流路径，在保证运输距离仅增加2.1%的情况下降低19.3%的拥堵风险暴露。


<details>
  <summary>Details</summary>
Motivation: 电子商务快速发展给物流网络带来巨大压力，传统静态路由策略难以应对交通拥堵和零售需求波动，需要更智能的动态路由解决方案。

Method: 1) 使用空间聚类方法从离散GPS数据构建物流拓扑图；2) 采用GCN和GRU混合深度学习模型提取时空特征预测未来拥堵风险；3) 将预测结果集成到动态边权重机制中进行路径规划。

Result: 在Smart Logistics Dataset 2024真实物联网传感器数据上评估，RADR算法显著增强供应链韧性。在高拥堵场景下，潜在拥堵风险暴露降低19.3%，运输距离仅增加2.1%。

Conclusion: 提出的数据驱动方法能有效平衡配送效率和运营安全，为动态物流路由提供了实用解决方案。

Abstract: With the rapid development of the e-commerce industry, the logistics network is experiencing unprecedented pressure. The traditional static routing strategy most time cannot tolerate the traffic congestion and fluctuating retail demand. In this paper, we propose a Risk-Aware Dynamic Routing(RADR) framework which integrates Spatiotemporal Graph Neural Networks (ST-GNN) with combinatorial optimization. We first construct a logistics topology graph by using the discrete GPS data using spatial clustering methods. Subsequently, a hybrid deep learning model combining Graph Convolutional Network (GCN) and Gated Recurrent Unit (GRU) is adopted to extract spatial correlations and temporal dependencies for predicting future congestion risks. These prediction results are then integrated into a dynamic edge weight mechanism to perform path planning. We evaluated the framework on the Smart Logistics Dataset 2024, which contains real-world Internet of Things(IoT) sensor data. The experimental results show that the RADR algorithm significantly enhances the resilience of the supply chain. Particularly in the case study of high congestion scenarios, our method reduces the potential congestion risk exposure by 19.3% while only increasing the transportation distance by 2.1%. This empirical evidence confirms that the proposed data-driven approach can effectively balance delivery efficiency and operational safety.

</details>


### [550] [Understanding Mental States to Guide Social Influence in Multi-Person Group Dialogue](https://arxiv.org/abs/2601.13687)
*Zhichao Liang,Satoshi Nakamura*

Main category: cs.AI

TL;DR: SocialMindChange：从被动追踪心理状态到主动改变心理状态的社交互动基准测试，评估LLM在复杂社交场景中规划对话以改变他人心理状态的能力。


<details>
  <summary>Details</summary>
Motivation: 现有动态心理理论基准测试主要让语言模型被动读取场景并报告心理状态变化，但真实社交互动中，心理理论被用于主动规划对话来改变他人的心理状态轨迹。需要评估LLM在主动社交互动中的能力。

Method: 构建SocialMindChange基准测试，包含1200个社交情境（4个角色、5个相连场景），模型扮演一个角色生成对话来达成目标，同时保持与所有参与者心理状态的一致性。使用结构化四步框架构建，包含6000个场景和超过90000个问题。

Result: 评估10个最先进的LLM，平均表现比人类低54.2%，表明当前LLM在长期相连互动中维持和改变心理状态表征方面仍有困难。

Conclusion: SocialMindChange揭示了LLM在主动社交互动中的显著能力差距，为评估和改进LLM的心理理论能力提供了重要基准。

Abstract: Existing dynamic Theory of Mind (ToM) benchmarks mostly place language models in a passive role: the model reads a sequence of connected scenarios and reports what people believe, feel, intend, and do as these states change. In real social interaction, ToM is also used for action: a speaker plans what to say in order to shift another person's mental-state trajectory toward a goal. We introduce SocialMindChange, a benchmark that moves from tracking minds to changing minds in social interaction. Each instance defines a social context with 4 characters and five connected scenes. The model plays one character and generates dialogue across the five scenes to reach the target while remaining consistent with the evolving states of all participants. SocialMindChange also includes selected higher-order states. Using a structured four-step framework, we construct 1,200 social contexts, covering 6000 scenarios and over 90,000 questions, each validated for realism and quality. Evaluations on ten state-of-the-art LLMs show that their average performance is 54.2% below human performance. This gap suggests that current LLMs still struggle to maintain and change mental-state representations across long, linked interactions.

</details>


### [551] [Hidden in Plain Text: Measuring LLM Deception Quality Against Human Baselines Using Social Deduction Games](https://arxiv.org/abs/2601.13709)
*Christopher Kao,Vanshika Vats,James Davis*

Main category: cs.AI

TL;DR: GPT-4o在社交推理游戏《黑手党》中比人类更擅长欺骗，通过异步多智能体框架模拟现实社交情境，检测器对LLM游戏的预测准确率低于人类游戏。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型在自然语言社交情境中的欺骗能力，特别是在社交推理游戏中，以评估LLM在现实社交互动中的安全风险。

Method: 使用异步多智能体框架模拟35场《黑手党》游戏，让GPT-4o智能体参与；创建基于GPT-4-Turbo的"黑手党检测器"分析游戏记录（无角色信息）预测黑手党玩家；将预测准确率作为欺骗质量的替代指标。

Result: 黑手党检测器对LLM游戏的预测准确率低于对人类游戏的预测，且结果在不同游戏天数和检测到的黑手党数量上保持一致，表明LLM能更好地融入群体并进行更有效的欺骗。

Conclusion: LLM在社交情境中展现出复杂的欺骗能力，这突显了其在实际应用中的潜在风险，研究同时发布了LLM游戏记录数据集供未来研究使用。

Abstract: Large Language Model (LLM) agents are increasingly used in many applications, raising concerns about their safety. While previous work has shown that LLMs can deceive in controlled tasks, less is known about their ability to deceive using natural language in social contexts. In this paper, we study deception in the Social Deduction Game (SDG) Mafia, where success is dependent on deceiving others through conversation. Unlike previous SDG studies, we use an asynchronous multi-agent framework which better simulates realistic social contexts. We simulate 35 Mafia games with GPT-4o LLM agents. We then create a Mafia Detector using GPT-4-Turbo to analyze game transcripts without player role information to predict the mafia players. We use prediction accuracy as a surrogate marker for deception quality. We compare this prediction accuracy to that of 28 human games and a random baseline. Results show that the Mafia Detector's mafia prediction accuracy is lower on LLM games than on human games. The result is consistent regardless of the game days and the number of mafias detected. This indicates that LLMs blend in better and thus deceive more effectively. We also release a dataset of LLM Mafia transcripts to support future research. Our findings underscore both the sophistication and risks of LLM deception in social contexts.

</details>


### [552] [Reasoning or Fluency? Dissecting Probabilistic Confidence in Best-of-N Selection](https://arxiv.org/abs/2601.13735)
*Hojin Kim,Jaehyung Kim*

Main category: cs.AI

TL;DR: 当前基于概率的置信度指标无法有效捕捉推理步骤间的因果依赖关系，主要反映表面流畅度而非逻辑结构


<details>
  <summary>Details</summary>
Motivation: 挑战"高置信度反映高推理质量"的假设，探究概率置信度指标是否真正捕捉推理步骤间的因果依赖关系

Method: 引入三类步骤间因果关系扰动，系统性地破坏推理步骤间的依赖关系但保持局部流畅性；提出对比因果度量方法

Result: 即使严重干扰推理步骤间的因果依赖，选择准确率仅轻微下降；当前概率指标对逻辑结构不敏感，主要捕捉表面流畅度

Conclusion: 需要开发能明确捕捉步骤间因果依赖的度量方法，对比因果度量比现有概率方法能产生更忠实的结果选择

Abstract: Probabilistic confidence metrics are increasingly adopted as proxies for reasoning quality in Best-of-N selection, under the assumption that higher confidence reflects higher reasoning fidelity. In this work, we challenge this assumption by investigating whether these metrics truly capture inter-step causal dependencies necessary for valid reasoning. We introduce three classes of inter-step causality perturbations that systematically disrupt dependencies between reasoning steps while preserving local fluency. Surprisingly, across diverse model families and reasoning benchmarks, we find that selection accuracy degrades only marginally under these disruptions. Even severe interventions, such as applying hard attention masks that directly prevent the model from attending to prior reasoning steps, do not substantially reduce selection performance. These findings provide strong evidence that current probabilistic metrics are largely insensitive to logical structure, and primarily capture surface-level fluency or in-distribution priors instead. Motivated by this gap, we propose a contrastive causality metric that explicitly isolates inter-step causal dependencies, and demonstrate that it yields more faithful output selection than existing probability-based approaches.

</details>


### [553] [Finding RELIEF: Shaping Reasoning Behavior without Reasoning Supervision via Belief Engineering](https://arxiv.org/abs/2601.13752)
*Chak Tou Leong,Dingwei Chen,Heming Xia,Qingyu Yin,Sunbowen Lee,Jian Wang,Wenjie Li*

Main category: cs.AI

TL;DR: RELIEF框架通过调整大推理模型的"推理信念"来塑造其行为，无需监督推理轨迹，只需微调自反式问答对即可提升效率和忠实度。


<details>
  <summary>Details</summary>
Motivation: 当前大推理模型存在计算冗余和推理不忠实的问题，现有基于强化学习或黄金推理轨迹微调的方法计算成本高且难以扩展，需要更高效的方法来塑造模型行为。

Method: 提出RELIEF框架：1) 发现大推理模型具有可通过logit探测捕获的潜在"推理信念"；2) 通过微调自反式问答对，将模型的自我概念与目标信念蓝图对齐，无需推理轨迹监督。

Result: 在效率和忠实度任务上的实验表明，RELIEF匹配或超越了基于行为监督和偏好的基线方法，同时训练成本更低；分析证实改变模型的推理信念能有效塑造其实际行为。

Conclusion: RELIEF提供了一种简单有效的框架，通过调整模型的自我概念来塑造其推理行为，避免了昂贵的推理轨迹监督，为高效可靠的推理模型开发提供了新途径。

Abstract: Large reasoning models (LRMs) have achieved remarkable success in complex problem-solving, yet they often suffer from computational redundancy or reasoning unfaithfulness. Current methods for shaping LRM behavior typically rely on reinforcement learning or fine-tuning with gold-standard reasoning traces, a paradigm that is both computationally expensive and difficult to scale. In this paper, we reveal that LRMs possess latent \textit{reasoning beliefs} that internally track their own reasoning traits, which can be captured through simple logit probing. Building upon this insight, we propose Reasoning Belief Engineering (RELIEF), a simple yet effective framework that shapes LRM behavior by aligning the model's self-concept with a target belief blueprint. Crucially, RELIEF completely bypasses the need for reasoning-trace supervision. It internalizes desired traits by fine-tuning on synthesized, self-reflective question-answering pairs that affirm the target belief. Extensive experiments on efficiency and faithfulness tasks demonstrate that RELIEF matches or outperforms behavior-supervised and preference-based baselines while requiring lower training costs. Further analysis validates that shifting a model's reasoning belief effectively shapes its actual behavior.

</details>


### [554] [DARC: Decoupled Asymmetric Reasoning Curriculum for LLM Evolution](https://arxiv.org/abs/2601.13761)
*Shengda Fan,Xuyan Ye,Yankai Lin*

Main category: cs.AI

TL;DR: DARC是一个两阶段自演化解耦框架，通过难度校准的问题生成和非对称自蒸馏机制，解决了自对弈中优化不稳定问题，在多个推理基准上平均提升10.9分。


<details>
  <summary>Details</summary>
Motivation: 现有自对弈框架存在优化不稳定问题：1）提问者依赖求解器反馈的非平稳目标；2）求解器使用自生成伪标签导致的引导误差。需要稳定自进化过程。

Method: DARC采用两阶段解耦框架：第一阶段训练提问者基于明确难度级别和外部语料合成难度校准的问题；第二阶段通过非对称自蒸馏机制训练求解器，使用文档增强的教师模型生成高质量伪标签来监督无文档访问的学生求解器。

Result: DARC是模型无关的，在9个推理基准和3个骨干模型上平均提升10.9分，持续优于所有基线方法，且无需人工标注就能接近全监督模型的性能。

Conclusion: DARC通过解耦和非对称自蒸馏有效稳定了自对弈的自进化过程，为自改进AI提供了有前景的解决方案，代码已开源。

Abstract: Self-play with large language models has emerged as a promising paradigm for achieving self-improving artificial intelligence. However, existing self-play frameworks often suffer from optimization instability, due to (i) non-stationary objectives induced by solver-dependent reward feedback for the Questioner, and (ii) bootstrapping errors from self-generated pseudo-labels used to supervise the Solver. To mitigate these challenges, we introduce DARC (Decoupled Asymmetric Reasoning Curriculum), a two-stage framework that stabilizes the self-evolution process. First, we train the Questioner to synthesize difficulty-calibrated questions, conditioned on explicit difficulty levels and external corpora. Second, we train the Solver with an asymmetric self-distillation mechanism, where a document-augmented teacher generates high-quality pseudo-labels to supervise the student Solver that lacks document access. Empirical results demonstrate that DARC is model-agnostic, yielding an average improvement of 10.9 points across nine reasoning benchmarks and three backbone models. Moreover, DARC consistently outperforms all baselines and approaches the performance of fully supervised models without relying on human annotations.The code is available at https://github.com/RUCBM/DARC.

</details>


### [555] [Look-Ahead-Bench: a Standardized Benchmark of Look-ahead Bias in Point-in-Time LLMs for Finance](https://arxiv.org/abs/2601.13770)
*Mostapha Benhenda*

Main category: cs.AI

TL;DR: 提出了Look-Ahead-Bench基准测试，用于评估金融LLM中的前瞻性偏差，通过实际金融工作流程测试模型表现，发现标准LLM存在显著前瞻性偏差，而PiT模型随规模增大表现更好。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要通过问答测试前瞻知识，缺乏对实际应用场景的评估。需要区分真正的预测能力和基于记忆的表现，建立标准化评估金融LLM时间偏差的基准。

Method: 创建标准化基准测试，在不同时间市场机制下分析性能衰减，引入多个量化基线建立性能阈值。评估开源LLM（Llama 3.1和DeepSeek 3.2）与PiT-Inference的PiT模型系列。

Result: 标准LLM显示出显著的前瞻性偏差（通过alpha衰减测量），而PiT模型随规模扩大展现出更好的泛化和推理能力。PiT模型在不同时间市场机制下表现更稳定。

Conclusion: 建立了评估金融LLM时间偏差的标准化基础，提供了识别适合实际部署模型的实用框架。PiT模型在减少前瞻性偏差方面表现优异，适合金融应用。

Abstract: We introduce Look-Ahead-Bench, a standardized benchmark measuring look-ahead bias in Point-in-Time (PiT) Large Language Models (LLMs) within realistic and practical financial workflows. Unlike most existing approaches that primarily test inner lookahead knowledge via Q\\&A, our benchmark evaluates model behavior in practical scenarios. To distinguish genuine predictive capability from memorization-based performance, we analyze performance decay across temporally distinct market regimes, incorporating several quantitative baselines to establish performance thresholds. We evaluate prominent open-source LLMs -- Llama 3.1 (8B and 70B) and DeepSeek 3.2 -- against a family of Point-in-Time LLMs (Pitinf-Small, Pitinf-Medium, and frontier-level model Pitinf-Large) from PiT-Inference. Results reveal significant lookahead bias in standard LLMs, as measured with alpha decay, unlike Pitinf models, which demonstrate improved generalization and reasoning abilities as they scale in size. This work establishes a foundation for the standardized evaluation of temporal bias in financial LLMs and provides a practical framework for identifying models suitable for real-world deployment. Code is available on GitHub: https://github.com/benstaf/lookaheadbench

</details>


### [556] [Virtual Urbanism: An AI-Driven Framework for Quantifying Urban Identity. A Tokyo-Based Pilot Study Using Diffusion-Generated Synthetic Environments](https://arxiv.org/abs/2601.13846)
*Glinskaya Maria*

Main category: cs.AI

TL;DR: 本文提出Virtual Urbanism (VU)框架，通过AI生成合成城市副本量化城市身份，在东京九个区域进行试点研究，验证了方法的可行性。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏可计算的城市身份度量方法，需要开发能够量化城市身份的分析框架，以支持AI增强的城市分析。

Method: 整合Stable Diffusion和LoRA模型生成东京九个区域的合成城市序列，排除现有导向标记以提取核心身份要素，并通过人类评估实验验证。

Result: 合成副本的平均识别准确率约81%，验证了有效性；开发了城市身份水平(UIL)指标评估各区域身份强度；语义分析揭示了文化嵌入的类型学作为核心身份形成要素。

Conclusion: VU框架为AI增强的城市分析提供了可行路径，展示了自动化、多参数城市身份度量的潜力。

Abstract: This paper introduces Virtual Urbanism (VU), a multimodal AI-driven analytical framework for quantifying urban identity through the medium of synthetic urban replicas. The framework aims to advance computationally tractable urban identity metrics. To demonstrate feasibility, the pilot study Virtual Urbanism and Tokyo Microcosms is presented. A pipeline integrating Stable Diffusion and LoRA models was used to produce synthetic replicas of nine Tokyo areas rendered as dynamic synthetic urban sequences, excluding existing orientation markers to elicit core identity-forming elements. Human-evaluation experiments (I) assessed perceptual legitimacy of replicas; (II) quantified area-level identity; (III) derived core identity-forming elements. Results showed a mean identification accuracy of ~81%, confirming the validity of the replicas. Urban Identity Level (UIL) metric enabled assessment of identity levels across areas, while semantic analysis revealed culturally embedded typologies as core identity-forming elements, positioning VU as a viable framework for AI-augmented urban analysis, outlining a path toward automated, multi-parameter identity metrics.

</details>


### [557] [LifeAgentBench: A Multi-dimensional Benchmark and Agent for Personal Health Assistants in Digital Health](https://arxiv.org/abs/2601.13880)
*Ye Tian,Zihao Wang,Onat Gungor,Xiaoran Fan,Tajana Rosing*

Main category: cs.AI

TL;DR: LifeAgentBench是一个大规模QA基准测试，用于评估LLM在长期跨维度生活方式健康推理方面的能力，包含22,573个问题，并提出了LifeAgent作为强基线代理。


<details>
  <summary>Details</summary>
Motivation: 个性化数字健康支持需要对异构生活方式信号进行长期跨维度推理，但当前LLM在此场景下的能力尚不明确，缺乏系统性基准测试。

Method: 引入LifeAgentBench基准测试，包含可扩展的构建流程和标准化评估协议；提出LifeAgent代理，集成多步证据检索与确定性聚合。

Result: 系统评估了11个领先LLM，识别出长期聚合和跨维度推理的关键瓶颈；LifeAgent相比两个广泛使用的基线有显著改进。

Conclusion: LifeAgentBench为LLM健康助手提供了可靠的评估框架，LifeAgent展示了在现实生活场景中的潜力，基准测试已公开可用。

Abstract: Personalized digital health support requires long-horizon, cross-dimensional reasoning over heterogeneous lifestyle signals, and recent advances in mobile sensing and large language models (LLMs) make such support increasingly feasible. However, the capabilities of current LLMs in this setting remain unclear due to the lack of systematic benchmarks. In this paper, we introduce LifeAgentBench, a large-scale QA benchmark for long-horizon, cross-dimensional, and multi-user lifestyle health reasoning, containing 22,573 questions spanning from basic retrieval to complex reasoning. We release an extensible benchmark construction pipeline and a standardized evaluation protocol to enable reliable and scalable assessment of LLM-based health assistants. We then systematically evaluate 11 leading LLMs on LifeAgentBench and identify key bottlenecks in long-horizon aggregation and cross-dimensional reasoning. Motivated by these findings, we propose LifeAgent as a strong baseline agent for health assistant that integrates multi-step evidence retrieval with deterministic aggregation, achieving significant improvements compared with two widely used baselines. Case studies further demonstrate its potential in realistic daily-life scenarios. The benchmark is publicly available at https://anonymous.4open.science/r/LifeAgentBench-CE7B.

</details>


### [558] [Human Simulation Computation: A Human-Inspired Framework for Adaptive AI Systems](https://arxiv.org/abs/2601.13887)
*Hong Su*

Main category: cs.AI

TL;DR: HSC是一个受人类启发的计算框架，将智能建模为包含思考、行动、学习、反思和活动调度的连续闭环过程，强调通过行动自动改进推理机制，无需外部干预。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型仅依赖文本数据，限制了其在开放动态现实环境中的适应能力、推理结果验证和有效操作能力，需要更接近人类智能的计算框架。

Method: 提出人类模拟计算（HSC）框架，将智能建模为包含思考、行动、学习、反思和活动调度的连续闭环内部推理过程，强调主动参与和行动驱动改进，融入人类常用思维策略如主特征导向推理、行动扩展范围和环境反馈驱动的即时学习。

Result: 通过理论分析表明，人类模拟策略无法仅从语言材料中完全学习，人类式推理过程和基于行动的推理方法对于在现实环境中实现稳健适应和有效交互至关重要。

Conclusion: HSC框架为解决大语言模型在现实环境中的局限性提供了新方向，强调行动与推理的闭环整合对于实现真正适应性和交互性智能系统的重要性。

Abstract: Large language models (LLMs) have demonstrated strong capabilities in knowledge representation and reasoning based on textual data. However, their reliance on language material alone limits their ability to adapt, verify reasoning outcomes, and operate effectively in open and dynamic real-world environments. In this paper, we propose Human Simulation Computation (HSC), a human-inspired computational framework that models intelligence as a continuous, closed-loop process involving thinking, action, learning, reflection, and activity scheduling, collectively referred to as the internal reasoning process. HSC emphasizes active participation both within the internal reasoning process and in interactions with the environment, where actions are used not only to achieve goals but also to automatically refine and improve internal reasoning mechanisms without external intervention. Furthermore, HSC incorporates commonly used human thinking strategies across all stages of the internal reasoning process, such as main-feature-oriented reasoning, scope expansion through action, and on-time learning driven by environmental feedback. Through theoretical analysis, we argue that human simulation strategies cannot be fully learned from language material alone, and that human-like reasoning processes and action-grounded reasoning methods are essential for robust adaptation and effective interaction with real-world environments.

</details>


### [559] [PREFAB: PREFerence-based Affective Modeling for Low-Budget Self-Annotation](https://arxiv.org/abs/2601.13904)
*Jaeyoung Moon,Youjin Choi,Yucheon Park,David Melhart,Georgios N. Yannakakis,Kyung-Joong Kim*

Main category: cs.AI

TL;DR: PREFAB是一种低成本的回顾式自我标注方法，通过检测情感变化区域而非完整标注来减轻标注负担，同时保持标注质量。


<details>
  <summary>Details</summary>
Motivation: 现有情感计算中的自我标注方法通常需要完整标注整个会话，这既耗时又认知负担重，容易导致疲劳和错误。需要一种更高效、负担更轻的标注方法。

Method: 基于峰值-终点规则和情感序数表示，PREFAB使用偏好学习模型检测相对情感变化，指导标注者只标注选定片段，其余部分通过插值处理。还引入了预览机制提供上下文线索辅助标注。

Result: 技术性能研究和25名参与者的用户研究表明，PREFAB在建模情感变化方面优于基线方法，减轻了工作负担（有条件地减轻了时间负担），提高了标注者信心且未降低标注质量。

Conclusion: PREFAB提供了一种有效的低预算情感标注方法，通过聚焦情感变化区域而非完整标注，在保持质量的同时显著减轻了标注负担。

Abstract: Self-annotation is the gold standard for collecting affective state labels in affective computing. Existing methods typically rely on full annotation, requiring users to continuously label affective states across entire sessions. While this process yields fine-grained data, it is time-consuming, cognitively demanding, and prone to fatigue and errors. To address these issues, we present PREFAB, a low-budget retrospective self-annotation method that targets affective inflection regions rather than full annotation. Grounded in the peak-end rule and ordinal representations of emotion, PREFAB employs a preference-learning model to detect relative affective changes, directing annotators to label only selected segments while interpolating the remainder of the stimulus. We further introduce a preview mechanism that provides brief contextual cues to assist annotation. We evaluate PREFAB through a technical performance study and a 25-participant user study. Results show that PREFAB outperforms baselines in modeling affective inflections while mitigating workload (and conditionally mitigating temporal burden). Importantly PREFAB improves annotator confidence without degrading annotation quality.

</details>


### [560] [Autonomous Knowledge Graph Exploration with Adaptive Breadth-Depth Retrieval](https://arxiv.org/abs/2601.13969)
*Joaquín Polonuer,Lucas Vittor,Iñaki Arango,Ayush Noori,David A. Clifton,Luciano Del Corro,Marinka Zitnik*

Main category: cs.AI

TL;DR: ARK是一个自适应知识图谱检索器，让语言模型通过两种操作（全局词法搜索和邻域探索）控制检索的广度-深度权衡，无需训练即可实现多跳检索，并通过蒸馏将轨迹知识迁移到小模型。


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱检索方法存在局限性：基于相似性的检索器覆盖广但深度浅，基于遍历的方法依赖种子节点选择且在多实体多关系查询中容易失败。需要一种能自适应平衡广度与深度的检索方法。

Method: 提出ARK自适应知识检索器，使用两种操作工具：1) 全局词法搜索节点描述符（广度导向）；2) 一跳邻域探索（深度导向），可组合成多跳遍历。ARK交替使用这两种操作，无需种子节点选择、预设跳数或检索训练，能根据查询类型自适应选择工具。

Result: 在STaRK基准上，ARK达到59.1%平均Hit@1和67.4平均MRR，比检索基线和无训练代理方法提升最高31.4% Hit@1和28.0% MRR。通过无标签模仿将大教师模型的工具使用轨迹蒸馏到8B模型，在AMAZON、MAG、PRIME数据集上比基础8B模型分别提升+7.0、+26.6、+13.5绝对点Hit@1，同时保留教师模型最高98.5%的Hit@1率。

Conclusion: ARK通过让语言模型控制广度-深度权衡的自适应检索策略，显著提升了知识图谱检索性能，并通过蒸馏实现了高效的知识迁移，为知识密集型任务提供了有效的检索解决方案。

Abstract: Retrieving evidence for language model queries from knowledge graphs requires balancing broad search across the graph with multi-hop traversal to follow relational links. Similarity-based retrievers provide coverage but remain shallow, whereas traversal-based methods rely on selecting seed nodes to start exploration, which can fail when queries span multiple entities and relations. We introduce ARK: Adaptive Retriever of Knowledge, an agentic KG retriever that gives a language model control over this breadth-depth tradeoff using a two-operation toolset: global lexical search over node descriptors and one-hop neighborhood exploration that composes into multi-hop traversal. ARK alternates between breadth-oriented discovery and depth-oriented expansion without depending on a fragile seed selection, a pre-set hop depth, or requiring retrieval training. ARK adapts tool use to queries, using global search for language-heavy queries and neighborhood exploration for relation-heavy queries. On STaRK, ARK reaches 59.1% average Hit@1 and 67.4 average MRR, improving average Hit@1 by up to 31.4% and average MRR by up to 28.0% over retrieval-based and agentic training-free methods. Finally, we distill ARK's tool-use trajectories from a large teacher into an 8B model via label-free imitation, improving Hit@1 by +7.0, +26.6, and +13.5 absolute points over the base 8B model on AMAZON, MAG, and PRIME datasets, respectively, while retaining up to 98.5% of the teacher's Hit@1 rate.

</details>


### [561] [Numina-Lean-Agent: An Open and General Agentic Reasoning System for Formal Mathematics](https://arxiv.org/abs/2601.14027)
*Junqi Liu,Zihao Zhou,Zekai Zhu,Marco Dos Santos,Weikun He,Jiawei Liu,Ran Wang,Yunzhou Xie,Junqiao Zhao,Qiufeng Wang,Lihong Zhi,Jia Li,Wenda Li*

Main category: cs.AI

TL;DR: 提出使用通用编码代理作为形式数学推理器的新范式，通过Numina-Lean-Agent实现，在Putnam 2025中解决所有问题，并成功形式化Brascamp-Lieb定理。


<details>
  <summary>Details</summary>
Motivation: 现有代理系统依赖特定任务流水线和训练过的形式证明器，限制了灵活性和可复现性。通用编码代理能提供超越证明的多样化推理任务接口，仅通过替换基础模型即可提升性能，且MCP支持灵活扩展和自主调用专业工具。

Method: 提出直接使用通用编码代理作为形式数学推理器的范式，开发Numina-Lean-Agent，结合Claude Code与Numina-Lean-MCP，实现与Lean的自主交互、相关定理检索、非形式化证明和辅助推理工具调用。

Result: 使用Claude Opus 4.5作为基础模型，Numina-Lean-Agent在Putnam 2025中解决了所有12个问题，与最佳闭源系统性能相当。此外，通过与数学家合作成功形式化了Brascamp-Lieb定理。

Conclusion: 通用编码代理作为形式数学推理器的新范式具有显著优势，Numina-Lean-Agent展示了其在形式定理证明和数学形式化方面的强大能力，为灵活、可扩展的数学推理系统提供了新方向。

Abstract: Agentic systems have recently become the dominant paradigm for formal theorem proving, achieving strong performance by coordinating multiple models and tools. However, existing approaches often rely on task-specific pipelines and trained formal provers, limiting their flexibility and reproducibility. In this paper, we propose the paradigm that directly uses a general coding agent as a formal math reasoner. This paradigm is motivated by (1) A general coding agent provides a natural interface for diverse reasoning tasks beyond proving, (2) Performance can be improved by simply replacing the underlying base model, without training, and (3) MCP enables flexible extension and autonomous calling of specialized tools, avoiding complex design. Based on this paradigm, we introduce Numina-Lean-Agent, which combines Claude Code with Numina-Lean-MCP to enable autonomous interaction with Lean, retrieval of relevant theorems, informal proving and auxiliary reasoning tools. Using Claude Opus 4.5 as the base model, Numina-Lean-Agent solves all problems in Putnam 2025 (12 / 12), matching the best closed-source system. Beyond benchmark evaluation, we further demonstrate its generality by interacting with mathematicians to successfully formalize the Brascamp-Lieb theorem. We release Numina-Lean-Agent and all solutions at https://github.com/project-numina/numina-lean-agent.

</details>


### [562] [Remapping and navigation of an embedding space via error minimization: a fundamental organizational principle of cognition in natural and artificial systems](https://arxiv.org/abs/2601.14096)
*Benedikt Hartl,Léo Pio-Lopez,Chris Fields,Michael Levin*

Main category: cs.AI

TL;DR: 该论文提出了一个统一框架，认为自然和人工系统的认知都基于两个尺度不变原则：嵌入空间的重映射和在这些空间中的导航，通过迭代误差最小化实现。


<details>
  <summary>Details</summary>
Motivation: 寻求一个整合视角来理解不同起源、组成和基质的智能体中的问题解决，探索从亚细胞化学网络到生物群落的尺度不变决策原则。

Method: 提出认知的双重原则框架：1) 嵌入空间的重映射（如转录、形态、生理或3D空间），2) 在这些空间中的导航（通过分布式误差校正）。

Result: 发现生物集体（从单细胞到整个生物体）和现代AI系统（如transformer、扩散模型、神经细胞自动机）都遵循相同的重映射和导航机制。

Conclusion: 重映射和通过迭代误差最小化的嵌入空间导航构成了认知的基质独立不变性，为跨尺度工程化自适应智能提供了统一框架。

Abstract: The emerging field of diverse intelligence seeks an integrated view of problem-solving in agents of very different provenance, composition, and substrates. From subcellular chemical networks to swarms of organisms, and across evolved, engineered, and chimeric systems, it is hypothesized that scale-invariant principles of decision-making can be discovered. We propose that cognition in both natural and synthetic systems can be characterized and understood by the interplay between two equally important invariants: (1) the remapping of embedding spaces, and (2) the navigation within these spaces. Biological collectives, from single cells to entire organisms (and beyond), remap transcriptional, morphological, physiological, or 3D spaces to maintain homeostasis and regenerate structure, while navigating these spaces through distributed error correction. Modern Artificial Intelligence (AI) systems, including transformers, diffusion models, and neural cellular automata enact analogous processes by remapping data into latent embeddings and refining them iteratively through contextualization. We argue that this dual principle - remapping and navigation of embedding spaces via iterative error minimization - constitutes a substrate-independent invariant of cognition. Recognizing this shared mechanism not only illuminates deep parallels between living systems and artificial models, but also provides a unifying framework for engineering adaptive intelligence across scales.

</details>


### [563] [Paper2Rebuttal: A Multi-Agent Framework for Transparent Author Response Assistance](https://arxiv.org/abs/2601.14171)
*Qianli Ma,Chang Guo,Zhiheng Tian,Siyu Wang,Jipeng Xiao,Yuanhao Yue,Zhipeng Zhang*

Main category: cs.AI

TL;DR: RebuttalAgent是一个多智能体框架，将反驳生成重构为以证据为中心的规划任务，通过分解评审意见、构建混合上下文和集成外部搜索来生成可验证的、基于证据的反驳。


<details>
  <summary>Details</summary>
Motivation: 当前的反驳生成方法通常将其视为直接文本生成问题，存在幻觉、忽略批评意见和缺乏可验证基础等问题。需要一种能够精确对齐评审意图和稿件细节的解决方案。

Method: 提出RebuttalAgent多智能体框架：1) 将复杂反馈分解为原子关注点；2) 动态构建混合上下文，合成压缩摘要与高保真文本；3) 集成自主按需外部搜索模块解决需要外部文献的问题；4) 在起草前生成可检查的响应计划。

Result: 在提出的RebuttalBench上验证，该流水线在覆盖率、忠实度和策略连贯性方面优于强基线，为同行评审过程提供了透明可控的助手。

Conclusion: RebuttalAgent通过将反驳生成重构为证据中心的规划任务，解决了现有方法的局限性，提供了可验证、透明且可控的同行评审助手，代码将开源。

Abstract: Writing effective rebuttals is a high-stakes task that demands more than linguistic fluency, as it requires precise alignment between reviewer intent and manuscript details. Current solutions typically treat this as a direct-to-text generation problem, suffering from hallucination, overlooked critiques, and a lack of verifiable grounding. To address these limitations, we introduce $\textbf{RebuttalAgent}$, the first multi-agents framework that reframes rebuttal generation as an evidence-centric planning task. Our system decomposes complex feedback into atomic concerns and dynamically constructs hybrid contexts by synthesizing compressed summaries with high-fidelity text while integrating an autonomous and on-demand external search module to resolve concerns requiring outside literature. By generating an inspectable response plan before drafting, $\textbf{RebuttalAgent}$ ensures that every argument is explicitly anchored in internal or external evidence. We validate our approach on the proposed $\textbf{RebuttalBench}$ and demonstrate that our pipeline outperforms strong baselines in coverage, faithfulness, and strategic coherence, offering a transparent and controllable assistant for the peer review process. Code will be released.

</details>


### [564] [Toward Efficient Agents: Memory, Tool learning, and Planning](https://arxiv.org/abs/2601.14192)
*Xiaofang Yang,Lijun Li,Heng Zhou,Tong Zhu,Xiaoye Qu,Yuchen Fan,Qianshan Wei,Rui Ye,Li Kang,Yiran Qin,Zhiqiang Kou,Daizong Liu,Qi Li,Ning Ding,Siheng Chen,Jing Shao*

Main category: cs.AI

TL;DR: 该论文系统研究了智能体系统的效率问题，从内存、工具学习和规划三个核心组件出发，分析成本（延迟、token数、步骤数等），并提出了两种效率评估方式：固定成本预算下的效果比较和相似效果水平下的成本比较。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型向智能体系统扩展，现有研究主要关注效果提升，而实际部署中至关重要的效率问题常被忽视。本文旨在填补这一空白，对智能体系统本身的效率进行全面研究。

Method: 从智能体的三个核心组件（内存、工具学习、规划）出发，综述了多种提高效率的方法，包括：通过压缩和管理限制上下文、设计强化学习奖励以减少工具调用、采用受控搜索机制等。提出了两种效率评估框架，并总结了相关基准测试和评估指标。

Result: 系统梳理了智能体效率优化的共同原则和方法，建立了效率评估的双重框架（固定成本下的效果比较和相似效果下的成本比较），总结了现有的效率导向基准测试和评估指标，为智能体系统的效率研究提供了系统化视角。

Conclusion: 智能体系统的效率研究至关重要但常被忽视，本文通过系统分析三个核心组件和效率评估框架，为未来高效智能体系统的设计和评估提供了理论基础和实践指导，并指出了关键挑战和未来研究方向。

Abstract: Recent years have witnessed increasing interest in extending large language models into agentic systems. While the effectiveness of agents has continued to improve, efficiency, which is crucial for real-world deployment, has often been overlooked. This paper therefore investigates efficiency from three core components of agents: memory, tool learning, and planning, considering costs such as latency, tokens, steps, etc. Aimed at conducting comprehensive research addressing the efficiency of the agentic system itself, we review a broad range of recent approaches that differ in implementation yet frequently converge on shared high-level principles including but not limited to bounding context via compression and management, designing reinforcement learning rewards to minimize tool invocation, and employing controlled search mechanisms to enhance efficiency, which we discuss in detail. Accordingly, we characterize efficiency in two complementary ways: comparing effectiveness under a fixed cost budget, and comparing cost at a comparable level of effectiveness. This trade-off can also be viewed through the Pareto frontier between effectiveness and cost. From this perspective, we also examine efficiency oriented benchmarks by summarizing evaluation protocols for these components and consolidating commonly reported efficiency metrics from both benchmark and methodological studies. Moreover, we discuss the key challenges and future directions, with the goal of providing promising insights.

</details>
